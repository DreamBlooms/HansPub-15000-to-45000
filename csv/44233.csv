"研究了基于视频的疲劳人脸检测问题。通过网络爬虫、CEW数据集和现场采集三种方式构建了疲劳人脸检测数据集样本，通过dlib算法识别人面部的特征点，提出了一种基于嘴部开合面积的改进判别策略，作为识别疲劳程度的标志，测试结果表明，算法精度较通用算法提升了8%，达到89%以上，且具有较好的泛化能力，为算法的工程化应用奠定了坚实基础。"
"随着经济的发展，汽车已经在人民的生活中日益普及，随即产生的问题是交通事故数量的不断增加。据公安部统计，2019年中国交通事故发生数量为24.8万起，死亡人数连续10多年居世界首位。疲劳驾驶引起的事故约占交通事故总量的25%~30%，而导致的车内人员重伤或死亡人数约占49%。上述结果表明，疲劳驾驶是重大交通事故的主要因素。研究表明，若驾驶员在危险出现的前几秒收到提示，大量事故可以避免发生，因此开展驾驶员疲劳状态检测研究具有重要意义。 基于图像的疲劳人脸检测研究近年来得到了普遍关注。文献 [ 1 ] 利用红外获取人类眼球特征，对眼球状态进行检测，从而判断测试人员疲劳与否。美国研制的瞌睡预警系统 [ 2 ]，依据PERCLOS算法对人当前的疲劳状态进行判断。PERCLOS算法 [ 3 ] 也是目前最为常用的基于眼睛状态的检测算法。PERCLOS是Percent of eyelid closure Over the Pupil Over Time的缩写，即：眼睛闭合时间占某一特定时间的百分率。2015年以来，随着深度学习的快速发展，已经有研究人员采用YOLO V5 [ 4 ]、SSD [ 5 ] 等卷积神经网络，识别测试者疲劳程度，研究结果表明，在硬件资源充足的情况下，识别的精度较高，但卷积神经网络结构复杂，资源消耗高导致难以在实际项目中得到普遍应用。针对这一问题，为在保障算法精度的同时降低计算量，提升算法的工程应用价值，受PERCLOS算法的启发对其进行改进，将嘴部和眼部同时进行检测，提出了一种改进算法，在自建疲劳人脸数据集上进行了了测试，取得较好效果，整个算法的流程如下图1所示。"
"目前学术也尚无疲劳人脸标准数据集，为此通过网络爬虫、CEW数据集 [ 6 ] 和现场采集等三种方式构建了疲劳人脸检测数据集样本数据集。 编写针对百度图片的爬虫小程序，获得600张图片(如图2所示)。南京航空航天大学提供的闭眼数据集CEW (Closed eyes in the wild) (如图3所示)包含了2423个测试者睁眼与闭眼状态的照片，数据集充分考虑了测试者个体的差异及光照、模糊度、遮挡等因素，通常用于眼睛检测任务的研究，因此从该数据集中手工筛选部分照片用于构建疲劳人脸图片样本 [ 7 ]。为进一步丰富数据集来源，增加数据的可靠性，项目组邀请实验室部分成员采集137张包含打哈欠和眼睛微闭的人脸图片。 图1. 疲劳人脸检测算法流程图 图2. 百度爬虫数据 图3. CEW数据集  在构建了数据集后，对数据进行遴选。鉴于上述数据中包括卡通图片之类的干扰，因此进行了人工遴选，使用opencv [ 8 ] 的人脸识别工具haarcascade_frontalface_alt.xml将图片尺寸统一裁剪为128*128，随后使用卷积神经网络将数据进行增广操作 [ 9 ]，将原始数据进行镜像处理、左右反转、随机裁剪等操作，将128*128图像随机裁剪为120*120，再将其尺寸扩增到128*128；之后添加少量的椒盐噪声 [ 10 ]。  经过遴选和数据处理之后，最终获得的合格的自制数据集样本图像2390张，其中正样本1191张，负样本1199张。样本经过规格化处理，所有样本大小均为128*128。最终制作好的数据集正负样本如下图4和图5所示。"
"Dlib是一个现代化的C++工具包，包含机器学习算法和工具，可以用于在C++中创建复杂的软件以解决现实世界的问题。它在工业界和学术界中广泛使用，包括机器人、嵌入式设备、移动电话和大型高性能计算环境。其核心原理是使用了图像Hog特征来表示人脸，和其它特征提取算子相比，它对图像的几何和光学的形变都能保持很好的不变性。该特征与LBP特征 [ 11 ]、Harr特征共同作为三种经典的图像特征，该特征提取算子通常和支持向量机(SVM)算法 [ 12 ] 搭配使用，用在物体检测场景。 Dlib实现的人脸检测方法便是基于图像的Hog特征，综合支持向量机算法实现的人脸检测功能，该算法的实现路径如下：对正样本数据集提取Hog特征 [ 13 ]，得到Hog特征描述子。对负样本数据集提取Hog特征，得到Hog描述子。利用SVM训练正负样本。利用该模型进行负样本难例检测，也就是难分样本挖掘，以便提高最终模型的分类能力。 图4. 正样本(疲劳) 图5. 负样本(非疲劳)  使用python调用Dlib [ 14 ]，首先需要安装Dlib人脸检测库，随后加载模型文件进行68个人脸关键点检测，如图6所示。"
"人在疲劳的状态下，眼睛和嘴巴的变化幅度较为明显，据此给出设计规则的算法初步设计思路：当人的眼睛闭合程度小于某个阈值，且人的嘴巴特征大于某个阈值，就可以判定这个人处于疲劳状态。阈值大小考虑根据网格法设置一定的步长，通过逐点测试的方式寻找最优数值。这整个算法设计思路包括：眼睛和嘴巴定位 [ 15 ]，及眼睛和嘴巴状态检测。具体步骤如图7所示。 图6. Dlib人脸检测特征点 图7. 算法设计流程  目前有很多成熟的算法能够从图像中检测眼睛、嘴巴，例如灰度投影方法，基于可变形模板的定位方法，基于霍夫变换的人眼定位等等，由于前期使用了dlib做了人脸特征点的识别，因此只需要找到眼部对应特征点就可以定位眼睛。眼部特征点分别为：36、37、38、39、40、41和42、43、44、45、46、47，嘴部的特征点是：48、49、50、51、52、53、54、55、56、57、58、59、60、61、62、63、64、65、66、67。识别到这些特征点等同于眼睛或嘴巴定位。  通过dlib定位到眼睛和嘴巴后，围绕眼部和嘴部的特征点进行数据处理。首先，基于眼部的开合程度去做判断 [ 16 ]，当眼部的长宽比大于某个阈值时，就判定为疲劳。随后，加入嘴巴的判定，采用类似眼部状态识别的方式，当嘴巴的长宽比大于某个阈值时，就判定为疲劳。试验结果表明，单纯依靠眼部和嘴巴的特征，算法精度有限。 针对上述问题，为进一步提升算法可靠性，将眼睛和嘴巴特征进行结合，进行人类疲劳特征检测判断。取前30帧图像的平均值作为眼睛判别的阈值；与此同时，采用嘴巴部分面积大小作为判断人脸疲劳的另一特征，当眼睛特征小于某一阈值且嘴巴面积大于某一阈值时，则判定其处于疲劳状态。整个算法的逻辑图如下图8所示。 图8. 阈值与疲劳判断逻辑 算法具体情况如下。将dlib检测到的36、37、38、39、40和41这6个围绕眼部的特征点进行处理：将36、39的横坐标之差作为眼睛的长，将37、38、41、40的纵坐标之差作为眼睛的宽，随后计算长宽比。在获取了嘴巴的60、49、50、51、52、53、64、55、56、57、58、59 这12个特征点后，将其分成10个三角形，计算每个三角形的面积，通过累加求和计算嘴巴的总面积。当眼睛长宽比大于某一阈值，且嘴巴也大于某一阈值时，则判定此时被测试人是疲劳状态。采用网格法 [ 17 ] 获取最佳阈值，最终确定眼睛长宽比的阈值设定在2.95，嘴巴面积阈值为在2150。"
"代码实现的环境为：Windows10操作系统、Python语言、IDE是Pycharm，系统的硬件环境为Intel(R) Core(TM)i5-4200M CPU处理器。  为测试论文提出的算法的有效性，基于项目自建的数据集，进行了10个状态、20组，总共200次的泛化测试，每次状态识别时间为15秒，最终的结果为：正确178次，错误22次，识别的效果图如下图9和图10所示，同时采用通用算法进行了对比实验，结果如表1所示。 图9. 检测状态为疲劳 图10. 检测状态为非疲劳 Table 1 算法 本算法 通用算法 识别率 89 81 表1. 设计算法与通用算法识别率(%)"
"通过网络爬虫、CEW数据集和现场采集三种方式构建了疲劳人脸检测数据集样本，基于dlib的人脸特征点检测方法，设计了一种基于眼睛和嘴巴特征结合的改进检测算法，进行人类疲劳特征检测判断。测试结果表明，算法精度较通用算法提升了8%，达到89%，且具有较好的泛化能力，提升了算法的工程应用价值。"
