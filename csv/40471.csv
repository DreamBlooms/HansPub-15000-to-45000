"由于朴素贝叶斯分类器对特征变量作了独立性假设，忽略了相关性，导致在某些特征相关的情况下分类效果很差。为了提高分类效果，本文对有缺失的数据集利用C-Vine Copula理论进行填补从而得到完整的数据集，并结合Copula函数研究特征变量之间的相关性优化问题，用C-Vine Copula分类器对完整数据集做分类。结果表明，基于C-Vine Copula理论的监督学习分类器具备良好的分类性能。"
"随着信息技术与网络技术的高速发展，各个行业每天都会产生大量数据。然而现实世界中的数据集通常有质量问题，如存在一些错误数据、缺失数据、不确定数据。在数据质量问题中，缺失数据现象尤其常见。 朴素贝叶斯分类是机器学习和数据挖掘中最流行的学习算法之一，主要用于给定特征变量的分类问题。朴素贝叶斯分类器对分类对象的特征变量作了条件独立性假设，该假设忽略了特征变量之间的相关性，从而忽略了实际数据中的相关性 [ 1 ]。 Sklar (1959) [ 2 ] 提出的Copula理论指出，一个多元联合分布可以分解为k个边缘分布和一个Copula函数，这个Copula函数描述了变量间的相关性。Nelsen (1999) [ 3 ] 较为系统地介绍了Copula函数的定义和构建方法，使得Copula理论成为构造多元变量联合分布及描述随机变量间相依结构的重要工具。Joe (1996) [ 4 ] 首次提出了Pair Copula的理念，Bedford和Cooke (2001) [ 5 ] 基于Joe的研究提出了Pair Copula构建(PCC)方法，利用图论中藤(Vine)描述结构，将高维Copula函数仿照树藤结构的分解形式分解为一系列二元成对Copula函数，称为Vine Copula模型。Aas (2009) [ 6 ] 等进一步深入研究Vine Copula模型，详细论述了Vine Copula模型的参数估计和数值模拟的方法。 针对有缺失的数据集，本文设计并提出基于C-Vine Copula理论的贝叶斯分类器，进一步优化贝叶斯分类器。首先，确定需要归因的特征变量，通过C-Vine Copula理论将数据集的联合概率分布分解为一系列二元Copula函数与边缘概率密度函数乘积的形式；然后，将归因特征作为目标特征，对其他特征变量根据特征样本间的相关性，选择适当的二元Copula函数，计算条件分布函数和相应的逆函数，从而提出C-Vine Copula Imputation算法(CVI)，用该算法得到的预测值替换缺失值得到新的数据集，对新的数据集构建贝叶斯分类器中的条件概率密度函数；最后，将优化后的分类器应用到实际分类问题中，对模型进行分析验证。与样本丢弃法(NADel)、均值归因法(Mean)、预测平均匹配插补法(PMM)、贝叶斯线性回归归因法(Norm)、分类回归树归因法(Cart)和在观测值中随机抽样归因法(Sample)比较，本文提出的分类器具备良好的性能，能够为有缺失的数据集的分类提供新的实现途径。"
"根据Sklar定理可知，一组n维随机向量，其联合概率分布可以分解为n个一元的边缘分布函数与一个n维Copula函数的乘积。设 X = ( X 1 , ⋯ , X n ) 为一组n维随机变量，其联合概率分布 F ( x 1 , ⋯ , x n ) 与边缘分布 F 1 , ⋯ , F n 的关系可以表示为： F ( x 1 , ⋯ , x n ) = C ( F 1 ( x 1 ) , ⋯ , F n ( x n ) ) ， 如果各边缘分布函数都是连续的，则Copula函数是唯一的。若 F k 的逆函数 F k − 1 存在，则 C ( u 1 , ⋯ , u n ) = F ( F 1 − 1 ( u 1 ) , ⋯ , F n − 1 ( u n ) ) ， 其中 u k = F k ( x k ) ∈ ( 0 , 1 ) ， k = 1 , 2 , ⋯ , p 。当Copula函数可微时，可以得到F的联合概率分布 f ( x 1 , ⋯ , x n ) = ∏ k − 1 p f k ( x k ) ⋅ c ( F 1 ( x 1 ) , ⋯ , F n ( x n ) ) ， f k ( x k ) 是 F k 的边缘密度，c是C的Copula密度。 f ( x 1 , ⋯ , x n ) = f n ( x n ) ⋅ f ( x n − 1 | x n ) ⋅ f ( x n − 2 | x n − 1 , x n ) ⋯ f ( x 1 | x 2 , ⋯ , x n ) (1) 根据Aas [ 6 ] 等的论述，可以再次分解条件概率密度函数式(1)，可得 f ( x | ν ) = c x , v j | ν − j ( F ( x | ν − j ) , F ( v k | ν − j ) ) ⋅ f ( x | ν − j ) ， 其中，条件分布的表达式为 F ( x | ν ) = ∂ C x , ν j | ν − j ( F ( x | ν − j ) , F ( v j | ν − j ) ) ∂ F ( v j | ν − j ) ， ν 是随机变量x去掉 x i 后的 n − 1 维向量； ν − j 是 ν 中去掉 ν j 后的向量； ν j 为 ν 中任意一个成分； c x , ν j | ν − j 为相应条件下的二元Copula条件概率密度函数。 当 ν − k = Φ ，x和 ν 都是均匀分布时，式(6)可简化得到 h ( x , ν ) = F ( x | ν ) = ∂ C x , ν ( x , ν ) ∂ ν ， (2) 其中 h ( ⋅ ) 称为h-函数，是用于生成伪观测值的函数，之后将用它来拟合C-Vine结构的模型 [ 7 ]。  在构建多维变量的联合概率分布函数时，可以用多种二元Copula结构描述变量之间的相关性，其中C-vine Copula和D-vine Copula是最典型的两种 [ 8 ]。本文采用C-vine Copula结构对随机变量的复杂相关性进行建模。图1为一个4维C-Vine的分解实例。 图1. 4维C-vine结构 逆采样方法是较为常见的生成随机数的方法，令F是 ℜ 上连续递增的分布函数，它的逆函数 F − 1 定义为： F − 1 : ( 0 , 1 ) → ℜ ， F − 1 ( x ) : = inf { y ∈ ℜ : F ( y ) ≥ x } 。 如果 U ~ U [ 0 , 1 ] 是在 [ 0 , 1 ] 上的均匀分布随机变量，则 F − 1 ( U ) 有分布函数F。如果X有分布函数F，则 F ( X ) 是 [ 0 , 1 ] 上的均匀分布。 Bedford和Cooke [ 5 ] [ 9 ] 以及Kurowicka和Cooke等 [ 10 ] 对Vine抽样算法都有讨论。Aas等 [ 6 ] 给出C-Vine和D-Vine的一般性算法。对于 X = ( X 1 , ⋯ , X n − 1 , X n ) 这组n维随机变量， X n 上有缺失数据。首先，生成与缺失数据数量相等的随机数 v n ；再根据条件分布函数和h-函数可以得到 F ( x n | x 1 , ⋯ , x n − 1 ) = ∂ n − 1 C n , n − 1 | 1 : n − 2 ( F ( x n | x 1 , ⋯ , x n − 2 ) , F ( x n − 1 | x 1 , ⋯ , x n − 2 ) ) ∂ F ( x n − 1 | x 1 , ⋯ , x n − 2 ) 。 所以，缺失数据 X n 可以表示为 X n = F n | 1 : n − 1 − 1 ( V n | X 1 , ⋯ , X n − 1 ) 。  在n维C-Vine结构中，有 n − 1 颗树 T j ( j = 1 , ⋯ , n − 1 ) ，每棵树由节点和边组成。每条边对应一个二元Copula，树 T j 的边是树 T j + 1 的节点。整个分解由n个边缘分布和 n ( n − 1 ) / 2 个二元Copula的乘积得到的。由此可知，C-vine Copula结构的联合概率分布函数可以分解为 f ( x 1 , ⋯ , x n ) = ∏ k = 1 n f ( x k ) × ∏ i = 1 n − 1 ∏ j = 1 n − i c i , i + j ; 1 : ( i − 1 ) ( F ( x i | x 1 , ⋯ , x i − 1 ) , F ( x i + j | x 1 , ⋯ , x i − 1 ) ) ， (3) 其中， F ( ⋅ | ⋅ ) 是条件分布函数，可由式(2)得到； c i , i + j ; 1 : ( i − 1 ) 为二元Copula条件概率密度。 根据贝叶斯准则，向量 X = ( X 1 , ⋯ , X n ) 是类别 e ∈ E 的概率为 Pr ( e | x ) ∝ Pr ( x | e ) ⋅ Pr ( e ) ， (4) 其中E是类向量， E = ( e 1 , ⋯ , e l ) ′ ，l是类别总数。结合联合概率分布函数式(3)，式(4)写作 Pr ( e | x ) ∝ ∏ k = 1 n f k ( x k | e ) ∏ i = 1 n − 1 ∏ j = 1 n − i c i , i + j ; 1 : ( i − 1 ) ( F ( x i | x 1 , ⋯ , x i − 1 ) , F ( x i + j | x 1 , ⋯ , x i − 1 ) | e ) ︸ f ( x | e ) × Pr ( e ) 。 根据最大后验决策规则(MAP)，可以得到 classify ( x ) = { e : arg max f ( x | e ) ⋅ Pr ( e ) } 。 本文采用核函数方法估计边缘概率密度函数。核函数方法是一种非参数方法， x 1 , ⋯ , x n 是独立同分布的n个样本点，设概率密度函数为f，则测试样本x的概率密度估计值为 f ^ n ( x ) = 1 n ∑ i = 1 n K n ( x − x i ) = 1 n h ∑ i = 1 n K ( x − x i h ) ， 其中， K ( ⋅ ) 是高斯核函数； h > 0 称为带宽 [ 11 ] [ 12 ]。"
"为验证本文提出方法的有效性和可行性，用UCI数据库中的数据集对比不同填补缺失数据方法下的分类结果。  首先，对数据集某一列 X n 做完全随机缺失，缺失率分别为5%、10%、20%、50%和70%，将数据集分为完整数据(complete)和缺失数据(missing)。然后，根据CVI得出缺失数据 u n ，并将 u n 与70%的完整数据(complete)放在一起作为新的训练集，剩下的30%完整数据作为测试集，依据新的训练集用C-vine Copula分类器对测试集进行分类。接下来，分别用样本丢弃法(NADel)、均值归因法(Mean)、预测平均匹配插补法(PMM)、贝叶斯线性回归归因法(Norm)、分类回归树归因法(Cart)及从观测值中随机抽样归因法(Sample)填补缺失数据，再在C-Vine Copula分类器上对测试集分类。最后，重复以上步骤100次，得到不同填补算法的平均分类准确性。各个填补算法的分类结果如下。  对UCI中的2个数据集分别在缺失率为5%、10%、20%、50%和70%的情况下，用CVI、NADel、Mean、PMM、Norm、Cart和Sample做填补处理。分类准确率的测试结果如表1和表2所示。由表1、表2可知，相比其他填补算法，CVI算法在大多数情况下均能得到更高的分类准确率。 Table 1 缺失率 CVI NADel Mean PMM Norm Cart Sample 5% 0.95644 0.81200 0.94800 0.95778 0.78556 0.95578 0.95667 10% 0.95778 0.81244 0.94778 0.95533 0.72733 0.95556 0.95489 20% 0.95489 0.86022 0.95022 0.95156 0.56889 0.95422 0.95067 50% 0.94733 0.86044 0.95289 0.94867 0.46089 0.94844 0.94667 70% 0.93711 0.85356 0.94667 0.93733 0.41422 0.94356 0.93267 5% 0.95644 0.81200 0.94800 0.95778 0.78556 0.95578 0.95667 10% 0.95778 0.81244 0.94778 0.95533 0.72733 0.95556 0.95489 表1. Iris数据集填补算法分类性能表 Table 2 缺失率 CVI NADel Mean PMM Norm Cart Sample 5% 0.94443 0.92057 0.94352 0.92567 0.76876 0.91319 0.94067 10% 0.94529 0.93729 0.94429 0.90848 0.71419 0.91381 0.93948 20% 0.94686 0.93729 0.94638 0.92533 0.69410 0.92014 0.94100 50% 0.95129 0.90781 0.94343 0.92614 0.65114 0.87686 0.92571 70% 0.95252 0.91243 0.94867 0.89952 0.65752 0.87848 0.90086 5% 0.94443 0.92057 0.94352 0.92567 0.76876 0.91319 0.94067 10% 0.94529 0.93729 0.94429 0.90848 0.71419 0.91381 0.93948 表2. Breast Cancer数据集填补算法分类性能表 图2描绘了数据集Breast Cancer在5种不同数据缺失率的情况下，用7种填补算法得到的分类性能比较图。由折线图可知，CVI算法在7种填补算法中具有最好的分类性能。 图2. Breast Cancer的分类性能图"
"本文针对数据集中存在缺失数据的情况，结合C-vine Copula函数，利用条件分布函数填补缺失数据，再将变量的联合概率分布分解成二元Copula函数与边缘概率密度函数乘积的形式，分别对二元Copula函数和边缘概率密度函数进行优化估计，将特征变量之间的复杂相关性构建在条件概率密度函数中。与其他算法相比，提高了贝叶斯分类器处理具有复杂相关性特征变量数据的分类性能，在实际应用中得到了较好的分类结果。"
