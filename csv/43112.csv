"人工智能技术的发展和不断成熟使其也更加广泛的应用到了传媒行业，给传媒业带来了巨大的变化。本文探讨了人工智能技术为媒体行业带来的新发展，如它使媒介在传递信息时突破了时空界限、提升了受众接收新闻信息的体验感、丰富了新闻内容的传播方式等，主要指出了智能新闻带来的媒介伦理失范现象，如新闻真实的淡化、新闻专业主义的消减、隐私权受到威胁等；同时针对上述失范现象，从政府、受众、企业、新闻从业者等多个角度提出了相应的解决措施。"
"2017年被业界称为人工智能商业化和产业化元年，在智能算法、大数据、运算能力的共同推动下，迎来了人工智能的第三次浪潮。同时，人工智能也更加广泛的应用到了传媒行业，带动了各大新媒体平台的发展，给传媒业带来了巨大的变化，它使得媒介在传递信息时突破了时空界限；提升了受众接受新闻信息的体验感；丰富了新闻内容的传播方式等等。总之，人工智能在传媒业的应用使得媒介的发展更加依赖于技术，也推动了媒介融合的发展趋势。但于此同时，伴随人工智能时代的到来，传媒业也滋生了许多的新媒介伦理失范问题，比如算法推荐带来的意见偏向性、机器人新闻伦理遭受质疑、假新闻现象严重等等。今年3月28日国家网信办指导组织“抖音”、“快手”、“火山小视频”等短视频平台试点上线青少年防沉迷系统，自此短视频平台保护青少年的“青少年模式”上线；2018年6月30日，北京网信办和北京工商局约谈“抖音”、“搜狗”和相关广告公司，就两公司出现的“侮辱英烈”广告内容进行跟进，要求五家公司自约谈日起，整改广告业务；2018年11月16日，“今日头条”头条号运营团队发布了《头条号平台持续打击违规账号的公告》，于此该平台展开了对标题党、低俗、谣言、刷粉刷量、侵犯版权等问题的清理。人工智能虽然给新媒体的发展带来了推动力，但随之而来的媒介伦理问题也是不可忽视的。  本文从人工智能技术在传媒行业的应用入手，通过对某些实例的解析，阐述人工智能的发展给媒介带来的影响和变化，主要探讨人工智能时代的媒介失范现象及具体原因，并针对性的提出相应的应对策略。理论层面，本文希望能够丰富技术媒介伦理方向的研究，提升该类研究的系统性和完整性，为业界提供可参考性观点和内容。实践层面，本文希望提出的可采取性措施能够有效改善当前媒介的失范现象，推动文明绿色网络空间的建成。"
"人工智能简称AI，它是计算机科学的一个分支，它的目的主要是研究出能胜任一些通常需要人类智能才能完成的复杂工作的机器，人工智能领域非常宽泛，包括机器人、语言识别、图像识别、自然语言处理等等。如今人工智能技术在媒介领域的使用非常广泛，比如“智能机器人”、“沉浸式新闻”、“算法推荐”等，这些技术在媒介的应用给媒介的发展带来了很多机遇，提升了媒介传递信息的时效，增强了受众的信息体验感，丰富了媒介传播新闻的方式，提高了受众地位。  人工智能对媒介信息传播时效性的影响，主要表现在搜集信息、整理信息和发布信息层面。搜集信息，媒介只有掌握有价值的新闻信息才能赢得受众，才有其存在的价值，然而有些重大新闻事件的信息搜集难上加难，尤其是灾难性新闻和自然灾害性新闻，传感器技术的出现，让无人机技术、GPS定位技术应用到了新闻信息的搜集中，给灾难性事件和自然灾害性事件的新闻搜集和报道带来了便利；整理信息和发布信息，机器人新闻生产通过数据采集、数据整理加工、自动写稿、编辑签发四个环节快速完成，2015年腾讯财经新闻就采取机器人发布了一篇《8月CH涨2%创12个月新高》，开辟了国内机器人写稿的先河。从某种程度来说，人工智能技术的应用加快了新闻生产的速度，有效的提高了信息传播的时效性。  人工智能技术的发展使得沉浸式新闻成为现实，沉浸式新闻这一概念由诺妮·德拉佩纳提出，指“可以增强使用者在新闻故事中事件或情境的第一人称体验的新闻制作形式” [ 1 ]。数据可视化的沉浸式新闻报道用数据图表创建新闻场景，抽象化、专业化的数据以直接清晰的方式呈现，让受众对新闻事件一目了然，如同身临其境，提升了其体验感，让传统文字图片式新闻不再乏味，让受众主动去感受信息，感受新闻。而央视新闻、央视频、央视网等总台新媒体都在已将AI技术应用于新闻制作过程中，央视新闻推出的《走过天安门》系列短视频凭借沉浸式的体验应得了不少收视率。  随着人工智能在媒介行业的使用，算法逐渐被运用到新闻生产过程中，尽管仍处于初期探索阶段，但使得传媒业发生了巨大的变化。受众不再被动接受媒介信息，而是转变成了“用户”，而在此身份的转换过程中，算法精准推送实际上将一部分的传播主动权交给了受众，使得受众以信息传播者的身份主动参与到传播过程中，与此同时，算法根据用户的需求和喜好对不同的信息进行精准分发推送。“抖音”、“今日头条”等多个新媒体平台都在依据用户的浏览习惯、浏览时长等多个因素选择分发给受众的内容，这满足了用户的个性化需求，为其提供了精细化的服务。"
"人工智能技术在新闻制作过程中的使用，实际上是将更多的注意力放在了追求受众体验感，追求新闻呈现效果上，而对新闻真实的重视度则稍有弱化，从这个层面来说这是一种对于新闻真实的淡化。首先，已经有相关技术人员展示了一种可能，新闻内容经过人工智能技术处理后，有些媒介素养和真假新闻辨识度不高的受众对其真假难辨；其次，人工智能的发展为视频音频的造假提供了技术支持，很有可能会给假新闻插上翅膀，助长其发展态势，扰乱社会秩序。梳理美国大选背后的假新闻可以发现，许多假新闻是由“机器人水军”工厂制造并传播。  人工智能技术尤其是算法推荐技术在新闻领域的使用，一定程度上消减了新闻专业主义。如今大受欢迎的“抖音”、“今日头条”则是成功使用算法技术精准垂直推送内容，赢得了一大批“忠实粉丝”，但与此同时，信息传播者似乎将传统编辑的把关能力让渡给了用户，新闻价值不再是选取新闻的标准，新闻从业人员的专业主义也被消减。《人民日报》曾三评算法推荐，表示算法并未带来信息开放，反而用取悦用户的信息隔离了观点的公平和交流 ，失去了在争议中达成共识的机会 [ 2 ]。信息的闭塞使得用户如同吃“偏食”，最终会造成意见偏向性，这是与新闻的客观性是相悖的。  随着AI时代的到来，人们的隐私保护问题越发受到关注，尤其是对于网络用户的“推断性信息”的保护。推断性信息是人工智能时代对传统“隐私”定义的扩展，它指的是很多看似无关紧要的、琐碎的、并无明确身份指向的一般的个人信息，比如网络浏览记录、浏览频率、浏览类别、消费记录等这些信息，这种信息往往涉及个人隐私。新媒体平台主要在经过大数据的整合与人工智能的分析之后，形成“数字化人格”，也就是根据数字化信息建立起来的人格，整个过程往往伴随非法获取个人数据以推断个人某方面的特质，如购买偏好、浏览习惯等等 [ 3 ]，由于当前法律层面对隐私内容的范畴界定有限，人工智能时代的隐私权面临挑战。  人工智能可以自动生成新闻报道，能够创造出比新闻工作者更专业的作品，但人工智能创作的作品是否拥有著作权，以及该权力的归属者应当是谁，当前的法律层面的界限和定义是模糊的。2019年7月北京互联网法院处理了首件有关人工智能技术生成内容的著作权纠纷案，正是因为B公司未经允许引用了A公司的人工智能自动生成的内容，而A公司认为B公司侵犯了其著作权、署名权、网络传播权。总之，人工智能在给传媒带来便利和巨大利益的同时，也给法律对著作权的定义和界限带来了挑战，引发了一系列的人工智能生成内容可版权性和权利归属问题。"
"人工智能技术在传媒行业的使用之所以会引发媒介伦理示范现象，归根结底是相关法律法规不完善和监管力度缺失的问题。新媒体平台使用算法推荐技术为用户精准推送信息，推送过程必然包含收集和整理用户的浏览记录、浏览习惯、消费记录等涉及隐私的信息的环节，而正因为当今法律层面对于隐私权定义的局限，使其无法有效的保护和服务人工智能时代用户的隐私权。 保护人工智能时代受众和网络用户的信息安全和隐私权，立法机关应当完善相关法律法规，对隐私权和信息安全等相关概念进行重新定义，要使其跟随时代的发展，要避免技术暗箱操作引起的漏洞；政府必须要加大对网络环境的监管，加大对传媒领域人工智能使用板块的监管，实时监督人工智能技术在媒介的使用，并对其造成的违反媒介伦理行为进行约谈和惩戒。  技术的发展使得受众身份和地位发生了变化，使受众由原先的新闻信息接收者转变为享用信息服务的用户，而作为提供服务的信息传播者为了迎合用户喜好，将追求流量、赚取经济利益作为首要动机，弱化了新闻专业主义的重要性。 人工智能时代的新闻信息传播活动仍须重视新闻专业主义，遵守媒介伦理道德。从新闻信息的采集、编辑、再到分发都必须由专业的新闻从业人员进行，新闻信息的选择要以新闻价值为出发点，而不是盲目的讨好受众、讨好用户；新闻采写要客观、真实、全面，避免出现假新闻、标题党、观点片面的现象；新闻从业者要有法律意识，保护他人隐私权，保护他人的个人信息。  技术的发展改变了信息传播方式和传播理念，公众的地位也由以前不被重视转变成新闻信息的生产者和传播者。因此，公众的媒介素养在当今的媒介环境下显得愈加重要，媒介素养的概念也拓宽到了更宽泛的领域，包括新闻信息的选择和生产、对新闻的认知和解读、以及对新闻的批判态度，随着技术的不断发展，由于媒介素养的缺失而造成的现实伦理问题不断凸显。 在新技术的媒介途经下，公众媒介素养的内涵需要进行重新诠释。公众要提升对信息的辨别能力，理性辨别虚假新闻和偏向性新闻，主动进行综合性搜索考究信息的真伪；公众应当理智谨慎的处理新闻信息，对自己的言论和转发行为负责，不传播流言和谣言；公众应当积极关注社会议题，并进行理性表达。  企业对人工智能技术的引入的确能够推动企业的发展，但对该技术的不合理使用往往存在与法律相违背的地方，传媒企业应当在合法的前提下使用人工智能技术。不少企业在使用人工智能的过程中存在“暗箱操作”，这些有时会伴随着违法行为，比如侵犯用户隐私权、侵犯创作者的著作权、威胁用户信息安全等。类似行为会对社会产生不良影响，比如推送内容过于暴力不适合青少年浏览、传播内容的过于低俗化，不利于正确价值观的形成等。目前，关于此类问问题已有多家新媒体公司被网信办约谈，令其整改。 面对当前现状，企业要对人工智能技术的使用进行规范化。首先，合法使用人工智能技术，不打法律擦边球，严格监督传媒平台内部推送内容，对违法内容的发布者进行惩罚，严重时对其进行封号处理；保护用户隐私，不泄露用户信息，维护用户的信息安全；保护未成年人，给未成年用户开辟“绿色通道”，如今“抖音”和“快手平台”的青少年模式都是可参考性措施。  当前，解决人工智能给媒介带来的伦理失范问题，首要任务就是实现人机交互协同。媒介伦理指的是传媒从业者的从业道德、传媒价值取向、道德功能与伦理规范等等 [ 4 ]，它是精神层面的一种规范，而人工智能属于技术层面，因此媒介在人工智能技术的使用过程中要想遵循媒介伦理规范，那么就必须将道德伦理准则纳入到机器的开发中。技术开发者可以将道德准则编发成符号潜入技术的使用；或者在智能新闻系统中可以运用人机互动重复学习伦理要求和职业规范，搭建自然语言学习体系让算法机器进行道德决策，但在运行初期需要人力在身边指导和及时修正其决策。"
"人工智能时代的到来为社会带来了发展，为媒介带来了发展，它拥有社会和国家的政策支撑作为后盾，但同时它也引起了人们对人工智能时代媒介伦理的反思，而这也应该引起社会各界的重视并采取切实可行的措施，这从微观上预示着人工智能迈向强人工智能的阶段还有很长的一段路要走。而对于人工智能带来的媒介伦理问题，诸如机器是否应当被赋予伦理规范？信息传播过程中每个环节所出现的伦理问题到底应该由谁来负责？数据采集分发过程能否向社会完全公开？有关媒介从业人员与人工智能技术之间的关系等诸多现实问题摆在了我们的面前。但不可忽视的是，人们面临人工智能技术带来的严峻挑战需坚信，有关智能新闻的伦理思考，很多方面是都是源于技术发展不成熟导致的，因此或许随时间的推移，技术不断完善，某些问题会迎刃而解。但强制性的伦理规范和职业要求是不可或缺的，相关部门需根据人工智能技术的发展水平及时完善和调整，填充新规范，破除旧规制，为信息的健康生产传播建立完整的规范体系。同时，新闻人和公民的媒介信息素养的培育也需提上日程。技术为人服务，为了正确认识和运用人工智能技术，我们应该在困难面前保持理性思维，促进新闻业的稳步发展。"
