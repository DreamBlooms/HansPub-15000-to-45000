"针对工业生产过程中出现的人工巡检工作量大、工业环境存在潜在危险等情况，本文提出了一种将ROS机器人操作系统与Unity3D软件相结合的方法。通过构建虚实交互场景，实现控制虚拟机器人和真实机器人交互移动，真实机器人反馈回来的环境信息也能映射于虚拟场景中，形成一种虚实交互的控制形式，相较于传统机器人控制，虚实交互控制可以使用户身历其境，拥有切实现场体验，统筹全局，也可用于机器人算法训练、观测状态信息、参数优化等。本项目通过ROS系统使用SLAM算法构建现实场景地图，并将其映射到Unity3D环境，以构建工业生产虚拟场景，同时将ROS作为Unity与真实机器人交互的中间件，采用OpenCV作为视觉交互，在无线通信、Rosbridge框架等技术的支持下实现数据交互，最终设计出了此虚实交互场景构建方案。"
"工业生产历来都是支撑一个国家甚至世界的支柱型产业，其是推动社会发展的重要因素之一。如何提高工业生产效率，如何提高工业生产的安全性、可靠性等都已成为各大工业生产公司必须考虑的问题。而随着“工业4.0”的这一概念的提出，为提速工业生产开辟了一条全新的道路。“工业4.0”以智能制造为核心，提出使用信息技术带领工业生产行业从数字化走向网络化、智能化 [ 1 ]。而与之相对应的即是智能机器人领域，即是体现生产智能化程度的重要标志之一，它是减轻人工劳动量、提高生产效率、降低人员安全风险极为有效的方式，特别在此次新冠疫情防控下，智能机器人极大体现了其优势，这也说明了无接触式的远程控制技术的必然趋势。 本项目即针对此方向结合虚实交互提出了此研究方案，利用WiFi无线通信，使电脑与ROS机器人建立通信连接，实现相同局域网内远程信息交互。同时以工业生产中的物料配送过程为模拟事例，将ROS机器人作为载体，在激光雷达帮助下采用SLAM算法生成二维地图，并在此基础上利用Unity构建工业生产虚拟场景。在运动过程中，虚拟配送机器人会在Unity的Navigation导航功能的帮助下从起点将物料送至生产加工口，其运动的同时会通过WiFi发送运动控制指令带动ROS机器人做同轨迹运动。此外，ROS机器人搭载的OpenCV摄像头会作出识别交通信号灯的动作协助虚拟与现实机器人完成配送任务。"
"本项目采用两轮差速移动机器人作为研究对象，实体图如下图1。根据其控制流程，可以将机器人分为以树莓派3B+控制板为核心的主控制器，解析指令并控制机器人的所有动作；为建图提供环境数据的激光雷达模块；提供机器视觉交互的OpenCV广角摄像头；提供机器人姿态数据的9轴IMU板块等。驱动上，机器人采用两个光电编码直流电机实现差速控制。 图1. ROS机器人实物图  机器人采用两轮差速驱动方式，每个轮子各带有独立的执行机构(光电编码步进电机)，同时机器人后方安装了钢珠万向轮，与前方的两驱动轮构成三脚架支撑结构。执行指令由树莓派控制板解析成相应脉冲电信号，并分别发送给两个驱动电机，控制机器人行进。下位机的具体控制流程如下图2： 图2. 下位机控制流程图"
"针对实验环境地图构建的方法上，我们采用即时定位与地图构建(Simultaneous Localization and Mapping, SLAM)技术 [ 2 ]，该技术目前被广泛的应用于地图构建。SLAM的核心思想是根据机器人的观测值 z 1 : t (地图中的点)和里程计测量序列 u 1 : t − 1 (机器人轨迹)来估计机器人轨迹分布 x 1 : t 和地图m，以此获得联合后验概率函数 P ( x 1 : t , m | z 1 : t , u 1 : t − 1 ) ，而为了简化计算，往往将其拆分成位姿状态估计和地图状态估计，即： P ( x 1 : t , m | z 1 : t , u 1 : t − 1 ) = P ( m | x 1 : t , z 1 : t ) P ( x 1 : t | z 1 : t , u 1 : t − 1 ) 这一举措即是RBPF(粒子滤波算法)的思想，而我们采用的Gmapping算法技术在RBPF基础上，针对RBPF所有粒子多和频繁执行采样问题提出了改进提议分布和选择性采样，优化了常规RBPF算法，使得实现SLAM建图更加准确。 常规RBPF粒子滤波算法总体可概括为采样、权重计算、重采样、地图估计。而Gmapping在此基础上提出改进提议分布，在激光雷达的帮助下获取比里程计更准确的环境数据，得到改进后的建议分布 [ 3 ]： P ( x t | m t − 1 ( i ) , x t − 1 ( i ) , z t , u t − 1 ) = P ( z t | m t − 1 ( i ) , x t ) P ( x t | x t − 1 ( i ) , u t − 1 ) P ( z t | m t − 1 ( i ) , x i − 1 ( i ) , u t − 1 ) 且其计算权重时的公式为： w t ( i ) = P ( x 1 : t ( i ) | z 1 : t , u 1 : t − 1 ) π ( x 1 : t ( i ) | z 1 : t , u 1 : t − 1 ) 使用贝叶斯加全概率展开等变换，可以得权重计算近似为： w t ( i ) ∝ w t − 1 ( i ) ⋅ P ( z t | m t − 1 ( i ) , x i − 1 ( i ) , u t − 1 ) 而随着粒子不断的迭代，在选择性采样的协助下，低权重粒子被舍去，高权重粒子被采纳，在重采样的过程中，以设定阀值 N e f f 的方式来评估粒子权重分散程度，即： N e f f = 1 ∑ i = 1 M ( φ ( i ) ) 2 其中 φ ( i ) 表示粒子归一化的权重，在粒子数目为M的情况下，只有在 N e f f < 1 2 时，系统才会进行重采样 [ 4 ]。 在SLAM的实现上，算法上ROS提供了实现Gamaping算法的功能包，在完成功能包中的相关参数配置以及激光雷达、里程计的配置后，即可实现定位与建图的功能。 图3是机器人执行建图时当前系统运行节点关系图： 图3. SLAM建图节点关系图 图3中可直观的观察到建图时系统涉及到的节点，以及节点间发布订阅话题的关系。其中/slam_gampping作为Gmapping算法的核心节点分别订阅了来自/hawkbot_lds节点发布的激光雷达/scan话题、/robot_state_publisher的底盘与里程计原点坐标变换/tf_static话题、/imu_complementary_filer的IMU提供的相对定位信息/tf话题、/base_link_to_laser的底座与激光雷达坐标变换/tf话题，此外/teleop则提供键盘控制话题，最终所有的输出都将作为/robot_pose_ekf节点的输入来控制机器人的移动。 在启动/slam_gmapping节点的同时，一并启动Rviz组件，地图将在Rviz中建立。完成二维地图构建后，在命令行终端使用指令： 将建立好的地图保存后，文件名即为map_1，保存的二维地图(图4)和真实的实验场景(图5)： 图4. 机器人构建的二维地图 图5. 机真实实验场景图   根据上文所述，在Gmapping建图过程中，使用ROS指令可以保存的构建的地图文件，其中会生成一个map_1.yaml和一个map_1.pgm文件，地图图像保存在map_1.pgm文件中，map_1.yaml文件则是对地图的参数的说明，而map_1.pgm文件可以通过Ubuntu中的GIMP图片编辑软件转成.png格式用于Unity加工，根据map_1.yaml文件中的resolution(分辨率)参数，其代表的是每个像素对应的实际距离(0.05 m/pixel)，再利用GIMP测量工具(图6)，测量出地图轮廓的像素值，再乘以分辨率即可知实际距离。 图6. GIMP测量图 实际实验场地尺寸计算公式即为： 实际距离=测量像素值×分辨率(resolution) 以下是对图5地图中每一条黑线(边界)的像素尺寸的测量值列表1： Table 1 边编号 第一次测量(/像素) 第二次测量(/像素) 第三次测量(/像素) 平均像素(/像素) 实际尺寸(/m) ① 43.6 42.4 44.2 43.40 2.17 ② 28.3 27.8 29.1 28.40 1.42 ③ 31.3 32.7 31.9 31.97 1.60 ④ 44.9 45.1 45.6 45.2 2.26 ⑤ 53.7 52.3 54.3 53.43 2.67 表1. 地图尺寸测量实验 由此我们可以在没有人员到实际场景进行手工测量的情况下便可实现远程尺寸测量。  结合Unity中像素与距离的关系，对导入的地图文件进行适当放缩，即可达到尺寸匹配的效果。经过查阅Unity中场景元素的属性,基础单位为米，参照导入Unity的ROS地图创建并调节出对应尺寸的GameObject对象“plane”，以该对象为载体调用C#脚本代码计算出plane对象的尺寸即求出ROS地图在Unity虚拟环境中的尺寸，关键代码如下： 以宽度 w 虚 为例，为plane添加MeshFilter组件，以此获取原始宽度default_w，再将原始宽度乘以放缩比即可得实际宽度map_w，长度 l 虚 以此类推，数据取整，计算出虚拟场景得： l 虚 × w 虚 = 10 × 13 与对于④号边与⑤号边实际长度的比值k分别为： k 1 = w 虚 l 4 = 4.425 ， k 2 = l 虚 l 5 = 4.869 ， k _ = ( k 1 + k 2 ) ÷ 2 = 4.647 则虚拟机器人与显示机器人的速度关系即根据该虚实交互比值来限定，以此提高两者的同步性能。 导入Unity后，为了更加体现出本项目的实用性，我们利用Unity在ROS地图基础上模拟构建了一个工业生产场景(如图7)。 在虚拟机器人的运动控制方面，我们采用Unity的导航功能，模拟虚拟机器人将物料配送到入料口的过程，该功能需要采用的Unity的Navigation导航网格 [ 5 ] 组件进行网格烘焙，同时为虚拟机器人添加上NavMeshAgent组件，而导航网格的作用是使得添加了NavMeshAgent组件的物体能够在导航网格上以最优路径移动到设定的终点，由此可实现自动配送物料的功能。 图7. Unity添加工业模型并导航烘焙后的虚拟场景  为了测试便利以及交互性的提高，我们使用Unity的GUI界面技术 [ 6 ] 在Unity客户端设计了用于人机交互的操作界面(如图8)，同时在PC端连接了外接摄像头，该摄像头处于实验场景，可将真实场景画面传送至Unity操作界面。在点击运行后，Unity会同时运行两个程序线程，主线程完成加载客户端界面，副线程则完成与ROS的网络链接。 界面上的操作区，空白处用于显示提示信息，“开启信号灯识别”按钮用于Unity接收识别信号灯的控制信号，如遇红灯则提示“通行状态如下：红灯停车等待中”，无信号灯或者为绿灯则提示“通行状态如下：可通行”。而“前进”、“左转”、“停止”、“右转”、“后退”按钮则可手动控制ROS机器人移动。“启动导航”按钮则是进行虚实交互控制的启动按钮，当按下该按钮后，提示“机器人已启动”，虚拟机器人首先移动，Unity发布控制信息给ROS机器人使之随动。具体的操作流程如图9。 图8. Unity初始化操作界面 图9. Unity界面操作流程图   针对Unity与ROS机器人的运动交互上，我们运用到了Unity导航功能中的NavMeshPath类型组件，通过定义该类型的变量path，将导航起始点坐标作为输入，path作为输出，调用NavMesh.CalculatePath()函数即可计算出导航的路径信息并保存在变量path中，path中所包含的Corners数组则存储了导航路径的所有关键点的坐标，因为Unity导航路线是由Corners关键点连接起来的(如图10所示)，通过比较相邻两点的坐标，可以很容易得到两点间的距离和方向转角。 图10. Unity界面操作流程图 如图设CD近似与轴重合(即此时机器人的正方向为CD)，故CD与轴夹角为，同时设 D ( x d , y d ) ， E ( x e , y e ) ，D、E点与轴的夹角分别为 θ 1 、 θ 2 ，若机器人从C点移动到D点，在D点停止时机器人的正向仍为CD，则以此时状态移动到E点的过程有： tan θ 1 = x e − x d y e − y d ， θ 1 = arctan x e − x d y e − y d ， Δ θ 1 = θ 1 − θ 0 即为机器人C到D的末态方向与D到E的初态方向夹角，同理可得E到F点的运动方向夹角为： Δ θ 2 = θ 2 − θ 1 ，同时DE的运动距离为： 或 y e − y d cos Δ θ 1 以上述方法可计算出任意相邻关键点的距离与转角，并将其转化为控制信息即可对ROS现实机器人进行虚实交互控制。  在现代工业场景中，为了更好的协调各个车辆工作的有序进行，必然会存在指示灯这类设施。于是，我们基于机器视觉为机器人设计了，针对识别交通信号灯控制其移动与停止的功能。 我们以一广角摄像头作为视觉交互设备。使用OpenCV开源计算机视觉库 [ 7 ] 实现视觉识别算法，并利用ROS所提供的CV_bridge视觉框架将OpenCV和ROS结合，实现通过ROS平台控制机器人调用视觉识别功能。ROS本身并不能直接使用OpenCV开源库函数，而在ROS提供的CV_bridge的帮助下可将两者紧密地联系起来，通过其内部函数，可将OpenCV返回的Mat类型图像数据转换为ROS内部通讯机制能够识别的sensor_msgs/image消息格式进行传输，也可逆向转换。而交通信号灯的识别，则是基于OpenCV的颜色空间模型 [ 7 ] 来实现颜色识别的。 在颜色模型选择上，我们使用RGB和HSV。RGB是最为常用的颜色空间模型，其显示效果同人眼所见最为相近，但是对于机器来说，RGB很难较好的反应图像中的具体信息。而HSV模型包含的色调(H)、饱和度(S)、亮度(V)三个参量，能够实现图像的特征调节凸显所要识别的颜色，可极大提高颜色间的对比效率。 由于基于ROS平台运行，摄像头读入的RGB信息转换为的是ROS的图像数据，通过话题发布此消息，经CV_bridge将该消息转换为OpenCV图像数据，再经一系列图像处理(如图10)，即可识别出特定颜色。针对交通信号灯，主要是对红色与绿色的识别，经过操作界面(如图12)调节得红色的三参数取值范围分别为H[0,10]，S[43,255]，V[46,255]，绿色的三参数取值范围分别是H[35,77]，S[43,255]，V[46,255]。 识别算法的实现过程如图11，同时红色识别并框选如图13，绿色类似。 图11. 算法流程图 图12. HSV操作界面 图13. 红色识别框选效果 而在虚实交互上，识别到红色指示和识别到绿色指示时，该节点会发布/traffic_deal话题，该话题会发送红色与绿色的对应数据，Unity通过订阅此话题即可让虚拟机器人知道此时是红灯还是绿灯。"
"为了尽可能的减少对机器人运动束缚，采用无线控制方式是最为合适的，结合树莓派3B+拥有无线网卡的特点，使树莓派产生WiFi热点，PC端连接此热点，可实现同域网中，使用PC端远程控制机器人。经过对无线网卡的配置，在连接热点后，我们采用SecureCRT远程桌面软件，以SSH协议 [ 8 ] 方式通过机器人IP地址远程登录树莓派系统，登录成功后，便可在SecureCRT中开启终端输入指令行远程对机器人进行操作。 与此同时，因为PC端处于连接树莓派热点的情况下，故PC端的虚拟机Ubuntu系统中通过ping通机器人IP的方式，可使虚拟机中ROS系统与机器人中的ROS系统实现数据互通，即在PC端的虚拟机中可对机器人上的ROS发布的话题进行订阅处理等操作，这样可将大型数据的处理交由PC端来完成，如SLAM建图等，大大降低了树莓派的工作负荷。  本项目能够实现使ROS平台与Unity进行数据交互，进而实现虚实交互功能的主要助手即是ROS官方为开发者提供的用于与非ROS系统进行交互通信的Rosbridge_suite功能包，该功能包为外部程序提供了能够调用ROS功能的JSON API，包括话题的订阅、消息的发布、服务的调用、参数的设置和获取以及图片信息的传递等，这些功能的调用指令都是以JSON格式发布的。而负责通信传输层管理的是Rosbridge_suite中的Rosbridge_server子功能包，它针对不同通信架构提供了包括WebSocket、TCP、UDP在内的几种通信方案。其中WebSocket针对Browser/Server架构，主要用于与Web浏览器进行交互的服务器；TCP与UDP则是针对Client/Server架构，该架构中UDP通信响应速度快，但会发生丢失数据包的情况，因此存在不确定性；而TCP通信因为需要三次握手 [ 9 ]，所以使得传输过程更加稳定准确。由此我们选用Rosbridge的TCP通信方式,并在ROS的Socket通信链路 [ 10 ] 的帮助下搭建起ROS与Unity的通信桥梁。Rosbridge的TCP通信服务端开启指令如下： 启动后，终端窗口提示默认port(端口号)为9090，IP则为PC端虚拟机Ubuntu系统的IP地址。在Unity客户端使用C#语言绑定连接该IP地址与9090端口号，即可实现Unity与ROS平台的TCP通信连接。与Unity连接成功后终端窗口的提示如图14： 图14. Unity与Rosbridge连接成功提示  Rosbridge协议是用于发送基于JSON格式的ROS指令的规范。应该说所有外部程序都必须遵守该协议才能调用ROS的相关功能。下面是使用Unity发布话题的JSON格式数据： 其作用是发布控制机器人角速度与线速度的话题,“op”表示操作动作，这里“publish”即是发布，话题名为“/cmd_vel”,“msg”表示发布的消息内容，即设定xyz轴上的线速度(linear)和角速度(angular)。而Unity客户端接收到ROS端发送的数据仍然是遵循Rosbridge协议的JSON格式。Unity通过脚本解析与判断这些JSON格式字符串，即可获得ROS传输的有用数据，以此实现给虚拟场景传递和反馈信息的功能。 而在虚拟机器人与现实ROS机器人的运动交互上，即是由Unity虚拟机器人在NavMeshAgent导航移动的同时，不断发布/cmd_vel话题给ROS机器人，控制ROS机器人的线角速度与虚拟机器人的移动趋于相同，从而实现虚实交互控制。 虚实交互的另一方面，ROS机器人遇到指示灯时，节点获取并识别信号灯信息，一方面该节点会根据识别信息发布控制ROS机器人运动与停止的/cmd_vel话题，另一方面又会发布/traffic_deal话题，Unity在Rosbridge的帮助下，通过以下JSON格式语句订阅此话题 而该话题发布的识别信息则将以下面JSON格式返回Unity，从而使虚拟机器人知道此时处于红灯需要停止，反之为无信号或绿灯可继续行驶。 由此在Rosbridge协议的帮助下便实现了ROS与Unity的双向虚实数据的交互。 图15. 导航路径模拟图"
"Unity与ROS的交互测试，即Unity导航对机器人的控制。ROS与Unity交互的过程仍然是遵循ROS节点通信机制，在Rosbridge的帮助下，Unity作为ROS的外部组件也可以被ROS系统视作为一个节点，同样拥有节点的基本功能。虚拟到现实交互过程中，以Unity作为主控方，当执行导航前，Unity生成由关键点组成的导航路线，执行导航过程中，关键点将路线分段，测试在不同速度通过时，观察Unity虚拟机器人与ROS机器人移动的同步情况，根据关键点坐标使用Matlab软件绘制出了实验的导航路径图(图15)，并根据测量虚实机器人移动距离与转角得出误差相对较小的线、角速度配速。 根据上文得到的虚实交互比 =4.647，以此作为实验的比例因数，进行速度匹配测试，我们通过虚拟机器人的关键点坐标可以计算出被关键点分割后所形成路段的距离，即为两个关键点之间虚拟机器人所行走的距离，利用可以求出理论上真实机器人应该走的距离，而对应于真实机器人所行走的距离，我们可以手工测得，由此计算出理论与实际的线速度差值，经过对ROS机器人线速度的多次不同设定，我们使用Matlab软件绘制出了对应配速下的差值与0线比较的折线图(如图16)： 图16. 不同线速度下虚实移动距离的误差情况 在角速度的测试上，同样通过关键点坐标值，我们可以计算出理论上ROS真实机器人在对应点上应该转动的角度，通过获取机器人上IMU板块的转角数据即可知道实际所转动的角度，由此可绘制出在不同角速度下，理论与实际转角的差值与0线比较的折线图(如图17)。 由实验结果分析可得，ROS机器人线速度在设定在0.25 m/s时，理论与实际之间的距离差的折线最接近0值，即移动距离误差最小；角速度上，根据每个关键点上理论与实际的转角差折线图，可以较为清晰的看出，在1.2 rad/s时，转角差最接近于0线。由此可以得到误差相对较小时的线速度、角速度分别为：0.25 m/s、1.2 rad/s。 图17. 不同角速度下虚实转角的误差情况"
"本项目以工业生产为背景，针对如何实现虚实交互技术这一问题提出了结合使用ROS机器人操作系统和Unity3D软件的研究思路，并在Gmapping算法、WiFi、Rosbridge、OpenCV等技术的支持下，实现了SLAM建图、无线通信、TCP通信、交通信号灯识别等功能，较完整地构成了一套由虚拟场景机器人控制真实机器人运动，真实机器人反馈现实信息至虚拟场景的虚实交互方案。为虚实交互技术的实现提供了较为可靠的参考。通过各项功能实验证实，得出了以下主要结论： 1) 在实现SLAM地图构建上，通过对Gmapping算法解析与多次的实验，已可进行稳定的室内环境二维地图的构建，为Unity虚拟场景构建提供了较为准确的基础。 2) 在ROS与Unity的通信上，通过ROS机器人发出WiFi热点能够使机器人与PC端建立连接，并在此基础上使用ROS中的Rosbridge架构打开ROS与外部的TCP通信接口，供Unity进行连接，实现了ROS与Unity环境的信息互通，从而建立起了虚实交互的通道。 3) 在交通信号灯识别上，在CV_bridge协助下，将OpenCV视觉技术与ROS系统结合，利用HSV颜色空间识别算法，实现了对红色、绿色的框选识别，从而能够为虚、实机器人反馈现实场景的控制信息。 4) 根据对虚拟、现实机器人线、角速度的配速实验，分析实验结果得出误差相对较小的ROS机器人线、角速度的配速分别为：0.25 m/s、1.2 rad/s。在此配速下，ROS真实机器人的运动轨迹最为接近于虚拟机器人的导航轨迹。"
