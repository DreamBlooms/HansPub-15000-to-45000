"利用Pena距离对KL估计的影响分析进行讨论，得到了KL估计的Pena统计量的表达式，并对其性质进行讨论分析，从而得到高杠异常点的判别方法。本文对Pena统计量与Cook统计量的性质进行了比较，得出在一定条件下Pena统计量是优于Cook统计量的结论。通过实例对比分析，得到研究结果表明本文提出的理论和方法是科学合理的。"
"在统计学中，统计诊断是数据分析的第一步，主要目的就是对样本数据中异常点或强影响点的识别和诊断，传统的判断异常点或强影响点的常用统计量有Cook距离、似然距离、W-K统计量和AP统计量等。美国统计学家Daniel Pena [ 1 ] 于2005年提出的一种新的诊断统计量Pena距离，该统计量是对诊断统计量的重要补充，Pena距离是一种度量线性回归模型影响的新方法，这种方法与传统的诊断方法有较大的区别。之前的方法是研究删除一个点(组)对回归分析的影响及对模型预测值的影响，或是某个样本点(组)的微小扰动对参数估计的影响及对模型预测的影响；而Pena距离这一统计量是研究样本中的某一点受其余各点的影响，也即度量样本中各点删除对某一特定样本点回归值及预测值的影响。孟丽丽等 [ 2 ] 基于Pena距离研究了加权最小二乘估计的影响分析，胡江等 [ 3 ] [ 4 ] [ 5 ] [ 6 ] 基于Pena距离研究了非线性回归模型、广义线性回归模型和t-回归模型的影响分析；Semra Türkan等 [ 7 ] 研究了基于Pena距离的岭估计和改进岭估计的影响分析；Hadi Emami等 [ 8 ] 研究了基于Pena距离的岭估计的影响分析；Muhammad Kashif等 [ 9 ] [ 10 ] 研究了基于Pena距离的Liu估计和改进岭估计的影响分析。 本文将Pena统计量推广到Kibria-Lukman估计的影响分析问题，给出Kibria-Lukman估计影响分析的Pena统计量的表达式，并对其性质进行了讨论，从而得到高杠异常点的判别方法。在一定条件下对Pena统计量与Cook统计量的性能进行了比较分析，并通过实例分析对该方法的有效性进行验证。"
"考虑一般线性回归模型： y = X β + ε (1) 其中 y = ( y 1 , y 2 , ⋯ , y n ) T ， β = ( β 0 , β 1 , ⋯ , β p − 1 ) T ， ε = ( ε 1 , ε 2 , ⋯ , ε n ) T ，   ε ~ N ( 0 , σ 2 I ) ， σ 2 > 0 ，I是n阶单位矩阵，X为 n × p 阶的已知设计矩阵，其中第i行为 ( 1 , x i 1 , x i 2 , ⋯ , x i p − 1 ) 。当模型(1)满足高斯–马尔可夫条件时，此时最小二乘估计(OLS) β ^ = ( X T X ) − 1 X T y 为 β 的最佳线性无偏估计。 y ^ = X β ^ = H y     ，其中 H = X ( X T X ) − 1 X T 为对角元素 h i i = x i T ( X T X ) − 1 x i 的帽子矩阵， s 2 = e T e n − p 是 σ 2 的无偏估计，其中 e = y − y ^ = y − X β ^ = ( I − H ) y 。 当解释变量存在复共线性时，最小二乘估计往往表现出不稳定性，其优良性就会被破坏，若再基于最小二乘估计方法做影响分析很明显是不合适。为了解决这个问题，B. M. Golam Kibria和Adewale F. Lukman [ 11 ] 提出了一种新的Ridge-Type估计，它称为Kibria-Lukman (KL)估计，该估计是在岭估计和刘估计类中提出了一种新的单参数估计，因此它具有岭估计和刘估计的很多特征。其KL估计的表示如下： β ^ K L = ( X T X + λ I p ) − 1 ( X T X − λ I p ) β ^ = W ( k ) M ( k ) β ^ 其中 λ 是非负常数， W ( k ) = [ I p + λ ( X T X ) − 1 ] − 1 ， M ( k ) = [ I p − λ ( X T X ) − 1 ] 。 根据Daniel Pena [ 1 ] 提出的Pena距离，得出基于KL估计的Pena距离可表示为： S K L , i = s K L , i T s K L , i p σ ( y ^ K L , i ) 2 ,                     i = 1 , 2 , ⋯ , n (2) 其中 s K L , i = ( y ^ K L , i − y ^ K L , i ( − 1 ) , y ^ K L , i − y ^ K L , i ( − 2 ) , ⋯ , y ^ K L , i − y ^ K L , i ( − n ) ) T ， y ^ K L , i − y ^ K L , i ( − j ) = h K L , j i e K L , i 1 − h K L , j j ， σ y ^ K L , i 2 = σ ^ 2 h K L , i i ，其中 e K L , i = y K L , i − y ^ K L , i ， y ^ K L , i 为第i个点 y K L , i 的拟合值， y ^ K L , i ( − j ) 是删除第j个点后第i个点的拟合值， h K L , i i 是 H K L = X ( X T X + λ I p ) − 1 ( X T X − λ I p ) ( X T X ) − 1 X T 的对角元素。因此，对于公式(2)又可以重新表示为： S K L , i = 1 p σ ^ 2 h K L , i i ∑ j = 1 n h K L , j i 2 e K L , j 2 ( 1 − h K L , j j ) 2 (3) 其中， σ ^ 2 的估计为 s 2 = e K L T e K L n − p 。 定理2.1 当样本中不含异常点时，有 E ( S K L , i ) → 1 p ( n → ∞ ) 证明 因为 e K L , j = ( 1 − h K L , j j ) y K L , j ，所以 var ( e K L , j ) = E ( e K L , j 2 ) = ( 1 − h K L , j j ) σ ^ 2 ，故 E ( S K L , i ) = 1 p σ ^ 2 h K L , i i ∑ j = 1 n h K L , j i 2 E ( e K L , j 2 ) ( 1 − h K L , j j ) 2 = 1 p h K L , i i ∑ j = 1 n h K L , j i 2 1 − h K L , j j 记 h * = max 1 ≤ i ≤ n h K L , i i ，对于上式有 E ( S K L , i ) ≤ 1 p ( 1 − h * ) = 1 p + h * p ( 1 − h * ) → 1 p ( h * → 0 ) 而当 h K L , j j ≥ 1 n ，有 E ( S K L , i ) = 1 p h K L , i i ∑ j = 1 n h K L , j i 2 1 − h K L , j j ≥ 1 p ( 1 − 1 n ) → 1 p ( n → ∞ ) 定理2.1表明：当 h * → 0 ， n → ∞ 时，所有样本点的数学期望影响趋于 1 p ，即 E ( S K L , i ) → 1 p ，所以当样本点的期望和 1 p 相差很大时，可以判断出样本点中的异常点。与Cook距离相比较，Pena距离是优于Cook距离的，因为Cook距离的数学期望为 h K L , i i p ( 1 − h K L , i i ) ，其数学期望是依赖于 h K L , i i ，随 h K L , i i 的变化而变化。 定理2.2 在 h K L , i i 很小的样本中，当 n → ∞ ， p → ∞ ，但 p n → 0 ，则 S K L , i 的分布近似于正态分布。 证明 利用中心极限定理，假设没有异常值， h * = max 1 ≤ i ≤ n h K L , i i ≤ c h ¯ ， c > 0 ，其中 h ¯ = ∑ i = 1 n h K L , i i n ，当 n → ∞ ， p → ∞ ，但 p n → 0 ，对于公式(3)可以写成 S K L , i = ∑ j = 1 n m i j ( e K L , j σ ^ ) 2 ，其中 m i j = h K L , j i 2 p h K L , i i ( 1 − h K L , j j ) 2 ， e K L , j 是 cov ( e K L , j ) = σ 2 ( I − 2 H K L + H K L H K L T ) 的正态随机变量。因此，当 n → ∞ ， h K L , i j → 0 ， S K L , i 是自由度为1的卡方独立变量的加权组合。 m i j > 0 ，下证 m i j ∑ j = 1 n m i j → 0 。 因为 m i j ≤ h K L , j j p ( 1 − h K L , j j ) 2 ≈ h K L , j j ( 1 + 2 h K L , j j ) p , 则有 m i j ∑ j = 1 n m i j ≤ h K L , j j ( 1 + 2 h K L , j j ) p + 2 ∑ j = 1 n h K L , j j 2 ≤ h K L , j j ( 1 + 2 h K L , j j ) p 所以，当 p → ∞ ， m i j ∑ j = 1 n m i j → 0 ，故在这些假设下， S K L , i 的分布是近似于正态分布。 定理2.2表明：对于大样本和解释变量比较多时，Pena距离 S K L , i 的分布近似于正态分布，而Cook距离的分布 [ 12 ] 是偏态分布，由此可知，Pena距离的这一性质是优于Cook距离。 S K L , i 的这一性质，对于大样本和解释变量比较多时， S K L , i 的分布将近似于正态分布，其截断点可以通过这一性质来寻找。因此，当样本观测点的值远远大于 S K L , i − E ( S K L , i ) S D ( S K L , i ) ，则该样本观测点就可以视为异常点或影响点，但是当样本中存在异常点或影响点时， S K L , i 的均值和标准差很容易受影响。于是Daniel Pena [ 1 ] 提出使用Pena距离的中位数和中位数绝对偏差来代替均值和标准差。所以，如果 S K L , i 满足 | S K L , i | ≥ M e d i a n ( S K L , i ) + 4.5 M A D ( S K L , i ) (4) 则称该样本点是异常点或影响点。 其中 M A D ( S K L , i ) = M e d i a n { | S K L , i − M e d i a n ( S K L , i ) | } 0.645 是正态数据标准差的稳健估计量， M e d i a n ( S K L , i ) 是 S K L , i 的中位数。 下面考虑Pena统计量 S K L , i 在含有一组相同的高杠异常点的样本点中具有的性质。 设有n个样本点 ( y 1 , x 1 T ) , ( y 1 , x 2 T ) , ⋯ , ( y 1 , x n T ) ，记 X 0 T = ( x 1 , x 2 , ⋯ , x n ) ， y 0 T = ( y 1 , y 2 , ⋯ , y n ) ， β ^ K L ( 0 ) = ( X 0 T X 0 + k I ) − 1 ( X 0 T y 0 − k ( X 0 T X 0 ) − 1 X 0 T y 0 ) ， u i = y i − x i T β ^ K L 0 。假设在样本点中含有k个相同的高杠异常点 ( y a , x a T ) ，令 u a = y a − x a T β ^ K L ( 0 ) ， X T T = ( X 0 T , x a 1 k T ) ， y T T = ( y 0 , y a 1 k T ) ，其中 1 k T = ( 1 , 1 , ⋯ , 1 ) ︷ k 个 ， e K L , i = y i − x i T β ^ K L ( T ) ， β ^ K L ( T ) = ( X T T X T + λ I ) − 1 ( X T T y T − λ ( X T T X T ) − 1 X T T y T ) ， H K L ( T ) = X T ( X T T X T + λ I ) − 1 ( X T T X T − λ I ) ( X T T X T ) − 1 X T T 是对 n + k 个样本点的投影矩阵，其中 H K L ( T ) 的元素记为 h K L ( i j ) ，记 H K L ( 0 ) = X 0 ( X 0 T X 0 + λ I ) − 1 ( X 0 T X 0 − λ I ) ( X 0 T X 0 ) − 1 X 0 T 是对n个正常点的投影矩阵，其中的元素记为 h K L ( i j ) 0 。 设投影矩阵 H K L ( T ) 的分块形式为： H K L ( T ) = [ H K L ( T ) 11 H K L ( T ) 12 H K L ( T ) 21 H K L ( T ) 22 ] ，则有 H K L ( T ) 11 ， H K L ( T ) 12 ， H K L ( T ) 22 分别是 n × n ， n × k ， k × k 矩阵， H K L ( T ) 21 是 H K L ( T ) 12 的转置矩阵，并且有 H K L ( T ) 11 = H K L ( 0 ) − k k h K L ( a ) 0 + 1 h K L ( 1 a ) 0 ( h K L ( 1 a ) 0 ) T , (5) 其中 h K L ( a ) 0 = x a T ( X 0 T X 0 + λ I ) − 1 ( X 0 T X 0 − λ I ) ( X 0 T X 0 ) − 1 x a ， h K L ( 1 a ) 0 = X 0 ( X 0 T X 0 + λ I ) − 1 ( X 0 T X 0 − λ I ) ( X 0 T X 0 ) − 1 x a . 同理可求得 H K L 12 = H K L 21 = 1 k h K L ( a ) 0 + 1 h K L ( 1 a ) 0 1 k T , (6) H K L 22 = 1 k h K L ( a ) 0 + 1 h K L ( a ) 0 1 k 1 k T (7) 又因为 e K L , i = y i − x i T β ^ K L ( T ) ， u K L , i = y i − x i T β ^ K L ( 0 ) 所以 e K L , i = u K L , i − k h K L ( i a ) u i a , i = 1 , 2 , ⋯ , n , (8) 对于异常点的 e K L , a 有 e K L , a = 1 k h K L ( a ) 0 + 1 u a , i = 1 , 2 , ⋯ , n (9) 对于正常点，利用公式(8)，有Cook距离为： D K L , i = ( u i − k h K L ( i a ) u a ) 2 h K L , i i p σ ^ 2 ( 1 − h K L , i i ) 2 (10) 对于异常点，利用公式(8)，有Cook距离为： D K L ( i a ) = u a 2 h K L ( a ) p σ ^ 2 ( 1 + ( k − 1 ) h K L ( a ) ) 2 ( 1 + k h K L ( a ) ) (11) 假设样本中有高杠异常点，即由 h K L ( a ) 0 → ∞ ，则有 H K L 12 = H K L 21 → 0 ，由此可得 h K L ( j a ) → 0 , ( j = 1 , 2 , n ) ， H K L 22 → 1 k 1 k T k ，即 H K L 22 中的元素 h K L ( a ) → 1 k 。 又因为 α j a 2 = h K L , ( j a ) 2 h K L , j j h K L ( a ) → { 0 ,                               j = 1 , 2 , ⋯ , n k n ,                   j = n + 1 , n + 2 , ⋯ , n + k 所以对于正常点，有 S K L , i = ∑ j = 1 n α j i 2 D K L , j , i = 1 , 2 , ⋯ , n (12) 而对于异常点，有 S K L , i = k 2 n D K L ( a ) , i = n + 1 , n + 2 , ⋯ , n + k (13) 综上所述可以得到：对于正常点的样本点，当 h K L ( a ) 0 → ∞ ， h K L ( j a ) → 0 时，利用公式(9)，有 e K L , i → u i , E ( S K L , i ) → 1 p 对于异常点，当 h K L ( a ) 0 → ∞ ， e K L , a → 0 ， D K L ( i a ) → 0 ， S K L , i → 0 。即有 定理2.3 当样本中含有高杠杆异常点时，Pena统计量 S K L , i 的数学期望，有 E ( S K L , i ) → { 0 ,                                           高 杠 杆 异 常 点 1 p ,                                     正 常 点 定理2.3表明：当数据中包含有一群相同的高杠异常点时，可以根据 S K L , i 的值很容易把它们识别出来，而这一点Cook距离是不能做到的。"
"案例数据来自文献Longley数据集 [ 13 ]，是强共线性的宏观经济数据，其中包含GNP deflator (GNP平减指数)、GNP (国民生产总值)、Unemployed (失业率)、Armed Forces (武装力量)、Population (14岁以上的非机构人口)、year (年份)，Employed (就业率)。回归模型(1)给出如下： y = X β + ε 其中 X = ( x 1 , x 2 , x 3 , x 4 , x 5 , x 6 ) ，y是就业率， x 1 是GNP平减指数， x 2 是国民生产总值， x 3 是失业率， x 4 是武装力量， x 5 是14岁以上的非机构人口， x 6 是年份。该数据集的条件数为43,275 [ 14 ]，则说明该数据集回归变量之间存在严重的多重共线性。 Cook [ 15 ] 使用该数据集基于数据删除法得到最小二乘估计的Cook距离，识别出样本点5，16，4，10和15为影响点，Walker和Birch [ 16 ] 基于岭估计的数据删除法使用Cook距离、W-K统计量、杠杆值和残差，识别出最有影响的五个点，即点16、10、4、15和5，Jahufer和Jianbao [ 17 ] 基于改进岭估计得到Cook距离和W-K统计量，确定点10、4、15、16和1为影响点，Semra Türkan等 [ 7 ] 基于岭估计和改进岭估计得到Pena统计量，当 k = 0 时，识别出影响点为5、16、6、15和10，当 k = 0.0002 时，岭估计识别出的影响点为16、15、10、4和1，改进岭估计识别出的影响点为16、15、5、4和10；Kashif等 [ 9 ] 基于Liu估计得到Pena统计量，当 d = 0.1 时，识别出的影响点为3、10、11、4和5， d = 0.5 时，识别出的影响点为10、3、4、15和16， d = 0.9 时，识别出的影响点为10、4、15、5和16， d = 1 时，识别出的影响点为15、10、5、4和16。在本文中，我们使用相同的数据集基于KL估计得到的Pena统计量来识别影响点，当 λ = 0 (OLS)和 λ = 0.0002 ，通过公式(3)计算得到 S L K , i ，结果见表1。 由表1显示结果可以看出，基于KL估计所提出的Pena统计量，当 λ = 0 时，KL估计退化为最小二乘估计，其识别出最有影响的五个样本点分别为：5、16、6、15和10，与Semra Türkan等 [ 7 ] 人识别出的影响点是一样的；当 λ = 0.0002 时，其Pena统计量识别出的最有影响的五个样本点分别为16、5、15、6和4，与其它作者相比，至少有三个影响点是一样的，验证了本文基于KL估计所提出来的Pena统计量是合理可行的。 Table 1 λ = 0 λ = 0.0002 case S L K , i case S L K , i 5 0.6976 16 0.6087 16 0.5701 5 0.5017 6 0.5270 15 0.4451 15 0.4308 6 0.4004 10 0.3364 4 0.3322 表1. Longley数据集中：最可能的5个影响点"
"在本文中，综合考虑了复共线性和影响诊断问题，Belsley等 [ 14 ] 建议在检测异常点或影响点时，应处理复共线性问题。因此本文在基于KL估计下一般线性回归模型中，使用Pena距离来讨论KL估计的影响诊断，得到了基于KL估计下的Pena距离的表达式，并对其性质进行证明，得到Pena距离的分布在一定条件下近似于正态分布，并通过该统计量能识别出数据中高杠异常点，从而得到高杠异常点的判别方法。在文中将Pena距离与Cook距离的性质进行了比较，得出在一定条件下Pena统计量是优于Cook统计量的。最后，通过实例研究的结果验证，说明本文所提出的理论与方法是合理可行的。"
