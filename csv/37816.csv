"萤火虫算法(FA)是一种基于群智能的优化技术，它在很多优化问题上表现出较好的性能。然而，它求解复杂优化问题时存在一些问题，如收敛速度慢，精度低。针对这些问题，本文提出了一种新的萤火虫算法(取名AFA)，该方法使用了三种混合策略，以获得好的优化性能。它首先使用一种自适应的参数方法来动态改变步长参数，然后应用一种改进的搜索策略来消除吸引力，于是，AFA不再包含光吸收系数和初始吸引力这2个参数；再使用反向学习来提高解的精度。仿真结果表明，本文提出的AFA算法优化结果优于MFA及PAFA算法。"
"萤火虫算法是由剑桥大学的Yang教授提出的一种群智能算法，它模拟了萤火虫的闪烁求偶行为。类似于粒子群算法，萤火虫算法也是一种基于群体的随机搜索算法。群体中的每个个体(萤火虫)是对应问题的一个候选解。萤火虫算法的搜索依靠个体之间的吸引而产生移动来完成，适应值较好(较亮)的萤火虫具有较大的吸引力，使得适应值较差(较暗)的萤火虫向其移动。 个体(萤火虫)之间的吸引力定义为： β ( r i j ) = β β 0 e − γ r i j 2 (1) 其中r ij 表示萤火虫之间的距离，它定义为： r i j = ‖ X i − X j ‖ = ∑ d = 1 D ( x i d − x j d ) 2 (2) 对于两个不同的萤火虫X i 和X j ，适应值较差(较暗)的萤火虫将向较好的萤火虫移动。假设X j 优于X i ，则X i 向X j 移动，移动方式表示为： x i d ( t + 1 ) = x i d ( t ) + β 0 e − γ r i j 2 ( x j d ( t ) − x i d ( t ) ) + α ε i d ( t ) (3) 标准FA中的参数都事先设定的，FA的搜索能力受到其控制参数(如步长因子)的影响，会导致算法收敛早熟；标准FA因参数设置不当而导致算法无法收敛或收敛速度过慢。为了解决这两类问题，使算法具有较好的优化性能，需要对标准FA进行改进。"
"萤火虫算法 [ 1 ] [ 2 ] 是基于以下三个理想化的特征提出的：(1) 萤火虫不分性别，即萤火虫之间的相互吸引只考虑个体发光的亮度；(2) 吸引力与发光亮度成正比，与个体之间的距离成反比；(3) 萤火虫的亮度由待优化的目标函数值决定，即 I i = f ( x i ) 。FA的关键思想是亮度小的萤火虫被亮度大的萤火虫吸引而向其移动，并更新自身的位置。萤火虫的发光亮度取决于自身所处位置的目标值，亮度越高所表示的目标值越好，吸引其他萤火虫的能力也越强。若相邻的个体亮度相同，萤火虫则随机移动。 在标准的FA中，每个萤火虫都能被人群中其他明亮的萤火虫所吸引，这种吸引力机制称为完全吸引模式 [ 3 ] [ 4 ]，在该模型下，标准FA具有双环操作，因此，计算时间复杂度很高，同时FA的搜索能力受到其控制参数(如步长因子)的影响 [ 5 ]。为了解决这个问题，本文提出了一种自适应的参数策略来动态调整步长因子，来消除吸引力。 1) 自适应搜索策略 一些文献指出，FA的搜索能力受到其控制参数(如步长因子)的影响。为了克服这个问题，本文使用了一种自适应的参数策略来动态调整步长因子α的值。 α ( t + 1 ) = ( 1 9000 ) 1 / t α ( t ) (4) 其中，t指进化的代数。 基于Rao等人提出的Jaya算法，本文针对萤火虫的移动方式进行了下面改进： x i d ( t + 1 ) = x i d ( t ) + r 1 d ( x j d ( t ) − | x i d ( t ) | ) − r 2 d ( x w d ( t ) − | x i d ( t ) | ) (5) 其中，r 1d 和r 2d 是2个[0,1]之间的随机数，X w 是当前种群中的最差解。与原有的萤火虫移动公式相比，上述改进公式消除了吸引力的概念。因此，我们新提出的算法不再包含初始吸引力和光吸收系数两个参数。 2) 反向学习过程 为了加快算法的收敛，本文使用了反向学习策略(Opposition-Based Learning OBL)。对于当前种群中的最好解X best ，本文利用OBL产生一个反向解 X b e s t * 。 X b e s t * ( t ) = a ¯ + b ¯ − X b e s t ( t ) (6) 其中， [ a ¯ , b ¯ ] 表示当前种群的搜索区间。如果新产生的反向解 X b e s t * 优于X best ，则使用 X b e s t * 替换X best 。一些研究表明 [ 6 ] [ 7 ]，反向学习策略OBL有较高的概率找到的反向解比当前解更好。 3) 算法实现过程 Begin Initialise the population; while the stopping condition is satisfied do Update the step factor according to equation (4); for i = 1 to N do for j = 1 to N do if f(Xj) < f(Xi) then Conduct the movement according to equation (5); Compute the fitness value of Xi; end if end for Conduct the X best * according to equation (6); ifX best * be better than X best X best = X best * end if end for end while End"
"为了验证AFA算法性能，本文使用了7个基准函数进行测试 [ 8 ] [ 9 ] [ 10 ] [ 11 ]，所有测试函数均为最小值优化函数且全局最优解均为零。 测试函数1： F 1 ( X ) = ∑ i = 1 D x i 2 ,     x i ∈ [ − 100 , 100 ] (7) 测试函数2： F 2 ( X ) = ∑ i = 1 D | x i | + ∏ i = 1 D x i ,     x i ∈ [ − 10 , 10 ] (8) 测试函数3： F 3 ( X ) = ∑ i = 1 D ( ∑ j = 1 i x j ) 2 ,     x i ∈ [ − 100 , 100 ] (9) 测试函数4： F 4 ( X ) = max i ( | x i | , 1 ≤ i ≤ D ) ,     x i ∈ [ − 100 , 100 ] (10) 测试函数5： F 5 ( X ) = ∑ i = 1 D − 1 ( 100 ( x i − x i 2 ) 2 + ( x i − 1 ) 2 ) ,     x i ∈ [ − 30 , 30 ] (11) 测试函数6： F 6 ( X ) = ∑ i = 1 D i x i 4 + r a n d ( 0 , 1 ) ,     x i ∈ [ − 1.28 , 1.28 ] (12) 测试函数7： F 7 ( X ) = 418.9829 ⋅ D − ∑ i = 1 D − 1 ( x i sin ( | x i | ) ) ,     x i ∈ [ − 500 , 500 ] (13)  测试实验中上述7个函数维度D分别设置为为10和30，并将AFA的计算结果与MFA和PAFA进行比较，结果显示，本文提出的HFA优于其它两种改进的FA算法。所有算法的终止条件均设置为适应值函数最大个数(MaxFEs)。维度D = 10时，MaxFEs设置为1.0e+04；维度D = 30时，MaxFEs设置为5.0e+04。对于两种不同的维度值，算法的其他参数α，β 0 ，γ分别设置为0.2，1.0，及1/Γ2。 表1展现了当维度D = 10时，经过30代的演化计算三种算法所得到的最优函数值。从结果来看AFA函数结果除函数F7外均优于MFA。求解函数F7问题时，算法MFA和PAFA的优化结果优于AFA算法的结果。与MFA算法类似的是，AFA算法求解F1至F6函数所表现出的其他性能(收敛速度、不易陷入局部寻优等)亦优于PAFA算法，如对于所有的测试函数求解过程中，当AFA算法已找到最优函数值时，算法MFA和PAFA仍陷入局部寻优过程。正如文章开始提到的“标准FA的搜索能力受到其控制参数(如步长因子)的影响，会导致算法收敛早熟”，通过自适应策略，本文提出的AFA算法不易陷入局部寻优的过程。 表2展现了当维度D = 30时，经过30代的演化计算三种算法所得到的最优函数值。如表所示，AFA求解F1，F2，F3，F5，F6，F7函数展现了较好的算法性能。MFA在求解F4函数时优于AFA。相对于PAFA，求解F1，F2，F5，F6函数时MFA能够找到更加精确地解。求解F3，F4，F7函数时PAFA性能优于AFA。 Table 1 测试函数 MFA PAFA AFA 最优解 最优解 最优解 F1 2.08e+02 2.59e+01 6.19e−05 F2 2.83e+00 8.46e−01 2.68e−03 F3 4.26e+02 1.56e+01 4.52e−01 F4 8.65e+00 1.21e+00 1.32e−01 F5 2.04e−02 6.49e−03 4.16e−03 F6 1.87e+03 1.42e+03 1.08e+03 F7 3.01e+01 1.84e+01 3.12e+01 表1. 维度D = 10各算法寻优结果 Table 2 测试函数 MFA PAFA AFA 最优解 最优解 最优解 F1 5.34e+02 8.82e−04 1.68e−09 F2 1.01e+01 1.42e−02 1.12e−05 F3 2.15e+03 8.08e−03 3.12e−01 F4 8.65e+00 1.29e−02 1.32e+01 F5 6.96e−02 1.62e−02 1.28e−02 F6 6.53e+03 6.12e+03 5.98e+03 F7 1.83e+02 2.78e+01 3.26e+01 表2. 维度D = 30各算法寻优结果 图1展示的是当维度D = 10，算法AFA、MFA和PAFA求解函数F1，F2时的算法收敛过程。 图1. D = 10，AFA、MFA及PAFA的收敛过程，(a) 功能F1，(b) 功能F2 图2展示的是当维度D = 30，算法AFA、MFA和PAFA求解函数F1，F2时的算法收敛过程。 图2. D = 30，AFA、MFA及PAFA的收敛过程，(a) 功能F1，(b) 功能F2 从收敛曲线来看，本文提出AFA的收敛速度也比MFA和PAFA快。通过标准反向学习过程，AFA解决了“FA因参数设置不当而导致算法无法收敛或收敛速度过慢”问题。 测试实验中，MaxFEs的值设置的较小。当维度从10增加到30时，MaxFEs的值从1.0e+04增加到5.0e+04，算法MFA和PAFA的实验结果值得到了改进，但如果将MaxFEs设置为一个更大的值时，AFA可能会有更好的表现。通过实验可以得出，MaxFEs的值对AFA的算法性能影响很大。"
"本文提出了一种新的数值优化算法AFA，该算法基于标准的萤火虫算法FA，采用三种改进的措施，包括自适应的参数方法来动态改变步长参数，应用一种改进的搜索策略来消除吸引力；再使用反向学习来提高解的精度。为了验证AFA的算法性能，文章测试了7个标准的数值优化函数，并分别测试了所测7个函数不同维度值。实验结果表明，AFA算法在求解大部分函数时所表现出来的性能都优于算法MFA和PAFA。 然而，通过函数收敛图可以发现，AFA在整个优化过程中，该算法的收敛速度并没有明显优于MFA和PAFA算法，如何解决这一问题，使AFA算法性能更好，这将是作者今后的研究工作之一。"
