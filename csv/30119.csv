"大多数植物图片识别的方法，都是聚焦与植物图片的某一特征进行识别，例如叶径，叶长，花，果实，叶片。使用其植物某个器官进行识别，这样得出的结果并不可靠，因为实际自然界有非常多的植物有着极其相似的特征。本文通过选取整个植物图片作为训练样本，即提取植物的所有特征，基于卷积神经网络(Convolutional Neural Networks, CNN)中的AlexNet模型，利用GPU并行计算能力加快模型训练和图片识别速度。通过对潘安湖的5类植物数据集进行训练，训练得到正确精度为87.5%的模型，并且将此训练精度与最近邻(K-NearestNeighbor, KNN)和BP神经网络(Back Propagation, BP)两种分类算法训练得到的训练精度作比较，验证了模型的高可用性。以此模型为基础，应用Python开发了一款基于潘安湖湿地公园植物的植物APP识别软件。 关键词 :深度学习，卷积神经网络，潘安湖湿地公园 Copyright © 2019 by author(s) and Hans Publishers Inc. This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/"
"植物是人类日常生活当中不可缺少的一部分。就刚需而言，它提供人类生活所必需的氧气、食物和药材，以及对空气的净化能力；而植物的观赏性和部分稀缺植物的珍贵则形成了人类对植物的弹需。无论是刚需或者是弹需，植物的作用不言而喻。如何普及人们对世界上已有植物的了解以及对现存海量植物的管理和保护，就是目前人们需要考虑的问题。潘安湖湿地公园地处于江苏徐州市，草本植物丰富。据调查，目前已发现植物97科227属353种 [ 1 ] 。 在植物识别方面，前人也有一些实践。但是，多种植物识别，一般传统意义上的机器学习算法很难支持，并且在识别效率和速度上也很难满足要求。第一款植物识别app由Leafsnap小组 [ 2 ] 研发成功，但其局限性很明显，只是满足其在植物的叶片上的识别。黄婕等 [ 3 ] 提出了尺度不变特征变换(SIFF)的带预处理的算法，此算法针对展示在摄像头之下的植物叶片，可以进行植物叶片的自动分类，达到了识别53中植物叶片的效果。秦风 [ 4 ] 等人提出了基于CNN和SVM算法的图像分析，测试集准确率达到87.48%。目前来说，这些植物识别准确率上差异明显，可识别的植物种类也少。 目前比较成熟的深度卷积网络模型有很多，最出名的包括AlexNet [ 5 ] ，VGGNet [ 6 ] ，GoogleNet [ 7 ] ，ResNet [ 8 ] ，这些网络模型在每年的IamgeNet图像分类竞赛中都有着出色的表现。并且在实际应用中，准确度、内存占用、参数、操作时间、操作次数、推理时间、功耗都体现出了优秀的成绩 [ 9 ] 。本文采用深度学习中卷积神经网络(Convolutional Neural Networks)的AlexNet模型对潘安湖植物进行植物特征提取和分类建模，与KNN最近邻分类和BP神经网络两种分类算法进行实验结果对比，验证实验可行性。"
"卷积神经网络(CNN)，是人工神经网络其中的一种。相较于全连接神经网络的输入层、输出层和隐藏层每一层的所有神经元与相邻的所有神经元全部连接相比，卷积神经网络的权重共享的网络结构，降低了模型的复杂度，减少了权值的数量。同时，卷积神经网络可以直接将图片作为输入对象，自动提取图片特征。卷积神经网络主要由卷积层、池化层和全连接层三个部分组成。 卷积层(Conv Layer)的输出张量(图像大小)计算公式： Putsize = floor ( Insize + 2 * padding-pool_size ) / stride + 1 (1) Putsize——卷积后的图片张量；Insize——输入张量大小；padding——填充数；pool_size——卷积核尺寸大小；stride——采样核移动步长。 池化层(MaxPool Layer)的输出张量(图像大小)计算公式： (2) Oousize——池化后的图片张量；Insize——输入张量大小；Csize——池化层尺寸；stride——采样核移动步长。 全连接层(Full Connected Layer)的输出张量(图像大小)：全连接层输出向量长度等于神经元的数量。  总共有八层网络。前5层是卷积层(convolution)，后3层是全连接层(full-connected)。 Conv1为96个大小为11 × 11 × 3，步长为4个像素的的核对224 × 224 × 3的输入图像进行滤波；conv2为256个大小为5 × 5 × 48的核对第一个卷积层的输出进行滤波；conv3为384个大小为3 × 3 × 256的核连接到第二个卷积层的输出；conv4和conv5分别为384个大小为3 × 3 × 198的核及256个大小为3 × 3 × 192的核。每个全连接层各有4096个神经元。 其中最后的一个全连接层output是具有100个输出的Softmax。在第一层conv1和conv2后是morm1和norm2层，每一个conv层以及全连接层后紧跟的是激活函数(ReLu)。池化(Maxpooling)操作紧跟在norm1和norm2和conv5之后。随机失活(Dropout)操作在最后两个全连接层。AlexNet网络结构如图1。 图1.AlexNet网络结构"
"本文使用的植物图像数据集是在潘安湖湿地公园实地采集到植物图片，数据集所包含的植物种类和数量如表1所示。 Table 1 数据集 含有植物种类 植物图片数量 潘安湖植物数据集 5 3670 表1. 植物图像数据集 数据集训练测试采用二八分，即实验过程中随机选取每种类别的植物图片的前80%样本为训练数据集，剩下的20%样本则构成测试数据集。  本系统采用的CPU显卡为GTX1050Ti，显存4GB。在Deepin 15.7版本环境下配置Tensorflow，opencv服务，构成以tensorflow为核心的GPU加速卷积神经网络框架。  1) 数据集处理：植物的五个类别每个类别约有680张图片，将每个类别对应图片按照二八百分比分成训练集和测试集。 2) 数据预处理：植物图片大小不一，所以通过python语言的图片处理代码将所有图片像素resize，使得每张图片的大小一样。实验采取三种不同输入的图片张量，分别为32 × 32 × 3，64 × 64 × 3，80 × 80 × 3。其中，图片通道数为3。 3) 确立网络流程，建立网络结构：本实验采用AlexNet网络结构，其中4个卷积层，三个全连接层。模型结构如图2。 图2. 模型结构 网络训练流程图如图3。 图3. 网络训练流程图 4) 定义损失函数、激励函数以及学习率和正则化 5) 模型尺寸分析：因为卷积层部分采用了全部补0，所以训练经过卷积层时长和宽不变，深度加深；而池化层全部没有补0，所以训练过程池化层长和宽均减少，深度不变。模型图片大参数变化过程如表2。 Table 2 Input_size filter kernel_size Pading Pool_size strides Output_size 32 × 32 × 3 32 -> 64 -> 128 -> 128 5 × 5 -> 5 × 5 -> 3 × 3 -> 3 × 3 Same 3 × 3 2 2 × 2 × 128 64 × 64 × 3 32 -> 64 -> 128 -> 128 5 × 5 -> 5 × 5 -> 3 × 3 -> 3 × 3 Same 3 × 3 2 4 × 4 × 128 80 × 80 × 3 32 -> 64 -> 128 -> 128 5 × 5 -> 5 × 5 -> 3 × 3 -> 3 × 3 same 3 × 3 2 5 × 5 × 128 表2. 模型图片参数变化过程 图片尺寸具体变化过程如表3。 Table 3 输入大小 尺寸变化 32 × 32 × 3 32 × 32 × 3 -> 32 × 32 × 32 -> 16 × 16 × 32 -> 16 × 16 × 64 -> 8 × 8 × 64 -> 8 × 8 × 128 -> 4 × 4 × 128 -> 2 × 2 × 128 64 × 64 × 3 64 × 64 × 3 -> 64 × 64 × 32 -> 32 × 32 × 32 -> 32 × 32 × 64 -> 16 × 16 × 64 -> 16 × 16 × 128 -> 8 × 8 × 128 -> 4 × 4 × 128 80 × 80 × 3 80 × 80 × 3 -> 80 × 80 × 32 -> 40 × 40 × 32 -> 40 × 40 × 64 -> 20 × 20 × 64 -> 20 × 20 × 128 -> 10 × 10 × 128 -> 5 × 5 × 128 表3. 图片尺寸具体变化过程 6) 存储模型并调用 在得到训练模型之后，将测试集的图片用于模型测试，检验模型可用性。测试流程如图4。 图4. 测试流程"
"可视化工具TensorBoard可以将TensorFlow程序运行过程中输出的日志文件可视化，其中训练模型张量变化过程如图5所示。 图5. 基于tensorboard训练模型  其中横坐标为训练集(测试集)图片数量/每次迭代输入的图片数量，一共迭代50次；纵坐标为正确率。三种不同像素输入张量所得到训练与测试的拟合程度如图6所示。 图6. 像素拟合程度汇总  数据集：训练数据总共有五类植物，其中雏菊(daisy)有633张图片，蒲公英(dandelion)有898张图片，红玫瑰(rose)有641张图片，向日葵(sunflower)有699张图片，郁金香(tulip)有799张图片。分别收集每类植物图片100张，用于模型正确率实测，测试结果如表4。 Table 4 Classification Daisy Dandelion Rose Sunflower Tulip Accuracy 88% 89% 95% 85% 78% 表4. 模型正确率实测 为了进一步验证本文采用的AlexNet模型识别的识别率，分别用BP神经网络 [ 10 ] 和KNN最近邻分类 [ 11 ] 这两种分类算法进行对比。验证方法与上面五类植物图片正确率验证一致，均用分类的方法分别对五种植物识别，得到综合识别率。对于识别速率的评价，使用了K交叉验证。该结果表明，本文采用的模型以及识别方法具有更高的识别率，其实验对比如表5所示。 Table 5 分类算法 识别率 KNN最近邻 0.8409 BP神经网络 0.8581 CNN 0.8748 表5. 不同分类器的自定义实验对比  通过将模型植入到Android项目中，开发app。app识别潘安湖图片效果如图7所示。 图7. 植物识别APP软件  此实验采用。由图5由图6可知，当输入张量为32 × 32和64 × 64时，训练集得到训练正确率和测试集得到的测试正确率呈稳步上升的趋势，两者在约各自迭代图片数据到三分之二时，正确率几乎重合，随着迭代的进行，正确率被拉开，最终各自稳定在99%和63%左右。图7输入张量为80 × 80时，训练所得到的正确率不可思议的达到了100%，而测试正确率仅为65%，显然训练过拟合造成了训练的正确率稳定在了1。同时，训练正确率和测试正确率的曲线重合率也反映出了收敛的过程。而最好的结果应该是训练正确率和测试正确率数据越接近，得到正确率越高。通过对三种不同的输入张量训练所得到的正确率进行对比，当图片张量为64 × 64时，所得到的训练、测试正确率数据最接近，且上升趋势稳定，因此，64 × 64像素处理应该是此实验最佳的方案，得到了87%的识别正确率。同时，在与KNN最近邻和BP神经网络两种分类算法分别对数据集图片进行实验比较，可知，在采用64 × 64像素处理的情况下，植物图片的识别率在三种图片分类算法上，卷积神经网络算法在植物图像识别上，有着更加优秀的表现。"
"本文在介绍了卷积神经网络之后，化理论为实操。通过实验，基于卷积神经网络将潘安湖湿地公园的部分植物用于实验数据，在通过不同参数的反复调整与训练，得到的识别模型的正确率基本稳定，最后将识别模型用于app中。本文目前只是采集了五种不同植物，并且图片数量有限，后期得到了更多的样本，再调整下网络结构，得到的正确率将会大大提高。"
