"糖尿病视网膜病变(Diabetic Retinopathy, DR)是由糖尿病引起的视网膜血管壁受损致使视觉功能下降的一种具有特异性改变的眼底病变，是主要致盲疾病之一。在医学图像处理中，糖尿病视网膜病变诊疗通常面临高质量标注样本少和未标注数据不能充分利用的困境。基于此，本文利用增强的半监督生成对抗网络对糖尿病视网膜病变等级和程度进行识别，实现更高的识别精度和泛化能力，最终四分类任务中准确率达到77.2%，二分类任务中AUC达到93.9%。 关键词 :生成对抗网络，视网膜病变识别，图像分类 Copyright © 2019 by authors and Hans Publishers Inc. This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/"
"糖尿病视网膜病变(Diabetic Retinopathy, DR)，又称糖网病，它是糖尿病引起的并发症之一 [ 1 ] 。糖尿病患者出现DR的概率是80%左右，出现失明的可能性是正常人的25倍 [ 2 ] 。为有效降低DR对患者视力的损害，亟需对DR进行早期诊断和治疗。然而，DR病变类型多元、形式多样、程度不等，因此眼科医生往往难以对糖尿病视网膜病变进行精准、快速诊断。 近年来，深度学习技术在医学图像模式识别领域受到广泛关注 [ 3 ] [ 4 ] [ 5 ] [ 6 ] ，特别是卷积神经网络(Convolution Neural Network, CNN)，能够模拟人脑视觉机理自动地学习图像各个层次的抽象特征，从而更好地反映目标图像的本质，但是深度学习模型具有对大量标注数据依赖度高的特性，然而实际医学应用中缺乏高质量的标注数据，导致监督学习方法存在着很大的局限性。 基于以上事实，本文提出一种增强的半监督生成对抗网络模型，它可以有效利用有限的标注数据，对视网膜病变图像进行自动等级分类，从而大幅度节省眼科医生的诊断时间，为患者疾病评估和治疗方案选择提供重要参考，对于实现可用的DR眼底图像分类系统同样具有重要的临床意义。"
"医学图像处理领域针对糖尿病视网膜病变疾病的识别，现有文献多集中于筛选区分有DR和无DR的图像二分类，应用于DR图像四分类的研究相对较少，并且在精度、性能等方面并不完善。 在国内，针对糖尿病视网膜病变识别的研究主要集中在深度学习与医学图像相结合进行疾病辅助诊断方面。张德彪 [ 7 ] 采用深度学习的方法对糖尿病视网膜病变的严重程度进行分类，并对微动脉瘤和弱监督环境下的病变区域进行检测定位。熊彪 [ 8 ] 将迁移学习用于卷积神经网络中，并用于DR分类，最终达到不错的效果。而国内外运用生成对抗网络对糖尿病视网膜病变进行识别的研究相对很少。张磊 [ 9 ] 在对眼底硬性渗出物进行检测过程中，成功改进和应用了信息生成对抗网络。 国外已经有较多相关辅助诊断系统研究，Seoud等人 [ 10 ] 提出了使用生成病变概率图进行分类的方法，并达到了74.1%的分类精度。Pratta等人 [ 11 ] 和提出了一种卷积神经网络方法，结合Kaggle视网膜病变数据集，最终在验证集中获得75%的准确率。Gulshan等人 [ 12 ] 提出了另一种深度卷积神经网络结合公开的数据集来检测DR，最终得到了很高的特异性和灵敏性。Haloi [ 13 ] 提出了一种新的微动脉瘤(MA)检测方法，对彩色眼底图像进行早期糖尿病视网膜病变筛查。Gargeya等人 [ 14 ] 使用2个公共数据库检测糖尿病视网膜病变时，该模型表现出最佳的诊断性能。Antal等人 [ 15 ] 提出基于集成的微动脉瘤检测系统，在数据集上取得了良好的效果。Vo H.H.等人 [ 16 ] 使用两个深度卷积神经网络，用于检测眼底图像病变情况。Alban等人 [ 17 ] 使用迁移学习的方法进行DR识别，从而减缓模型收敛的速度。  卷积神经网络(CNN)是近年发展起来并引起广泛重视的一种高效识别方法，它已经成为众多科学领域的研究热点之一，特别是在模式分类领域，由于该网络避免了对图像的复杂前期预处理，可以直接输入原始图像，因而得到了更为广泛的应用。卷积神经网络一般包含输入层、隐藏层和输出层，而其中隐藏层通常由一个或多个的卷积层与池化层交替结构连接一个或多个全连接层构成。图片经卷积层提取特征，通过池化层降低数据维度并提高特征不变性，多层卷积池化组合特征后，由全连接层选取其中的有效特征，构建与输出的映射关系 。"
"本文中使用的数据集是Messidor [ 18 ] 眼球数据集，该数据集中包括大约1200个眼底彩色图像。图像的大小为1440 × 960，2240 × 1488和2304 × 1536像素，如图1所示，其中，800张是瞳孔扩张图像，400张是瞳孔未扩张图像。 图1. 视网膜病变图片 对于每张图片，根据微血管瘤、出血点、硬渗出物和新血管的个数进行疾病诊断，每个图像都标有病变等级R0至R3。其数据描述和分布如表1所示，识别任务描述如表2所示。 Table 1 等级 描述 数目 R0 (μA = 0) AND (H = 0) 546 R1 (0 < μA ≤ 5) AND (H = 0) 153 R2 ((5 < μA < 15) OR (0 < H < 5)) AND (NV = 0) 247 R3 (μA ≥ 15) OR (H ≥ 5) OR (NV = 1) 254 表1. 视网膜病变特征描述 注：μA表示微动脉瘤的个数，H表示出血点的个数，NV = 0/1分别表示无/有新生血管。 Table 2 分类任务 描述 数目 DR四分类 R0/R1/R2/R3 546/153/247/254 正常/不正常 R0/R1R2R3 546/654 表2. 分类任务描述   生成对抗网络(Generative Adversarial Network, GAN)是一种新的深度学习模型，它主要包括了两个部分，即生成器和判别器。生成器主要用来学习真实图像分布从而让自身生成的图像更加真实，以骗过判别器。判别器则需要对接收的图片进行真假判别。在整个过程中，生成器致力于让生成的图像更加真实，而判别器则专注于识别图像的真假，这个过程相当于博弈，随着时间的推移，生成器和判别器在不断地进行对抗中达到了一种动态均衡，即生成器生成的图像接近于真实图像分布，而判别器识别不出真假图像，对于给定图像的预测为真的概率基本接近0.5，即达到纳什平衡状态。  增强型半监督生成对抗网络是基于生成对抗网络进行的优化，由于糖尿病视网膜病变图像都是高分辨率图像，并且它的病变特征又非常的小，因此在生成图像时总会丢掉疾病特征的关键信息，为了更精准地生成图像的关键信息，更好地学习到数据的分布，需要一个强的生成器。而且现实中带标注数据明显少于未标注数据，这也有助于提升模型的性能。因此，本方法采用强学习能力的半监督生成对抗网络进行识别。这种改进型生成对抗网络可以很好地学习到原始数据的分布、更充分地利用少量带标注的数据和大量未带标注的数据，具体的网络结构和参数设置如图2所示。 图2. 网络结构和参数"
"本实验的环境设置如表3所示。对于生成器，它输入是一个100维的噪声向量，紧接着是通过权值共享卷积核为4 × 4的反卷积层，随后按视网膜病变图像的通道进行图像生成，将生成的图像和真实图像同时输入给判别器进行判别。对于判别器，我们采用3 × 3的卷积核进行特征提取。具体的网络结构和卷积核的个数如图2所示。我们使用Adam优化算法，学习率和两个衰减率参数分别取0.0001与0.9、0.999。权重参数W使用Xavier均匀分布初始化，最小批次数量设置为32。 Table 3 序号 项目 详细信息 1 GPU NVIDIA Ge Force GTX1080 2 CPU Intel (R) Core (TM) i7-6700 CPU@3.41 GHz 3 深度学习框架 Tensorflow、Keras 4 操作系统 Ubuntu 16.04 表3. 实验环境参数配置   正如“没有免费的午餐”理论所说，没有一个模型适用于任何任务。表4中的网络结构分为两列：图像压缩尺寸和判别器。判别器的结构以“32c7s2-64c5s2-128c4s4-128c4s2-gm”的格式呈现。这个例子表明有4层卷积层和一层平均池化层，其中第一层卷积层“32c7s2”代表一个7 × 7卷积层，其卷积核数为32，步长为2，卷积层后均连接到Relu激活函数层。 Table 4 网络结构 网络编号 图像尺寸 判别器 256 × 256 32c4s2-64c4s2-128c4s4-256c4s2-512c4s2-gp 1 32c7s2-64c5s2-128c5s2-128c5s2-256c5s2-256c5s2-gp 2 32c7s2-32c5s2-64c3s2-64c3s2-128c3s2-128c3s2-gp 3 128 × 128 32c4s2-64c4s2-128c4s2-256c4s2-512c4s2-gp 4 32c3s2-64c3s2-128c3s2-256c3s2-512c3s2-gp 5 32c5s2-64c5s2-128c5s2-256c5s2-512c5s2-gp 6 32c7s2-64c7s2-128c5s4-128c5s2-128c3s1-gp 7 32c7s2-64c5s2-128c4s4-128c4s2-gp 8 表4. 不同网络结构 在这11种网络结构下，模型精度如图3所示，训练了DR四分类器模型。由表4可知，最好的是网络5，它的平均精度达到了77.2%，相比其他的网络结构有较大的优势。  为了更好的说明模型的性能，本文使用准确度(Accuracy, ACC)，灵敏度(Sensitivity, SN)，特异性(Specificity, SP)，ROC和AUC描述了实验结果。SN表示所有真实的阳性样本中有多少阳性样本可以被检测出来，SP表示所有真实的阴性样本中有多少阴性样本可以被检测出来。分类性能指标SN、SP和ACC的计算方法： 图3. 不同网络结构下糖尿病视网膜病变分类精度 SN = T P T P + F N , SP = T N T N + F P , ACC = T P + T N T P + F P + T N + F N 其中TP表示真阳性，即正阳性样本的数量为正；FP表示假阳性，即阳性阴性样本的阳性数量；TN表示真阴性，即表示被判定为否定的阴性样本数；FN是假阴性，这意味着阳性样本的数量被判断为阴性。ROC是以阳性率(1 − SP)为横坐标，真阳性率(SN)为纵坐标来反映分类性能。ROC曲线越接近左上角，分类性能越好，并且ROC曲线可以综合评估两种或更多种分类性能的差异。AUC表示ROC曲线下的面积，AUC范围是0~1，AUC越大，分类性能越好。 表5是关于糖尿病视网膜病变等级的四分类问题，对比了目前关于糖尿病视网膜病变等级中相对较高的精度，其中前两行分别是来自眼部疾病专家对糖尿病视网膜病变分类的精度。从表中可以得知，增强后的模型达到了比专家更高的精度。 Table 5 方法 分类精度 Expert A [ 19 ] 0.73 Expert B [ 19 ] 0.681 Seoud et al. [ 10 ] 0.741 增强的SSGAN 0.772 表5. 糖尿病视网膜病变分类精度对比 表6是糖尿病视网膜是否发生病变的性能，其主要采取四个指标去判断模型的识别能力，包括AUC、灵敏度、特异度和精度。通过实验可以表明本实验使用的增强型半监督生成对抗网络在各个指标下有较大的优势。 Table 6 方法 AUC 灵敏性 特异性 分类精度 Expert A [ 19 ] 0.922 - - 0.878 Expert B [ 19 ] 0.865 - - 0.764 Haloi et al. [ 12 ] 0.988 0.970 0.960 0.960 VoHH et al. [ 16 ] 0.870 0.882 0.857 0.871 VoHH et al. [ 16 ] 0.862 0.916 0.803 0.858 增强的SSGAN 0.939 0.921 0.861 0.889 表6. 糖尿病视网膜是否发生病变性能指标对比"
"糖尿病视网膜病变易导致失明并且并发率非常高，所以必须对DR进行早期诊断与治疗以降低对患者视力的损害。本文提出的半监督生成对抗网络可以有效地实现DR辅助诊断。本文主要内容包括： 第一，在原始的半监督生成对抗网络的基础上，采用多通道的生成器按彩色图片的通道来学习，有效识别高分辨率图片，使生成器更容易辨别原始数据的真实分布情况，从而精准判别疾病种类并给出诊断结果。第二，通过大量实验验证并对比眼部疾病专家和相关自动识别系统的性能，确保即使运用较少的带标注数据也能实现较高的识别精度。综合实验证明，运用改进的生成对抗网络可以更高效地识别糖尿病视网膜疾病，在四分类任务中准确率达到77.2%，二分类任务中AUC达到93.9%。以训练后网络模型参数为基础构建糖尿病视网膜病变自动识别模型，可实现输入眼球图片即可判定和输出疾病等级。 此外，由于数据集不足、图片精度与存储空间等客观问题，本文尚有一些不足之处，如糖尿病视网膜病变的等级识别由疾病特征个数决定，目前尚未处理好高分率图像压缩比例与模型规定的输入数据大小之间的最佳平衡问题等。为此，在未来的实验与研究中可尝试运用回归的损失函数进行更新等方法进行优化。"
