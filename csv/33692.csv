"人脸识别一般可分为识别及验证等两种应用场景。早期的人脸识别输入数据，大多是通过二维灰图像实现，同时，一些方法也引入了立体视觉系统来获取三维信息进行识别。由于受到使用环境上的诸多限制，如二维脸部数据较易受到环境光源、脸部方位、及化妆等影响而造成准确性降低，而三维人脸识别信息虽可克服上述缺点，但仍有高运算量及易受脸部表情影响等限制。因此，结合二维与三维的优点，本文实现一个实用且稳定的人脸识别技术，本文通过对目前该领域的研究，作一详细的介绍与比较，相信能对建基于多维信息的现代人脸识别系统的发展有所帮助。 关键词 :人脸识别，深度图像，人脸特征，正规化 Copyright © 2020 by author(s) and Hans Publishers Inc. This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/"
"人脸识别为图形识别领域内，已研究多年的题目。因为它为人类个体最重要的个人特征，所以很直觉地可以作为身份识别的基础，进而开发出众多的应用。例如以人脸识别为基础的门禁系统，即为一显而易见的应用例子。然而，稳定又高效率的人脸识别，事实上为一个相当困难的技术。数十年来，各方学者已持续提出各类的方法及见解。这些众多的方法各有特色，但也各有优缺点及适用范围，因此，有必要作一整理及分析，以对后续研究有所指引与帮助。 人脸识别一般而言可分为识别及验证等两种应用情境。早期的人脸识别输入数据，大多是通过二维灰阶或彩色图像。同时，有一部分的学者亦引入立体视觉系统作为人脸识别的数据输入。近年来，随着传感器的进步与发展，越来越多的深度测量仪器被用来取得三维的脸部信息，并作为人脸识别的数据输入。一般而言，二维脸部数据较易受到环境光源、脸部方位、及彩妆等影响而造成准确性下滑，因此常受到使用环境上的诸多限制。而三维数据虽可克服上述缺点，但仍有高运算量及易受脸部表情影响等限制。因此，结合两者的优点，以实现一个实用且稳定的人脸识别技术，为目前一个引起高度研究兴趣的新课题。"
"近年来，随着计算机技术的迅速发展，人脸自动识别技术得到广泛研究与开发，人脸识别成为近30年里模式识别和图像处理中最热门的研究主题之一。人脸识别的目的是从人脸图像中抽取人的个性化特征，并以此来识别人的身份。人脸识别主要分为人脸检测、特征提取和人脸图像匹配与识别。 人脸检测：这是指从输入图像中检测并提取人脸图像，通常采用haar特征和Adaboost算法训练级联分类器对图像中的每一块进行分类。假如某一矩形区域通过了级联分类器，就被判别为人脸图像。 特征提取：人脸识别可使用的特征通常分为视觉特征、像素统计特征、人脸图像变换系数特征、人脸图像代数特征等。人脸特征提取就是针对人脸的某些特征进行的。而人脸特征提取，也称人脸表征，它是对人脸进行特征建模的过程。特征提取的方法可以分为两大类：一种是基于知识的表征方法；另外一种是基于代数特征或统计学习的表征方法。 人脸图像匹配与识别：这是提取人脸图像的特征数据与数据库中存储的特征模板进行匹配，认证。人脸识别就是把待识别的人脸特征与已得到的人脸特征模板进行相比较，根据相似程度对人脸的身份信息进行判断。这一过程可以分为两类：一类是确认，就是一对一进行图像比较的过程，而另一类是辨认，就是一对多进行图像匹配识别对比的过程。 一个简单的自动人脸识别系统，包括以下4个方面的内容： 1) 人脸检测(Detection)：即从各种不同的场景中检测出人脸的存在并确定其位置。 2) 人脸规范化(Normalization)：校正人脸在尺度、光照和旋转等方面的变化，即人脸对齐或人脸校准。 3) 人脸校验(Face verification)：采取某种方式表示检测出人脸和数据库中的已知人脸，确认两张脸是否是同一个人。 4) 人脸识别(Recognition)：将待识别的人脸与数据库中的已知人脸比较，得出给你的脸是库里的谁。"
"一般而言，不论识别或验证的应用情境，都需先将数个已知的人脸存入一数据库来进行注册(Enrollment)的程序，这些存入数据库的人脸数据一般称为注册组，而往后用来比对验证的人脸图像则称为搜寻图。在识别的情境中，其为一对多的搜寻，搜寻图在注册组内逐一比对，在相似度大于一预设阀值的情况下，找出一最佳的对应；另一方面，验证的情境则是在一已知的身分下，进行一对一的比对，验正该搜寻图是否等同于对应身分的注册组图像。 人脸识别技术的流程图如图1所示，首先将摄影机或其他传感器取得的人脸图像，通过图像前处理步骤去除噪声、图像正规化步骤校正其姿态后，取出人脸上的特征再与数据库内的人脸进行比对，进而得出识别结果。 图1. 人脸识别技术的流程图 早期的人脸识别输入数据，大多是通过摄影机所取得的二维灰阶或彩色图像，但随着传感器的进步与发展，越来越多的深度测量仪器如雷射扫描仪、结构光或基于多摄影机的立体视觉系统被用来取得三维的脸部信息，作为人脸识别的数据输入。一般而言，二维脸部数据较易受到环境光源、脸部方位、及彩妆等影响而造成准确性下滑，而三维数据虽可克服上述缺点，但仍有高运算量及易受脸部表情影响等限制。 图1中的图像前处理步骤，旨在去除传感器产生的噪声、插补遗失的信息、降低环境光源的影响等，此部份我们会于第四节中作较详细的说明。而图像正规化则是将取得的脸部数据，转换成统一的形式，主要包含校正图像大小及脸部方位，使所有图像具有一致性的比对标准，一个准确且强健的正规化可大幅提高后续图像特征撷取及识别的准确性。  至于人脸识别模块，则根据撷取的特征可分为三类，分别为全貌式(Holistic)、局部特征式(Feature-Based)及混合式(Hybrid)三种。全貌式为将脸部所有的像素均作为输入信息，再通过主要成分分析法(PCA, Principle Component Analysis) [ 1 ]、线性判别分析法(Linear Discriminant Analysis) [ 2 ]、贝氏决策(Bayesian Method) [ 3 ]、支援向量机(Support Vector Machine) [ 4 ] 或类神经网络(Neural Network) [ 5 ] 等人工智能算法进行决策。相较于全貌式，局部特征式则是撷取脸部特定区域或局部特征如眼耳鼻口等处，作为评量的基准，而混合式则是将两者结合，藉以提高识别的准确度。"
"图像前处理及正规化的目的在于使注册组与搜寻图的图像都能在相同的分辨率、亮度对比或脸部方位下进行后续的特征撷取及识别处理，以减少因为数据间的变异性造成识别率的下降。 由于在搜集注册组与搜寻图的图像时，不可避免地总是会受到环境光线变化的影响，使得图像亮度的差异严重地图像人脸识别的正确率。基于这个因素，使用Census Transform [ 6 ] 以每一像素为中心，比较周围3 × 3区域内相邻像素的亮度值，亮度值小于中心的亮度值便标示为1，大于则标示为0，便可得到一个8bits的值。因为Census Transform是以局部亮度为基准所得到的比较值，因此对于全局的光影变化及伽马校正(Gamma correction)所造成的亮度变化具有强健性，同时能够保有边缘与纹理等信息。图2第一列表示不同光影环境下所拍摄的人脸图像，第二列表示分别经过Census Transform之后，便可消除不同光影环境所造成的影响 [ 7 ]。 图2. 不同光影环境下利用Census Transform处理的结果 在Lu等人的研究中 [ 8 ]，其针对三维深度图像的所有点，计算其斜率变化并转换为轮廓索引(Shape Index)图像，由于眼窝等凹陷处在轮廓索引图像上有较强烈的响应，可藉此将双眼眼窝自动找出，并藉以衍生取出鼻尖及外眼角位置，通过这些初步定位的特征点先将脸部做初步对齐，再通过递归式最近点法(ICP, Iterative Closest Point) [ 9 ] 将两组数据作更进一步的对齐，以达到脸部方位校正的目的。上述的ICP，为目前最广泛被使用的三维物体表面对位算法，算法中欲进行对位的两组模型可由点、线或三角形的形式构成，称参考点数据以及浮动点数据。在每一次的计算，于浮动点数据上的每一个点搜寻相对应于参考点数据上的最近点，在尽量缩小两组模型的距离之下，计算出一组几何转换公式，经过数次的递归计算以得到最佳的转换关系，以达到对位目的。 ICP匹配算法是一个解决复杂配准问题的关键方法，如有两个点集，Model-Point-Set和Data-Point-Set，固定Model-Point-Set，对Data-Point-Set进行旋转(Rotation)和平移(Translation)甚至加上尺度(Scale)变换， 使得Data-Point-Set上的点尽量和Model-Point-Set上的点尽最大可能的重合。假定 { p 1 , 1 , 2 , ⋯ , N } 表示空 间第一个点集，应用最小二乘法，使得第二点集的对齐变换目标函数为最小： f ( R , t ) = ∑ i + 1 N p i − ( R P t + T ) 2 p i (1) ICP算法的本质是基于最小二乘法，重复进行“对应点集的确定与实体最优空间变换”的迭代过程，直到整个迭代满足设定配准的收敛要求，ICP算法的目的是找到目标点集p与参考点集Q之间的旋转矩阵R和平移矩阵T变换，获取到的数据与参考数据之间的最优匹配。假设目标点集p的坐标为 p i 及参考点集Q的坐标为 Q i ，在第k次迭代中计算与点集p的坐标相对应的对应点坐标为 Q i k ( i = 1 , 2 , 3 , ⋯ , N p ) ，计算P与 Q k 之间的变换矩阵并对原变换进行更新，直到数据间平均距离小于给定阀值 τ ，即满足 f ( R , t ) 最小。具体步骤： 1) 在目标点集P中取点集 p i k ∈ p ； (2) 2) 计算参考点集Q中对应点 Q i k ∈ Q k ，使 ‖ Q i k − p i k ‖ = min ； (3) 3) 计算旋转矩阵 R k 与平移向量 T k ，使 ∑ i = 1 n ‖ R k p i k + T k − Q i k ‖ 2 = min ； (4) 4) 计算 p k + 1 = { R k p i k + T k , p i k ∈ p } ；计算 d k + 1 = 1 n ∑ i = 1 n ‖ p i k + 1 − Q i k ‖ 2 ； (5) 5) 如果 d k + 1 ≥ τ ，则返回2)，直到 d k + 1 ≺ τ 。 (6) Chang等人 [ 10 ] 同样通过ICP来达到正规化的目的，其先利用肤色检测取出脸部部分，再利用三维脸数据的曲率(Curvature)来做特征点的检测，特征点包含鼻尖，眼窝及鼻梁，通过取出的特征点，定义出鼻子周围一圆型区域，再将这个区域内的数据通过ICP对应至统一的脸部模型上。 Mian等人 [ 11 ] 则通过另一手法来进行鼻尖检测，其由左至右从三维深度数据中逐一取出侧脸曲线，并以该曲线上任一点为圆心产生一半径为r的圆，取交点与圆心形成的三角形，定义具有最高垂线的三角形的圆心点为鼻尖，如图3所示，再针对鼻尖周围一范围内的特征点，考虑点的三维坐标，通过PCA转换来校正脸部的方位。 图3. 鼻尖检测技术示意图 如第三节所提到，人脸识别模块根据其撷取的特征可区分为三类，分别为全貌、局部特征式及混合式，本章节即就此三类加以说明。  全貌式的方法是将整个脸部数据作为特征，优点是不需要特殊前处理，但缺点则在于特征空间的维度太大。Turk等人为了克服全貌式方法的特征空间维度太大的问题，同时又能保留原有的特征信息，便利用PCA转换找出最具有最大Eigenvalue的基底向量集合，此基底向量集合保有最多的数据分布信息，称为Eigenfaces [ 1 ]。将整个脸部特征投影到此Eigenfaces所构成的较低维度的特征空间后，便可将脸部特征以Eigenfaces的线性组合表示。通常以投影后特征之间的欧几里得度量(Euclidean Distance)或马氏距离(Mahalanobis distance)来表示相似程度，以进行人脸识别。 Samani等人 [ 12 ] 利用Eigenfaces的原理，分别对二维灰阶图像与三维深度图像进行PCA转换，并得到各自的Eigenfaces后，结合二维与三维信息的相似度进行人脸识别。Chang等人 [ 13 ] 则是在寻找Eigenfaces时，除了去掉Eigenvalue最小的数个基底向量之外，也去掉Eigenvalue最大的数个基底向量，如此可以避免训练数据当中光影与表情变化所造成的影响。由于PCA仅考虑特征在空间分布的分散性，投影后的特征空间未必对人脸识别有最佳的效果，Heseltine等人 [ 14 ] 首先利用不同 kernel对深度信息图像进行特征撷取，然后对全脸特征进行线性判别分析(LDA，Linear Discriminant Analysis)找出对分类效果最佳的投影空间后，再进行PCA转换求取Eigenfaces，如此便可弥补PCA未对数据分类优化的缺点。 相较于基于PCA的方法，Tsalakanidou等人 [ 15 ] 则是针对二维与三维脸部信息，分别通过隐藏式马可夫模型(HMM，Hidden Markov Model)来进行机率式的推论，并将推论结果通过加权和(Weighted Sum)的方式来合并。基于HMM的方法是将人脸由上至下分为数个有重迭的矩形，每个矩形在分别撷取出特征(离散余弦转换为常见方法)并串接起来，如图4所示，作为HMM模型的观察值，并藉此分别训练不同人脸间的HMM模型作为识别的依据。 图4. HMM模型 在Bronstein等人的研究中 [ 16 ]，其通过等距转换(isometric transformation)，根据三维深度图像得到的距离数据，将三维图像摊开成平面，并投影上二维的灰阶信息，如图5所示。接下来再利用上述的基于PCA转换的特征脸(Eigenface)方式，进行人脸识别。 图5. 通过等距转换所得到的2D人脸数据  所谓的局部特征式的方法，乃是针对原始的数据做筛选，取出特定但具有显著鉴别能力的部位来作为识别的基础。早期在Beumier与Acherory的研究中 [ 17 ]，其取出脸部的中央及左右两侧的垂直侧面曲线(Profile)作为特征，并计算于该曲线上的二维灰阶与三维位置的差异作来评估人脸相似度，进而达到人脸识别的目的。 在Lu等人的研究中 [ 8 ]，为了解决识别结果易因同一个体的不同表情而误判，其针对脸部几个较不受表情而变化的区域如鼻梁四周、眼睛四周等，如图6所示，计算搜寻图与注册组图像间的对齐程度，亦即两组点资料对齐后的均方根值(Root-Mean-Square)，并结合数个脸部特征点包含鼻尖、内眼角及外眼角的轮廓索引值(Shape Index)的差异，作为判定的依据。而Chang [ 10 ] 等人亦同样利用鼻子附近包含眉心与鼻翼的点数据，发现其具有极佳的能力来进行人脸识别，并可克服因表情造成脸部差异所导致的错误识别结果。 图6. 脸部不受表情影响区域 同样是针对脸部的数个特征点，Wang等人 [ 18 ] 则取出脸部的数个特征点，包含内外眼角、眉心、鼻尖、鼻翼两侧及嘴角，针对这些点，在二维图像上通过Gabor滤波器测量其纹理上的特性，而在三维深度图像上，则计算其点签名(point signature)作为特征，最后则结合SVM与有向性且非循环图(Directed Acyclic Graph)作决策进而达到识别的目的。  混和式的方法，是较为非主流的一支，但是也有众多的学者提出这类的方法，此类方法的共通手法，是以一局部特征式模块及一全貌式模块，加以搭配组合，达到相辅相成的目的。近年由Assadi等人提出的研究为此类方法的代表之一 [ 19 ]，其先比对二维灰阶脸部图像，若搜寻图与注册组两者的SIFT特征 [ 20 ] 的对应点数多于一阀值(Threshold)，则注册组内最多点数者即为识别结果。而若上述最多对应点数小于该阀值，则选出较多对应点数的数个候选者，再通过深度信息图像去判断，首先通过ICP作对齐后，比较两者的交互相关(Cross Correlation)值，最大者即为识别结果。"
"进行人脸识别研究的另外一个重点，是能够提出量化的效能评估。因效能评估的公信力与实验对象的定义，具有密不可分的关系，各方的学者即建立了数个数据库，并将数据库中的所有对象予以分类及卷标化，以作为针对该数据库特性的算法效能评估的基准。此工作事实上相当旷日费时，所以这些数据库的建立，实为有利于这类研究的顺利进行。 在表1中，列出数个符合本研究范围的数据库。其中，FRGC因涵盖各种条件的数据特性，且相对数量足够，所以尤为最常使用者，相关的研究文献也较为丰富。 Table 1 DB Name Data size/pixel Persons Images FRGC v1 480 × 640 200 468 FRGC v2 480 × 640 466 4007 Sheffield 2D: 256 × 256 3D: 128 × 128 22 1080 K. I. Chang 2D: 1704 × 2272 3D: 640 × 480 275 2365 The 3D Face Database - 280 1770 表1. 常用于人脸识别算法效能评估的人脸数据库列表"
"随着传感器的进步与发展，越来越多的深度传感器，被用在三维的脸部数据的获取中，作为新型态的人脸识别方法，由于二维脸部数据较易受到环境光源等影响而缩限了其使用环境，而三维数据虽可克服上述缺点，但仍有高运算量及易受脸部表情影响等限制。因此，结合二维方法的快速与直觉，以及三维方法的多维度信息等两者的优点，来实现一个实用且稳定的人脸识别技术，是非常有必要的。因此，本论文对该领域的代表性研究，作了一详尽的介绍与比较，对建基于二维及三维信息的现代人脸识别技术的研究，提供有益帮助。"
