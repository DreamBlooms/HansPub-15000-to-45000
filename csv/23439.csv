"随着经济不断转型，小微企业为我国经济发展注入了新的活力。为了增强小微企业的风险管理水平，从而提高其成活率，就必须进行有效的风险评价。对我国小微企业进行风险评级，可以运用支持向量机(SVM)方法，并依据建立的风险评价指标体系，通过对选取的样本数据进行SVM分类训练，评估我国部分小微企业风险等级水平。从而方便企业管理者根据风险水平，采取切实有效风险控制措施，促进小微企业良性发展。 关键词 :小微企业，风险评级，支持向量机，分类训练 Copyright © 2018 by authors and Hans Publishers Inc. This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/"
"近年来，我国股权众筹行业高速发展，项目数量和平台数量都大幅增长。股权众筹在增加投资者理财方式的同时，更完善了小微企业的融资渠道，从而提高了金融市场的效率，促进了我国创新创业，推动了经济结构转型。股权众筹虽然有优势有活力，可以降低获取信息的成本，但也不可避免地存在着虚假信息，各利益相关者信用风险问题很大，所以股权众筹行业乱象丛生 [ 1 ] 。尤其是这两年互联网众筹平台跑路、倒闭、作假事件屡屡发生，互联网金融行业的信用风险不容乐观。如何对股权众筹信用风险进行分析，并采取量化的方法对其进行风险评级，进而提高小微企业抵御风险的能力，已成为学术界、工业界研究的重点 [ 2 ] 。 从过去的研究来看，对小微企业风险的研究大部分集中在定性分析上，即使涉及到定量方法，也多是层次分析法、模糊评价法等传统方法。这些方法不适合股权众筹平台这种影响因素繁多复杂的系统，而且评价结果的可靠性和精确性无法保证。随着互联网技术的不断创新发展，风险评价也向着标准化、系统化和精确化方向推进，出现了新的将计算机模拟与风险评价相结合的方法。支持向量机法(SVM)作为一种备受推崇的数据挖掘技术，已经在文本识别、人脸识别、银行信用风险评估等诸多实践领域得到广泛应用 [ 3 ] 。本文将SVM方法引入我国小微企业风险评级中，以提高风险评价精度和效率。"
"小微企业所面临的风险因素多而复杂，本文从科学、全面、量化和可操作等角度出发，建立一套科学合理的风险指标体系。根据小微企业的特点，将风险评价指标体系分为5个一级指标和18个二级指标，指标体系具体构建为行业市场环境、产品竞争力、企业基本情况、管理团队素质和财务数据表现五个一级指标，其相应的二级指标以及与一级指标的关系如图1。"
"支持向量机(SVM)核心思想是建立一个最优分类线或最优超平面作为决策曲面，将多类样本正确地进行分类。即先通过一定量的样本进行训练，通过不断检验与优化得到较高的训练精度，确定一个最优的决策函数再对分类问题进行处理。我们以二分类问题为例分析一下具体过程 [ 4 ] 。  图2中分别是两类样本，支持向量机方法就是寻找最优分类线将两类样本分开，分类线表示为 图1. 我国小微企业风险评级指标体系 图2. 寻找两类样本的最优分类线 ( w ⋅ x ) + b = 0 ，最优分类线代表着最大分类间隔，可用如下最优化问题表示： min w , b   1 2 ‖ w ‖ 2 (1) s .t .       y i ( ( ( w ⋅ x i ) + b ) + 1 ) ≥ 1 ,   i = 1 , ⋯ , l (2) 其中的约束要求各数据点 ( x i , y i ) 到分类面的距离大于等于1。其中， y i 为数据的分类。 引入Lagrange函数可将上述问题转化为对偶问题： min α   1 2 ∑ i = 1 l ∑ j = 1 l y i y α j i α j ( x i ⋅ x j ) − ∑ j = 1 l α j (3) s .t .       ∑ i = 1 l y i α i = 0 (4) α i ≥ 0 (5) 求解上述问题得到最优解： w * = ∑ i = 1 l y i a i * x i ,     b * = y j − ∑ i = 1 l y i α i ( x i ⋅ x j ) (6) 将参数代入原式，即可得到最优分类平面。  对于线性不可分问题，原来对间隔的要求不能达到。引入松弛变量 ξ i ，使约束条件弱化为： y i ( ( ( w ⋅ x i ) + b ) + 1 ) ≥ 1 − ξ i 。但是，我们仍然希望该松弛变量 ξ i 最小化。于是，在优化目标函数中使用惩罚参数 C 来引入对 ξ i 最小化的目标。此时模型为： min w , b   1 2 ‖ w ‖ 2 + C ∑ i = 1 l ξ i (7) s .t .       y i ( ( ( w ⋅ x i ) + b ) + 1 ) ≥ 1 − ξ i ,   i = 1 , ⋯ , l (8) 以此为原问题，其对偶问题为： min α   1 2 ∑ i = 1 l ∑ j = 1 l y i y α j i α j ( x i ⋅ x j ) − ∑ j = 1 l α j (9) s .t .       ∑ i = 1 l y i α i = 0 (10) 0 ≤ α i ≤ C (11) 求解得到最优解为： w * = ∑ i = 1 l y i a i * x i ,     b * = y j − ∑ i = 1 l y i α i ( x i ⋅ x j ) (12)  对于非线性问题，可以将低维空间中的曲线(曲面)映射为高维空间中的直线或平面。数据经这种映射后，在高维空间中是线性可分的。设映射为 x ′ = ϕ ( x ) ，则高维空间中的线性支持向量机模型为： min α   1 2 ∑ i = 1 l ∑ j = 1 l y i y α j i α j ( ϕ ( x i ) ⋅ ϕ ( x j ) ) − ∑ j = 1 l α j (13) s .t .       ∑ i = 1 l y i α i = 0 (14) 0 ≤ α i ≤ C (15) 由于数据被映射到高维空间， ϕ ( x i ) ⋅ ϕ ( x j ) 的计算量比 x i ⋅ x j 大得多。此时引入了 “核函数”： K ( x i , x j ) = ϕ ( x i ) ⋅ ϕ ( x j ) (16) 由上式可见，核函数的作用是，在将 x 映射到高维空间的同时，也计算了两个数据的在高维空间的内积，使计算量回归到 x i ⋅ x j 的量级。"
"根据图1风险评价指标体系搜集相关的样本数据，本文选取130家小微企业作为研究对象，并搜集他们2017年的原始数据资料，部分企业数据见表1。 观察数据集中每一个评级的数量分布，结果见表2。 可见，各个评级的样本分布相对均衡。 Table 1 X1 X2 X3 X4 X5 X6 X7 X8 X9 coolook 0.35 241 8 2200 100 1 36 13.38 6 e代泊 0.75 805 10 320 90 2 46 292.83 10 看孩子 0.46 487 6 30 20 1 22 125.08 13 骑乐无穷 0.47 379 19 3800 580 2 51 114 2 潮牌pr 0.47 85 7 140 50 8 23 100 4 悟空音乐 0.57 185 27 300 60 3 32 200 5 脉圈 0.34 461 9 450 88 1 27 119 3 慧金天下 0.56 484 2 450 90 2 30 5649.72 7 羽乐圈 0.57 553 27 8000 66 4 37 123.21 8 聘宝 0.35 513 4 2000 400 7 44 488.81 6 X10 X11 X12 X13 X14 X15 X16 X17 X18 评级 coolook 3 6 12 0 0 0 830 0.020 4 1 e代泊 6 8 17 4 7800 258 1340 0.069 4 1 看孩子 1 8 12 1 300 626 350 0.090 4 0 骑乐无穷 4 6 10 0 0 0 500 0.100 3 2 潮牌pr 2 8 8 0 0 0 300 0.070 2 2 悟空音乐 3 6 6 2 1243 604 350 0.100 2.5 2 脉圈 5 8 13 1 500 686 200 0.035 3 1 慧金天下 3 9 10 1 500 755 400 0.074 3.5 1 羽乐圈 4 6 6 0 0 0 300 0.130 2 1 聘宝 1 9 12 1 500 504 600 0.170 3 1 表1. 前10家企业原始数据 我们进一步观察每一个指标的取值分布，见表3。 观察发现数据取值范围差异很大，因为SVM要用到距离，所以必须做标准化处理，这里采用Min-Max标准化方法处理，结果见表4。 可以看到所有数据都在0~1之间，可以进行后续的距离计算。  把前91家公司数据作为训练集，后39家公司数据作为测试集，用SVM来进行模型构建。SVM有两个主要的参数可以设置：核函数参数kernel和约束惩罚参数C。其中约束惩罚函数C为对超过约束条件的样本的惩罚项。C值越大，惩罚越大，支持向量机的决策边界越窄。我们选用最简单的线性核函数，C采用200，训练得到最初的模型。  首先，要得到我们训练的模型在测试集上的预测结果，然后对模型的性能进行评估。模型准确率、 Table 2 0 58 1 46 2 26 表2. 各评级分布 Table 3 mean std min 25% 50% 75% max X1 0.524461538 0.114513203 0.34 0.46 0.56 0.58 0.75 X2 458.6769231 161.6385198 85 379 484 548 805 X3 12.09230769 16.05776692 0 3 8 15 113 X4 1907.830769 7455.064861 11 267 450 1000 60,000 X5 548.2153846 2505.925452 11 80 110 200 20,000 X6 2.461538462 1.905332566 1 1 2 4 8 X7 30.47692308 16.60494714 3 21 28 37 102 X8 654.3972308 1213.803404 1 114 200 583.33 5649.72 X9 5.015384615 3.026970792 1 3 4 7 13 X10 2.123076923 1.335359224 0 1 2 3 6 X11 7.169230769 1.359083489 5 6 7 8 10 X12 9.661538462 3.37007774 3 7 10 12 22 X13 1.292307692 1.123713072 0 0 1 2 4 X14 3602.753846 7914.165782 0 0 500 3300 37,800 X15 318.7230769 280.2317152 0 0 270 525 1087 X16 1134.692308 1788.638536 100 300 600 1500 13,000 X17 0.330229231 1.873030315 0.0033 0.0667 0.1 0.12 15.25 X18 3.769230769 2.105873887 1 2 3 4.5 10 表3. 各项指标统计数据 Table 4s after standardizatio mean std min 25% 50% 75% max X1 0.449906191 0.279300496 0 0.292682927 0.536585366 0.585365854 1 X2 0.518995726 0.224497944 0 0.408333333 0.554166667 0.643055556 1 X3 0.107011572 0.142104132 0 0.026548673 0.07079646 0.132743363 1 X4 0.031619643 0.124273865 0 0.004267449 0.007318008 0.016486356 1 X5 0.026875551 0.125365223 0 0.003451899 0.004952724 0.0094552 1 X6 0.208791209 0.272190367 0 0 0.142857143 0.428571429 1 X7 0.277544678 0.167726739 0 0.181818182 0.252525253 0.343434343 1 X8 0.115671733 0.214881142 0 0.020004532 0.03522922 0.103090612 1 X9 0.334615385 0.252247566 0 0.166666667 0.25 0.5 1 X10 0.353846154 0.222559871 0 0.166666667 0.333333333 0.5 1 X11 0.433846154 0.271816698 0 0.2 0.4 0.6 1 X12 0.350607287 0.177372513 0 0.210526316 0.368421053 0.473684211 1 X13 0.323076923 0.280928268 0 0 0.25 0.5 1 X14 0.095310948 0.209369465 0 0 0.013227513 0.087301587 1 X15 0.293213502 0.257802866 0 0 0.248390064 0.482980681 1 X16 0.080208706 0.13865415 0 0.015503876 0.03875969 0.108527132 1 X17 0.021442622 0.122848244 0 0.004158277 0.006342356 0.007654115 1 X18 0.307692308 0.233985987 0 0.111111111 0.222222222 0.388888889 1 表4. 标准化后各项指标统计数据 召回率和f1-score见表5。 具体的评级预测结果见表6。 该混淆矩阵中对角线的元素表示模型正确预测数，对角元素之和表示模型整体预测正确的样本数。而非对角线元素上的值则可以反映模型在哪些类的预测上容易犯错，例如评级2均有三次被预测为0和1。 最终分类正确率：0.866666666667。  各项指标可以进一步提高，我们进行参数调优，可以改善模型性能，进一步提升模型效果。 首先是核函数，通过循环依次取不同的核函数，准确率见表7。 可以看到，最好的是“rbf”这个核函数，可将正确率提升至：0.883333333333。 核函数确定后，我们再来看C的取值。第一次给定这样一个列表：c_list = [0.01,0.1,1,10,100,500]，循环依次取值，准确率见表8。 可以看到，在C = 500左右模型效果提升很大，可以进一步探究C = 500左右的正确率变化情况。所以给定这样一个列表c_list2 = [100,200,300,400,500,600]，循环依次取值，准确率见表9。 可以发现C = 500时模型效果确实不错，可将正确率提升至：0.933333333333，评价指标及混淆矩阵见表10和表11。 为了进一步提升模型的效果，我们重点关注惩罚因子C是否会有更优的取值。因为求SVM最优参 Table 5 precision recall f1-score support 0 0.85 0.96 0.9 24 1 0.88 0.96 0.92 23 2 0.88 0.54 0.67 13 avg/total 0.87 0.87 0.86 60 表5. 模型评价指标 Table 6 0 1 2 0 23 0 1 1 1 22 0 2 3 3 7 表6. 模型评级结果 Table 7 kernel Accuracy linear 0.866667 rbf 0.883333 poly 0.633333 sigmoid 0.4 表7. 各核函数对应准确率 Table 8 C Accuracy 0.01 0.4 0.1 0.4 1 0.433333 10 0.65 100 0.816667 500 0.933333 表8. 各C值对应准确率 Table 9 C Accuracy 100 0.816667 200 0.883333 300 0.9 400 0.916667 500 0.933333 600 0.933333 表9. 各C值对应准确率 Table 1 0 precision recall f1-score support 0 0.92 0.96 0.94 24 1 0.96 0.96 0.96 23 2 0.92 0.85 0.88 13 avg/total 0.93 0.93 0.93 60 表10. 模型评价指标 Table 1 1 0 1 2 0 23 0 1 1 1 22 0 2 1 1 11 表11. 模型评级结果 数本质上是一个二次凸规划问题，即求解函数最优值，而遗传算法最主要的用处就是函数最优化。因为遗传算法是一种高效的随机搜索算法，而且克服了诸如网格搜索法等容易陷入局部最优的缺点，可以通过多次尝试，找到全局最优解。同时遗传算法也会同时考虑kernel参数，避免模型出现过拟合现象 [ 5 ] 。我们基于遗传算法的SVM算法如下： 步骤1：初始化种群，随机生成初始种群个体； 步骤2：将种群中各个体基因串解码为相应核函数编号、核函数参数和错误惩罚因子，并将参数代入SVM，以训练数据和测试数据对其进行训练和测试； 步骤3：按照适应度计算法则，计算每个个体的适应度值； 步骤4：判断是否满足终止条件，如果满足终止条件，退出循环，遗传优化结束，得到优化参数组合，否则转到步骤5； 步骤5：执行选择算子，按照最优保存、最差取代的原则进行； 步骤6：执行交叉算子和变异算子，交叉概率取0.7，变异概率取0.1，形成新一代个体后，返回步骤2继续执行。 我们用这个模型来进行参数优化，最终选取核函数“rbf”以及惩罚因子C = 700，评价指标及混淆矩阵见表12和表13。 正确率可以达到：0.966666666667。  为了更好的说明模型效果，我们以逻辑回归模型作为对比，且选择调优后的参数，这里C = 1000，penalty = “l1”，solver = “liblinear”，评价指标及混淆矩阵见表14和表15。 正确率可以达到：0.85，效果不如SVM模型。"
"通过对我国小微企业风险评级的研究，我们发现： 1) 与逻辑回归方法相比，SVM方法在准确率等各项评价指标都明显更优，而且可以通过参数调优不断提升指标，从而更好的对企业风险进行评级。该方法对小微企业风险评价与预测这一复杂的领域有 Table 1 2 precision recall f1-score support 0 1 0.96 0.98 24 1 0.96 1 0.98 23 2 0.92 0.92 0.92 13 avg/total 0.97 0.97 0.97 60 表12. 模型评价指标 Table 1 3 0 1 2 0 23 0 1 1 0 23 0 2 0 1 12 表13. 模型评级结果 Table 1 4 precision recall f1-score support 0 0.92 1 0.96 24 1 0.78 0.91 0.84 23 2 0.86 0.46 0.6 13 avg/total 0.85 0.85 0.84 60 表14. 模型评价指标 Table 1 5 0 1 2 0 24 0 0 1 1 21 1 2 1 6 6 表15. 模型评级结果 很重要的指导作用。 2) 对SVM参数直接调优可以得到更好的效果，本文引入了遗传算法进行参数调优，可以得到最优化的结果。"
