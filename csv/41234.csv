"本文考虑一类目标函数由可微(可能非凸)函数和凸(可能非光滑)函数组成的极小化问题。惯性邻近(iPiano)算法是解决这类问题的一种有效而重要的方法。通过引入非单调线搜索，提出了非单调线搜索的iPiano (iPiano-nml)算法。通过证明说明了由iPiano-nml生成的序列的任何聚点都是一个稳定点。最后，对图像处理问题进行了数值实验来说明新算法的理论结果。"
"本文考虑下列最小化问题： min x ∈ R n F ( x ) = f ( x ) + g ( x ) , (1) 其中， f ( x ) : R N → R 是一个光滑(可能非凸)且为梯度李普希兹连续函数， g ( x ) : R N → R 是一个正常下半连续凸(可能非光滑)函数。另外 F ( x ) 是一个强制函数且有下界。 问题(1)出现在很多领域，如机器学习 [ 1 ]，信号处理 [ 2 ] 等。解决上述问题的经典方法是邻近梯度法 [ 3 ]： x k + 1 ∈ arg min x { 〈 ∇ f ( x k ) , x 〉 + α 2 ‖ x − x k ‖ 2 + g ( x ) } , 其中 α 是步长。然而，邻近梯度算法在解决一些问题时，它的收敛速度较慢，于是人们逐渐地寻找一些策略来改善这样的问题。常见的一个有效的策略是加速方法，因此在上述邻近梯度法中，通过引入外推项，一些文献提出了加速邻近梯度算法 [ 4 ]，FISTA [ 5 ] 算法等。加速邻近梯度算法如下： x k + 1 ∈ arg min x { 〈 ∇ f ( y k ) , x 〉 + α 2 ‖ x − y k ‖ 2 + g ( x ) } , y k = x k + β k ( x k − x k − 1 ) , 其中 α 是步长， β k 是外推参数。这些算法的收敛速度为 O ( 1 k 2 ) 。除此自外，惯性项也是一类能加速算法的有效策略，通过将邻近梯度法和惯性项结合得到下列惯性邻近算法(iPiano) [ 6 ] ]： x k + 1 = ( I + α ∂ g ) − 1 ( x k − α ∇ f ( x k ) + β ( x k − x k − 1 ) ) , (2) 其中， α 是步长， β 是惯性因子。iPiano在实际运行中收敛速度比邻近梯度法快，广泛地应用于非凸问题 [ 7 ] [ 8 ]。另一方面，线搜索也是一项能加速原始算法的有效策略，其非单调线搜索有更好的数值表现。非单调邻近梯度法(NPG) [ 9 ] 采用了下列线搜索： u ∈ arg min x { 〈 ∇ f ( x k ) , x − x k 〉 + L 2 ‖ x − x k ‖ 2 + g ( x ) } , F ( u ) ≤ max [ k − M ] + ≤ i ≤ k F ( x i ) − c 2 ‖ u − x k ‖ 2 , 其中c和M都大于0。该线搜索在每次迭代中通过选取k与 k − M 之间的最大值来满足条件，从而保证目标函数有更大的下降。 本文在惯性邻近算法的基础上，将其与NPG结合，提出一种带非单调线搜索的惯性邻近算法，并将其运用于图像处理，通过信噪比来说明新算法的有效性。"
"本节给出一些基本的定义。本文考虑欧式空间且维数 N ≥ 1 。 定义1：令 g ( x ) 为一个正常下半连续凸函数，那么邻近算子定义为： ( I + α ∂ g ) − 1 ( x ^ ) = arg min x ‖ x − x ^ ‖ 2 2 + α g ( x ) . 引理1： f ( x ) : R N → R 为一个光滑函数且为L梯度李普希兹连续。则对于 ∀ x , y ∈ R N ， ∃ L > 0 ，下式成立： ‖ ∇ f ( x ) − ∇ f ( y ) ‖ ≤ L ‖ x − y ‖ . 引理2： f ( x ) : R N → R 为一个光滑函数且为L梯度李普希兹连续。则对于 ∀ x , y ∈ R N ，我们成立以下下降引理 f ( x ) ≤ f ( y ) + 〈 ∇ f ( y ) , x − y 〉 + L 2 ‖ x − y ‖ 2 . 命题1：令 F , f , g 满足上述定义，则对于 x ∈ d o m F ，我们有下式成立： ∂ F ( x ) = ∇ f ( x ) + ∂ g ( x ) ."
"本节给出iPiano-nml算法和收敛性分析。首先我们引入一个辅助序列： H δ ( x , y ) = f ( x ) + g ( x ) + δ ‖ x − y ‖ 2 . 易知当时 x = y ，我们有 H δ ( x , y ) = f ( x ) + g ( x ) 。  iPiano-nml算法： 步骤0：选择 x 0 ∈ d o m F , x 0 = x − 1 。 c 1 , c 2 接近0。 L max ≥ L min > 0 , τ > 1 , c > 0 , M ≥ 0 。 步骤k：1) 选择 L k ∈ [ L min , L max ] , y k = x k + β k ( x k − x k − 1 ) 。 1a) 求解子问题： u ∈ arg min x { g ( x ) + 〈 ∇ f ( x k ) , x 〉 + 1 2 α k ‖ x − y k ‖ 2 } . 1b) 如果满足 H δ k + 1 ( u , x k ) ≤ max [ k − M ] + ≤ i ≤ k H δ i ( x i , x i − 1 ) − c 2 ‖ u − x k ‖ 2 , 那么进行步骤2)。 1c) 令 L k ← τ L k ，继续步骤1a)。 2) 令 x k + 1 ← u , k ← k + 1 然后进行步骤1)。 其中序列满足 α k ≥ c 1 , β k ≥ 0 , δ k ≥ γ k ≥ c 2 。 δ k 单调递减，另有： δ k = 1 α k − L k 2 − β k 2 α k , γ k = 1 α k − L k 2 − β k α k .  引理1：对于 k ≥ 0 ，存在 δ k ≥ γ k , β k ∈ [ 0 , 1 ) , α k < 2 ( 1 − β k ) L k 。另外给定 L k ≥ 0 ，存在 α k , β k 满足 δ k 单调递减。 证明：该引理证明参考文献 [ 6 ]。 引理2：序列 ( H δ k ( x k , x k − 1 ) ) k = 0 ∞ 单调递减且收敛，且我们有 H δ k + 1 ( x k + 1 , x k ) ≤ H δ k ( x k , x k − 1 ) − γ k ‖ x k − x k − 1 ‖ 2 . 证明：该引理证明参考文献 [ 6 ]。 定理1： 1)序列 { x k } 有界。 2) lim k → ∞ ‖ x k − x k − 1 ‖ = 0 。 3)任意序列的聚点都是稳定点。 证明： 1) 由引理2可知整个序列 { x k } 都包含于下列水平集合： { x ∈ R N : F _ ≤ F ( x ) ≤ H δ 0 ( x 0 , x − 1 ) } . 那么由 F _ = inf F ( x ) > ∞ ，我们可推知序列 { x k } 有界。 2) 显然，我们有： H δ k + 1 ( x k + 1 , x k ) − max [ k − M ] + ≤ i ≤ k H δ i ( x i , x i − 1 ) = f ( x k + 1 ) + g ( x k + 1 ) + δ k + 1 ‖ x k + 1 − x k ‖ 2 − max [ k − M ] + ≤ i ≤ k { f ( x i ) + g ( x i ) + δ i ‖ x i − x i − 1 ‖ 2 } ≤ f ( x k + 1 ) + g ( x k + 1 ) + δ k + 1 ‖ x k + 1 − x k ‖ 2 − f ( x k ) − g ( x k ) − δ k ‖ x k − x k − 1 ‖ 2 = H δ k + 1 ( x k + 1 , x k ) − H δ k ( x k , x k − 1 ) . 由引理2可知： H δ k + 1 ( x k + 1 , x k ) − max [ k − M ] + ≤ i ≤ k H δ i ( x i , x i − 1 ) ≤ − γ k ‖ x k − x k − 1 ‖ 2 . 将上式两边从 k = 0 加到N。则由引理2和M的定义我们有 0 < ∑ k = 0 N γ k ‖ x k − x k − 1 ‖ 2 ≤ ∑ k = 0 N max [ k − M ] + ≤ i ≤ k H δ i ( x i , x i − 1 ) − H δ k + 1 ( x k + 1 , x k )     = ( M − 1 ) H δ 0 ( x 0 , x − 1 ) − ⋯ − H δ N − M + 2 ( x N − M + 2 , x N − M + 1 )           − H δ N − M + 3 ( x N − M + 3 , x N − M + 2 ) − ⋯ − H δ N ( x N , x N − 1 ) − H δ N + 1 ( x N + 1 , x N ) < ∞ , 从而我们可以推断出 lim k → ∞ ‖ x k − x k − 1 ‖ = 0 。 3) 令 x * 为序列的聚点且存在 { x k j } 使得 lim j → ∞ x k j = x * 。那么由一阶最优条件，我们有 − 1 α k j ‖ x k j + 1 − y k j ‖ ∈ ∂ g ( x k j + 1 ) + ∇ f ( x k j ) . 由 y k j = x k j + β k j ( x k j − x k j − 1 ) ，我们可以得到 − 1 α k j ‖ x k j + 1 − x k j − β k j ( x k j − x k j − 1 ) ‖ ∈ ∂ g ( x k j + 1 ) + ∇ f ( x k j ) . 由函数 g ( x ) 的凸性， ∇ f ( x ) 连续性以及 ‖ x k − x k − 1 ‖ = 0 ，我们有 0 ∈ ∇ f ( x * ) + ∂ g ( x * ) , 这就说明了 x * 是算法的稳定点。"
"本节将算法用于数值实验，运行环境为MATLAB R2014a 2.80 GHz CPUs。我们先简单介绍一下问题模型。 问题模型为马尔科夫随机场： min u ∈ R N ∑ i = 1 N f ζ i ϕ ( K i u ) + g ( u , u 0 ) , 其中u是所求图像信息， u 0 是噪声图像信息， ϕ 是非凸罚函数，表达式为： ϕ ( K i u ) = ∑ p φ ( ( K i u ) p ) , 其中 K i 是学习率，是基于 ζ i 权重的线性算子， N f 是滤子数，本文考虑7 * 7的滤波器 [ 6 ]，且 K i u = k i ∗ u 。 对于 φ ( t ) ，我们考虑学生t分布： φ ( t ) = log ( 1 + t 2 ) . 我们考虑高斯噪声，其中函数模型为 g ( u , u 0 ) = λ 2 ‖ u − u 0 ‖ 2 。 对于终止条件我们选择下述能量差： ε k = F k − F * , 其中， F * 是真实值(数值由 [ 6 ] 给出)， F k 是每次迭代的值，两者做差即为能量差 ε k 。 为了增强对比效果，我们用iPiano-nml和iPiano-Backtracking作比较。iPiano-Backtracking为带回溯线搜索的iPiano算法： f ( x k + 1 ) ≤ f ( x k ) + 〈 ∇ f ( x k ) , x k + 1 − x k 〉 + L k 2 ‖ x k + 1 − x k ‖ 2 ( k ∈ N ) . 当满足回溯线搜索时，令 L k + 1 = L k / 1.05 否则令 L k + 1 = L k ∗ 1.2 。 在iPiano-nml中，令 L k 为BB步长 [ 10 ]： L k = { min ( max ( ‖ s k − 1 ‖ 2 s k − 1 T l k − 1 , L min ) , L max ) ( s k − 1 T l k − 1 ≠ 0 ) L max , otherwise . 另外参数选取为： L 1 = 3 , α k = 2 ∗ ( 1 − β ) L k ∗ 0.99 , β = 0.8 , λ = 1 , c = 4.8 , τ = 1.6 , M = 2. 在iPiano-Backtracking中，令参数选取为： L 1 = 3 , α k = 2 ∗ ( 1 − β ) L k ∗ 0.99 , β = 0.8 , λ = 1. 接下来我们给出峰值信噪比与迭代变化关系图： 图1. 两个算法效果对比图 由图1中可知在过程中iPiano-nml比iPiano-Backtracking效果表现好。 下面给出效果对比图： 图2出了效果对比。上方左图为原始图像，右图为噪声图像。下方左图为iPiano-nml去噪效果，右图为iPiano-Backtracking去噪效果。图2验证了iPiano-nml算法的有效性。 图2. 效果对比"
"本文在考虑一类非凸非光滑问题中借鉴了NPG的思想，将非单调线搜索整合到iPiano中，提出了带非单调技术的iPiano算法，并通过一定的条件证明了新算法的收敛性。本文将新算法运用于图像降噪实验，通过与原算法的对比说明新算法的有效性。以后我们的工作将研究新算法的收敛速度。"
