"针对现有异常检测方法难以解释异常属性的问题，本文提出基于双侧空间窗的异常检测方法。首先，在前景检测的基础上，本文对场景边界区域进行双侧空间窗采样，提取双侧空间窗特征；随后，为了提取异常事件的速度属性、相关性属性、时间差属性的提取，本文分析了双侧空间窗的时序互相关理论和实际特性，实现了异常细分属性的描述；最后为了进一步描述目标类别属性，本文使用了基于快速傅里叶变换的外观特征，利用最大间隔思想训练异常检测模型。在真实场景BEHAVE数据库的实验中，可以看出AP和AUC评价指标超出现有对比方法，而且还能在没有先验知识指导的情况下，自动识别出监控场景出入口的位置。 关键词 :异常检测，双侧空间窗，时序互相关，语境发现 Copyright © 2019 by authors and Hans Publishers Inc. This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/"
"场景中的异常事件通常伴随着危险和安全隐患，异常检测关注于监控场景中的异常事件识别，已经受到计算机视觉领域的广泛关注 [ 1 ] 。但是，由于场景中内容的不同，在缺少异常清晰定义的情况下，如何实现异常的准确识别，仍然是一项重要的挑战。 在事件统计方面，异常可以定义为场景中出现的小概率事件，在此基础上，现有方法关注于不同特征提取方法基础上的小概率模型构建。光流特征作为运动描述被广泛使用，Cong关注于基于光流的运动特征 [ 2 ] ，Hassner使用带阈值的光流特征ViF [ 3 ] ，Nievas使用SIFT检测点处的光流特征MoSIFT [ 4 ] ，Zhang在光流特征的基础上，添加Weber梯度和方向的局部描述子MoWLD [ 5 ] 。除了光流特征以外，现有方法还考虑时长特征和场景中群体的分布特征，例如，Li对时间段内的图像序列，进行混合动态纹理特征的小概率建模 [ 6 ] ，Hu关注于目标跟踪轨迹方面的异常分析 [ 7 ] ，Mehran关注于人群中不同个体的交互关系，构建一种社会力模型 [ 8 ] 。上述方法使用手工设计特征，该类特征是否符合场景中处在的客观规律，难以验证，也约束了模型的使用范围。 基于统计学习方法，可以将运动原始特征映射到隐空间，并实现有效的特征编码。稀疏编码是近年来广泛使用的方法，Wang使用结构稀疏保持的编码方式(SSS: structural semi-supervised) [ 9 ] ，Babagholami使用概率半监督字典的编码方式(PSS: Probabilistic semi-supervised) [ 10 ] ，Zhang进行局部约束的稀疏编码(LSC: Local sparse constraint) [ 1 ] 。随着编码效率的提升，现有异常检测方法也改进了分类模型的设计，Wright使用稀疏表达分类器(SR: Sparse representation) [ 11 ] ；而且深度学习也逐渐进入该领域，蔡瑞初使用多尺度时间递归神经网络方法 [ 12 ] ；Xu提出外感和运动的深度网络结构对异常检测的建模(AMDN: Appearance and Motion Deep Net) [ 13 ] 。但是，上述方法仍然将异常事件的属性作为黑盒处理，没有清晰的异常规则定义，实际上在真实的场景监控应用中，难以设置知识规则，也难以根据人类的经验对现有异常检测模型进行拓展。 现有异常检测模型均是基于时空窗的状态分析，但是，难以描述事件中的时间的细节属性。本文针对实际监控的出入口状态分析需求，将采样窗口进一步细分为内侧窗和外侧窗，利用时序相关分析方法，有效实现了速度属性、相关性属性、时间差属性的检测，从而实现对异常事件属性的细分。基于上述分析，本文提出一种基于时序互相关分析的异常检测方法，其主要贡献如下： 1) 通过提出的双侧空间窗特征，利用互相关分析方法，实现进入和离开的异常事件的自动判定。 2) 对场景中异常区域进行双侧空间窗采样，利用时序互相关分析，自动发现并定位监控场景中出入口的语境信息。 3) 根据监控任务的实际需求，将异常模式根据特性细分为：速度属性，出入属性和目标类属性，构建多属性分类器，实现不同人车不同类别目标的异常检测。"
"本文的算法处理流程，如图1所示。针对现有异常检测方法无法解释事件属性类型，本文将异常事件描述为速度属性，出入属性和目标类属性的联合判决形式。在前景检测的基础上，首先，进行双侧空间窗特征提取，随后，利用互相关分析方法实现目标的速度特征和相关性特征提取，最终，结合目标外观特征完成异常检测任务。 图1. 基于时序互相关分析的异常检测  本文提出的双侧空间窗特征建立在前景检测基础上。为了提高前景检测的可靠性，使用HSI颜色空间的帧差方法，HIS图像包含三个色彩通道： I t ( x , y ) = { I h , t ( x , y ) , I s , t ( x , y ) , I i , t ( x , y ) } (1) 其主要原因在于目标发生运动时，背景差方法容易受到外部光照的影响，HSI颜色空间，尤其是色调H分量对光照具有较好的不变性。因此，对于给定视频图像帧并转化为HSI图像，通过估计当前帧像素的HSI特征 I t ( x , y ) 和前一帧像素的HSI特征 I t - 1 ( x , y ) ，比较帧差大小获得前景图像 F t ( x , y ) ， F t ( x , y ) = { 1 ‖ I t ( x , y ) − I t − 1 ( x , y ) ‖ 2 > η ⋅ H 0 ‖ I t ( x , y ) t − I t − 1 ( x , y ) ‖ 2 ≤ η ⋅ H (2) ‖ I t ( x , y ) − I t − 1 ( x , y ) ‖ 2 为两帧像素的HSI向量的2范数， η ⋅ H 为帧差阈值，其取值方法为，首先估计视频帧中最大的帧差 H = max x , y , t ‖ I t ( x , y ) − I t − 1 ( x , y ) ‖ 2 ，并将帧差与最大值比例大于 η 的像素，认为是显著运动，本文方法中 η 取值0.3。 针对目标出入属性，本文提出双侧空间窗并通过分析其中前景像素的变化规律，实现目标的速度和出入状态的估计。在每个空间窗中，记录前景像素的和作为局部特征，有 M t ( D ) = ∑ ( x , y ) ∈ D F t ( x , y ) (3) 其中D为空间窗，本文针对场景边界使用双侧空间窗，即包含内侧窗 D in 和外侧窗 D out ，如图2(a)所示。内侧窗(图2(a)红色窗)和外侧窗(图2(a)蓝色窗)尺寸相同，位置相邻。内侧窗和外侧窗根据异常目标类别不同，设置为行人和交通工具两种尺寸。内侧窗和外侧窗在边界框的左右两侧水平相邻，在上下两侧垂直相邻。则此时有内侧窗特征 M in t = M t ( D in ) ，和外侧窗特征 M out t = M t ( D out ) ，并将双侧窗特征记作 M t = { M in t , M out t } 。 图2. 双侧空间窗及其目标进入场景的前景像素变化，(a) 双侧空间，(b) 场景目标的双侧空间窗前景变化，(c) 理想情况下双侧空间窗相关性 利用双侧空间窗特征估计速度的基本思想是，像素变化的快慢，包含内侧窗和外侧窗。为了避免环境噪声对瞬时速度的影响，采用时间窗 ( t , t + N t ) 对进行速度属性估计： v t = 1 2 ( N t + 1 ) ∑ j = t t + N t ( M in j − M in j − 1 ) + ( M out j − M out j − 1 ) (4) 其中 t 为初始帧， N t 为时间窗的宽度。图2(b)给出了以时间窗内，内侧窗和外侧窗特征的演化实例，可以看出在目标外侧窗比内侧窗波峰出现时间迟，说明目标先进入内侧窗，后进入外侧窗，目标的状态为离开。  双侧空间窗特征体现为先后出现的两个波峰，波峰之间的帧编号间隔可以视为时间差，记作 τ ，为了计算内侧窗和外侧窗的相关性，本文在时间窗下，考虑带时间差的互相关系数，作为互相关度量 r e t ( τ ) ： r e t ( τ ) = 1 N t + 1 ∑ j = t t + N t M in j | D in | M out j + τ | D out | (5) 其中， | D in | 为内侧空间窗的像素数量， | D out | 为外侧空间窗的像素数量，互相关度量是时间差 τ 的函数，当波峰相近，波形基本吻合时出现 r e t ( τ ) 最大值。我们将最佳吻合的相关性和时间差作为异常事件的相关系数 r t 和时间差属性 τ t ，此时，有 r t , τ t = max r , τ r e t ( τ ) (6) 本文对互相关函数进行理论分析，图2(c)给出了正弦波形下的弧相关系数估计。将图2(c)的绿色曲线和红色曲线作为输入，对于情况内侧窗(绿色曲线)和外侧窗(红色曲线)，可以获得不同时间差情况下的相关值，即获得粉色曲线，此时红色曲线延时时间间隔，可以获得最大相关性，即时间差为正值，判断为离开状态。反之，对于情况内侧窗(红色曲线)和外侧窗(绿色曲线)，绿色曲线需要提前移动获得最大值，获得蓝色相关性曲线，即时间差为负值，判断为进入状态。因此，相关性分析是一种获得出入属性的判断的有效方法。  监控场景中需要明确异常中的目标类型，本文使用快速傅里叶变换特征实现目标的外观特征提取，其主要原因是，快速傅里叶变换不仅实现快速，而且具有较好的循环特性 [ 14 ] ，空间窗滑动情况下，能够保证快速傅里叶变换特征具有较好平移不变性，有利训练样本的采集，获得更精确的模型。因此，使用快速傅里叶变换 f f t ，分别对采样窗口 C 中，HSI色彩空间的各层图像，提取快速傅里叶变换特征 f x t = { f f t ( I h , t ( C ) ) , f f t ( I s , t ( C ) ) , f f t ( I i , t ( C ) ) } 。不失一般性，对视频中的异常样本进行采样，联合双侧空间窗，构建异常属性集合记作 z t = ( f x t , v t , r t , τ t ) 。基于最大间隔分类思想，设计本文异常检测的目标函数为： Ω ( w ) = 1 2 ‖ w ‖ 2 + 〈 w T ⋅ z 〉 (7) 其中， w 为异常检测模型参数，其中字母T表示模型参数向量的转置。本文对BEHAVE视频数据库中的异常目标提取属性特征，并随机分配训练集样本和测试集样本，采用10折交叉验证对模型进行训练，通过最小化目标函数获得最佳异常检测模型参数 w * = arg min w Ω ( w ) 。获得异常检测模型参数后，异常事件检测的测试过程为，首先根据1.1节，1.2节，1.3节描述，提取异常属性 z t e s t = ( f x t e s t , v t e s t , r t e s t , τ t e s t ) ， 可疑获得异常检测得分，随后，根据异常模型估计异常得分 s t e s t = 〈 ( w * ) T ⋅ z t e s t 〉 。通过设置阈值，可以计 算异常检测的准确率，和查全率，在此基础上，现有异常检测方法中通常考虑不同阈值下的检测效率和演化趋势，因此，本文使用平均准确率(AP: Average Precision)和曲线下方面积(AUC: Area Under Curve)作为评价标准来衡量。"
"本文的研究对象是监控场景中的异常检测，采用BEHAVE场景数据库，其主要原因是，1) BEHAVE是真实监控视频(包含11,200帧)，视频分辨率为480 × 640，可以验证低分辨率事件检测能力，2) 数据库存在外观挑战，选取视频中行人着装与道路、土壤的外观颜色都很相近，并存在场景的光照变化、视频镜头附近的人影噪声等影响。3) 该数据库拍摄的高度较高范围较广，场景视场较宽，事件内容丰富，视频包含真实监控视频遇到的多种情况，例如多人进入、跑步离开等。  本文方法通过互相关性质的分析，可以有效发现目标的事件状态，这突破了现有异常检测方法对属性检测的限制。而且在目标事件状态基础上，即使在没有场景已知信息的情况下，本文提出的双侧空间窗可以对场景边界的出入口进行定位，这可以实现自动识别监控场景的感兴趣区域，有利于后续监控算法的自动化实现。 为了有效实现出入口自动定位，根据出现目标的基本尺寸设置双侧空间窗的大小，具体为行人内侧窗和外侧窗像素尺寸各为80 × 30，交通工具内侧窗和外侧窗像素尺寸各160 × 60。根据监控场景边界进行全遍历，计算出场景过程中出入状态目标的数量，对于目标数量大于3的位置，判定为场景中可行的出入口位置。图3给出了BEHAVE数据库场景中的出入口检测结果，根据场景的特点，BEHAVE场景包含编号为1，2的两个交通工具出入口，编号为3，4，5，6，7共5个行人出入口，BEHAVE场景出入口检测与实际场景的出入口数量和位置一致，全部检测成功。表1给出了对应监控过程中真实出现的目标及相关性分析，说明本文方法可靠有效。 图3. 基于双侧空间窗的监控场景出入口位置检测 Table 1 出入口 起始帧 速度属性 相关系数 时间差 进出状态 6 1956 79.9 0.876 −4 进入 1 3730 138.3 0.818 4 离开 3 3740 152.4 0.909 1 离开 7 4053 84.3 0.984 22 离开 5 4233 78.3 0.953 −9 进入 2 9237 110.7 0.81 2 离开 4 10,910 46.8 0.903 3 离开 表1. 监控场景出入口检测和相关性分析  本文对异常检测进行了属性细分，包含速度属性、相关性属性、时间差属性、外观属性，从判断能力上比现有模型更全面，结合本文使用的最大边界分类器的训练过程，可以实现模型的有效训练。本文使用平均准确率(AP: average precision)和曲线下方面积(AUC: Area Under Curve)进行异常检测评价 [ 1 ] 。具体来说，本文以0.1为间隔，对0到1的阈值采样11个阈值，分别对每个阈值计算准确率(检测正确的数量/检测出所有的数量)和查全率(检测出所有的数量/真实存在所有异常的数量)。平均准确率(AP)是11个阈值下准确率的平均值，平均准曲率越大说明模型准确性越高。曲线下方面积(AUC)需要使用另一个概念，即第一类错误假阳性率(False Positive)即虚警率，虚警数量是指异常得分大于阈值但并非为异常的事件数量，曲线下方面积越大则模型的准确性越高 [ 1 ] 。 本文选择的对比方法包括3类，1) 不同外观特征方法，ViF [ 3 ] 使用带阈值的光流特征，MoSIFT + BoW [ 4 ] 使用SIFT检测点处的光流特征，MoWLD + SC [ 5 ] 在光流特征的基础上，添加Weber梯度和方向的局部描述子，并考虑稀疏编码进行特征变换。2) 不同特征编码方法，MoSIFT + BoW [ 4 ] 使用词汇包的编码方式，MoWLD + SC [ 5 ] 使用稀疏编码方式，MoWLD + LS [ 1 ] 对运动weber局部描述子，进行局部约束的稀疏编码。此外，SSS [ 9 ] 使用结构稀疏保持的编码方式，PSS [ 10 ] 使用概率半监督字典的编码方式，不同的特征编码方式将原始特征映射到隐空间，提高检测器的判决能力。3) 不同分类判决方法，SRC [ 11 ] 使用稀疏表达分类器；AMDN [ 13 ] 使用深度结构训练外观和运动特征。通过与选择的方法对比，能够说明本文方法的有效性和优势。表2给出了本文方法和对比方法的实验结果，由于本文方法在外观特征和运动特征基础上，引入了描述时间的速度属性、相关性属性、时间差属性，是一种显式的属性表达，比现有其他特征提取和编码方法更直观有效，因此，本文在BEHAVE真实监控场景中，实现了比现有方法更高的平均准确率。图4真实监控场景BEHAVE数据库给出了异常检测结果，由于目标尺寸的不同，检测结果进一步可以分为交通工具(图4第一行)和行人(图4第二行)。检测结果能够说明，成功识别出各目标进入和离开的位置和时刻。 本文实验工作站配置参数为Intel(R) Core(TM) i7-4770，内存8 GB，CPU为8核3.4 GHz，使用matlab实现。实验时，前景检测耗时0.03秒，相关性分析耗时0.06秒，外观特征提取耗时约0.71秒，从本文方法可以看出外观特征是较为耗时的，而且对异常检测来说，运动特征更为直观有效，因此，本文没有选择HOG，SIFT等耗时较多的特征提取方法，其目的是为了提高异常检测应用的实时性。本文方法的实时性为1.25 FPS (帧每秒)，如果仅使用运动特征和相关性分析，本文的实时性为11.1 FPS (帧每秒)。由于matlab是解释性语言，执行过程中缺少编译耗时较多，通过更换实验语言平台可以进一步提高本文方法的实时性。 Table 2 对比方法 AP AUC MoSIFT + BoW 62.78 0.6679 SRC 82.7 0.8538 AMDN 84.22 0.8562 ViF 83.62 0.8632 PSS 85.15 0.8727 MoWLD + SC 85.27 0.8758 LSC 88.26 0.9028 SSS 89.07 0.9096 Our 94.33 0.9667 表2. 真实监控场景BEHAVE数据库异常检测的评价结果 图4. 真实监控场景BEHAVE数据库异常检测结果，第一行：交通工具(汽车，自行车)；第二行：行人"
"本文面对实际监控需求，针对现有异常检测方法对事件属性无法准确描述的问题，提出一种基于双侧空间窗的异常检测方法。本文在双侧空间窗特征的基础上，利用互相关分析方法，可以有效获得目标的速度属性、相关属性和时间差属性，上述属性能够满足时间监控的任务需求。本文方法进一步结合外观特征，分析事件中的目标类型，从而有效辨别出交通工具和行为不同种类目标的异常事件。本文方法与现有的不同特征提取、特征编码、分类模型进行比较，实验结果说明本文方法不仅能够快速准确的实现异常检测，在真实场景BEHAVE数据库中，AP和AUC指标超出现有方法，而且还能在没有先验知识指导的情况下，自动识别出监控场景出入口的位置。"
