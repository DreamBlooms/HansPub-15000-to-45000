"由于结构简单、收敛速度快等优点，回声状态网络(Echo State Network, ESN)已被广泛的用于时间序列的预测。针对回声状态网络中随机生成权值矩阵带来的不适用于特定时间序列的问题，本文提出利用改进的粒子群优化算法来优化回声状态网络部分随机权值。与标准粒子群优化算法相比，惯性权重和学习因子自适应调整，以提高算法的寻优性能。为验证本文方法的有效性，对Mackey-Glass时间序列、非线性自回归滑动模型(Nonlinear Auto Regressive Moving Average, NARMA)和Lorenz时间序列进行仿真实验。实验结果表明，本文提出的方法可以进一步提升回声状态网络对时间序列的预测精度。"
"时间序列预测就是通过分析时间序列，根据历史数据的发展过程、方向和趋势对未来进行预测。时间序列预测在人类生活的各个领域都有着广泛的应用，如生物学领域的基因表达谱 [ 1 ]、金融领域的股票价格 [ 2 ]、社会领域的城市交通流量 [ 3 ]、工业领域风能评估 [ 4 ] 和气候领域的温度变化预测 [ 5 ] 等。然而，实际中的时间序列往往表现出复杂的特性，如非平稳、随机性、高维性、非线性和非周期性等，时间序列的预测研究仍然面临着巨大的挑战。 对于时间序列数据的预测方法，主要有线性方法和非线性方法。其中，线性方法主要有：自回归 [ 6 ]、自回归滑动平均 [ 7 ]、自回归综合滑动平均 [ 8 ] 等，这些线性方法适合持续时间较长、变化较为缓慢的时间序列的预测。非线性方法主要有：支持向量机 [ 9 ]、最小二乘支持向量机 [ 10 ]、人工神经网络 [ 11 ] 等。随着网络规模和复杂程度的不断提高，非线性方法可以很好地处理时间序列的非平稳、随机性、高维性、非线性和非周期性等问题。虽然非线性方法能够很好的处理复杂时间序列，但是也存在一些局限性，例如支持向量机和最小二乘支持向量机当训练样本过大时，会存在运行时间过长且效果不佳的问题。前向神经网络存在训练算法复杂，网络结构难以确定，网络计算量较大的问题 [ 9 ]。回声状态网络预测方法(ESN) [ 12 ] 作为一种基于储备池计算的神经网络，只需采用一个大规模的稀疏连接的储备池即可保证模型对非线性数据的处理能力。因其训练过程简单，计算量小，ESN已被广泛用于时间序列的应用中 [ 12 ] [ 13 ] [ 14 ] [ 15 ] [ 16 ]。然而，ESN输入连接权值、储备池内部连接权值和反馈连接权值的随机性赋值，使得模型性能不确定、收敛速度慢，无法满足时间序列准确有效的预测需求 [ 17 ] [ 18 ] [ 19 ]。 粒子群优化算法(PSO)作为一种元启发式算法，由于简单容易实现、搜索能力强，已被广泛应用于神经网络结构的优化 [ 20 ]，电力 [ 21 ]，工业 [ 22 ] 等领域。文献 [ 15 ] 中，作者利用标准粒子群算法对回声状态网络中部分随机权值进行优化，提升了网络的预测性能。然而，标准PSO存在易陷入局部极小值和全局搜索能力不足等问题。为了克服标准PSO算法的这些缺点，本文采用改进的粒子群算法(IPSO)对回声状态网络输入连接权值、储备池连接权值和反馈连接权值进行优化。试验结果表明该方法有效地减少了随机生成权值矩阵带来的不适用于特定任务的局限性，进一步提高ESN的预测性能。"
"ESN基本原理 回声状态网络(ESN)由Jaeger和Haas教授于2001提出，它是由输入层、储备池和输出层组成的简单三层递归神经网络(如图1所示)。 u ( t ) ， x ( t ) ， y ( t ) 分别表示t时刻的输入单元、储备池内部的神经元状态以及输出单元。 W i n , W , W o u t 和 W b a c k 分别代表网络的输入层到储备池、储备池内部的神经元、输入层到输出层、储备池到输出层和输出层到储备池之间的连接权值矩阵。当 W b a c k 存在时，ESN可以进行多步预测；否则，它只能进行单步预测。在ESN中，通过随机初始化产生输入层到储备池、储备池的内部及输出层到储备池的连接权值，且在训练过程中保持不变。因此，ESN只需要训练储备池到输出层的连接权值。大规模的储备池来代替全连接的隐藏层，增强了复杂时间序列的建模能力。只需要训练储备池到输出层的连接权值可避免传统神经网络基于梯度下降原理的收敛速度缓慢，且在寻找最优解的时候可能会陷入局部最优的问题。 图1. 回声状态网络的标准结构 在ESN中，当信号 u ( t + 1 ) 输入到网络时，储备池内部神经元状态和网络输出的更新规则如下： x ( t + 1 ) = f ( W i n u ( t + 1 ) + W x ( t ) + W b a c k y ( t ) ) , y ( t + 1 ) = f out ( W o u t x ( t + 1 ) ) , (1) 其中f和 f out 分别表示储备池和输出单元的激活函数，f一般为双曲正切函数 tanh ， f out 一般为恒等函数。 当 f out 为恒等函数时，模型输出 y ( t ) 可表简单地表示为： y ( t ) = W o u t x ( t ) . (2) 在模型训练过程中，希望得到的 W o u t 能够使模型的输出 y ( t ) 与目标值 y ^ ( t ) 间的误差最小，即需要求解如下的优化问题： W o u t = arg min W o u t ∑ t = 1 k ‖ y ^ ( t ) − W o u t x ( t ) ‖ 2 2 . (3) 其中k为训练的样本数。"
"在回声状态网络的学习过程中，仅调节储备池到输出层之间的连接权值，而其他连接权值被随机赋值后保持不变。如果这些被随机赋值的连接权值设置不合适，那么也会直接影响ESN的预测性能。因此，文献 [ 15 ] 利用标准粒子群算法(PSO)对回声状态网络中部分随机权值进行优化，进而提高ESN的预测性能。虽然标准粒子群算法寻优速度较快、效率高、算法简单，但也存在自身的缺陷。因此，本文将尝试引入自适应调整的惯性权重和动态学习因子对标准的粒子群算法进行改进，进而应用改进的粒子群算法(IPSO)对ESN的部分随机连接权值进行优化，进一步提升ESN的预测精度。  粒子群优化算法是美国心理学家Kennedy和电气工程师Eberhart受鸟类觅食行为的启发，于1995年提出了粒子群优化算法。PSO是一种基于群体智能的全局随机寻优算法，它模仿鸟类的觅食行为，将问题的搜索空间类比于鸟类的飞行空间，将每只鸟抽象成为一个粒子，用以表征问题的一个候选解，所需要寻找的最优解等同于要寻找的食物。算法为每个粒子给定位置和速度，每个粒子通过更新速度来更新其自身的位置。通过迭代搜索，种群可以不断地找到更好的粒子位置，从而得到优化问题的较优解。 粒子群优化算法的原理：在维度为D的解空间中有n个飞行粒子，每个飞行粒子的状态可用位置向 量和飞行速度向量进行描述。假设向量 X i = ( x i 1 , x i 2 , ⋯ , x i d ) 为飞行粒子i当前的位置，向量 V i = ( v i 1 , v i 2 , ⋯ , v i d ) 为飞行粒子i当前的飞行速度，其中 1 ≤ i ≤ n ， 1 ≤ d ≤ D 。定义适应度函数，计算每一个飞行粒子的适应度值，根据适应度值大小选取飞行粒子个体当前的最优位置 P i = ( p i 1 , p i 2 , ⋯ , p i d ) 。同时进行信息共享，筛选出整个种群当前的最优位置 P g = ( p g 1 , p g 2 , ⋯ , p g d ) 。当算法开始运行时，对飞行 粒子的位置和飞行速度进行初始设置，利用以下公式对飞行粒子状态进行更新： V i d ( t + 1 ) = w V i d ( t ) + c 1 r 1 ( P i d ( t ) − X i d ( t ) ) + c 2 r 2 ( P g d ( t ) − X i d ( t ) ) , X i d ( t + 1 ) = X i d ( t ) + V i d ( t + 1 ) , (4) 其中常数w为惯性权重，其大小对算法的全局搜索能力和局部搜索能力有较大的影响；常数 c 1 和 c 2 分别为认知因子和社会因子，分别表示粒子对自身和整个群体的认知； r 1 和 r 2 为 [ 0 , 1 ] 之间的随机数。  在标准的PSO中，惯性权重w的取值对粒子的速度大小有着很大的影响。w取值较大时，虽然粒子全局搜索能力强，但是收敛能力变差。w取值较小时，容易导致局部搜索能力变小，最终陷入局部最优。因此，本文将采取(5)式的非线性变化权重进一步提升PSO的搜索性能。 w = w min + ( w max − w min ) × e 1 − t max t max − t + 1 . (5) 其中 w max 和 w min 为最大和最小的惯性权重， t max 为最大迭代次数，t为当前迭代次数。当t较小时，w接近 w max 且w的减少速度也比较慢，这保证了算法的全局寻优能力；随着t的增大，w非线性递减，并且随w的减少速度迅速增加，保证了算法的局部寻优能力。从而使算法灵活的调整全局寻优能力和局部寻优能力。 3.3. 学习因子c 1 和c 2 的改进 在标准的PSO中，学习因子 c 1 和 c 2 设置为固定的常数。因此，在整个迭代的过程中粒子受到个体信息和群体信息的影响是不变的。因此，在后期搜索阶段粒子的位置缺乏多样性，容易陷入局部最优和收敛速度慢等问题。因此引入了动态学习因子的方法 [ 21 ]，改进的 c 1 和 c 2 如下： c 1 ( t ) = 1 − ln 2 ⋅ ( t t max ) , c 2 ( t ) = 1 + ln 2 ⋅ ( t t max ) . (6) 其中 t max 为最大迭代次数， W i n 为当前迭代次数。学习因子 W 随迭代递减，而学习因子 W b a c k 随迭代递增。因此，在迭代的前期，粒子主要受到个体信息的影响，这有助于增加种群的多样性；在迭代的后期，粒子主要受群体信息影响，这有助于粒子向全局最优解靠近，获得最优解。  基于IPSO优化的ESN模型(ESN-IPSO)的训练过程分为以下几个步骤： Step 1. 数据预处理。为消除量纲，提升模型的收敛速度和预测精度，对原时间序列数据进行归一化处理。 Step 2. ESN权值初始化。将ESN的权重进行随机赋值。 Step 3. 选择优化权值。选择的权值包括：从输入到隐藏( W i n )、隐藏到隐藏( W )和输出到隐藏( W b a c k )连接的部分的权值。为了保持ESN的独特性，节约计算成本，建议选择少量的权值。 Step 4. 优化选择权值。将选择的权值构成粒子群，利用改进的粒子群算法对选择权值进行优化。 Step 5. ESN的输出权值训练。在Step 4确定的权值下，对ESN网络中的输出权值进行训练。"
"为验证所提ESN-IPSO模型的有效性，本文选择Mackey-Glass时间序列、非线性自回归滑动模型(NARMA)和Lorenz时间序列进行仿真实验，并与标准的ESN模型和标准粒子群优化的ESN模型(ESN-PSO)进行数值仿真比较。  本文利用均方根误差(Root Mean Square Error, RMSE)对模型预测性能进行评估，RMSE的定义如下： RMSE = 1 k ∑ t = 1 k ( y ^ t − y t ) 2 . (7) 其中 y ^ t 和 y t 分别表示t时刻的预测值和真实值，k表示预测值的个数。 在数值模拟中，储备池的规模设置50，输入单元的数目和输出单元的数目均设置为1。 W i n ， W 和 W b a c k 的连通性分别为1，0.1和0.1。对于IPSO，设置最大惯性权重 w max 和最小惯性权重 w min 分别为0.9，0.4，粒子的数量n为10，最大迭代次数 t max 设置为50。  在深度学习中，对数据集进行归一化操作是非常有必要的预处理步骤。因为归一化操作不仅可以消除量纲，将数据统一到相同的尺度上，还可以提升模型的收敛速度和预测精度。本文利用归一化将原始时间序列变换到 ( 0 , 1 ) 范围之间，归一化函数可表示为： x * = x − x m e a n x max − x min . (8) 其中 x * 为归一化的标准时间序列，x为原始时间序列， x mean 为原始时间序列的均值， x max 为原始时间序列的最大值， x min 为原始时间序列的最小值。 数值模拟中，使用500个数据样本作为训练数据集，500个样本作为测试数据集。为避免预测结果的随机性，独立运行实验10次，取10次运行结果的平均值作为最终的预测结果，以保证实验结果的可靠性。  Mackey-Glass时间序列是时间序列预测常用基准之一，具有很强的代表性，已多次被用来测试ESN网络的预测性能。Mackey-Glass时间序列的产生模型可描述如下： d x ( t ) d t = a x ( t − τ ) 1 + x c ( t − τ ) b x ( t ) . (9) 其中参数 α = 0.2 , b = 0.1 和 c = 10 ， τ 为可调参数。当 ( τ > 16.8 ) 时，系统(10)呈现混沌运动状态，在文献中 τ 经常被设置为17或30。预测结果和预测误差如图2和图3所示，表1和表2列出了ESN-IPSO模型和其他模型的预测结果对比。 图2. Mackey-Glass时间序列预测( τ = 17 ) Table 1 Method RMSE ESN 4.03e−03 ESN-PSO 2.97e−03 ESN-IPSO 9.27e−04 表1. 模型误差对比 图3. Mackey-Glass时间序列预测( τ = 30 ) Table 2 Method RMSE ESN 9.01e−02 ESN-PSO 5.11e−03 ESN-IPSO 2.31e−03 表2. 模型误差对比 从图2，图3中可以看出，ESN-IPSO对Mackey-Glass时间序列的预测取得了较好的结果，不仅能够预测时间序列变化的趋势，且真实值和预测值之间的误差较小，说明本文提出的模型取得了较高的预测精度。从表1中可以看出，ESN-IPSO模型达到了最佳性能，其RMSE值9.27e−04。同时，ESN-IPSO的预测精度分别比ESN，ESN-PSO提升77%，69%。从表2中可以看出，ESN-IPSO模型具有最小的RMSE误差值，这意味着它在本次的Mackey-Glass预测任务中具有最佳的泛化性能。同时，与原始ESN，ESN-PSO相比，ESN-IPSO的预测精度分别提高了97%，54%。显然，通过IPSO算法优化ESN部分随机连接权值，模型的性能得到了一定的提高。  NARMA是广泛应用于ESN测试的混沌时间序列之一。NARMA序列的特点是其不可预测的复杂性，以及高度的混乱性和输入的非相关性。其动力学方程式，如下式所示： y ( t + 1 ) = c 1 y ( t ) + c 2 y ( t ) ∑ i = 1 k y ( t − i ) + c 3 x ( t − ( k − 1 ) ) x ( t ) + c 4 . (10) 其中的 y ( t ) 和 x ( t ) 分别是系统在时间t时的输出和输入，常数 c i 设置为0.3，0.05，1.5和0.1。常数k决定了NARMA的复杂性，本论文k取值为30。数据预处理后，用ESN-IPSO模型进行训练和预测，预测结果和预测误差如图4所示，表3列出了ESN-IPSO模型和其他模型的预测结果对比。 图4. NARMA时间序列预测( k = 30 ) Table 3 Method RMSE ESN 1.96e−01 ESN-PSO 1.17e−02 ESN-IPSO 4.35e−03 表3. 模型误差对比 图4所显示的NARMA时间序列预测结果很好地表现了ESN-IPSO的预测性能，在测试集上，模型的预测结果误差较小，精度较高，非常接近真实值。从表3也可以看出，ESN的RMSE值最高，为1.96e−01。而所提出的ESN-IPSO模型的RMSE值最低，为4.35e−03。同时，与ESN和ESN-PSO模型相比，ESN-IPSO的预测精度分别提高了98%和63%。说明本文提出的模型预测精度高，预测性能较好。  作为一个最经典的混沌模型，Lorenz系统的研究纵贯整个混沌科学的发展，几乎与所有混沌科学的重要发展都密切相关。因此Lorenz系统的研究对整个非线性科学的发展具有重要的意义。Lorenz混沌系统基本形式如下： d x d t = α ( y − x ) , d y d t = − y − x z + γ x , d z d t = x y − b z . (11) 其中在 α = 10 , γ = 28 和 b = 8 / 3 时呈现混沌态。对Lorenz系统的时间序列 x ( t ) 经过数据预处理后，用ESN-IPSO模型进行训练和预测，预测结果和预测误差如图5所示。表4则列出了ESN-IPSO模型和其他模型的预测结果对比。 图5. Lorenz-x(t)时间序列预测 Table 4 Method RMSE ESN 2.69e−02 ESN-PSO 2.01e−03 ESN-IPSO 1.08e−03 表4. 模型误差对比 从图5中可以看出，ESN-IPSO模型在Lorenz-x(t)时间序列的预测上仍然具有较好的表现，能够很好地预测序列的变化趋势。从表4中也能看出，在Lorenz样本集上本文提出的ESN-IPSO模型表现依然出色，且ESN-IPSO的预测性能明显优于ESN，ESN-IPSO模型。"
"本论文针对不同的时间序列，利用改进的粒子群算法来动态选择回声状态网络的部分随机权值，以适应不同时间序列的动力学特性，从而提高预测精度和泛化性能。对于标准的粒子群算法有两方面改进，一是对粒子群算法的权值进行改进，二是对粒子群算法的学习因子进行改进。对三组常见的混沌时间序列进行预测，仿真实验结果表明本文所提出的预测模型对ESN-PSO和ESN有了很大的改善，具有较高的预测精度。值得注意的是本文使用的是基本结构的回声状态网络，其自身性能可能会受到一定的限制。在未来，可以研究使用其他更加有效的元启发式算法优化具有复杂结构的回声状态网络的随机连接权值矩阵，进一步提升回声状态网络的性能。"
