"本文提出了一个新的带有信息熵的聚类目标函数，它是由基于图论的随机路径的熵率和平衡项两部分组成。熵率有利于形成紧凑和均匀的聚类，平衡函数鼓励相似度比较高的对象才能聚类，并惩罚那些相似度比较低的对象。首先构造了与数据关联的赋权无向图，并发现这种构造诱导出一个拟阵，它是一个组合在向量空间中推广线性独立概念的结构。接着得到了拟阵约束下最大化子模函数的模型。最后根据目标函数的单调性、递增性和下模性，开发了一个高效的贪婪算法并讨论了它的性能保证。最后根据数值实验，与已有的算法做了比较，说明了该算法的有效性。 关键词 :聚类，图理论，信息理论，子模函数，离散优化 Copyright © 2017 by authors and Hans Publishers Inc. This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/"
"聚类是在机器学习中的一种无监督学习方式，既是数据挖掘的重要部分，又是模式识别领域的基础问题 [ 1 ] [ 2 ] ，在统计学里也有广泛的引用。在几乎每个处理经验数据的科学领域里，研究人员试图通过识别相似字符组的数据获得第一印象。在不同的领域已经提出了很多种聚类方法，并且都有性能保证。然而，它们通常是基于不同的假设，而且很难在同一个标准下比较。此外，最理想的标准会导致成NP-hard问题。因此聚类的进一步发展就是对存在理论证明或更新的问题的目标函数的精细化设计。 在各种各样的聚类算法中，一些使用单个目标函数，一些递归地使用中间成本函数，以及一些基于数据点的投影(子空间，流形)。制定聚类问题作为一个图拓扑选择问题，当数据点及其对应关系分别映射到图中的顶点和边。然后通过查找图拓扑来解决聚类问题。主要考虑紧凑的、均匀的、平衡的类别。在一个紧凑的类别中，数据点彼此接近。为了获得以上这些性质，我们提出了一个新的由两部分组成的目标函数：一是图上的随机路径的熵率；二是类分布的平衡项。熵率 [ 3 ] 有利于形成紧凑和均匀的聚类，平衡函数鼓励相似度比较高的聚类，并惩罚那些相似度比较差的对象。根据图中的随机路径和类别的分布有很大的不确定性，构造一个图拓扑。 本文把聚类作为一个图划分问题，将图划分为 k 个群，研究具有 k 连通子图的图拓扑，并最大化所提出的目标函数。"
"图：无向图表示为 G = ( V , E ) ，其中 V 是顶点的集合， E 是边的集合。 v i 和 e i , j 表示顶点与边。 w i , j 表示顶点 v i 和 v j 之间边 e i , j 上的权重。在无向图中边的权重是对称的，即 w i , j = w j , i 。 图的划分 [ 4 ] ：在 G = ( V , E ) 中，如果 V = { V 1 , V 2 , ⋯ , V K } ，且满足： (1) V i ∩ V j = Φ , i ≠ j ；(2) ∪ i = 1 K V i = V ， 则称 V 1 , V 2 , ⋯ , V K 为 V 的一个划分。图的顶点的子集的选择问题就是图的划分问题。 本文的目标是选择边的子集 A ∈ E ，使得子图 ( V , A ) 是K-连通的。 熵：用来度量随机变量的不确定性。设离散随机变量 X ，概率密度函数为 p X ，则它的熵定义为： H ( X ) = − ∑ p X ( x ) log p X ( x ) , (1) 相应的，条件熵 H ( X | Y ) 的定义为： H ( X | Y ) = − ∑ p Y ( y ) H ( X | Y = y ) = − ∑ p Y ( y ) ∑ p X | Y ( x | y ) log p X | Y ( x | y ) , (2) 其中 p X | Y 是条件概率密度函数 [ 5 ] [ 6 ] 。 熵率：用来度量随机过程 X = { X t | t ∈ T } 的不确定性。对于一个离散的随机过程，熵率定义为一个渐近测度 [ 7 ] ： H ( X ) = lim t → ∞ H ( X t | X t − 1 , X t − 2 , ⋯ , X 1 ) , (3) 对于一阶平稳的马尔可夫过程，熵率有一个简单的形式 [ 8 ] [ 9 ] ： H ( X ) = lim t → ∞ H ( X t | X t − 1 ) = lim t → ∞ H ( X 2 | X 1 ) = H ( X 2 | X 1 ) . (4) 第一个等式是由于一阶马尔可夫性，而第二个等式是平稳性的结果。有关更多详细信息，可以参考 [ 10 ] 。 图上的随机路径：设 X = { X t | t ∈ T , X t ∈ V } 是带有非负的相似权 ω 的图 G = ( V , E ) 上的随机路径。转移概率定义为： p i , j = P ( X t + 1 = v j | X t = v i ) = ω i , j ω i , (5) 其中 ω i = ∑ k : e i . k ∈ E ω i , k 是顶点 v i 发生事件之和，并且平稳分布为： μ = ( μ 1 , μ 2 , ⋯ , μ | V | ) T = ( ω 1 ω T , ω 2 ω T , ⋯ , ω | V | ω T ) T , (6) 其中 ω T = ∑ i = 1 | V | ω i 是归一化常数。对于一个非连通图，平稳分布不是唯一的。但是，(6)式中的 μ 总是 平稳分布，容易证明得到 μ = P T μ ，其中 P = [ p ] i , j 是转移矩阵。随机路径的熵率为： H ( X ) = H ( X 2 | X 1 ) = ∑ i μ i H ( X 2 | X 1 = v i ) = − ∑ i ∑ j ω i , j ω T log ω i , j ω T + ∑ i ω i ω T log ω i ω T (7) 下模性 [ 11 ] ：设 E 是有限集，函数 f : 2 E → R 是下模函数当且仅当 ∀   A , B ⊆ E , ∀   a 1 , a 2 ∈ E ，有 f ( A ) + f ( B ) ≥ f ( A ∪ B ) + f ( A ∩ B ) . 或 f ( A ∪ { a 1 } ) − f ( A ) ≥ f ( A ∪ { a 1 , a 2 } ) − f ( A ∪ { a 2 } ) (8) 等价于： δ f a 1 ( A ) ≥ δ f a 1 ( A ∪ { a 2 } ) ，对于所有的 A ⊆ E 和 a 1 , a 2 ∈ E \ A ，其中 δ f a 1 ( A ) = f ( A ∪ { a 1 } ) − f ( A ) 进一步地，如果 f ( A ) ≤ f ( A ∪ { a 1 } ) ，则称 f 是单调递增函数 [ 12 ] 。 拟阵：设 E 是有限集， I 是 E 的子集组成的集合，拟阵是一个有序对 M = ( E , I ) ，并且满足： 1) Φ ∈ I 。 2) 如果 I 1 ∈ I 且 I ′ ⊆ I 1 ，则 I ′ ∈ I 。 3) 如果 I 1 ∈ I , I 2 ∈ I 且 | I 1 | < | I 2 | ，则存在元素 e ∈ I 2 − I 1 ，使得 I 1 ∪ e ∈ I 。 我们提出聚类作为一个图的划分问题。将图划分为 k 个类，搜索图具有 k 连通子图的拓扑，然后最大化提出的目标函数。  将数据集映射到图 G = ( V , E ) ，顶点表示该数据点和边权重表示两数据点之间的相似性。为了聚类，将数据集映射成K-最近邻域图。目标是划分图成为几个连通分支。选择一个边的子集 A ⊆ E ，产生一个子图 G ′ = ( V , A ) ，包含K-连通子图。再者，我们也假设每个顶点具有自环。虽然自环不影响图的划分，但它们对提出的随机路径模型是必要的。当某边不包含在 A 内时，增加与该边关联顶点的自环的权重，这样每个顶点的总发生的权保持常数。 如果边 e i , j 是被聚类时选择了，则顶点 v i 的自环的权为 ω i , i ，顶点 v j 的自环的权为 ω j , j ，边 e i , j 的权为 ω i , j 。 如果边 e i , j 是被聚类时未选择，则顶点 v i 的自环的权为 ω i , i → ω i , i + ω i , j ，顶点 v j 的自环的权为 ω j , j ← ω j , j + ω i , j ，边 e i , j 的权为 ω i , j ← 0 。  利用平衡函数鼓励大小相似的数据点分到同一个聚类中。设 A 是已经被选择的边集， N A 是图中被划分部分的数量， Z A 是聚类的分布。例如，设图对边集 A 的划分是 S A = { S 1 , S 2 , ⋯ , S N A } ，有 p Z A ( i ) = | S i | | V | ,   i = { 1 , 2 , ⋯ , N A } , (9) 并且平衡项为： Β ( A ) ≡ H ( Z A ) − N A = − ∑ i p Z A ( i ) log ( p Z A ( i ) ) − N A . (10) 熵 H ( Z A ) 将大小相似的聚为一类，同时通过类与类数据点之间的最小化可以得到聚类数目 N A 。 推论2：2.2中构造的图上的平衡函数 Β : 2 E → R 是一个单调递增的下模函数。  目标函数是熵率和平衡函数的结合，因此得到了更加紧凑的、均匀的和平衡的聚类。 max A ⊆ E   F ( A ) s .t .   N A ≥ K (11) 其中 F ( A ) = H ( A ) + λ Β ( A ) 是目标函数。参数 λ ≥ 0 是平衡项的权重。目标函数也是单调递增的下模函数。 推论3：设 E 是边集， I 是边集的集合， A ⊆ E 满足：1) A 是无循环的；2) A 构成一个大于或等于K-连通分支的图划分，则 M = ( E , I ) 是一个拟阵。 在无循环的约束下，图的划分问题变成了在拟阵约束下子模函数的最大化问题，即： max A ⊆ E   F ( A ) s .t .         A ∈ I (12)"
"对于求解模型(12)的贪婪算法如下： 拟阵约束的下模函数的最大化问题是组合优化研究中活跃的领域 [ 13 ] ，Fisher [ 14 ] 等给出了单调递增下模函数的最大化问题的以 1 2 近似上界的贪婪算法。同样地，我们也给出如下的性能保证： 定理：设 A o p t 是问题(15)的最优解， A g r e e d y 是应用上述算法得到的一个近似解，则 F ( A g r e e d y ) − F ( ∅ ) F ( A o p t ) − F ( ∅ ) ≥ 1 2 证明利用 [ 14 ] theorem2.1直接得到。"
"在聚类方面我们进行了大量的实验来评估所提出的算法方法，在整个实验中，使用了 λ ′ = 0.5 来测定平衡权重。该算法需要成对相似性数作为输入，这里使用的是高斯核 ω ( v i , v j ) = exp ( − d ( v i , v j ) 2 2 σ 2 ) ，这里 d ( v i , v j ) 是样本 i 和 j 之间的距离， σ 是核带宽。然后构造一个邻域图1，其中在群集之前，每个示例都连接到其30个最近的邻域。 在实验中，我们设置了聚类的个数对于所有算法的数字K，为了比较，使用以下两个标准的群集性能指标：1) 聚类精度(ca)和2) rand指数(ri)： 聚类精度是一种分类精度性能指标。设 ℂ = { C 1 , C 2 , ⋯ , C K } 是聚类的真分布。类似地，设 S = { S 1 , S 2 , ⋯ , S K } 是计算的聚类的分布。聚类精度为： C A = max J 1 n ∑ i | C i ∩ S J ( i ) | , 其中 n 是数据中的样本总数和 J 表示任意可能的排列 { 1 , 2 , ⋯ , K } 。 聚类指数是两者之间的相似性度量。设TP是相同的样本对的数量群集的真实性和估计聚类，设TN是在中的样本对的数目真实与估计的不同聚类聚类，设FP是对的示例对的数量在不同的集群中为真实的集群在同一个组中进行估计聚类，FN是样本对的数目这在同一个群中是真实的聚类，但在不同的集群中估计的聚类输出。聚类指数为： R I = TP + TN TP + TN + FP + FN 我们比较我们的结果和已有的聚类算法包括AP、k-means、ncut，以及平面最大间隔聚类算法(cpmmc) [ 16 ] ，它们代表了各种各样的聚类，结果如下： 图1. 图像来自自然场景识别数据集 [ 15 ] 。从左到右，图像类是海岸、森林、高速公路、内部城市，山，开放的乡村，街道和高楼。由于不同的成像条件，相同类的图像表现出很大的变化地点和季节 Table 1 数据 新方法 ncut AP k-means cpmmc Ionosphere 92.54 83.19 70.94 70.00 75.48 Letters 94.44 94.28 91.83 93.38 95.02 Sattellite 98.50 97.50 62.30 94.10 98.79 Digits 0689 97.34 91.83 90.31 78.46 96.74 Digits 1279 98.23 91.70 85.51 89.32 94.52 Breast Cancers 95.78 92.09 93.32 91.04 n/a Iris 93.01 86.67 86.00 83.33 n/a Wine 96.63 98.31 93.82 96.63 n/a Glass 50.98 55.41 40.19 45.33 n/a Movement Libras 52.98 50.83 46.94 44.44 n/a Natural Scenes 47.45 56.36 43.64 47.70 n/a MPEG-7 Shapes 73.56 71.64 69.14 n/a n/a 表1. 聚类性能比较：聚类精度 Table 2 数据 新方法 ncut AP k-means cpmmc Ionosphere 0.87 0.72 0.59 0.58 0.65 Letters 0.89 0.89 0.85 0.88 0.92 Sattellite 0.98 0.95 0.53 0.89 0.97 Digits 0689 0.99 0.93 0.92 0.87 0.97 Digits 1279 0.95 0.92 0.87 0.90 0.96 Breast Cancers 0.86 0.85 0.88 0.84 n/a Iris 0.92 0.86 0.85 0.83 n/a Wine 0.97 0.98 0.92 0.95 n/a Glass 0.72 0.70 0.66 0.70 n/a Movement Libras 0.91 0.92 0.91 0.91 n/a Natural Scenes 0.80 0.84 0.81 0.83 n/a MPEG-7 Shapes 0.98 0.99 0.99 n/a n/a 表2. 聚类性能比较：聚类指数 从表1和表2，我们看到了所提出的算法在聚类中产生略好的性能。根据聚类精度度量，在12个数据集中的7个数据集上的算法优于其它算法。我们还获得更好的性能索引：在12个数据集中有8个更好。"
