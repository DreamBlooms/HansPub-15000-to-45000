"AIC信息准则，BIC信息准则和Cross-Validation (交叉验证法，简称CV)是统计学中模型选择和评价的重要工具。本文为研究对数工资与周平均时长、IQ得分、世界工作知识得分、受教育年限等11个协变量之间的关系，从无协变量的模型经每次引入一个协变量共产生了12个备选的线性模型。基于AIC，BIC，CV三个准则分别在全样本上选择最优模型。在训练集上选最优模型，在测试集上进行误差分析对三个准则进行评判。其中，三个准则对应的值越小越好。在全样本上，基于三个准则选择的模型均是11个协变量共存的线性模型。将全样本分为训练集和测试集，基于AIC，BIC和CV三个准则，经过1000次运算，选择11个协变量共存的模型的概率分别为100%，99%，100%。对对数工资的探究，最优线模型为11个协变量共存的模型，并且三个准则的表现无明显差异。"
"随着社会经济的快速发展，人们在解决温饱问题后，对物质的追求和精神的追求越来越高。所以，人们在享受生活便利的同时，在一定程度上增加了经济压力。所以对工资因素的研究是有必要的，供人们根据自己的实际情况选择工作环境提供一个参考。在本文中，探究对数工资与周平均时长、人种、居住地、工作方位等因素之间的关系。   多元线性回归研究的是一个变量与多个变量之间的关系。  最小二乘法用于估计多元线性回归模型中协变量的系数。  AIC信息准则是衡量统计模型拟合优良性的一种标准，可以权衡所估计模型的复杂度和此模型拟合数据的优良性,全称是最小信息量准则 [ 1 ]。  BIC准则全称贝叶斯信息准则与AIC信息准则相似，用于模型选择 [ 2 ]。  Cross-Validation根据模型的预测能力选择模型的一种方法 [ 3 ]。将样本分为训练集和测试集，在训练集上进行模型选择，在测试集上预测误差。  Jun Shao [ 3 ] 在1993年通过交叉验证法选择选择线性模型。虽然交叉验证法测试为一个样本的很受欢迎，也比较方便，但是存在一定的缺陷，随着样本量的增加，最优模型的概率不趋近于1。因此Jun Shao [ 3 ] 做了与去一交叉验证法相对的验证法，训练集样本数量减少，测试集样本量增多，有效的弥补了去一交叉验证法的缺陷 [ 3 ]。而当预测变量的样本量相对于总的样本量较大时，AIC，BIC可能会出现倾向于过度拟合的问题，因此Yuhong Yang [ 4 ] 提出了修正的AIC准则，即AICc，能有效避免由于变量过多导致的过度拟合的现象 [ 4 ]。"
"基于多元回归模型的最小二乘法，方法是使得真实值与预测值之间的差距达到最小。 Step 1. 模型的建立 y = β 0 + β 1 x 1 + β 2 x 2 + ⋯ + β p x p + ε (1) 在这里，模型中的 x 1 , x 2 , ⋯ , x p 是协变量，未知参数 β 0 , β 1 , ⋯ , β p 模型参数， ε 是服从正态分布的随机误差项。 Step 2. 参数估计 记目标函数为如下(2)式： ϕ ( β 0 , β 1 , ⋯ β p ) = min { ∑ i = 1 n [ y i − ( β ^ 0 + β ^ 1 x i 1 + β ^ 2 x i 2 + ⋯ + β ^ p x i p ) ] 2 } , i = 1 , 2 , ⋯ , n (2) 用(2)式对未知参数 β 0 , β 1 , ⋯ , β p 求偏导，并令其等于0可得如下(3)式： { ∂ ϕ / ∂ β 0 = − 2 ∑ i = 1 n [ y i − ( β 0 + β 1 x i 1 + β 2 β x i 2 + ⋯ + β p x i p ) ] = 0 ∂ ϕ / ∂ β 1 = − 2 ∑ i = 1 n [ y i − ( β 0 + β 1 x i 1 + β 2 β x i 2 + ⋯ + β p x i p ) ] x i 1 = 0                                                                                   ⋮ ∂ ϕ / ∂ β p = − 2 ∑ i = 1 n [ y i − ( β 0 + β 1 x i 1 + β 2 β x i 2 + ⋯ + β p x i p ) ] x i p = 0 (3) 通过(3)式可得未知参数的估计表达式如下(4)式： β ^ = ( X ′ X ) − 1 X ′ y (4) 其中， β ^ = ( β ^ 0 , β ^ 1 , ⋯ , β ^ p ) ′ ， X = ( x 1 , x 2 , ⋯ , x p ) ， x i = ( x i 1 , x i 2 , ⋯ , x i p ) , i = 1 , 2 , ⋯ , n 。  Step 1. 模型的建立 y i = β 0 + β 1 x i 1 + β 2 x i 2 + ⋯ + β p x i p + ε i , ε i ~ N ( 0 , σ 2 ) (5) Step 2. AIC准则的建立 对于Step1中的模型， y i , i = 1 , 2 , ⋯ , n 是相互独立的，所以其极大似然函数为： L = ∏ i = 1 n 1 2 π σ exp { − [ y i − ( β 0 + β 1 x i 1 + β 2 x i 2 + ⋯ + β p x i p ) ] 2 2 σ 2 } (6) 根据(6)式，其对数似然函数为： ln L = − n 2 ln ( 2 π ) − n 2 ln σ 2 − ∑ i = 1 n [ y i − ( β 0 + β 1 x i 1 + β 2 x i 2 + ⋯ + β p x i p ) ] 2 2 σ 2 (7) 通过极大化模型的对数似然函数(7)式可得： σ 2 = ∑ i = 1 n [ y i − ( β 0 + β 1 x i 1 + β 2 x i 2 + ⋯ + β p x i p ) ] 2 n (8) AIC = − 2 ln L ( β , σ 2 | y ) + 2 ( p + 1 ) (9) (9)式为AIC信息准则的判别式，其中未知参数 β 由最小二乘法得到，p为未知变量的个数。  BIC准则的表达式的建立类似于AIC。 BIC = − 2 ln L ( β , σ 2 | y ) + ( p + 1 ) ln ( n ) (10)  在本文中，采用的是每次剔除一个样本并将其作为测试集，剩余的作为训练集的Cross-Validation。将其在测试集上的误差的平法和作为模型选择的标准。 Step 1. 将数据划分为训练集和测试集两部分。 剔除一个样本，将其作为测试集，将剩余的 n − 1 个样本作为训练集。 Step 2. 计算测试集上的误差的平方如下(11)式 p e i = { y i − x ′ ≠ i x ≠ i x ≠ i y } 2 (11) Step 3. 重复Step1和Step2 重复Step1和Step2，将得到 n − 1 个误差的平方。并将这 n − 1 个误差的平方和作为选模型的准则。 p e = ∑ i = 1 n p e i (12) 即为一个模型对应的 p e 越小，说明该模型越好。"
"本文研究的是对数工资(lwage)与11变量之间的关系。这11个变量分别为每周的平均时数(hours)、IQ得分(IQ)、世界工作分数知识(KWW)、教育年限(educ)、工作的年限(exper)、目前雇主年资(tenure)、岁数(age)、是否已婚(married)、是否是黑人(black)、是否位于南方(south)、是否住在SMSA(urban)。并且把这11个协变量分别记为 x 1 , x 2 , ⋯ , x 11 ，将响应变量lwage记为y。  协变量之间的相关系数矩阵。表1为协变量的系数矩阵每一列绝对值的最大值和对应的变量(除本身外)。 Table 1 变量 绝对值 真实值 ( x 1 , x 3 ) 0.1139 0.1139 ( x 2 , x 4 ) 0.5157 0.5157 ( x 3 , x 2 ) 0.4135 0.4135 ( x 4 , x 2 ) 0.5157 0.5157 ( x 5 , x 7 ) 0.4953 0.4953 ( x 6 , x 7 ) 0.2706 0.2706 ( x 7 , x 5 ) 0.4953 0.4953 ( x 8 , x 7 ) 0.1070 0.1070 ( x 9 , x 2 ) 0.3879 −0.3879 ( x 10 , x 9 ) 0.2365 0.2365 ( x 11 , x 10 ) 0.1099 −0.1099 表1. 变量间的相关系数 从表1可知， x 2 和 x 4 的相关系数是最大的为0.5157， x 5 和 x 7 相关系数为0.4953， x 3 和 x 2 的相关系数为0.4135。其余相关系数较小，说明在做线性模型时，当 x 2 、 x 4 和 x 3 共存或 x 5 和 x 7 共存时，模型可能会存在一定的共线性。  在本文中，共验证了12线性模型。从无变量入选模型经每次入选一个变量，一共有12个线性模型。分别为： 模型1： y i = β 0 + ε i , ε i ~ N ( 0 , σ 2 ) 模型2： y i = β 0 + β 1 x i 1 + ε i , ε i ~ N ( 0 , σ 2 ) 模型3： y i = β 0 + β 1 x i 1 + β 2 x i 2 + ε i , ε i ~ N ( 0 , σ 2 ) 模型4： y i = β 0 + β 1 x i 1 + β 2 x i 2 + β 3 x i 3 + ε i , ε i ~ N ( 0 , σ 2 ) 模型5： y i = β 0 + β 1 x i 1 + β 2 x i 2 + β 3 x i 3 + β 4 x i 4 + β 5 x i 5 + ε i , ε i ~ N ( 0 , σ 2 ) 模型6： y i = β 0 + β 1 x i 1 + β 2 x i 2 + β 3 x i 3 + β 4 x i 4 + β 5 x i 5 + β 6 x i 6 + ε i , ε i ~ N ( 0 , σ 2 ) … 模型12： y i = β 0 + β 1 x i 1 + β 2 x i 2 + β 3 x i 3 + β 4 x i 4 + ⋯ + β 11 x i 11 + ε i , ε i ~ N ( 0 , σ 2 )  通过MATLAB计算12个模型对应的AIC、BIC和CV值。  根据全部样本，采用最小二乘法确定模型参数，并根据(9)式，通过MATLAB软件可计算出每个模型对应的AIC值和BIC值如下表2。 由表2可知，第12个模型对应的AIC值为759.270，对应的BIC的值为822.197。在所有模型中模型12对应的AIC值和BIC值是最小的，因此通过AIC准则和BIC准则，选择的最优模型均是第12个模型。 Table 2 模型编号 AIC值 BIC值 1 1039.275 1048.956 2 1039.188 1053.709 3 940.511 959.873 4 899.478 923.681 5 880.183 909.226 6 859.210 893.094 7 842.402 881.127 8 843.434 886.999 9 823.755 872.160 10 814.156 867.402 11 800.787 858.874 12 759.270 822.197 表2. 各模型的AIC值和BIC值  通过MATLAB软件可计算出每个模型对应的CV值如下表3。 Table 3 模型编号 CV值 1 166.011 2 166.139 3 149.499 4 143.105 5 140.211 6 137.106 7 134.706 8 134.865 9 132.057 10 130.697 11 128.865 12 123.271 表3. 各模型对应的CV值 由表3可知，第12个模型对应的CV的值最小为123.271，在所有模型中是最小的。因此，通过交叉验证，选择的最优模型是第12个模型。  在本文中，将数据集随机地分为训练集和测试集，其中训练集有500个样本，测试集有435个样本。在训练集上做模型选择，在测试集上做误差分析。在本节实验中共做1000次实验。 下表4为每一次实验过程中，所选出的12个模型中最小的AIC值、BIC值以及CV值。在这里，只展示部分结果。其中，C1AIC为 12个模型中AIC值的最小值。C1BIC为12个模型中BIC值的最小值。C1CV为12个模型中CV值的最小值。括号中的数字代表的是模型序号。 Table 4 C1AIC值 C1BIC值 C1CV值 341.95 (12) 396.74 (12) 58.04 (12) 469.66 (12) 524.45 (12) 74.838 (12) 408.15 (12) 462.94 (12) 66.08 (12) 431.62 (12) 486.41 (12) 62.315 (12) 378.73 (12) 433.52 (12) 62.32 (12) 456.61 (12) 511.40 (12) 72.82 (12) 451.68 (12) 506.47 (12) 72.29 (12) 386.75 (12) 441.54 (12) 63.51 (12) 419.63 (12) 474.42 (12) 61.63 (12) 368.37 (12) 423.16 (12) 61.17 (12) 表4. 各模型在训练集上对应的AIC、BIC以及CV值 由表4可以看出，模型12对应的AIC值、BIC值以及CV值是最小的。 下表5为在1000次实验过程中，三个准则选择模型12的概率。 Table 5 准则类别 AIC BIC CV 选择模型12的概率 1 0.9900 1 表5. 基于三个准则对模型12的选择情况 由表5可知，基于AIC准则选择模型12的概率为100%；基于BIC准则选择模型12的概率为99%；基于交叉验证选择模型的12的概率为100%。因此，基于在本文中选用的模型是模型12。  由3.3节可知，在全部样本下，AIC准则、BIC准则以及CV选择的均是第12个模型，基于最小二乘法确定第12个模型，如下： y = 5.2797 − 0.0056 x 1 + 0.0033 x 2 + 0.0035 x 3 + 0.0492 x 4 + 0.0105 x 5           + 0.0100 x 6 + 0.0054 x 7 + 0.1950 x 8 − 0.1419 x 9 − 0.815 x 10 + 0.054 x 11 (13) 由(13)式可知，在其他条件不变的情况下，当 x 1 每增加一个单位，即每周平均时数每增加一个单位，对数工资y平均减少0.0056单位。当 x 2 每增加一个单位，即IQ每增加一个单位，对数工资y平均增加0.0033个单位。当 x 3 增加一个单位，即世界工作分数知识每增加一个单位，对数工资平均增加0.0035个单位。当 x 4 每增加一个单位，即教育年限每增加一个单位，对数工资平均增加0.0492个单位。当 x 5 每增加一个单位，即工作的年限每增加一个单位，对数工资平均增加0.0105个单位。当 x 6 每增加一个单位，即目前雇主年资每增加一个单位，对数工资平均增加0.0100个单位。当 x 7 每增加一个单位，即岁数每增加一个单位，对数工资平均增加0.0054个单位。当 x 8 = 1 ，即已婚，对数工资平均增加0.1950个单位。当 x 9 = 1 ，即是黑人，对数工资平均减少0.1419个单位。当 x 10 = 1 ，即是住在南方，对数工资平均减少0.0815个单位。当 x 11 = 1 ，即居住SMSA，对数工资平均增加0.1775个单位。"
"在本文中，依据WAGE2.XLS数据集，对对数工资和其他协变量之间的线性关系进行探究。从无协变量引入模型经每次入选一个协变量共产生了12个备选线性模型。 1) 在所有的935个样本上，从12个备选线性模型中，基于AIC、BIC和CV准则，选择的最优模型均是第12个模型，即为引入所有的协变量。通过最小二乘法可以确定第12个模型。 2) 将935个样本分为训练集和测试集，其中训练集有500个样本，测试集有435个样本。在训练集上，基于AIC、BIC和CV准则，从12个备选线性模型中选择最优模型。经过1000次运算，基于AIC信息准则选中第12个模型的概率为100%，基于BIC信息准则选择第12个模型的概率为99%，基于CV准则选中第12个模型的概率为100%。所以，针对对数工资与其余变量之间关系的这个数据集，三个准则的效果是一样的。"
