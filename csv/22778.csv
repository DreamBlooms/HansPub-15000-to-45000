"针对增强现实作为新的宣传媒介应用到商业活动中以达到宣传企业文化、活跃现场气氛的目的，基于人体部位识别技术构建了一个基于人的肢体语言识别的增强现实应用，阐述了基于彩色图像识别人体部位、基于深度图像识别人体部位的关键技术和基于人体部位识别构建虚拟现实交互展示系统的技术方案，验证了应用这两种技术进行人体部位识别存在的优缺点和可交互的增强现实系统在商业活动中应用的效果。 关键词 :增强现实，部位识别，新媒体 Copyright © 2017 by authors and Hans Publishers Inc. This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/"
"增强现实(Augmented Reality, AR)是在用户观察到的真实自然环境中添加计算机生成的文字、3D模型等信息的技术 [ 1 ] 。1992年Caudell等 [ 2 ] 首次提出了AR的概念，Azuma [ 3 ] 认为，AR可以被定义为满足三个基本特征的系统：真实和虚拟世界的融合，实时交互，虚拟和真实物体在3D空间中的真实注册 [ 4 ] 。将增强现实应用到新闻业的实践，自20世纪90年代中期起也在持续不断的探索中 [ 5 ] 。 增强现实主要应用各类成像技术、计算机图形图像处理技术、交互技术等来实现，是一门涉及多学科交叉的研究领域 [ 6 ] 。近年来，增强现实技术在医疗、教育、娱乐、军事等领域得到非常广泛的应用 [ 7 ] ，同时，在各个领域的应用中也在探索方法，以获取更丰富的内容和更好的用户体验。 本文利用图像识别技术获取人体头部位置，利用摄像头捕获的真实场景作为背景，在进入画面的用户头部偏上位置生成带有动画效果的文字特效，文字特效跟随用户移动，达到吸引用户的目的，向用户展示企业文化等内容，同时在画面最下方可以叠加企业活动宣传等广告内容。该应用在商业活动中可以提升参与活动主动性、活跃现场气氛，同时也能够宣传企业文化，为企业经济活动提供帮助。"
"人体部位识别即从视频图像中获取到运动的人的肢体部位在视频图像中的位置，根据图像数据不同可以分为基于可见光图像识别和基于深度图像识别 [ 8 ] 。本文利用人体部位识别技术，获取到进入摄像头视角范围内的用户的头部位置，根据其头部位置生成文字特效跟随动画，是实现系统人机交互的关键。  基于可见光图像的识别人体部位，是通过对摄像头获取的视频流的每一帧图像检测所有人脸的位置，以人脸位置中心点表示系统中所需的头部位置信息，本文使用级联分类器的方法进行人脸位置的检测，其实现原理是：首先，利用若干人脸图像样本，提取特征进行分类器训练，得到若干个简单的分类器，这些分类器进行级联，进而得到一个级联的分类器。训练样本分为正例样本和反例样本，其中正例样本是指包含人脸特征的样本，反例样本指其它任意图片，所有的样本图片都被归一化为同样的尺寸大小；分类器训练完以后，就可以应用于输入图像中的感兴趣区域(与训练样本相同的尺寸)的检测。检测到目标区域(人脸)分类器输出为1，否则输出为0。为了检测整幅图像，可以在图像中移动搜索窗口，检测每一个位置来确定可能的目标。为了搜索不同大小的目标物体，分类器被设计为可以进行尺寸改变，这样比改变待检图像的尺寸大小更为有效。所以，为了在图像中检测未知大小的目标物体，扫描程序通常需要用不同比例大小的搜索窗口对图片进行几次扫描。 分类器的实现原理虽然复杂，但在该系统实现的过程中，没有必要编码实现每一个细节，可以使用已有的类库进行功能开发。我们使用OpenCV中一个基于树的分类器：Haarcascades来检测人的面部，选用此分类器是因为它建立了“boosted”筛选时级联分类器，“boosted“即指级联分类器的每一层都可以从中选取一个boosting算法，并利用基础分类器的自我训练得到。 分类器构建完成后，我们先通过摄像头捕捉到每一帧的图像，然后将图像进行直方图均衡化，再转化为灰度图像传递给分类器，这样分类器将会得到脸部的数量，和每一个脸部位置信息的数据。通过访问这些数据列表的每一项，我们可以算出脸部的轮廓，确定人头部上方的具体坐标值，将坐标储存作为每一个特效的初始化位置，完成特效的生成。 基于可见光识别人体部位的优点在于对外界环境要求较低，在大多数场合下都可使用，识别人数也不受限制，只要空间条件允许，多少人都可以识别，其缺点在于容易受到场景中变化的光线、影子等因素影响，尤其是场景中灯光剧烈变化的话，很容易出现识别不准确的情况。  深度图像也称为距离图像，与彩色图像相比，深度图像能直接反映出物体表面的三维特征，且不受光照、阴影等外部因素的干扰 [ 9 ] 。深度图像不能通过普通摄像头直接获得。微软的Kinect体感设备可以生成深度图像，然后利用分隔策略，将人体从深度图像的背景环境中区分出来，进行复杂的矩阵变换、计算，辨别出人体不同的部位 [ 10 ] ，然后得出人体各个关节的坐标。 利用Kinect设备进行人体部位识别，性能稳定，可以准确的得到人体各个部位的相对坐标，微软也为使用该设备的开发者提供了良好的接口。在实际应用中，kinect设备识别人体关键部位有存在一些缺点，首先，由于kinect设备深度图像的获取是利用红外线发射器将镭射光均匀的投射到物体的表面，然后利用红外摄像头拍摄得到镭射光在物体表面形成的图像，经过计算得到的，在室外由于红外线的干扰，不能得到准确的深度图像。其次，第一代kinect设备最多可识别人数为2个，第二代kinect设备最多可识别人数为6个，识别人数有限。最后，kinect设备对识别空间范围有限制，在近景模式下最远识别距离为3米(如图1所示)，在默认模式下最远识别距离为4米(如图2所示)。"
"系统功能模块如图3所示，利用Unity3D游戏引擎进行开发，Unity3D游戏引擎为AR系统的开发提供了非常便利的工具，它为图像的获取、图像的处理、视频的叠加都提供了简单易用的接口，同时，也 图1. 近景模式识别示意图 图2. 远景模式识别示意图 图3. 系统功能模块图 能很好地兼容opencv所提供的程序运行库，并专门为Kinect工具的使用提供了开发包。系统流程如图4所示，首先获取实时图像作为背景，然后利用人体部位识别技术计算得出进入图像用户的头部坐标，为每个坐标随即选取跟随文字特效内容，利用程序生成跟随动画，文字特效叠加在实时图像之上，创建广告展示图层，叠加在在实时图像底部。  实时图像采集模块从摄像头获取真实场景视频流，并将视频流作为背景图像交给AR融合器，然后由图像处理接口对每一帧视频图像进行识别，获取到人头部位置，图像处理接口让识别得出的结果提供给文字动画控制器，文字动画控制器根据识别结果，为每一个人物头部以上位置，生成一个跟随的动画特效，整个处理流程如图所示。图像处理接口模块实现了两种识别人体头部的接口：基于Opencv的可见光图像识别技术识别人体部位和基于Kinect深度图像的人体部位识别，两种接口可以满足在不同环境下的应用需求。  文字特效动画的实现完全由程序控制，特效由跟随动画、文字、背景色三部分组成，首先为每一个用户随即选择配置文件中所存在的句子，为每个句子随即选择一种背景颜色，句子有单词组成，单词间在竖直方向上间距事先设置完成，在水平方向上，第一个单词根据配置时间、速度变化曲线运动到对应 的人的头部位置，第二单词以同样的逻辑运动到第一单词的位置，随着时间更新的单词及其背景颜色形成了运动的动画特效。 系统被应用在商业活动中，吸引参与用户，系统会对用户肢体语言自动的产生响应，给用户新奇感，活跃活动现场气氛。同时，也能够将宣传信息传递给用户，给他们留下深刻的印象，达到了营销的目的，是增强现实技术转化为实际成果的一个成功应用案例，用户参与效果如图5所示。 图4. 系统流程图 图5. 跟随动画效果图"
"本文利用人体部位识别技术实现的用于企业理念宣传的可交互增强现实应用验证了不同的人体部位识别技术在应用中存在的优缺点，该系统的应用效果表明虚拟现实作为新的广告媒介受到广大用户的青睐，具有广阔的应用前景。该系统图像处理所截取的图像分辨率低，交互内容单一，是影响用户体验关键因素，在下一步的工作中，需要进步提高处理速度，提升图像质量，增加交互效果。"
