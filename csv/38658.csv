"为了提高光滑支撑向量机模型的分类性能，文章给出了一种新的光滑函数反比例函数，并利用光滑技术克服了支撑向量机模型的不可微性，通过数学理论上严谨的论证和分析，证明了所给出光滑函数的性质和基于此光滑函数所建立的反比例光滑支撑向量机模型(ISSVM)的收敛性。实验数值表明，反比例光滑支撑向量机比多项式光滑支撑向量机在分类性能上更有优越性。"
"2001年Lee等人通过对支撑向量机的深入研究引入光滑的概念，使用了sigmoid积分函数p(x,α)对无约束的支撑向量机模型SVM [ 1 ] 进行光滑化，得出了分类性能较好的光滑支撑向量机SSVM [ 2 ]。继而使用Newton-Armijo算法对SSVM进行求解，结果展现出了SSVM比标准SVM具有更好的分类性能和较高的计算效率，从此光滑函数作为SSVM模型的核心引起了人们的广泛关注，并开辟了支撑向量机的一个新的研究方向。 2005年文献 [ 3 ] 提出了两个多项式光滑函数，同时对无约束的支撑向量机模型进行光滑化处理，引出了PSSVM模型。可以证明，PSSVM比SSVM有更好的分类性能。之后文献 [ 4 ] 提出了三阶样条光滑函数，从而引出了新的支撑向量机的TSSVM模型。通过分析TSSVM模型的收敛性，并通过数据实验可以说明TSSVM分类器的效果要更优。2008年，文献 [ 5 ] 提出了六阶光滑函数，此光滑函数逼近正号函数的精度比三阶样条光滑函数更是高了一个数量级。2014年，吴青等人在此基础上提出指数光滑支持向量分类机 [ 6 ] 的模型，证明了其收敛性并通过数值实验表明了指数光滑支持向量机比多项式光滑支持向量机在分类性能上更有优势。 很明显可以得知，光滑支撑向量机的分类性能随着光滑函数的逼近精度提高而改善，那么，能否寻求一种新的光滑函数使得光滑支撑向量机的分类性能获得提升，一直是学者研究关于相关SVM问题的热点。本文通过借鉴指数光滑支持向量机模型中指数光滑函数的性质对反比例函数的研究提出了新的光滑函数，并对支撑向量机模型光滑化处理得出了反比例光滑支撑向量机。"
"根据光滑函数是支撑向量机研究的重点，依据反比例函数的一些性质，提出反比例光滑函数 i ( x , k ) = { x ,     x > 1 10 k 1 10 k ( 2 − 10 k x ) ,     x ≤ 1 10 k 性质1已知光滑函数 i ( x , k ) 并且 x + 是正号函数，那么 1) i ( x , k ) 关于x一阶光滑。 2) 当 x → − ∞ 且 k > 0 时， i ( x , k ) → 0 。 证明 对函数 i ( x , k ) 关于变量x求一阶导得分段函数 i ′ ( x , k ) = { 1 ,     x > 1 10 k 1 ( 2 − 10 k x ) 2 ,     x ≤ 1 10 k 因为 i ′ ( x , k ) 在分段点处左右极限存在并且左极限 lim x → 1 10 k − 1 ( 2 − 10 k x ) 2 = 1 与右极限相等，故为 i ′ ( x , k ) 在整个区间连续，又因 i ″ ( x , k ) = { 0 ,     x > 1 10 k 20 k ( 2 − 10 k x ) 3 ,     x ≤ 1 10 k 在分段点处左右极限皆存在，但其右极限为0而左极限非0，所以 i ″ ( x , k ) 在断点处不连续。综上可知 i ( x , k ) 关于x一阶光滑。 当 x → − ∞ 并且 k > 0 时，对 i ( x , k ) 求极限，即得 lim x → − ∞ 1 10 k ( 2 − 10 k x ) = 0 性质2已知光滑函数 i ( x , k ) 并且 x + 是正号函数，那么 1) i ( x , k ) ≥ x + 。 2) 对于 x ∈ ( − ∞ , + ∞ ) ，当 k > 0 时，有 i 2 ( x , k ) − x + 2 ≤ 0.00131105 1 k 2 证明 当 x > 1 10 k 时，显然有 i ( x , k ) ≥ x + ，而当 0 ≤ x ≤ 1 10 k 时，构造函数 f 1 ( x , k ) = i ( x , k ) − x + = 1 10 k ( 2 − 10 k x ) − x 对 f 1 ( x , k ) 求导得 f ′ 1 ( x , k ) = 1 ( 2 − 10 k x ) 2 − 1 < 0       ( 0 ≤ x ≤ 1 10 k ) 故 f 1 ( x , k ) 在 ( 0 , 1 10 k ) 内单调递减，又因 f 1 ( x , k ) 在 x = 1 10 k 处取得最小值0，因此 f 1 ( x , k ) = i ( x , k ) − x + ≥ 0 也即 i ( x , k ) ≥ x + 。另当 x < 0 时，显然有 f 2 ( x , k ) = i ( x , k ) − 0 = 1 10 k ( 2 − 10 k x ) > 0 因此也有 i ( x , k ) ≥ x + 。综上可得结论(1)。 当 x ≥ 1 10 k 时，结论(2)显然成立。当 0 < x < 1 10 k 时， x + = x ，于是对 g 1 ( x , k ) = i 2 ( x , k ) − x 2 = 1 100 k 2 ( 2 − 10 k x ) 2 − x 2 关于x求导得 g ′ 1 ( x , k ) = 1 5 k ( 2 − 10 k x ) 3 − 2 x 用二分法 [ 7 ] 求得导函数的零点为 x 0 = 0.020312 1 k 可求得 g 1 ( x , k ) 在 x 0 处取得最大值为 g 1 ( x 0 , k ) = 0.00131105 1 k 2 另当 x < 0 时， x + = 0 ，于是 g 2 ( x , k ) = i 2 ( x , k ) = 1 100 k 2 ( 2 − 10 k x ) 2 在 ( − ∞ , 0 ] 上单调递增，且其最大值 g 2 ( 0 , k ) = 1 400 k 2 = 0.0025 1 k 2 综上可知结论(2)成立，且 i 2 ( x , k ) − x + 2 ≤ 0.00131105 1 k 2 < 0.0188 1 k 2 性质2表明了反比例光滑函数对正号函数的逼近精度比六阶光滑函数提高了一个数量级。 光滑因子为 k = 10 时，各个光滑函数对正号函数的逼近程度如图1所示，从中可见，反比例光滑函数的逼近效果更好。 图1. 不同光滑函数的逼近程度"
"由软间隔支撑向量机的原始型和对偶形式我们可以对其进行求解得到 α i * ，于是分类函数 f ( x ) = sign [ ∑ i = 1 m     y i α i * ( φ ( x i ) , φ ( x ) ) + b * ] = sign [ ∑ i = 1 m     y i α i * K ( x i , x ) + b * ] (1) 其中 b * = 1 m ∑ i = 1 m ( y i − ∑ i = 1 m     y i α j * ( φ ( x j ) , φ ( x i ) ) ) (2) 令 M = ( x 1 , x 2 , ⋯ , x m ) T x i = ( x i 1 , x i 2 , ⋯ , x i n )   ( i = 1 , 2 , ⋯ , m ) ， e = ones ( m , 1 ) ， D = diag ( y 1 , y 2 , ⋯ , y m ) ， H = D K ( M , M T ) D 则原始问题改写为 { min α , b   1 2 α T H α + C e T ξ s .t .     D ( K ( M , M T ) D α + e b ) − e + ξ ≥ 0 , ξ ≥ 0 (3) 对于任何核函数，上式均是个凸二次规划问题，不妨取 H = I ，同时用b衡量分类间隔 ( 2 ‖ ( w , b ) ‖ 2 ) ，于是在对偶问题中 b = − e T D α ，同时让松弛变量 ξ T ξ 最小，则(3)式转化为 { min α , b   1 2 ( α T α + b 2 ) + c 2 ξ T ξ s .t .     D ( K ( M , M T ) D α + e b ) − e + ξ ≥ 0 , ξ ≥ 0 (4) 由约束条件知， ξ = ( e − D ( K ( M , M T ) D α + e b ) ) + 这里是非光滑的。将其代入问题(12)，得到一个强凸无约束优化问题 min α , b 1 2 ( α T α + b 2 ) + c 2 ‖ ( e − D ( K ( M , M T ) D α + e b ) ) + ‖ 2 (5) 有唯一解。 我们用反比例函数对上述无约束支撑向量机模型SVM进行光滑化，可以得到一个新的光滑支撑向量机模型 min α , b 1 2 ( α T α + b 2 ) + c 2 ‖ i ( e − D ( K ( M , M T ) D α + e b ) , k ) ‖ 2 2 (6) 称之为ISSVM模型。 记 ω = α , γ = − b , A = K ( M , M T ) D ，则上式可化为 min ω , γ   1 2 ( ω T ω + γ 2 ) + c 2 ‖ i ( e − D ( A ω − e γ ) , k ) ‖ 2 2 分析反比例光滑支撑向量机模型，可以证明此模型收敛。该模型的最优解在 k → + ∞ 时无限逼近无约束SVM模型的最优解。 定理1设 A ∈ ℝ m × n ， b ∈ ℝ m × 1 ，定义实函数 f + ( x ) : ℝ n → ℝ f + ( x ) = 1 2 ‖ ( A x − b ) + ‖ 2 2 + 1 2 ‖ x ‖ 2 2 f i ( x , k ) : ℝ n × ℕ → ℝ f i ( x , k ) = 1 2 ‖ i ( A x − b , k ) ‖ 2 2 + 1 2 ‖ x ‖ 2 2 则有结论 1) f + ( x ) 和 f i ( x , k ) 都是强凸函数。 2) 优化函数 min x f + ( x ) 存在唯一解 x * ，优化函数 min x f i ( x , k ) 存在唯一解 ( x * ) k 。 3) 对于任意的 k ≥ 1 ，有 ‖ ( x * ) k − x * ‖ 2 ≤ 0.00131105 m 2 k 2 4) x * 和 ( x * ) k 满足 lim k → ∞ ( x * ) k = x * 证明因为 ‖   ⋅   ‖ 2 2 具有强凸性，所以 f + ( x ) 和 f i ( x , k ) 也满足强凸性质。 由性质1可知，水平集 L v ( f i ( x , k ) ) 和水平集 L v ( f + ( x ) ) 满足 L v ( f i ( x , k ) ) ⊆ L v ( f + ( x ) ) ⊆ { x : ‖ x ‖ 2 ≤ 2 v } ( v ≥ 0 ) 因此它们都是 ℝ n 中的紧子集，从而有 min x f + ( x ) 和 min x f i ( x , k ) 都有解存在，而由 min x f + ( x ) 和 min x f i ( x , k ) 的强凸性可得解具有唯一性。 5) 我们不妨假设 x * 和 ( x * ) k 分别是 min x f + ( x ) 和 min x f i ( x , k ) 的唯一解，则有 f + ( ( x * ) k ) − f + ( x * ) ≥ ∇ f + ( x * ) ( ( x * ) k − x * ) + 1 2 ‖ ( x * ) k − x * ‖ 2 2 = 1 2 ‖ ( x * ) k − x * ‖ 2 2 f i ( x * , k ) − f i ( ( x * ) k , k ) ≥ ∇ f i ( ( x * ) k , k ) ( x * − ( x * ) k ) + 1 2 ‖ ( x * ) k − x * ‖ 2 2 = 1 2 ‖ ( x * ) k − x * ‖ 2 2 两式相加得 ‖ ( x * ) k − x * ‖ 2 2 ≤ ( f i ( x * , k ) − f + ( x * ) ) − ( f i ( ( x * ) k , k ) − f + ( ( x * ) k ) ) ≤ f i ( x * , k ) − f + ( x * ) = 1 2 ‖ i ( A x * − b , k ) ‖ 2 2 − 1 2 ‖ ( A x * − b ) + ‖ 2 2 又根据性质2可知 ‖ ( x * ) k − x * ‖ 2 ≤ 0.00131105 m 2 k 2 根据上式可知 lim k → ∞ ‖ ( x * ) k − x * ‖ 2 ≤ lim k → ∞ 0.00131105 m 2 k 2 = 0 因此 lim k → ∞ ( x * ) k = x *"
"由性质1可知光滑函数 i ( x , k ) 是一阶光滑函数，我们可选用BFGS算法 [ 8 ] [ 9 ] 来对上述ISSVM模型进行优化。其具体算法步骤如下： 步骤1初始化 H 0 = I ,     ( ( ω 0 ) , γ 0 ) = p 0 ∈ ℝ n + 1 ,   ε = 10 − 8 ,   α 0 = I ,   i = 0 , 其中I为单位矩阵。 步骤2计算 F i = F ( p i , k ) ,   g i = ∇ F ( p i , k ) , 其中 F ( p i , k ) 指光滑函数。 步骤3如果 ‖ g i ‖ 2 2 ≤ ε 或迭代次数达到最大，那么迭代停止，并取 ( ( ω i ) T , γ i ) = p i 为ISSVM模型的最优参数解； 否则计算梯度方向 d i = − H i g i 。 步骤4沿着方向 d i 采用线搜索计算步长 α i ，于是有 s i = − α i H i g i 再计算出 F i + 1 = F ( p i + 1 , k ) ,   g i + 1 = ∇ F ( p i + 1 , k ) ,   y i = g i + 1 − g i 步骤5计算 H i + 1 = ( I − s i ( y i ) T ( s i ) T y i ) H i ( I − y i ( s i ) T ( s i ) T y i ) + s i ( s i ) T ( s i ) T y i 步骤6令 i = i + 1 ，转步骤2。"
"对于SSVM，FSSVM，TSSVM，ESSVM和ISSVM5种模型采用BFGS算法求解无约束优化模型，算法采用的最大的迭代次数为1000，且取 ε = 10 − 8 。使用matlab2018a作为运行环境，实验结果记录CPU耗时、样本分类的训练正确率和测试正确率，根据这3个指标对这五种模型的分类性能进行比较和分析。 实验1 为了说明ISSVM具有解决大规模数据集的能力，采用的数据集是NDC数据集 [ 10 ]，数据集的样本数数量级至少在万以上。在采用BFGS算法对模型进行求解时，为求结果的准确性，对训练数据使用10折交叉验证方法 [ 11 ]。结果如表1所示。 Table 1 Data Models time/s Training error rate (%) Test error rate (%) 10000 × 10 SSVM 0.0532 96.7700 96.7700 FSSVM 0.0642 96.8744 96.8700 TSSVM 0.0652 96.9722 96.9700 ESSVM 0.0567 97.4744 97.4800 ISSVM 0.0557 97.5237 97.5300 10000 × 20 SSVM 0.0743 97.3211 97.2800 FSSVM 0.0811 97.4233 97.3900 TSSVM 0.1047 97.5089 97.4800 ESSVM 0.0795 98.1022 98.1200 ISSVM 0.0790 98.1024 98.1200 20000 × 10 SSVM 0.1118 97.4394 97.4350 FSSVM 0.1319 97.5461 97.5550 TSSVM 0.1730 97.6061 97.6200 ESSVM 0.1120 97.7833 97.7850 ISSVM 0.1086 97.8124 97.8200 20000 × 20 SSVM 0.2004 97.8078 97.8000 FSSVM 0.1920 97.9656 97.9650 TSSVM 0.2508 98.0317 98.0400 ESSVM 0.1971 98.7033 98.6900 ISSVM 0.1902 98.8422 98.8500 30000 × 10 SSVM 0.1145 95.7356 95.7300 FSSVM 0.1365 95.8507 95.8467 TSSVM 0.1722 95.9496 95.9300 ESSVM 0.1133 96.8707 96.8700 ISSVM 0.1002 96.9852 96.9900 30000 × 20 SSVM 0.1510 96.3856 96.3933 FSSVM 0.1718 96.5107 96.5100 TSSVM 0.2083 96.5726 96.5700 ESSVM 0.1496 97.0181 97.0067 ISSVM 0.1298 97.2532 97.2500 表1. NDC数据集实验 由表1可知，新提出的反比例光滑支撑向量机ISSVM模型具有解决大规模数据问题的能力，并且在分类正确率和测试正确率上都有着较好的表现。在解决大规模数据问题时，ISSVM在CPU耗时和正确率上有着一定的优势。 数值实验数据来自用python编写的随机线性不可分数据集，统共样本数据有1200样本，测试样本有288个，每个样本有29个特征，采用了高斯核来将其映射到高维特征空间上得到分类结果如图2~5。 图2. 分类结果(1) 图3. 分类结果(2) 图4. 分类结果(3) 图5. 分类结果(4) 可以看出在小规模数据集下其分类的正确率都有着良好的性质。 除此之外，我们还补充了对于非线性数据集Checkerboard数据集的实验结果。当采用的核函数为高斯核函数 K ( x , y ) = exp ( − μ ‖ x − y ‖ 2 ) 时 [ 12 ] 结果如表2所示： Table 2 Data Models time/s Training error rate(%) Test error rate(%) 1000/9000 SSVM 2.170 93.900 93.430 FSSVM 2.220 93.900 93.501 TSSVM 2.102 93.900 93.370 ESSVM 1.662 93.900 93.500 ISSVM 1.420 93.890 93.920 2000/8000 SSVM 22.840 95.600 95.320 FSSVM 23.920 95.902 95.331 TSSVM 22.030 95.650 95.440 ESSVM 20.702 95.900 95.664 ISSVM 20.280 95.880 95.980 3000/7000 SSVM 103.480 97.430 97.311 FSSVM 81.892 97.430 97.310 TSSVM 80.925 97.534 97.361 ESSVM 76.750 97.700 97.470 ISSVM 74.830 97.938 98.004 表2. Checkerboard数据集实验 由表2可知，ISSVM在处理非线性数据时，其耗时最短并且有着更高的分类正确率和测试正确率，说明了ISSVM处理非线性数据集的性能更好。"
"本文给出了一种新的光滑函数反比例函数，并基于光滑支撑向量机的过程应用此光滑反比例函数建立了ISSVM模型。与以往的光滑函数如多项式光滑函数、sigmoid积分函数、样条光滑函数等相比较而言，其逼近正号函数的精度提高了不同的数量级。实验数据表明，该反比例光滑支撑向量机模型对于大数据集具有较好的分类性能，相比于三阶样条光滑支撑向量机模型等而言，反比例光滑支撑向量机模型对线性数据分类所花费的时间更短且正确率也有所提升，整体比较来说对于非线性数据也能有较好的分类性能。反比例光滑函数相比其他光滑函数有着逼近程度更强的能力，反比例光滑支撑向量机相比于其他光滑支撑向量机模型的性能也更优越。"
