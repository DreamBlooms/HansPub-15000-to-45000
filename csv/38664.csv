"随着互联网技术的迅速发展，社会进入了大数据时代。数据不仅类型多种多样，结构错综复杂还具有动态变化的特点。如何从海量数据中快速获取有价值的信息是当前亟待解决的问题。粗糙集是一种处理数据不确定性的数据评价方法。属性约简是粗糙集理论的一个重要核心应用。本文将围绕属性约简后信息损失量进行研究，从而找寻一种属性约简算法，在约简后既能保持数据分类准确率较高且信息损失较少。本文借助知识粒度的概念和约简算法，引入联合粒度，并将其运用到属性约简过程，进一步得出基于联合粒度属性约简算法。然后运用其算法对决策表系统进行约简，得出该算法在保持分类准确率不变的情况下，其信息损失量降至较低。最后通过UCI数据集进行仿真实验探究，从而验证了该方法的准确性和有效性。"
"粗糙集理论 [ 1 ] 作为一种数据分析方法，在定性和定量分析的基础上用来描述决策系统中的不确定性。属性约简 [ 2 ] [ 3 ] [ 4 ] [ 5 ]，也称特征选择，是粗糙集理论的重要核心应用。它是从信息系统的所有属性中选择部分重要度较高的属性，同时不减少数据分类的准确性。属性约简已被广泛应用于许多研究领域，如模式识别、数据挖掘与机器学习等。在数据挖掘 [ 6 ] 领域中，属性约简是一种常用的数据处理工具，主要对数据中的冗余属性进行删除操作，使其达到更高的分类性能且不损失数据表的任何信息。 前期学者们提出了许多属性约简准则和约简算法，几乎所有的约简准则都宣称保持分类不变、信息无损失。然而，本文从信息熵角度 [ 6 ] 分析，定量分析删除的冗余属性可能含有一定的信息量，可以得出属性约简可能会导致信息的损失。为了探究不同约简准则信息损失量的差异，提出联合粒度属性约简算法，同时对比了正区域约简、知识粒度约简和该算法的约简准则对数据分类、信息损失量的影响，从而验证此算法的有效性。"
"给定一个信息系统 [ 1 ] I S = ( U , A ) 中，U是论域，A是论域U上的条件属性集。在条件属性集中任取条件属性 m ∈ A 都存在一个函数 m : U → F m ，与其相对应， F m 为属性m的值域。U中每个元素称为个体、对象或行。 定义2.1 [ 5 ] 对于任意的属性子集 B ⊆ A 和任何个体 x ∈ A 都对应着如下的信息函数： I n f B ( x ) = { ( a , a ( x ) ) : a ∈ B } B-不分明关系(或称为不可区分关系)定义为: I N D ( B ) = { ( x , y ) : I n f B ( x ) = I n f B ( y ) } 任何满足 I N D ( B ) 的2个元素 x , y 都不能由B的任何子集区分， [ x ] B 表示由x引导的 I N D ( B ) 等价类。  定义2.2 [ 6 ] 在决策系统 D S = ( U , C , d ) 中， B ⊆ C 是DS的基于正区域的相对约简当且仅当 B ⊆ C 满足以下两个条件： (1) P O S B ( d ) = P O S C ( d ) ； (2) 对于任意的 a ∈ B ，都有 P O S B − { a } ( d ) ≠ P O S C ( d ) . 定义2.3 [ 6 ] 给定一个决策系统 D S = ( U , A , d ) ， B ⊆ A 称为该决策系统DS的一个基于条件熵的相对约简当且仅当 B ⊆ A 满足如下两个条件： (1) H ( D S , { d } | B ) = H ( D S , { d } | A ) ； (2) 对任意的 S ⊂ B ，均都有 H ( D S , { d } | S ) ≠ H ( D S , { d } | A ) 。  定义2.4 [ 7 ] 给定一个信息系统 I S = ( U , A , V , f ) ，对于任意属性子集 M ⊆ A 导出的划分 U / M = { R 1 , R 2 , R 3 , ⋯ , R n } ，则该信息系统对于属性子集M的知识粒度的定义为 G D ( M ) = ∑ i = 1 n | R i | 2 | U | 2 定义2.5 [ 7 ] 设给定一个信息系统 I S = ( U , A , V , f ) ，如果存在属性子集 R 1 , R 2 ⊆ A ，则有属性子集 R 1 相对于子集 R 2 的知识粒度的定义为 G D ( R 1 | R 2 ) = G K ( R 2 ) − G K ( R 1 ∪ R 2 ) 定义2.6 [ 7 ] 对于给定决策系统 D S = ( U , A ∪ D , V , f ) ，若属性子集 R ⊆ A 是当且仅当满足以下两个条件： (1) G D ( D | A ) = G K ( D | R ) ； (2) 对于任意的 m ∈ R ， G K ( D | R − { m } ) ≠ G K ( D | R ) 。 称 R ⊆ A 为该决策系统的一个知识属性约简。 定义2.7 [ 8 ] 在给定的信息系统 I S = ( U , A ∪ D , V , f ) 中，若存在属性子集 c ∈ A ，则属性 c ∈ A 与决策属性D的相似度定义为： s ( c , D ) = | I N D ( D ∪ { c } ) | | I N D ( c ) | ⋅ | I N D ( D ) | 2.3. 知识粒度的启发式属性约简算法 [ 8 ] 根据知识属性约简的定义可得出一个属性约简算法，算法具体步骤如表1。 目前很多约简算法均要先求核属性，但该算法不需要。此算法在一定程度上减少了求核属性的工作量，同时时间复杂度相对缩减。"
"受表1算法的启发，以知识粒度 [ 7 ] 作为启发式函数进行遍历搜索，选取知识粒度值的大小进行比较，得出一个新算法—基于联合粒度属性约简算法。算法的具体描述如表2所示。 Table 1 输入：一个简单决策表 D T = ( U , C ∪ D , V , f ) 。 输出：条件属性C相对于决策属性D的一个相对约简 B ∈ R E D D ( C ) 。 1. 计算每个条件属性与决策属性的相似度 s ( c i , D ) 。 2. 然后根据每个条件属性与决策属性的相似度的值的大小将条件属性集进行降序排列 C = { c 1 , c 2 , ⋯ , c n } ,其中n是条件属性的个数。 3. 对属性约简 R E D D ( C ) 赋初始值 R E D D ( C ) = C ，冗余属性 C P = ∅ ，对此，检验 C 1 = ∅ ，然后对集合C中的每个条件属性属性 c i ，令 C m = R E D D ( C ) − c i ，执行下述操作： 3.1. 计算每个条件属性属性 c i 与集合 C m 中条件属性 c j 的相似度 s ( c i , c j ) ，然后与前面的 s ( c i , D ) 进行比较，若 s ( c i , D ) ≤ s ( c i , c j ) ，则将条件属性 c j 赋值给 C P ，将集合 R E D D ( C ) − c j 赋值给 C 1 ； 3.2. 接下来计算 s ( C 1 , D ) 是否与 s ( C , D ) 相等，如果相等，则删除条件属性 c j ，将集合 C 1 赋给 R E D D ( C ) ，反之将保留 c j ， R E D D ( C ) 保持不变； 3.3. 如果 C m 中的条件属性没有完成遍历，则直接转至步骤3.1，若完成遍历，则令 i = i + 1 ， C m = R E D D ( C ) − c i ，如果 C m = ∅ ，转步骤4，否则，转步骤3.1； 4. 算法结束，输出相对属性约简集合 R E D D ( C ) 。 表1. 基于知识粒度的启发式属性约简算法 [ 8 ] Table 2 输入：一个完备的决策信息系统 D T = ( U , A ∪ { d } , V , f ) 输出：属性约简结果 P = R E D A 1. 初始化 R E D A = ∅ ； 2. 根据知识粒度的定义，计算所有剩余属性的知识粒度值 G K ( A i ) ； 3. If G K ( A i ) < 1 then 4. 寻找第2步中的知识粒度最小的属性，记为 min ( A i ) ； 5. R E D A = R E D A ∪ min ( A i ) ； 6. 跳入第2步； 7. Else跳转步骤10； 8. Endif 9. 返回属性约简 R E D A 。算法结束。 表2. 基于联合粒度属性约简算法 基于联合粒度属性约简算法不同于上述表1，它主要从知识属性、粒计算 [ 9 ] 角度进行约简，可以直接对不同知识属性进行粒度和重要度的比较，同时使得约简过程更加精细，约简结果更加精确。 属性约简信息损失 [ 9 ] 定义3.1 [ 9 ] [ 10 ] [ 11 ] 在一个给定的决策系统 D S = ( U , A , d ) 中，设A和 { d } 在论域U上导出的划分分别为X和Y，其中 X = U / A = { X 1 , X 2 , ⋯ , X N } ， Y = U / { d } = { Y 1 , Y 2 , ⋯ , Y M } ， p ( X i ) = | X i | | U | ， p ( Y j ) = | Y j | | U | ， p ( X i , Y j ) = | X i ∩ Y j | | U | ， p ( Y j | X i ) = | X i ∩ Y j | | X i | ， i = 1 , 2 , ⋯ , N ， j = 1 , 2 , ⋯ , M . A和 { d } 的信息熵 [ 12 ] 分别可 定义为： H ( D S , A ) = − ∑ i = 1 N p ( X i ) l b p ( X i ) { d } 与A的联合熵 [ 13 ] 即可定义为： H ( D S , A , { d } ) = − ∑ i = 1 N ∑ i = 1 M p ( X i , Y j ) l b p ( X i , Y j ) 定义3.2 [ 9 ] [ 10 ] [ 11 ] 给定 D S = ( U , A , d ) 是一个决策系统， B ⊆ A 是该决策系统的一个约简，则 B ⊆ A 属性约简的信息损失定义如下： Δ ( B ) = H ( D S , A ) − H ( D S , B ) B ⊆ A 属性约简的信息损失率可定义如下： s ( B ) = Δ ( B ) H ( D S , A ) × 100 % = 1 − H ( D S , B ) H ( D S , A ) × 100 % 命题1 给定一个决策系统 D S = ( U , A , d ) ，若 B 1 ⊆ A 是基于正区域的相对约简， B 2 ⊆ A 是基于知识粒度的属性约简， B 3 ⊆ A 是基于联合粒度的属性约简，则有 Δ ( B 1 ) ≥ Δ ( B 2 ) ≥ Δ ( B 3 ) . 证明：根据知识粒度约简、联合粒度约简及正区域相对约简可证。 例1下表所示 D S 1 = ( U , C ∪ D , V , f ) 是一个决策表，如表3所示。U为论域，其中 U = { x 1 , x 2 , x 3 , x 4 , x 5 , x 6 , x 7 , x 8 } ， C = { e 1 , e 2 , e 3 , e 4 } 是条件属性， D = { d } 是决策属性集。 Table 3U e 1 e 2 e 3 e 4 d x 1 0 1 2 1 0 x 2 0 2 1 1 1 x 3 1 0 1 1 0 x 4 1 0 1 1 1 x 5 1 1 1 1 0 x 6 1 1 1 1 1 x 7 1 1 0 1 0 x 8 1 1 0 0 1 表3. 决策系统 D S 1 = ( U , A , d ) U / C = { { x 1 } , { x 2 } , { x 3 , x 4 } , { x 5 , x 6 } , { x 7 } , { x 8 } } U / { d } = { { x 1 , x 3 , x 5 , x 7 } , { x 2 , x 4 , x 6 , x 8 } } 由正区域的定义可得： P O S C ( d ) = { x 1 , x 2 , x 7 , x 8 } 。 根据条件属性依赖度的计算公式可得： γ C ( D ) ≠ 1 ，所以该决策表是不相容决策表。 (1) 根据知识粒度的属性约简算法可得约简后为： R 1 = R E D C = { e 2 , e 3 , e 4 } . 根据属性约简的信息损失的计算方法可得： H ( D S 1 , C ) = − ∑ p ( X ) l b p ( X ) = 2.5 H ( D S 1 , R 1 ) = − ∑ p ( X ) l b p ( X ) = 2.5 故 R 1 的信息损失量为： Δ ( R 1 ) = 0 。 (2) 由正区域约简算法可得： R 2 = { e 2 , e 3 , e 4 } ， R 3 = { e 1 , e 3 , e 4 } H ( D S 1 , R 3 ) = − ∑ p ( X ) l b p ( X ) = 2 故 R 2 的信息损失量为0。 R 3 的信息损失量为 Δ ( R 3 ) = 0.5 。 (3) 根据联合粒度属性约简算法可得： R 4 = { e 2 , e 3 , e 4 } 故 R 4 的信息损失量为0。 例2下表所示为一个决策表， D S 2 = ( U , A , d ) 是一个决策系统，如表4所示。U为论域， A = { α 1 , α 2 , α 3 , α 4 } 是条件属性， { d } 是决策属性集。 Table 4U a b c e d e 1 0 1 0 1 0 e 2 1 1 0 0 1 e 3 1 1 0 1 1 e 4 0 1 1 1 0 e 5 0 2 1 0 1 e 6 1 2 0 1 0 表4. 决策系统 D S 2 = ( U , A , d ) U / A = { { e 1 } , { e 2 } , { e 3 } , { e 4 } , { e 5 } , { e 6 } } ， U / { d } = { { e 1 , e 4 , e 6 } , { e 2 , e 3 , e 5 } } ， 由正区域的定义可得： P O S A ( d ) = { e 1 , e 2 , e 3 , e 4 , e 5 , e 6 } 。 根据条件属性依赖度计算公式得： γ A ( D ) = 1 ，所以该决策表是相容决策表。 H ( D S 2 , A ) = − ∑ p ( X ) l b p ( X ) = 2.585 (1) 基于正区域的相对约简： S 1 = { a , b } H ( D S 2 , S 1 ) = − ∑ p ( X ) l b p ( X ) = 1.918 故 S 1 的信息损失量为： Δ ( S 1 ) = 0.667 。 (2) 基于知识粒度的属性约简： S 2 = R E D A = { a , b , e } H ( D S 2 , S 2 ) = − ∑ p ( X ) l b p ( X ) = 2.252 故 S 2 的信息损失量为： Δ ( S 2 ) = 0.333 。 (3)基于联合粒度的属性约简： S 3 = { a , b , e } , S 4 = { a , b , c } H ( D S 2 , S 4 ) = − ∑ p ( X ) l b p ( X ) = 2.252 故 S 3 , S 4 的信息损失量为： Δ ( S 3 ) = Δ ( S 4 ) = 0.333 。"
"本节将采用一系列数据集进行验证本文所提出的算法的高效性和准确性。首先将本文提出的联合粒度属性约简算法与知识粒度属性约简算法、正区域相对约简算法 [ 14 ] 对同一组UCI数据集进行离散化处理，然后比较三种算法属性约简后的信息损失量从而验证本文算法的有效性。其实验平台的硬件环境为CPU Intel core i5和4 GB内存，操作系统为Windows 10专业版，实验所运用的编程工具为VC++6.0。 本次实验数据取自UCI数据集中的四组典型数据如表5所示。首先将每组数据集分成10等份，选择1份作为测试集，其他9份作为训练集，对这9份训练集进行联合粒度、知识粒度和正区域约简，然后比较它们约简后的信息损失量。 Table 5 序号 数据集名称 属性 对象 1 Dermatology 34 366 2 Contraceptive Method Choice 9 1473 3 Mushroom 22 8124 4 Letter Recognition 16 20000 表5. 数据集描述 文中采用重庆邮电大学开发的RIDAS系统进行属性约简。使用正区域约简算法、知识粒度约简算法和联合粒度约简算法求取不同属性约简集合。根据信息熵的计算公式，根据已有计算信息熵的程序代码 [ 9 ]，计算给定信息系统的条件属性集合的信息熵及每个约简后的信息熵，可得出不同约简准则的信息损失量的大小以及信息熵与信息损失率之间的关系。 图1~4分别表示四组数据集的约简准则与信息损失量仿真实验结果图，其中横坐标表示属性约简结果，纵坐标表示信息损失量大小。图5~8分别表示四组数据集约简后集合的信息熵与信息损失率仿真实验图，其中横坐标表示约简后信息熵，纵坐标表示信息损失率大小。 根据上述8张图示可以清楚地看出，本文提出的基于联合粒度属性约简的信息损失远小于基于正区域、基于知识粒度属性约简信息损失，从而说明本文提出的基于联合粒度属性约简算法的有效性，可以有效地解决大数据时代下海量数据的约简，减少约简导致的分类准确率较低、信息损失量较大的问题。 图1. Dermatology比较 图2. Contraceptive Method Choice比较 图3. Mushroom比较 图4. Letter Recognition比较 图5. Dermatology分析 图6. Contraceptive Method Choice分析 图7. Mushroom分析 图8. Letter Recognition分析"
"本文通过引入联合粒度的概念，并将其运用到粗糙集理论的属性约简 [ 15 ] 中，提出了基于联合粒度属性约简算法，然后分析比较不同的属性约简产生的信息损失，最终得到本文的基于联合粒度的属性约简不仅能保持数据分类的准确性，同时也能维持约简后的信息损失较低的结论。后续我们将继续研究该算法对带权决策表的约简信息损失的影响及进一步的优化。"
