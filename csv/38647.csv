"运用神经网络技术，建立基于主成分分析的长短期记忆神经网络(PCA-LSTM)模型并对股票开盘价格进行预测。实验采用五粮液(000858)股票，首先，利用主成分法对该股票的多个指标进行特征提取，然后利用提取的主成分建立LSTM神经网络模型，并与PCA-Elman、LSTM模型对比，结果发现PCA-LSTM模型的预测结果更好一些。"
"运用神经网络来预测金融数据成为当今热点，许多不同类型的神经网络算法也由此产生。股票市场一直受到投资者的青睐，股票价格的变化对投资者的收益有十分重大的影响，因此通过预测未来时刻股票价格进行规避风险是股票研究的一项重要内容 [ 1 ]。学者们认为神经网络可以被人们广泛利用，能较好的优化网络结构。 由于股票数据的特殊性，会受到很多因素的影响，宏观上来看，社会、政治、经济和文化等方面会影响市场价格。微观上看，产业发展前景和区域经济发展状况以及市场等因素也会影响股市。这就使得我们在选取输入变量的时候，容易导致信息量过于庞大，使得神经网络结构过于复杂，加重了神经网络的训练负担，学习速度就会急剧下降；并且，主观上的选择可能影响输入变量与输出变量的相关性，从而导致神经网络运行效率和预测精度变低。 针对这一问题，引入了统计学中的主成分分析法(PCA)，对影响数据的输入变量先进行筛选，通过降维的方法挑出较少的变量，而这些变量对整体数据有85%以上的贡献值，减轻了神经网络的训练负担，并提高了学习率。在降维后使用长短期记忆网络的输入参数减少，提高了网络的运行效率和预测精度。同样对比不降维直接将数据在LSTM中训练，我们就可以发现PCA-LSTM的优点，本文还将引入PCA-Elman网络，对比其他模型的预测精度。"
"主成分分析(Principal Component Analysis, PCA)是比较常用的降维方法，它将原变量的相关性进行转换从而使得维数减少，转换以后的变量叫做主成分。 主成分分析定义如下： 设d维随机变量 X = ( X 1 , X 2 , ⋯ , X d ) T ，对原始空间进行线性变化。变换 d ′ ( ≤ d ) 维的随机变量 Y = ( Y 1 , Y 2 , ⋯ , Y d ′ ) T 。 Y = W ′ X ， 其中 W ∈ R d × d ′ 是变换矩阵， W = [ W 1 , W 2 , ⋯ , W d ′ ] ， W i 是d维列向量。 设X的协方差矩阵为 Σ ，随机变量Y的协方差矩阵为 D ( Y ) = D ( W T X ) = W T D ( X ) W = W T Σ W ，于是优化目标为 max t r ( W T Σ W ) 根据拉格朗日乘子法有 L ( W ) = t r ( W T Σ W ) − λ ( W T W − I ) ∂ L ( W ) ∂ W = 2 Σ W − 2 λ W = 0 于是得 Σ W = λ W 这样通过求 Σ 的特征根和特征向量就可以解出W，将求得的特征值进行排序： λ 1 ≥ λ 2 ≥ ⋯ ≥ λ d ，取前 d ′ 个特征值对应的特征向量构成 W = ( w 1 , w 2 , ⋯ , w d ′ ) ，这就是主成分的解。 解出W后， Y i = w i T X , i = 1 , 2 , ⋯ , d ′ ，于是有 D ( Y i ) = D ( w i T X ) = w i T D ( X ) w i = w i T Σ w i = w i T λ i w i = λ i 且 cov ( Y i , Y j ) = 0   ( i ≠ j ) ，可知 Y 1 是方差最大的，为第一主成分，以此类推。 实际中我们用样本方差矩阵估计。 取n个样本，得到样本观测值为 X = [ x 11 x 12 ⋯ x 1 d x 21 x 22 ⋯ x 2 d ⋮ ⋮ ⋱ ⋮ x n 1 x n 2 ⋯ x n d ] 每行为原始d维随机变量的一个观测值，这里用X表示数据矩阵。 确定W后，将原始数据矩阵X降维后得到： Y = W T X T = [ y 11 y 21 ⋯ y n 1 y 12 y 22 ⋯ y n 2 ⋮ ⋮ ⋱ ⋮ y 1 d ′ y 2 d ′ ⋯ y n d ′ ] 这样原始数据就由d维降到 d ′ 维 X = [ x 11 x 12 ⋯ x 1 d x 21 x 22 ⋯ x 2 d ⋮ ⋮ ⋱ ⋮ x n 1 x n 2 ⋯ x n d ] → [ y 11 y 21 ⋯ y n 1 y 12 y 22 ⋯ y n 2 ⋮ ⋮ ⋱ ⋮ y 1 d ′ y 2 d ′ ⋯ y n d ′ ]  LSTM (Long Short-Term Memory)是长短期记忆网络，是一种特殊的递归神经网络，与常规递归网络相比能够有效地解决长时间依赖数据信息的问题，防止训练过程出现梯度消失和梯度爆炸的问题。 LSTM神经网络含有智能网络单元，因为它可以记忆不定时间长度的数值，网络单元中的gate可以决定input能否能被记住以及output能否被输出，是一种通过门控状态控制传输状态的神经网络。 LSTM在算法中加入“cell”处理器，包含三扇门： 1、遗忘门(Forget Gate)，是LSTM的忘记阶段，对上一节点 f t 的输入信息选择性忘记，留下有用的信息，优化了数据信息。 2、输入门(Input Gate)，是LSTM的记忆阶段，随着时间对 i t 来不断更新状态值Ct，选择留下有用的状态值，抛弃无用的数值。 3、输出门(Output Gate)，是LSTM的输出阶段，经遗忘门和输入门对信息 o t 的不断筛选过滤，最终决定当前状态的输出 h t 。 最重要的是遗忘门(Forget gate)，遗忘门不受人为因素的干扰，自行决定保留多久的记忆 [ 2 ]。"
"本文选取五粮液(000858) 2017年5月5日到2020年10月12日共836个交易日的数据。分别用开盘价、收盘价、最高价、最低价、成交量、MA.MA1、OBV.OBV、MACD.DIFF、KDJ.K、等9个指标预测未来5日股票的开盘价。我们选取开盘价为输出变量，其他指标作为输入变量。图中可以看出五粮液股票的开盘价格浮动没有明显的规律。  首先把数据作标准化处理，采用“max-min标准化”方法，这样处理数据消除了量纲的影响，但不改变数据的原始意义。 标准化后的数据进行主成分分析将原来9维的数据降到了3维，贡献率已达到95%。降维后将数据输入到LSTM神经网络中进行训练，选取前831个数据作为训练样本，后5个数据作为测试样本，采用前一日的特征指标来预测下一日的股票开盘价格。PCA-LSTM选取Adam作为优化器，经过多次尝试训练，发现当初始学习率为0.008，迭代次数为200次的时候效果最佳。结果如图：  同样，若不对数据进行主成分分析，在数据标准化之后直接在LSTM神经网络里进行训练，选取参数不变的情况下，得到如图所示的预测效果： Elman网络包含输入层、中间层(隐藏层)、承接层和输出层。Elman对比静态的BP网络，由于它增加了一个承接层当作一种延时算子，具有记忆的功能 [ 3 ]，记忆隐含层前一时刻的输出，对历史的状态比较敏感，由于不断更新网络状态，从而增加了网络处理动态信息的能力。Elman网络结构如图： 将数据用PCA-Elman神经网络训练，结果如下： 我们预测了五粮液2020年9月28日到10月12日共5日的开盘价格，将三种模型的预测值放到如下表格： 从表格中我们也可以知道PCA-LSTM模型的拟合效果最好，较比于LSTM和PCA-Elman模型误差也是最小的，对五粮液股票数据的开盘价格预测效果最佳。"
"本文建立了PCA-LSTM、PCA-Elman和LSTM神经网络模型，LSTM是解决长序依赖问题的有效技术。对比试验发现PCA-LSTM对五粮液股票价格的预测精度更高，对于数据波动较大的开盘价格有较好的预测。由于长短记忆网络的适用性比较广，导致模型的变化程度也比较高。后期考虑加入对股票影响大的新闻、市场指数等特征来训练模型，希望能提高模型对股价预测的精准度，给股民的选择带来更有价值的参考 [ 4 ]。"
