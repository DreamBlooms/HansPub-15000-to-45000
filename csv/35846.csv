"过去，语料库曾经是少数专业人士如语言学或语言测试学专家使用的工具；但现在随着电脑技术的广泛普及和教学理念的更新，基于语料库的研究方兴未艾。语料库的数据统计和分析功能使得对英语教材的评估变为现实。本文主要探讨通过自建语料库的方法，对《PrepEdge Bridging》写作教材的中等频率的词汇难度和分布情况进行评估和研究，以及基于此数据和给教材编写者、教材使用者以及学生提出可优化的建议。 关键词 :教材，词汇，难度，频率，语料库，索引 Copyright © 2020 by author(s) and Hans Publishers Inc. This work is licensed under the Creative Commons Attribution International License (CC BY 4.0). http://creativecommons.org/licenses/by/4.0/"
"自上世纪90时代开始，语料库语言学以及电脑技术蓬勃发展。语料库曾经是一片无人熟知的领域，而现在无论在语言学还是外语教学，语料库都占有一席之地，且势头越演越烈。语料库研究属跨学科的研究，涉及到语料库的建库方法以及学习者语料库的分析研究，其理论基础涉及到语言学和教学法的相关理论。如今，现在便捷的电脑技术，辅以语料库相关知识和软件，可以使任意一名普通的语言研究者能够更好地量化教学效果。借助语料库他们可以对教学过程有更全局的了解，以量化的方式评估和测量。值得一提的是，基于语料库的研究和应用对外语教学带来了许多革新性的影响。本文旨在讨论语料库的建库方法，分析英语教材词汇难度和词汇分布情况，基于语料库图示和数据分析来提供相应的优化解决方案 [ 1 ]。  从字面上来看，语料库“corpus”一词在拉丁文原意为“主体，躯体”。如今corpus指的是经文本处理，以电子形式储存的大型文本库。人们会误以为语料库就是本文的集合。狭义来讲，文本集合不完全等同于语料库 [ 2 ]。具体来说，语料库的文本，都是根据特定的采样标准，为了达到特定目的而收集建设的。这些文本都是以电子形式储存，是所研究的目的语言的缩影。通过对这些样本的分析研究，我们旨在发觉目的语言的内在规律特点，而这些特点都是可延伸，可扩展到语言本体的。 总的来说，语料库软件是教材编纂者和教材使用者分析语言的利器。比如说单语语料库软件AntConc就是最好的例子。AntConc由日本早稻田大学的Laurence Anthony教授开发。AntConc最初运行于Windows系统和Mac系统。现已发展为世界知名的多功能语料库软件 [ 3 ]。  教师可以借助AntConc进行各种各样的语言研究和实验，如编纂相关文本和教材的高频词表和关键词表等。文本的关键词可以通过AntConc的KWIC板块呈现出来。以《PrepEdge系列托福直通车：进阶写作》(下面简称为《Bridging》)为例，我们可获得教材文本的高频词汇表(图1) [ 4 ]。 图1. AntConc的高频词表界面 如果我们要查看这些关键词在具体的语境的句子，我们可以点开关键词如understand，打开索引(concordance)界面查看，具体语句如下(图2)： 图2. AntConc的索引界面 上述这些基本功能如索引和词表编纂就是语料库的常规功能，不过这些都只是冰山一角。接下来我们来看一个关键的功能：索引标记图(concordance plot)。  索引标记图(concordance plot)是语料库软件AntConc的一个特有功能，就是可以通过可视化的条纹状的方式，显示出特定某个单词在整篇文章或者整本书的分布情况，比如下图是“species”一词在《剑桥雅思官方真题集14》 [ 5 ] 整套真题中的出现位置和频率(图3)： 图3. AntConc的索引标记图界面 根据AntConc这幅图，不难发现“species”这一词非常高频，这意味着使用《剑桥雅思官方真题集14》备考雅思的学生几乎隔三差五就会遇到它。如果考生刷完整本书就会遇到“species”共31次，那么他们想不熟悉这个单词也难。 这项索引标记图的功能对于教材评估也有重大意义。根据Paul Nation的观点，编写教材的核心原则之一是“spaced retrieval”，意思是：教材编纂者在设计内容时，需要故意地让一些目标语言(target language)词汇高频地出现，让读者或学习者能够不断遇到这些表达，对学习者起到一个唤醒的作用 [ 6 ]。更重要的是，Paul Nation认为这种对于语言的唤醒是“潜意识的”，有助于学生的词汇学习。对于教师而言，这样的重复可以让老师有根据去要求学生多去系统地复习，为教学效果提供了有力的支持；对于教材编纂者而言，这样的重复也是提高了教材的衔接与连贯性，确保整本书的语言表达都是连贯的。"
"为了进一步评估《Bridging》教材，我们需要把整本教材转化为语料库工具可以读取的格式，这里就涉及到自建语料库的基本操作。 通常来说，有以下几个关键步骤： 1) 了解和检查语料库文本； 2) 选择语料文本； 3) 文本整理与清洁。 首先，我把《Bridging》写作教材的原稿word文档进行检查，确保文稿的完整性，以及确保文稿内容和出版物正文的版本一致，没有关键信息的遗漏。其次，我把原稿中一些无用信息如中文标记、编辑批注等内容进行清除，确保我所选择的是教材中的核心英语文本。第三，我把《Bridging》写作教材原稿的word文档转换为txt格式，这是因为虽然word文档向来以编辑方便和易于标记而著称，然而作为本次研究关键工具AntConc只能和txt文档兼容，也就说所有的word文档必须转换为txt文档。而且大多数情况下，txt文档可以轻松地消除word文档中的冗余信息，格式不统一等情况 [ 7 ]。 在转换文档的过程中，文档格式错误是值得注意的问题。尤其是汉语和英语的符号混用问题必须小心处理，不然文档的格式错误会损害最终数据的准确性。在作文数量不大的情况下，人工剔除和转换是可接受的。但在应对规模较大的语料库文本时，我们可以借助风林开发的TextEditor软件来处理(图4) [ 8 ]。 图4. TextEditor的基本界面 通过TextEditor轻松点击鼠标便可解决文本中信息冗余和格式错乱的问题。  接下来，通过AntConc工具我们可以生成一份《Bridging》写作教材的词汇表(图5)。但值得注意的是，有一些词汇是超高频出现的，比如像“the”“of”“and”等等，平均出现频率高达几百次。但事实上，针对CEFR-B1水平的学生，他们不会对这些词汇感到陌生，这也不是他们的障碍词汇(blocking vocabulary)，更不是教师想让学生重点学习的内容。 图5. AntConc的词频界面 和大众的认知相反，其实无论是标准化英语考试还是英语学习教材，其中的“中低频词”才是学生需要进一步关注和背诵掌握的内容，那么这一块正是本文研究的重点(图6)。鉴于《Bridging》这套教材最开始设计之初是针对CEFR-B1水平的学生，而且对他们比较难的也就是“低频词”(blocking vocabulary)已经被提取了出来放在《Bridging》教材后面作为附录的单词表。这部分词汇很大程度上是和单元话题紧密相关，也就是说除了在特定单元出现，他们几乎不会贯穿整本书，所以自然也不是本文研究的主体对象。 图6. 《Bridging》写作教材Unit 09 词汇表部分截图 因此，除去前文所说的“超高频词”和 “低频词”，本文通过AntConc工具、excel表格和人工筛选，可以获得这本教材的“通用中频词”，也就是本文研究的主体对象。具体来说，这批通用中频词的定义和特征是： 1) 词汇频率：在整篇教材中出现频率介于4~14次(这个数字是词频表的均值，说明在词汇教材有一定重复性)； 2) 词汇等级：在CEFR [ 9 ] 中属于B1及以上难度的词汇(相当于大学四六级词汇，适合B1水平学生)； 3) 有助于学生考试写作、属于学生需要掌握的积极词汇(active vocabulary)。 这批词表共有40个通用中频词，其中这些词已经经过lemmatization处理，比如“benefits”等含有单复数的形态会归到“benefit”词条中。具体请看表1： Table 1 序号 频率 单词 CEFR级别 1 14 affect B2 2 14 issue B1 3 13 claim B2 4 13 identify B2 5 13 interact B1 6 12 significant B2 7 11 current B2 8 11 damage B1 9 11 fund C1 10 11 source B2 11 10 benefit B1 12 10 distract B2 13 9 argue B1 14 9 financial B1 15 8 bond B2 16 8 constantly B2 17 8 personality B2 18 8 participate B2 19 8 campus B2 20 7 determine C1 21 7 effort B1 22 7 harmful B2 23 7 variety B1 24 7 consequence B2 25 7 competitive B2 26 6 career B1 27 6 engage C1 28 6 motivate C1 29 6 device B2 30 6 beneficial B2 31 5 guarantee B2 32 5 resource B2 33 5 factor B2 34 5 aspect B2 35 4 evidence B2 36 4 expose B2 37 4 sustainable C1 38 4 facility B1 39 4 essential B1 40 4 address C1 表1. 《Bridging》写作教材的中频词频率以及词汇难度  这一批通用中频词都基本属于B1~B2的难度，是托福初级班的学生可以优先掌握并且用在作文中的语言表达。而这恰恰证明了教材编纂者在处理语料时，是有较为严格的控制的。从应试角度来看，学生如果可以用好这批B1~B2的词汇，就已经可以进一步丰富表达多样性和语言准确性，并非一定要用很难的C1~C2词汇，这一点值得广大《Bridging》教材使用者注意。 另一方面，根据AntConc索引标记图的统计数据(具体请看附录1)，在这40个中频词的研究中：1) 只有4个单词(10%)的出现是贯穿整本书，满足“全局分布均匀合理”的要求，意味着学生能较为容易地自主发现单词有重复，教材前后有衔接；2) 有24个单词(60%)是“全局分布不合理”，编排不够科学，分布规律不明显，学生不容易发现单词存在跨单元的记录，不容易有连贯性和衔接；3) 有12个单词(30%)属于“全局分布一般”，虽然分布有瑕疵，但是在老师引导下学生依然能够发现词汇的重复，达成Paul Nation所主张的“spaced retrieval”的原则。  针对教材编纂者，本文建议考虑把上述那些属于“全局分布不合理”以及“全局分布一般”的单词做进行调整和处理，具体步骤为： 1) 获取选中单词的N-gram高频短语； 2) 根据AntConc测算单词出现过的单元/未出现的单元； 3) 把N-gram高频短语根据单元主题安插对应的单元正文。 下面以address (v. 解决，处理)一词为例： 首先，根据NLP (Natural Language Processing)的N-gram原则，通过语料库算法找到“address”作为动词时最高频的短语搭配用法如下(图7)： 图7. “address”一词的N-gram高频短语在Writefull软件 [ 10 ] 的结果 由此我们可以得出，“address”作为动词的常见宾语搭配为：issue/problem/question/needs等。 其次，通过AntConc测算出“address”出现过的和未出现过的单元(图8)： 图8. “address”一词在AntConc的索引标记图 e.g. “address”首次出现在Unit 6，Page 74，para 2，line 8，“address induvial student preferences”(图9)。 图9. “address”一词在《Bridging》教材的出现语境1 第二次在Unit 7，Page 92，ex. 5 para 1，line 1，“address the topic of”(图10)。 图10. “address”一词在《Bridging》教材的出现语境2 第三次出现在Unit 8，Page 124，ex. 7 para 2，“address … sites”(图11)。 图11. “address”一词在《Bridging》教材的出现语境3 第四次出现在Unit 10，Page 132，Health Care最后一句话，“address aspects”(图12)。 图12. “address”一词在《Bridging》教材的出现语境4 根据上述调查可以发现，“address”未出现的单元为：Units 1~5，9； 第三，结合《Bridging》写作教材的单元话题，教材编纂者可以把N-gram列表中出现过的合适短语(e.g. address the problem/needs)插入到Unit 1~5中。 具体来说，可以在Unit 3 Page 38综合写作句式中加入“address the problem”： 可以在Unit 4 Page 51的段落中加入“address the emotional needs”： 经过这一番调整，教师在备课时，以及学生在上课阅读教材文本时，两者都会更频繁地接触到在不同的单元出现的“address”。通过减少目标单词两次出现的间隔，学生对这部分词汇短语会有机会更容易被唤醒，对语言使用的连贯性会更强；所以，教材编纂者也可以尝试在教材的更新改版时，把对“全局分布不合理”或者“全局分布一般”单词进行局部微调，用同样的方式进行适当的增减，提高学生的“spaced retrieval”意识。 此外，关于授课老师，本文建议在处理这批中频词或者其他类似的内容时，如果老师想要巩固学生对特定目标语言的掌握，授课教师可以人为地在一些特定单元的特点节点，对长期未出现的单词进行语料补充和单词检测，并且积极鼓励学生在习作中使用这些中频词表达，以此达到均匀分布精准学习的效果。"
"基于语料库等科技手段来筛选词比人主观去选词会更全面客观一些，但是如果教材单元是按照主题来进编写，无可避免地某些词汇集中在某一主题单元出现，想要达到整本书都能隔三差五出现这些词确实有点困难，而且坚持语料库这个标准筛词有可能主观地筛掉对于某主题来说是很关键核心的词。所以在进行该项研究时，研究者所选出来的中频词则必须是比较通用的，不太受到单元或者话题的限制。而正因为如此，这些单词才更需要被增加频率，达到比较均衡的分布。还需要进一步更细致的研究。"
