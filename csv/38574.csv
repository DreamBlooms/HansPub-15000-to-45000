"时间序列是指将某种统计指标的数值按照时间顺序排列所形成的序列，对时间序列进行分析预测有助于我们提前判断、减少潜在风险，在生产和生活中都有着重大的意义。常见的时间序列数据包括股票数据、商品日销量以及每日的气候等等。其中股票数据是一个高度复杂的非线性系统，对股票长期趋势的预测一直是一个令人感兴趣的话题。本文以股票收盘价数据为例，提出一种新的思路，对时间序列数据进行建模并预测。首先采用B样条回归对股票价格与时间变量之间的非线性关系进行建模。由于B样条曲线只能在一个提前给定的区间内进行拟合，对区间外的预测问题无能为力，因此，为解决这个问题，本文将B样条回归与长短期记忆(Long Short-Term Memory)神经网络模型相结合，构建LSTM-Bspline模型，通过训练神经网络来获取B样条曲线的参数，从而获得预测值。最后通过对某公司股票每日收盘价数据进行分析预测，并将预测结果与经典LSTM神经网络预测结果相比较，证明了LSTM-Spline模型的可行性。"
"时间序列是指将某种统计指标的数值按照时间顺序排列所形成的序列，如股票收盘价、商品日销量以及每日的气候等等。而时间序列预测法就是通过处理和分析时间序列，提取出时间序列所蕴含的数据特征、发展方向和趋势等信息，进行类推或延伸，借以预测下一时间段内或以后若干时间段内数据可能达到的水平 [ 1 ]。 1927年数学家耶尔为了预测市场变化的规律，提出的自回归(Autoregressive)模型，首次提出了系统的时间序列分析方法。紧接着，在自回归(AR)模型的基础上，1931年Walker，建立了滑动平均(Moving Average)模型 [ 2 ]。20世纪70年代G. P. Box和G. M. Jenkins发表了著作《Time Series Analysis: Forecasting and Control》 [ 3 ]，在书中对于平稳的时间序列数据提出了和自回归滑动平均(Autoregressive Moving Average)模型，并且建立了一套完整的建模、估计、检验和控制的方法。随后为了应对非平稳时间序列，又出现了更为完善的差分整合滑动平均自回归(Autoregressive Integrated Moving Average)模型。 上述传统时间序列模型在大量不间断数据的基础上，拥有较高的预测精度，但是需要复杂的参数估计，而且计算出的参数不能移植 [ 4 ]。 非参数回归是一种适合不确定的、非线性的动态系统的建模方法。它包括局部回归、光滑样条和正交回归等。非参数回归不需先验知识，只需足够的历史数据，寻找历史数据中与当前点相似的“近邻”，并用这些“近邻”进行预测。1991年，Davis和Nihan [ 5 ] 将非参数回归应用在了时间序列分析中。 20世纪40年代，诞生了一种新的方法：人工神经网络。1987年Lapedes [ 6 ] 等人最早将神经网络应用于时间序列预测，但只针对仿真数据进行了研究。1988年Werbos [ 7 ]，1990年Varfis和Versino [ 8 ] 分别对真实时间序列数据进行了预测研究。1990年Weigend [ 9 ] 等人针对太阳黑子的年平均活动数据，将神经网络与回归方法作了对比，得出神经网络预测优于统计预测。1991年，Matsuba [ 10 ] 等人将神经网络应用到股票预测。 循环神经网络(Recurrent Neural Network)是一类专门用于处理序列数据的神经网络，与传统神经网络相比，循环神经网络具有记忆功能，可以考虑历史序列的信息，更加注重挖掘样本之间的时序关联 [ 10 ]。循环神经网络可以处理任意长度的序列数据，因此，在视频 [ 11 ]、语音 [ 12 ] [ 13 ] 和文本 [ 14 ] 等序列数据中都有着广泛的应用。 但是循环神经网络也有局限性，由于其自身结构的复杂，导致其存在梯度消失的问题，当输入序列数据过长时，距离某时刻较远的序列信息会被弱化甚至忽略，因此循环神经网络无法“记忆”距当前时刻较远但重要的信息 [ 15 ]。为了解决这个问题，2012年，Graves A [ 16 ] 提出了长短期记忆(Long Short-Term Memory)神经网络，通过引入线性连接和门控单元来解决梯度消失问题。 股票走势的预测问题一直是金融市场感兴趣的问题之一，一方面股票价格直接影响投资者的经济利益，另一方面股票价格也反映着国家的经济状况以及不同行业的景气情况。因此，建立适当的模型对股票价格进行预测，对于投资者把控投资方向以及国家经济政策的调整有着重大的研究意义。 本文将非参数回归中的B样条方法和当前流行的长短期记忆神经网络结合，构建了LSTM-Bspline模型以一种新的思路来对某公司股票收盘价数据进行分析并预测，并将预测结果与经典的长短期记忆神经网络相比较，证明方法的适用性。本文其余内容如下：第2部分，我们介绍B样条方法和长短期记忆神经网络的相关概念与定义。第3部分，将B样条与长短期记忆神经网络相结合，构建出LSTM-Bspline模型。第4部分以某公司股票的每日收盘价数据为例，分别使用LSTM-Bspline模型和LSTM模型进行预测，并将结果进行比较，证明本文所提出方法的有效性。第五部分对本文的研究进行总结，指出模型的不足和未来的研究方向。"
"在不失一般性的前提下，假设函数 f ( x ) 定义域为[0, 1]，多项式样条是指在一组内部节点上平滑连接的分段多项式，本文采用多项式样条中的B样条，因为它具有稳定的数值性质。 对于B样条，假设把定义域[0, 1]分成M段，内节点为 0 < j 1 < ⋯ < j M − 1 < 1 。则对应的B样条基函数可以表示为 B 1 ( x ) , ⋯ , B M + d + 1 ( x ) ，B样条基的定义由de Boor [ 17 ] 导出： B i , 0 ( u ) = { 1 ,         j i ≤ u ≤ j i + 1 0 ,             other B i , d ( u ) = u − j i j i + d − j i B i , d + 1 ( u ) + j i + d + 1 − u j i − j i + 1 B i + 1 , d − 1 ( u ) , d > 0 约定0/0 = 0，其中d是B样条的次数， j i 为节点。每个B样条基函数都具有局部支撑性，并且对于任意相邻的节点 j i − 1 , j i ( 1 ≤ i ≤ M + 1 ) ，除了基函数 B j ( x ) , ⋯ , B j + d + 1 ( x ) 外，其余基函数在区间 [ j i − 1 , j i ] 都为零。 设G是B样条基函数 { B j ( x ) , j = 1 , ⋯ , M + d + 1 } 在[0,1]上张成的线性空间。假设 f ( x ) 可以被G中的元素近似，则： f ( x ) ≈ ∑ j = 1 M + d + 1 γ j B j , d ( x ) (2.1)  在上述(2.1)式中的参数可以通过最小二乘准则估计出，即最小化下式： 1 n ∑ i = 1 n ( Y i − ∑ j = 1 M + d + 1 γ j B j , d ( X i ) ) 2 = 1 n ‖ Y − B γ ‖ 2 2 (2.2) 其中 γ = ( γ 1 , ⋯ , γ M + d + 1 ) T 表示系数向量，B表示矩阵 ( B ( X 1 ) , ⋯ , B ( X n ) ) T ，其中 B ( x ) = ( B 1 ( x ) , ⋯ , B M + d + 1 ( x ) ) T 。 Y = ( Y 1 , ⋯ , Y n ) T 表示响应变量。如果直接通过(2.2)式对时间序列数据进行拟合，往往难以取得较好的效果，原因在于对于不同的时间点t，如果使用一组统一的系数 γ = ( γ 1 , ⋯ , γ M + d + 1 ) T ，会使得总体误差比较大。  LSTM (长短期记忆神经网络)是一类用于捕获时序数据中长期和短期依赖关系的RNN (Recurrent Neural Network)模型，近年来，在语音识别，机器翻译等领域取得了巨大的成功。从数学上来讲，LSTM是一个高度复合的非线性参数函数，它将一列向量 ( x 1 , ⋯ , x n ) 通过隐含层 ( h 1 , ⋯ , h n ) 映射到另一组向量 ( y 1 , ⋯ , y n ) 。LSTM神经网络内部结构如图1： 图1. LSTM神经网络内部结构 LSTM神经网络由相互联系的递归子网络，即记忆模块组成，记忆模块主要包括三个门：遗忘门，输入门，输出门，和一个记忆单元。 RNN模型是LSTM模型的底层结构，函数形式为： h j = σ h ( W h x j + U h h j − 1 + b h ) y j = σ y ( W y h j + b y ) 其中 W h , U h , b h , W y , b y 表示参数， σ h , σ y 是非线性激活函数，上式模拟了 x 1 , ⋯ , x n 与 y 1 , ⋯ , y n 之间的非线性函数关系。可以通过将这种结构进行多次叠加，得到多层或分层RNN模型。 LSTM是RNN结构的扩展，具体函数形式为： f j = σ g ( W f x j + U f h j − 1 + b f ) , i j = σ g ( W i x j + U i h j − 1 + b i ) , o j = σ g ( W o x j + U o h j − 1 + b o ) , g j = σ h ( W g x j + U g h j − 1 + b g ) , c j = f j ∗ c j − 1 + i j ∗ g j , h j = o j ∗ σ h ( c j ) , 最后输出值 y j 是一个关于 h j 非线性函数，即： y j = σ h ( W h h j + b y ) 所有的W，U，b代表参数， σ g , σ h 代表非线性激活函数，本文中分别采用了logistic函数和tanh函数。Logistic函数和tanh函数是神经网络中最常用的两个激活函数，这些激活函数的多个组合可以逼近输入向量和输出向量间复杂的非线性关系。"
"对于一组时间序列数据 { y 1 , y 2 , ⋯ , y n } ，将其对应的时间变量设为 { 1 , 2 , ⋯ , n } ，假设对未来k个时间点的值 { y n + 1 , y n + 2 , ⋯ , y n + k } 进行预测，即预测时间点 { n + 1 , n + 2 , ⋯ , n + k } 对应的值。 首先将区间 [ n + 1 , n + k ] 分割成M个子区间，其中节点为 { n + 1 ≤ j 1 ≤ ⋯ ≤ j M − 1 ≤ n + k } ，则对应的B样条基函数可以表示为 B 1 ( x ) , ⋯ , B M + d + 1 ( x ) ，d为B样条的次数，则根据(2.1)我们可以建立如下函数关系 y t = f t = ∑ j = 1 M + d + 1 γ t , j B j , d ( t ) ,     t ∈ { n + 1 , ⋯ , n + k } 其中 γ t , 1 , ⋯ , γ t , M + d + 1 为时变参数，表示t时间B样条基的系数。 而对于数据 { y 1 , y 2 , ⋯ , y n } ，我们将其以k个值为一组等分，共得到n/k组数据，分别设为第1，2，…，n/k组，对每组数据采用B样条拟合，其中每组数据的节点间隔同区间 [ n + 1 , n + k ] 的节点间隔相同，并且每组数据对应一组B样条基函数，则对于第i组数据，可以得到以下函数关系： y t = f t = ∑ j = 1 M + d + 1 γ t , j B i , j , d ( t ) ,     t ∈ { k ( i − 1 ) + 1 , ⋯ , i k } 其中 B i , j , d ( t ) ( j = 1 , ⋯ , M + d + 1 ) 为第i组B样条基函数。 通过将上式子整合，在区间 [ 1 , n + k ] 上，可以用一个方程来表示 y t 与t的关系： 设将 y t 所在的组为第 i t 组，则： y t = f t = ∑ j = 1 M + d + 1 γ t , j B i t , j , d ( t ) ,     t ∈ { 1 , 2 , ⋯ , n + k } 其中 B i t , j , d ( t ) 为 y t 所在的组对应的B样条基函数，而 γ t , 1 , ⋯ , γ t , M + d + 1 仍为时变参数，表示t时间B样条基的系数。 下面要解决的关键问题就是时变参数 γ t , 1 , ⋯ , γ t , M + d + 1 的获取问题，显然参数 γ t , 1 , ⋯ , γ t , M + d + 1 依赖于过去的时间序列数据 y t − 1 , y t − 2 , ⋯ ，为了对这种依赖关系建模，我们从 y t − 1 , y t − 2 , ⋯ 中选取了一段固定长度的子序列来构造一个特征向量序列。假设选取的长度为L，可以构造出以下长度为L的特征向量序列： x 1 t , ⋯ , x L t = [ y t − L ( y t − L − y t ¯ ) 2 ( y t − L − y t ¯ ) 3 ( y t − L − y t ¯ ) 4 ] , ⋯ , [ y t − L ( y t − L − y t ¯ ) 2 ( y t − L − y t ¯ ) 3 ( y t − L − y t ¯ ) 4 ] ,     y t ¯ = 1 L ∑ i = 1 L y t − i 构造的依据是提取与过去L个样本的第一阶，二阶，三阶，四阶中心矩有关的信息。在这种构造下，我们将 x 1 t , ⋯ , x L t 作为LSTM单元的输入，将 γ t , 1 , ⋯ , γ t , M + d + 1 作为LSTM单元的输出： [ γ t , 1 , ⋯ , γ t , M + d + 1 ] T = tanh ( W o h t + b o ) ,         h t = LSTM Θ ( x 1 t , ⋯ , x L t ) 其中 Θ 表示LSTM参数， h t 代表最后的隐藏状态， W o , b o 代表输出层参数，上述一系列参数可以通过最小二乘准则获得，即： min Θ , W o , b o 1 n ∑ t = 1 n ( Y t − ∑ j = 1 M + d + 1 γ t , j B i t , j , d ( t ) ) 2 经过对模型的训练，对于要预测的序列 { y n + 1 , y n + 2 , ⋯ , y n + k } 任意 y t ( t = n + 1 , ⋯ , n + k ) ，B样条的时变参数 γ t , 1 , ⋯ , γ t , M + d + 1 可以通过用训练获得的模型参数 Θ ^ , W ^ o , b ^ o 计算出来，从而获得预测值。"
"本文选取了某公司股票1750个数据进行研究，将其中五分之三的数据作为训练集，五分之一作为验证集集，五分之一作为测试集。分别用LSTM模型与LSTM-Spline模型进行预测，比较分析预测结果。  由于我们采取的LSTM激活函数是tanh，输出结果为−1到1之间，所以对数据进行归一化处理，同时归一化处理可以提升网络学习的速度，加快收敛。具体方法如下： y = y max − y y max − y min  本文提出的模型超参数有三个：1，用于预测下个时间点的前一段时间序列的长度L；2，LSTM神经网络隐含层的维数H；3，定义B样条基函数时的节点选取，为了计算方便，我们统一选择等距节点，节点之间的间距为D。则模型可以表达为LSTM-Spline (H, L, D)。 超参数的调优在以下集合中进行： L ∈ { 40 , 60 , 80 , 100 } ， H ∈ { 8 , 16 } ， D ∈ { k / 2 , k / 5 , k / 10 } ，其中k表示测试集的长度。  在尝试了不同的超参数组合后，选取效果最好的一组超参数，运行的结果如图2，图中纵轴数值为归一后的值。左图为LSTM-Spline模型的结果，右图为LSTM模型的结果。其中橙色曲线代表归一化后实际值，蓝色曲线代表归一化后的预测值。  通过观察可以发现，LSTM-Spline程序的结果可以大致预测出未来一段时间的股票的走势，虽然具体数值有些偏差，但是趋势正确。与传统LSTM模型结果相比误差更小。通过计算两模型结果(归一化后)的MSE (均方误差)，结果如表1，证明了我们的观点。 图2. LSTM-Spline模型与LSTM模型运行结果 Table 1 模型 均方误差 LSTM-Spline 0.0013 LSTM 0.0044 表1. 两模型结果均方误差对比"
"本文提出了一种新的思路来对股票价格进行研究，将非参数回归中常用的B样条与当前流行的LSTM神经网络结合，得到了不错的结果。但只能预测总体变化趋势，与真实值仍存在误差，股票市场中，大盘之上瞬息万变，股价的影响因子众多，因此，为了进一步提升预测效果，仍有进一步的工作要做：1. 本文只考虑了股价过去一段时间价格对自身的影响，没有加入其他变量，而股价的影响因子众多，未来应尝试加入其他变量进行预测；2. 本文中超参数的选择是在一组参数中不断尝试选取的，不一定是最优解，未来应考虑选择更为科学的办法选择超参数，提升预测效果。"
