"在新一轮科技革命的浪潮中，各国纷纷把人工智能提升到国家战略层面。本文首先介绍了人工智能概念、发展历史、当前的研究重点和发展态势，阐述推动人工智能与我国核工业融合应用的必要性。接着介绍了当前人工智能的核心技术——基于深度学习的神经网络算法的发展历史、主要的四种网络模型，重点分析它在核领域的典型实例、应用现状和未来趋势，最后为加强我国核工业智能化发展提出几点建议。 关键词 :人工智能，核领域，神经网络，深度学习 Copyright © 2020 by author(s) and Hans Publishers Inc. This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/"
"人工智能(Artificial Intelligence, AI)，是研究开发用于模拟、延伸和扩展人的智能的理论、方法、技术及应用系统的技术科学。从1956年在达特蒙斯学院(Dartmouth)暑期论坛上首次提出 [ 1 ]，已经经过了60多年的发展和积淀，近十几年来，随着互联网、云计算、大数据、超级计算等新技术的发展，推动了以基于深度学习的神经网络(简称深度学习)为代表的人工智能技术飞速发展，广泛应用于图像分类、语音识别、知识问答、人机对弈、无人驾驶等领域，迎来爆发式增长的新高潮，正引发可产生链式反应的科学突破，加速新一轮的科技革命和产业变革。当前，人工智能的研究热点是基于深度学习的神经网络算法的理论完善和应用拓展。 作为引领未来的战略性技术，世界主要发达国家均把发展人工智能作为提升国家竞争力、维护国家安全的重大战略，加紧出台规划和政策，力图在新一轮国际科技竞争中掌握主导权。2017年7月，我国颁布实施《新一代人工智能发展规划》，将人工智能提升至国家战略层面，提出了面向2030年我国新一代人工智能发展的三步走战略目标，要求到2030年，人工智能理论、技术与应用总体达到世界领先水平，成为世界主要人工智能创新中心。2019年3月，中央全面深化改革委员会第七次会议审议通过了《关于促进人工智能和实体经济深度融合的指导意见》。我国发展人工智能具有市场规模、应用场景、数据资源、人力资源、资金投入、国家政策支持等多方面的综合优势。当前是我国加强人工智能布局、收获人工智能红利、引领智能时代的重大历史机遇期。 核工业作为高科技战略产业，既是国家安全重要基石，又是科技强国建设的重要先导和支撑。我国已建立起包括铀矿地质勘探、铀矿采冶、铀纯化、铀浓缩、元件制造、核电、乏燃料后处理、放射性废物处理处置等环节的完整核工业体系，核工业已经成为军民结合产业的标杆。我们应该抓住人工智能发展的重要机遇期，从整个核产业链出发，探索人工智能尤其是深度学习技术融合应用的需求和场景，大力推动人工智能在全产业链的深度融合、创新应用和转型驱动，实现全产业链智慧核能，引领国际核科技发展。目前，国内各大核相关科研单位均已开展了人工智能方面的基础研究，各大核电集团也已全面启动数字核电、智慧核电建设，加强应用研发，国际上各大核强国也纷纷布局，竞相争夺智慧核能的新高地。 目前了解到，国际上的研究都还处于方法可靠性和应用软件的开发上，无论是美国还是欧洲的项目，由于该技术路线难度极大，所需投入的资源较多，目前尚未在工程领域大量应用。要想在此轮智慧核能争夺中占据主动，首先应当深入掌握当前人工智能的核心技术——基于深度学习的神经网络算法，它是一种具有多个隐含层的人工神经网络，通过调整隐含层数、各层的神经元节点数、节点之间的连接关系、连接权重以及网络的学习系数、激活函数等，具有强大的非线性映射功能，在参数预测、智能控制、故障诊断等许多领域都有着广泛的应用前景。本文首先介绍神经网络算法一些基本模型，接着重点阐述其在核工业各领域的应用，最后对加强智能核能建设提出一些建议和展望。"
"作为人工智能的一个分支，神经网络的发展是贯穿在整个人工智能的发展中的：1942年，McCulloch和Pitts [ 2 ] 提出了第一个MP神经元数学模型；1958年，第一代神经网络单层感知器由Rosenblatt [ 3 ] 提出，第一代神经网络能够区分三角形、正方形等基本形状，但是1969年，Minsky [ 4 ] 指出单层感知器无法解决异或问题(非线性分类)问题；1975年，Paul Werbos第一次提出BP (误差反向传播)算法，但并未引起广泛重视；1986年，Hinton等 [ 5 ] 重新整理并提出BP神经网络，将原始单一固定的特征层替换成多个隐藏层，激活函数采用Sigmoid函数，能有效解决非线性分类问题。1989年，Cybenko和Hornik等 [ 6 ] [ 7 ] 证明了万能逼近定理：任何函数都可以被三层BP神经网络以任意精度逼近。同年，LeCun等 [ 8 ] [ 9 ] 发明了卷积神经网络用来识别手写体。1995年，Cortes与Vapnik [ 10 ] 提出了支持向量机(SVM)模型。但这些模型往深层发展都遇到困难。2006年被普遍认为是深度学习元年，Hinton等探讨大脑中的图模型 [ 11 ]，提出自编码器(autoencoder)来降低数据的维度 [ 12 ]，并提出用预训练的方式快速训练深度信念网 [ 13 ]，来抑制梯度消失问题。Bengio等 [ 14 ] 证明预训练的方法还适用于自编码器等无监督学习，Poultney等 [ 15 ] 用基于能量的模型来有效学习稀疏表示。这些论文奠定了基于深度学习的神经网络基础，从此深度学习进入快速发展期。2010年，美国国防部DARPA计划首次资助深度学习项目。2011年，Glorot等 [ 16 ] 提出ReLU激活函数，能有效抑制梯度消失问题。深度学习在语音识别上最先取得重大突破，微软和谷歌 [ 17 ] [ 18 ] 先后采用深度学习将语音识别错误率降低至20%~30%，是该领域10年来最大突破。2012年，Hinton和他的学生将ImageNet [ 19 ] 图片分类问题的Top5错误率由26%降低至15% [ 20 ]，从此深度学习进入爆发期。Dauphin等 [ 21 ] 在2014年，Choromanska等 [ 22 ] 在2015年分别证明局部极小值问题通常来说不是严重的问题，消除了笼罩在神经网络上的局部极值阴霾。 深度学习实质是通过构建具有很多隐层的神经网络模型和海量的训练数据，来学习更有用的特征，研究表明，模型的表示能力会随着深度的增加而呈指数增长 [ 23 ]，从而最终提升分类或预测的准确性。   典型的BP神经网络由输入层、输出层以及中间的隐含层构成(隐含层数可变)，是一种误差反向传播网络，图1展示了BP神经网络结构和信号传播方式。 BP网络结构简单，工作方式稳定，理论上可实现高精度非线性拟合，对于简单分类、非线性映射、模式识别等问题有不错的应用效果。  卷积神经网络适合处理图像数据，在计算机视觉领域应用广泛。CNN的设计思想受到了视觉神经科学的启发，主要由输入层、卷积层、池化层、全连接层及输出层组成，卷积层与池化层交替连接，卷积层和池化层的数量可由模型的复杂度决定。卷积层能够保持图像的空间连续性，将图像的局部特征提取出来．池化层能降低中间隐藏层的维度，减少后续各层的运算量，并提供了旋转不变性。 图1. BP神经网络结构图  在全连接的BP和CNN网络中，每层神经元的信号只能向上一层传播，样本的处理在各个时刻相互独立，因此，该类神经网络无法对时间序列上的变化进行建模，如自然语言处理、语音识别等，RNN网络应运而生。RNN中神经元的输出可以在下一个时间戳直接作用到自身，即第i层神经元在t时刻的输入，除了(i − 1)层神经元在t − 1时刻的输出外，还包括其自身在t时刻的输入。如图2所示。(t + 1)时刻网络的最终结果O(t + 1)是该时刻输入和所有历史共同作用的结果，这就达到了对时间序列建模的目的。 图2. RNN在时间上进行展开  GAN是在2014年由Goodfellow [ 24 ] 等提出的一种生成模型。在结构上，GAN原理类似于博弈论中的二人零和博弈(二人的利益之和为零，一方利益正是另一方损失)，如图3所示。GAN作为一种最新的深度学习技术，与前面几种体现预测功能的网络模型不一样，它是一种生成模型，对生成样本鲁棒性强，可以生成以假乱真的样本，缓解了小样本机器学习的困难。随着数据的增加，处理数据的成本也在同步增加，对数据要求不高的半监督学习、非监督学习将是机器学习下一阶段研究的热点。作为非监督学习的代表，GAN将是未来研究重点，其适合“无中生有”、“想象”的场合：文字生成图像、图像复原、图像修补、图像超分辨、艺术风格迁移等。 图3. GAN架构示意图  随着深度学习技术的不断发展，新的神经网络模型正在不断涌现，目前的研究重点有： 1) 无监督数据的特征学习。当前，标签数据的特征学习仍然占据主导地位，而真实世界存在着海量的无标签数据，将这些无标签数据逐一添加人工标签，显然是不现实的，因此，随着深度学习技术的发展，越来越重视对无标签数据的特征学习，以及将无标签数据进行自动添加标签技术的研究。 2) 多种模型融合。相关研究表明，单一的深度学习模型往往不能带来最好的效果，而通过增加深度来提高模型效果的方法往往会有一定的局限性，如，梯度消失问题、计算过于复杂、模型的并行性有限等问题，因此通过融合其他模型或者多种简单模型进行平均打分，可能会带来更好的效果。 3) 迁移学习。迁移学习可以说是一种“站在巨人肩上”的学习方法，可以在不同领域中进行知识迁移，使得在一个领域中已有的知识得到充分的利用，不需要每次都将求解问题视为全新的问题。一个好的迁移学习方法可以大大加快模型的训练速度。 4) 模型压缩。深度学习仍在不断进步，目前网络的规模开始朝着更深但是参数更少的方向发展，如微软提出的深度残差网络和Standford提出的稀疏神经网络，该研究体现了深度神经网络中存在参数的冗余性，可以预见未来的算法研究会进一步压缩冗余参数的存在空间，网络可能具有更好的精度但是却拥有更少的参数。 5) 嵌入式设备。目前深度学习技术正往嵌入式设备靠近，即原来的训练往往在服务器或者云端，而嵌入式设备通过网络将待识别的任务上传至云端，再由云端将处理结果发送到嵌入式端，随着嵌入式设备计算能力的提升、新型存储技术以及储电技术的进步，在嵌入式端完成实时训练是完全可能的，到时就可能实现真正的人工智能。"
"核电厂有数百个系统、专业，设备众多，传统运行维护及检修需要耗费大量人力、物力。随着智能仪表广泛应用，大量设备状态信号被监测，形成核电运行大数据，运用深度神经网络，能够对设备状态进行快速预测和诊断，具体应用有以下几个方面：  核电厂在正常运行和运行瞬变中，堆芯的运行工况处于经常变化的状态，这些变化导致实际运行中的堆芯状态与装料方案中的计算结果发生偏离，操纵员需及时准确地了解堆芯功率因子等参数状况。因此，研制一种能快速判断压水堆堆芯参数的计算机实时预测程序是十分必要的。王端等人基于自适应BP网络，对秦山二期压水堆堆芯3个堆芯关键参数(有效增殖因数k eff 、组件功率峰因子R PF 、棒功率峰因子F △ H )进行预测 [ 25 ]，流程如图4。 图4. BP神经网络算法堆芯关键参数预测流程 从表1发现，每个参数的平均相对误差均小于2%，均方误差均小于0.003，最大相对误差在5%附近，说明预测误差小、精度较高。 Table 1 测试参数 最小相对误差/% 最大相对误差/% 平均相对误差/% 均方误差 k eff 0.052 4.015 0.424 0.000049 R PF 0.130 5.126 1.516 0.002664 F △ H 0.072 4.725 1.597 0.002211 平均 0.085 4.622 1.179 0.001641 表1. 堆芯关键参数预测误差分析  反应堆堆芯的热工参数是否超出限值是评价反应堆安全运行的标准。针对燃料包壳最高温度预测问题，通过堆芯子通道分析程序COBRA生成数据样本后，王东东、杨红义等开发出基于BP神经网络的智能预测程序，对于特定的单盒组件，仅需给出堆芯进口功率和流量，就可实现燃料包壳最高温度的快速准确预测，部分程序运行结果如图5、图6。与COBRA相比，在大规模重复性计算的场景下，能够节约大量计算时间和算力，提高燃料棒包壳设计和CEFR堆运行时的操作效率。实验分析得出BP神经网络方法的最大相对误差不超过6%，平均预测相对误差不超过3%，计算效率缩短至原先程序的300倍 [ 26 ]。 图5. 神经元数目对应误差的曲线 图6. 不同优化器对应的误差收敛曲线  堆芯三维功率分布的实时监测对核电厂的安全高效运行和控制系统优化均有重大意义，堆芯功率分布包含了堆芯内的大量信息，由于在反应堆运行过程中无法直接测量堆芯内所有位置的功率，因此需通过其他方法得到堆芯三维功率分布的情况。蔡宛睿等人文以秦山一期工程为对象，利用堆外中子探测器在不同棒位和不同功率下的计数及BP神经网络对堆芯三维功率分布进行重构计算，图7展示了堆芯功率重构BP神经网络模型结构 [ 27 ]。 在此研究的基础上，夏虹等人开展了基于RBF神经网络的压水堆堆芯三维功率分布方法研究 [ 28 ]，提出利用RBF神经网络对堆外核测量系统与堆芯功率三维分布间的非线性对应关系进行合理建模，实现对堆芯功率三维分布的实时监测，图8展示了基于RBF神经网络模拟堆芯三维功率分布。  核电厂控制中心的运行人员经常面临大量的信息，要求运行人员在短时间内做出决策。由于报警信 图7. 堆芯功率重构BP神经网络模型结构示意图 图8. 基于RBF神经网络模拟堆芯三维功率分布 号模式与系统故障之间并不是单值对应关系，当核电运行方式不同时，同一故障还可能表现出不同的报警信号，并且可能含有噪声。这些因素都给报警信号分析增加了更大的难度。目前大多数常规技术的主要缺陷是无法对含有噪声的报警模式精确分类。根据信号判别系统故障的过程可看作是一个模式识别的过程。神经网络一个很成功的应用领域就是模式识别，与其他方法相比，具有报警速度快、鲁棒性好、易于知识获取等突出优点。袁灿等开发了基于神经网络的核动力一回路专家系统故障诊断 [ 29 ]，毛伟等 [ 30 ] 开发了基于改进粒子群算法的神经网络用于二回路凝给水系统的故障诊断，韩龙等将神经网络与模糊逻辑融合进行稳压器泄漏监测 [ 31 ] 等。中国核动力研究设计院研发的反应堆远程智能诊断平台PRID，使用自主开发的智能诊断分析算法和深度学习技术，对于关键设备诊断分析的质量和效率具有显著提高作用。图9和图10分别展示了神经网络故障诊断流程和神经网络故障诊断的应用。 以上所述应用大多是使用智能算法诊断或预测数据，体现出较多统计学特点。目前，智能方法正在与先进仿真技术相融合，即将统计模型与物理仿真结合。国内在该领域也开展了一定工作。例如在研究堆领域，中国原子能科学研究院研究发布了数字微堆系统，构建了一个虚拟数字反应堆集成开发环境，对安装、首次临界、运行、应用、退役和安全等开展全方位模拟仿真。据介绍，采用数字微堆系统后，新设计和建造一个微堆将显著缩短建设周期，节省建设投资，并可为用户提供数字化运行和维修培训及教学系统。   核电厂投入运行后，在每个堆芯寿期末都要停堆换料。堆芯换料过程中，将产生大量的换料方案，而换料方案的选择直接关系到核电厂运行的安全性和经济性。目前国内工程设计单位通常采用手工搜索的做法。随着中国核电迅速发展，核电运行机组增多，要在短时间内优选换料方案，换料工程师将承受较大的压力和困难。因此，研发高效实用的智能堆芯换料设计软件具有很高的工程应用价值和实际意义。 图9. 神经网络故障诊断流程框图 图10. 神经网络故障诊断应用 基于大规模数据，训练神经网络模型，准确预测了堆芯的三个关键参数k eff 、R ad 和F ΔH ，并以此三个参数作为衡量换料方式优劣的标准，构造改进的遗传算法从大量堆芯燃料方案中迅速搜索出最优排布方案，解决了在大量堆芯换料方案中选择最优方案费时费算力的问题，图11展示了复合算法的收敛情况。堆芯装载方式建模时，设计二进制向量作为输入参数，有效减少了网络复杂度、提高了预测精度；最优方案搜索时，具有独特交叉算子、选择算子的遗传算法保证了搜索结果在可行域内，并提高了搜索效率。理论分析和数值实验表明，包含一个隐藏层的单隐层自适应BP网络可很好预测k eff 数据，包含三个隐藏层的自适应BP神经网络可以作为R ad 和F ΔH 数据较好的预测模型，再运用遗传算法快速搜索出了一个比较理想的换料方案。 图11. 复合算法的收敛情况  船用反应堆的屏蔽设计问题直接关系到核能能否安全的用作舰船的动力系统，而在屏蔽设计问题中屏蔽计算是十分重要的环节。为了实现在一定误差范围内实现快速计算功能，于志翔等人 [ 32 ] 采用BP神经网络模拟学习MCNP的计算过程，仅需给出指定的输入变量即可预测屏蔽计算输出结果，解决了MCNP计算耗时过长问题，提高了屏蔽设计优化效率，图12展示了基于神经网络和遗传算法的屏蔽优化流程。张泽寰等通过将神经网络预测结果作为遗传算法适应度函数的参数进行约束寻优，大幅度提高了反应堆屏蔽结构优化计算效率。 图12. 基于神经网络和遗传算法的屏蔽优化流程图  核素识别技术已在核材料分析、核设施安全监测、环境放射性监测以及防止核恐怖主义发生等诸多方面得到广泛的应用。传统的核素识别主要采用能谱分析、解谱、检索核素库、能谱特征峰匹配等方法实现 [ 33 ]。由于能谱中不仅具有特征峰，还包含康普顿坪、单双逃逸峰、反射峰，并极易受到噪声、基线漂移等因素的影响，以致识别准确度低、速度慢。从1990年开始，国内外学者把神经网络算法应用于能谱分析当中 [ 34 ] [ 35 ]，并取得了一定的成果。1996年陈泽民等基于神经网络对BaF2闪烁探测器的γ能谱进行分析，可判断出被检测物品中是否含有爆炸物 [ 36 ]。图13和图14分别展示了核素识别分类器集成系统设计和分类器集成系统在实测核素下的识别。 这之后有众多学者将不同类型的网络应用到能谱进行分析中，包括BP网络 [ 37 ] [ 38 ] 、OLAM网络 [ 39 ] [ 40 ] 、多层感知器(MLP)网络 [ 41 ] 、概率神经网络 [ 42 ] 、LVQ网络 [ 43 ] 等，最新研究指出能谱分析与神经网络结合还可以应用于核安全与防止核扩散 [ 44 ]。 图13. 核素识别分类器集成系统设计 图14. 分类器集成系统在实测核素下的识别率 神经网络具有非线性映射、快速并行分布处理、学习特征等能力，应用于能谱分析能有效提高核素识别效率，减少对核专业知识的依赖，最终实现核素识别的快速化、智能化，有很好的应用前景。  在核医学领域，CT、MRI、PET、SPECT [ 45 ] 等医学图像的质量好坏直接影响医务人员对疾病的诊断治疗，通常需要对原始图像进行后处理后，作为疾病诊断的辅助信息提供给医生。图像的后处理包括：图像分割、图像增强、图像配准、图像重建等。基于前面的阐述，深度学习技术在图像处理方面有很大的优势，可以得到更高质量的核医学图像，并在此基础上进行智能辅助诊断，比如我国科研团队已经研发了核磁共振医学影像智能分析系统“阿尔法医生”，取得了比拟人类医生的诊断准确率，并大幅提升了诊断速度。在工业影像诊断领域，使用智能算法可以实现全天候、快速、高于人类准确率的核级焊缝X射线探伤识别应用。图15展示了神经网络医学图像重建技术，美国普渡大学采用深度图像智能识别技术，开发了堆内金属构件裂缝图像识别模块，能够对照相机拍摄的堆内构件照片进行分析，自动寻找裂缝，可有效减轻检测人员工作量，避免人因失误，保证核反应堆运行安全。 图15. 神经网络医学图像重建技术  核电机器人可替代人潜入核电站拍摄传递图像，让人们更真切了解核电站内部真实状况，也可在高辐射区域代替人工开展一些特殊操作。例如，中国科学院自行研制的多功能水下智能检查机器人已先后为中核、中广核等多家单位提供支持。国家863计划“核反应堆专用机器人技术与应用”课题在广西防城港核电基地通过验收，研发出6款核电智能机器人。在智能机器人设计的过程中，主要涉及到以下关键技术：多传感器信息融合、导航与定位、路径规划、机器人视觉、智能控制等，其中深度神经网络都能发挥很大的作用。  近年来，中核集团核四院与天山铀业致力于数字矿山探索，瞄准国际先进矿山技术和管理经验，不断提升自动化、信息化水平，初步建成了集工艺过程控制、生产场所实时监控、生产流程统一调度、应急管理综合指挥为一体的智能管理网络平台。目前，专家系统、神经网络、模糊逻辑、自适应模式识别、遗传算法等人工智能技术、GPS技术、并行计算技术、射频识别技术以及面向岩石力学问题的全局优化方法、遥感技术等已在智能矿山地质勘探调查与测量、智能矿山设计、智能矿山开采、计划与控制、矿山灾害遥感预报等研究领域得到应用。"
"根据叶奇蓁院士的分析 [ 46 ]，我国核电领域人工智能发展分为三个阶段，第一阶段为基础建设阶段，从采用智能仪表、智能控制到核电站全数字仪控系统建立；第二阶段为人工智能系统架构建立阶段，利用互联网+建立大数据系统，开发数字核电站和虚拟现实技术；第三阶段为人工智能系统应用开发阶段，实现智能操作指导、事故处理指导、设备系统的智能维护，以及高辐射区、不可达地区机器人的使用等。目前，我国大部分核电站已采用全数字化仪控系统，正处在第二阶段数字化核电站系统架构建立阶段，其中深度学习是关键技术之一。 但是，我国核领域神经网络算法的应用起步相对较晚，总体而言，系统性研究还不多见，主要的应用还是进行模式识别、故障诊断、关键参数预测等，对于神经网络的生成功能、决策功能使用较少。这十多年来，赶上了神经网络爆发性发展的大势，我国的神经网络理论和应用研究正在飞速发展，与核领域的交叉融合也是整个行业的发展战略，未来必将在这方面取得突破性进展。 为促进我国智慧核能建设进一步健康发展，笔者有以下建议： 1) 关注数据安全和模型稳健性 近年来，各国核电领域信息安全事件频发。黑客、病毒等对核电系统的攻击会导致系统遭到破坏，信息和数据被非法访问、更改、泄露，系统控制的装置和设备失灵，甚至核设施和核电厂被强制关闭。尤其是2010年伊朗核电站爆发的“震网”病毒，造成伊朗核电站关闭，持续影响长达半年。Szegedy等 [ 47 ] 发现深度学习会被对抗性样本攻击，即本来正确分类的图片加上小的扰动能使深度学习模型误判成别的类别。因此，在做好纵深防御、分等级保护等信息安全保障措施的同时，我们需要防止对抗性样本攻击造成神经网络失效，研究在对抗性样本攻击下，仍能保持一定程度稳定性的算法。 2) 加强核领域的专用神经网络算法开发 我国核领域的神经网络应用研究不少，但是缺乏对于算法的深入理解，大多数应用开发都是基于一些神经网络工具箱进行，无法根据实际问题的需要修改算法内部细节，在算法效能上缺乏进一步提升的空间。我们应当加强对算法原理的研究，根据核领域的特定需求，自主开发专用定制软件，达到更好的应用效果。 3) 耦合其他算法综合应用 神经网络算法在对数据的分类、学习、预测与评估等方面具有广泛而有效的应用，其局部搜索能力强，但是全局搜索能力稍差，在全局优化方面不如其他人工智能算法：遗传算法、粒子群算法、模拟退火算法等。针对神经网络算法网络结构复杂问题，可以使用其他人工智能算法辅助搜索网络的模型参数，比如隐含层数、节点个数等，寻找较优的网络模型；针对神经网络使用梯度下降算法优化权值容易陷入局部最优、全局搜索能力稍差的问题，可以结合其他人工智能算法设计新的优化权值的算法，加速神经网络的训练过程，提高训练的效果。目前这两方面的耦合均已有研究，正在发展更深层次的交叉算法。 4) 加强顶层整体规划和跨学科合作 当前，我国核工业以“数字矿山、智能制造、数字(智能)核电、智慧经营”为主线的行业科技发展路径已清晰显现。在整个行业智能化趋势的大背景下，各单位都在纷纷开展人工智能的应用研究，需要做好全行业的顶层规划，统一体系、统一方向、统筹安排，避免重复投入。在技术上，由于人工智能、神经网络技术是一个涉及心理学、神经科学、数学、计算机、控制论等多学科的交叉科学，它的应用研究需要复合背景的人才，需要构建一个多专业、跨学科、综合性的科研团队，通力合作，才能产出高质量的成果。  展望核领域神经网络技术的发展，还有以下几个新的技术方向： 1) 基础物理现象建模。 核反应堆工程涉及多个学科，其中一些物理现象比较复杂，难以通过理论推导得到准确的通用基础模型。由此导致新型反应堆或换热器的设计仍然离不开热工实验，需要花费大量资金搭建实验装置。随着实验技术的进步，目前对于沸腾、流动等复杂现象能够开展更加精细的测量，得到大量数据。美国的科研团队正研究采用深度神经网络的技术分析海量实验数据，以建立适用性更广的热工水力学基础模型，从而减少新设计对于大型实验设施的依赖。 2) 核反应堆的少人或无人值守智能运行。 目前，通过使用智能化技术，一些常规发电厂已经实现了少人值守，并在探索无人值守，这将有利于避免人因失误。与火电厂相比，核电厂的安全标准和要求非常高，进一步研究打造以无人监测、少人值守为目标的智慧核电运营模式，可有效提升核电运行安全水平。此外，对于未来太空、深海区域的核反应堆，因环境特殊性需要实现无人智能运行。目前，美国正在开发适用于火星等太空环境的核反应堆，使用深度神经网络实现智能运行是其中的关键技术。 3) 与大数据技术的结合。 随着反应堆向数字化方向迈进，围绕反应堆研究、设计、设备、建造、运维、退役等全生命周期多专业产生的大量数据被保存，相关数据呈现爆炸式增长趋势，形成了涵盖反应堆全生命周期的“数据宝库”。从数据分析角度来看，这类数据具备大数据的典型特征，其中蕴含着很多待开发的价值信息，但其种类繁多、格式多样、来源多样，信息分散在各个应用系统中，数据冗余度高，并且存在错误数据和有缺失的数据，我们需要结合数据传输、数据治理、数据挖掘等大数据技术提升数据质量，再使用神经网络建立智能决策分析系统，将数据仓库中的海量数据变为有运行指导价值或经济价值信息。当前，我国核工业相关单位积极开展如何把大数据应用于反应堆行业的相关问题研究，大数据技术已初步应用于反应堆安全管理、优化运行、状态在线检测、故障诊断、智能检修、远程运维、供应链管理、预防性维护等多个方面。大数据技术与神经网络技术的结合，将成为未来反应堆及其相关产业领域的研究热点和重点之一。"
"在新一轮人工智能发展的重大战略机遇期，在构筑我国人工智能发展的先发优势和建设创新型国家和世界科技强国过程中，加强神经网络算法的理论研究，推动其与核工业的交叉融合应用，努力实现技术融合、算法融合、数据融合，对于促进核电行业向数字化、网络化、智能化发展，建设智慧核工业、加快我国由核大国向核强国跨越的进程有重大意义。"
