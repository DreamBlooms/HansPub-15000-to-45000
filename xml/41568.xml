<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2021.114088</article-id><article-id pub-id-type="publisher-id">CSA-41568</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20210400000_38594846.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于User-BERT模型的微博谣言检测
  Microblog Rumor Detection Based on User-BERT
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>缪</surname><given-names>鑫</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib></contrib-group><aff id="aff1"><label>1</label><addr-line>null</addr-line></aff><aff id="aff2"><label>1</label><addr-line>广东工业大学，广东 广州</addr-line></aff><pub-date pub-type="epub"><day>13</day><month>04</month><year>2021</year></pub-date><volume>11</volume><issue>04</issue><fpage>859</fpage><lpage>866</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   随社交媒体的快速发展，微博已经成为人们获取信息的主要平台。它给人们生活带来便利的同时，也带来了谣言泛滥的问题。有越来越多研究投入到谣言检测中，从早期的特征工程方法到近期的深度学习方法。但是，目前的工作没有充分利用预训练语言模型与其它特征相结合。因此，文本推出User-BERT模型，使BERT模型能够充分利用文本和用户特征。它使用BERT模型对原文和评论文本进行编码，得到文本表示向量再与用户属性向量结合，最后由深度分类器对其进行解析并预测。在公开微博数据集上，User-BERT取得了当前最好的结果。 With the rapid development of social media, Sina weibo has become the main platform for people to obtain information. While it brings convenience to people’s lives, it also brings the problem of spreading rumors. More and more research is devoted to rumor detection, from early feature engineering methods to recent deep learning methods. However, the current work does not make full use of the pretrained language model combined with other features. Therefore, this work introduces the User-BERT model, which enables the BERT model to make full use of text and user characteristics. It uses the BERT model to encode text of source post and comments, obtains the text representation vector and combines it with the user attribute vector, and it finally is parsed by the deep classifier. On the public weibo dataset, User-BERT has achieved the best results currently. 
  
 
</p></abstract><kwd-group><kwd>谣言检测，BERT，深度学习，自然语言处理, Rumor Detection</kwd><kwd> BERT</kwd><kwd> Deep Learning</kwd><kwd> NLP</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>摘要</title><p>随社交媒体的快速发展，微博已经成为人们获取信息的主要平台。它给人们生活带来便利的同时，也带来了谣言泛滥的问题。有越来越多研究投入到谣言检测中，从早期的特征工程方法到近期的深度学习方法。但是，目前的工作没有充分利用预训练语言模型与其它特征相结合。因此，文本推出User-BERT模型，使BERT模型能够充分利用文本和用户特征。它使用BERT模型对原文和评论文本进行编码，得到文本表示向量再与用户属性向量结合，最后由深度分类器对其进行解析并预测。在公开微博数据集上，User-BERT取得了当前最好的结果。</p></sec><sec id="s2"><title>关键词</title><p>谣言检测，BERT，深度学习，自然语言处理</p></sec><sec id="s3"><title>Microblog Rumor Detection Based on User-BERT</title><p>Xin Miao</p><p>Guangdong University of Technology, Guangzhou Guangdong</p><p><img src="//html.hanspub.org/file/9-1542098x4_hanspub.png" /></p><p>Received: Mar. 14<sup>th</sup>, 2021; accepted: Apr. 8<sup>th</sup>, 2021; published: Apr. 15<sup>th</sup>, 2021</p><p><img src="//html.hanspub.org/file/9-1542098x5_hanspub.png" /></p></sec><sec id="s4"><title>ABSTRACT</title><p>With the rapid development of social media, Sina weibo has become the main platform for people to obtain information. While it brings convenience to people’s lives, it also brings the problem of spreading rumors. More and more research is devoted to rumor detection, from early feature engineering methods to recent deep learning methods. However, the current work does not make full use of the pre-trained language model combined with other features. Therefore, this work introduces the User-BERT model, which enables the BERT model to make full use of text and user characteristics. It uses the BERT model to encode text of source post and comments, obtains the text representation vector and combines it with the user attribute vector, and it finally is parsed by the deep classifier. On the public weibo dataset, User-BERT has achieved the best results currently.</p><p>Keywords:Rumor Detection, BERT, Deep Learning, NLP</p><disp-formula id="hanspub.41568-formula31"><graphic xlink:href="//html.hanspub.org/file/9-1542098x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2021 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/9-1542098x7_hanspub.png" /> <img src="//html.hanspub.org/file/9-1542098x8_hanspub.png" /></p></sec><sec id="s5"><title>1. 引言</title><p>随因特网和移动设备的普及，微博逐渐成为人们获取和表达信息的主要平台。它给人们生活带来便利的同时，也带来了谣言泛滥的问题。中文社会科学院发布的《新媒体蓝皮书》显示，中国有59%的网络谣言来自新浪微博 [<xref ref-type="bibr" rid="hanspub.41568-ref1">1</xref>]。谣言传播恐惧和偏见，它可能会造成(个人、品牌、政府等)被诽谤 [<xref ref-type="bibr" rid="hanspub.41568-ref2">2</xref>]，甚至导致出现社会信任危机。所以，微博谣言检测是一项十分有必要的研究工作。</p><p>在研究早期，谣言检测主要是以特征工程为基础的机器学习方法，例如Ma等人 [<xref ref-type="bibr" rid="hanspub.41568-ref3">3</xref>] 用到支持向量机(Support Vector Machine, SVM)。随算力快速提升，以深度学习为基础的方法成为机器学习主流，各类深度学习方法在谣言检测领域取得了长足的进步。Ma等人 [<xref ref-type="bibr" rid="hanspub.41568-ref4">4</xref>] 和Wang等人 [<xref ref-type="bibr" rid="hanspub.41568-ref5">5</xref>] 用到循环神经网络(Recurrent Neural Network, RNN)，Yu等人 [<xref ref-type="bibr" rid="hanspub.41568-ref6">6</xref>] 用到卷积神经网络(Convolutional Neural Networks, CNN)，Bian等人 [<xref ref-type="bibr" rid="hanspub.41568-ref7">7</xref>] 用到图卷积网络(Graph Convolutional Network, GCN)，尹鹏博等人 [<xref ref-type="bibr" rid="hanspub.41568-ref1">1</xref>] 和Geng等人 [<xref ref-type="bibr" rid="hanspub.41568-ref8">8</xref>] 用到以深度学习为基础的集成学习(Ensemble Learning, EL)。</p><p>尽管当前以深度学习为基础的方法取得了不错的效果，但它们没有充分利用预训练语言模型或用户特征。以BERT(Bidirectional Encoder Representations from Transformers) [<xref ref-type="bibr" rid="hanspub.41568-ref9">9</xref>] 为代表的预训练语言模型已经在诸多自然语言处理领域取得了领先的效果。其以Tansformer [<xref ref-type="bibr" rid="hanspub.41568-ref10">10</xref>] 为基础，经过大规模文本预训练，学到了丰富的语言知识，可将知识迁移至任意下游任务。另外，用户特征已被证明能有效促进谣言检测 [<xref ref-type="bibr" rid="hanspub.41568-ref11">11</xref>]，通常越是权威的用户发布的消息越真实可靠，反之亦然。因此本文提出User-BERT模型，充分将文本特征和用户特征与BERT模型相结合，充分发挥BERT模型的性能优势。User-BERT模型将BERT模型作为文本编码器对原文和评论文本进行编码，然后将输出的文本表示向量和用户特征向量进行拼接组成新的综合表示向量，最后将综合表示向量输入至全连接层即深度分类器中进行解析并预测结果。实验结果表明，在Ma等人 [<xref ref-type="bibr" rid="hanspub.41568-ref4">4</xref>] 提出的公开微博数据集上，User-BERT取得了当前最好的实验结果。</p></sec><sec id="s6"><title>2. 相关工作</title><p>因社交平台的普及，谣言检测引起了更多重视，随机器学习的发展而进步。机器学习的早期主要以特征工程为基础的方法为主流，在谣言检测领域同样如此。Ma等人 [<xref ref-type="bibr" rid="hanspub.41568-ref3">3</xref>] 从内容、用户、传播三方面共选取了27条特征表示数据，用SVM模型作为分类器。其它以特征工程为基础的方法大致相同，特征选取是这类方法的关键，发掘有效的特征能给模型带来显著的提升。近些年因深度学习的快速发展，以深度学习为基础的方法已经成为机器学习的主流。深度学习因其自动提取高级特征和更强的拟合数据的能力得到广泛应用，多种深度学习模型也被应用到谣言检测领域。Ma等人 [<xref ref-type="bibr" rid="hanspub.41568-ref4">4</xref>] 用词频-逆文本频率指数(Term Frequency-Inverse Document Frequency, TF-IDF)表示原文或评论，然后逐步将特征表示输入到RNN模型中，用最后的输出向量预测结果。Wang等人 [<xref ref-type="bibr" rid="hanspub.41568-ref5">5</xref>] 用word2vec对原文或评论作词嵌入，同时结合情感词典加入情感嵌入，分别输入到两个双层RNN模型中。Yu等人 [<xref ref-type="bibr" rid="hanspub.41568-ref6">6</xref>] 用CNN模型作为特征提取器构建检测模型。Bian等人 [<xref ref-type="bibr" rid="hanspub.41568-ref7">7</xref>] 则用到了近来流行的GCN模型 [<xref ref-type="bibr" rid="hanspub.41568-ref12">12</xref>] 通过学习谣言的传播特征来判别真假。此外，还有联合多个深度学习模型为基础学习器的深度集成学习模型。尹鹏博等人 [<xref ref-type="bibr" rid="hanspub.41568-ref1">1</xref>] 以CNN和RNN模型作为基分类器，选取随机森林作为元模型，合并基模型的输出为二次训练集，在元模型上进行二次训练。Geng等人 [<xref ref-type="bibr" rid="hanspub.41568-ref8">8</xref>] 用三种RNN模型作为基分类器，最后以投票的方式整合基分类器的预测结果。</p></sec><sec id="s7"><title>3. 先导</title><sec id="s7_1"><title>3.1. 问题描述</title><p>谣言检测任务可被定义为：设数据集定义为 D = { d 1 , d 2 , ⋯ , d n } ， d i ∈ D 表示一条数据元组，n表示数据集的大小。且 d i = { s i , C i , u i , l i } ，其中 s i = { w 1 i , w 2 i , ⋯ , w m i } 表示原文， w j i ∈ s i 表示原文的字，m为原文的长度； C i = { c 1 i , c 2 i , ⋯ , c o i } 表示原文s<sub>i</sub>对应的评论(回复)集， c j i ∈ C i 表示一条评论，其中每条评论又由若干字组成，o表示评论个数；u<sub>i</sub>表示发布者的用户画像，用户画像由若干个属性组成；l<sub>i</sub>表示该条数据的标签，具体为{0, 1}，0表示为真，1表示为假。总之，对于数据集D，给定{s, C, u}，需要预测其标签l。</p></sec><sec id="s7_2"><title>3.2. Tansformer</title><p>BERT模型以Transformer编码器为基础构建，其结构如图1所示。Transformer最早由Vaswani等人 [<xref ref-type="bibr" rid="hanspub.41568-ref10">10</xref>] 提出，分为编码器和解码器。BERT用编码器作为模型的基本单元，Base版本堆叠12层Tansformer编码器，Large版本则堆叠24层Transformer编码器。Transformer作为强特征提取器，其成功主要归功于全局的多头自注意力机制，该机制的公式化描述为：</p><p>图1. Transformer编码器结构图</p><p>Attention ( Q , K , V ) = softmax ( Q K T d k ) V (1)</p><p>MultiHead ( Q , K , V ) = Concat ( Attention 1 , ⋯ , Attention N ) (2)</p><p>Q代表Query矩阵，K代表Key矩阵，V代表Value矩阵，它们从相同的表示矩阵经过线性变换而来，即自注意力机制。d<sub>k</sub>表示向量的维度。公式(1)得到经过自注意力机制计算后的表示矩阵，公式(2)意为将多头注意力表示矩阵做拼接即得到最终表示矩阵。</p></sec></sec><sec id="s8"><title>4. User-BERT模型</title><sec id="s8_1"><title>4.1. 整体架构</title><p>图2展示了User-BERT模型的整体架构。架构大致可以分为两部分，本文编码器和深度分类器。文本编码器即为BERT模型，其将谣言原文和评论的文本编码成文本表示向量。输出的文本表示向量和用户属性向量进行拼接，形成综合表示向量。深度分类器为全连接层网络(Fully Conneted Network, FCN)，对综合表示向量进行解析并输出最后预测结果。</p><p>图2. User-BERT整体架构</p></sec><sec id="s8_2"><title>4.2. 文本编码</title><p>文本将BERT文本编码器的输入分成原文区和评论区两部分，原文区长度限制为128，评论区长度限制为384。(BERT长度限制为512)原文和评论及评论和评论之间用[SEP]表示符进行分隔。评论按照时间先后顺序排列。本文取BERT最后一层的[CLS]表示符对应的表示向量作为整体文本的表示向量。该过程可公式化为：</p><p>H 0 i = BERT ( s i , C i ) [ 0 ] (3)</p><p>s<sub>i</sub>表示原文，C<sub>i</sub>表示评论集， H 0 i 表示数据i的文本表示向量。文本表示向量不仅包含了原文的特征，还包含了丰富的评论特征。</p></sec><sec id="s8_3"><title>4.3. 用户特征</title><p>本文对用户属性分布进行了详细分析，最终选出六个分布差异明显的用户特征，详见附录。即u<sub>i</sub> = {verified, verified_type, verified_reason_length, followers_count, bi_followers_count, statuses_count}。verified表示用户是否得到官方认证，verified_type表示认证类型，verified_reason_length表示认证原因的文本长度，followers_count表示粉丝数量，bi_followers_count表示双向关注用户数量，statuses_count表示用户的微博数量。将文本表示向量 H 0 i 和用户属性向量 H 1 i 做拼接，得到综合表示向量 H 2 i ：</p><p>H 2 i = Concatenate ( H 0 i , H 1 i ) (4)</p></sec><sec id="s8_4"><title>4.4. 深度分类器</title><p>深度分类器采用FCN模型，对输入的综合表示向量 H 2 i 进行解析得到中间结果向量h<sub>i</sub>：</p><p>h i = FCN ( H 2 i ) (5)</p><p>最后通过softmax [<xref ref-type="bibr" rid="hanspub.41568-ref13">13</xref>] 激活函数对h<sub>i</sub>进行归一化处理即可得到数据d<sub>i</sub>对应标签l<sub>i</sub>的概率分布：</p><p>p j = exp ( h j i ) ∑ k = 0 n exp ( h k i ) (6)</p></sec></sec><sec id="s9"><title>5. 实验与分析</title><sec id="s9_1"><title>5.1. 数据集</title><p>本文采用的数据集是Ma等人 [<xref ref-type="bibr" rid="hanspub.41568-ref4">4</xref>] 提出的新浪微博数据集Ma-Weibo。数据集从微博社区管理中心<sup>1</sup>收集而来，其中的谣言数据由人工验证且公开，是来自现实中的真实数据。数据集总共包含4664条数据，谣言2313条，非谣言2351条。公开的数据集<sup>2</sup>带有微博原文、评论、用户属性等信息。</p></sec><sec id="s9_2"><title>5.2. 实验设置</title><p>实验设备情况大致如下，操作系统为Ubuntu 18.04.4，CPU型号为Inter(R) Xeon Silver 4110，显卡型号为GeForce RTX 2080Ti。采用的BERT是谷歌官方<sup>3</sup>提供的中文Base版模型，实验环境为Python3.6、Tensorflow1.14。FCN模型为三层的全连接层网络，前两层神经元个数为128，第三层为2。训练时使用两段式分别训练User-BERT的文本编码器和深度分类器，第一阶段使用数据集对BERT模型进行调优，第二阶段冻结BERT模型参数，对FCN模型参数进行训练。此外，训练BERT的学习率为2e-5，epoch为8。</p></sec><sec id="s9_3"><title>5.3. 对比方法</title><p>实验充分对比了各种机器学习方法，从特征工程到最新的深度学习方法。对比的方法如下：</p><p>&#183; SVM-TS (Ma等人提出 [<xref ref-type="bibr" rid="hanspub.41568-ref3">3</xref>] )：使用线性SVM分类器对人工提取特征进行分类。</p><p>&#183; RNN (Ma等人提出 [<xref ref-type="bibr" rid="hanspub.41568-ref4">4</xref>] )：将原文和评论的表示向量输入到RNN网络进行分类。</p><p>&#183; CGRU (Wang等人提出 [<xref ref-type="bibr" rid="hanspub.41568-ref5">5</xref>] )：除原文和评论，加入情感特征到RNN网络进行分类。</p><p>&#183; CAMI (Yu等人提出 [<xref ref-type="bibr" rid="hanspub.41568-ref6">6</xref>] )：使用CNN模型对谣言进行分类。</p><p>&#183; Bi-GCN (Bain等人提出 [<xref ref-type="bibr" rid="hanspub.41568-ref7">7</xref>] )：使用双向GCN网络学习谣言传播特征进行分类。</p><p>&#183; RFS-BD (尹鹏博等人提出 [<xref ref-type="bibr" rid="hanspub.41568-ref1">1</xref>] )：使用CNN和RNN作为基学习器，随机森林为元学习器的集成学习。</p><p>&#183; GRU-Ensemble (Geng等人提出 [<xref ref-type="bibr" rid="hanspub.41568-ref9">9</xref>] )：使用三种RNN模型作为基学习器，以投票方式进行分类。</p></sec><sec id="s9_4"><title>5.4. 结果分析</title><p>表1展示了所有方法的实验结果，文本提出的User-BERT在每个指标都取得了最好的结果。本文取准确率、精确率、召回率及综合考虑精确率和召回率的F1值四个指标，充分展示各模型的表现结果。对比方法的结果取其论文和复现实验中最好的结果。通过观察可以得到以下结论：(1) SVM-TS的结果比其它深度学习方法都要差，说明深度学习方法比特征工程方法确实有明显的性能优势。(2) User-BERT的结果好于RNN和CGRU，显然是因为Tansformer比RNN单元有更强的特征提取能力，RNN单元随着序列长度增加会遗忘部分信息，而Transformer则能从全局注意力中学习。(3) User-BERT的结果明显好于CAMI，说明Tansorformer比卷积神经网络更适合用于处理文本信息。(4) User-BERT的结果好于Bi-GCN，说明即使不使用谣言的传播信息也可以达到更好的结果。(5) User-BERT比两个集成模型即RFS-BD和GRU-Ensemble的表现明显更加优异，展示了User-BERT单模型的强大性能。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Comparison of experimental result</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >方法</th><th align="center" valign="middle" >准确率</th><th align="center" valign="middle" >精确率</th><th align="center" valign="middle" >召回率</th><th align="center" valign="middle" >F1值</th></tr></thead><tr><td align="center" valign="middle" >SVM-TS</td><td align="center" valign="middle" >0.846</td><td align="center" valign="middle" >0.845</td><td align="center" valign="middle" >0.845</td><td align="center" valign="middle" >0.845</td></tr><tr><td align="center" valign="middle" >RNN</td><td align="center" valign="middle" >0.910</td><td align="center" valign="middle" >0.914</td><td align="center" valign="middle" >0.910</td><td align="center" valign="middle" >0.910</td></tr><tr><td align="center" valign="middle" >CGRU</td><td align="center" valign="middle" >0.963</td><td align="center" valign="middle" >0.963</td><td align="center" valign="middle" >0.963</td><td align="center" valign="middle" >0.963</td></tr><tr><td align="center" valign="middle" >CAMI</td><td align="center" valign="middle" >0.933</td><td align="center" valign="middle" >0.933</td><td align="center" valign="middle" >0.933</td><td align="center" valign="middle" >0.933</td></tr><tr><td align="center" valign="middle" >Bi-GCN</td><td align="center" valign="middle" >0.961</td><td align="center" valign="middle" >0.962</td><td align="center" valign="middle" >0.963</td><td align="center" valign="middle" >0.961</td></tr><tr><td align="center" valign="middle" >RFS-BD</td><td align="center" valign="middle" >0.929</td><td align="center" valign="middle" >0.927</td><td align="center" valign="middle" >0.923</td><td align="center" valign="middle" >0.925</td></tr><tr><td align="center" valign="middle" >GRU-Ensemble</td><td align="center" valign="middle" >0.956</td><td align="center" valign="middle" >0.956</td><td align="center" valign="middle" >0.957</td><td align="center" valign="middle" >0.956</td></tr><tr><td align="center" valign="middle" >User-BERT(Ours)</td><td align="center" valign="middle" >0.968</td><td align="center" valign="middle" >0.969</td><td align="center" valign="middle" >0.968</td><td align="center" valign="middle" >0.968</td></tr></tbody></table></table-wrap><p>表1. 实验结果对比</p></sec><sec id="s9_5"><title>5.5. 消融实验</title><p>为了更好理解User-BERT每个部分的作用，文本对User-BERT模型进行了消融实验，实验结果如表2所示。User-BERT/User表示只去除用户属性，User-BERT/Comment表示只去除评论信息，User-BERT/User/Comment表示去除用户属性和评论信息。可以看到，去除用户属性或评论信息都会造成性能下降，说明它们对谣言检测都有帮助。而从下降幅度来看，评论信息比用户属性更加重要，这可能是因为参与用户能有效反映原文的情感和观点 [<xref ref-type="bibr" rid="hanspub.41568-ref14">14</xref>]，给原文补充更多有效特征。</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> Comparison of ablation experiment result</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >方法</th><th align="center" valign="middle" >准确率</th><th align="center" valign="middle" >精确率</th><th align="center" valign="middle" >召回率</th><th align="center" valign="middle" >F1值</th></tr></thead><tr><td align="center" valign="middle" >User-BERT</td><td align="center" valign="middle" >0.968</td><td align="center" valign="middle" >0.969</td><td align="center" valign="middle" >0.968</td><td align="center" valign="middle" >0.968</td></tr><tr><td align="center" valign="middle" >User-BERT/User</td><td align="center" valign="middle" >0.960</td><td align="center" valign="middle" >0.961</td><td align="center" valign="middle" >0.960</td><td align="center" valign="middle" >0.960</td></tr><tr><td align="center" valign="middle" >User-BERT/Comment</td><td align="center" valign="middle" >0.946</td><td align="center" valign="middle" >0.946</td><td align="center" valign="middle" >0.947</td><td align="center" valign="middle" >0.946</td></tr><tr><td align="center" valign="middle" >User-BERT/User/Comment</td><td align="center" valign="middle" >0.935</td><td align="center" valign="middle" >0.934</td><td align="center" valign="middle" >0.936</td><td align="center" valign="middle" >0.935</td></tr></tbody></table></table-wrap><p>表2. 消融实验结果对比</p></sec></sec><sec id="s10"><title>6. 总结与展望</title><p>本文提出了User-BERT模型，充分利用预训练语言模型BERT和文本信息及用户属性相结合，并在公开微博数据集Ma-Weibo上取得了最好的结果。通过实验还证明了评论信息和用户属性对谣言检测的作用。未来将考虑把更多可能的特征融入到预训练语言模型中，比如知识被证明对谣言检测很有帮助 [<xref ref-type="bibr" rid="hanspub.41568-ref15">15</xref>]，传播路径也被证明有帮助 [<xref ref-type="bibr" rid="hanspub.41568-ref7">7</xref>]。此外，还将会使用更多其它的预训练语言模型进行实验。</p></sec><sec id="s11"><title>文章引用</title><p>缪 鑫. 基于User-BERT模型的微博谣言检测 Microblog Rumor Detection Based on User-BERT[J]. 计算机科学与应用, 2021, 11(04): 859-866. https://doi.org/10.12677/CSA.2021.114088</p></sec><sec id="s12"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.41568-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">尹鹏博, 彭成, 潘伟民. 基于集成学习的微博谣言早期检测[J]. 微电子学与计算机, 2021, 38(1): 83-88.</mixed-citation></ref><ref id="hanspub.41568-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Liu, X., Nour-bakhsh, A., Li, Q., et al. (2015) Real-Time Rumor Debunking on Twitter. Proceedings of the 24th ACM International on Conference on Information and Knowledge Management, Melbourne, 19-23 October 2015, 1867- 1870. &lt;br&gt;https://doi.org/10.1145/2806416.2806651</mixed-citation></ref><ref id="hanspub.41568-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Ma, J., Gao, W., Wei, Z., et al. (2015) Detect Rumors Using Time Series of Social Context Information on Microblogging Websites. Proceedings of the 24th ACM International on Conference on Information and Knowledge Management, Melbourne, 19-23 October 2015, 1751-1754. &lt;br&gt;https://doi.org/10.1145/2806416.2806607</mixed-citation></ref><ref id="hanspub.41568-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Ma, J., Gao, W., Mitra, P., et al. (2016) Detecting Rumors from Microblogs with Recurrent Neural Networks.</mixed-citation></ref><ref id="hanspub.41568-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Wang, Z. and Guo, Y. (2020) Rumor Events Detection Enhanced by Encoding Sentimental Information into Time Series Division and Word Representations. Neurocomputing, 397, 224-243.  
&lt;br&gt;https://doi.org/10.1016/j.neucom.2020.01.095</mixed-citation></ref><ref id="hanspub.41568-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Yu, F., Liu, Q., Wu, S., et al. (2017) A Convolutional Approach for Misin-formation Identification. Proceedings of the 26th International Joint Conference on Artificial Intelligence, Melbourne, 19-25 August 2017, 3901-3907.  
&lt;br&gt;https://doi.org/10.24963/ijcai.2017/545</mixed-citation></ref><ref id="hanspub.41568-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Bian, T., Xiao, X., Xu, T., et al. (2020) Rumor Detection on Social Media with Bi-Directional Graph Convolutional Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 34, 549-556.  
&lt;br&gt;https://doi.org/10.1609/aaai.v34i01.5393</mixed-citation></ref><ref id="hanspub.41568-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Geng, Y., Lin, Z., Fu, P., et al. (2019) Rumor Detection on Social Media: A Mul-ti-View Model Using Self-Attention Mechanism. In: International Conference on Computational Science, Springer, Cham, 339-352.  
&lt;br&gt;https://doi.org/10.1007/978-3-030-22734-0_25</mixed-citation></ref><ref id="hanspub.41568-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Devlin, J., Chang, M.W., Lee, K., et al. (2018) Bert: Pre-Training of Deep Bidirectional Transformers for Language Understanding.</mixed-citation></ref><ref id="hanspub.41568-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Vaswani, A., Shazeer, N., Parmar, N., et al. (2017) Attention Is All You Need.</mixed-citation></ref><ref id="hanspub.41568-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Li, Q., Zhang, Q. and Si, L. (2019) Rumor Detection by Exploiting User Credibility Information, Attention and Multi-Task Learning. Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, Florence, 28 July-2 August 2019, 1173-1179. &lt;br&gt;https://doi.org/10.18653/v1/P19-1113</mixed-citation></ref><ref id="hanspub.41568-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Kipf, T.N. and Welling, M. (2016) Semi-Supervised Classification with Graph Convolutional Networks.</mixed-citation></ref><ref id="hanspub.41568-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Liu, W., Wen, Y., Yu, Z., et al. (2016) Large-Margin Softmax Loss for Convolutional Neural Networks. The 33rd International Conference on Machine Learning (ICML 2016), New York, 19-24 June 2016, 7.</mixed-citation></ref><ref id="hanspub.41568-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">Lu, Y.J. and Li, C.T. (2020) GCAN: Graph-Aware Co-Attention Networks for Explainable Fake News Detection on Social Media. Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, July 2020, 505-514. &lt;br&gt;https://doi.org/10.18653/v1/2020.acl-main.48</mixed-citation></ref><ref id="hanspub.41568-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">Li, Q., Zhang, Q., Si, L., et al. (2019) Rumor Detection on Social Media: Da-tasets, Methods and Opportunities. Proceedings of the Second Workshop on Natural Language Processing for Internet Freedom: Censorship, Disinformation, and Propaganda, Hong Kong, November 2019, 66-75. &lt;br&gt;https://doi.org/10.18653/v1/D19-5008</mixed-citation></ref></ref-list></back></article>