<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">JISP</journal-id><journal-title-group><journal-title>Journal of Image and Signal Processing</journal-title></journal-title-group><issn pub-type="epub">2325-6753</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/JISP.2015.44017</article-id><article-id pub-id-type="publisher-id">JISP-16232</article-id><article-categories><subj-group subj-group-type="heading"><subject>JISP20150400000_79352923.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于对SIFT算法优化的图像拼接技术
  Image Mosaic Technology Based on an Optimized Method of SIFT Algorithm
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>杨</surname><given-names>程</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>徐</surname><given-names>晓刚</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>徐</surname><given-names>冠雷</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib></contrib-group><aff id="aff1"><addr-line>海军大连舰艇学院，辽宁 大连</addr-line></aff><aff id="aff2"><addr-line>null</addr-line></aff><author-notes><corresp id="cor1">* E-mail:<email>245591167@qq.com(杨程)</email>;</corresp></author-notes><pub-date pub-type="epub"><day>08</day><month>10</month><year>2015</year></pub-date><volume>04</volume><issue>04</issue><fpage>139</fpage><lpage>145</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   针对利用SIFT算法的图像拼接在匹配过程中会出现一些错误的特征点问题，提出一种对SIFT算法优化的方法。利用算法将错误的特征点除去，并且利用最小二乘法对提纯后的图像进行拟合，提高了匹配精度，对拼接效果有较好的增强，同时也缩短了拼接的时间。实验结果表明，优化后的算法可实现相对较好效果的图像拼接。 In order to solve the problems of wrong feature points in the process of image mosaic algorithm based on SIFT, an optimized method is put forward. Using a new algorithm to eliminate the wrong feature points, and using the least square method to fit the new picture not only improve the matching accuracy, but also improve the image mosaic result and reduce the time of the image mosaic. Experimental results demonstrate that the method can produce high quality image mosaic.
    
  
 
</p></abstract><kwd-group><kwd>SIFT，图像拼接，最小二乘法, SIFT</kwd><kwd> Image Mosaic</kwd><kwd> The Least Square Method</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>基于对SIFT算法优化的图像拼接技术<sup> </sup></title><p>杨程，徐晓刚，徐冠雷</p><p>海军大连舰艇学院，辽宁 大连</p><p>Email: 245591167@qq.com</p><p>收稿日期：2015年10月6日；录用日期：2015年10月21日；发布日期：2015年10月27日</p><disp-formula id="hanspub.16232-formula786"><graphic xlink:href="http://html.hanspub.org/file/9-2670061x5_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>针对利用SIFT算法的图像拼接在匹配过程中会出现一些错误的特征点问题，提出一种对SIFT算法优化的方法。利用算法将错误的特征点除去，并且利用最小二乘法对提纯后的图像进行拟合，提高了匹配精度，对拼接效果有较好的增强，同时也缩短了拼接的时间。实验结果表明，优化后的算法可实现相对较好效果的图像拼接。</p><p>关键词 :SIFT，图像拼接，最小二乘法</p><disp-formula id="hanspub.16232-formula787"><graphic xlink:href="http://html.hanspub.org/file/9-2670061x6_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s3"><title>1. 引言</title><p>随着计算机视觉领域的发展，图像拼接技术变成计算机图形学的一个重要的研究内容。对于不同的需要，将具有相同特征点的多幅图像拼接成一幅全景图[<xref ref-type="bibr" rid="hanspub.16232-ref1">1</xref>] ，就能实现对需要观察的区域进行整体的实时观察。最早MORAVEC提出了基于点算子实现立体视觉匹配[<xref ref-type="bibr" rid="hanspub.16232-ref2">2</xref>] ；之后HARRIS等人对MORAVEC算子进行了改进[<xref ref-type="bibr" rid="hanspub.16232-ref3">3</xref>] ，但它对尺度、视角、照明变化比较敏感，而且抗噪声能力较差；LOWE提出一种更加稳定的SIFT算子[<xref ref-type="bibr" rid="hanspub.16232-ref4">4</xref>] 。现有的拼接算法存在特征点提取不精确、拼接速度较慢等缺点。本文对SIFT算法进行了优化，先对SIFT算法匹配的特征点提纯，再用最小二乘法对提纯后的图像拟合，通过对特征点的提纯从而减少特征点的数量，同时也缩短了图像拼接的时间。</p></sec><sec id="s4"><title>2. SIFT算法的特征匹配</title><sec id="s4_1"><title>2.1. 构建尺度空间</title><p>尺度空间 [<xref ref-type="bibr" rid="hanspub.16232-ref5">5</xref>] 建立的目的是模拟图像数据的多尺度特征。由Lindeberg等人证明了高斯卷积核是实现尺度变换的唯一线性核 [<xref ref-type="bibr" rid="hanspub.16232-ref6">6</xref>] 。对于一幅二维图像的尺度空间定义如下：</p><disp-formula id="hanspub.16232-formula788"><graphic xlink:href="http://html.hanspub.org/file/9-2670061x7_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/9-2670061x8_hanspub.png" xlink:type="simple"/></inline-formula>是尺度可变高斯函数。<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/9-2670061x9_hanspub.png" xlink:type="simple"/></inline-formula>是图像的空间坐标，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/9-2670061x10_hanspub.png" xlink:type="simple"/></inline-formula>是尺度空间因子。对于不同的<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/9-2670061x11_hanspub.png" xlink:type="simple"/></inline-formula>，图像的平滑程度也不同，大的<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/9-2670061x12_hanspub.png" xlink:type="simple"/></inline-formula>值表示该图像被平滑的多，相对来说较粗糙。小的<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/9-2670061x13_hanspub.png" xlink:type="simple"/></inline-formula>值表示该图像被平滑的少，相对精细。通过建立尺度空间，构建出高斯差分尺度空间(DOG scale-space)，可以有效的获得稳定的特征点。DOG结果是通过每组上下相邻两层的高斯尺度空间图像相减得到的，如图1左部分所示。图1是由DOG算子如下：</p></sec><sec id="s4_2"><title>2.2. 点的搜索与定位</title><p>通过同一组内各个DOG相邻层之间的比较，完成关键点的搜索 [<xref ref-type="bibr" rid="hanspub.16232-ref7">7</xref>] 。为了寻找尺度空间的极值点，每一个采样点要和它所有的相邻点进行比较，如图2所示，中间的检测点和它同尺度的8个相邻点和上下相邻尺度对应的9 &#215; 2个点共26个点比较，确保在尺度空间和二维图像位置空间都检测到极值点。若待测检测点在本层已经上下两层的26个点中是最大值或最小值，则认为该点是图像在该尺度下的一个极值点。以上极值点的搜索并不是真正意义上的极值点，因为搜索是在离散空间中进行的，所以要用已知的离散空间点插值得到连续空间的极值点。运用泰勒级数展开，可以得到极值点。</p><p>图1. 高斯差分尺度空间</p><p>图2. 尺度空间关键点检测</p><p>泰勒展开式：</p><disp-formula id="hanspub.16232-formula789"><label>(1)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/9-2670061x17_hanspub.png"  xlink:type="simple"/></disp-formula><p>同时对等式两变求导，求<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/9-2670061x18_hanspub.png" xlink:type="simple"/></inline-formula>的极值，即令<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/9-2670061x19_hanspub.png" xlink:type="simple"/></inline-formula>，得</p><p>极值点所在的矢量位置：</p><disp-formula id="hanspub.16232-formula790"><label>(2)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/9-2670061x20_hanspub.png"  xlink:type="simple"/></disp-formula><p>将(2)代入(1)中可以得到极值点的极值：</p><disp-formula id="hanspub.16232-formula791"><graphic xlink:href="http://html.hanspub.org/file/9-2670061x21_hanspub.png"  xlink:type="simple"/></disp-formula><p>如果<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/9-2670061x22_hanspub.png" xlink:type="simple"/></inline-formula>时(假设图像的灰度值在<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/9-2670061x23_hanspub.png" xlink:type="simple"/></inline-formula>之间)，其响应过小，这样容易受到噪声的干扰，应丢弃。</p></sec><sec id="s4_3"><title>2.3. 赋予特征点128维参数方向</title><p>前面确定了特征点，为每个特征点计算一个方向，利用关键点邻域像素的梯度方向分布特性为每个关键点指定方向参数，使算子具备旋转不变性 [<xref ref-type="bibr" rid="hanspub.16232-ref8">8</xref>] 。</p><disp-formula id="hanspub.16232-formula792"><graphic xlink:href="http://html.hanspub.org/file/9-2670061x24_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/9-2670061x25_hanspub.png" xlink:type="simple"/></inline-formula>为像素点梯度模值，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/9-2670061x26_hanspub.png" xlink:type="simple"/></inline-formula>为像素点方向，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/9-2670061x27_hanspub.png" xlink:type="simple"/></inline-formula>为关键点所处的尺度。</p></sec><sec id="s4_4"><title>2.4. 特征描述</title><p>以关键点为中心取8 &#215; 8的窗口，如图3。</p><p>图左中央部分为关键点，每个小格代表关键点邻域所在空间的一个像素，根据泰勒公式求出每个像素的梯度幅值与梯度方向，箭头方向代表梯度方向，箭头长度代表梯度模值，这样可以得到4 &#215; 4 &#215; 8 = 128维的特征向量。通过大量实验证明，128维特征向量的描述符的不变性与独特性的综合效果最优，增强了算法抗噪声的能力。</p></sec></sec><sec id="s5"><title>3. 利用Ransac算法进行特征点筛选</title><p>由于图像会受到噪声，光照等许多因素影响，经过上面搜索方法后得到的最近邻会存在较多的误匹配点，所以要对搜索到的点进行匹配提纯。</p><sec id="s5_1"><title>3.1. Ransac算法的描述</title><p>通过采样和验证的策略，求解大部分特征点都可以满足的数学模型的参数 [<xref ref-type="bibr" rid="hanspub.16232-ref9">9</xref>] 。每次从数据集中采样模型需要的最少数目样本，计算模型的参数，然后在数据集中统计符合该模型的参数的样本数目，最多样本符合的参数就被认为是最终模型的参数值。符合模型样本的点叫做内点，不符合模型的样本点就叫做外点。在Ransac算法中，有3个参数会对其性能产生影响。这3个参数分别是：判断内外点距离阈值，估计次数和一致性集合大小阈值。</p><p>1) 内外点的距离阈值。这个阈值用来判定数据点是内点或者外点。</p><p>2) 估计次数N。令w为数据是真是数学模型内点的概率，n为确定模型参数的最少点数，如果要确定变换关系，则需要4个匹配对，即n = 4。这样，依次估计中使用的所有n个点都为内点的概率就是<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/9-2670061x28_hanspub.png" xlink:type="simple"/></inline-formula>。如果要保证经过N次至少有一次估计中的所有数据点都是内点的概率是p，那么N需要满足：</p><disp-formula id="hanspub.16232-formula793"><graphic xlink:href="http://html.hanspub.org/file/9-2670061x29_hanspub.png"  xlink:type="simple"/></disp-formula><p>3) 一致性集合大小阈值。估计得到模型的参数后，还要统计整个数据集中符合该模型的内点数目t。令数据点是错误模型内点的概率为y，我们希望错误模型的内点数目t越小越好，即</p><p><inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/9-2670061x30_hanspub.png" xlink:type="simple"/></inline-formula><inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/9-2670061x31_hanspub.png" xlink:type="simple"/></inline-formula>的值很小，一般取0.05。</p></sec><sec id="s5_2"><title>3.2. 本文的方法</title><p>通过SIFT算法对目标图片进行粗匹配，然后根据粗匹配的特征点集合，用Ransac算法将错误的特征点剔除，进而提高匹配的精度，得到第二次匹配的特征点集合。最后再用最小二乘法最大程度的拟合所有数据点，使得优化后的图像匹配的数据点最靠近真实的点，最后进行拼接。从图4中可以看出优化后的拟合线可以较好的还原真实的曲线。</p><p>图3. 关键点邻域梯度信息生成特征向量</p><p>图4. 利用最小二乘法拟合示意</p></sec></sec><sec id="s6"><title>4. 实验结果</title><p>从实验结果来看，图5(c)、图5(d)两图表明在寻找特征点时，直接用SIFT算法会有一些明显错误的匹配点，而优化后的算法匹配结果较准确。图5(e)、图5(f)两图表明用SIFT算法找到特征点拼接时拼接出的图像在一定区域内存在重影，而优化后拼接的图像效果较好。表1列出的数据表明通过Ransac算法提纯后再用最小二乘法进行拟合匹配的特征点数目为102个，而直接用SIFT算法匹配找的的特征点数目是114个，优化后的算法对存在错误的特征点进行了很好的消除。拼接时间方面直接用SIFT算法拼接图像需要0.83秒，优化后的算法拼接图像需要0.79秒，时间上缩短了0.04秒，优化后的算法在图像拼接中提高了拼接的速度。</p></sec><sec id="s7"><title>5. 结束语</title><p>本文对SIFT算法进行了的介绍，并且指出了SIFT算法的优点和缺点。针对SIFT算法的缺点引出了一种优化后的算法。通过实验表明优化后的算法不仅保存了SIFT算法的优点，而且剔除了SIFT算法在</p><p>图5. (a) 待拼接图像1；(b) 待拼接图像2；(c) SIFT算法匹配结果；(d) 优化后匹配结果；(e) 直接拼接后的结果；(f) 优化后拼接的结果</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Comparison between SIFT and optimized metho</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" >SIFT算法</th><th align="center" valign="middle" >优化后</th></tr></thead><tr><td align="center" valign="middle" >待拼接图像1特征点数</td><td align="center" valign="middle" >385</td><td align="center" valign="middle" >385</td></tr><tr><td align="center" valign="middle" >待拼接图像2特征点数</td><td align="center" valign="middle" >468</td><td align="center" valign="middle" >468</td></tr><tr><td align="center" valign="middle" >匹配到的特征点数</td><td align="center" valign="middle" >114</td><td align="center" valign="middle" >102</td></tr><tr><td align="center" valign="middle" >图像拼接时间</td><td align="center" valign="middle" >0.83秒</td><td align="center" valign="middle" >0.79秒</td></tr></tbody></table></table-wrap><p>表1. SIFT算法和优化后算法的数据对比</p><p>图像匹配时错误的特征点，使得匹配的准确性更高，图像拼接的速度更快、效果更好。今后要进一步探讨在有外界干扰的情况下图像匹配的稳定性以及匹配的精度问题，从而提高算法整体的性能。</p></sec><sec id="s8"><title>文章引用</title><p>杨 程,徐晓刚,徐冠雷. 基于对SIFT算法优化的图像拼接技术 Image Mosaic Technology Based on an Optimized Method of SIFT Algorithm[J]. 图像与信号处理, 2015, 04(04): 139-145. http://dx.doi.org/10.12677/JISP.2015.44017</p></sec><sec id="s9"><title>参考文献 (References)</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.16232-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">袁杰 (2013) 基于SIFT的图像配准与拼接技术研究. 南京理工大学, 南京.</mixed-citation></ref><ref id="hanspub.16232-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Moravec, H.P. (1981) Rover visual obstacle avoidance. International Joint Conference on Artificial Intelligence, 3, 117-118.</mixed-citation></ref><ref id="hanspub.16232-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Harris, C.G. and Stephens, M. (1988) A combined corner and edge detector. Proceedings of Fourth Alvey Vision Conference, 147-151.</mixed-citation></ref><ref id="hanspub.16232-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Lowe, D.G. (2004) Distinctive image features from scale-invariant key points. International Journal of Computer Vision, 60, 91-110. &lt;br&gt;http://dx.doi.org/10.1023/B:VISI.0000029664.99615.94</mixed-citation></ref><ref id="hanspub.16232-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Perona, P., Malik, J., Perona, P., et al. (1990) Scale-space filtering and edge detection using anisotropic diffusion. IEEE Transactions on Pattern Analysis &amp; Machine Intelligence, 12, 629-639. &lt;br&gt;http://dx.doi.org/10.1109/34.56205</mixed-citation></ref><ref id="hanspub.16232-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Lindeberg, T. (1994) Scale-space theory: A basic tool for analysing structures at different scales. Journal of Applied Statistics, 21, 224- 270.</mixed-citation></ref><ref id="hanspub.16232-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Liao, K., Liu, G. and Hui, Y. (2013) An improvement to the SIFT descriptor for image representation and matching. Pattern Recognition Letters, 34, 1211-1220. &lt;br&gt;http://dx.doi.org/10.1016/j.patrec.2013.03.021</mixed-citation></ref><ref id="hanspub.16232-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Zhong, S., Wang, J., Yan, L., et al. (2013) A real-time embedded architecture for SIFT. Journal of Systems Architecture the Euromicro Journal, 59, 16-29. &lt;br&gt;http://dx.doi.org/10.1016/j.sysarc.2012.09.002</mixed-citation></ref><ref id="hanspub.16232-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Wu, X., Zhao, Q. and Bu, W. (2014) A SIFT-based contactless palmprint verification approach using iterative RANSAC and local palmprint descriptors. Pattern Recognition, 47, 3314-3326. 
&lt;br&gt;http://dx.doi.org/10.1016/j.patcog.2014.04.008</mixed-citation></ref></ref-list></back></article>