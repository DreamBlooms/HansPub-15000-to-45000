<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">AP</journal-id><journal-title-group><journal-title>Advances in Psychology</journal-title></journal-title-group><issn pub-type="epub">2160-7273</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/AP.2019.910203</article-id><article-id pub-id-type="publisher-id">AP-32422</article-id><article-categories><subj-group subj-group-type="heading"><subject>AP20191000000_14619837.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>人文社科</subject><subject> 合作期刊</subject></subj-group></article-categories><title-group><article-title>
 
 
  从认知神经科学的角度看表情符号与真实面孔的异同
  The Similarities and Differences between Emoji and Real Faces from the Perspective of Cognitive Neuroscience
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>岳</surname><given-names>亚奇</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>李</surname><given-names>杨楠</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib></contrib-group><aff id="aff3"><addr-line>河南大学，河南 开封</addr-line></aff><aff id="aff2"><addr-line>null</addr-line></aff><aff id="aff1"><addr-line>石河子大学，新疆 石河子</addr-line></aff><pub-date pub-type="epub"><day>30</day><month>09</month><year>2019</year></pub-date><volume>09</volume><issue>10</issue><fpage>1677</fpage><lpage>1684</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
  表情符号是一种对真实面孔简化后的图像，在当下基于互联网的交流中有着庞大的应用市场。目前，在表情符号的研究中存在争议性的问题有：表情符号是否可以归入面孔感知的范畴；二者之间的处理是否存在相似的神经基础；这些争议也为表情符号的后续研究指明了方向，即符号化的面孔在在人脸识别中起着什么样的作用；不同情感意义的表情符号与人类表情处理之间的反应差异；探讨表情符号刺激与脑电成分间的关系；采用多种方法的结合从不同层面深入揭示表情符号的认知机制。&lt;br/&gt;Emoji is a simplified image of real faces. It has a huge application market in current Internet-based communication. At present, there are controversial questions in the study of emoji: whether emoji can be classified into the category of face perception; whether there is a similar neural basis for the treatment between the two. These controversies also point the way to the follow-up study of emoji, that is, what role does the symbolized face play in face recognition; the difference between the expressions of different emotional meanings and human expression processing; the relationship between stimulation and EEG components; the combination of multiple methods reveals the cognitive mechanisms of emoji from different levels.
 
</p></abstract><kwd-group><kwd>表情符号，真实面孔，神经机制, Emoji</kwd><kwd> Real Face</kwd><kwd> Neural Mechanism</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>从认知神经科学的角度看表情符号与真实面孔的异同<sup> </sup></title><p>岳亚奇<sup>1</sup>，李杨楠<sup>2</sup></p><p><sup>1</sup>石河子大学，新疆 石河子</p><p><sup>2</sup>河南大学，河南 开封</p><p><img src="//html.hanspub.org/file/1-1131681x1_hanspub.png" /></p><p>收稿日期：2019年9月8日；录用日期：2019年9月23日；发布日期：2019年9月30日</p><disp-formula id="hanspub.32422-formula4"><graphic xlink:href="//html.hanspub.org/file/1-1131681x5_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>表情符号是一种对真实面孔简化后的图像，在当下基于互联网的交流中有着庞大的应用市场。目前，在表情符号的研究中存在争议性的问题有：表情符号是否可以归入面孔感知的范畴；二者之间的处理是否存在相似的神经基础；这些争议也为表情符号的后续研究指明了方向，即符号化的面孔在在人脸识别中起着什么样的作用；不同情感意义的表情符号与人类表情处理之间的反应差异；探讨表情符号刺激与脑电成分间的关系；采用多种方法的结合从不同层面深入揭示表情符号的认知机制。</p><p>关键词 :表情符号，真实面孔，神经机制</p><disp-formula id="hanspub.32422-formula5"><graphic xlink:href="//html.hanspub.org/file/1-1131681x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2019 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/1-1131681x7_hanspub.png" /> <img src="//html.hanspub.org/file/1-1131681x8_hanspub.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>表情符号是一种类似真实面部表情的图形符号，相比较于人类的真实面孔，它所具有的面部特征往往被简化，省略或者被夸大。自1982年法尔曼教授在键盘上随意敲打出第一个笑脸符号“:-)”以来，这些由字符组成的表情就开始风靡于各种电子邮件、聊天软件中(Rongbin, 2019)。随着计算机通讯的进一步发展，表情符号的设计逐渐向真实人脸靠拢并快速成为广大网民在线传达情感的“官方语言”。在此背景下，各式各样的“表情包”和“斗图”等活动越来越受到年轻化群体的欢迎。</p><p>表情符号、表情包的流行除了设计者、自媒体作为推手以外，其本身也符合网友们的需要。互联网的发展使人们的沟通方式发生了重大改变，越来越多的人使用表情符号来传递情感状态(Prada et al., 2018)。Huang, Yen, &amp; Zhang (2008)指出表情符号作为一种人性化的情感表达工具取代了面对面交流中自然面部变化的线索，它解决了面孔不可视的情况下对话信息会引起误解的尴尬情况，同时也为网友们提供了更多的乐趣和信息。Schuller和Batliner (2013)也曾提出表情符号可以改变人际间的互动倾向，影响人们的决策、情绪以及谈话的重点。因此，表情符号很好地适应了社交网络对非言语信息的需求(Weib, Gutzeit, Rodrigues, Mussel, &amp; Hewig, 2018)。近年来，关于表情符号是如何被我们大脑处理的问题引起了认知神经科学家们的重视(Kappenman &amp; Luck, 2012)。作者在对此相关领域的文献梳理中发现主要的争议集中在：大脑对表情符号与面部表情这两种非言语信息的处理是否存在着相似的神经活动机制。本文将以此入手，系统回顾了功能性核磁共振与事件相关电位的研究，并简要展望后续的研究方向。</p></sec><sec id="s4"><title>2. 功能性核磁共振的研究</title><p>表情符号与真实面孔是否在同一脑区被处理是解决这一问题的关键，参与面部处理的脑结构之一是大脑的右侧梭状回(fusiform face area)，面孔失认症的患者该区会发生明显的病变(Kanwisher &amp; Yovel 2006)。理论上来说，如果表情符号的处理涉及到人们对面孔的认知，那么右侧梭状回应会处于明显的激活状态。</p><p>最初的fMRI研究表明，孤立的表情符号在处理过程中并不激活与面孔识别相同的大脑区域。然而，它们激活了与情感处理相关的区域。Yuasa (2006)等研究者对比了被试观看快乐(^-^)、悲伤(T_T)的颜文字表情和面孔时发现，人类面孔激活了右侧梭状回、右额下回(right inferior frontal gyrus)、右额中回(right middle frontal gyrus)和右侧顶叶(right inferior parietal lobe)部分；表情符号虽然没有激活右侧梭状回，但激活了右额下回(如图1所示)。这些发现表明，表情符号可能与情绪辨别有关。</p><p>图1. 阴影区域表示(1)右侧梭状回(2)右侧额下回(3)右侧额中回(4)右侧顶叶下叶的活动区域</p><p>在后续的一项研究中，Yuasa, Saito, &amp; Mukawa (2011)调查了在句子末尾添加表情符号时大脑的活动状态，结果发现表情符号与非语言信息的处理有关，句子末尾添加表情符号使大脑的非语言处理区域(左右侧额下回)更加活跃。此外，还观察到了与语言理解相关的布洛卡区域的脑活动增加，但右侧梭状会仍然未激活。Yuasa的结果表明，这种基于表情符号的情感识别与其它非语言线索达到的效果一样，但该处理过程并不涉及到对面孔的认知。在另一项研究中，Shin (2008)等人为了观察符号识别的神经基础，将真实面孔和真实房屋图片的大脑活动与其相应的图标进行了比较。结果发现表情符号的大脑皮层激活要大于皮质下的活动，其中主要涉及到额叶(frontal)与顶叶皮层(parietal cortex)，以及腹侧通路中的颞叶(temporo)和枕叶(occipital)连接处的激活。作者认为，这种激活对应于视觉概念形成的神经过程，将抽象性的视觉对象与具体化的物体区分开来。更有意义的是，他们观察到了被试在接触面孔符号期间双侧梭状回的激活。此外，Han (2014)等研究者观察了自闭症患者(autismspectrum disorder) (ASD)对表情符号和面部表情的梭状回活动情况。这些患者由于脑区发生的病变而产生了社交功能障碍，例如，ASD患者在看到情绪性面孔时梭状回不会出现活动(Critchley et al.,2000; Pierce et al., 2001)，在面部表情的辨别中亦没有显示出梭状回的激活(Schultz et al., 2000)。在Han (2014)的这项研究中，相比较于健康的被试，ASD患者在观看表情符号时右侧梭状回活动有着显著的增加(如图2所示)。</p><p>图2. 表情符号和面部表情的大脑活动</p><p>以上研究结果的不统一可能是因为实验材料与被试群体的选择不同导致的，比如，并不是所有的表情符号都有相同的人性化程度的，Yuasa (2006, 2011)等人在研究中所使用的表情符号则属于印刷体，与人脸的结构信息相去甚远。而Han (2014)等人的研究发现了ASD患者在识别表情符号时大脑梭状回的激活程度更高，可能是因为控制社会情感信息的补偿机制在发挥作用，所以这一结论尚不能推广到普通被试群体中。因此，关于表明符号和面部表情这两种非语言信息线索是否存在相似的神经机制的问题，还需进一步探讨。</p></sec><sec id="s5"><title>3. 事件相关电位的研究</title><p>事件相关电位(event related potential)技术具有低成本、高时间分辨率的优点，能够实时反映认知过程的输出，且能在没有行为反应的情况下提供关于刺激处理的测量，现已被广泛的应用于大脑高级皮质功能的研究。已经发现的与面部处理相关的ERP成分是N170 (Taylor, Batty, &amp; Itier, 2004; Rossion &amp; Caharel, 2003; Woodman, 2010)，它是在面部刺激呈现后约170 ms的时间里达到峰值的负波，与面部的结构编码(Bentin et al., 1996; Allison et al., 1999; McCarthy et al., 1999)以及人脸的特征处理相关(Gosling and Eimer 2011; Liu, Harris, and Kanwisher 2002; M&#252;hlberger et al. 2009)。目前已知的是，面部的示意图也会引起该成分的出现(Sagiv &amp; Bentin, 2001; Babiloni et al., 2010)。</p><p>关于表情符号的EEG记录在最近几年里也开始出现，Comesana, Soares, Perea, PiEiro, Fraga, &amp; Pinheiro, (2013)将表情符号作为内隐的情感启动刺激时发现它能起到很好的启动效应，与表情符号所对应的描述性情感词汇相比似乎有着独立的认知通道。随后，Churches (2014)等研究者单独比较了正立和倒置的表情符号的神经处理活动差异，发现了N170不同的波幅情况。具体为，表情符号在直立时引发较大N170波幅，反转会使N170的波幅降低(如图3所示)。他们认为，表情符号在直立时与面部知觉相类似，同样进行了构形处理。而关于倒置的表情符号引起较小的N170现象，Churches等研究者是这样解释的，表情符号中用来表示眼睛、鼻子、嘴巴的字符本身并不携带任何面孔信息，只有将它们视为一个整体时，才能与真实的面孔建立有意义的联系。也就是说，一旦倒置破坏了表情符号的结构时，它所包含的结构信息便已经失去了面孔的象征意义，变成了一个个零散的标点符号。这一结果暗示了表情符号虽然有与面孔相似的整体结构，但它的特征却不一定被我们进行面部处理。在另一项研究中，Taejin Park (2016)等研究者考察了表情符号在面部表情处理中与注意依赖的关系，发现了注意条件下的N170波幅在右半球对恐惧的表情符号表现出显著的情绪效应。在非注意条件下，任何的表情符号都没有表现出类似真实面孔表情所能够引起的情绪效应现象。所以他们认为，当人们投入足够多的注意力资源时，表情符号与人类情绪面孔的处理有着共同的神经活动基础。</p><p>图3. 表情符号在正立与倒置情况下P7(左)和P8(右)电极点N170的波幅差异情况</p><p>Cao &amp; Zhao (2018)在比较表情符号和情感词汇早期处理阶段的差异时发现，相比于情感词汇，表情符号引起的N170波在右侧枕颞叶皮质区域显示出更高的振幅以及更长的潜伏期。同时，也发现了表情符号的处理具有右半球优势。最近的一项研究中，Gantiva, Sotaquira, Araujo, &amp; Cuervo (2019)为了研究表情符号与真实面孔是否具有相似的神经处理过程，比较了开心、中性、愤怒三种情绪的面部图片以及表情符号的差异情况，结果表明表情符号引发的N170波幅显著的大于面孔(如图4)。</p><p>图4. 愉快(左)、中性(中)、愤怒(右)的表情符号与真实面孔的N170差异对比</p><p>他们认为可以用表情符号中眼睛或嘴巴等特征的大小和显著性相对增加来解释，这些特征的变化反过来会增进皮质处理。这一假设与过往的一些研究相吻合，Bentin (1996)和Taylor, Batty, &amp; Itier (2004)曾报告过只暴露眼睛的面部刺激与包含所有面部特征的人脸相比产生更高的N170振幅。Pesciarelli, Leo &amp; Sarlo (2016)也曾提出过眼睛是被自动处理程度最高的面部特征，能够改变由面部刺激引起的神经生理反应的幅度和潜伏期的分布状态。所以与人脸相比，表情符号往往只包含眼睛、嘴巴等主要的面部特征并且这些特征具有更高的显著性，这种夸张的设计可能同时增进了个体大脑皮层的处理。</p><p>以上这些证据都显示出表情符号的面部特征与真实面孔有着相似的神经活动。因为N170本身就是面部特异性的指标(Itier &amp; Taylor, 2004; Rossion et al., 2003)，结合源定位技术也已将它的产生源定位在了大脑的梭状回，即梭状回面孔识别区(fusiform face area) (Kanwisher, McDwemott, &amp; Chun, 1997; Itier &amp; Taylor, 2004)。多位研究者证实了表情符号的神经处理过程与面部表情十分相似，并且表情符号的面部特征似乎有着增强皮质处理的作用。</p></sec><sec id="s6"><title>4. 小结与展望</title><p>总体而言，经过研究者们的努力，对上述问题进行了广泛而深入的探讨。但关于后续的研究方向，作者提出以下几点建议，为以后的研究者们提供系统研究的思路。</p><p>首先，关于表情符号的识别是否与真实面孔表情的识别相类似，或者说表情符号的识别属于面孔识别的子集还是分属两个完全不同的认知通道，仍然是后续的一个主要研究方向。最早期的研究表明表情符号与真实面孔是两个完全独立的子集，但后来的报道却表明两者之间存在类似的神经活动，这可能是因为我们的大脑正在不断地适应的结果。此外，相比较于真实人脸，儿童通常喜欢符号化的卡通人脸，这种面孔对于自闭症的患者来说通常也更加容易处理(Rosset et al., 2008)。Kendall (2016)等研究者经过实验也发现过表情刺激符号化的程度越高，识别的正确率也随之提高的现象。后续的研究可以探讨一下这种符号化的面孔在面部的识别中能够起到何种作用。</p><p>其次，研究者也可以从表情符号的情感信息与真实面孔表情的处理差异入手，观察表情符号产生的情绪效应是否会与真实面孔不同。比如，愤怒和恐惧的表情通常会增大N170的振幅(Batty &amp; Taylor, 2003; Bublatzky et al., 2014; Ma et al., 2015)，快乐的表情也可以引起更大N170负波(Bublatzky et al., 2017)。后续的研究可以观察对不同情绪的表情符号识别过程中会产生怎样的神经机制活动。另外，人脸的识别会产生更大的LPP波幅，预示着更高的唤醒和注意的投入，也可以以此为指标检验表情符号是否参与与人脸相类似的调制。无论是表情符号还是真实的面孔，都包含了情绪识别的处理过程。而情绪面孔认知的研究方法主要包括情绪面孔数据库以及识别任务两部分(肖明岳，2019)，关于表情符号的研究也可以借鉴情绪面孔的研究方法完善这一领域。同时，也可以探讨表情符号所传递的情感信息对个体情绪调节的影响，为情绪调节在实践中的应用价值贡献力量(史书彦&amp;潘发达，2018)。事实上，也并不是所有的表情符号都具有相同的人性化程度，研究不同表情符号的形象特点(如印刷体、颜文字、表情包)对情绪传达的影响，将有利于发展通信技术以促进社会公共关系的发展。</p><p>最后，表情符号自身庞大的应用市场彰显了其本身独特魅力。从认知神经层面对它的探讨将有助于了解表情符号感知背后的处理机制，推动这一新兴领域开发和利用。尽管这方面的研究还处于起步阶段，但我们的大脑正在通过不同的处理方式适应一个充满表情符号的新奇世界。</p></sec><sec id="s7"><title>文章引用</title><p>岳亚奇,李杨楠. 从认知神经科学的角度看表情符号与真实面孔的异同The Similarities and Differences between Emoji and Real Faces from the Perspective of Cognitive Neuroscience[J]. 心理学进展, 2019, 09(10): 1677-1684. https://doi.org/10.12677/AP.2019.910203</p></sec><sec id="s8"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.32422-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">史书彦, 潘发达(2018). 情绪调节研究综述. 心理学进展, 8(10), 1486-1492.</mixed-citation></ref><ref id="hanspub.32422-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">肖明岳(2019). 情绪面孔认知研究方法综述. 心理学进展, 9(1), 11-17.</mixed-citation></ref><ref id="hanspub.32422-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Allison, T., Puce, A., Spencer, D. D., &amp; McCarthy, G. (1999). Electrophysiological Studies of Human Face Perception: Potentials Generated in Occipitotemporal Cortex by Face and Non-Face Stimuli. Cerebral Cortex, 9, 415-430.  
&lt;br&gt;https://doi.org/10.1093/cercor/9.5.415</mixed-citation></ref><ref id="hanspub.32422-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Babiloni, C., Vecchio, F., Buffffo, P., Buttiglione, M., Cibelli, G., &amp; Rossini, P. M. (2010). Cortical Responses to Consciousness of Schematic Emotional Facial Expressions: A High-Resolution EEG Study. Human Brain Mapping, 31, 1556-1569. &lt;br&gt;https://doi.org/10.1002/hbm.20958</mixed-citation></ref><ref id="hanspub.32422-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Batty, M., &amp; Taylor, M. J. (2003). Early Processing of the Six Basic Facial Emotional Expressions. Brain Research Cognitive Brain Research, 17, 613-620. &lt;br&gt;https://doi.org/10.1016/S0926-6410(03)00174-5</mixed-citation></ref><ref id="hanspub.32422-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Bentin, S., Allison, T., Puce, A., Perez, E., &amp; McCarthy, G. (1996). Electrophysiological Studies of Face Perception in Humans. Journal of Cognitive Neuroscience, 8, 551-565. &lt;br&gt;https://doi.org/10.1162/jocn.1996.8.6.551</mixed-citation></ref><ref id="hanspub.32422-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Bublatzky, F., Gerdes, A. B., White, A. J., Riemer, M., &amp; Alpers, G. W. (2014). Social and Emotional Relevance in Face Processing: Happy Faces of Future Interaction Partners Enhance the Late Positive Potential. Frontiers in Human Neuroscience, 8, 493-506. &lt;br&gt;https://doi.org/10.3389/fnhum.2014.00493</mixed-citation></ref><ref id="hanspub.32422-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Cao, J., &amp; Zhao, L. (2018). The Electrophysiological Correlates of Internet Language Processing Revealed by n170 Elicited by Network Emoticons. Neuroreport, 29, 1055-1060. &lt;br&gt;https://doi.org/10.1097/WNR.0000000000000954</mixed-citation></ref><ref id="hanspub.32422-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Churches, O., Nicholls, M., Thiessen, M., Kohler, M., &amp; Keage, H. (2014). Emoticons in Mind: An Event-Related Potential Study. Social Neuroscience, 9, 196-202. &lt;br&gt;https://doi.org/10.1080/17470919.2013.873737</mixed-citation></ref><ref id="hanspub.32422-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Comesana, M., Soares, A. P., Perea, M., PiEiro, A. P., Fraga, I., &amp; Pinheiro, A. (2013). ERP Correlates of Masked Affective Priming with Emoticons. Computers in Human Behavior, 29, 588-595. &lt;br&gt;https://doi.org/10.1016/j.chb.2012.10.020</mixed-citation></ref><ref id="hanspub.32422-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Critchley, H. D., Daly, E. M., Bullmore, E. T., Williams, S. C., Van Amelsvoort, T., Robertson, D. M. et al. (2000). The Functional Neuroanatomy of Social Behaviour. Brain, 123, 2203-2212. &lt;br&gt;https://doi.org/10.1093/brain/123.11.2203</mixed-citation></ref><ref id="hanspub.32422-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Gantiva, C., Sotaquira, M., Araujo, A., &amp; Cuervo, P. (2019). Cortical Processing of Human and Emoji Faces: An ERP Analysis. Behaviour &amp; Information Technology, 9, 1362-1370. &lt;br&gt;https://doi.org/10.1080/0144929X.2019.1632933</mixed-citation></ref><ref id="hanspub.32422-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Gosling, A., &amp; Eimer, M. (2011). An Event-Related Brain Potential Study of Explicit Face Recognition. Neuropsychologia, 49, 2736-2745. &lt;br&gt;https://doi.org/10.1016/j.neuropsychologia.2011.05.025</mixed-citation></ref><ref id="hanspub.32422-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">Han, D. H., Yoo, H. J., Kim, B. N., McMahon, W., &amp; Renshaw, P. F. (2014). Brain Activity of Adolescents with High Functioning Autism in Response to Emotional Words and Facial Emoticons. PLoS ONE, 9, e91214.  
&lt;br&gt;https://doi.org/10.1371/journal.pone.0091214</mixed-citation></ref><ref id="hanspub.32422-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">Huang, A. H., Yen, D. C., &amp; Zhang, X. (2008). Exploring the Potential Effects of Emoticons. Information &amp; Management, 45, 466-473. &lt;br&gt;https://doi.org/10.1016/j.im.2008.07.001</mixed-citation></ref><ref id="hanspub.32422-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">Itier, R. J., &amp; Taylor, M. J. (2004). N170 or N1? Spatiotemporal Differences between Object and Face Processing Using ERPs. Cerebral Cortex, 14, 132-142. &lt;br&gt;https://doi.org/10.1093/cercor/bhg111</mixed-citation></ref><ref id="hanspub.32422-ref17"><label>17</label><mixed-citation publication-type="other" xlink:type="simple">Kanwisher, N., &amp; Yovel, G. (2006). The Fusiform Face Area: A Cortical Region Specialized for the Perception of Faces. Philosophical Transactions of the Royal Society B: Biological Sciences, 361, 2109-2128.  
&lt;br&gt;https://doi.org/10.1098/rstb.2006.1934</mixed-citation></ref><ref id="hanspub.32422-ref18"><label>18</label><mixed-citation publication-type="other" xlink:type="simple">Kanwisher, N., McDermott, J., &amp; Chun, M. (1997). The Fusiform Face Area: A Module in Human Extrastriate Cortex Specialized for Face Perception. Journal of Neuroscience, 17, 4302-4311.  
&lt;br&gt;https://doi.org/10.1523/JNEUROSCI.17-11-04302.1997</mixed-citation></ref><ref id="hanspub.32422-ref19"><label>19</label><mixed-citation publication-type="other" xlink:type="simple">Kappenman, E. S., &amp; Luck, S. J. (2012). The Oxford Handbook of Event-Related Potential Components. Oxford: Oxford University Press. 54(1), 705-713. 
&lt;br&gt;https://doi.org/10.1093/oxfordhb/9780195374148.001.0001</mixed-citation></ref><ref id="hanspub.32422-ref20"><label>20</label><mixed-citation publication-type="other" xlink:type="simple">Kendall, L. N., Raffaelli, Q., Kingstone, A., &amp; Todd, R. M. (2016). Iconic Faces Are Not Real Faces: Enhanced Emotion Detection and Altered Neural Processing as Faces Become More Iconic. Cognitive Research: Principles and Implications, 1, 19. &lt;br&gt;https://doi.org/10.1186/s41235-016-0021-8</mixed-citation></ref><ref id="hanspub.32422-ref21"><label>21</label><mixed-citation publication-type="other" xlink:type="simple">Liu, J., Harris, A., &amp; Kanwisher, N. (2002). Stages of Processing in Face Perception: An MEG Study. Nature Neuroscience, 5, 910-916. &lt;br&gt;https://doi.org/10.1038/nn909</mixed-citation></ref><ref id="hanspub.32422-ref22"><label>22</label><mixed-citation publication-type="other" xlink:type="simple">Ma, Q., Hu, Y., Jiang, S., &amp; Meng, L. (2015). The Undermining Effect of Facial Attractiveness on Brain Responses to Fairness in the Ultimatum Game: An ERP Study. Frontiers in Neuroscience, 9, 77-86.  
&lt;br&gt;https://doi.org/10.3389/fnins.2015.00077</mixed-citation></ref><ref id="hanspub.32422-ref23"><label>23</label><mixed-citation publication-type="other" xlink:type="simple">McCarthy, G., Puce, A., Belger, A., &amp; Allison, T. (1999). Electrophysiological Studies of Human Face Perception. II: Response Properties of Face-Specific Potentials Generated in Occipitotemporal Cortex. Cerebral Cortex, 9, 431-444.  
&lt;br&gt;https://doi.org/10.1093/cercor/9.5.431</mixed-citation></ref><ref id="hanspub.32422-ref24"><label>24</label><mixed-citation publication-type="other" xlink:type="simple">Mühlberger, A., Wieser, M. J., Herrmann, M. J., Weyers, P., Tröger, C., &amp; Pauli, P. (2009). Early Cortical Processing of Natural and Artificial Emotional Faces Differs between Lower and Higher Socially Anxious Persons. Journal of Neural Transmission, 116, 735-746. &lt;br&gt;https://doi.org/10.1007/s00702-008-0108-6</mixed-citation></ref><ref id="hanspub.32422-ref25"><label>25</label><mixed-citation publication-type="other" xlink:type="simple">Park, T. (2016). Emotional Facial Expression Processing of Emoticon: An ERP Study. Social Cognitive and Affective Neuroscience, 1, 194-202.</mixed-citation></ref><ref id="hanspub.32422-ref26"><label>26</label><mixed-citation publication-type="other" xlink:type="simple">Pesciarelli, F., Leo, I., &amp; Sarlo, M. (2016). Implicit Processing of the Eyes and Mouth: Evidence from Human Electrophysiology. PLoS ONE, 11, e0147415. &lt;br&gt;https://doi.org/10.1371/journal.pone.0147415</mixed-citation></ref><ref id="hanspub.32422-ref27"><label>27</label><mixed-citation publication-type="other" xlink:type="simple">Pierce, K., Müller, R. A., Ambrose, J., Allen, G., &amp; Courchesne, E. (2001). Face Processing Occurs outside the Fusiform Face Area in Autism: Evidence from Functional MRI. Brain, 124, 2059-2073. &lt;br&gt;https://doi.org/10.1093/brain/124.10.2059</mixed-citation></ref><ref id="hanspub.32422-ref28"><label>28</label><mixed-citation publication-type="other" xlink:type="simple">Prada, M., Rodrigues, D. L., &amp; Garrido, M. V. (2018). Motives, Frequency and Attitudes toward Emoji and Emotion Use. Telematics and Informatics, 9, 1925-1934. &lt;br&gt;https://doi.org/10.1016/j.tele.2018.06.005</mixed-citation></ref><ref id="hanspub.32422-ref29"><label>29</label><mixed-citation publication-type="other" xlink:type="simple">Rongbin, W. (2019). The Semiotics of Emoji: The Rise of Visual Language in the Age of the Internet. Social Semiotics, 9, 557-559. &lt;br&gt;https://doi.org/10.1080/10350330.2018.1472864</mixed-citation></ref><ref id="hanspub.32422-ref30"><label>30</label><mixed-citation publication-type="other" xlink:type="simple">Rosset, D. B., Rondan, C., Da Fonseca, D., Santos, A., Assouline, B., &amp; Deruelle, C. (2008). Typical Emotion Processing for Cartoon But Not for Real Faces in Children with Autistic Spectrum Disorders. Journal of Autism and Developmental Disorders, 38, 919-925. &lt;br&gt;https://doi.org/10.1007/s10803-007-0465-2</mixed-citation></ref><ref id="hanspub.32422-ref31"><label>31</label><mixed-citation publication-type="other" xlink:type="simple">Rossion, B., &amp; Caharel, S. (2011). ERP Evidence for the Speed of Face Categorization in the Human Brain: Disentangling the Contribution of Low-Level Visual Cues from Face Perception. Vision Research, 51, 1297-1311.  
&lt;br&gt;https://doi.org/10.1016/j.visres.2011.04.003</mixed-citation></ref><ref id="hanspub.32422-ref32"><label>32</label><mixed-citation publication-type="other" xlink:type="simple">Rossion, B., Joyce, C. A., Cottrell, G. W., &amp; Tarr, M. J. (2003). Early Lateralization and Orientation Tuning for Face, Word, and Object Processing in the Visual Cortex. NeuroImage, 20, 1609-1624.  
&lt;br&gt;https://doi.org/10.1016/j.neuroimage.2003.07.010</mixed-citation></ref><ref id="hanspub.32422-ref33"><label>33</label><mixed-citation publication-type="other" xlink:type="simple">Sagiv, N., &amp; Bentin, S. (2001). Structural Encoding of Human and Schematic Faces: Holistic and Part-Based Processes. Journal of Cognitive Neuroscience, 13, 937-951. &lt;br&gt;https://doi.org/10.1162/089892901753165854</mixed-citation></ref><ref id="hanspub.32422-ref34"><label>34</label><mixed-citation publication-type="other" xlink:type="simple">Schultz, R. T., Gauthier, I., Klin, A., Fulbright, R. K., Erson, A. W., Volkmar, F. et al. (2000). Abnormal Ventral Temporal Cortical Activity during Face Discrimination among Individuals with Autism and Asperger Syndrome. Archives of General Psychiatry, 57, 331-340. &lt;br&gt;https://doi.org/10.1001/archpsyc.57.4.331</mixed-citation></ref><ref id="hanspub.32422-ref35"><label>35</label><mixed-citation publication-type="other" xlink:type="simple">Shin, Y. W., Kwon, J. S., Kwon, K. W., Gu, B. M., Song, I. C., Na, D. G. et al. (2008). Objects and Their Icons in the Brain: The Neural Correlates of Visual Concept Formation. Neuroscience Letters, 436, 300-304.  
&lt;br&gt;https://doi.org/10.1016/j.neulet.2008.03.047</mixed-citation></ref><ref id="hanspub.32422-ref36"><label>36</label><mixed-citation publication-type="other" xlink:type="simple">Taylor, M. J., Batty, M., &amp; Itier, R. J. (2004). The Faces of Development: A Review of Early Face Processing over Childhood. Journal of Cognitive Neuroscience, 16, 1426-1442. &lt;br&gt;https://doi.org/10.1162/0898929042304732</mixed-citation></ref><ref id="hanspub.32422-ref37"><label>37</label><mixed-citation publication-type="other" xlink:type="simple">Weib, M., Gutzeit, J., Rodrigues, J., Mussel, P., &amp; Hewig, J. (2018). Do Emojis Influence Social Interactions? Neural and Behavioral Responses to Affective Emojis in Bargaining Situations. Psychophysiology, 56, e13321.</mixed-citation></ref><ref id="hanspub.32422-ref38"><label>38</label><mixed-citation publication-type="other" xlink:type="simple">Woodman, G. F. (2010). A Brief Introduction to the Use of Event-Related Potentials (ERPs) in Studies of Perception and Attention. Attention and Perceptual Psychophysiology, 72, 2031-2046. &lt;br&gt;https://doi.org/10.3758/APP.72.8.2031</mixed-citation></ref><ref id="hanspub.32422-ref39"><label>39</label><mixed-citation publication-type="other" xlink:type="simple">Yuasa, M., Saito, K., &amp; Mukawa, N. (2006). Emoticons Convey Emotions without Cognition of Faces: An fMRI Study. Extended Abstracts on Human Factors in Computing Systems, 23, 1565-1570. &lt;br&gt;https://doi.org/10.1145/1125451.1125737</mixed-citation></ref><ref id="hanspub.32422-ref40"><label>40</label><mixed-citation publication-type="other" xlink:type="simple">Yuasa, M., Saito, K., &amp; Mukawa, N. (2011). Brain Activity When Reading Sentences and Emoticons: An fMRI Study of Verbal and Nonverbal Communication. Electronics &amp; Communications in Japan, 94, 17-24.  
&lt;br&gt;https://doi.org/10.1002/ecj.10311</mixed-citation></ref></ref-list></back></article>