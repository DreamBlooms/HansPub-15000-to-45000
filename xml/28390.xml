<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">AAM</journal-id><journal-title-group><journal-title>Advances in Applied Mathematics</journal-title></journal-title-group><issn pub-type="epub">2324-7991</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/AAM.2019.81005</article-id><article-id pub-id-type="publisher-id">AAM-28390</article-id><article-categories><subj-group subj-group-type="heading"><subject>AAM20190100000_83391805.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>数学与物理</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于一种新的特征选择方法的朴素贝叶斯分类器选择证券的研究
  Research on Security Selection by Naive Bayes Classifier Based on a New Feature Selection Method
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>郭</surname><given-names>盼盼</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>刘</surname><given-names>海军</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>李</surname><given-names>双双</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>郑州大学，数学与统计学院，河南 郑州</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>07</day><month>01</month><year>2019</year></pub-date><volume>08</volume><issue>01</issue><fpage>41</fpage><lpage>49</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
  
    本文提出了基于一种新的特征选择方法的朴素贝叶斯证券分类模型。首先，根据深交所50家公司2011年的交易数据和常用的18个指标，采取新的特征选择方法即互信息和主成分分析相结合选出用于分类的因子；其次，利用前10个月的数据建立朴素贝叶斯分类模型，用后两个月的数据检验模型的预测精度。实证分析表明模型的分类平均正确率达到75%，具有应用价值。
    In this paper, a naive Bayes classifier for securities selection based on a new feature selection method is established. Firstly, in consideration of the trading data of 50 companies in Shenzhen Stock Exchange and 18 commonly used indicators, a new feature selection method, i.e. the combi-nation of mutual information and principal component analysis, is adopted to select the value fac-tors for classification. Secondly, a naive Bayes classifier is constructed with the data of the first 10 months, and the prediction accuracy of the classifier is tested with that of the last two months. The empirical analysis shows that the average accuracy of the classifier reaches 75%, which is of ap-plication value. 
  
 
</p></abstract><kwd-group><kwd>特征选择，互信息，主成分分析，朴素贝叶斯分类器, Feature Selection</kwd><kwd> Mutual Information</kwd><kwd> Principal Component Analysis</kwd><kwd> Naive Bayes Classifier</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>基于一种新的特征选择方法的朴素贝叶斯分类器选择证券的研究<sup> </sup></title><p>郭盼盼，刘海军，李双双</p><p>郑州大学，数学与统计学院，河南 郑州</p><p><img src="//html.hanspub.org/file/5-2620815x1_hanspub.png" /></p><p>收稿日期：2018年12月18日；录用日期：2019年1月2日；发布日期：2019年1月9日</p><disp-formula id="hanspub.28390-formula43"><graphic xlink:href="//html.hanspub.org/file/5-2620815x5_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>本文提出了基于一种新的特征选择方法的朴素贝叶斯证券分类模型。首先，根据深交所50家公司2011年的交易数据和常用的18个指标，采取新的特征选择方法即互信息和主成分分析相结合选出用于分类的因子；其次，利用前10个月的数据建立朴素贝叶斯分类模型，用后两个月的数据检验模型的预测精度。实证分析表明模型的分类平均正确率达到75%，具有应用价值。</p><p>关键词 :特征选择，互信息，主成分分析，朴素贝叶斯分类器</p><disp-formula id="hanspub.28390-formula44"><graphic xlink:href="//html.hanspub.org/file/5-2620815x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2019 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/5-2620815x7_hanspub.png" /> <img src="//html.hanspub.org/file/5-2620815x8_hanspub.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>证券投资是金融研究领域的热门话题，如何选择证券是投资决策的关键。尽管投资者的盲目任意性和股票市场中的严重非线性给股票的预测与选择带来了很大的困难，事实表明，股票收益在一定程度上还是可以预测的 [<xref ref-type="bibr" rid="hanspub.28390-ref1">1</xref>] 。有不少人尝试关于数据挖掘技术比如决策树 [<xref ref-type="bibr" rid="hanspub.28390-ref2">2</xref>] [<xref ref-type="bibr" rid="hanspub.28390-ref3">3</xref>] [<xref ref-type="bibr" rid="hanspub.28390-ref4">4</xref>] 、分类器 [<xref ref-type="bibr" rid="hanspub.28390-ref5">5</xref>] [<xref ref-type="bibr" rid="hanspub.28390-ref6">6</xref>] [<xref ref-type="bibr" rid="hanspub.28390-ref7">7</xref>] 及神经网络 [<xref ref-type="bibr" rid="hanspub.28390-ref8">8</xref>] [<xref ref-type="bibr" rid="hanspub.28390-ref9">9</xref>] [<xref ref-type="bibr" rid="hanspub.28390-ref10">10</xref>] [<xref ref-type="bibr" rid="hanspub.28390-ref11">11</xref>] 等选股的研究。</p><p>钱颖能和胡运发 [<xref ref-type="bibr" rid="hanspub.28390-ref5">5</xref>] 使用2002年至2004年上海证券交易所的中报和年报的财务信息，利用朴素贝叶斯分类法对由超越市场指数而得到额外汇报的股票进行选择，结果表明朴素贝叶斯分类法在股票选择方面很有效；左辉和楼新远 [<xref ref-type="bibr" rid="hanspub.28390-ref6">6</xref>] 使用证券分析师推荐的股票数据并从中选取2007年1月8日到2007年10月29日的数据，用“事件研究”方法分析其总体特征，寻找符合特征的股票以求得到超额回报，然后用朴素贝叶斯分类法选股。结果表明朴素贝叶斯分类法在股票的短线操作上有实用价值。骆桦和张喜梅 [<xref ref-type="bibr" rid="hanspub.28390-ref7">7</xref>] 对沪深证券市场的能源股通过聚类分析选出对股票投资价值影响显著的财务指标构造样本特征集，再合理选取贝叶斯分类器的参数对股票分类。结果产生了44.6%累计回报率，优于32.4%的基准回报率。结果表明朴素贝叶斯分类法选股有较好的效果。如果利用不同的方法从较多的特征中筛选出有价值的特征，或许会得到更好的效果。</p><p>本文提出了基于一种新的特征选择方法的朴素贝叶斯证券分类模型，并且对深交所50家公司2011年的交易数据利用该模型分类，实证分析表明模型的平均正确率达到75%，具有应用价值。</p></sec><sec id="s4"><title>2. 预备知识</title><sec id="s4_1"><title>2.1. 特征选择</title><p>数据集中包含大量的特征，特征维度越高，计算越复杂，且其中包含的不相关特征和冗余特征会影响分类精度。特征选择可以定义为从原始N个特征中选出M个有价值特征的过程。特征选择方法可分为过滤式 [<xref ref-type="bibr" rid="hanspub.28390-ref12">12</xref>] 、封装式 [<xref ref-type="bibr" rid="hanspub.28390-ref13">13</xref>] 和混合式 [<xref ref-type="bibr" rid="hanspub.28390-ref14">14</xref>] 方法。过滤式方法独立于分类算法评估选取的特征的质量，封装式方法需要用分类器来评估这种质量，混合式方法是前两种方法的结合。</p></sec><sec id="s4_2"><title>2.2. 互信息</title><p>互信息是信息论里一种描述变量间相关性的信息度量。互信息的大小表示变量间包含共同信息的多少，变量耦合越强，互信息越大 [<xref ref-type="bibr" rid="hanspub.28390-ref15">15</xref>] 。互信息对变量的分布类型没有要求，能够描述变量间的线性及非线性相关关系，故在变量选择中得到了广泛应用 [<xref ref-type="bibr" rid="hanspub.28390-ref16">16</xref>] [<xref ref-type="bibr" rid="hanspub.28390-ref17">17</xref>] 。</p><p>设两个离散随机变量X和Y， p ( x , y ) 是X和Y的联合概率分布函数， p ( x ) 和 p ( y ) 分别是X和Y的边缘概率分布函数，根据互信息理论 [<xref ref-type="bibr" rid="hanspub.28390-ref18">18</xref>] ，随机变量X的熵 H ( X ) 表示随机变量X的不确定度，可以定义为：</p><p>H ( X ) = − ∑ x ∈ X p ( x ) log p ( x ) (1)</p><p>条件熵 H ( X | Y ) 表示在Y已知的条件下X的不确定度，可以定义为：</p><p>H ( X | Y ) = − ∑ y ∈ Y ∑ x ∈ X p ( x , y ) log p ( x | y ) (2)</p><p>互信息表示不确定度的减少量，可以用熵定义为：</p><p>I ( X ; Y ) = H ( X ) − H ( X | Y ) (3)</p><p>当X和Y相互独立即没有相关关系时，互信息为0；当X和Y不相互独立即有相关关系时，互信息为正数，且相关性越强，互信息越大。</p></sec><sec id="s4_3"><title>2.3. 主成分分析</title><sec id="s4_3_1"><title>2.3.1. 基本概念</title><p>主成分分析是将多指标化为少数几个综合指标的一种统计分析方法 [<xref ref-type="bibr" rid="hanspub.28390-ref19">19</xref>] 。</p><p>定义1 [<xref ref-type="bibr" rid="hanspub.28390-ref19">19</xref>] 设某样本包含p个变量，分别用 X 1 , X 2 , ⋯ , X p 表示，构成p维随机向量 X = ( X 1 , X 2 , ⋯ , X p ) ′ ，其中均值为 μ ，协方差矩阵为 Σ ，称 Y i = a ′ i X ( i = 1 , 2 , ⋯ , p ) 为X的第i主成分，如果：</p><p>1) a ′ i a i = 1 ( i = 1 , 2 , ⋯ , p ) ；</p><p>2) 当 i &gt; 1 时， a ′ i Σ a j = 0 ( j = 1 , 2 , ⋯ , i − 1 ) ；</p><p>3) V a r ( Y i ) = max a ′ a = 1 , a ′ i Σ a j = 0 ( j = 1 , ⋯ , i − 1 ) V a r ( a ′ X ) 。</p><p>定义2 [<xref ref-type="bibr" rid="hanspub.28390-ref19">19</xref>] 设随机向量 X = ( X 1 , X 2 , ⋯ , X p ) ′ 的协方差矩阵为 Σ ， λ 1 ≥ λ 2 ≥ ⋯ ≥ λ p ≥ 0 为 Σ 的特征值， a 1 , a 2 , ⋯ , a p 为相应的单位正交特征向量，则X的第i个主成分为：</p><p>Y i = a ′ i X = a 1 i X 1 + a 2 i X 2 + ⋯ + a p i X p ( i = 1 , 2 , ⋯ , p ) (4)</p><p>定义3 [<xref ref-type="bibr" rid="hanspub.28390-ref19">19</xref>] 称 λ k / ∑ i = 1 p λ i 为主成分 Y k 的贡献率，称 ∑ k = 1 m λ k / ∑ i = 1 p λ i 为主成分 Y 1 , Y 2 , ⋯ , Y m ( m &lt; p ) 的累计贡献率。</p></sec><sec id="s4_3_2"><title>2.3.2. 具体步骤</title><p>1) 用Z-score法对数据进行标准化变换</p><p>2) 求指标数据的相关矩阵</p><p>3) 求相关矩阵的特征根与特征向量</p><p>4) 计算主成分贡献率及累计贡献率，确定主成分(一般取累计贡献率为85%~95%的特征值所对应的主成分。)</p></sec></sec><sec id="s4_4"><title>2.4. 朴素贝叶斯分类器</title><sec id="s4_4_1"><title>2.4.1. 基本概念</title><p>贝叶斯分类是一种可以预测给定样本属于某个特定类的概率的统计学分析方法。贝叶斯分类技术通过对已分类的样本子集进行训练，学习归纳出分类函数，利用训练得到的分类器实现对未分类数据的分类。其中朴素贝叶斯分类器是解决相应问题的最实际的方法之一。朴素贝叶斯分类基于一个简单的假设：给定目标值的属性值之间相互条件独立 [<xref ref-type="bibr" rid="hanspub.28390-ref20">20</xref>] 。朴素贝叶斯分类器的原理是：给定待分类项，利用贝叶斯公式求解在此项出现的条件下各个类别出现的概率，哪个概率最大，就认为此待分类项属于哪个类别。</p></sec><sec id="s4_4_2"><title>2.4.2. 朴素贝叶斯分类器</title><p>设研究对象的属性值为 X = ( x 1 , x 2 , ⋯ , x n ) ，而目标值的属性值为 Y = ( y 1 , y 2 , ⋯ , y n ) ，假设有m个类 v 1 , v 2 , ⋯ , v m 。分类器考虑类的集合m并在其中寻找给定属性值 X = ( x 1 , x 2 , ⋯ , x n ) 时可能性最大的类 j ∈ m ，这种分类方法称为极大后验(MAP)分类，即： v M A P = arg max v j ∈ { v 1 , v 2 , ⋯ , v m } P ( v j | x 1 , x 2 , ⋯ , x n ) ，属性值已知的条件下</p><p>极大后验分类就是m个类中概率最大的一类。利用贝叶斯公式将其整理为</p><p>v M A P = arg max v j ∈ { v 1 , v 2 , ⋯ , v m } P ( x 1 , x 2 , ⋯ , x n | v j ) P ( v j ) P ( x 1 , x 2 , ⋯ , x n ) (5)</p><p>= arg max v j ∈ { v 1 , v 2 , ⋯ , v m } P ( x 1 , x 2 , ⋯ , x n | v j ) P ( v j ) (6)</p><p>其中， P ( x 1 , x 2 , ⋯ , x n | v j ) = ∏ i P ( x i | v j ) 。在条件独立假设成立时，朴素贝叶斯分类等于极大后验分类，因</p><p>而可得到朴素贝叶斯分类器的公式：</p><p>v N B = arg max v j ∈ { v 1 , v 2 , ⋯ , v m } P ( v j ) ∏ i P ( x i | v j ) (7)</p><p>如果类的先验概率 P ( v j ) 未知，则通常假设各类的先验概率相等，即： P ( v 1 ) = P ( v 2 ) = ⋯ = P ( v m ) 。概率 P ( x j | v i ) 可以由训练样本来估计。这里用m-估计 P ( x i | v j ) = ( n j i + m p ) / ( n j + m ) 来估计。其中， n j i 是</p><p>对应属性具有值 x i 的类 v j 的训练样本数，而 n j 是类 v j 的训练样本总数。p所求概率的先验估计，m为等效样本大小的常量。</p></sec></sec></sec><sec id="s5"><title>3. 数据，指标与因子</title><sec id="s5_1"><title>3.1. 数据</title><p>本文所用数据来自于锐思数据库。选取深圳证券交易所50只2011年1月4日至2011年12月31日股票，对数据中进行简单的预处理，主要包括补全数据和复权。</p></sec><sec id="s5_2"><title>3.2. 指标</title><p>所选指标有： Z 1 ：前收盘价、 Z 2 ：收盘价、 Z 3 ：开盘价、 Z 4 ：最高价、 Z 5 ：最低价、 Z 6 ：成交额、 Z 7 ：成交量、 Z 8 ：中价、 Z 9 ：5日收盘价均值、 Z 10 ：5日成交额均值、 Z 11 ：5日成交量均值、 Z 12 ：买卖指标AR、 Z 13 ：意愿指标BR、 Z 14 ：随机指标K、 Z 15 ：D、 Z 16 ：J、 Z 17 ：相对强弱指标RSI、 Z 18 ：日换手率。</p><sec id="s5_2_1"><title>3.2.1. 股票收益率</title><p>本文中的股票收益率是对数收益率，在 内的计算公式为：</p><p>R i , T = ln ( P i , T + Δ t + I i , T + Δ t P i , T ) (8)</p><p>其中， R i , T 是股票i在T时刻的收益率， P i , T 是股票i在T时刻的价格， P i , T + Δ t 是股票i在 T + Δ t 时刻的价格， I i , T + Δ t 是股票i在 [ T , T + Δ t ] 内的分红。</p></sec><sec id="s5_2_2"><title>3.2.2. 日换手率</title><p>换手率也成周转率，指在一定时间内市场中股票转手买卖的频率。日换手率是指某一个交易日中某支股票当日的日成交量初一该股的流通股本，即换手率 = 某一段时期内的成交量/发行总股数 &#215; 100%。</p></sec></sec><sec id="s5_3"><title>3.3. 因子的选取</title><p>计算每个原始指标与收益率之间的互信息。为了方便对股票数据的调用，本文按1.xls--50.xls的形式对存放数据信息的Excel表进行命名，借助MATLAB软件，通过编写程序一次性计算得到50家股票的这18个指标与收益率之间的互信息。其中前5家公司的结果如表1所示：</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Mutual information outcomes of the top five companie</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" >表格1</th><th align="center" valign="middle" >表格2</th><th align="center" valign="middle" >表格3</th><th align="center" valign="middle" >表格4</th><th align="center" valign="middle" >表格5</th></tr></thead><tr><td align="center" valign="middle" >I(Z<sub>1</sub>;Z<sub>19</sub>)</td><td align="center" valign="middle" >1.110359668</td><td align="center" valign="middle" >1.099889033</td><td align="center" valign="middle" >1.089842697</td><td align="center" valign="middle" >1.125920538</td><td align="center" valign="middle" >1.109784047</td></tr><tr><td align="center" valign="middle" >I(Z<sub>2</sub>;Z<sub>19</sub>)</td><td align="center" valign="middle" >1.10881697</td><td align="center" valign="middle" >1.117758017</td><td align="center" valign="middle" >1.098010072</td><td align="center" valign="middle" >1.124252332</td><td align="center" valign="middle" >1.117001218</td></tr><tr><td align="center" valign="middle" >I(Z<sub>3</sub>;Z<sub>19</sub>)</td><td align="center" valign="middle" >1.127126861</td><td align="center" valign="middle" >1.131420511</td><td align="center" valign="middle" >1.098508071</td><td align="center" valign="middle" >1.126748527</td><td align="center" valign="middle" >1.12507881</td></tr><tr><td align="center" valign="middle" >I(Z<sub>4</sub>;Z<sub>19</sub>)</td><td align="center" valign="middle" >1.117911243</td><td align="center" valign="middle" >1.124494251</td><td align="center" valign="middle" >1.098405772</td><td align="center" valign="middle" >1.125080478</td><td align="center" valign="middle" >1.125917003</td></tr><tr><td align="center" valign="middle" >I(Z<sub>5</sub>;Z<sub>19</sub>)</td><td align="center" valign="middle" >1.124473626</td><td align="center" valign="middle" >1.124494251</td><td align="center" valign="middle" >1.096169704</td><td align="center" valign="middle" >1.125080478</td><td align="center" valign="middle" >1.125917003</td></tr><tr><td align="center" valign="middle" >I(Z<sub>6</sub>;Z<sub>19</sub>)</td><td align="center" valign="middle" >1.122911464</td><td align="center" valign="middle" >1.120409902</td><td align="center" valign="middle" >1.096169704</td><td align="center" valign="middle" >1.125920538</td><td align="center" valign="middle" >1.129343262</td></tr><tr><td align="center" valign="middle" >I(Z<sub>7</sub>;Z<sub>19</sub>)</td><td align="center" valign="middle" >1.116737838</td><td align="center" valign="middle" >1.11559817</td><td align="center" valign="middle" >1.096650386</td><td align="center" valign="middle" >1.125920538</td><td align="center" valign="middle" >1.103221733</td></tr><tr><td align="center" valign="middle" >I(Z<sub>8</sub>;Z<sub>19</sub>)</td><td align="center" valign="middle" >0.474802198</td><td align="center" valign="middle" >0.471361895</td><td align="center" valign="middle" >0.811832636</td><td align="center" valign="middle" >0.494832378</td><td align="center" valign="middle" >0.389729731</td></tr><tr><td align="center" valign="middle" >I(Z<sub>9</sub>;Z<sub>19</sub>)</td><td align="center" valign="middle" >0.260569554</td><td align="center" valign="middle" >0.238567169</td><td align="center" valign="middle" >0.461843167</td><td align="center" valign="middle" >0.216786665</td><td align="center" valign="middle" >0.171769686</td></tr><tr><td align="center" valign="middle" >I(Z<sub>10</sub>;Z<sub>19</sub>)</td><td align="center" valign="middle" >0.414676474</td><td align="center" valign="middle" >0.388254771</td><td align="center" valign="middle" >0.73972281</td><td align="center" valign="middle" >0.44846479</td><td align="center" valign="middle" >0.325828778</td></tr><tr><td align="center" valign="middle" >I(Z<sub>11</sub>;Z<sub>19</sub>)</td><td align="center" valign="middle" >0.32151623</td><td align="center" valign="middle" >0.286835637</td><td align="center" valign="middle" >0.586627111</td><td align="center" valign="middle" >0.263599006</td><td align="center" valign="middle" >0.191785667</td></tr><tr><td align="center" valign="middle" >I(Z<sub>12</sub>;Z<sub>19</sub>)</td><td align="center" valign="middle" >0.091289193</td><td align="center" valign="middle" >0.026499282</td><td align="center" valign="middle" >0.17527769</td><td align="center" valign="middle" >0.076333218</td><td align="center" valign="middle" >0.065591362</td></tr><tr><td align="center" valign="middle" >I(Z<sub>14</sub>;Z<sub>19</sub>)</td><td align="center" valign="middle" >0.026951949</td><td align="center" valign="middle" >0.035696271</td><td align="center" valign="middle" >0.107708479</td><td align="center" valign="middle" >0.017773471</td><td align="center" valign="middle" >0.025841353</td></tr><tr><td align="center" valign="middle" >I(Z<sub>15</sub>;Z<sub>19</sub>)</td><td align="center" valign="middle" >0.035095403</td><td align="center" valign="middle" >0.038838678</td><td align="center" valign="middle" >0.110865222</td><td align="center" valign="middle" >0.021354449</td><td align="center" valign="middle" >0.030282553</td></tr><tr><td align="center" valign="middle" >I(Z<sub>16</sub>;Z<sub>19</sub>)</td><td align="center" valign="middle" >0.019787418</td><td align="center" valign="middle" >0.031444862</td><td align="center" valign="middle" >0.095732429</td><td align="center" valign="middle" >0.014057081</td><td align="center" valign="middle" >0.01621386</td></tr><tr><td align="center" valign="middle" >I(Z<sub>17</sub>;Z<sub>19</sub>)</td><td align="center" valign="middle" >0.072058185</td><td align="center" valign="middle" >0.054467933</td><td align="center" valign="middle" >0.221375307</td><td align="center" valign="middle" >0.080950792</td><td align="center" valign="middle" >0.089453431</td></tr><tr><td align="center" valign="middle" >I(Z<sub>18</sub>;Z<sub>19</sub>)</td><td align="center" valign="middle" >0.266973154</td><td align="center" valign="middle" >0.238567169</td><td align="center" valign="middle" >0.461843167</td><td align="center" valign="middle" >0.216786665</td><td align="center" valign="middle" >0.155561539</td></tr></tbody></table></table-wrap><p>表1. 前5家公司的互信息</p><p>表中 I ( Z j ; Z 19 ) ( j = 1 , 2 , ⋯ , 18 ) 表示第j个指标与收益率之间的互信息。从上述结果可以看出，5个表格均显示指标 Z 1 , Z 2 , Z 3 , Z 4 , Z 5 , Z 6 , Z 7 与收益率之间的互信息都大于1.5，指标 Z 8 , Z 9 , Z 10 , Z 11 , Z 18 与收益率之间的互信息都介于0.1和1.0之间，而有4个表格显示指标 Z 12 , Z 13 , Z 14 , Z 15 , Z 16 , Z 17 与收益率之间的互信息都小于0.1，只有表格3显示指标 Z 12 , Z 13 , Z 14 , Z 15 , Z 16 , Z 17 与收益率之间的互信息介于0.1和1.0之间，此种情况占比不大，对指标的选择影响不大。故可以认为指标 Z 1 , Z 2 , Z 3 , Z 4 , Z 5 , Z 6 , Z 7 , Z 8 , Z 9 , Z 10 , Z 11 对收益率有显著影响，指标 Z 12 , Z 13 , Z 14 , Z 15 , Z 16 , Z 17 对收益率无显著影响。此5个表格的结果可以反应整体情况，因此，选出 Z 1 , Z 2 , Z 3 , Z 4 , Z 5 , Z 6 , Z 7 , Z 8 , Z 9 , Z 10 , Z 11 , Z 18 作为主成分分析的指标。</p><p>对选出的指标进行主成分分析。以“东旭蓝天”即表格40为例，说明主成分分析过程。以预处理后的标准数据矩阵作为原始数据矩阵，计算其相关阵并绘制特征值图，如图1所示：</p><p>图1. 特征值</p><p>由图1可以看出，第二个主成分的变化趋势开始减慢，因此可以只考虑前两个主成分反映原有信息。相关阵的前两个特征值、对应的特征向量、贡献率及累计贡献率如表2。</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> Principal component resul</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" >主成分Y<sub>1</sub></th><th align="center" valign="middle" >主成分Y<sub>2</sub></th></tr></thead><tr><td align="center" valign="middle" >Z<sub>1</sub>：前收盘价</td><td align="center" valign="middle" >0.298643431</td><td align="center" valign="middle" >0.206278919</td></tr><tr><td align="center" valign="middle" >Z<sub>2</sub>：开盘价</td><td align="center" valign="middle" >0.299813199</td><td align="center" valign="middle" >0.176391377</td></tr><tr><td align="center" valign="middle" >Z<sub>3</sub>：最高价</td><td align="center" valign="middle" >0.300701394</td><td align="center" valign="middle" >0.170618405</td></tr><tr><td align="center" valign="middle" >Z<sub>4</sub>：最低价</td><td align="center" valign="middle" >0.295734648</td><td align="center" valign="middle" >0.244725169</td></tr><tr><td align="center" valign="middle" >Z<sub>5</sub>：收盘价</td><td align="center" valign="middle" >0.295985477</td><td align="center" valign="middle" >0.235804528</td></tr><tr><td align="center" valign="middle" >Z<sub>6</sub>：中价</td><td align="center" valign="middle" >0.298082313</td><td align="center" valign="middle" >0.21570945</td></tr><tr><td align="center" valign="middle" >Z<sub>7</sub>：5日收盘价均值</td><td align="center" valign="middle" >0.294324182</td><td align="center" valign="middle" >0.257869676</td></tr><tr><td align="center" valign="middle" >Z<sub>8</sub>：5日成交金额均值</td><td align="center" valign="middle" >0.293524812</td><td align="center" valign="middle" >−0.098104744</td></tr><tr><td align="center" valign="middle" >Z<sub>9</sub>：成交量</td><td align="center" valign="middle" >0.261981139</td><td align="center" valign="middle" >−0.493856614</td></tr><tr><td align="center" valign="middle" >Z<sub>10</sub>：成交金额</td><td align="center" valign="middle" >0.286372458</td><td align="center" valign="middle" >−0.239864428</td></tr><tr><td align="center" valign="middle" >Z<sub>11</sub>：5日成交量均值</td><td align="center" valign="middle" >0.273257891</td><td align="center" valign="middle" >−0.336067968</td></tr><tr><td align="center" valign="middle" >Z<sub>18</sub>：换手率</td><td align="center" valign="middle" >0.261699545</td><td align="center" valign="middle" >−0.494679098</td></tr><tr><td align="center" valign="middle" >特征值</td><td align="center" valign="middle" >9.411734966</td><td align="center" valign="middle" >2.111541604</td></tr><tr><td align="center" valign="middle" >贡献率</td><td align="center" valign="middle" >0.784311247</td><td align="center" valign="middle" >0.1759618</td></tr><tr><td align="center" valign="middle" >累计贡献率</td><td align="center" valign="middle" >0.784311247</td><td align="center" valign="middle" >0.96027304</td></tr></tbody></table></table-wrap><p>表2. 主成分结果</p><p>从表2中可以看出，前两个主成分的累计贡献率已经达到了96%，因此，只取前两个主成分，分别为：</p><p>Y 1 = 0.298643431 Z 1 + ⋯ + 0.273257891 Z 11 + 0.261699545 Z 18 Y 2 = 0.206278919 Z 1 − ⋯ − 0.336067968 Z 11 − 0.494679098 Z 18</p></sec></sec><sec id="s6"><title>4. 构建朴素贝叶斯分类器</title><p>将利用主成分分析所得的2个主成分 Y 1 、 Y 2 和收益率R训练朴素贝叶斯分类器规则。用均匀聚类法将主成分 Y 1 、 Y 2 离散化，分成3个类，将指标R离散化，分成4个类。因此，该分类器有4类， v 1 为低收益率类， v 4 为高收益率类， v 2 , v 3 为普通收益率类；有2个样本，每个样本有3个属性值。以表格40为例，2011年11月9日的主成分 、 Y 2 和收益率R的值分别为−1.6887、1.3689、4.47，离散化后为1、3、2。</p><p>将前10个月的数据作为训练集训练分类规则，后2个月的数据作为测试集检验分类规则的预测精度，通过Matlab软件编写程序一次性计算得到50家股票的分类结果。如表3所示。</p><table-wrap id="table3" ><label><xref ref-type="table" rid="table3">Table 3</xref></label><caption><title> Classification Situation </title></caption><table><tbody><thead><tr><th align="center" valign="middle" >表格</th><th align="center" valign="middle" >训练集正确率</th><th align="center" valign="middle" >测试集正确率</th><th align="center" valign="middle" >表格</th><th align="center" valign="middle" >训练集正确率</th><th align="center" valign="middle" >测试集正确率</th><th align="center" valign="middle" >表格</th><th align="center" valign="middle" >训练集正确率</th><th align="center" valign="middle" >测试集正确率</th></tr></thead><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" >0.770491803</td><td align="center" valign="middle" >0.918918919</td><td align="center" valign="middle" >18</td><td align="center" valign="middle" >0.628415301</td><td align="center" valign="middle" >0.783783784</td><td align="center" valign="middle" >35</td><td align="center" valign="middle" >0.677595628</td><td align="center" valign="middle" >0.702702703</td></tr><tr><td align="center" valign="middle" >2</td><td align="center" valign="middle" >0.683060109</td><td align="center" valign="middle" >0.540540541</td><td align="center" valign="middle" >19</td><td align="center" valign="middle" >0.732240437</td><td align="center" valign="middle" >0.837837838</td><td align="center" valign="middle" >36</td><td align="center" valign="middle" >0.726775956</td><td align="center" valign="middle" >0.945945946</td></tr><tr><td align="center" valign="middle" >3</td><td align="center" valign="middle" >0.606557377</td><td align="center" valign="middle" >0.72972973</td><td align="center" valign="middle" >20</td><td align="center" valign="middle" >0.797814208</td><td align="center" valign="middle" >0.702702703</td><td align="center" valign="middle" >37</td><td align="center" valign="middle" >0.672131148</td><td align="center" valign="middle" >0.864864865</td></tr><tr><td align="center" valign="middle" >4</td><td align="center" valign="middle" >0.74863388</td><td align="center" valign="middle" >0.783783784</td><td align="center" valign="middle" >21</td><td align="center" valign="middle" >0.715846995</td><td align="center" valign="middle" >0.702702703</td><td align="center" valign="middle" >38</td><td align="center" valign="middle" >0.699453552</td><td align="center" valign="middle" >0.702702703</td></tr><tr><td align="center" valign="middle" >5</td><td align="center" valign="middle" >0.655737705</td><td align="center" valign="middle" >0.945945946</td><td align="center" valign="middle" >22</td><td align="center" valign="middle" >0.737704918</td><td align="center" valign="middle" >0.891891892</td><td align="center" valign="middle" >39</td><td align="center" valign="middle" >0.765027322</td><td align="center" valign="middle" >0.486486486</td></tr><tr><td align="center" valign="middle" >6</td><td align="center" valign="middle" >0.781420765</td><td align="center" valign="middle" >0.783783784</td><td align="center" valign="middle" >23</td><td align="center" valign="middle" >0.584699454</td><td align="center" valign="middle" >0.594594595</td><td align="center" valign="middle" >40</td><td align="center" valign="middle" >0.841530055</td><td align="center" valign="middle" >0.972972973</td></tr><tr><td align="center" valign="middle" >7</td><td align="center" valign="middle" >0.693989071</td><td align="center" valign="middle" >0.783783784</td><td align="center" valign="middle" >24</td><td align="center" valign="middle" >0.726775956</td><td align="center" valign="middle" >0.702702703</td><td align="center" valign="middle" >41</td><td align="center" valign="middle" >0.677595628</td><td align="center" valign="middle" >0.648648649</td></tr><tr><td align="center" valign="middle" >8</td><td align="center" valign="middle" >0.644808743</td><td align="center" valign="middle" >0.837837838</td><td align="center" valign="middle" >25</td><td align="center" valign="middle" >0.721311475</td><td align="center" valign="middle" >0.945945946</td><td align="center" valign="middle" >42</td><td align="center" valign="middle" >0.743169399</td><td align="center" valign="middle" >0.459459459</td></tr><tr><td align="center" valign="middle" >9</td><td align="center" valign="middle" >0.721311475</td><td align="center" valign="middle" >0.810810811</td><td align="center" valign="middle" >26</td><td align="center" valign="middle" >0.704918033</td><td align="center" valign="middle" >0.891891892</td><td align="center" valign="middle" >43</td><td align="center" valign="middle" >0.754098361</td><td align="center" valign="middle" >0.648648649</td></tr><tr><td align="center" valign="middle" >10</td><td align="center" valign="middle" >0.754098361</td><td align="center" valign="middle" >0.405405405</td><td align="center" valign="middle" >27</td><td align="center" valign="middle" >0.661202186</td><td align="center" valign="middle" >0.810810811</td><td align="center" valign="middle" >44</td><td align="center" valign="middle" >0.770491803</td><td align="center" valign="middle" >0.675675676</td></tr><tr><td align="center" valign="middle" >11</td><td align="center" valign="middle" >0.792349727</td><td align="center" valign="middle" >0.567567568</td><td align="center" valign="middle" >28</td><td align="center" valign="middle" >0.655737705</td><td align="center" valign="middle" >0.72972973</td><td align="center" valign="middle" >45</td><td align="center" valign="middle" >0.721311475</td><td align="center" valign="middle" >0.675675676</td></tr><tr><td align="center" valign="middle" >12</td><td align="center" valign="middle" >0.704918033</td><td align="center" valign="middle" >0.918918919</td><td align="center" valign="middle" >29</td><td align="center" valign="middle" >0.699453552</td><td align="center" valign="middle" >0.891891892</td><td align="center" valign="middle" >46</td><td align="center" valign="middle" >0.765027322</td><td align="center" valign="middle" >0.648648649</td></tr><tr><td align="center" valign="middle" >13</td><td align="center" valign="middle" >0.693989071</td><td align="center" valign="middle" >0.891891892</td><td align="center" valign="middle" >30</td><td align="center" valign="middle" >0.765027322</td><td align="center" valign="middle" >0.783783784</td><td align="center" valign="middle" >47</td><td align="center" valign="middle" >0.759562842</td><td align="center" valign="middle" >0.972972973</td></tr><tr><td align="center" valign="middle" >14</td><td align="center" valign="middle" >0.786885246</td><td align="center" valign="middle" >0.864864865</td><td align="center" valign="middle" >31</td><td align="center" valign="middle" >0.743169399</td><td align="center" valign="middle" >0.432432432</td><td align="center" valign="middle" >48</td><td align="center" valign="middle" >0.732240437</td><td align="center" valign="middle" >0.648648649</td></tr><tr><td align="center" valign="middle" >15</td><td align="center" valign="middle" >0.699453552</td><td align="center" valign="middle" >0.891891892</td><td align="center" valign="middle" >32</td><td align="center" valign="middle" >0.797814208</td><td align="center" valign="middle" >0.837837838</td><td align="center" valign="middle" >49</td><td align="center" valign="middle" >0.737704918</td><td align="center" valign="middle" >0.567567568</td></tr><tr><td align="center" valign="middle" >16</td><td align="center" valign="middle" >0.792349727</td><td align="center" valign="middle" >0.702702703</td><td align="center" valign="middle" >33</td><td align="center" valign="middle" >0.650273224</td><td align="center" valign="middle" >0.648648649</td><td align="center" valign="middle" >50</td><td align="center" valign="middle" >0.710382514</td><td align="center" valign="middle" >0.783783784</td></tr><tr><td align="center" valign="middle" >17</td><td align="center" valign="middle" >0.710382514</td><td align="center" valign="middle" >0.783783784</td><td align="center" valign="middle" >34</td><td align="center" valign="middle" >0.721311475</td><td align="center" valign="middle" >0.783783784</td><td align="center" valign="middle" >平均正确率</td><td align="center" valign="middle" >0.723180903</td><td align="center" valign="middle" >0.750355619</td></tr></tbody></table></table-wrap><p>表3. 分类结果1</p><p>从上表结果统计得出：利用朴素贝叶斯分类器选股，50家股票中，训练集正确率在70%以上且测试集正确率在40%以上的有33家，占比66%，训练集正确率在75%以上且测试集正确率在40%以上的有12家，占比24%。表明朴素贝叶斯分类器选股在一定程度上有很好的效果。</p><p>为了证明本文提出的方法更有效，用相同公司的数据，不利用互信息筛选因素只做主成分分析，分类结果如表4所示：</p><p>从上表结果统计得出：利用朴素贝叶斯分类器选股，50家股票中，训练集正确率在70%以上且测试集正确率在40%以上的有22家，占比44%，训练集正确率在75%以上且测试集正确率在40%以上的有6家，占比12%。</p><p>从正确分类的比例和平均绝对误差两方面对比基于两种特征选择方法的朴素贝叶斯分类器的分类结果，如表5所示：</p><table-wrap id="table4" ><label><xref ref-type="table" rid="table4">Table 4</xref></label><caption><title> Classification Situation </title></caption><table><tbody><thead><tr><th align="center" valign="middle" >表格</th><th align="center" valign="middle" >训练集正确率</th><th align="center" valign="middle" >测试集正确率</th><th align="center" valign="middle" >表格</th><th align="center" valign="middle" >训练集正确率</th><th align="center" valign="middle" >测试集正确率</th><th align="center" valign="middle" >表格</th><th align="center" valign="middle" >训练集正确率</th><th align="center" valign="middle" >测试集正确率</th></tr></thead><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" >0.721311475</td><td align="center" valign="middle" >0.945945946</td><td align="center" valign="middle" >18</td><td align="center" valign="middle" >0.639344262</td><td align="center" valign="middle" >0.702702703</td><td align="center" valign="middle" >35</td><td align="center" valign="middle" >0.693989071</td><td align="center" valign="middle" >0.837837838</td></tr><tr><td align="center" valign="middle" >2</td><td align="center" valign="middle" >0.721311475</td><td align="center" valign="middle" >0.513513514</td><td align="center" valign="middle" >19</td><td align="center" valign="middle" >0.666666667</td><td align="center" valign="middle" >0.621621622</td><td align="center" valign="middle" >36</td><td align="center" valign="middle" >0.710382514</td><td align="center" valign="middle" >0.891891892</td></tr><tr><td align="center" valign="middle" >3</td><td align="center" valign="middle" >0.677595628</td><td align="center" valign="middle" >0.648648649</td><td align="center" valign="middle" >20</td><td align="center" valign="middle" >0.655737705</td><td align="center" valign="middle" >0.675675676</td><td align="center" valign="middle" >37</td><td align="center" valign="middle" >0.639344262</td><td align="center" valign="middle" >0.486486486</td></tr><tr><td align="center" valign="middle" >4</td><td align="center" valign="middle" >0.677595628</td><td align="center" valign="middle" >0.432432432</td><td align="center" valign="middle" >21</td><td align="center" valign="middle" >0.672131148</td><td align="center" valign="middle" >0.513513514</td><td align="center" valign="middle" >38</td><td align="center" valign="middle" >0.595628415</td><td align="center" valign="middle" >0.864864865</td></tr><tr><td align="center" valign="middle" >5</td><td align="center" valign="middle" >0.655737705</td><td align="center" valign="middle" >0.486486486</td><td align="center" valign="middle" >22</td><td align="center" valign="middle" >0.74863388</td><td align="center" valign="middle" >0.72972973</td><td align="center" valign="middle" >39</td><td align="center" valign="middle" >0.628415301</td><td align="center" valign="middle" >0.594594595</td></tr><tr><td align="center" valign="middle" >6</td><td align="center" valign="middle" >0.737704918</td><td align="center" valign="middle" >0.756756757</td><td align="center" valign="middle" >23</td><td align="center" valign="middle" >0.666666667</td><td align="center" valign="middle" >0.72972973</td><td align="center" valign="middle" >40</td><td align="center" valign="middle" >0.803278689</td><td align="center" valign="middle" >0.756756757</td></tr><tr><td align="center" valign="middle" >7</td><td align="center" valign="middle" >0.683060109</td><td align="center" valign="middle" >0.702702703</td><td align="center" valign="middle" >24</td><td align="center" valign="middle" >0.699453552</td><td align="center" valign="middle" >0.567567568</td><td align="center" valign="middle" >41</td><td align="center" valign="middle" >0.732240437</td><td align="center" valign="middle" >0.675675676</td></tr><tr><td align="center" valign="middle" >8</td><td align="center" valign="middle" >0.584699454</td><td align="center" valign="middle" >0.378378378</td><td align="center" valign="middle" >25</td><td align="center" valign="middle" >0.612021858</td><td align="center" valign="middle" >0.891891892</td><td align="center" valign="middle" >42</td><td align="center" valign="middle" >0.775956284</td><td align="center" valign="middle" >0.918918919</td></tr><tr><td align="center" valign="middle" >9</td><td align="center" valign="middle" >0.666666667</td><td align="center" valign="middle" >0.918918919</td><td align="center" valign="middle" >26</td><td align="center" valign="middle" >0.601092896</td><td align="center" valign="middle" >0.864864865</td><td align="center" valign="middle" >43</td><td align="center" valign="middle" >0.704918033</td><td align="center" valign="middle" >0.432432432</td></tr><tr><td align="center" valign="middle" >10</td><td align="center" valign="middle" >0.775956284</td><td align="center" valign="middle" >0.432432432</td><td align="center" valign="middle" >27</td><td align="center" valign="middle" >0.704918033</td><td align="center" valign="middle" >0.864864865</td><td align="center" valign="middle" >44</td><td align="center" valign="middle" >0.737704918</td><td align="center" valign="middle" >0.945945946</td></tr><tr><td align="center" valign="middle" >11</td><td align="center" valign="middle" >0.74863388</td><td align="center" valign="middle" >0.864864865</td><td align="center" valign="middle" >28</td><td align="center" valign="middle" >0.62295082</td><td align="center" valign="middle" >0.540540541</td><td align="center" valign="middle" >45</td><td align="center" valign="middle" >0.726775956</td><td align="center" valign="middle" >0.675675676</td></tr><tr><td align="center" valign="middle" >12</td><td align="center" valign="middle" >0.595628415</td><td align="center" valign="middle" >0.675675676</td><td align="center" valign="middle" >29</td><td align="center" valign="middle" >0.710382514</td><td align="center" valign="middle" >0.621621622</td><td align="center" valign="middle" >46</td><td align="center" valign="middle" >0.775956284</td><td align="center" valign="middle" >0.648648649</td></tr><tr><td align="center" valign="middle" >13</td><td align="center" valign="middle" >0.595628415</td><td align="center" valign="middle" >0.432432432</td><td align="center" valign="middle" >30</td><td align="center" valign="middle" >0.672131148</td><td align="center" valign="middle" >0.648648649</td><td align="center" valign="middle" >47</td><td align="center" valign="middle" >0.666666667</td><td align="center" valign="middle" >0.540540541</td></tr><tr><td align="center" valign="middle" >14</td><td align="center" valign="middle" >0.704918033</td><td align="center" valign="middle" >0.72972973</td><td align="center" valign="middle" >31</td><td align="center" valign="middle" >0.743169399</td><td align="center" valign="middle" >0.540540541</td><td align="center" valign="middle" >48</td><td align="center" valign="middle" >0.704918033</td><td align="center" valign="middle" >0.702702703</td></tr><tr><td align="center" valign="middle" >15</td><td align="center" valign="middle" >0.628415301</td><td align="center" valign="middle" >0.405405405</td><td align="center" valign="middle" >32</td><td align="center" valign="middle" >0.693989071</td><td align="center" valign="middle" >0.621621622</td><td align="center" valign="middle" >49</td><td align="center" valign="middle" >0.710382514</td><td align="center" valign="middle" >0.702702703</td></tr><tr><td align="center" valign="middle" >16</td><td align="center" valign="middle" >0.781420765</td><td align="center" valign="middle" >0.72972973</td><td align="center" valign="middle" >33</td><td align="center" valign="middle" >0.546448087</td><td align="center" valign="middle" >0.675675676</td><td align="center" valign="middle" >50</td><td align="center" valign="middle" >0.655737705</td><td align="center" valign="middle" >0.432432432</td></tr><tr><td align="center" valign="middle" >17</td><td align="center" valign="middle" >0.737704918</td><td align="center" valign="middle" >0.486486486</td><td align="center" valign="middle" >34</td><td align="center" valign="middle" >0.661202186</td><td align="center" valign="middle" >0.351351351</td><td align="center" valign="middle" >平均正确率</td><td align="center" valign="middle" >0.685464481</td><td align="center" valign="middle" >0.656216216</td></tr></tbody></table></table-wrap><p>表4. 分类结果2</p><table-wrap id="table5" ><label><xref ref-type="table" rid="table5">Table 5</xref></label><caption><title> Classification Situation </title></caption><table><tbody><thead><tr><th align="center" valign="middle"  rowspan="2"  ></th><th align="center" valign="middle"  colspan="2"  >本文建立的朴素贝叶斯分类器</th><th align="center" valign="middle"  colspan="2"  >基于主成分分析的朴素贝叶斯分类器</th></tr></thead><tr><td align="center" valign="middle" >训练集</td><td align="center" valign="middle" >测试集</td><td align="center" valign="middle" >训练集</td><td align="center" valign="middle" >测试集</td></tr><tr><td align="center" valign="middle" >正确分类的比例</td><td align="center" valign="middle" >72.30%</td><td align="center" valign="middle" >75.00%</td><td align="center" valign="middle" >68.50%</td><td align="center" valign="middle" >65.60%</td></tr><tr><td align="center" valign="middle" >平均绝对误差</td><td align="center" valign="middle" >0.041</td><td align="center" valign="middle" >0.118</td><td align="center" valign="middle" >0.047</td><td align="center" valign="middle" >0.126</td></tr></tbody></table></table-wrap><p>表5. 分类结果3</p><p>从上表可以看出：本文建立的朴素贝叶斯分类器训练集和测试集正确分类的比例均高于基于主成分分析的朴素贝叶斯分类器正确分类的比例，其平均绝对误差均低于基于主成分分析的朴素贝叶斯分类器的平均绝对误差。从对比中得出本文提出的方法的分类结果优于不利用互信息筛选因素只做主成分分析的分类结果。</p></sec><sec id="s7"><title>5. 结论</title><p>本文利用证券的交易数据并结合一种新的特征选择方法给出了一种朴素贝叶斯分类模型。实证分析表明：训练集正确率在70%以上且预测精度在40%以上的达到66%，训练集正确率在75%以上且预测精度在40%以上的有12家，占比24%。该分类器的平均正确率达到75%，并且从正确分类样本属性值的比例和平均绝对误差两方面对比，本文提出的方法的分类结果均优于不利用互信息筛选因素只做主成分分析的分类结果。</p></sec><sec id="s8"><title>文章引用</title><p>郭盼盼,刘海军,李双双. 基于一种新的特征选择方法的朴素贝叶斯分类器选择证券的研究Research on Security Selection by Naive Bayes Classifier Based on a New Feature Selection Method[J]. 应用数学进展, 2019, 08(01): 41-49. https://doi.org/10.12677/AAM.2019.81005</p></sec><sec id="s9"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.28390-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Fama, E.F. and French, K.R. (1992) The Cross-Section of Expected Stock Returns. The Journal of Finance, 47, 427-465. &lt;br&gt;https://doi.org/10.1111/j.1540-6261.1992.tb04398.x</mixed-citation></ref><ref id="hanspub.28390-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">唐文慧. 基于数据挖掘技术的股价预测实证分析[D]: [硕士学位论文]. 成都: 西南财经大学, 2009.</mixed-citation></ref><ref id="hanspub.28390-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">雷炜, 叶东毅. 利用决策树技术对股票价格数据库进行数据挖掘[J]. 福建电脑, 2004(8): 52-53.</mixed-citation></ref><ref id="hanspub.28390-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">王领, 胡扬. 基于C4.5决策树的股票数据挖掘[J]. 计算机与现代化, 2015(10): 21-24.</mixed-citation></ref><ref id="hanspub.28390-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">钱颖能, 胡运发. 用朴素贝叶斯分类法选股[J]. 计算机应用与软件, 2007, 24(6): 90-92.</mixed-citation></ref><ref id="hanspub.28390-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">左辉, 楼新远. 基于贝叶斯分类的选股方法[J]. 电脑知识与技术, 2008, 2(10): 173-176.</mixed-citation></ref><ref id="hanspub.28390-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">骆桦, 张喜梅. 基于贝叶斯分类法的股票选择模型的研究[J]. 浙江理工大学学报(自然科学版), 2015, 33(3): 418-422.</mixed-citation></ref><ref id="hanspub.28390-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">White, H. (1988) Economic Prediction Using Neural Networks: The Case of IBM Daily Stock Returns. IEEE International Conference on Neural Networks, 2, 451-458.</mixed-citation></ref><ref id="hanspub.28390-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Oliveira, F.A.D., Nobre, C.N. and Zárate, L.E. (2013) Applying Artificial Neural Networks to Prediction of Stock Price and Improvement of the Directional Prediction Index—Case Study of PETR4, Petrobras, Brazil. Expert Systems with Applications, 40, 7596-7606. &lt;br&gt;https://doi.org/10.1016/j.eswa.2013.06.071</mixed-citation></ref><ref id="hanspub.28390-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Zahedi, J. and Rounaghi, M.M. (2015) Application of Artificial Neural Network Models and Principal Component Analysis Method in Predicting Stock Prices on Tehran Stock Ex-change. Physica A Statistical Mechanics &amp; Its Applications, 438, 178-187. &lt;br&gt;https://doi.org/10.1016/j.physa.2015.06.033</mixed-citation></ref><ref id="hanspub.28390-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Qiu, M., Song, Y. and Akagi, F. (2016) Application of Artificial Neural Network for the Prediction of Stock Market Returns: The Case of the Japanese Stock Market. Chaos, Solitons &amp; Fractals, 85, 1-7.  
&lt;br&gt;https://doi.org/10.1016/j.chaos.2016.01.004</mixed-citation></ref><ref id="hanspub.28390-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Almuallim, H. and Dietterich, T.G. (1991) Learning With Many Irrelevant Features. Proceedings of the 9th National Conference on Artificial Intelligence, Anaheim, 14-19 July 1991, AAAI Press, Volume 2.</mixed-citation></ref><ref id="hanspub.28390-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Domingos, P. and Pazzani, M. (1997) On the Optimality of the Simple Bayesian Classi-fier under Zero-One Loss. Machine Learning, 29, 103-130. &lt;br&gt;https://doi.org/10.1023/A:1007413511361</mixed-citation></ref><ref id="hanspub.28390-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">Blum, A.L. and Langley, P. (1997) Selection of Relevant Features and Examples in Machine Learning. Artificial Intelligence, 97, 245-271. &lt;br&gt;https://doi.org/10.1016/S0004-3702(97)00063-5</mixed-citation></ref><ref id="hanspub.28390-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">唐勇波, 桂卫华, 彭涛, 等. 基于互信息变量选择的变压器油中溶解气体浓度预测[J]. 仪器仪表学报, 2013, 34(7): 1492-1498.</mixed-citation></ref><ref id="hanspub.28390-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">郭伟. 基于互信息的RBF神经网络结构优化设计[J]. 计算机科学, 2013, 40(6): 252-255.</mixed-citation></ref><ref id="hanspub.28390-ref17"><label>17</label><mixed-citation publication-type="other" xlink:type="simple">韩敏, 刘晓欣. 基于互信息的分步式输入变量选择多元序列预测研究[J]. 自动化学报, 2012, 38(6): 999-1006.</mixed-citation></ref><ref id="hanspub.28390-ref18"><label>18</label><mixed-citation publication-type="other" xlink:type="simple">Cover, T.M. and Thomas, J.A. (1991) Elements of Information Theory. John Wiley &amp; Sons, Inc, New York.  
&lt;br&gt;https://doi.org/10.1002/0471200611</mixed-citation></ref><ref id="hanspub.28390-ref19"><label>19</label><mixed-citation publication-type="other" xlink:type="simple">何晓群. 多元统计分析[M]. 第二版. 北京: 中国人民大学出版社, 2008.</mixed-citation></ref><ref id="hanspub.28390-ref20"><label>20</label><mixed-citation publication-type="other" xlink:type="simple">Tom M. Mitchell, 米切尔, 曾华军, 等. 机器学习[M]. 北京: 机械工业出版社, 2003.</mixed-citation></ref></ref-list></back></article>