<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">AIRR</journal-id><journal-title-group><journal-title>Artificial Intelligence and Robotics Research</journal-title></journal-title-group><issn pub-type="epub">2326-3415</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/AIRR.2020.92008</article-id><article-id pub-id-type="publisher-id">AIRR-34707</article-id><article-categories><subj-group subj-group-type="heading"><subject>AIRR20200200000_75710693.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject><subject> 工程技术</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于截断核范数张量鲁棒主成分分析
  Tensor Robust Principal Component Analysis Based on Truncated Nuclear Norm
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>杨</surname><given-names>枥皓</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib></contrib-group><aff id="aff1"><label>1</label><addr-line>null</addr-line></aff><aff id="aff2"><label>1</label><addr-line>西南大学数学与统计学院，重庆  </addr-line></aff><pub-date pub-type="epub"><day>25</day><month>03</month><year>2020</year></pub-date><volume>09</volume><issue>02</issue><fpage>64</fpage><lpage>73</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
  
    低管秩张量的分解由于其在图像处理中的实际应用已经在各个领域引起了关注。但是传统的张量分解算法为了得到给定张量的低秩和稀疏成分，利用了全部的数据。尽管这些现存的方法都有较快的收敛速度，但是这些方法都忽略了小奇异值几乎不含信息这一事实。基于这一事实，我们提出了一种新的分解方法。我们的方法通过限制核范数的大小从而简化张量分解。和其他张量恢复方法相较而言，我们提出的方法能在实验中能取得更好的效果。
    Low-tubal-rank tensor decomposition has been attracting attention of various fields due to the real application in image processing. However, conventional algorithms for tensor decomposition utilise the entire data to obtain the Low-tubal-rank and sparse components of a given tensor. Although many existing methods have fast convergence rates, these methods ignore the fact that small singular values contain little information. Based on this fact, we come up with a new decomposition method. Our method can simplify the tensor decomposition according to constrain the nuclear norm. Compared with the experimental results of many other tensor recovery methods, our proposed method can obtain a better effect. 
  
 
</p></abstract><kwd-group><kwd>张量分解，主成分分析，截断核范数，图像去噪, Tensor Decomposition</kwd><kwd> Principal Component Analysis</kwd><kwd> Truncated Nuclear Norm</kwd><kwd> Image Denoising</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>基于截断核范数张量鲁棒主成分分析<sup> </sup></title><p>杨枥皓</p><p>西南大学数学与统计学院，重庆</p><p>收稿日期：2020年3月2日；录用日期：2020年3月18日；发布日期：2020年3月25日</p><disp-formula id="hanspub.34707-formula131"><graphic xlink:href="//html.hanspub.org/file/2-2610190x5_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>低管秩张量的分解由于其在图像处理中的实际应用已经在各个领域引起了关注。但是传统的张量分解算法为了得到给定张量的低秩和稀疏成分，利用了全部的数据。尽管这些现存的方法都有较快的收敛速度，但是这些方法都忽略了小奇异值几乎不含信息这一事实。基于这一事实，我们提出了一种新的分解方法。我们的方法通过限制核范数的大小从而简化张量分解。和其他张量恢复方法相较而言，我们提出的方法能在实验中能取得更好的效果。</p><p>关键词 :张量分解，主成分分析，截断核范数，图像去噪</p><disp-formula id="hanspub.34707-formula132"><graphic xlink:href="//html.hanspub.org/file/2-2610190x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2020 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/2-2610190x7_hanspub.png" /> <img src="//html.hanspub.org/file/2-2610190x8_hanspub.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>随着时代的发展和大数据时代的来临，从高维数据中发现和挖掘低维结构的思想已经在图像分析，视频降噪，模式识别，基因数据分析 [<xref ref-type="bibr" rid="hanspub.34707-ref1">1</xref>] [<xref ref-type="bibr" rid="hanspub.34707-ref2">2</xref>] [<xref ref-type="bibr" rid="hanspub.34707-ref3">3</xref>] [<xref ref-type="bibr" rid="hanspub.34707-ref4">4</xref>] 等方面起着越来越重要的作用。一般来讲，假设我们给定一个被观测到的数据矩阵<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x9_hanspub.png" xlink:type="simple"/></inline-formula>，该矩阵是由另一个低秩矩阵<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x10_hanspub.png" xlink:type="simple"/></inline-formula>的其中一些元素被噪声污染后得到的。为了从观测矩阵<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x11_hanspub.png" xlink:type="simple"/></inline-formula>中恢复出<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x12_hanspub.png" xlink:type="simple"/></inline-formula>，我们希望<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x13_hanspub.png" xlink:type="simple"/></inline-formula>可以被分解为<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x14_hanspub.png" xlink:type="simple"/></inline-formula>，其中<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x15_hanspub.png" xlink:type="simple"/></inline-formula>是低秩矩阵，而<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x16_hanspub.png" xlink:type="simple"/></inline-formula>中由于只有很少一部分元素才是非零的，所以我们称<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x17_hanspub.png" xlink:type="simple"/></inline-formula>为稀疏矩阵(这些非零元素即为异常值)。为了解决这个问题，文献 [<xref ref-type="bibr" rid="hanspub.34707-ref5">5</xref>] 提出了用鲁棒主成分分析(Robust Principal Component Analysis, RPCA)方法来从被污染的矩阵<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x18_hanspub.png" xlink:type="simple"/></inline-formula>中恢复出<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x19_hanspub.png" xlink:type="simple"/></inline-formula>：</p><disp-formula id="hanspub.34707-formula133"><label>(1)</label><graphic position="anchor" xlink:href="//html.hanspub.org/file/2-2610190x20_hanspub.png"  xlink:type="simple"/></disp-formula><p>RPCA在多项式时间内仍然保持良好的恢复效果和稳定性，所以该方法被广泛地应用于数据分析工作中。遗憾的是，在大部分情况下RPCA只能处理矩阵数据，即二维数组。然而高维数据(即张量)在实际生活和科研工作中随处可见，比如彩色图片，高光谱图像大部分都被编译为三阶张量：行，列元素的分布以及每一个像素的颜色；彩色视频也可以视为四阶张量。张量在图像去噪 [<xref ref-type="bibr" rid="hanspub.34707-ref6">6</xref>]，视频存储 [<xref ref-type="bibr" rid="hanspub.34707-ref7">7</xref>]，数据挖掘 [<xref ref-type="bibr" rid="hanspub.34707-ref8">8</xref>]，背景提取 [<xref ref-type="bibr" rid="hanspub.34707-ref9">9</xref>] 中都有着非常广泛的应用。而对于张量形式的分解，具体来说，就是给定一个三阶张量<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x21_hanspub.png" xlink:type="simple"/></inline-formula>，它可以被分解和被表示为<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x22_hanspub.png" xlink:type="simple"/></inline-formula>，其中<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x23_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x24_hanspub.png" xlink:type="simple"/></inline-formula>在<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x25_hanspub.png" xlink:type="simple"/></inline-formula>的空间内分别具有低秩和稀疏的结构。</p><p>值得注意的是，关于张量秩的定义并不是唯一的，其中使用比较广泛的两种张量秩是由CANDECOMP/PARAFAC (CP) [<xref ref-type="bibr" rid="hanspub.34707-ref10">10</xref>] 分解和Tucker [<xref ref-type="bibr" rid="hanspub.34707-ref11">11</xref>] 分解得到的CP秩和Tucker秩。但上述两种秩的定义都有其局限性：文献 [<xref ref-type="bibr" rid="hanspub.34707-ref12">12</xref>] 已经证明正确地估计CP秩是一个NP-hard的问题，而Tucker秩是一个向量而非标量，不适合用于比较大小。在本文中，我们采取基于张量SVD分解的管秩(tensor tubal rank，见定义7)作为张量秩的定义。因此张量形式下低秩和稀疏部分可以通过下面的张量鲁棒主成分分析(Tensor Robust Principal Component analysis, TRPCA)问题求得</p><disp-formula id="hanspub.34707-formula134"><label>(2)</label><graphic position="anchor" xlink:href="//html.hanspub.org/file/2-2610190x26_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x27_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x28_hanspub.png" xlink:type="simple"/></inline-formula>分别代表<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x29_hanspub.png" xlink:type="simple"/></inline-formula>范数以及核范数(会在第二节定义)；<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x30_hanspub.png" xlink:type="simple"/></inline-formula>为正则化参数，用于平衡低秩项和稀疏</p><p>项。图1展示矩阵和张量分解的联系与区别。</p><p>图1. 矩阵和张量分解的图示</p><p>从理论上讲，并不是所有的张量都能够分解成稀疏和低秩两部分，比如当一个张量只有极少数的元素非零，而其余元素都为零时，这个“病态”张量就是既低秩又稀疏的，是不可能通过优化问题(2)将其分解为两个张量的。因此文献 [<xref ref-type="bibr" rid="hanspub.34707-ref13">13</xref>] 给出张量核范数的定义和判断张量能否“病态”的非相关性条件，此外还提出了利用交替方向乘子法(Alternating Direction of Method of Multipliers, ADMM)来解决TRPCA问题。然后美中不足的是，尽管问题(2)是凸优化问题，可以在多项式时间内被解决，但是随着张量规模的扩大，计算时间也在成倍的增长：当张量的规模增长到<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x32_hanspub.png" xlink:type="simple"/></inline-formula>时，甚至需要近四十多个小时才能够完成分解。从文献 [<xref ref-type="bibr" rid="hanspub.34707-ref14">14</xref>] [<xref ref-type="bibr" rid="hanspub.34707-ref15">15</xref>] 中可以知道，对于矩阵而言，不同的奇异值包含的矩阵的不同信息，而较小的奇异值所包含的信息量很少，而且大部分是观测噪声或者人为的结构信息，如果能舍弃掉部分较小的奇异值，可以明显提升运算效率，得到更优的解以及更好的去噪效果。</p><p>由于张量与矩阵结构和维度的不同，本文首先给出了张量的乘积，奇异值分解以及张量管秩、范数等定义。为了提高张量分解计算速度，受上述文献思想的启发，我们之后利用交替方向乘子法设计了一个基于截断核范数TRPCA算法，由于较大的奇异值已经包含了张量的主要信息，我们通过舍弃较小的奇异值来减少计算复杂度。最后本文通过对真实图片的恢复，证实了我们提出的方法的优势和有效性。</p></sec><sec id="s4"><title>2. 张量的相关定义与运算</title><p>矩阵和张量在结构和维度上有较大的不同，为了方便区分以及后面的行文，本节会给出张量的相关定义以及张量的乘法、奇异值分解等运算法则。在本文中，我们分别用粗体小写字母<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x33_hanspub.png" xlink:type="simple"/></inline-formula>，粗体大写字母<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x34_hanspub.png" xlink:type="simple"/></inline-formula>和粗体手写体字母<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x35_hanspub.png" xlink:type="simple"/></inline-formula>来表示向量，矩阵和张量。对于一个三维的张量<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x36_hanspub.png" xlink:type="simple"/></inline-formula>，用<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x37_hanspub.png" xlink:type="simple"/></inline-formula>或<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x38_hanspub.png" xlink:type="simple"/></inline-formula>来表示</p><p>位于张量<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x39_hanspub.png" xlink:type="simple"/></inline-formula>的<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x40_hanspub.png" xlink:type="simple"/></inline-formula>位置上的元素；用<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x41_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x42_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x43_hanspub.png" xlink:type="simple"/></inline-formula>来分别表示第i个水平切面，第j个侧面切片，第k个正面切片，特别地，也可以用<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x44_hanspub.png" xlink:type="simple"/></inline-formula>来表示第k个正面切片。类似于矩阵，张量范数的定义如下：<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x45_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x46_hanspub.png" xlink:type="simple"/></inline-formula>；<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x47_hanspub.png" xlink:type="simple"/></inline-formula>，不难看出，张量的第三个维度<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x48_hanspub.png" xlink:type="simple"/></inline-formula></p><p>时，张量的范数就会退化成矩阵范数。此外，我们还给出块循环矩阵和折叠、展开算子的定义：</p><p><inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x49_hanspub.png" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x50_hanspub.png" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x51_hanspub.png" xlink:type="simple"/></inline-formula></p><p>定义1. (张量积) [<xref ref-type="bibr" rid="hanspub.34707-ref16">16</xref>]：假设张量<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x52_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x53_hanspub.png" xlink:type="simple"/></inline-formula>，则<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x54_hanspub.png" xlink:type="simple"/></inline-formula>与<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x55_hanspub.png" xlink:type="simple"/></inline-formula>的张量乘积的规模为<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x56_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x57_hanspub.png" xlink:type="simple"/></inline-formula>。</p><p>定义2. (张量共轭转置) [<xref ref-type="bibr" rid="hanspub.34707-ref16">16</xref>]：假设张量<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x58_hanspub.png" xlink:type="simple"/></inline-formula>，记<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x59_hanspub.png" xlink:type="simple"/></inline-formula>为其共轭转置张量，并且<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x60_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x61_hanspub.png" xlink:type="simple"/></inline-formula> 其中<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x62_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x63_hanspub.png" xlink:type="simple"/></inline-formula>表示矩阵的共轭矩阵。</p><p>定义3. (单位张量) [<xref ref-type="bibr" rid="hanspub.34707-ref16">16</xref>]：如果一个张量<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x64_hanspub.png" xlink:type="simple"/></inline-formula>，并且<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x65_hanspub.png" xlink:type="simple"/></inline-formula>的第一个正面切片是一个<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x66_hanspub.png" xlink:type="simple"/></inline-formula>的单位矩阵，其余正面切片全部为0，则称<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x67_hanspub.png" xlink:type="simple"/></inline-formula>为单位张量。</p><p>定义4. (正交张量) [<xref ref-type="bibr" rid="hanspub.34707-ref16">16</xref>]：称张量<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x68_hanspub.png" xlink:type="simple"/></inline-formula>为正交张量，如果其满足<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x69_hanspub.png" xlink:type="simple"/></inline-formula>。</p><p>定义5：(F-对角张量) [<xref ref-type="bibr" rid="hanspub.34707-ref16">16</xref>]：称<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x70_hanspub.png" xlink:type="simple"/></inline-formula>为F-对角张量，如果<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x71_hanspub.png" xlink:type="simple"/></inline-formula>的每一个正面切片<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x72_hanspub.png" xlink:type="simple"/></inline-formula>均为对角矩阵。</p><p>定理1. (张量奇异值分解t-SVD) [<xref ref-type="bibr" rid="hanspub.34707-ref16">16</xref>]：任意一个张量<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x73_hanspub.png" xlink:type="simple"/></inline-formula>都可以被分解为</p><disp-formula id="hanspub.34707-formula135"><graphic xlink:href="//html.hanspub.org/file/2-2610190x74_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x75_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x76_hanspub.png" xlink:type="simple"/></inline-formula>为正交张量，<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x77_hanspub.png" xlink:type="simple"/></inline-formula>为F-对角张量。</p><p>定义6. (张量管秩) [<xref ref-type="bibr" rid="hanspub.34707-ref17">17</xref>] 张量<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x78_hanspub.png" xlink:type="simple"/></inline-formula>，其张量奇异值分解为<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x79_hanspub.png" xlink:type="simple"/></inline-formula>，则<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x80_hanspub.png" xlink:type="simple"/></inline-formula>的管秩定义为F-对角张量<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x81_hanspub.png" xlink:type="simple"/></inline-formula>所有正面切片中最大的秩，即</p><disp-formula id="hanspub.34707-formula136"><graphic xlink:href="//html.hanspub.org/file/2-2610190x82_hanspub.png"  xlink:type="simple"/></disp-formula><p>定义7. (张量谱范数和核范数) [<xref ref-type="bibr" rid="hanspub.34707-ref13">13</xref>] 设张量<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x83_hanspub.png" xlink:type="simple"/></inline-formula>，其张量奇异值分解为<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x84_hanspub.png" xlink:type="simple"/></inline-formula>，其谱范数和核范数分别记为</p><disp-formula id="hanspub.34707-formula137"><graphic xlink:href="//html.hanspub.org/file/2-2610190x85_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x86_hanspub.png" xlink:type="simple"/></inline-formula>为块循环矩阵，r为定义6中的管秩。</p><p>至此我们给出了后面会涉及到的张量相关的定义与运算。张量可以视为矩阵的推广，对于三阶张量而言，每一个切片都可以视为矩阵；也可以把矩阵视为<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x87_hanspub.png" xlink:type="simple"/></inline-formula>的特殊张量。矩阵与张量的有关运算类似又不尽相同，为此我们需要先了解张量的共轭转置、管秩、张量乘积以及张量奇异值分解等基本概念才方便我们进行后面优化算法的研究。</p></sec><sec id="s5"><title>3. 主要模型及算法</title><sec id="s5_1"><title>3.1. 图像的低秩性</title><p>在实际生活和工作中，彩色图片随处可见，而绝大多数彩色图片都是以RGB的形式记录和储存的。具体来讲，RGB的彩色图片可以视为一个三阶张量<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x88_hanspub.png" xlink:type="simple"/></inline-formula>，它的三个正面切片<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x89_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x90_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x91_hanspub.png" xlink:type="simple"/></inline-formula>，分别代表红，绿，蓝三个通道。而且对于图片这样的可视数据，它极有可能是低秩的或者有着低秩的结构 [<xref ref-type="bibr" rid="hanspub.34707-ref18">18</xref>]，并且该图片的较大奇异值已经可以包含数据的原始信息，而较小的奇异值虽然并不严格等于零，但是非常接近零，这部分奇异值可能是观测，收集时带来的噪声，对图像的恢复作用并不是很大。为了验证图像中普遍存在的低秩结构，图2选取了三个不同规模的图片，并给出了其t-SVD分解后，第一个正面切片的奇异值。我们可以清楚地看到，图片奇异值最开始都非常的大，而后快速下降，并且越来越接近零，只有前面一小部分奇异值是显著大于零的。从这些不同清晰度的图片中也可以知道，无论图片分辨率的高低，这一奇异值的变化规律都是普遍存在的，即图片普遍都是具有低秩结构的。</p><p>图2. 标准试验系统结果曲线(a和A)维度为512 &#215; 512 &#215; 3的图片“Lenna”以及它的奇异值。(b和B)维度为3225 &#215; 2491 &#215; 3的图片“Landscape”以及它的奇异值。(c和C) 维度为5272 &#215; 3997 &#215; 3的图片“Sunflowers”以及它的奇异值</p></sec><sec id="s5_2"><title>3.2. 模型的建立与求解</title><p>受上述思想的启发，本文采用截断核范数的思想来解决张量鲁棒主成分分析问题，具体优化模型如下：</p><disp-formula id="hanspub.34707-formula138"><label>(3)</label><graphic position="anchor" xlink:href="//html.hanspub.org/file/2-2610190x93_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x94_hanspub.png" xlink:type="simple"/></inline-formula>，表示张量奇异值的保留率，比如当<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x95_hanspub.png" xlink:type="simple"/></inline-formula>时，<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x96_hanspub.png" xlink:type="simple"/></inline-formula>表示保留观测张量<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x97_hanspub.png" xlink:type="simple"/></inline-formula>前 的奇异值。由于张量的核范数是由其t-SVD分解后<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x98_hanspub.png" xlink:type="simple"/></inline-formula>的第一个正面切片的奇异值之和定义的，所以这里只对<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x99_hanspub.png" xlink:type="simple"/></inline-formula>进行截断。则该优化问题的增广拉格朗日函数为：</p><disp-formula id="hanspub.34707-formula139"><label>(4)</label><graphic position="anchor" xlink:href="//html.hanspub.org/file/2-2610190x100_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x101_hanspub.png" xlink:type="simple"/></inline-formula>为惩罚参数，张量<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x102_hanspub.png" xlink:type="simple"/></inline-formula>为新引入的拉格朗日乘子。ADMM方法处理多变量优化问题的核心思想上是在每一次计算中，仅选取其中一个为变量，其余均视为常数来处理，然后依次优化各个变量，最后经过多次迭代，满足收敛条件后停止。</p><p>1) 固定变量<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x103_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x104_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x105_hanspub.png" xlink:type="simple"/></inline-formula>，更新<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x106_hanspub.png" xlink:type="simple"/></inline-formula>：</p><disp-formula id="hanspub.34707-formula140"><label>(5)</label><graphic position="anchor" xlink:href="//html.hanspub.org/file/2-2610190x107_hanspub.png"  xlink:type="simple"/></disp-formula><p>2) 固定变量<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x108_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x109_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x110_hanspub.png" xlink:type="simple"/></inline-formula>，更新<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x111_hanspub.png" xlink:type="simple"/></inline-formula>，类似的，我们有：</p><disp-formula id="hanspub.34707-formula141"><label>(6)</label><graphic position="anchor" xlink:href="//html.hanspub.org/file/2-2610190x112_hanspub.png"  xlink:type="simple"/></disp-formula><p>3) 固定变量<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x113_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x114_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x115_hanspub.png" xlink:type="simple"/></inline-formula>，更新<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x116_hanspub.png" xlink:type="simple"/></inline-formula>：</p><disp-formula id="hanspub.34707-formula142"><label>(7)</label><graphic position="anchor" xlink:href="//html.hanspub.org/file/2-2610190x117_hanspub.png"  xlink:type="simple"/></disp-formula><p>4) 更新参数<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x118_hanspub.png" xlink:type="simple"/></inline-formula>：</p><disp-formula id="hanspub.34707-formula143"><label>(8)</label><graphic position="anchor" xlink:href="//html.hanspub.org/file/2-2610190x119_hanspub.png"  xlink:type="simple"/></disp-formula><p>通过上述的讨论，我们现在给出利用截断核范数来解决问题(4)的算法：</p></sec></sec><sec id="s6"><title>4. 实验结果与分析</title><p>张量鲁棒主成分分析在图像去噪，人脸识别等方面的应用极为广泛。因此，为了验证我们所提出的方法的有效性和优势，在本节中我们将会与另外两种在图像去噪上应用非常广泛的RPCA [<xref ref-type="bibr" rid="hanspub.34707-ref5">5</xref>]，SNN [<xref ref-type="bibr" rid="hanspub.34707-ref19">19</xref>] 方法进行对比。因为RPCA只能处理矩阵数据，所以在恢复彩色图片时，我们将其用于依次恢复每一个正面切片，最后再合为一个张量。经过多次实验和调试，为了使每个方法都能取较好的恢复效果，我们</p><p>最终选取RPCA的参数<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x141_hanspub.png" xlink:type="simple"/></inline-formula>，SNN的参数<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x142_hanspub.png" xlink:type="simple"/></inline-formula>，我们的方法的参数<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x143_hanspub.png" xlink:type="simple"/></inline-formula>。本文所有实验的实验环境均为Intel(R) Core i5-8250 CPU @ 1.60GHZ 处理器，</p><p>内存为4.00 GB，win10的计算机，在版本为R2016b的MATLAB上运行。</p><p>为了定量地比较各个方法之间的差异性，我们引入信噪比(PSNR)和结构相似性(SSIM)这两个指标来评价去噪后的图片效果，具体定义如下：</p><p><inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x144_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x145_hanspub.png" xlink:type="simple"/></inline-formula></p><p>其中<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x146_hanspub.png" xlink:type="simple"/></inline-formula>，分别表示原始张量和恢复张量；<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x147_hanspub.png" xlink:type="simple"/></inline-formula>分别两个张量的代表局部均值，标准方差，互协方差以及每个像素值动态变化范围。这两种指标的数值越大，代表两个图片越接近，即恢复效果越好。</p><sec id="s6_1"><title>4.1. 参数δ的取值</title><p>在进行模拟实验时，我们引入<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x148_hanspub.png" xlink:type="simple"/></inline-formula>的高斯噪声来构造污染后的观测张量<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x149_hanspub.png" xlink:type="simple"/></inline-formula>，即从真实图片<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x150_hanspub.png" xlink:type="simple"/></inline-formula>，随机选取20%的元素令其成为[0, 255]内的随机值。此外为了探究在去噪过程中，参数<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x151_hanspub.png" xlink:type="simple"/></inline-formula>对我们恢复效果的影响，我们从[0.2, 0.95]中每间隔0.5进行取值，图3展示了参数奇异值选取率<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x152_hanspub.png" xlink:type="simple"/></inline-formula>不同取值下，图片“Lenna”的恢复效果和恢复时间。</p><p>我们可以很直观的看出，随着奇异值的增大，PSNR值和所需要花费的时间都在逐渐增大，但是当<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x153_hanspub.png" xlink:type="simple"/></inline-formula>时，时间的变化就不再明显；而<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x154_hanspub.png" xlink:type="simple"/></inline-formula>时，PSNR值取得最大，因此在后面的实验中，我们都取<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x155_hanspub.png" xlink:type="simple"/></inline-formula>。</p><p>图3. 当污染率<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x159_hanspub.png" xlink:type="simple"/></inline-formula>时，奇异值保留率<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x160_hanspub.png" xlink:type="simple"/></inline-formula>从0.2增长到0.95时，图片“Lenna”的恢复效果</p></sec><sec id="s6_2"><title>4.2. 模拟实验结果及分析</title><p>为了研究各个方法在图像去噪时的表现，本小节会选取5张不同规模的彩色图片来进行实验，污染率仍为<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x161_hanspub.png" xlink:type="simple"/></inline-formula>，并且被污染元素的位置和大小都是未知的，所以可以视为稀疏张量<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x162_hanspub.png" xlink:type="simple"/></inline-formula>。并且前面已经说明过了，原始图像本身就是低秩的，因而可以把被污染的观测张量<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/2-2610190x163_hanspub.png" xlink:type="simple"/></inline-formula>的去噪问题，视为TRPCA问题。各个方法的表现情况如图4所示：</p><p>图4. 图像恢复效果的比较。(a) 原始图片；(b) 被污染的图片；(c)-(e) 分别由RPCA，SNN和本文的方法得到的恢复图片</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Recovering result by RPCA, SNN and our method (PSNR/SSIM/Time</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle"  colspan="3"  >RPCA</th><th align="center" valign="middle"  colspan="3"  >SNN</th><th align="center" valign="middle"  colspan="3"  >Ours</th></tr></thead><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >PSNR</td><td align="center" valign="middle" >SSIM</td><td align="center" valign="middle" >Time</td><td align="center" valign="middle" >PSNR</td><td align="center" valign="middle" >SSIM</td><td align="center" valign="middle" >Time</td><td align="center" valign="middle" >PSNR</td><td align="center" valign="middle" >SSIM</td><td align="center" valign="middle" >Time</td></tr><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" >27.0824</td><td align="center" valign="middle" >0.9643</td><td align="center" valign="middle" >31.49s</td><td align="center" valign="middle" >29.1129</td><td align="center" valign="middle" >0.9764</td><td align="center" valign="middle" >66.68s</td><td align="center" valign="middle" >29.7939</td><td align="center" valign="middle" >0.9801</td><td align="center" valign="middle" >37.12s</td></tr><tr><td align="center" valign="middle" >2</td><td align="center" valign="middle" >25.2466</td><td align="center" valign="middle" >0.8624</td><td align="center" valign="middle" >44.97s</td><td align="center" valign="middle" >27.5576</td><td align="center" valign="middle" >0.8998</td><td align="center" valign="middle" >105.85s</td><td align="center" valign="middle" >28.5208</td><td align="center" valign="middle" >0.9368</td><td align="center" valign="middle" >59.72s</td></tr><tr><td align="center" valign="middle" >3</td><td align="center" valign="middle" >21.9990</td><td align="center" valign="middle" >0.7919</td><td align="center" valign="middle" >44.36s</td><td align="center" valign="middle" >24.2700</td><td align="center" valign="middle" >0.7898</td><td align="center" valign="middle" >104.19s</td><td align="center" valign="middle" >24.3273</td><td align="center" valign="middle" >0.8370</td><td align="center" valign="middle" >62.31s</td></tr><tr><td align="center" valign="middle" >4</td><td align="center" valign="middle" >25.9929</td><td align="center" valign="middle" >0.8940</td><td align="center" valign="middle" >42.71s</td><td align="center" valign="middle" >28.0183</td><td align="center" valign="middle" >0.8930</td><td align="center" valign="middle" >103.46s</td><td align="center" valign="middle" >27.9924</td><td align="center" valign="middle" >0.9268</td><td align="center" valign="middle" >56.79s</td></tr><tr><td align="center" valign="middle" >5</td><td align="center" valign="middle" >24.0668</td><td align="center" valign="middle" >0.8522</td><td align="center" valign="middle" >47.86s</td><td align="center" valign="middle" >26.9679</td><td align="center" valign="middle" >0.8902</td><td align="center" valign="middle" >111.83s</td><td align="center" valign="middle" >27.5271</td><td align="center" valign="middle" >0.9247</td><td align="center" valign="middle" >62.78s</td></tr><tr><td align="center" valign="middle" >Average</td><td align="center" valign="middle" >24.8775</td><td align="center" valign="middle" >0.8730</td><td align="center" valign="middle" >42.28s</td><td align="center" valign="middle" >27.1953</td><td align="center" valign="middle" >0.8898</td><td align="center" valign="middle" >98.40s</td><td align="center" valign="middle" >27.6323</td><td align="center" valign="middle" >0.9210</td><td align="center" valign="middle" >55.74s</td></tr></tbody></table></table-wrap><p>表1. RPCA，SNN和我们的方法的恢复效果(PSNR/SSIM/Time)</p><p>表1展示上面五个图片恢复效果，包括PSNR，SSIM以及时间这三个指标的对比。从恢复效果来看，我们的方法取得的去噪效果最好，其次是SNN，RPCA的表现最差。以PSNR的平均值为例，我们的方法比RPCA高了2.75，我们从图4中也可以很直观地看出，(c)组图片有很明显的失真和不清晰，而用我们的方法去噪后图片会相对更加清晰，几乎看不到斑点等噪声。很有可能是因为RPCA没有考虑到张量的整体结构，而是简单地将其转化成矩阵来恢复。</p><p>SNN对于张量的恢复效果也很不错，但是我们的方法得到的PSNR和SSIM还是比SNN来得高。并且从时间上来看，SNN恢复所花的时间会更加的漫长，几乎是我们方法的两倍。如果是更加高清的图片，张量规模会更大，我们方法在时间复杂度上的优势会更加明显。</p></sec></sec><sec id="s7"><title>5. 总结与展望</title><p>本文在结合张量数据的高维结构和实际图片的低秩性，提出了利用截断核范数来解决张量鲁棒主成分分析问题，可以将一个被污染的张量分解成低管秩张量和稀疏张量，从而达到去噪的目的。张量的核范数由其奇异值之和定义的，而张量的较小奇异值包含的信息很少，可以将其舍弃，基于这个思想，我们通过约束奇异值的个数，来达到简化计算和提高恢复效果的目的。从实验中我们可以看出来，我们的方法可以用较小的时间取得很好的效果，优于使用也很广泛的SNN和RPCA模型。在之后的工作中，我们可以考虑大规模张量的恢复问题，寻求更好的核范数约束方式，以此来获得更好的去噪效果。</p></sec><sec id="s8"><title>基金项目</title><p>中央高校基本科研业务费专项资金资助XDJK2018C076。</p></sec><sec id="s9"><title>文章引用</title><p>杨枥皓. 基于截断核范数张量鲁棒主成分分析Tensor Robust Principal Component Analysis Based on Truncated Nuclear Norm[J]. 人工智能与机器人研究, 2020, 09(02): 64-73. https://doi.org/10.12677/AIRR.2020.92008</p></sec><sec id="s10"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.34707-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Litjens, G., Kooi, T., Bejnordi, B.E., et al. (2017) A Survey on Deep Learning in Medical Image Analysis. Medical Image Analysis, 42, 60-88. &lt;br&gt;https://doi.org/10.1016/j.media.2017.07.005</mixed-citation></ref><ref id="hanspub.34707-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Brubaker, S.W., Bonham, K.S., Zanoni, I., et al. (2015) Innate Immune Pattern Recognition: A Cell Biological Perspective. Annual Review of Immunology, 33, 257-290. &lt;br&gt;https://doi.org/10.1146/annurev-immunol-032414-112240</mixed-citation></ref><ref id="hanspub.34707-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Hancock, P.J.B., Burton, A.M. and Bruce, V. (1996) Face Processing: Human Perception and Principal Components Analysis. Memory &amp; Cognition, 24, 26-40. &lt;br&gt;https://doi.org/10.3758/BF03197270</mixed-citation></ref><ref id="hanspub.34707-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Misra, J., Schmitt, W., Hwang, D., et al. (2002) Interactive Exploration of Microarraygene Expression Patterns in a Reduced Dimensional Space. Genome Research, 12, 1112-1120. &lt;br&gt;https://doi.org/10.1101/gr.225302</mixed-citation></ref><ref id="hanspub.34707-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Candes, E., Li, X., Ma, Y. and Wright, J. (2011) Robust Principal Component Analysis? Journal of the ACM, 58, Article No. 11. &lt;br&gt;https://doi.org/10.1145/1970392.1970395</mixed-citation></ref><ref id="hanspub.34707-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Liu, J., Musialski, P., Wonka, P. and Ye, J. (2013) Tensor Completion for Estimating Missing Values in Visual Data. IEEE Transactions on Pattern Analysis and Machine Intelligence, 35, 208-220.  
&lt;br&gt;https://doi.org/10.1109/TPAMI.2012.39</mixed-citation></ref><ref id="hanspub.34707-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Ji, H., Huang, S., Shen, Z. and Xu, Y. (2011) Robust Video Restoration by Joint Sparse and Low Rank Matrix Approximation. SIAM Journal on Imaging Sciences, 4, 1122-1142. &lt;br&gt;https://doi.org/10.1137/100817206</mixed-citation></ref><ref id="hanspub.34707-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Mørup, M. (2011) Applications of Tensor (Multiway Array) Factorizations and Decompositions in Data Mining. Data Mining and Knowledge Discovery, 1, 24-40. &lt;br&gt;https://doi.org/10.1002/widm.1</mixed-citation></ref><ref id="hanspub.34707-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Cao, W., Wang, Y., et al. (2016) Total Variation Regularized Tensor RPCA for Background Subtraction from Compressive Measurements. IEEE Transactions on Image Processing, 25, 4075-4090.  
&lt;br&gt;https://doi.org/10.1109/TIP.2016.2579262</mixed-citation></ref><ref id="hanspub.34707-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Kiers, H.A. (2000) Towards a Standardized Notation and Terminology in Multiway Analysis. Journal of Chemometrics: A Journal of the Chemometrics Society, 14, 105-122.  
&lt;br&gt;https://doi.org/10.1002/1099-128X(200005/06)14:3&lt;105::AID-CEM582&gt;3.0.CO;2-I</mixed-citation></ref><ref id="hanspub.34707-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Tucker, L.R. (1996) Some Mathematical Notes on Three-Mode Factor Analysis. Psychometrika, 31, 279-311.  
&lt;br&gt;https://doi.org/10.1007/BF02289464</mixed-citation></ref><ref id="hanspub.34707-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Hillar, C.J. and Lim, L.-H. (2013) Most Tensor Problems Are NP-Hard. Journal of the ACM, 60, 45. 
&lt;br&gt;https://doi.org/10.1145/2512329</mixed-citation></ref><ref id="hanspub.34707-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Lu, C., Feng, J., Chen, Y., Liu, W., Lin, Z. and Yan, S. (2016) Tensor Robust Principal Component Analysis: Exact Recovery of Corrupted Low-Rank Tensors via Convex Optimization. 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Las Vegas, NV, 27-30 June 2016, 5249-5257. &lt;br&gt;https://doi.org/10.1109/CVPR.2016.567</mixed-citation></ref><ref id="hanspub.34707-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">谢瑞, 王春祥, 马会阳, 张永显. 等式约束病态模型的截断奇异值解及其统计性质[J]. 测绘科学技术学报, 2019, 36(3): 227-232+237.</mixed-citation></ref><ref id="hanspub.34707-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">王艺卓, 曾海金, 赵佳佳, 谢晓振. 基于张量截断核范数的高光谱图像超分辨率重构[J]. 激光与光电子学进展, 2019, 56(21): 80-89.</mixed-citation></ref><ref id="hanspub.34707-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">Kilmer, M.E. and Martin, C.D. (2011) Factorization Strategies for Third-Order Tensors. Linear Algebra and Its Applications, 435, 641-658. &lt;br&gt;https://doi.org/10.1016/j.laa.2010.09.020</mixed-citation></ref><ref id="hanspub.34707-ref17"><label>17</label><mixed-citation publication-type="other" xlink:type="simple">Zhang, Z., Ely, G., Aeron, S., Hao, N. and Kilmer, M. (2014) Novel Methods for Multilinear Data Completion and Denoising Based on Tensor-SVD. 2014 IEEE Conference on Computer Vision and Pattern Recognition, Columbus, OH, 23-28 June 2014, 3842-3849. &lt;br&gt;https://doi.org/10.1109/CVPR.2014.485</mixed-citation></ref><ref id="hanspub.34707-ref18"><label>18</label><mixed-citation publication-type="other" xlink:type="simple">Hu, Y., Zhang D.B., Ye, J.P., et al. (2013) Fast and Accurate Matrix Completion via Truncated Nuclear Norm Regularization. IEEE Transactions on Pattern Analysis and Machine Intelligence, 35, 2117-2130.  
&lt;br&gt;https://doi.org/10.1109/TPAMI.2012.271</mixed-citation></ref><ref id="hanspub.34707-ref19"><label>19</label><mixed-citation publication-type="other" xlink:type="simple">Huang, B., Mu, C., Goldfarb, D., et al. (2014) Provable Low-Rank Tensor Recovery. Optimization-Online, 4252, 455-500.</mixed-citation></ref></ref-list></back></article>