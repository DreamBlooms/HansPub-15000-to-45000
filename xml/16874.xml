<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">SSEM</journal-id><journal-title-group><journal-title>Service Science and Management</journal-title></journal-title-group><issn pub-type="epub">2324-7908</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/SSEM.2016.51003</article-id><article-id pub-id-type="publisher-id">SSEM-16874</article-id><article-categories><subj-group subj-group-type="heading"><subject>SSEM20160100000_73992166.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>经济与管理</subject></subj-group></article-categories><title-group><article-title>
 
 
  距离学习在结构化概念管理本体模型中的应用
  Distance Learning Applied in Structure Concept Management Ontology Model
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>何</surname><given-names>国英</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>高</surname><given-names>炜</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>云南师范大学经济与管理学院，云南 昆明</addr-line></aff><aff id="aff3"><addr-line>云南师范大学信息学院，云南 昆明</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>12</day><month>01</month><year>2016</year></pub-date><volume>05</volume><issue>01</issue><fpage>18</fpage><lpage>25</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   本体作为一种结构化数据模型，已经被广泛应用在各个科学领域。在管理学中，本科作为一种信息检索模型用于信息的语义查询和扩张。本文给出一种基于距离学习的本体学习算法，利用特征值优化方法得到计算模型。通过两个仿真实验来验证新本体算法的有效性。&lt;br/&gt;As a structured data model, ontology has been widely used in various fields of science. In man-agement, ontology model is a tool for information retrieving and semantic query expanding. In this paper, we present an ontology learning algorithm based on distance learning method, and the framework is obtained by means of eigenvalues calculation. Through two simulation experiments, we verify the effectiveness of the new ontology algorithm.
    
  
 
</p></abstract><kwd-group><kwd>本体，相似度计算，本体映射，距离学习, Ontology</kwd><kwd> Ontology Similarity Measuring</kwd><kwd> Ontology Mapping</kwd><kwd> Distance Learning</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>距离学习在结构化概念管理本体模型中的应用<sup> </sup></title><p>何国英<sup>1</sup>，高炜<sup>2</sup></p><p><sup>1</sup>云南师范大学经济与管理学院，云南 昆明</p><p><sup>2</sup>云南师范大学信息学院，云南 昆明</p><disp-formula id="hanspub.16874-formula232"><graphic xlink:href="http://html.hanspub.org/file/3-2710147x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>收稿日期：2016年1月8日；录用日期：2016年1月26日；发布日期：2016年1月29日</p><disp-formula id="hanspub.16874-formula233"><graphic xlink:href="http://html.hanspub.org/file/3-2710147x7_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>本体作为一种结构化数据模型，已经被广泛应用在各个科学领域。在管理学中，本科作为一种信息检索模型用于信息的语义查询和扩张。本文给出一种基于距离学习的本体学习算法，利用特征值优化方法得到计算模型。通过两个仿真实验来验证新本体算法的有效性。</p><p>关键词 :本体，相似度计算，本体映射，距离学习</p><disp-formula id="hanspub.16874-formula234"><graphic xlink:href="http://html.hanspub.org/file/3-2710147x8_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s3"><title>1. 引言</title><p>本体一词最初起源于哲学领域，用于表述事物之间的本质必然关联。之后，本体作为一个数据管理模型应用于计算机领域。进入本世纪之后，本体已经成为集数据管理、存储、计算、检索为一体的工具。在管理学中，为了有效地对海量数据进行管理，需要其管理模型能拥有结构化表示数据的能力，从而，本体开始应用于数据管理领域，其相关技术在近几年得到了长足的发展，各种本体算法孕育而生(见[<xref ref-type="bibr" rid="hanspub.16874-ref1">1</xref>] -[<xref ref-type="bibr" rid="hanspub.16874-ref10">10</xref>] )。此外，借于其强大的数据管理功能，本体被应用于其他学科领域，比如教育学、心理学、生物学、化学等等。</p><p>一般地，用用O表示一个本体，用一个图<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x9_hanspub.png" xlink:type="simple"/></inline-formula>来该本体对应的数据结构。在管理学中，本体利用其自身结构化特征为用于提供查询服务。在具体的工程应用中，数据查询是本体这一数据管理模型的主要功能。从这一角度来说，在本体上的各种应用算法，其核心和本质是对存储的概念进行相似度计算，进而知道它们之间的联系。</p><p>近年来，通过学习方法得到本体算法已经成为研究的热点。[<xref ref-type="bibr" rid="hanspub.16874-ref2">2</xref>] 提出了基于对偶理论的本体稀疏向量学习算法；[<xref ref-type="bibr" rid="hanspub.16874-ref3">3</xref>] 模糊本体中的模糊相似度计算；[<xref ref-type="bibr" rid="hanspub.16874-ref4">4</xref>] 给出了基于MLS方法的本体学习算法；[<xref ref-type="bibr" rid="hanspub.16874-ref5">5</xref>] 提出基于梯度下降策略的本体稀疏向量学习算法；[<xref ref-type="bibr" rid="hanspub.16874-ref6">6</xref>] 在多重分割框架下提出无限推荐本体算法；[<xref ref-type="bibr" rid="hanspub.16874-ref7">7</xref>] 利用控制论方法提出新本体相似度计算和本体映射优化算法；[<xref ref-type="bibr" rid="hanspub.16874-ref8">8</xref>] 得到基于TLP经验模型的本体学习算法；[<xref ref-type="bibr" rid="hanspub.16874-ref9">9</xref>] 将信号逼近的方法应用于本体相似度计算和本体映射中，得到相应的算法；[<xref ref-type="bibr" rid="hanspub.16874-ref10">10</xref>] 在k-部排序框架下给出基于AUC标准的本体算法。</p><p>本文提出基于距离学习的本体相似度计算和本体映射算法，其算法主要是利用特征值优化技术。</p></sec><sec id="s4"><title>2. 本体学习算法框架</title><p>在本体管理模型中，每个概念对应本体图中的一个顶点。为了将本体算法融入到学习框架中，需要对这些概念进行预处理，即对每个顶点而言，用一个向量来表示这个顶点对应概念的所有信息。在不引起混淆的情况下，符号<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x10_hanspub.png" xlink:type="simple"/></inline-formula>同时表示顶点和它对应的向量。因此在本文中，表示顶点对应概念信息的向量用该顶点v来表示，不再使用标准向量的粗体。在整个学习过程中，使用如下两个集合作为样本集，其实S是相似顶点对构成的集合，D是不相似顶点对构成的集合：</p><p><inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x11_hanspub.png" xlink:type="simple"/></inline-formula>,</p><p><inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x12_hanspub.png" xlink:type="simple"/></inline-formula>.</p><p>而顶点之间的距离则用如下公式进行计算：</p><disp-formula id="hanspub.16874-formula235"><label>(1)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/3-2710147x13_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中M是一个半正定对称矩阵。根据公式(1)，距离学习的实质是学习得到文矩阵M。对任意自然数n，设<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x14_hanspub.png" xlink:type="simple"/></inline-formula>。设<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x15_hanspub.png" xlink:type="simple"/></inline-formula>是对称p阶矩阵空间，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x16_hanspub.png" xlink:type="simple"/></inline-formula>为正定对称p阶矩阵空间。设任意<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x17_hanspub.png" xlink:type="simple"/></inline-formula>，空间<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x18_hanspub.png" xlink:type="simple"/></inline-formula>上的内积可以表示为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x19_hanspub.png" xlink:type="simple"/></inline-formula>，其中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x20_hanspub.png" xlink:type="simple"/></inline-formula>表示矩阵的迹。用<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x21_hanspub.png" xlink:type="simple"/></inline-formula>表示标准欧式空间下的泛数。由n个本体样本点构成的样本集合记为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x22_hanspub.png" xlink:type="simple"/></inline-formula>，其中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x23_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x24_hanspub.png" xlink:type="simple"/></inline-formula>是顶点<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x25_hanspub.png" xlink:type="simple"/></inline-formula>对应的标记。记<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x26_hanspub.png" xlink:type="simple"/></inline-formula>，则由(1)可知<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x27_hanspub.png" xlink:type="simple"/></inline-formula>。若<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x28_hanspub.png" xlink:type="simple"/></inline-formula>属于相似集合对，则设<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x29_hanspub.png" xlink:type="simple"/></inline-formula>，并将<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x30_hanspub.png" xlink:type="simple"/></inline-formula>记为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x31_hanspub.png" xlink:type="simple"/></inline-formula>。</p><p>在学习过程中，我们希望相似的顶点对，它们的距离尽可能的小；而不相似的顶点对，它们的距离尽可能的大。进而可以如下表示：</p><disp-formula id="hanspub.16874-formula236"><label>(2)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/3-2710147x32_hanspub.png"  xlink:type="simple"/></disp-formula><p>采用对最小平方距离进行最大化的方法，(2)又可以化为</p><disp-formula id="hanspub.16874-formula237"><label>(3)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/3-2710147x33_hanspub.png"  xlink:type="simple"/></disp-formula><p>记<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x34_hanspub.png" xlink:type="simple"/></inline-formula>，则(3)又可以写成</p><disp-formula id="hanspub.16874-formula238"><label>(4)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/3-2710147x35_hanspub.png"  xlink:type="simple"/></disp-formula><p>可见，(4)是一个典型的半正定规划(semi-definite programming，简称SDP)，其等价于</p><disp-formula id="hanspub.16874-formula239"><label>(5)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/3-2710147x36_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s5"><title>3. 主要本体学习算法描述</title><p>下面我们给出本文主要本体学习策略。对任意<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x37_hanspub.png" xlink:type="simple"/></inline-formula>，记<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x38_hanspub.png" xlink:type="simple"/></inline-formula>为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x39_hanspub.png" xlink:type="simple"/></inline-formula>的最大特征值。设<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x40_hanspub.png" xlink:type="simple"/></inline-formula>为不相似对的个数，它的单纯形则为</p><p><inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x41_hanspub.png" xlink:type="simple"/></inline-formula>.</p><p>记<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x42_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x43_hanspub.png" xlink:type="simple"/></inline-formula>。设<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x44_hanspub.png" xlink:type="simple"/></inline-formula>是可逆的，则(4)等价于</p><disp-formula id="hanspub.16874-formula240"><label>. (6)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/3-2710147x45_hanspub.png"  xlink:type="simple"/></disp-formula><p>更进一步，可以表示成如下特征值优化问题：</p><p><inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x46_hanspub.png" xlink:type="simple"/></inline-formula>.</p><p>如果设三元组<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x47_hanspub.png" xlink:type="simple"/></inline-formula>表示为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x48_hanspub.png" xlink:type="simple"/></inline-formula>与<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x49_hanspub.png" xlink:type="simple"/></inline-formula>相似，但<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x50_hanspub.png" xlink:type="simple"/></inline-formula>与<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x51_hanspub.png" xlink:type="simple"/></inline-formula>不相似，并设<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x52_hanspub.png" xlink:type="simple"/></inline-formula>为这样的三元组的集合。重新记<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x53_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x54_hanspub.png" xlink:type="simple"/></inline-formula>。则本体算法问题又可以重新写为如下形式：</p><disp-formula id="hanspub.16874-formula241"><label>(7)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/3-2710147x55_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x56_hanspub.png" xlink:type="simple"/></inline-formula>是平衡参数。通过计算可知，上述(7)又等价于</p><p><inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x57_hanspub.png" xlink:type="simple"/></inline-formula>.</p><p>类似地，设<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x58_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x59_hanspub.png" xlink:type="simple"/></inline-formula>。假设<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x60_hanspub.png" xlink:type="simple"/></inline-formula>可逆，则上述本体问题(7)又等价于</p><disp-formula id="hanspub.16874-formula242"><label>(8)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/3-2710147x61_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中向量<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x62_hanspub.png" xlink:type="simple"/></inline-formula>表示其所有分量都是1。设<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x63_hanspub.png" xlink:type="simple"/></inline-formula>表示向量<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x64_hanspub.png" xlink:type="simple"/></inline-formula>的最大元素，则(7)可以表示为广义特征值优化问题如下：</p><p><inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x65_hanspub.png" xlink:type="simple"/></inline-formula>.</p><p>事实上，由(6)可知本体问题可看成</p><p><inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x66_hanspub.png" xlink:type="simple"/></inline-formula>.(9)</p><p>为解答本体问题(9)，引入光滑参数<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x67_hanspub.png" xlink:type="simple"/></inline-formula>，并定义</p><p><inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x68_hanspub.png" xlink:type="simple"/></inline-formula>.</p><p>下面我们使用光滑逼近的思想来解(9):</p><p>输入：光滑参数<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x69_hanspub.png" xlink:type="simple"/></inline-formula>，阈值<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x70_hanspub.png" xlink:type="simple"/></inline-formula>，步长序列<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x71_hanspub.png" xlink:type="simple"/></inline-formula>；</p><p>初始化：<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x72_hanspub.png" xlink:type="simple"/></inline-formula>满足<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x73_hanspub.png" xlink:type="simple"/></inline-formula>；</p><p>对<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x74_hanspub.png" xlink:type="simple"/></inline-formula>做如下循环</p><p><inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x75_hanspub.png" xlink:type="simple"/></inline-formula>,</p><p>即<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x76_hanspub.png" xlink:type="simple"/></inline-formula>其中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x77_hanspub.png" xlink:type="simple"/></inline-formula>为矩阵<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x78_hanspub.png" xlink:type="simple"/></inline-formula>的最大特征值。</p><p><inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x79_hanspub.png" xlink:type="simple"/></inline-formula>;</p><p>若<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x80_hanspub.png" xlink:type="simple"/></inline-formula>，则退出循环；</p><p>输出：<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x81_hanspub.png" xlink:type="simple"/></inline-formula>阶矩阵<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x82_hanspub.png" xlink:type="simple"/></inline-formula>。</p><p>可知道，如果步长序列满足<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x83_hanspub.png" xlink:type="simple"/></inline-formula>且<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x84_hanspub.png" xlink:type="simple"/></inline-formula>，则有<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x85_hanspub.png" xlink:type="simple"/></inline-formula>。</p><p>另外一个解答本体优化问题(8)的思路可以表述如下。先设</p><p><inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x86_hanspub.png" xlink:type="simple"/></inline-formula>.</p><p>这样一来，(8)等价于</p><p><inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x87_hanspub.png" xlink:type="simple"/></inline-formula>.</p><p>用如下的函数来逼近<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x88_hanspub.png" xlink:type="simple"/></inline-formula>：</p><p><inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x89_hanspub.png" xlink:type="simple"/></inline-formula>.</p><p>其梯度为</p><p><inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x90_hanspub.png" xlink:type="simple"/></inline-formula>,</p><p><inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x91_hanspub.png" xlink:type="simple"/></inline-formula>.</p><p>其具体逼近方法为：</p><p>输入：光滑参数<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x92_hanspub.png" xlink:type="simple"/></inline-formula>，阈值<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x93_hanspub.png" xlink:type="simple"/></inline-formula>，步长序列<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x94_hanspub.png" xlink:type="simple"/></inline-formula>；</p><p>初始化：<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x95_hanspub.png" xlink:type="simple"/></inline-formula>满足<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x96_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x97_hanspub.png" xlink:type="simple"/></inline-formula>；</p><p>对<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x98_hanspub.png" xlink:type="simple"/></inline-formula>做如下循环</p><p><inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x99_hanspub.png" xlink:type="simple"/></inline-formula>；</p><p><inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x100_hanspub.png" xlink:type="simple"/></inline-formula>;</p><p>若<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x101_hanspub.png" xlink:type="simple"/></inline-formula>，则退出循环；</p><p>输出：<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x102_hanspub.png" xlink:type="simple"/></inline-formula>阶矩阵<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x103_hanspub.png" xlink:type="simple"/></inline-formula>和松弛变量<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2710147x104_hanspub.png" xlink:type="simple"/></inline-formula>。</p><p>利用以上两种策略，都可以得到顶点对应向量之间距离计算公式，进而间接确定顶点对应概念之间的相似度。</p></sec><sec id="s6"><title>4. 实验</title><p>本节中，我们将验证以上得到的本体算法对本体相似度计算和本体映射的有效。为此，将本文学习算法应用于生物学GO本体和物理教育学本体，前者验证算法对相似度计算的效率，后者验证算法对本体映射构建是否有效。</p><sec id="s6_1"><title>4.1. 本体相似度实验</title><p>GO本体构建于http://www.geneontology.Org网站，它将一些生物基因概念集合在一起进行管理，方便用户查找信息。因此，GO本体可以看成一个数据库，图1可见该本体的大致结构，其图形可以表示为一棵树，所有概念分成“molecular function”，“biological process”和“cellular component”三个部分。实验的过程是利用本文得到的算法在GO本体上进行概念顶点之间的距离计算，距离越小则表示相似度越大；反之，距离越大则表示相似度越小。因为这样得到的相似度是相对的，所以实验结构可以使用P@N[<xref ref-type="bibr" rid="hanspub.16874-ref11">11</xref>] 平均准确率来判定它的优劣。为了有所比较，将如下以下三类本体学习算法也同时作用于GO本体：基于传统回归学习模型的本体算法[<xref ref-type="bibr" rid="hanspub.16874-ref12">12</xref>] 、基于快速排序的学习模型的本体算法[<xref ref-type="bibr" rid="hanspub.16874-ref13">13</xref>] 和基于一般本体排序学习方法的本体算法[<xref ref-type="bibr" rid="hanspub.16874-ref14">14</xref>] 。取N = 3，5，10，其P@N准确率对比可参考表1。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Part of dat</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >算法名称</th><th align="center" valign="middle" >P@3平均准确率</th><th align="center" valign="middle" >P@5平均准确率</th><th align="center" valign="middle" >P@10平均准确率</th></tr></thead><tr><td align="center" valign="middle" >本文算法</td><td align="center" valign="middle" >57.52%</td><td align="center" valign="middle" >66.02%</td><td align="center" valign="middle" >84.61%</td></tr><tr><td align="center" valign="middle" >本体回归算法</td><td align="center" valign="middle" >56.44%</td><td align="center" valign="middle" >63.48%</td><td align="center" valign="middle" >78.41%</td></tr><tr><td align="center" valign="middle" >快速排序算法</td><td align="center" valign="middle" >47.73%</td><td align="center" valign="middle" >55.52%</td><td align="center" valign="middle" >69.93%</td></tr><tr><td align="center" valign="middle" >标准排序算法</td><td align="center" valign="middle" >52.37%</td><td align="center" valign="middle" >60.62%</td><td align="center" valign="middle" >72.96%</td></tr></tbody></table></table-wrap><p>表1. 部分实验数据</p><p>图1. GO本体O<sub>1</sub></p><p>根据取N = 3，5，10时表1中的P@N准确率数据分析对比可知，利用特征值优化得到的距离计算方法可以用于本体相似度计算，并且对GO本体而言，其效率要高于另外三种使用的方法。</p></sec><sec id="s6_2"><title>4.2. 本体映射实验</title><p>接下来，需要验证本文使用特征值优化方法的距离计算模型是否对多个本体之间映射的构建有效。借助物理教育学本体O<sub>2</sub>和O<sub>3</sub>，其结构可参考图2和图3。由于是本体映射，因此此次距离计算只在不同本体之间进行。同理，距离越小说明相似度越高，距离越大说明相似度越小。而最后本体映射的构建是在相似度计算的基础上进行的。即对于某一个顶点而言，返回在另一个本体中与之相似的顶点集合作为映射值。算法得到的是相对相似度，因此实验准确率同样采用P@N准确率来判断。为了和其他算法的结果进行对比，我们还是将上一个实验中用过的三类算法作用于物理教育学本体O<sub>2</sub>和O<sub>3</sub>：基于传统回归学习模型的本体算法、基于快速排序的学习模型的本体算法和基于一般本体排序学习方法的本体算法。由于本次实验中本体顶点数量较少，因此只取N = 1，3，5。表2中显示了部分实验结果。</p><p>由表2的数据可知，在取N = 1，3，5的情况下，本文特征值优化得到的距离计算模型在物理学教育本体上构建本体映射的效率要高于其他使用的三种方法。</p></sec></sec><sec id="s7"><title>5. 结束语</title><p>本体的本质是一个概念集合。在管理学中，为了对概念进行有效管理，需要将其结构化存储和表示，</p><p>图2. 教育学本体O<sub>2</sub></p><p>图3. 教育学本体O<sub>3</sub></p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> Part of dat</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >算法名称</th><th align="center" valign="middle" >P@1平均准确率</th><th align="center" valign="middle" >P@3平均准确率</th><th align="center" valign="middle" >P@5平均准确率</th></tr></thead><tr><td align="center" valign="middle" >本文算法</td><td align="center" valign="middle" >48.39%</td><td align="center" valign="middle" >56.99%</td><td align="center" valign="middle" >77.42%</td></tr><tr><td align="center" valign="middle" >本体回归算法</td><td align="center" valign="middle" >48.39%</td><td align="center" valign="middle" >52.69%</td><td align="center" valign="middle" >65.81%</td></tr><tr><td align="center" valign="middle" >快速排序算法</td><td align="center" valign="middle" >41.94%</td><td align="center" valign="middle" >49.46%</td><td align="center" valign="middle" >59.35%</td></tr><tr><td align="center" valign="middle" >标准排序算法</td><td align="center" valign="middle" >45.16%</td><td align="center" valign="middle" >56.99%</td><td align="center" valign="middle" >64.52%</td></tr></tbody></table></table-wrap><p>表2. 部分实验数据</p><p>因而本体作为一种方法和工具被广泛应用于大数据相关概念管理中。而用户则需要知道这些概念之间的相互联系，因而在本体上进行相似度计算时本体应用的核心内容。本文利用特征值优化得到距离学习方法，并将其用在本体相似度计算和本体映射中。第四节中所示的两个实验表明，新算法是可行的并且是有效的。</p></sec><sec id="s8"><title>基金项目</title><p>国家自然科学青年基金资助项目(11401519)。</p></sec><sec id="s9"><title>文章引用</title><p>何国英,高 炜. 距离学习在结构化概念管理本体模型中的应用Distance Learning Applied in Structure Concept Management Ontology Model[J]. 服务科学和管理, 2016, 05(01): 18-25. http://dx.doi.org/10.12677/SSEM.2016.51003</p></sec><sec id="s10"><title>参考文献 (References)</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.16874-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">何国英, 高炜. 基于AJAX和CSS技术的教师在线评价系统设计[J]. 昆明学院学报, 2013, 35(6): 109-111.</mixed-citation></ref><ref id="hanspub.16874-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">高炜. 基于对偶理论的本体稀疏向量学习算法[J]. 云南师范大学学报(自然科学版), 2015, 35(4): 46-50.</mixed-citation></ref><ref id="hanspub.16874-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">赵白露, 高炜. 模糊本体中的模糊相似度计算[J]. 重庆工商大学学报(自然科学版), 2014, 31(9): 60-62.</mixed-citation></ref><ref id="hanspub.16874-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">何国英, 高炜. 基于MLS方法的本体算法[J]. 红河学院学报, 2015, 13(5): 14-16.</mixed-citation></ref><ref id="hanspub.16874-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Gao, W., Wu, J.Z. and Zhu, L.L. (2015) Ontology Optimization Strategies for Sparse Vector Learning Using Gradient Descent Tricks. Journal of Com-putational Information Systems, 11, 6393-6402.</mixed-citation></ref><ref id="hanspub.16874-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Gao, W., Zhu, L.L. and Guo, Y. (2015) Multi-Dividing Infinite Push Ontology Algorithm. Engineering Letters, 23, 132-139.</mixed-citation></ref><ref id="hanspub.16874-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Yu, X., Wu, J.Z. and Gao, W. (2015) A New On-tology Optimization Algorithm for Similarity Measuring and Ontology Mapping in Multi-Dividing Setting. Journal of Computational Information Systems, 11, 3297-3305.</mixed-citation></ref><ref id="hanspub.16874-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">何国英, 高炜. 基于TLP经验模型的本体学习算法[J]. 大理学院学报, 2015, 13(12): 11-14.</mixed-citation></ref><ref id="hanspub.16874-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Gao, Y. and Gao, W. (2015) Ontology Similarity Measuring and Ontology Mapping Algorithms Based on Fused Lasso Signal Approximator. American Journal of Circuits, Systems and Signal Processing, 1, 14-19.</mixed-citation></ref><ref id="hanspub.16874-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Gao, Y., Gao, W. and Liang, L. (2013) A New k-Partite Ranking Learning Algorithm Based on AUC Metric and Application in Ontology. Scientific Journal of Computer Science, 3, 136-144.</mixed-citation></ref><ref id="hanspub.16874-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Craswell, N. and Hawking, D. (2003) Overview of the TREC 2003 Web Track. Proceedings of the Twelfth Text Retrieval Conference, Gaithersburg, NIST Special Publication, 78-92.</mixed-citation></ref><ref id="hanspub.16874-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Gao, Y. and Gao, W. (2012) Ontology Similarity Measure and Ontology Mapping via Learning Optimization Similarity Function. International Journal of Machine Learning and Computing, 2, 107-112.  
&lt;br&gt;http://dx.doi.org/10.7763/IJMLC.2012.V2.97</mixed-citation></ref><ref id="hanspub.16874-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Huang, X., Xu, T., Gao, W. and Jia, Z. (2011) Ontology Si-milarity Measure and Ontology Mapping via Fast Ranking Method. International Journal of Applied Physics and Ma-thematics, 1, 54-59.  
&lt;br&gt;http://dx.doi.org/10.7763/ijapm.2011.v1.11</mixed-citation></ref><ref id="hanspub.16874-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">王雅玡, 高炜, 张云港, 高云. 基于排序学习方法的本体相似度计算[C]. 3rd International Conference on Computational Intelligence and Industrial Application (PACIIA), 2010, 武汉, 20-23.</mixed-citation></ref></ref-list></back></article>