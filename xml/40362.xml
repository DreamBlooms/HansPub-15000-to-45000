<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2021.112030</article-id><article-id pub-id-type="publisher-id">CSA-40362</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20210200000_71408838.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于改进SURF算法的显微图像大范围拼接
  Large Scale Microscopic Image Mosaic Based on SURF Algorithm
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>王</surname><given-names>世民</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>袁</surname><given-names>小龙</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>秦</surname><given-names>襄培</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>陈</surname><given-names>林</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>武汉工程大学机电工程学院，湖北 武汉</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>08</day><month>02</month><year>2021</year></pub-date><volume>11</volume><issue>02</issue><fpage>299</fpage><lpage>304</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   在实现大范围微结构测量时，白光干涉表面测量受限于单个光学视场的大小，不能看到完整的结构。为了获得大范围的视野效果，文中提出基于改进SURF算法对显微图像进行拼接。首先用Harris对图像进行特征点检测，然后对特征点进行描述符计算寻找点对之间的对应点对。再使用RANSAC对误配的点对进行删除，最后使用加权融合的方法来消除拼接缝。实验结果表明，该方法是有效的，可以将多次采集得到多幅图片拼成一幅完整的图片来实现大视野的测量。 In large-scale microstructure measurement, the white light interferometric surface measurement is limited by the size of a single optical field of view, and cannot see the complete structure. In order to obtain a wide range of visual field effect, this paper proposes an improved surf algorithm for micro-scopic image mosaic. Firstly, Harris is used to detect the feature points of the image, and then the descriptor of the feature points is calculated to find the corresponding point pairs. Then RANSAC is used to delete the mismatched point pairs, and the weighted fusion method is used to eliminate the seam. The experimental results show that the method is effective, and it can put multiple images collected many times into a complete image to realize the measurement of large field of vision. 
  
 
</p></abstract><kwd-group><kwd>大范围测量，图像拼接，SURF算法，Harris角点，加权融合, Large Scale Measurement</kwd><kwd> Image Mosaic</kwd><kwd> SURF Algorithm</kwd><kwd> Harris Corner</kwd><kwd> Weighted Fusion</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>摘要</title><p>在实现大范围微结构测量时，白光干涉表面测量受限于单个光学视场的大小，不能看到完整的结构。为了获得大范围的视野效果，文中提出基于改进SURF算法对显微图像进行拼接。首先用Harris对图像进行特征点检测，然后对特征点进行描述符计算寻找点对之间的对应点对。再使用RANSAC对误配的点对进行删除，最后使用加权融合的方法来消除拼接缝。实验结果表明，该方法是有效的，可以将多次采集得到多幅图片拼成一幅完整的图片来实现大视野的测量。</p></sec><sec id="s2"><title>关键词</title><p>大范围测量，图像拼接，SURF算法，Harris角点，加权融合</p></sec><sec id="s3"><title>Large Scale Microscopic Image Mosaic Based on SURF Algorithm<sup> </sup></title><p>Shimin Wang, Xiaolong Yuan, Xiangpei Qin<sup>*</sup>, Lin Chen</p><p>School of Mechanical &amp; Electrical Engineering, Wuhan Institute of Technology, Wuhan Hubei</p><p><img src="//html.hanspub.org/file/5-1542007x4_hanspub.png" /></p><p>Received: Jan. 8<sup>th</sup>, 2021; accepted: Feb. 3<sup>rd</sup>, 2021; published: Feb. 10<sup>th</sup>, 2021</p><p><img src="//html.hanspub.org/file/5-1542007x5_hanspub.png" /></p></sec><sec id="s4"><title>ABSTRACT</title><p>In large-scale microstructure measurement, the white light interferometric surface measurement is limited by the size of a single optical field of view, and cannot see the complete structure. In order to obtain a wide range of visual field effect, this paper proposes an improved surf algorithm for microscopic image mosaic. Firstly, Harris is used to detect the feature points of the image, and then the descriptor of the feature points is calculated to find the corresponding point pairs. Then RANSAC is used to delete the mismatched point pairs, and the weighted fusion method is used to eliminate the seam. The experimental results show that the method is effective, and it can put multiple images collected many times into a complete image to realize the measurement of large field of vision.</p><p>Keywords:Large Scale Measurement, Image Mosaic, SURF Algorithm, Harris Corner, Weighted Fusion</p><disp-formula id="hanspub.40362-formula16"><graphic xlink:href="//html.hanspub.org/file/5-1542007x7_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2021 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/5-1542007x8_hanspub.png" /> <img src="//html.hanspub.org/file/5-1542007x9_hanspub.png" /></p></sec><sec id="s5"><title>1. 绪论</title><p>近年来，随着计算机视觉技术的不断发展，在生活中的很多方面都会涉及到图像拼接 [<xref ref-type="bibr" rid="hanspub.40362-ref1">1</xref>] [<xref ref-type="bibr" rid="hanspub.40362-ref2">2</xref>] 来获得一幅视野较广的图像，广泛地应用在汽车导航 [<xref ref-type="bibr" rid="hanspub.40362-ref3">3</xref>]、森林火灾监测 [<xref ref-type="bibr" rid="hanspub.40362-ref4">4</xref>]、医学图像分析等多个领域。</p><p>图像拼接技术是通过找到相邻两幅图像重合的部分，然后确定两张图像之间的变换关系，最后将两幅图像进行拼接和融合 [<xref ref-type="bibr" rid="hanspub.40362-ref5">5</xref>]。该技术能够克服一般成像设备视野受限的弊端，在不改变硬件条件的前提下能够进行大范围测量 [<xref ref-type="bibr" rid="hanspub.40362-ref6">6</xref>]。</p><p>目前常用的图像拼接算法有直接法和基于特征法这两种。直接法是利用图像间的灰度信息来确定图像之间的变换参数。基于特征法是通过找到图像的特征点，然后对两幅图像的特征点进行匹配来确定图像间的变换参数。目前常用的算法是基于特征法，常见的基于特征的匹配算法有SIFT (Scale Invariant Feature Transform)算法，又称为尺度不变特征变换 [<xref ref-type="bibr" rid="hanspub.40362-ref7">7</xref>] [<xref ref-type="bibr" rid="hanspub.40362-ref8">8</xref>] [<xref ref-type="bibr" rid="hanspub.40362-ref9">9</xref>] 和SURF (Speeded-up Robust Feaures)算法，即快速鲁棒特征算法 [<xref ref-type="bibr" rid="hanspub.40362-ref10">10</xref>]。Bay等人 [<xref ref-type="bibr" rid="hanspub.40362-ref11">11</xref>] 于2006年提出了SURF算法，它被称为SIFT算法的加速版，该算法采用了积分图像的概念，在多幅图像拼接下具有更好的鲁棒性。特征提取算法目前在机器视觉、人脸识别等领域应用比较广泛 [<xref ref-type="bibr" rid="hanspub.40362-ref12">12</xref>]，但是在显微图像的应用上相对来说较少。常用于显微图像拼接是基于SIFT和SURF的征点提取算法，尽管能较大程度上解决上述问题，但是速度慢，而SURF算法在寻找特征点时具有不稳定性，在进行点对匹配时，易造成较多的误匹配，从而对配准结果造成影响 [<xref ref-type="bibr" rid="hanspub.40362-ref13">13</xref>] [<xref ref-type="bibr" rid="hanspub.40362-ref14">14</xref>]。</p><p>基于此，本文提出一种基于改进的SURF算法来进行显微图像大范围拼接。首先利用Harris对图像进行特征点检测，然后再对特征点进行描述符计算寻找点对之间的对应点，使用RANSAC对误配点对进行剔除，最后采用加权融合的方法来消除拼接过程中产生的缝隙。实验结果表明该方法是有效的，可以将多次采集得到多幅图片拼成一幅完整的图片。</p></sec><sec id="s6"><title>2. Harris角点检测</title><p>Harris角点检测的思想是在图像中设计一个局部检测窗口，然后让窗口在图像的各个方向上进行微小的滑动，若窗口内区域的灰度发生了较大的变化，那么就认为在窗口内存在角点。如果没有灰度变化或者某一个方向上没有灰度变化，则可认为该窗口不存在角点。对于图像I(x,y)，在点(x,y)处分别平移u和v个单位，可得灰度强度变化的表达式为：</p><p>E u , v ( x , y ) = ∑ ( u , v ) W u , v [ I ( x + u , y + v ) − I ( x , y ) ] 2 (1)</p><p>其中： E u , v 为窗口灰度值； W u , v 为二维高斯窗口的函数。</p><p>将 E u , v ( x , y ) 化为二次型有</p><p>E u , v ( x , y ) = ( u , v ) M [ u v ] (2)</p><p>式中M称为像素点自相关矩阵。通过计算M，可得到角点响应函数CRF (Corner Response Function)表达式，其中k是常数，取值范围0.04~0.06。</p><disp-formula id="hanspub.40362-formula17"><label>(3)</label><graphic position="anchor" xlink:href="//html.scirp.org/file/5-1542007x10_hanspub.png"  xlink:type="simple"/></disp-formula><p>如果某个像素点的角点响应函数值是其周围中的最大值并且超过设置的阈值，则可以将此像素点认为是角点。</p></sec><sec id="s7"><title>3. SURF特征提取算法</title><p>SURF算法在保持SIFT算子优良性能的基础上，对兴趣点提取及其特征向量描述进行了改进。与SIFT相比，SURF变得更加稳定且计算效率得到了提高。SURF算法特征提取步骤如下：</p><p>1) 极值点检测</p><p>SURF算法特征点的提取是基于尺度空间理论，通过寻找图像的局部极值点来确定特征点，一般是局部最暗或者最亮的点。SURF算法检测特征点是通过构造Hessian矩阵来实现的。</p><p>2) 特征点定位</p><p>首先初步定为特征点，根据Hessian矩阵求出极值后，将其与3维邻域内的26个像素点进行比较，若它比周围26个像素点都大或者都小，则将其保留下来，作为候选特征点。再采用三维线性插值滤掉小于一定阈值的点以及错误定位的关键点，筛选出稳定的特征点。</p><p>3) 主方向确定</p><p>确定主方向可以保证旋转不变性。以特征点为中心，计算半径为6σ邻域内的点在水平和垂直方向上的Harr小波响应，再根据特征点远近给响应值赋予高斯权重系数，然后将响应值进行累加形成新矢量，选择最长矢量方向作为特征点主方向。</p><p>4) 生成特征描述符</p><p>以特征点为中心，将坐标轴旋转到主方向，根据特征点的主方向选取边长为20σ的正方形区域，再将该窗口区域划分 4 &#215; 4 的16个子区域，再对每个子区域统计25个像素的水平方向和垂直方向的Harr小波特征。分别得出各个区域相对于主方向而言的水平、垂直方向的Harr小波响应为dx、dy，然后再统计各个方向上的响应及响应的绝对值。</p></sec><sec id="s8"><title>4. RANSAC算法剔除误配点</title><p>根据上文所提及的SURF描述方法，我们可以得到图像之间的对应点对，由于两幅图像具有相似性，因此特征点之间也会存在相似性，这会造成对应点对的误匹配。因此本文利用RANSAC算法对误匹配点进行剔除。假定待配准图像的对应点对转换关系可以如下表示：</p><p>1) 在特征点的集合中随机抽取4对对应点对，计算其单应性矩阵H。</p><p>2) 计算剩余特征对应点在单应性矩阵H变换下的结果，计算出匹配点之间的误差，假如误差小于给定阈值则认为是内点，然后再计算内点的占比率，若占比率大于设定阈值则接受H值。</p><p>3) 若内点占比率小于设定阈值，重复1)和2)。</p></sec><sec id="s9"><title>5. 图像融合</title><p>完成图像的特征点匹配以后直接拼接图像，在重叠区域会产生裂缝、“鬼影”等变化现象。为了消除产生的裂缝，本文采用加权平均图像融合的方法进行平滑过渡消除这种现象，使图像重叠的中间区域较好地适应左右两边平滑的过渡，实现无缝无损的图像拼接。</p></sec><sec id="s10"><title>6. 实验结果及分析</title><p>本次实验利用白光干涉显微镜获取了不同视野下具有重叠的两张照片，利用Matlab平台对基于SURF算法和改进后的SURF算法进行图像匹配，再采用RANSAC算法进行误匹配点剔除。实验结果如图1和图2所示，两者的误配率与效率对比如表1所示。</p><p>图1. 改进前</p><p>图2. 改进后</p><p>图1为基于SURF和RANSAC获得的匹配图，在剔除误匹配点之前，初始匹配点为33对，使用RANSAC算法后剩余正确的特征点为22对，匹配时间为3726.57 ms。</p><p>图2为基于改进后的SURF和RANSAC获得的匹配图，在剔除误匹配点之前，初始匹配点为8对，使用RANSAC算法后剩余正确的特征点为6对，匹配时间为2469.27 ms。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Comparison of mismatch rate and efficienc</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" >筛选数目/对</th><th align="center" valign="middle" >误配点数目/对</th><th align="center" valign="middle" >误配率</th><th align="center" valign="middle" >效率/ms</th></tr></thead><tr><td align="center" valign="middle" >改进前</td><td align="center" valign="middle" >33</td><td align="center" valign="middle" >11</td><td align="center" valign="middle" >33.33%</td><td align="center" valign="middle" >3726.57</td></tr><tr><td align="center" valign="middle" >改进后</td><td align="center" valign="middle" >8</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >25%</td><td align="center" valign="middle" >2469.27</td></tr></tbody></table></table-wrap><p>表1. 两者误配率与效率对比</p><p>由表1的数据可知，改进后的算法在误配率方面相比于之前的SURF算法下降了8.33%；在运行时间上也由3726.566 ms减少到2469.259 ms，相对于改进前提高了33.7%。</p><p>为了验证此方法的合理性，在两幅图像匹配的基础上增加实验对象，对三幅具有部分相同的图像进行拼接，待拼接的3幅图像如图3所示，拼接结果如图4所示。结果表明该方法可以完成多幅图的拼接，且在拼接缝合处的效果较好。</p><p>图3. 待拼接图像</p><p>图4. 改进后的拼接图像</p></sec><sec id="s11"><title>7. 结论</title><p>本文通过对SURF算法进行研究实现了图像拼接，并基于此提出了一种改进的SURF算法对显微图像进行拼接，一般情况下，由于部分错误特征点的存在，会导致在图像拼接的时候在图像缝合处会有不完全融合情况，改进后的方法降低了匹配点对的误配率以及提高了匹配效率，消除了缝合处不平滑的现象，鲁棒性更强。</p></sec><sec id="s12"><title>文章引用</title><p>王世民,袁小龙,秦襄培,陈 林. 基于改进SURF算法的显微图像大范围拼接Large Scale Microscopic Image Mosaic Based on SURF Algorithm[J]. 计算机科学与应用, 2021, 11(02): 299-304. https://doi.org/10.12677/CSA.2021.112030</p></sec><sec id="s13"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.40362-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">刘进林, 等. 基于改进马尔科夫特征的图像拼接检测研究[J]. 信息技术与网络安全, 2020(2): 13-18.</mixed-citation></ref><ref id="hanspub.40362-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Xie, R.P., Tu, J.M. and Yao, J. (2019) A Robust Projection Plane Selection Strategy for UAV Image Stitching. International Journal of Remote Sensing, 40, 3118-3138. &lt;br&gt;https://doi.org/10.1080/01431161.2018.1539273</mixed-citation></ref><ref id="hanspub.40362-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">王震, 许恒硕, 袁红亮, 汪国平. 基于抖动的导航路径图像无缝拼接方法仿真[J]. 计算机仿真, 2020, 37(1): 425-429.</mixed-citation></ref><ref id="hanspub.40362-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">刘尚, 李哲. 面向野外火灾监测的图像拼接技术研究[J]. 计算机与数字工程, 2020, 48(3): 653-657.</mixed-citation></ref><ref id="hanspub.40362-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">万国挺, 王俊平, 李锦, 等. 图像拼接质量评价方法[J]. 通信学报, 2013, 34(8): 76-81.</mixed-citation></ref><ref id="hanspub.40362-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">杨云涛, 冯莹, 曹毓, 等. 基于SURF的序列图像快速拼接方法[J]. 计算机技术与发展, 2011, 21(3): 6-9.</mixed-citation></ref><ref id="hanspub.40362-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">李穆, 路艳蒙, 韩帅虎, 等. 基于sift特征点的透射电子显微镜多幅图像拼接[J]. 南方医科大学学报, 2015, 35(9): 1251-1257.</mixed-citation></ref><ref id="hanspub.40362-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">邹承明, 侯小碧, 马静. 基于几何学图像配准的SIFT图像拼接算祛[J]. 华中科技大学学报(自然科学版), 2016, 44(4): 32-36.</mixed-citation></ref><ref id="hanspub.40362-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">张勇, 王志峰, 马文. 基于改进SIFT特征点匹配的图像拼接算法研究[J]. 微电子学与计算机, 2016, 33(3): 60-64.</mixed-citation></ref><ref id="hanspub.40362-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Liu, Y.M., Chen, L.F. and Liu, Y. (2013) An Image Matching Algorithm Based on SIFT and Improved LTP. 2013 Ninth International Conference on Computational Intelligence and Security (CIS), 432-436.  
&lt;br&gt;https://doi.org/10.1109/CIS.2013.98</mixed-citation></ref><ref id="hanspub.40362-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Bay, H., Tuytelaars, T. and Gool, L. (2006) SURF: Speeded up Robust Features. European Conference on Computer Vision, Springer, Berlin, Heidelberg. &lt;br&gt;https://doi.org/10.1007/11744023_32</mixed-citation></ref><ref id="hanspub.40362-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">李丽, 郭双双, 梅树立, 等. 基于特征点提取匹配的蝗虫切片图像的拼接和修复方法[J]. 农业工程学报, 2015, 31(7): 157-165.</mixed-citation></ref><ref id="hanspub.40362-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">卢钢, 张翼. 基于局部特征的医学显微图像自动拼接[J]. 计算机与数字工程, 2015, 43(5): 892-895.</mixed-citation></ref><ref id="hanspub.40362-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">Ma, L.L., Cao, C.M. and Chen, J.G. (2016) Feature Point Matching Algorithm Based on RA NSAC. Computer Engineering and Design, 37, 1793-1797.</mixed-citation></ref></ref-list></back></article>