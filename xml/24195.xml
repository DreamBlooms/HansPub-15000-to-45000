<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">AP</journal-id><journal-title-group><journal-title>Advances in Psychology</journal-title></journal-title-group><issn pub-type="epub">2160-7273</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/AP.2018.83046</article-id><article-id pub-id-type="publisher-id">AP-24195</article-id><article-categories><subj-group subj-group-type="heading"><subject>AP20180300000_18389714.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>人文社科</subject><subject> 合作期刊</subject></subj-group></article-categories><title-group><article-title>
 
 
  场景主旨识别需要注意参与
  Scene Gist Perception Necessitates Attention
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>张</surname><given-names>志媛</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>王</surname><given-names>华</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib></contrib-group><aff id="aff1"><addr-line>西南大学心理学部，重庆</addr-line></aff><aff id="aff2"><addr-line>null</addr-line></aff><author-notes><corresp id="cor1">* E-mail:<email>zhangzhiyuan1018@163.com(张志)</email>;</corresp></author-notes><pub-date pub-type="epub"><day>07</day><month>03</month><year>2018</year></pub-date><volume>08</volume><issue>03</issue><fpage>371</fpage><lpage>378</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   识别场景主旨是否需要注意参与目前尚存争论。本研究采用快速序列视觉呈现范式，通过操纵场景主旨水平(基本水平与上级水平)和实验任务(单任务与双任务)，观察被试在四种T1-T2间隔延迟条件下(Lag2, Lag4, Lag6, Lag8)，识别T2场景主旨的正确率，从而揭示场景主旨识别与注意的关系。结果表明：被试能高效识别双任务下T1的场景主旨，无论是上级水平还是基本水平的场景主旨；但识别单任务和双任务条件下T2的场景主旨都出现注意瞬脱，并且识别上级水平的场景主旨引发更大的注意瞬脱。本研究支持场景主旨识别需要注意参与，并且识别上级水平的场景主旨消耗更多的注意资源。 It remains to be discussed about whether the scene gist perception needs attention. In the present study, participants identified one or two target scenes in a rapid serial visual presentation (RSVP) sequence with scrambled scenes and reported their basic-level category or superordinate-level category. T2 (the second target) was presented at Lag2, Lag4, Lag6 or Lag8 following T1 (the first target) in RSVP. Participants showed good performance in classifying T1 under dual-task condition whether or not the scene category was basic-level or superordinate-level. However, we observed the pronounced scene perception deficit in identifying T2 when it appeared within a few hundred milliseconds of T1 both in single-task condition and dual-task condition, namely attentional blink. In addition, the most interesting finding in our data was that the magnitude of the attentional blink increased when asked participants to identify the scene targets’ superordinate-level category, suggesting that superordinate-level scene gist perception demanded more attention. The results suggested that natural scene perception indeed necessitated attention, and the superordinate-level scene gist perception required more attention. 
  
 
</p></abstract><kwd-group><kwd>场景主旨，注意，注意瞬脱，上级水平，基本水平, Scene Gist</kwd><kwd> Attention</kwd><kwd> Attentional Blink</kwd><kwd> Superordinate Level</kwd><kwd> Basic Level</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>场景主旨识别需要注意参与<sup> </sup></title><p>张志媛，王华</p><p>西南大学心理学部，重庆</p><p><img src="//html.hanspub.org/file/10-1131153x1_hanspub.png" /></p><p>收稿日期：2018年3月7日；录用日期：2018年3月20日；发布日期：2018年3月27日</p><disp-formula id="hanspub.24195-formula8"><graphic xlink:href="//html.hanspub.org/file/10-1131153x5_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>识别场景主旨是否需要注意参与目前尚存争论。本研究采用快速序列视觉呈现范式，通过操纵场景主旨水平(基本水平与上级水平)和实验任务(单任务与双任务)，观察被试在四种T1-T2间隔延迟条件下(Lag2, Lag4, Lag6, Lag8)，识别T2场景主旨的正确率，从而揭示场景主旨识别与注意的关系。结果表明：被试能高效识别双任务下T1的场景主旨，无论是上级水平还是基本水平的场景主旨；但识别单任务和双任务条件下T2的场景主旨都出现注意瞬脱，并且识别上级水平的场景主旨引发更大的注意瞬脱。本研究支持场景主旨识别需要注意参与，并且识别上级水平的场景主旨消耗更多的注意资源。</p><p>关键词 :场景主旨，注意，注意瞬脱，上级水平，基本水平</p><disp-formula id="hanspub.24195-formula9"><graphic xlink:href="//html.hanspub.org/file/10-1131153x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2018 by authors and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/10-1131153x7_hanspub.png" /> <img src="//html.hanspub.org/file/10-1131153x8_hanspub.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>生活中人们能够仅在一瞥之间理解场景的意义，获取的信息可能是场景的类别(森林或街道)、场景的结构(开阔或封闭的空间)或是场景中的某些物体。识别场景主旨即理解场景的意义或主题(Potter, 1976; Friedman, 1979)。注意在场景主旨识别过程中是否发挥作用是当前场景认知加工研究的热点之一。</p><sec id="s3_1"><title>1.1. 识别场景主旨与注意的关系</title><p>Potter (1976)研究发现场景图片仅呈现100 ms时，人们就可以理解一个场景的意义，并且能够对场景中的物体进行探测和辨别。Thorpe等人(1996)研究表明，当场景图片呈现20 ms时，被试就能判断出场景中是否存在动物。另外，在刺激呈现后大约150 ms时目标场景与非目标场景引发的脑电成分出现显著差异，这表明人们对场景的识别是在150 ms前进行的(Thorpe, Fize, &amp; Marlot, 1996)。Kirchner和Thorpe (2006)研究表明当同时呈现两张场景图片时，被试能够对其中包含动物的图片在120~130 ms时发生超快速的眼跳。人们能够如此快速地加工场景信息，自上而下的注意可能还来不及发挥作用。这使得研究者提出这样一个问题：在快速的场景识别过程中，注意是否起重要的作用。</p><p>有研究者认为场景主旨识别不需要注意的参与。Rensink, O’Regan和Clark (1997)研究表明，尽管人们没有察觉到场景中的某个物体被移除，但被试能够立即发现场景的主旨是否发生改变。Li, VanRullen, Koch和Perona (2002)研究发现在双任务范式下，被试能高效地完成出现在周边视区的自然场景觉察任务。Li, VanRullen, Koch和Perona (2005)进一步研究发现，在周边视区同时呈现两张或是一张自然场景图片，被试都能够高效地完成场景识别任务，并且即使去掉自然场景图片的颜色，被试依然能够出色进行场景识别。</p><p>然而，另一部分研究者认为场景主旨识别需要注意参与。Cohen, Alvarez和Nakayama (2011)采用多物体追踪和快速序列视觉呈现任务(rapid serial visual presentation, RSVP)，这类任务的完成需要大量且持续的注意，此时被试对任务背景中意外出现的场景图片出现了非注意盲视。同样Mack和Clarke (2012)的研究结果也表明被试对任务背景中意外出现的自然场景图片出现了非注意盲视，即使场景图片在背景中意外地呈现两次，被试仍然会出现非注意盲视。</p><p>除了上述非注意盲视研究的证据，来自RSVP范式的研究也表明场景主旨识别需要注意的参与。RSVP范式中在同一位置快速序列呈现多个不同类型的刺激，如果第二个目标(T2)出现在第一个目标(下称T1)之后的200~500 ms之间，被试对T2的识别正确率显著降低，这种现象被称为注意瞬脱(Attentional Blink，下文简称AB，Raymond, Shapiro, &amp; Arnell, 1992)。Marois，Yi和Chun(2004)研究发现被试在RSVP任务中准确识别T1人脸目标之后，完成在T2位置出现的场景主旨识别任务时出现了AB效应。Evans和Treisman (2005)进一步研究发现当要求对自然场景中的物体进行识别时出现AB效应，而当只要求探测自然场景中物体是否存在时，几乎不会出现AB效应，由此他们推论识别场景主旨需要注意参与。</p></sec><sec id="s3_2"><title>1.2. 场景信息的认知加工研究</title><p>真实场景中包含大量的视觉信息，人们是按照怎样的顺序对自然场景包含的各类信息进行快速加工的呢？前人研究表明真实场景中包含两种信息，一是全局属性(global scene properties)信息，用来描述场景的整体特征—空间布局和结构功能等，如识别该场景是一个封闭或者炎热的地方；二是基本水平(basic-level)信息，识别出该场景的具体内容，如识别该场景是街道还是山脉(Oliva &amp; Torralba, 2001)。研究表明真实场景的全局属性主要有自然性、开放性、平均深度、隐蔽性和导航性等(Oliva &amp; Torralba, 2001; Greene &amp; Oliva, 2009; Greene &amp; Oliva, 2010; Greene &amp; Wolfe, 2011)。Oliva和Torralba (2001)提出的空间泡模型(the Spatial Envelope)将对场景主旨的描述划分为三个水平：下级水平(如街道上的汽车或行人)、基本水平(如森林或街道)和上级水平(如自然场景或人工场景)。</p><p>Greene和Oliva (2009)研究表明识别场景中的全局属性所需的呈现时间显著短于识别场景的基本水平类别的呈现时间，说明人们在视觉加工的早期，更倾向于识别出该场景是一个开阔空间或是一个人工场景(上级水平)，而不是识别出该场景的基本类别是沙漠或是街道(基本水平)，但人们对全局属性和基本水平类别的识别都可以在很短的时间内完成，被试达到75%正确率所需要的平均呈现时间大约是19~67 ms之间。</p><p>根据以上研究结果可知，场景中不同水平的信息在人们视觉加工过程中发挥着重要作用，场景的全局属性信息在视觉加工过程中能够被优先快速加工，更容易被觉察和识别。我们进而推测，不同水平的场景主旨是有区别的信息，能够在知觉加工过程中发挥调节作用，从而影响场景主旨识别对注意的需求量。</p></sec><sec id="s3_3"><title>1.3. 问题提出及研究思路</title><p>本研究从识别不同水平的场景主旨这一角度出发，考察识别基本水平和上级水平的场景主旨是否对注意需求存在差异。实验设计思路如下：将场景主旨划分两个水平：一是基本水平，识别出某场景的具体类别—沙滩、森林、街道和会议室；二是上级水平，识别出某场景是人工场景还是自然场景。本实验采用RSVP范式，通过操纵场景主旨的不同水平(基本水平和上级水平)和实验任务形式(单任务和双任务)，观察被试在T2-T1不同间隔延迟条件下(Lag2, Lag4, Lag6, Lag8)对T2识别的正确率，考察识别不同水平的场景主旨是否都会出现AB效应，以及出现AB的大小和持续时间是否存在差异，揭示场景主旨识别与注意之间的关系。</p><p>我们根据不同的理论提出以下两种可能的实验假设。根据原型理论(Prototype theory)，就像在物体命名实验中人们会对基本水平概念优先加工一样(Rosch, 1988)，我们预测识别基本水平的场景主旨对注意需求量更小，不出现或者出现较小的AB效应。但是，近年来多项实验研究发现全局属性信息比基本水平信息更容易被识别和区分(Greene &amp; Oliva, 2009)，据此我们假设人们能够在注意资源很少甚至没有注意参与时识别上级水平的场景主旨，而识别基本水平场景主旨会出现显著的AB效应。</p></sec></sec><sec id="s4"><title>2. 方法</title><sec id="s4_1"><title>2.1. 被试</title><p>40名大学生(男12，女28)作为有偿被试参加实验，年龄在17~23岁间(M = 20.3)，均为有利手，视力或矫正视力正常，无色盲色弱，之前均未参加过该类实验。</p></sec><sec id="s4_2"><title>2.2. 刺激与仪器</title><p>实验刺激呈现在17寸CRT彩色显示器上(屏幕分辨率1024 &#215; 768，刷新率75 Hz)。刺激材料选自场景图片库(Oliva &amp; Torralba, 2001; Greene &amp; Oliva, 2009)和互联网，均为彩色的真实场景图片(示例见图1)，图片大小均为256 &#215; 256像素。</p><p>本实验目标刺激T1和T2均为清晰的真实场景图片，将清晰的真实场景图片按照8 &#215; 16的矩形结构打乱后重新排列并倒置作为干扰刺激。正式实验共选取目标刺激图片576张，自然场景和人工场景图片各288张，包括沙滩、森林、街道、会议室各144张，干扰刺激图片共1872张，包括山脉、瀑布、田野、高楼、厨房、卧室等多种真实场景。此外，练习阶段另选取40张目标刺激和130张干扰刺激图片，练习阶段所用图片均不会出现在正式实验中。在整个实验中每张目标刺激图片仅呈现一次，每张干扰刺激图片在单任务和双任务条件下各呈现一次。</p></sec><sec id="s4_3"><title>2.3. 实验设计</title><p>采用2 (场景主旨水平：上级水平和基本水平) &#215; 2(实验任务：单任务和双任务) &#215; 4(T1-T2间隔延迟：lag2、lag4、lag6、lag8)的混合设计，场景主旨水平为组间变量，实验任务和T1-T2间隔延迟为组内变量。因变量为T1正确率和T1正确情况下T2的正确率(T2|T1)，对反应时间不做任何要求。</p></sec><sec id="s4_4"><title>2.4. 实验程序</title><p>每个试次开始前均在屏幕中央呈现1000 ms红色的“+”注视点。每个试次包含13张干扰刺激图片和2张目标刺激图片共15张图片，干扰刺激前后不会重复出现，每张呈现80 ms。为限制被试的准备效应，T1随机出现在刺激序列的第4、5、6个位置，T2为出现在T1之后的第二张清晰场景图片，T2随机在T1后的第2、4、6、8个位置出现。每个试次结束后要求被试根据屏幕上的问题作出按键反应，单任务条件下只识别T2的场景主旨，双任务条件下需要识别T1和T2的场景主旨，要求被试优先对T1进行判断并保证反应的正确率。作答没有时间限制，只要求尽可能准确地作出判断(示例见图1)。一半被试先做单任务，再做双任务，另一半被试反之。</p><p>将40名被试随机分成两组，每组20人，分别完成上级水平和基本水平的场景主旨识别任务。上级水平组被试判断目标是自然场景还是人工场景，基本水平组被试判断目标的具体场景类别—沙滩、森林、街道和会议室。为保证两组被试任务难度相同，完成二择一的迫选任务，所以将基本水平组分成两个区组，一个区组判断目标是沙滩还是森林，另一个区组判断是街道还是会议室，两个区组顺序在被试间进行平衡。</p><p>实验分为练习和正式实验两部分，每个区组任务都先进行10次练习。正式实验包括2种实验任务 &#215; 4种T2-T1间隔延迟共8种条件，每种条件包含36个试次，共288个试次。</p></sec></sec><sec id="s5"><title>3. 结果</title><p>双任务实验条件下的有效数据仅统计T1反应正确的实验试次的T2的反应正确率(见图2)。对被试T1正确率(T1)和T1正确情况下T2的正确率(T2|T1)进行分析。</p><sec id="s5_1"><title>3.1. T1的识别正确率(T1)</title><p>双任务实验条件下识别T1场景主旨的平均正确率为0.88，其中识别基本水平(M = 0.91)场景主旨的正确率显著高于上级水平(M = 0.85), t (38) = 2.823, p &lt; 0.01，表明双任务条件下，对T1场景主旨的识别，</p><p>图1. 单个实验试次示意图，图示为双任务条件下识别T1和T2上级水平的场景主旨，T1出现刺激流中在第4个位置，T2与T1间隔延迟为Lag2</p><p>图2. 不同实验条件下T1的反应正确率(T1)和T1正确情况下T2的反应正确率(T2|T1)</p><p>被试更容易获取基本水平的场景主旨。</p></sec><sec id="s5_2"><title>3.2. T2的识别正确率(T2|T1)</title><p>对T2的正确率进行2 &#215; 2 &#215; 4的重复测量方差分析，结果表明三个因素的主效应均显著，而交互作用均不显著。场景主旨水平主效应显著，F(1, 38) = 6.53, p &lt; 0.05, η<sub>p</sub><sup>2</sup> = 0.147，场景主旨为基本水平时(M = 0.82)正确率显著高于上级水平(M = 0.75)。实验任务主效应显著，F(1, 38) = 28.78, p &lt; 0.001, η<sub>p</sub><sup>2</sup> = 0.431，单任务下(M = 0.82)的正确率显著高于双任务(M = 0.75)。T2-T1的间隔延迟主效应显著，F(3, 114) = 88.45, p &lt; 0.001, η<sub>p</sub><sup>2</sup> = 0.699，多重比较分析发现，Lag2正确率显著低于Lag4、Lag6、Lag8，Lag4正确率也显著低于Lag6、Lag8(ps &lt; 0.01)，Lag6和Lag8差异不显著。</p><p>实验中的交互作用均不显著：场景主旨水平和实验任务交互作用不显著，F(1, 38) = 1.54, p &gt; 0.05, η<sub>p</sub><sup>2</sup> = 0.039；实验任务和T2-T1间隔延迟交互作用不显著，F(3, 114) = 0.70, p &gt; 0.05, η<sub>p</sub><sup>2</sup> = 0.018；场景主旨水平和T2-T1间隔延迟交互作用不显著，F(3, 114) = 0.09, p &gt; 0.05, η<sub>p</sub><sup>2</sup> = 0.002；三者交互作用也不显著，F(3, 114) = 0.59, p &gt; 0.05, η<sub>p</sub><sup>2</sup> = 0.015。</p></sec></sec><sec id="s6"><title>4. 讨论</title><p>本研究采用RSVP范式，考察识别不同水平的场景主旨是否都会引发AB效应。实验结果表明，识别基本水平和上级水平的场景主旨时，被试都能高效地识别T1的场景主旨，而在T1数百秒之后出现的T2却不能被有效地识别，表现出显著的T2-T1间隔延迟主效应，表明人们对场景主旨的识别出现显著的AB效应，支持场景主旨识别需要注意资源的参与，这与部分前人的研究结果是一致的(Marois, Yi, &amp; Chun, 2004; Evans &amp; Treisman, 2005; Cohen, Alvarez, &amp; Nakayam, 2011; Mack &amp; Clarke, 2012)。</p><sec id="s6_1"><title>4.1. 场景主旨识别引发AB效应</title><p>本研究中单任务和双任务实验条件下，识别不同水平的场景主旨都出现AB效应，并且结果表明被试在单任务实验条件下只是整体提高了对T2的识别正确率，并没有改变Lag effect的反应趋势。Marois，Yi和Chun (2004)结果表明在双任务条件下，T2场景识别任务出现显著AB效应，而在单任务条件被试能够有效地识别T2，而在本研究中被试在单任务下也出现AB效应。两个研究的不同在于，Marois等人采用的T1是随机呈现固定的三张人脸中的一个，要求判断T2是室内还是室外场景，每个刺激呈现100 ms；而本研究中T1和T2都是随机呈现的清晰场景图片，前后不会重复，每张图片只呈现80 ms。我们认为在Marois等人研究中，T1和T2是不同类型的刺激，即识别T1和T2是完成两种不同的任务，单任务条件下被试能够直接忽略T1，只判断出现的场景图片T2，并且T1中的人脸多次重复呈现，被试能更好地识别T1。但是本实验中干扰刺激是杂乱的场景图片，T1和T2都是清晰的真实场景图片，并且T2是继T1后出现的第二张清晰场景图片，因此单任务条件下即使要求被试忽略T1只判断T2的场景主旨，被试也需要先看到T1后才能找到T2，那么单任务条件下T1也会占用有限的注意资源，进而导致单任务条件下也出现AB效应，这更加说明场景主旨识别的确需要注意资源。</p><p>此外，与注意瞬脱范式的典型行为结果相比，前人采用字母或数字刺激序列时，引发的AB效应一般发生在200~500 ms时间窗内(Raymond et al.,1992; Chun &amp; Potter, 1995)，本研究中真实场景图片引发的AB持续时间为160~640 ms，说明识别场景主旨引发的AB效应持续时间更长，说明识别场景主旨对注意资源需求量更大。</p></sec><sec id="s6_2"><title>4.2. 识别不同水平的场景主旨对注意的需求</title><p>为探究场景主旨识别与注意的关系，我们操纵场景主旨的不同水平，研究发现识别不同水平的场景主旨都出现AB效应，识别上级水平场景主旨引发的AB效应大于基本水平，并且双任务条件下T1的识别正确率上级水平组也显著低于基本水平组，意味着识别不同水平的场景主旨都需要注意参与，并且识别上级水平场景主旨需要更多注意资源。</p><p>前人研究表明，在注意充足条件下，场景的全局属性能够被优先识别(Greene &amp; Oliva, 2009)。但本研究发现，在注意缺乏的条件下，全局属性信息并不能被优先加工，识别上级水平场景主旨出现更大的AB效应，对注意的需求量更大。我们认为当前的研究结果并不与Greene和Oliva (2009)矛盾，人们能够在注意充足时快速识别和区分场景全局属性特征，并不意味着场景的全局属性在注意缺乏时也能被优先加工。例如Greene和Oliva (2011)研究发现场景中的全局属性并不能有效地引导视觉搜索，场景的全局属性能够从一张单独图片中被快速识别，但当同时呈现多张图片时，场景的全局属性并不能有效引导注意。Rosch (1988)研究表明人们在对物体命名时基本水平的类别概念更容易被优先加工，如人们看到一个苹果，首先把它归类为苹果，再把它归类到上级水平的水果范畴。本实验结果表明在注意资源缺乏的条件下，场景的全局属性信息不能优先得到加工，人们更容易对场景主旨的基本水平类别作出判断，如人们倾向先识别该场景是一条街道，再识别出该场景是一个人工场景。但是这种推论是否正确还需要进一步的研究。</p><p>此外，也可能是实验中的干扰刺激对两组被试产生了不平衡的干扰作用。虽然两组采用的干扰刺激完全相同，都是随机杂乱的场景图片，但是基本水平组被试是要判断T1或T2的具体场景类别，干扰刺激中并不包含这四种目标类别，故而对识别目标的具体类别产生的干扰作用要小；而上级水平组是要判断T1或T2是人工场景还是自然场景，干扰刺激都是杂乱的人工场景和自然场景，当被试根据颜色、朝向和空间布局等判断刺激的全局属性(自然性)时，干扰刺激起到了更大的干扰作用，从而导致上级水平场景主旨的识别绩效显著低于基本水平。干扰刺激是否产生了不平衡的干扰作用还需进一步研究。</p></sec><sec id="s6_3"><title>4.3. 研究意义与展望</title><p>本研究首次通过操作识别不同水平的场景主旨，并采用RSVP范式来探讨识别场景主旨与注意的关系，研究结果支持场景主旨识别需要注意参与。正确率和反应时是心理学实验中两种不同的测量指标，AB效应是注意资源在时程上的一种认知局限性，以T1和T2的正确率作为测量指标。心理不应期是另一种证明注意资源有限性的现象，以T1和T2的反应时作为测量指标，未来可以采用心理不应期范式来进一步验证不同水平的场景主旨识别与注意的关系。另外，本研究表明识别基本水平场景主旨绩效显著高于上级水平，未来可采用视觉搜索范式来进一步探究基本水平和上级水平的场景主旨是否对注意产生的不同引导作用。</p></sec></sec><sec id="s7"><title>5. 结论</title><p>在RSVP实验范式中，单任务条件下也出现AB效应，并且识别上级水平的场景主旨产生的AB效应大于基本水平。本研究表明场景主旨识别需要注意的参与，并且识别上级水平的场景主旨对注意的需求量更大。</p></sec><sec id="s8"><title>文章引用</title><p>张志媛,王 华. 场景主旨识别需要注意参与 Scene Gist Perception Necessitates Attention[J]. 心理学进展, 2018, 08(03): 371-378. https://doi.org/10.12677/AP.2018.83046</p></sec><sec id="s9"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.24195-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Chun, M. M., &amp; Potter, M. C. (1995). A Two-Stage Model for Multiple Target Detection in Rapid Serial Visual Presentation. Journal of Experimental Psychology Human Perception &amp; Performance, 21, 109-127.  
&lt;br&gt;https://doi.org/10.1037//0096-1523.21.1.109</mixed-citation></ref><ref id="hanspub.24195-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Cohen, M. A., Alvarez, G. A., &amp; Nakayama, K. (2011). Natu-ral-Scene Perception Requires Attention. Psychological Science, 22, 1165-1172. &lt;br&gt;https://doi.org/10.1177/0956797611419168</mixed-citation></ref><ref id="hanspub.24195-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Evans, K. K., &amp; Treisman, A. (2005). Perception of Objects in Natural Scenes: Is It Really Attention Free? Journal of Experimental Psychology: Human Perception and Performance, 31, 1476-1492. &lt;br&gt;https://doi.org/10.1037/0096-1523.31.6.1476</mixed-citation></ref><ref id="hanspub.24195-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Friedman, A. (1979). Framing Pictures: The Role of Knowledge in Automatized Encoding and Memory for Gist. Journal for Experimental Psychology: General, 108, 316-355. &lt;br&gt;https://doi.org/10.1037/0096-3445.108.3.316</mixed-citation></ref><ref id="hanspub.24195-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Greene, M. R., &amp; Oliva, A. (2009). The Briefest of Glances: The Time Course of Natural Scene Understanding. Psychological Science, 20, 464-472. &lt;br&gt;https://doi.org/10.1111/j.1467-9280.2009.02316.x</mixed-citation></ref><ref id="hanspub.24195-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Greene, M. R., &amp; Oliva, A. (2010). High-Level Aftereffects to Global Scene Properties. Journal of Experimental Psychology: Human Perception and Performance, 36, 1430-1432. &lt;br&gt;https://doi.org/10.1037/a0019058</mixed-citation></ref><ref id="hanspub.24195-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Greene, M. R., &amp; Wolfe, J. M. (2011). Global Image Properties Do Not Guide Visual Search. Journal of Vision, 11, 1-9. 
&lt;br&gt;https://doi.org/10.1167/11.6.18</mixed-citation></ref><ref id="hanspub.24195-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Kirchner, H., &amp; Thorpe, S. J. (2006). Ultra-Rapid Object Detection with Saccadic Eye Movements: Visual Processing Speed Revisited. Vision Research, 46, 1762-1776. &lt;br&gt;https://doi.org/10.1016/j.visres.2005.10.002</mixed-citation></ref><ref id="hanspub.24195-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Li, F. F., VanRullen, R., Koch, C., &amp; Perona, P. (2002). Rapid Natural Scene Categorization in the Near Absence of Attention. Proceedings of the National Academy of Sciences of the United States of America, 99, 9596-9601.  
&lt;br&gt;https://doi.org/10.1073/pnas.092277599</mixed-citation></ref><ref id="hanspub.24195-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Li, F. F., VanRullen, R., Koch, C., &amp; Perona, P. (2005). Why Does Natural Scene Categorization Require Little Attention? Exploring Attentional Requirements for Natural and Synthetic Stimuli. Visual Cognition, 12, 893-924. 
&lt;br&gt;https://doi.org/10.1080/13506280444000571</mixed-citation></ref><ref id="hanspub.24195-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Mack, A., &amp; Clarke, J. (2012). Gist Perception Requires Attention. Visual Cognition, 20, 300-327. 
&lt;br&gt;https://doi.org/10.1080/13506285.2012.666578</mixed-citation></ref><ref id="hanspub.24195-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Marois, R., Yi, D.-J., &amp; Chun, M. M. (2004). The Neural Fate of Perceived and Missed Events in the Attentional Blink. Neuron, 41, 465-472. &lt;br&gt;https://doi.org/10.1016/S0896-6273(04)00012-1</mixed-citation></ref><ref id="hanspub.24195-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Oliva, A., &amp; Torralba, A. (2001). Modeling the Shape of the Scene: A Holistic Representation of the Spatial Envelope. International Journal of Computer Vision, 42, 145-175. &lt;br&gt;https://doi.org/10.1023/A:1011139631724</mixed-citation></ref><ref id="hanspub.24195-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">Potter, M. C. (1976). Short-Term Conceptual Memory for Pictures. Journal of Experimental Psychology: Human Learning and Memory, 2, 509-522. &lt;br&gt;https://doi.org/10.1037/0278-7393.2.5.509</mixed-citation></ref><ref id="hanspub.24195-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">Raymond, J. E., Shapiro, K. L., &amp; Arnell, K. M. (1992). Temporary Suppression of Visual Processing in an RSVP Task: An Attentional Blink ? Journal of Experimental Psychology: Human Perception and Performance, 18, 849-860.  
&lt;br&gt;https://doi.org/10.1037/0096-1523.18.3.849</mixed-citation></ref><ref id="hanspub.24195-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">Rensink, R. A., O’Regan, J. K., &amp; Clark, J. J. (1997). To See or Not to See: The Need for Attention to Perceive Changes in Scenes. Psychological Science, 8, 368-373. &lt;br&gt;https://doi.org/10.1111/j.1467-9280.1997.tb00427.x</mixed-citation></ref><ref id="hanspub.24195-ref17"><label>17</label><mixed-citation publication-type="other" xlink:type="simple">Rosch, E. (1988). Principles of Categorization. Readings in Cognitive Science, 312-322.  
&lt;br&gt;https://doi.org/10.1016/B978-1-4832-1446-7.50028-5</mixed-citation></ref><ref id="hanspub.24195-ref18"><label>18</label><mixed-citation publication-type="other" xlink:type="simple">Thorpe, S. J., Fize, D., &amp; Marlot, C. (1996). Speed of Processing in the Human Visual System. Nature, 381, 520-522. 
&lt;br&gt;https://doi.org/10.1038/381520a0</mixed-citation></ref></ref-list></back></article>