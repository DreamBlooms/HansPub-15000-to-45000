<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">BIPHY</journal-id><journal-title-group><journal-title>Biophysics</journal-title></journal-title-group><issn pub-type="epub">2330-1686</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/BIPHY.2019.72002</article-id><article-id pub-id-type="publisher-id">BIPHY-30667</article-id><article-categories><subj-group subj-group-type="heading"><subject>BIPHY20190200000_15238592.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>数学与物理</subject><subject> 生命科学</subject></subj-group></article-categories><title-group><article-title>
 
 
  应用深度神经网络对多导睡眠图的睡眠分期研究
   Application of Deep Neural Network to Study the Sleep Stage Scoring on the Polysomnography
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>王</surname><given-names>抒伟</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>徐</surname><given-names>富献</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>钱</surname><given-names>镶钰</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>胡</surname><given-names>桓</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>何</surname><given-names>情祖</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>林</surname><given-names>海</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>帅</surname><given-names>建伟</given-names></name><xref ref-type="aff" rid="aff4"><sup>4</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib></contrib-group><aff id="aff4"><addr-line>厦门大学物理科学与技术学院物理系，福建 厦门；厦门大学健康医疗大数据国家研究院，福建 厦门</addr-line></aff><aff id="aff3"><addr-line>厦门中翎易优创科技有限公司，福建 厦门</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><aff id="aff2"><addr-line>厦门大学物理科学与技术学院物理系，福建 厦门</addr-line></aff><pub-date pub-type="epub"><day>06</day><month>06</month><year>2019</year></pub-date><volume>07</volume><issue>02</issue><fpage>11</fpage><lpage>25</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   传统上，自动睡眠分期是一项非常具有挑战性且费时费力的任务。大多数现有的自动睡眠分期方法都基于单通道的脑电(electroencephalography, EEG)数据，然而，这些方法忽略了医师从整体上观测多个通道EEG信号进行睡眠阶段评分的过程。为了解决这一问题，我们优化了数据结构，对医师的评分过程进行了详细的学习与建模，提出了一种基于多通道脑电图的自动睡眠评分方法。我们介绍了在原始EEG与EOG样本上使用深度卷积神经网络(convolutional neural network, CNN)进行睡眠阶段评分的监督学习。该网络具有11层，每30 s的睡眠数据作为一个分期，并且不需要任何信号预处理或特征提取。本文使用来自福建省某医院的EEG与EOG及专家评估的多导睡眠图(polysomnography, PSG)数据对系统进行训练和评估。实验结果表明，在自动睡眠分期的研究中不应该忽略EOG数据。我们的系统性能与中级睡眠分期专家的结果相当。 In the field of medical informatics, the automatic sleep staging is a challenging and time-consuming task, and most existing automatic sleep staging methods are based on single channel electroencephalography (EEG) data. However, these methods ignore the physician’s overall observation of multiple channel EEG and EOG signals for the sleep stage scoring. To resolve this problem, we propose an automatic sleep scoring method based on multi-channel EEG, including three-channel EEG and two-channel Electrooculogram (EOG) data. We introduce the use of a deep convolutional neural network (CNN) on raw EEG samples for supervised learning of sleep stage prediction, which does not require any signal preprocessing or feature extraction. We use the EEG and EOG of polysomnography (PSG) data which have been assessed by medical expert from a Hospital of Fujian Province to train and evaluate our system. Comparing with the staging result with single-channel EEG data, we indicate that the EOG data should not be ignored for a better sleep staging. It shows that the performance of our system is comparable to that of mid-level experts.
    
  
 
</p></abstract><kwd-group><kwd>睡眠分期，多通道，卷积神经网络，脑电图，眼电图,  Sleep Stage Classification</kwd><kwd> Multichannel</kwd><kwd> Convolutional Neural Network</kwd><kwd> EEG</kwd><kwd> EOG</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>应用深度神经网络对多导睡眠图的睡眠分期 研究<sup> </sup></title><p>王抒伟<sup>1</sup>，徐富献<sup>1</sup>，钱镶钰<sup>1</sup>，胡桓<sup>1</sup>，何情祖<sup>1</sup>，林海<sup>2</sup>，帅建伟<sup>1,3*</sup></p><p><sup>1</sup>厦门大学物理科学与技术学院物理系，福建 厦门</p><p><sup>2</sup>厦门中翎易优创科技有限公司，福建 厦门</p><p><sup>3</sup>厦门大学健康医疗大数据国家研究院，福建 厦门</p><disp-formula id="hanspub.30667-formula9"><graphic xlink:href="//html.hanspub.org/file/1-2790057x5_hanspub.png"  xlink:type="simple"/></disp-formula><p>收稿日期：2019年5月16日；录用日期：2019年5月30日；发布日期：2019年6月6日</p><disp-formula id="hanspub.30667-formula10"><graphic xlink:href="//html.hanspub.org/file/1-2790057x6_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>传统上，自动睡眠分期是一项非常具有挑战性且费时费力的任务。大多数现有的自动睡眠分期方法都基于单通道的脑电(electroencephalography, EEG)数据，然而，这些方法忽略了医师从整体上观测多个通道EEG信号进行睡眠阶段评分的过程。为了解决这一问题，我们优化了数据结构，对医师的评分过程进行了详细的学习与建模，提出了一种基于多通道脑电图的自动睡眠评分方法。我们介绍了在原始EEG与EOG样本上使用深度卷积神经网络(convolutional neural network, CNN)进行睡眠阶段评分的监督学习。该网络具有11层，每30 s的睡眠数据作为一个分期，并且不需要任何信号预处理或特征提取。本文使用来自福建省某医院的EEG与EOG及专家评估的多导睡眠图(polysomnography, PSG)数据对系统进行训练和评估。实验结果表明，在自动睡眠分期的研究中不应该忽略EOG数据。我们的系统性能与中级睡眠分期专家的结果相当。</p><p>关键词 :睡眠分期，多通道，卷积神经网络，脑电图，眼电图</p><disp-formula id="hanspub.30667-formula11"><graphic xlink:href="//html.hanspub.org/file/1-2790057x7_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2019 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/1-2790057x8_hanspub.png" /> <img src="//html.hanspub.org/file/1-2790057x9_hanspub.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>人类大约三分之一的时间都被用来睡觉。睡眠对人类的健康来说是极其重要的。与睡眠有关的疾病，如睡眠呼吸暂停、失眠、阵发性发作性睡病，严重影响人类的生活质量。最近的研究表明，睡眠/昼夜节律紊乱可能是阿尔茨海默病和帕金森病等神经退行性疾病的重要标志，睡眠病理的治疗可以改善患者的生活质量 [<xref ref-type="bibr" rid="hanspub.30667-ref1">1</xref>]。</p><p>根据美国睡眠医学会(American Academy of Sleep Medicine, AASM)的睡眠分期标准 [<xref ref-type="bibr" rid="hanspub.30667-ref2">2</xref>]，人类睡眠是一个动态过程，可分为清醒期(Awake, W)，快速眼动期(rapid eye movement, REM)和非快速眼动期(non-rapid eye movement, NREM)三个主要期。通常，睡眠专家使用多导睡眠图(Polysomnographic, PSG)进行睡眠阶段分期的临床诊断。PSG包含一组信号，例如脑电图(Electroencephalogram, EEG)，肌电图(Electromyogram, EMG)，心电图(Electrocardiogram, ECG)和眼电图(Electrooculogram, EOG)等。这些信号是通过连接到身体不同部位的传感器记录下来的。PSG录音一般分为20秒或30秒的样本，睡眠专家或医生将根据美国睡眠医学会睡眠分期标准，把这些样本分为不同的睡眠期，该过程被称为睡眠阶段评分或睡眠分期。</p><p>睡眠多导图是睡眠质量的简单表示，可用于诊断睡眠障碍。此外，睡眠分期的质量取决于医师的经验和疲劳程度，睡眠专家分期的准确度通常不到90% [<xref ref-type="bibr" rid="hanspub.30667-ref3">3</xref>] [<xref ref-type="bibr" rid="hanspub.30667-ref4">4</xref>]，且人工标记PSG数据需要耗费大量的时间，因此迫切需要自动睡眠分期算法。</p><p>在传统统计学习方法中，有许多研究者一直试图开发一种基于EEG、EOG和EMG等多种信号 [<xref ref-type="bibr" rid="hanspub.30667-ref5">5</xref>] [<xref ref-type="bibr" rid="hanspub.30667-ref6">6</xref>] [<xref ref-type="bibr" rid="hanspub.30667-ref7">7</xref>]，或单通道脑电图 [<xref ref-type="bibr" rid="hanspub.30667-ref8">8</xref>] [<xref ref-type="bibr" rid="hanspub.30667-ref9">9</xref>] 的自动化睡眠阶段分期的方法。这些方法首先从每个记录样本时期提取时域、频域和时频域特征。在多个信号的情况下，把来自一个时期的所有特征连接成一个特征向量。然后，这些特征用于训练分类器被用于识别单个样本的睡眠阶段分期。由于受试者和记录硬件之间的非均衡异质性，这些网络是根据研究所使用数据集的特征而进行手工设计的，我们认为这些方法并不具有广泛的应用价值。</p><p>近年来，深度学习已经被用于睡眠阶段分期，深度学习利用多层线性和非线性处理单元学习来自输入数据的分层表示或特征。其中，卷积神经网络被用于短脑电时间序列数据，例如脑计算机接口 [<xref ref-type="bibr" rid="hanspub.30667-ref10">10</xref>] [<xref ref-type="bibr" rid="hanspub.30667-ref11">11</xref>]，癫痫发作检测 [<xref ref-type="bibr" rid="hanspub.30667-ref12">12</xref>]，驾驶员的认知表现 [<xref ref-type="bibr" rid="hanspub.30667-ref13">13</xref>] 和眼动追踪 [<xref ref-type="bibr" rid="hanspub.30667-ref14">14</xref>] 以及睡眠分期 [<xref ref-type="bibr" rid="hanspub.30667-ref15">15</xref>] [<xref ref-type="bibr" rid="hanspub.30667-ref16">16</xref>]。CNN已经在其他领域用于原始连续信号，从图像识别开始 [<xref ref-type="bibr" rid="hanspub.30667-ref17">17</xref>] [<xref ref-type="bibr" rid="hanspub.30667-ref18">18</xref>]，到许多其他领域，如自然语言处理 [<xref ref-type="bibr" rid="hanspub.30667-ref19">19</xref>]，推荐系统 [<xref ref-type="bibr" rid="hanspub.30667-ref20">20</xref>] 和其他监督模式识别任务。</p><p>一般来说，神经网络模型的发展源于双重目标：第一，更好地理解神经系统；第二，尝试构建生物功能启发的信息处理系统。虽然在某些领域计算机能够比人脑执行处理的更有效，但计算机无法与大脑相提并论。现阶段大多数网络结构并没有提供任何可以被用于建模系统的信息 [<xref ref-type="bibr" rid="hanspub.30667-ref21">21</xref>]，它没有考虑原始系统的物理组织。神经网络的一个优点是它表现为非线性黑箱，几乎可以建模和描述任何非线性动态。就传统统计学而言，神经网络常常被认为是不可识别的模型，在某种意义上可以获得具有不同拓扑和参数的各种网络。与传统的数据分析方法相比，它们在解决现实问题方面具有很强的竞争力。</p><p>作为深度学习的一种 [<xref ref-type="bibr" rid="hanspub.30667-ref17">17</xref>]，CNN是一种可训练的多层非线性系统，旨在从图像中提取和分类高维模式。CNN本质上是具有特殊拓扑结构的多层感知器(Multi-Layer Perceptron, MLP)，它包含多个隐藏层 [<xref ref-type="bibr" rid="hanspub.30667-ref10">10</xref>]。CNN已经成功应用于原始EEG数据 [<xref ref-type="bibr" rid="hanspub.30667-ref22">22</xref>]，对象识别 [<xref ref-type="bibr" rid="hanspub.30667-ref23">23</xref>] 和手写字符识别 [<xref ref-type="bibr" rid="hanspub.30667-ref17">17</xref>]，如分析视觉图像 [<xref ref-type="bibr" rid="hanspub.30667-ref24">24</xref>]，语音识别和预测人流量等。CNN具有共享权重架构和转换不变性的特征。CNN由输入和输出层以及多个隐藏层组成。隐藏层可以是卷积层、池化层或全连接层。与其他传统算法相比，CNN使用相对较少的预处理。这意味着CNN网络可以学习传统算法中人工设计的滤波器。其主要优点便是可以代替先验知识和人工设计特征工程。</p><p>循环神经网络(Recurrent Neural Networks, RNN)让神经网络有了记忆，对于序列化的数据，循环神经网络能达到更好的效果。由于RNN容易出现梯度爆炸，不易训练的缺点，RNN发展出了许多变种，其中长短期记忆网络(Long Short-Term Memory, LSTM)网络是一种循环神经网络特殊的类型，可以学习长期依赖信息。LSTM由Hochreiter &amp; Schmidhuber (1997)提出，并在近期被Alex Graves进行了改良和推广。</p><p>在 [<xref ref-type="bibr" rid="hanspub.30667-ref25">25</xref>] 中，L&#228;ngkvist等人提出了第一个基于深度学习的睡眠分期系统；在 [<xref ref-type="bibr" rid="hanspub.30667-ref26">26</xref>] 中，Ronan Collobert提出了一种端到端深度学习方法，它采用多变量睡眠信号(即EEG，EOG和EMG)进行时间睡眠阶段分期。随着可穿戴设备的快速发展和EEG信号采集设备的发展，例如，Supratak等 [<xref ref-type="bibr" rid="hanspub.30667-ref16">16</xref>] 提出DeepSleepNet，该模型基于原始睡眠EEG信号，包含两个不同的CNN来提取时不变特征，一个双向长短期记忆(Long Short-Term Memory, LSTM)用于序列残差学习 [<xref ref-type="bibr" rid="hanspub.30667-ref27">27</xref>]。然而这些工作都忽略了睡眠专家的分期过程，睡眠专家是通过经验和AASM规则从整体上观测多个通道EEG信号进行睡眠阶段分期。</p><p>在本文中，我们介绍了一种使用深度监督卷积神经网络(CNN)对原始信号样本进行的睡眠分期的方法。实验目标是利用深度学习的特征提取功能代替手动特征提取工作。这项工作的主要贡献如下：1) 构建了一个基于卷积神经网络的睡眠评分系统；2) 网络端到端训练，并在原始脑电图上学习特征检测；3) 系统在大型数据集上进行评估，保证了训练的模型能够得到良好的推广应用。</p></sec><sec id="s4"><title>2. 数据与方法</title><p>此次实验所用的数据是通过Alice Sleepware G3软件添加Alice5设备进行采集的。Alice Sleepware G3软件是飞利浦公司专门为Alice系列多导睡眠检测仪设计的软件。Alice Sleepware G3软件可以直接对釆集的各种指标数据进行展示，之后对采集到的数据每30 s应用—次的睡眠自动分期。然后专家依据Alice Sleepware G3编辑界面观察各个通道的生理信号，对错误的分期进行排查，并对分错的进行手动标记矫正，分期结果以专家手工校正为准，最终得到睡眠结构图。</p><sec id="s4_1"><title>2.1. 数据及预处理</title><p>本文采用的数据集来自于福建省某睡眠中心医院以及公开的Physionet Sleep-EDFx数据库 [<xref ref-type="bibr" rid="hanspub.30667-ref28">28</xref>]，睡眠中心医院使用飞利浦Alice 5多导睡眠监测仪来进行实验。实验前对来睡眠监测中心的患者进行简单编号并要求每一名患者填写问卷调查。问卷主要内容包括患者身高、体重、颈围、血压和心率以及医嘱现病史、既往病史、家族史、用药情况等。数据是通过Alice Sleepware G3软件添加Alice5设备进行采集。随机挑选114名患者的数据，这些患者没有服用任何睡眠相关的药物。我们对这些患者使用Alice5设备以200 Hz采样率进行一整夜的睡眠采用。经统计患者的睡眠时间为8~10小时。需要说明的是，福建省某睡眠中心医院所有的数据都采集自有睡眠障碍的患者。</p><p>图1. EEG波形特征示例</p><p>图1展示了本次实验使用的两种不同期EEG波形示例，分别为公开数据以及睡眠中心医院数据集。根据Amaud Sors的研究表明，“可用的EEG通道是对称的，因此它们具有相当的性能” [<xref ref-type="bibr" rid="hanspub.30667-ref29">29</xref>]。然而这个工作忽略了睡眠专家的分期过程，睡眠专家通过经验和AASM规则，从整体上观测多个通道EEG信号进行睡眠阶段分期。因此，在下文中也采用EEG-F3-A2，EEG-C3-A2，EEG-O1-A2通道，以及眼电信号采用EOG-left与EOG-Right等多个通道来执行自动睡眠阶段分期任务。每个受试者的整个EEG信号被分成30秒的样本数据(每个样本包含6000个数据点)。每个时期被标记为W，N1，N2，N3，REM和未分期(未记录的时期在每次记录的开始或结束时)，由睡眠专家进行分期。在本研究中，占比较少的REM和未分期的时期已经被删除。</p><p>图2. 睡眠时期的数量</p><p>某些特殊的睡眠样本例如含有12个小时的清醒期样本以及睡眠时长达到25小时的样本等，没有被包含到实验数据中，同时，通过专业睡眠专家的筛选，极少数患者被排除在外，因为它们可能是异常值。从图2可以明显看出不同期的数据分布不平衡，因此，我们对N1期的数据做了数据增强，提取全部N1期数据拼接成总长度为81 h的数据，然后去除数据前10 s，再重新以30 s逐一切割，从而减少数据不平衡带来的误差。因为这样错位10 s的数据，既可以实现数据增强，又可以实现数据的多样性。从以上工作来看没有对EEG信号本身进行额外的预处理。</p></sec><sec id="s4_2"><title>2.2. 网络结构</title><p>对于CNN架构的选择尝试了两种结构，一种是是现有的主流EEG分期模型，这类模型是使用单通道EEG数据进行分期的结构；另外一种是本文提出的新分期模型，使用多通道EEG与EOG进行分期，下文将主要以此模型的结果进行分析和讨论。</p><sec id="s4_2_1"><title>2.2.1. 基于单通道EEG的模型A</title><p>首先介绍基于单通道EEG的模型结构：这一部分，我们构建了基于卷积神经网络与循环神经网络的自动睡眠阶段分期模型A。</p><p>为了更好的模拟睡眠专家的分期过程，CNN的输入包括分类的时期未处理的EEG信号与EOG信号，以一个数字矩阵作为输入。模型训练好之后，如果当前要预测的样本信号为不确定的情况下，模型中表现为该期的分期概率值小于等于0.25，偶尔会引用下一个和前一个样本的分期结果。</p><p>图3给出了该网络结构的基本视图，展示了基于EEG信号的卷积神经网络的自动睡眠阶段分期模型。该模型的输入是一个30 s的采样率为200 Hz的EEG信号，每个信号包含30 &#215; 200个数据，表示为1 &#215; 6000的矩阵。其中1代表采用1个通道的数据，6000代表一个通道的数据量。实验采用F3-A2通道的EEG，每个EEG样本信号按顺序由输入层，Cov1，dropout，Cov2，Pool1，Cov3，dropout，Pool2，FC1，dropout，FC2，dropout和输出也即属于每个睡眠期的概率组成。需要说明的是，为了加快网络的训练，测试阶段采用8个人的样本数据。当网络准确率达到75%时，找到了合适的参数区间后采用39人数据样本，总的期数达到41,000。</p><p>图3. 基于单通道EEG模型B的网络结构</p></sec><sec id="s4_2_2"><title>2.2.2. 基于多通道EEG与EOG的模型B</title><p>以下是基于多通道EEG与EOG的模型结构：在这一部分中，我们构建了基于卷积神经网络的自动睡眠阶段分期模型B。</p><p>模型B采用4个二维卷积层，激活函数采用线性整流函数(Rectified Linear Unit, ReLU)，每个二维卷积层紧接着采用了dropout避免过拟合的方法，都以20%的几率使得神经元会被关闭或丢弃。每个卷积层后都接一个最大池化层。紧接着是两个全连接层，第一个全连接层有4096个单元，另一个全连接层有1500个单元，这两个全连接层也采用了dropout避免过拟合的方法，都以50%的几率使得神经元会被关闭/丢弃。最后是一个大小为5的全连接层，激活函数采用Relu，卷积层的激活函数都用的是Relu，负斜率为0。</p><p>图4展示了基于EEG信号的卷积神经网络的自动睡眠阶段分期模型，网络的输入为一个30 s的采样率为200 Hz的EEG信号，它以5 &#215; 6000的矩阵形式表示。其中5代表采用了5个通道的数据，模型B采用F3-A2，C3-A2，O1-A2通道的EEG以及Left EOG，Right EOG，每个EEG样本信号按顺序由输入层，Cov，dropout，Pool交替搭建，直到FC1与FC2和输出。测试阶段采用8个人的样本数据，当网络准确率达到75%时，找到了合适的参数区间采用114人数据样本，图2显示了各个期的数量分布。</p><p>图4. 基于多通道数据模型B的体系结构</p></sec></sec><sec id="s4_3"><title>2.3. 模型评估与优化</title><p>本文的前半部分，详细介绍了本研究中使用的数据结构和模型设计。表1显示了本研究中使用的样本数。为了评估模型的性能，实验使用了K-fold交叉验证方法 [<xref ref-type="bibr" rid="hanspub.30667-ref30">30</xref>]，K设置为5，也即5折交叉验证。我们将所有类型的睡眠期EEG信号以及EOG数据划分为测试集和训练集。在本文中，K被设置为5，具体来说，随机选择所有数据集的20%作为测试集，其余作为每个训练期间的训练集。一般使用反向传播算法就可以直接得到梯度，但是对于模型B，此优化方法结果并不是很好。为了优化，用了Adam [<xref ref-type="bibr" rid="hanspub.30667-ref31">31</xref>] 优化方法。模型B还采用了随机梯度下降Stochastic Gradient Descent (SGD)，SGD因为更新比较频繁，会造成损失函数有剧烈的震荡，最终停留在局部最小或者Saddle Point，也即鞍点处。所以模型B采用Adamwith Momentum梯度更新方法，引入moment可以避免落入局部最优解最终可以加快收敛的同时减小震荡。</p><p>在固定长度的时间序列上使用CNN时，卷积部分的输出大小直接与输入大小、卷积层数和它们的步幅有关。如果最后一个卷积层的输出太大，则绝多大数权重将位于全连接层中。我们试验了6~12层，步长为2~10，还尝试了7号，5号和3号大小的卷积核，最终选择了3号和5号卷积核，尽管5到7之间的性能差异很小。经过各种功能配置的测试，模型B保留了前四层的128个特征图和256个特征图，以及最后两层卷积的512个特征图。最后，在网络架构中，使用3号和5号卷积核组合是一个很好的折衷。除此之外，还采用批训练的方法来加快训练过程。实验过程中尝试了16、64、128、256批次的训练。结果显示，当批次为128时效果最好。</p><p>最后要说明的是，本实验的代码使用python (Python 3.6.6)语言和Pytorch (Pytorch 0.4.1)深度学习框架。为了加速模型的训练，模型在Pytorch中实施，并在Nvidia GTX1060的GPU上进行模拟训练。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> The specific params of our CNN model based on multi-channel dat</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >层级</th><th align="center" valign="middle" >层类</th><th align="center" valign="middle" >卷积核数量</th><th align="center" valign="middle" >激活函数</th><th align="center" valign="middle" >大小</th><th align="center" valign="middle" >Dropout率</th><th align="center" valign="middle" >步长</th><th align="center" valign="middle" >边缘填充</th></tr></thead><tr><td align="center" valign="middle" >Input</td><td align="center" valign="middle" >EEG &amp; EOG matrix</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" >(1, 5, 6000)</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td></tr><tr><td align="center" valign="middle" >Cov1</td><td align="center" valign="middle" >Convolutional</td><td align="center" valign="middle" >128</td><td align="center" valign="middle" >Relu</td><td align="center" valign="middle" >(3, 50)</td><td align="center" valign="middle" >Dropout-0.2</td><td align="center" valign="middle" >(1, 10)</td><td align="center" valign="middle" >(1, 1)</td></tr><tr><td align="center" valign="middle" >Pool1</td><td align="center" valign="middle" >Max-Pooling</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" >(2, 2)</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >(2, 2)</td><td align="center" valign="middle" >(0, 0)</td></tr><tr><td align="center" valign="middle" >Cov2</td><td align="center" valign="middle" >Convolutional</td><td align="center" valign="middle" >256</td><td align="center" valign="middle" >Relu</td><td align="center" valign="middle" >(3, 5)</td><td align="center" valign="middle" >Dropout-0.2</td><td align="center" valign="middle" >(1, 1)</td><td align="center" valign="middle" >(1, 1)</td></tr><tr><td align="center" valign="middle" >Pool2</td><td align="center" valign="middle" >Max-Pooling</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" >(2, 2)</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >(2, 2)</td><td align="center" valign="middle" >(0, 0)</td></tr><tr><td align="center" valign="middle" >Cov3</td><td align="center" valign="middle" >Convolutional</td><td align="center" valign="middle" >512</td><td align="center" valign="middle" >Relu</td><td align="center" valign="middle" >(3, 5)</td><td align="center" valign="middle" >Dropout-0.2</td><td align="center" valign="middle" >(1, 1)</td><td align="center" valign="middle" >(1, 1)</td></tr><tr><td align="center" valign="middle" >Pool3</td><td align="center" valign="middle" >Max-Pooling</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" >(1, 2)</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >(1, 2)</td><td align="center" valign="middle" >(0, 0)</td></tr><tr><td align="center" valign="middle" >Cov4</td><td align="center" valign="middle" >Convolutional</td><td align="center" valign="middle" >512</td><td align="center" valign="middle" >Relu</td><td align="center" valign="middle" >(3, 5)</td><td align="center" valign="middle" >Dropout-0.2</td><td align="center" valign="middle" >(2, 2)</td><td align="center" valign="middle" >(1, 1)</td></tr><tr><td align="center" valign="middle" >Pool4</td><td align="center" valign="middle" >Max-Pooling</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" >(1, 2)</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >(1, 2)</td><td align="center" valign="middle" >(0, 0)</td></tr><tr><td align="center" valign="middle" >Fc1</td><td align="center" valign="middle" >Fully-Connected</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >Relu</td><td align="center" valign="middle" >(4096)</td><td align="center" valign="middle" >Dropout-0.5</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td></tr><tr><td align="center" valign="middle" >Fc2</td><td align="center" valign="middle" >Fully-Connected</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >Relu</td><td align="center" valign="middle" >(1500)</td><td align="center" valign="middle" >Dropout-0.5</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td></tr><tr><td align="center" valign="middle" >Output</td><td align="center" valign="middle" >Sleep Stage</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td></tr></tbody></table></table-wrap><p>表1. 基于多通道数据的卷积神经网络模型参数</p></sec></sec><sec id="s5"><title>3. 结果</title><p>我们使用召回(Recall, REC)，准确率(Precision，PRE)和F1值(F1-Score，F1)以及总体准确度(accuracy, ACC)来评估模型A与模型B的分类表现。其中准确率PRE表示被模型预测为正例的样本中实际也是正例的比例；召回率REC，又称查全率，是一种覆盖面的衡量标准，表示样本中的正例有多少被预测正确。其中指数MF1指的是每个睡眠期的所有F1的平均值。ACC表示正确数量的睡眠阶段时期分类与所有睡眠阶段时期的比例。REC，PRE，F1值，ACC与MF1的计算方法分别如下：</p><p>P R E = T P T P + F P , R E C = T P T P + F N (1)</p><p>F 1 = 2 P R E * R E C P R E + R E C (2)</p><p>A C C = ∑ c = 1 C T P c N (3)</p><p>M F 1 = ∑ c = 1 C F 1 c C (4)</p><p>其中方程3.3中的 是每个类中被预测为正确的数量，F1<sub>c</sub>是某一类的F1分数，C是睡眠分期的数量，N是所有的30秒样本数量。TP是真阳性，FN是假阴性和FP是假阳性。</p><sec id="s5_1"><title>3.1. 基于单通道EEG的模型结果</title><p>在单通道模型中，时长为30秒的EEG信号样本总数是41,000，实验使用5折交叉验证方法来评估模型的性能。因此，取出总样本的20%作为测试集，这些样本没有参与模型的训练，只作为测试集。在下面的内容中，表2显示模型在每个实验中的测试集的平均性能。</p><p>表2显示了使用模型A从睡眠期的单通道EEG信号的实验获得的混淆矩阵。该实验的总体准确度ACC为79.92%。在表2中，每行和每列分别表示由睡眠专家判断并通过模型A预测的30秒EEG信号和EOG信号的睡眠分期的数量。</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> Confusion matrix obtained from experiment on single channel EEG signals using our mode</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" >W</th><th align="center" valign="middle" >N1</th><th align="center" valign="middle" >N2</th><th align="center" valign="middle" >N3</th><th align="center" valign="middle" >REM</th><th align="center" valign="middle" >PRE</th><th align="center" valign="middle" >REC</th><th align="center" valign="middle" >F1</th></tr></thead><tr><td align="center" valign="middle" >W</td><td align="center" valign="middle" >6601</td><td align="center" valign="middle" >728</td><td align="center" valign="middle" >373</td><td align="center" valign="middle" >74</td><td align="center" valign="middle" >391</td><td align="center" valign="middle" >0.871</td><td align="center" valign="middle" >0.808</td><td align="center" valign="middle" >0.838</td></tr><tr><td align="center" valign="middle" >N1</td><td align="center" valign="middle" >292</td><td align="center" valign="middle" >1399</td><td align="center" valign="middle" >829</td><td align="center" valign="middle" >27</td><td align="center" valign="middle" >539</td><td align="center" valign="middle" >0.454</td><td align="center" valign="middle" >0.453</td><td align="center" valign="middle" >0.454</td></tr><tr><td align="center" valign="middle" >N2</td><td align="center" valign="middle" >311</td><td align="center" valign="middle" >498</td><td align="center" valign="middle" >13362</td><td align="center" valign="middle" >1353</td><td align="center" valign="middle" >676</td><td align="center" valign="middle" >0.853</td><td align="center" valign="middle" >0.825</td><td align="center" valign="middle" >0.839</td></tr><tr><td align="center" valign="middle" >N3</td><td align="center" valign="middle" >28</td><td align="center" valign="middle" >8</td><td align="center" valign="middle" >490</td><td align="center" valign="middle" >5362</td><td align="center" valign="middle" >202</td><td align="center" valign="middle" >0.786</td><td align="center" valign="middle" >0.880</td><td align="center" valign="middle" >0.831</td></tr><tr><td align="center" valign="middle" >REM</td><td align="center" valign="middle" >350</td><td align="center" valign="middle" >447</td><td align="center" valign="middle" >609</td><td align="center" valign="middle" >6</td><td align="center" valign="middle" >6045</td><td align="center" valign="middle" >0.770</td><td align="center" valign="middle" >0.811</td><td align="center" valign="middle" >0.790</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle"  colspan="8"  >ACC = 79.92%，MF1 =74.99%</td></tr></tbody></table></table-wrap><p>表2. 使用基于单通道EEG的模型获得的混淆矩阵</p><p>为了评估模型A的性能，模型结果与几种现有方法的结果进行比较。需要说明的是这些方法都是采用Fpz-Cz通道EEG数据。我们应用这些现有方法，因为它们的结果也基于模型A在本研究中使用的数据集，即福建省某睡眠中心医院数据集，表3列出了比较结果。根据表3，对于相同数据集，模型A达到了最佳性能参考的准确性。</p><table-wrap id="table3" ><label><xref ref-type="table" rid="table3">Table 3</xref></label><caption><title> Accuracy comparison matrix with other metho</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >模型</th><th align="center" valign="middle" >作者</th><th align="center" valign="middle" >方法</th><th align="center" valign="middle" >基于公开数据集PhysioNet准确率</th><th align="center" valign="middle" >基于福建省某医院睡眠中心数据准确率</th></tr></thead><tr><td align="center" valign="middle" >模型1</td><td align="center" valign="middle" >Akara Supratak (2017) [<xref ref-type="bibr" rid="hanspub.30667-ref16">16</xref>]</td><td align="center" valign="middle" >CNN and LSTM</td><td align="center" valign="middle" >81.50%</td><td align="center" valign="middle" >70.52%</td></tr><tr><td align="center" valign="middle" >模型2</td><td align="center" valign="middle" >Liangjie We (2017) [<xref ref-type="bibr" rid="hanspub.30667-ref32">32</xref>]</td><td align="center" valign="middle" >Time-Frequency CNN</td><td align="center" valign="middle" >82.86%</td><td align="center" valign="middle" >72.60%</td></tr><tr><td align="center" valign="middle" >模型A</td><td align="center" valign="middle" >Wang and Xu et al.</td><td align="center" valign="middle" >Based the multi-channels EEG and CNN</td><td align="center" valign="middle" >79.23%</td><td align="center" valign="middle" >79.92%</td></tr></tbody></table></table-wrap><p>表3. 与其他方法的精度比较矩阵</p><p>模型A比其他的单通道模型具有更好的性能，尽管它们都具有良好的性能，图5显示出了由睡眠专家分期的其中一位受试者一整夜的多导睡眠图的比较，即睡眠专家分期结果与模型A的结果对比。可以看出模型A是最优的，相对来说，对于福建省某睡眠中心医院数据集，模型2的分期结果是最差的。</p><p>图5. 睡眠专家分期的睡眠结构图和我们提出的模型A的结果比较</p><p>从表3来看，基于公开数据集模型1与模型2具有很好的性能，而当我们应用这两个模型测试于福建省某医院睡眠中心数据集时，发现模型A优于这两个模型，说明这些模型的泛化能力还是不足，依旧有很大的提升空间。反观模型A应用于福建省某医院睡眠中心数据集时却有更好的表现，相对来说有很强泛化能力。分析原因不乏有模型1与模型2本身是以健康人群的数据为训练数据，而模型A是以福建省某医院睡眠中心数据为训练数据，是采集自有睡眠障碍患者的数据集，具有很大的多样性，直观上可以从图5看出。接下来我们将主要对多通道模型B的结果进行分析与讨论。</p></sec><sec id="s5_2"><title>3.2. 基于多通道EEG与EOG的模型结果</title><p>由图2可见，睡眠期30秒EEG信号样本的总数是130130，实验使用5折交叉验证来评估模型的性能。因此，取出总样本的20%作为测试集，这些样本没有参与模型B的训练，只作为测试集。下面的内容将显示模型B在每个实验中的测试集的平均性能。表4显示了使用模型B在多通道EEG和EOG信号的实验获得的混淆矩阵。总体上来看，该实验的总体准确度ACC为81.93%。</p><table-wrap id="table4" ><label><xref ref-type="table" rid="table4">Table 4</xref></label><caption><title> Confusion matrix obtained from experiment on multi-channel EEG signals using our proposed mode</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" >W</th><th align="center" valign="middle" >N1</th><th align="center" valign="middle" >N2</th><th align="center" valign="middle" >N3</th><th align="center" valign="middle" >REM</th><th align="center" valign="middle" >PRE</th><th align="center" valign="middle" >REC</th><th align="center" valign="middle" >F1</th></tr></thead><tr><td align="center" valign="middle" >W</td><td align="center" valign="middle" >58875</td><td align="center" valign="middle" >2562</td><td align="center" valign="middle" >508</td><td align="center" valign="middle" >68</td><td align="center" valign="middle" >121</td><td align="center" valign="middle" >0.922</td><td align="center" valign="middle" >0.948</td><td align="center" valign="middle" >0.935</td></tr><tr><td align="center" valign="middle" >N1</td><td align="center" valign="middle" >2963</td><td align="center" valign="middle" >3962</td><td align="center" valign="middle" >3602</td><td align="center" valign="middle" >39</td><td align="center" valign="middle" >772</td><td align="center" valign="middle" >0.407</td><td align="center" valign="middle" >0.349</td><td align="center" valign="middle" >0.376</td></tr><tr><td align="center" valign="middle" >N2</td><td align="center" valign="middle" >935</td><td align="center" valign="middle" >1655</td><td align="center" valign="middle" >33600</td><td align="center" valign="middle" >1204</td><td align="center" valign="middle" >852</td><td align="center" valign="middle" >0.777</td><td align="center" valign="middle" >0.879</td><td align="center" valign="middle" >0.852</td></tr><tr><td align="center" valign="middle" >N3</td><td align="center" valign="middle" >95</td><td align="center" valign="middle" >51</td><td align="center" valign="middle" >2646</td><td align="center" valign="middle" >4299</td><td align="center" valign="middle" >50</td><td align="center" valign="middle" >0.763</td><td align="center" valign="middle" >0.602</td><td align="center" valign="middle" >0.673</td></tr><tr><td align="center" valign="middle" >REM</td><td align="center" valign="middle" >965</td><td align="center" valign="middle" >1503</td><td align="center" valign="middle" >2885</td><td align="center" valign="middle" >28</td><td align="center" valign="middle" >5863</td><td align="center" valign="middle" >0.766</td><td align="center" valign="middle" >0.521</td><td align="center" valign="middle" >0.620</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle"  colspan="8"  >ACC = 81.93%；MF1 =68.60%</td></tr></tbody></table></table-wrap><p>表4. 使用基于多通道信号的CNN模型获得的混淆矩阵</p><p>正如表4所示，模型B的ACC达到了更高的值，表明模型B具有良好的性能。实验中最显著的结果是W，N2和N3的睡眠期具有优异的分类性能。例如，W期分类的准确率接近92%，N2和N3期接近77%。模型B在期REM上的表现略差，但其REC仍然超过76%。可以看出，N1期具有最差的分类性能，因为N1期主要被错误地分类为W期和N2期。从各个期的特征波来看，原因可能是背景EEG波与三个睡眠期非常相似。另一个原因可能是缺乏N1期的样本，平均每一个人的整夜睡眠中，仅有大约70个30秒的EEG信号属于N1期，五个期的分布不均可能导致使用CNN模型的N1期的分类结果差。因此，我们对N1期的数据做了数据增强，提取全部N1期数据拼接成总长度为81 h的数据，然后去除数据前10 s，再重新以30 s逐一切割，从而减少数据不平衡带来的误差。因为这样错位10 s的数据，既可以实现数据增强，又可以实现数据的多样性。从以上工作来看，没有对EEG信号本身进行额外的预处理。</p><table-wrap id="table5" ><label><xref ref-type="table" rid="table5">Table 5</xref></label><caption><title> Accuracy comparison matrix with other metho</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >模型</th><th align="center" valign="middle" >作者</th><th align="center" valign="middle" >方法</th><th align="center" valign="middle" >基于公开数据集PhysioNet准确率</th><th align="center" valign="middle" >基于福建省某医院睡眠中心数据准确率</th></tr></thead><tr><td align="center" valign="middle" >模型-3</td><td align="center" valign="middle" >Fraiwan. et al.(2015) [<xref ref-type="bibr" rid="hanspub.30667-ref33">33</xref>]</td><td align="center" valign="middle" >Based on time-frequency analysis of and random forest classifier</td><td align="center" valign="middle" >79.23%</td><td align="center" valign="middle" >70.45%</td></tr><tr><td align="center" valign="middle" >模型-4</td><td align="center" valign="middle" >Orestis Tsinalis, et al. (2016) [<xref ref-type="bibr" rid="hanspub.30667-ref34">34</xref>]</td><td align="center" valign="middle" >Using Convolutional Neural Networks</td><td align="center" valign="middle" >74.00%</td><td align="center" valign="middle" >63.850%</td></tr><tr><td align="center" valign="middle" >模型-B</td><td align="center" valign="middle" >Wang and Xu et al.</td><td align="center" valign="middle" >Based the multi-channels EEG and CNN</td><td align="center" valign="middle" >80.05%</td><td align="center" valign="middle" >81.93%</td></tr></tbody></table></table-wrap><p>表5. 与其他方法的精度比较矩阵</p><p>为了评估模型B的性能，我们与几种现有方法进行了比较。因为它们的结果也基于模型B在本研究中使用的数据集，即福建省某医院睡眠中心的数据集。表5列出了比较结果，由表5可见，模型B达到了最佳性能，并且有着优于模型3与模型4的分期准确率。可以将这两个模型应用于更多可用数据集，并将结果与这些模型进行比较，以显示模型B的泛化能力。从结果中可以看出，我们的多通道EEG和EOG模型在福建省某医院睡眠中心数据集是优于现有的多通道模型方法。由于模型使用的数据是有睡眠障碍患者的数据，这说明模型B泛化能力显然高于公开数据集的模型。</p><p>虽然模型3与模型4都具有良好的性能，模型B比模型3与模型4具有更好的性能，图6显示出了由睡眠专家分期的代表性样本的一整夜的多导睡眠图PSG的比较，即睡眠专家分期结果与模型B的结果对比。从不同模型的分期结果来看，模型B有着显著的优势。模型B与原标签基本一致，错误的部分大多数为清醒期与N1期，N3期与N4期的错误分类其次。</p><p>图6. 睡眠专家分期的睡眠结构图和我们提出的模型B以及文献方法结果比较</p></sec></sec><sec id="s6"><title>4. 结论</title><p>这项研究表明，使用多通道EEG和EOG，使用卷积神经网络对睡眠阶段分期进行分类是可行的，在自动睡眠分期的研究中不应该忽略EOG数据，我们的系统性能与中级睡眠人类分期专家的性能结果相当。训练是端到端的，无需任何专业知识选择或任何信号预处理是一个优势。因为神经网络可以自主学习各个期的特征，最适合分类任务的功能。</p><p>从卷积网络的特征来看，卷积层已经能够学习出优秀的过滤器。另一个优点是该方法更易于适应另一种应用或者类似的医学序列数据。关于睡眠专家产生的误差，我们注意到误差主要对应于睡眠周期中连续的期。例如，N3期最常与N2期混淆，几乎从不与N1混淆。类似的，N1期虽然被称为人类医师分歧最小的期，但它们会被误分为Wake，N2或REM，因为这些期都可以包含类似于N1期的特征。</p><p>作为睡眠阶段分期的数据集，从图2可以看出我们的数据集的类别分布是不平衡的，需要进一步研究以解决类别不平衡问题。集成学习 [<xref ref-type="bibr" rid="hanspub.30667-ref35">35</xref>] 或人工平衡 [<xref ref-type="bibr" rid="hanspub.30667-ref36">36</xref>] 是比较合适的。</p><p>表3与表5分别显示了近期单通道和多通道睡眠图睡眠分期研究的一些特征和性能指标。睡眠分期的研究是具有挑战性的，因为它们并非都使用相同的数据库、样本数量和分期规则，并且它们并非都以相同的方式平衡类别。例如，Physionet Sleep-EDFx数据库 [<xref ref-type="bibr" rid="hanspub.30667-ref28">28</xref>] 有比任何其他睡眠阶段更多的清醒期，因为此数据库保留了夜晚前后数小时的清醒期的记录。</p><p>在本文中，我们提出了一种基于深度卷积神经网络的多通道EEG信号的自动睡眠分期的方法。将CNN应用于脑电信号以及眼电信号的分类，可以把EEG时间序列信号和EOG时间序列信号转换为有意义的数据矩阵，类似于图的CNN可以处理的格式。睡眠分期结果表明，我们提出的方法比其他现有方法获得更好的睡眠阶段分期性能，并且对不同类型人群的30秒EEG信号和EOG信号睡眠分期数据具有更好的适应性，避免了设计和提取分类器过程的不准确性和复杂性，可用于自动睡眠阶段分期的EEG信号的特征。</p><p>随着睡眠数据的累积，我们的模型性能将得到进一步提升。应该指出的是，人类专家通常不会仅使用一个通道进行睡眠分期。例如，在AASM指南中推荐至少三个通道，并且通常是非EEG标记，例如EOG、EMG或运动，其帮助神经生理学家区分N1期或REM期。在现存的大多数的例子中，虽然使用单个通道对轻便携式设备很有意义，但它同时限制了模型性能 [<xref ref-type="bibr" rid="hanspub.30667-ref26">26</xref>]。未来将继续改进基于CNN的自动睡眠阶段分期方法，并将进一步与RNN结合，实现对同一个样本不同期之间的时序信息的学习。</p><p>此外，我们的方法还为分析其他非线性和非平稳时间序列数据提供了一个思路方法。此模型原则上适用于使用CNN分类器的其他医学领域，我们将探索使用其他医疗时序数据，来处理相应的疾病检测和健康分析问题，例如用于肺音分类 [<xref ref-type="bibr" rid="hanspub.30667-ref37">37</xref>] 和心音分类 [<xref ref-type="bibr" rid="hanspub.30667-ref38">38</xref>]。</p></sec><sec id="s7"><title>基金项目</title><p>国家自然科学基金资助项目(批准号：11874310和11675134)，国家111项目(批准号：b16029)。</p></sec><sec id="s8"><title>文章引用</title><p>王抒伟,徐富献,钱镶钰,胡 桓,何情祖,林 海,帅建伟. 应用深度神经网络对多导睡眠图的睡眠分期研究 Application of Deep Neural Network to Study the Sleep Stage Scoring on the Polysomnography[J]. 生物物理学, 2019, 07(02): 11-25. https://doi.org/10.12677/BIPHY.2019.72002</p></sec><sec id="s9"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.30667-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Wulff, K., Gatti, S., Wettstein, J.G. and Foster, R.G. (2010) Sleep and Circadian Rhythm Disruption in Psychiatric and Neurodegenerative Disease. Nature Reviews Neuroscience, 11, 589-599. https://doi.org/10.1038/nrn2868</mixed-citation></ref><ref id="hanspub.30667-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Berry, R.B., Brooks, R., Gamaldo, C.E., Harding, S.M., Marcus, C.L. and Vaughn, B.V. (2012) The AASM Manual for the Scoring of Sleep and Associated Events, Rules, Terminology and Technical Specifications. American Academy of Sleep Medicine, Darien, IL, 176.</mixed-citation></ref><ref id="hanspub.30667-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Stepnowsky, C., Levendowski, D., Popovic, D., Ayappa, I. and Rapoport, D.M. (2013) Scoring Accuracy of Automated Sleep Staging from a Bipolar Electroocular Recording Compared to Manual Scoring by Multiple Raters. Sleep Medicine, 14, 1199-1207. Https://Doi.Org/10.1016/J.Sleep.2013.04.022</mixed-citation></ref><ref id="hanspub.30667-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Wang, Y., Loparo, K.A., Kelly, M.R. and Kaplan, R.F. (2015) Evaluation of an Automated Single-Channel Sleep Staging Algorithm. Nature and Science of Sleep, 7, 101-111. https://doi.org/10.2147/NSS.S77888</mixed-citation></ref><ref id="hanspub.30667-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Huang, C.-S., Lin, C.-L., Ko, L.-W., Liu, S.-Y., Su, T.-P. and Lin, C.-T. (2014) Knowledge-Based Identification of Sleep Stages Based on Two Forehead Electroencephalogram Channels. Frontiers in Neuroscience, 8, 263.  
https://doi.org/10.3389/fnins.2014.00263</mixed-citation></ref><ref id="hanspub.30667-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Güneş, S., Polat, K. and Yosunkaya, Ş. (2010) Efficient Sleep Stage Recognition System Based on EEG Signal Using k-Means Clustering Based Feature Weighting. Expert Systems with Applications, 37, 7922-7928.  
https://doi.org/10.1016/j.eswa.2010.04.043</mixed-citation></ref><ref id="hanspub.30667-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Tsinalis, O., Matthews, P.M. and Guo, Y. (2016) Automatic Sleep Stage Scoring Using Time-Frequency Analysis and Stacked Sparse Autoencoders. Annals of Biomedical Engineering, 44, 1587-1597.  
https://doi.org/10.1007/s10439-015-1444-y</mixed-citation></ref><ref id="hanspub.30667-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Sharma, R., Pachori, R.B. and Upadhyay, A. (2017) Automatic Sleep Stages Classification Based on Iterative Filtering of Electroencephalogram Signals. Neural Computing and Applications, 28, 2959-2978.  
https://doi.org/10.1007/s00521-017-2919-6</mixed-citation></ref><ref id="hanspub.30667-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Hassan, A.R. and Subasi, A. (2017) A Decision Support System for Automated Identification of Sleep Stages from Single-Channel EEG Signals. Knowledge-Based Systems, 128, 115-124. https://doi.org/10.1016/j.knosys.2017.05.005</mixed-citation></ref><ref id="hanspub.30667-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Cecotti, H. and Graser, A. (2011) Convolutional Neural Networks for P300 Detection with Application to Brain-Computer Interfaces. IEEE Transactions on Pattern Analysis and Machine Intelligence, 33, 433-445. 
https://doi.org/10.1109/TPAMI.2010.125</mixed-citation></ref><ref id="hanspub.30667-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Manor, R. and Geva, A.B. (2015) Convolutional Neural Network for Multi-Category Rapid Serial Visual Presentation BCI. Frontiers in Computational Neuroscience, 9, 146. https://doi.org/10.3389/fncom.2015.00146</mixed-citation></ref><ref id="hanspub.30667-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Page, A., Shea, C. and Mohsenin, T. (2016) Wearable Seizure Detection Using Convolutional Neural Networks with Transfer Learning. 2016 IEEE International Symposium on Circuits and Systems (ISCAS), Montreal, QC, 22-25 May 2016, 1086-1089. https://doi.org/10.1109/ISCAS.2016.7527433</mixed-citation></ref><ref id="hanspub.30667-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Hajinoroozi, M., Mao, Z. and Huang, Y. (2015) Prediction of Driver’s Drowsy and Alert States from EEG Signals with Deep Learning. 2015 IEEE 6th International Workshop on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP), Cancun, Mexico, 13-16 December 2015, 493-496.  
https://doi.org/10.1109/CAMSAP.2015.7383844</mixed-citation></ref><ref id="hanspub.30667-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">Drouin-Picaro, A. and Falk, T.H. (2016) Using Deep Neural Networks for Natural Saccade Classification from Electroencephalograms. 2016 IEEE EMBS International Student Conference (ISC), Ottawa, ON, 29-31 May 2016, 1-4. 
https://doi.org/10.1109/EMBSISC.2016.7508606</mixed-citation></ref><ref id="hanspub.30667-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">Manzano, M., Guillén, A., Rojas, I. and Herrera, L.J. (2017) Combination of EEG Data Time and Frequency Representations in Deep Networks for Sleep Stage Classification. In: Huang, D.S., Jo, K.H., Figueroa-García, J., Eds., Intelligent Computing Theories and Application (ICIC 2017), Lecture Notes in Computer Science, vol 10362, Springer, Cham, 219-229. https://doi.org/10.1007/978-3-319-63312-1_20</mixed-citation></ref><ref id="hanspub.30667-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">Supratak, A., Dong, H., Wu, C. and Guo, Y. (2017) DeepSleepNet: A Model for Automatic Sleep Stage Scoring Based on Raw Single-Channel EEG. IEEE Transactions on Neural Systems and Rehabilitation Engineering, 25, 1998-2008. 
https://doi.org/10.1109/TNSRE.2017.2721116</mixed-citation></ref><ref id="hanspub.30667-ref17"><label>17</label><mixed-citation publication-type="other" xlink:type="simple">Lecun, Y., Bottou, L., Bengio, Y. and Haffner, P. (1998) Gradi-ent-Based Learning Applied to Document Recognition. Proceedings of the IEEE, 86, 2278-2324. https://doi.org/10.1109/5.726791</mixed-citation></ref><ref id="hanspub.30667-ref18"><label>18</label><mixed-citation publication-type="other" xlink:type="simple">Krizhevsky, A., Sutskever, I. and Hinton, G.E. (2012) Imagenet Classification with Deep Convolutional Neural Networks. In: Pereira, F., Burges, C.J.C., Bottou, L. and Weinberger, K.Q., Eds., Proceedings of the 25th International Conference on Neural Information Processing Systems, Curran Associates Inc., New York, 1097-1105.</mixed-citation></ref><ref id="hanspub.30667-ref19"><label>19</label><mixed-citation publication-type="other" xlink:type="simple">Collobert, R. and Weston, J. (2008) A Unified Architecture for Natural Language Pro-cessing: Deep Neural Networks with Multitask Learning. In: Proceedings of the 25th International Conference on Machine Learning, ACM, New York, 160-167. https://doi.org/10.1145/1390156.1390177</mixed-citation></ref><ref id="hanspub.30667-ref20"><label>20</label><mixed-citation publication-type="other" xlink:type="simple">Van den Oord, A., Dieleman, S. and Schrauwen, B. (2013) Deep Content-Based Music Recommendation. In: Burges, C.J.C., Bottou, L., Welling, M., Ghahramani, Z. and Weinberger, K.Q., Eds., Proceedings of the 26th International Conference on Neural Information Processing Systems, Curran Associates Inc., New York, 2643-2651.</mixed-citation></ref><ref id="hanspub.30667-ref21"><label>21</label><mixed-citation publication-type="other" xlink:type="simple">Sjoberg, J., Zhang, Q., Ljung, L., Benveniste, A., Delyon, B., Glorennec, P., Hjalmarsson, H. and Juditsky, A. (1995) Nonlinear Black-Box Modeling in System Identification: A Unified Overview. Automatica, 31, 1691-1724. 
https://doi.org/10.1016/0005-1098(95)00120-8</mixed-citation></ref><ref id="hanspub.30667-ref22"><label>22</label><mixed-citation publication-type="other" xlink:type="simple">Mirowski, P.W., Madhavan, D. and LeCun, Y. (2007) Time-Delay Neural Networks and Independent Component Analysis for EEG-Based Prediction of Epileptic Seizures Propagation. Proceedings of the 22nd AAAI Conference on Artificial Intelligence, Vancouver, 22-26 July 2007, 1892-1893.</mixed-citation></ref><ref id="hanspub.30667-ref23"><label>23</label><mixed-citation publication-type="other" xlink:type="simple">LeCun, Y., Huang, F.J. and Bottou, L. (2004) Learning Methods for Generic Object Recognition with Invariance to Pose and Lighting. Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, Washington DC, 27 June-2 July 2004, 97-104.</mixed-citation></ref><ref id="hanspub.30667-ref24"><label>24</label><mixed-citation publication-type="other" xlink:type="simple">LeCun, Y., Kavukcuoglu, K. and Farabet, C. (2010) Convolutional Networks and Applications in Vision. Proceedings of 2010 IEEE International Symposium on Circuits and Systems, Paris, 30 May-2 June 2010, 253-256.  
https://doi.org/10.1109/ISCAS.2010.5537907</mixed-citation></ref><ref id="hanspub.30667-ref25"><label>25</label><mixed-citation publication-type="other" xlink:type="simple">Längkvist, M., Karlsson, L. and Loutfi, A. (2012) Sleep Stage Classification Using Unsupervised Feature Learning. Advances in Artificial Neural Systems, 2012, Article ID: 107046. https://doi.org/10.1155/2012/107046</mixed-citation></ref><ref id="hanspub.30667-ref26"><label>26</label><mixed-citation publication-type="other" xlink:type="simple">Chambon, S., Galtier, M.N., Arnal, P.J., Wainrib, G. and Gramfort, A. (2018) A Deep Learning Architecture for Temporal Sleep Stage Classification Using Multivariate and Multimodal Time Series. IEEE Transactions on Neural Systems and Rehabilitation Engineering, 26, 758-769. https://doi.org/10.1109/TNSRE.2018.2813138</mixed-citation></ref><ref id="hanspub.30667-ref27"><label>27</label><mixed-citation publication-type="other" xlink:type="simple">He, K., Zhang, X., Ren, S. and Sun, J. (2016) Deep Residual Learning for Image Recognition. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Las Vegas, NV, 27-30 June 2016, 770-778.  
https://doi.org/10.1109/CVPR.2016.90</mixed-citation></ref><ref id="hanspub.30667-ref28"><label>28</label><mixed-citation publication-type="other" xlink:type="simple">Goldberger, A.L., Amaral, L.A.N., Glass, L., Hausdorff, J.M., Ivanov, P.C., Mark, R.G., Mietus, J.E., Moody, G.B., Peng, C. and Stanley, H.E. (2000) PhysioBank, PhysioToolkit, and PhysioNet: Components of a New Research Resource for Complex Physiologic Signals. Circulation, 101, e215-e220. https://doi.org/10.1161/01.CIR.101.23.e215</mixed-citation></ref><ref id="hanspub.30667-ref29"><label>29</label><mixed-citation publication-type="other" xlink:type="simple">Sors, A., Bonnet, S., Mirek, S., Vercueil, L. and Payen, J.-F. (2018) A Convolutional Neural Network for Sleep Stage Scoring from Raw Single-Channel EEG. Biomedical Signal Processing and Control, 42, 107-114. 
https://doi.org/10.1016/j.bspc.2017.12.001</mixed-citation></ref><ref id="hanspub.30667-ref30"><label>30</label><mixed-citation publication-type="other" xlink:type="simple">Jung, Y. (2018) Multiple Predicting k-Fold Cross-Validation for Model Selection. Journal of Nonparametric Statistics, 30, 197-215. https://doi.org/10.1080/10485252.2017.1404598</mixed-citation></ref><ref id="hanspub.30667-ref31"><label>31</label><mixed-citation publication-type="other" xlink:type="simple">Kingma, D.P. and Ba, J. (2015) Adam: A Method for Stochastic Optimization. International Conference on Learning Representations, San Diego, CA, 7-9 May 2015, 1-13.</mixed-citation></ref><ref id="hanspub.30667-ref32"><label>32</label><mixed-citation publication-type="other" xlink:type="simple">Wei, L., Lin, Y., Wang, J. and Ma, Y. (2017) Time-Frequency Convolutional Neural Network for Automatic Sleep Stage Classification Based on Single-Channel EEG. 2017 IEEE 29th International Conference on Tools with Artificial Intel-ligence, Boston, MA, 6-8 November 2017, 88-95. https://doi.org/10.1109/ICTAI.2017.00025</mixed-citation></ref><ref id="hanspub.30667-ref33"><label>33</label><mixed-citation publication-type="other" xlink:type="simple">Fraiwan, L., Lweesy, K., Khasawneh, N., Wenz, H. and Dickhaus, H. (2012) Automated Sleep Stage Identification System Based on Time-Frequency Analysis of a Single EEG Channel and Random Forest Classifier. Computer Methods and Programs in Biomedicine, 108, 10-19. https://doi.org/10.1016/j.cmpb.2011.11.005</mixed-citation></ref><ref id="hanspub.30667-ref34"><label>34</label><mixed-citation publication-type="other" xlink:type="simple">Tsinalis, O., Matthews, P.M., Guo, Y. and Zafeiriou, S. (2016) Automatic Sleep Stage Scoring with Single-Channel EEG Using Convolutional Neural Networks. Machine Learning, arXiv: 1610.01683.</mixed-citation></ref><ref id="hanspub.30667-ref35"><label>35</label><mixed-citation publication-type="other" xlink:type="simple">Dietterich, T.G. (2000) Ensemble Methods in Machine Learning. In: Multiple Classifier Systems. MCS 2000. Lecture Notes in Computer Science, Springer, Berlin, Heidelberg, 1-15. https://doi.org/10.1007/3-540-45014-9_1</mixed-citation></ref><ref id="hanspub.30667-ref36"><label>36</label><mixed-citation publication-type="other" xlink:type="simple">Huang, C., Li, Y., Change Loy, C. and Tang, X. (2016) Learning Deep Representation for Imbalanced Classification. 2016 IEEE Conference on Computer Vision and Pattern Recognition, Las Vegas, NV, 27-30 June 2016, 5375-5384. 
https://doi.org/10.1109/CVPR.2016.580</mixed-citation></ref><ref id="hanspub.30667-ref37"><label>37</label><mixed-citation publication-type="other" xlink:type="simple">Cugell, D.W. (1985) Lung Sounds: Classification and Controversies. Seminars in Respiratory and Critical Care Medicine, 6, 180-182. https://doi.org/10.1055/s-2007-1011495</mixed-citation></ref><ref id="hanspub.30667-ref38"><label>38</label><mixed-citation publication-type="other" xlink:type="simple">Olmez, T. and Dokur, Z. (2003) Classification of Heart Sounds Using an Artificial Neural Network. Pattern Recognition Letters, 24, 617-629. https://doi.org/10.1016/S0167-8655(02)00281-7</mixed-citation></ref></ref-list></back></article>