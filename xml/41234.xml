<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">AAM</journal-id><journal-title-group><journal-title>Advances in Applied Mathematics</journal-title></journal-title-group><issn pub-type="epub">2324-7991</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/AAM.2021.103080</article-id><article-id pub-id-type="publisher-id">AAM-41234</article-id><article-categories><subj-group subj-group-type="heading"><subject>AAM20210300000_14771994.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>数学与物理</subject></subj-group></article-categories><title-group><article-title>
 
 
  非凸优化中一种带非单调线搜索的惯性邻近算法
  An Inertial Proximal Algorithm with Non-Monotone Line Search for Non-Convex Optimization
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>刘</surname><given-names>海玉</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib></contrib-group><aff id="aff1"><label>1</label><addr-line>null</addr-line></aff><aff id="aff2"><label>1</label><addr-line>河北工业大学，理学院，天津</addr-line></aff><pub-date pub-type="epub"><day>10</day><month>03</month><year>2021</year></pub-date><volume>10</volume><issue>03</issue><fpage>732</fpage><lpage>739</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
  
    本文考虑一类目标函数由可微(可能非凸)函数和凸(可能非光滑)函数组成的极小化问题。惯性邻近(iPiano)算法是解决这类问题的一种有效而重要的方法。通过引入非单调线搜索，提出了非单调线搜索的iPiano (iPiano-nml)算法。通过证明说明了由iPiano-nml生成的序列的任何聚点都是一个稳定点。最后，对图像处理问题进行了数值实验来说明新算法的理论结果。
    We consider a class of minimization problems whose objective function is composed of a differentiable (possibly nonconvex) function and a convex (possibly nonsoomth) function. The inertial proximal algorithm is a common and important method for this kind of problems. By incorporating the non-monotone line search, iPiano algorithm with non-monotone line search is proposed. We show that any cluster point of sequence which is generated by iPiano-nml is a stationary point. Finally, we perform numerical experiments on the image processing problems to illustrate our theoretical results. 
  
 
</p></abstract><kwd-group><kwd>非单调邻近梯度法，非凸，非光滑，图像降噪, Non-Monotone Proximal Gradient Method</kwd><kwd> Nonconvex</kwd><kwd> Non-Smooth</kwd><kwd> Image Denoising</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>摘要</title><p>本文考虑一类目标函数由可微(可能非凸)函数和凸(可能非光滑)函数组成的极小化问题。惯性邻近(iPiano)算法是解决这类问题的一种有效而重要的方法。通过引入非单调线搜索，提出了非单调线搜索的iPiano (iPiano-nml)算法。通过证明说明了由iPiano-nml生成的序列的任何聚点都是一个稳定点。最后，对图像处理问题进行了数值实验来说明新算法的理论结果。</p></sec><sec id="s2"><title>关键词</title><p>非单调邻近梯度法，非凸，非光滑，图像降噪</p></sec><sec id="s3"><title>An Inertial Proximal Algorithm with Non-Monotone Line Search for Non-Convex Optimization<sup> </sup></title><p>Haiyu Liu</p><p>School of Science, Hebei University of Technology, Tianjin</p><p><img src="//html.hanspub.org/file/11-2621502x4_hanspub.png" /></p><p>Received: Feb. 23<sup>rd</sup>, 2021; accepted: Mar. 19<sup>th</sup>, 2021; published: Mar. 26<sup>th</sup>, 2021</p><p><img src="//html.hanspub.org/file/11-2621502x5_hanspub.png" /></p></sec><sec id="s4"><title>ABSTRACT</title><p>We consider a class of minimization problems whose objective function is composed of a differentiable (possibly nonconvex) function and a convex (possibly nonsoomth) function. The inertial proximal algorithm is a common and important method for this kind of problems. By incorporating the non-monotone line search, iPiano algorithm with non-monotone line search is proposed. We show that any cluster point of sequence which is generated by iPiano-nml is a stationary point. Finally, we perform numerical experiments on the image processing problems to illustrate our theoretical results.</p><p>Keywords:Non-Monotone Proximal Gradient Method, Nonconvex, Non-Smooth, Image Denoising</p><disp-formula id="hanspub.41234-formula4"><graphic xlink:href="//html.hanspub.org/file/11-2621502x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2021 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/11-2621502x7_hanspub.png" /> <img src="//html.hanspub.org/file/11-2621502x8_hanspub.png" /></p></sec><sec id="s5"><title>1. 引言</title><p>本文考虑下列最小化问题：</p><p>min x ∈ R n F ( x ) = f ( x ) + g ( x ) , (1)</p><p>其中， f ( x ) : R N → R 是一个光滑(可能非凸)且为梯度李普希兹连续函数， g ( x ) : R N → R 是一个正常下半连续凸(可能非光滑)函数。另外 F ( x ) 是一个强制函数且有下界。</p><p>问题(1)出现在很多领域，如机器学习 [<xref ref-type="bibr" rid="hanspub.41234-ref1">1</xref>]，信号处理 [<xref ref-type="bibr" rid="hanspub.41234-ref2">2</xref>] 等。解决上述问题的经典方法是邻近梯度法 [<xref ref-type="bibr" rid="hanspub.41234-ref3">3</xref>]：</p><p>x k + 1 ∈ arg min x { 〈 ∇ f ( x k ) , x 〉 + α 2 ‖ x − x k ‖ 2 + g ( x ) } ,</p><p>其中 α 是步长。然而，邻近梯度算法在解决一些问题时，它的收敛速度较慢，于是人们逐渐地寻找一些策略来改善这样的问题。常见的一个有效的策略是加速方法，因此在上述邻近梯度法中，通过引入外推项，一些文献提出了加速邻近梯度算法 [<xref ref-type="bibr" rid="hanspub.41234-ref4">4</xref>]，FISTA [<xref ref-type="bibr" rid="hanspub.41234-ref5">5</xref>] 算法等。加速邻近梯度算法如下：</p><p>x k + 1 ∈ arg min x { 〈 ∇ f ( y k ) , x 〉 + α 2 ‖ x − y k ‖ 2 + g ( x ) } ,</p><p>y k = x k + β k ( x k − x k − 1 ) ,</p><p>其中 α 是步长， β k 是外推参数。这些算法的收敛速度为 O ( 1 k 2 ) 。除此自外，惯性项也是一类能加速算法的有效策略，通过将邻近梯度法和惯性项结合得到下列惯性邻近算法(iPiano) [<xref ref-type="bibr" rid="hanspub.41234-ref6">6</xref>] ]：</p><p>x k + 1 = ( I + α ∂ g ) − 1 ( x k − α ∇ f ( x k ) + β ( x k − x k − 1 ) ) , (2)</p><p>其中， α 是步长， β 是惯性因子。iPiano在实际运行中收敛速度比邻近梯度法快，广泛地应用于非凸问题 [<xref ref-type="bibr" rid="hanspub.41234-ref7">7</xref>] [<xref ref-type="bibr" rid="hanspub.41234-ref8">8</xref>]。另一方面，线搜索也是一项能加速原始算法的有效策略，其非单调线搜索有更好的数值表现。非单调邻近梯度法(NPG) [<xref ref-type="bibr" rid="hanspub.41234-ref9">9</xref>] 采用了下列线搜索：</p><p>u ∈ arg min x { 〈 ∇ f ( x k ) , x − x k 〉 + L 2 ‖ x − x k ‖ 2 + g ( x ) } ,</p><p>F ( u ) ≤ max [ k − M ] + ≤ i ≤ k F ( x i ) − c 2 ‖ u − x k ‖ 2 ,</p><p>其中c和M都大于0。该线搜索在每次迭代中通过选取k与 k − M 之间的最大值来满足条件，从而保证目标函数有更大的下降。</p><p>本文在惯性邻近算法的基础上，将其与NPG结合，提出一种带非单调线搜索的惯性邻近算法，并将其运用于图像处理，通过信噪比来说明新算法的有效性。</p></sec><sec id="s6"><title>2. 预备定义</title><p>本节给出一些基本的定义。本文考虑欧式空间且维数 N ≥ 1 。</p><p>定义1：令 g ( x ) 为一个正常下半连续凸函数，那么邻近算子定义为：</p><p>( I + α ∂ g ) − 1 ( x ^ ) = arg min x ‖ x − x ^ ‖ 2 2 + α g ( x ) .</p><p>引理1： f ( x ) : R N → R 为一个光滑函数且为L梯度李普希兹连续。则对于 ∀ x , y ∈ R N ， ∃ L &gt; 0 ，下式成立：</p><p>‖ ∇ f ( x ) − ∇ f ( y ) ‖ ≤ L ‖ x − y ‖ .</p><p>引理2： f ( x ) : R N → R 为一个光滑函数且为L梯度李普希兹连续。则对于 ∀ x , y ∈ R N ，我们成立以下下降引理</p><p>f ( x ) ≤ f ( y ) + 〈 ∇ f ( y ) , x − y 〉 + L 2 ‖ x − y ‖ 2 .</p><p>命题1：令 F , f , g 满足上述定义，则对于 x ∈ d o m F ，我们有下式成立：</p><p>∂ F ( x ) = ∇ f ( x ) + ∂ g ( x ) .</p></sec><sec id="s7"><title>3. 算法和收敛性</title><p>本节给出iPiano-nml算法和收敛性分析。首先我们引入一个辅助序列：</p><p>H δ ( x , y ) = f ( x ) + g ( x ) + δ ‖ x − y ‖ 2 .</p><p>易知当时 x = y ，我们有 H δ ( x , y ) = f ( x ) + g ( x ) 。</p><sec id="s7_1"><title>3.1. iPiano-nml算法</title><p>iPiano-nml算法：</p><p>步骤0：选择 x 0 ∈ d o m F , x 0 = x − 1 。 c 1 , c 2 接近0。 L max ≥ L min &gt; 0 , τ &gt; 1 , c &gt; 0 , M ≥ 0 。</p><p>步骤k：1) 选择 L k ∈ [ L min , L max ] , y k = x k + β k ( x k − x k − 1 ) 。</p><p>1a) 求解子问题：</p><p>u ∈ arg min x { g ( x ) + 〈 ∇ f ( x k ) , x 〉 + 1 2 α k ‖ x − y k ‖ 2 } .</p><p>1b) 如果满足</p><p>H δ k + 1 ( u , x k ) ≤ max [ k − M ] + ≤ i ≤ k H δ i ( x i , x i − 1 ) − c 2 ‖ u − x k ‖ 2 ,</p><p>那么进行步骤2)。</p><p>1c) 令 L k ← τ L k ，继续步骤1a)。</p><p>2) 令 x k + 1 ← u , k ← k + 1 然后进行步骤1)。</p><p>其中序列满足 α k ≥ c 1 , β k ≥ 0 , δ k ≥ γ k ≥ c 2 。 δ k 单调递减，另有：</p><p>δ k = 1 α k − L k 2 − β k 2 α k , γ k = 1 α k − L k 2 − β k α k .</p></sec><sec id="s7_2"><title>3.2. 收敛性分析</title><p>引理1：对于 k ≥ 0 ，存在 δ k ≥ γ k , β k ∈ [ 0 , 1 ) , α k &lt; 2 ( 1 − β k ) L k 。另外给定 L k ≥ 0 ，存在 α k , β k 满足 δ k 单调递减。</p><p>证明：该引理证明参考文献 [<xref ref-type="bibr" rid="hanspub.41234-ref6">6</xref>]。</p><p>引理2：序列 ( H δ k ( x k , x k − 1 ) ) k = 0 ∞ 单调递减且收敛，且我们有</p><p>H δ k + 1 ( x k + 1 , x k ) ≤ H δ k ( x k , x k − 1 ) − γ k ‖ x k − x k − 1 ‖ 2 .</p><p>证明：该引理证明参考文献 [<xref ref-type="bibr" rid="hanspub.41234-ref6">6</xref>]。</p><p>定理1：</p><p>1)序列 { x k } 有界。</p><p>2) lim k → ∞ ‖ x k − x k − 1 ‖ = 0 。</p><p>3)任意序列的聚点都是稳定点。</p><p>证明：</p><p>1) 由引理2可知整个序列 { x k } 都包含于下列水平集合：</p><p>{ x ∈ R N : F _ ≤ F ( x ) ≤ H δ 0 ( x 0 , x − 1 ) } .</p><p>那么由 F _ = inf F ( x ) &gt; ∞ ，我们可推知序列 { x k } 有界。</p><p>2) 显然，我们有：</p><p>H δ k + 1 ( x k + 1 , x k ) − max [ k − M ] + ≤ i ≤ k H δ i ( x i , x i − 1 ) = f ( x k + 1 ) + g ( x k + 1 ) + δ k + 1 ‖ x k + 1 − x k ‖ 2 − max [ k − M ] + ≤ i ≤ k { f ( x i ) + g ( x i ) + δ i ‖ x i − x i − 1 ‖ 2 } ≤ f ( x k + 1 ) + g ( x k + 1 ) + δ k + 1 ‖ x k + 1 − x k ‖ 2 − f ( x k ) − g ( x k ) − δ k ‖ x k − x k − 1 ‖ 2 = H δ k + 1 ( x k + 1 , x k ) − H δ k ( x k , x k − 1 ) .</p><p>由引理2可知：</p><p>H δ k + 1 ( x k + 1 , x k ) − max [ k − M ] + ≤ i ≤ k H δ i ( x i , x i − 1 ) ≤ − γ k ‖ x k − x k − 1 ‖ 2 .</p><p>将上式两边从 k = 0 加到N。则由引理2和M的定义我们有</p><p>0 &lt; ∑ k = 0 N γ k ‖ x k − x k − 1 ‖ 2 ≤ ∑ k = 0 N max [ k − M ] + ≤ i ≤ k H δ i ( x i , x i − 1 ) − H δ k + 1 ( x k + 1 , x k )     = ( M − 1 ) H δ 0 ( x 0 , x − 1 ) − ⋯ − H δ N − M + 2 ( x N − M + 2 , x N − M + 1 )           − H δ N − M + 3 ( x N − M + 3 , x N − M + 2 ) − ⋯ − H δ N ( x N , x N − 1 ) − H δ N + 1 ( x N + 1 , x N ) &lt; ∞ ,</p><p>从而我们可以推断出 lim k → ∞ ‖ x k − x k − 1 ‖ = 0 。</p><p>3) 令 x * 为序列的聚点且存在 { x k j } 使得 lim j → ∞ x k j = x * 。那么由一阶最优条件，我们有</p><p>− 1 α k j ‖ x k j + 1 − y k j ‖ ∈ ∂ g ( x k j + 1 ) + ∇ f ( x k j ) .</p><p>由 y k j = x k j + β k j ( x k j − x k j − 1 ) ，我们可以得到</p><p>− 1 α k j ‖ x k j + 1 − x k j − β k j ( x k j − x k j − 1 ) ‖ ∈ ∂ g ( x k j + 1 ) + ∇ f ( x k j ) .</p><p>由函数 g ( x ) 的凸性， ∇ f ( x ) 连续性以及 ‖ x k − x k − 1 ‖ = 0 ，我们有</p><p>0 ∈ ∇ f ( x * ) + ∂ g ( x * ) ,</p><p>这就说明了 x * 是算法的稳定点。</p></sec></sec><sec id="s8"><title>4. 数值实验</title><p>本节将算法用于数值实验，运行环境为MATLAB R2014a 2.80 GHz CPUs。我们先简单介绍一下问题模型。</p><p>问题模型为马尔科夫随机场：</p><p>min u ∈ R N ∑ i = 1 N f ζ i ϕ ( K i u ) + g ( u , u 0 ) ,</p><p>其中u是所求图像信息， u 0 是噪声图像信息， ϕ 是非凸罚函数，表达式为：</p><p>ϕ ( K i u ) = ∑ p φ ( ( K i u ) p ) ,</p><p>其中 K i 是学习率，是基于 ζ i 权重的线性算子， N f 是滤子数，本文考虑7 * 7的滤波器 [<xref ref-type="bibr" rid="hanspub.41234-ref6">6</xref>]，且 K i u = k i ∗ u 。</p><p>对于 φ ( t ) ，我们考虑学生t分布：</p><p>φ ( t ) = log ( 1 + t 2 ) .</p><p>我们考虑高斯噪声，其中函数模型为 g ( u , u 0 ) = λ 2 ‖ u − u 0 ‖ 2 。</p><p>对于终止条件我们选择下述能量差：</p><p>ε k = F k − F * ,</p><p>其中， F * 是真实值(数值由 [<xref ref-type="bibr" rid="hanspub.41234-ref6">6</xref>] 给出)， F k 是每次迭代的值，两者做差即为能量差 ε k 。</p><p>为了增强对比效果，我们用iPiano-nml和iPiano-Backtracking作比较。iPiano-Backtracking为带回溯线搜索的iPiano算法：</p><p>f ( x k + 1 ) ≤ f ( x k ) + 〈 ∇ f ( x k ) , x k + 1 − x k 〉 + L k 2 ‖ x k + 1 − x k ‖ 2 ( k ∈ N ) .</p><p>当满足回溯线搜索时，令 L k + 1 = L k / 1.05 否则令 L k + 1 = L k ∗ 1.2 。</p><p>在iPiano-nml中，令 L k 为BB步长 [<xref ref-type="bibr" rid="hanspub.41234-ref10">10</xref>]：</p><p>L k = { min ( max ( ‖ s k − 1 ‖ 2 s k − 1 T l k − 1 , L min ) , L max ) ( s k − 1 T l k − 1 ≠ 0 ) L max , otherwise .</p><p>另外参数选取为：</p><p>L 1 = 3 , α k = 2 ∗ ( 1 − β ) L k ∗ 0.99 , β = 0.8 , λ = 1 , c = 4.8 , τ = 1.6 , M = 2.</p><p>在iPiano-Backtracking中，令参数选取为：</p><p>L 1 = 3 , α k = 2 ∗ ( 1 − β ) L k ∗ 0.99 , β = 0.8 , λ = 1.</p><p>接下来我们给出峰值信噪比与迭代变化关系图：</p><p>图1. 两个算法效果对比图</p><p>由图1中可知在过程中iPiano-nml比iPiano-Backtracking效果表现好。</p><p>下面给出效果对比图：</p><p>图2出了效果对比。上方左图为原始图像，右图为噪声图像。下方左图为iPiano-nml去噪效果，右图为iPiano-Backtracking去噪效果。图2验证了iPiano-nml算法的有效性。</p><p>图2. 效果对比</p></sec><sec id="s9"><title>5. 结论</title><p>本文在考虑一类非凸非光滑问题中借鉴了NPG的思想，将非单调线搜索整合到iPiano中，提出了带非单调技术的iPiano算法，并通过一定的条件证明了新算法的收敛性。本文将新算法运用于图像降噪实验，通过与原算法的对比说明新算法的有效性。以后我们的工作将研究新算法的收敛速度。</p></sec><sec id="s10"><title>文章引用</title><p>刘海玉. 非凸优化中一种带非单调线搜索的惯性邻近算法An Inertial Proximal Algorithm with Non-Monotone Line Search for Non-Convex Optimization[J]. 应用数学进展, 2021, 10(03): 732-739. https://doi.org/10.12677/AAM.2021.103080</p></sec><sec id="s11"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.41234-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Curtis, F.E. and Scheinberg, K. (2017) Optimization Methods for Supervised Machine Learning: From Linear Models to Deep Learning. In: Leading Developments from INFORMS Communities, 89-114.  
&lt;br&gt;https://doi.org/10.1287/educ.2017.0168</mixed-citation></ref><ref id="hanspub.41234-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Combettes, P.L. and Pesquet, J.C. (2011) Proximal Splitting Methods in Signal Processing. In: Bauschke, H., Burachik, R., Combettes, P., Elser, V., Luke, D. and Wolkowicz, H. (Eds.), Fixed-Point Algorithms for Inverse Problems in Science and Engineering, Springer, New York, NY, 185-212. &lt;br&gt;https://doi.org/10.1007/978-1-4419-9569-8_10</mixed-citation></ref><ref id="hanspub.41234-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Boţ, R.I., Csetnek, E.R. and Hendrich, C. (2015) Inertial Douglas-Rachford Splitting for Monotone Inclusion Problems. Applied Mathematics and Computation, 256, 472-487. &lt;br&gt;https://doi.org/10.1016/j.amc.2015.01.017</mixed-citation></ref><ref id="hanspub.41234-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Wen, B. and Xue, X. (2019) On the Convergence of the Iterates of Proximal Gradient Algorithm with Extrapolation for Convex Nonsmooth Minimization Problems. Journal of Global Optimization, 75, 767-787.  
&lt;br&gt;https://doi.org/10.1007/s10898-019-00789-8</mixed-citation></ref><ref id="hanspub.41234-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Beck, A. and Teboulle, M. (2009) A Fast Iterative Shrinkage-Thresholding Algorithm for Linear Inverse Problems. SIAM journal on Imaging Sciences, 2, 183-202. &lt;br&gt;https://doi.org/10.1137/080716542</mixed-citation></ref><ref id="hanspub.41234-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Ochs, P., Chen, Y., Brox, T., et al. (2014) iPiano: Inertial Proximal Algorithm for Nonconvex Optimization. SIAM Journal on Imaging Sciences, 7, 1388-1419. &lt;br&gt;https://doi.org/10.1137/130942954</mixed-citation></ref><ref id="hanspub.41234-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Ochs, P. (2019) Unifying Abstract Inexact Convergence Theorems and Block Coordinate Variable Metric iPiano. SIAM Journal on Optimization, 29, 541-570. &lt;br&gt;https://doi.org/10.1137/17M1124085</mixed-citation></ref><ref id="hanspub.41234-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Ochs, P. (2018) Local Convergence of the Heavy-Ball Method and iPiano for Non-Convex Optimization. Journal of Optimization Theory and Applications, 177, 153-180. &lt;br&gt;https://doi.org/10.1007/s10957-018-1272-y</mixed-citation></ref><ref id="hanspub.41234-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Chen, X., Lu, Z. and Pong, T.K. (2016) Penalty Methods for a Class of Non-Lipschitz Optimization Problems. SIAM Journal on Optimization, 26, 1465-1492. &lt;br&gt;https://doi.org/10.1137/15M1028054</mixed-citation></ref><ref id="hanspub.41234-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Barzilai, J. and Borwein, J.M. (1988) Two-Point Step Size Gradient Methods. IMA Journal of Numerical Analysis, 8, 141-148. &lt;br&gt;https://doi.org/10.1093/imanum/8.1.141</mixed-citation></ref></ref-list></back></article>