<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">AAM</journal-id><journal-title-group><journal-title>Advances in Applied Mathematics</journal-title></journal-title-group><issn pub-type="epub">2324-7991</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/AAM.2021.103083</article-id><article-id pub-id-type="publisher-id">AAM-41242</article-id><article-categories><subj-group subj-group-type="heading"><subject>AAM20210300000_61481491.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>数学与物理</subject></subj-group></article-categories><title-group><article-title>
 
 
  一种带分布式自适应时延的粒子群算法
  A Particle Swarm Optimization Algorithm with Distributed Adaptively Weighted Delays
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>胡</surname><given-names>建华</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>熊</surname><given-names>伟利</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>上海理工大学理学院，上海</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>10</day><month>03</month><year>2021</year></pub-date><volume>10</volume><issue>03</issue><fpage>753</fpage><lpage>762</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
  
    针对粒子群算法(PSO)容易陷入局部最优值、收敛精度低等缺陷，提出一种新的带分布式自适应时延的粒子群算法(PSO-DW)。改进的算法主要在RODDPSO算法的基础上考虑时延的时变性和种群的进化状态，以平衡算法的全局搜索和局部搜索能力，降低早熟收敛的可能性，提高算法的收敛速度和精度。主要思想：1) 在引入了分布式时延的速度更新公式中，每个时延项配以自适应权重，2) 引入通过当前状态和概率转移矩阵预测下一进化状态的预测机制，3) 分布式时延的强度因子由预测状态所确定。在九个基准函数上与四个算法作对比的实验结果表明，改进后的算法在寻优质量、稳定性、收敛速度等方面更具优越性。
    A new particle swarm optimization algorithm (PSO) with distributed adaptively weighted delays (PSO-DW) has been proposed to overcome the defects of the PSO algorithm, such as falling into local optimal value, low convergence accuracy. Based on the RODDPSO algorithm, the improved algorithm further considers the time-varying delays and the evolutionary states of the population, so that it can balance the global search and local search ability of the algorithm, reduce the possibility of premature convergence, and improve the convergence speed and accuracy of the algorithm. The main ideas are: 1) each delay is equipped with adaptive weight in the velocity update formula; 2) prediction mechanism of the next evolutionary state has been introduced by the current state and probability transfer matrix; 3) intensity factor of the distributed delay is determined by the prediction state. The experimental results show that the improved algorithm has more advantages in optimizing quality, stability and convergence speed by comparing with four algorithms on nine benchmark functions. 
  
 
</p></abstract><kwd-group><kwd>粒子群优化(PSO)，分布式时延，进化因子，权重, Particle Swarm Optimization (PSO)</kwd><kwd> Distributed Time-Delay</kwd><kwd> Evolutionary Factor</kwd><kwd> Weight</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>摘要</title><p>针对粒子群算法(PSO)容易陷入局部最优值、收敛精度低等缺陷，提出一种新的带分布式自适应时延的粒子群算法(PSO-DW)。改进的算法主要在RODDPSO算法的基础上考虑时延的时变性和种群的进化状态，以平衡算法的全局搜索和局部搜索能力，降低早熟收敛的可能性，提高算法的收敛速度和精度。主要思想：1) 在引入了分布式时延的速度更新公式中，每个时延项配以自适应权重，2) 引入通过当前状态和概率转移矩阵预测下一进化状态的预测机制，3) 分布式时延的强度因子由预测状态所确定。在九个基准函数上与四个算法作对比的实验结果表明，改进后的算法在寻优质量、稳定性、收敛速度等方面更具优越性。</p></sec><sec id="s2"><title>关键词</title><p>粒子群优化(PSO)，分布式时延，进化因子，权重</p></sec><sec id="s3"><title>A Particle Swarm Optimization Algorithm with Distributed Adaptively Weighted Delays<sup> </sup></title><p>Jianhua Hu, Weili Xiong</p><p>University of Shanghai for Science and Technology, Shanghai</p><p><img src="//html.hanspub.org/file/14-2621517x4_hanspub.png" /></p><p>Received: Feb. 23<sup>rd</sup>, 2021; accepted: Mar. 19<sup>th</sup>, 2021; published: Mar. 26<sup>th</sup>, 2021</p><p><img src="//html.hanspub.org/file/14-2621517x5_hanspub.png" /></p></sec><sec id="s4"><title>ABSTRACT</title><p>A new particle swarm optimization algorithm (PSO) with distributed adaptively weighted delays (PSO-DW) has been proposed to overcome the defects of the PSO algorithm, such as falling into local optimal value, low convergence accuracy. Based on the RODDPSO algorithm, the improved algorithm further considers the time-varying delays and the evolutionary states of the population, so that it can balance the global search and local search ability of the algorithm, reduce the possibility of premature convergence, and improve the convergence speed and accuracy of the algorithm. The main ideas are: 1) each delay is equipped with adaptive weight in the velocity update formula; 2) prediction mechanism of the next evolutionary state has been introduced by the current state and probability transfer matrix; 3) intensity factor of the distributed delay is determined by the prediction state. The experimental results show that the improved algorithm has more advantages in optimizing quality, stability and convergence speed by comparing with four algorithms on nine benchmark functions.</p><p>Keywords:Particle Swarm Optimization (PSO), Distributed Time-Delay, Evolutionary Factor, Weight</p><disp-formula id="hanspub.41242-formula7"><graphic xlink:href="//html.hanspub.org/file/14-2621517x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2021 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/14-2621517x7_hanspub.png" /> <img src="//html.hanspub.org/file/14-2621517x8_hanspub.png" /></p></sec><sec id="s5"><title>1. 引言</title><p>粒子群算法(particle swarm optimization, PSO)是一种基于群体智能的随机全局优化算法 [<xref ref-type="bibr" rid="hanspub.41242-ref1">1</xref>]，最初由Eberhart和Kennedy (1995) [<xref ref-type="bibr" rid="hanspub.41242-ref2">2</xref>] 受鸟群捕食行为启发而提出，其基本思想是通过群体中个体之间的协作和信息共享来寻找最优解。由于算法简单、易于实现、快速收敛等特性，PSO算法自从提出之日起就受到很多学者的青睐。近些年来PSO算法得到长足的发展并被广泛应用到实际领域的优化问题中。但粒子群算法依旧存在容易陷入局部最优从而导致早熟收敛的缺陷，这种缺陷随搜索空间维数的增大愈发明显。为了增加粒子的多样性以减少陷入局部收敛的可能性，学者们提出了各种改进策略来提高PSO算法的优化性能。基于参数调整的PSO算法有PSO-LDIW (Shi, 1998, 1999) [<xref ref-type="bibr" rid="hanspub.41242-ref3">3</xref>] [<xref ref-type="bibr" rid="hanspub.41242-ref4">4</xref>] [<xref ref-type="bibr" rid="hanspub.41242-ref5">5</xref>]、PSO-CK (Clerc和Kennedy, 2002) [<xref ref-type="bibr" rid="hanspub.41242-ref6">6</xref>]、PSO-TVAC (Ratnaweera, 2004) [<xref ref-type="bibr" rid="hanspub.41242-ref7">7</xref>]、NCPSO (2017) [<xref ref-type="bibr" rid="hanspub.41242-ref8">8</xref>]、AWPSO (Liu and Wang, 2019) [<xref ref-type="bibr" rid="hanspub.41242-ref9">9</xref>] 等。基于拓扑结构和学习策略的改进算法有APSO (Zhan等人，2009) [<xref ref-type="bibr" rid="hanspub.41242-ref10">10</xref>]、SPSO (Tang等人，2011) [<xref ref-type="bibr" rid="hanspub.41242-ref11">11</xref>]、SDPSO (Zeng等人，2016) [<xref ref-type="bibr" rid="hanspub.41242-ref12">12</xref>]、MDPSO (Song等人，2017, 2018) [<xref ref-type="bibr" rid="hanspub.41242-ref13">13</xref>] [<xref ref-type="bibr" rid="hanspub.41242-ref14">14</xref>] 等。这些算法通过考虑粒子群的四种进化状态和时延影响等因素大大提高了PSO算法的性能。2019年，Liu等人 [<xref ref-type="bibr" rid="hanspub.41242-ref9">9</xref>] 提出了一种基于随机分布式时延的PSO算法(RODDPSO)，大大提高了算法的搜索能力，但是这种算法忽略了不同阶段的历史信息对当前状态的影响是不同的。事实上，离当前状态越近的历史信息对当前状态的影响较大，而越远的历史信息对当前状态的影响相对较小。</p><p>本文拟在RODDPSO算法的基础上，充分考虑不同历史信息对当前状态的影响，提出一种带分布式自适应时延的粒子群算法(PSO-DW)。改进算法中时延是具有时变性的，分布式时延的强度因子由预测状态所确定。新算法能进一步平衡全局搜索能力和局部搜索能力，降低早熟收敛的可能，提高算法的收敛速度和精度。仿真实验在150维搜索空间的九个基准函数上与四个算法作对比。结果表明，改进后的算法在寻优质量、稳定性、收敛速度等方面更具优越性。</p></sec><sec id="s6"><title>2. 传统PSO算法</title><p>在PSO算法中，所有的粒子构成种群，并且每一个粒子都可能是所研究优化问题的最优解。粒子在搜索空间中根据个体的最优位置和群体最优位置更新速度和位置，从而寻找最优解 [<xref ref-type="bibr" rid="hanspub.41242-ref15">15</xref>]。设种群由S个粒子组成，记集合 I = { 1 , 2 , 3 , ⋯ , S } 。设搜索空间为 R D ，其中D为维数。用 X i ∈ R D , i ∈ I 表示第i个粒子的位置，其速度为 V i ∈ R D 。第i个粒子第k次迭代后的速度和位置分别是：</p><p>V i ( k ) = ( V i 1 ( k ) , V i 2 ( k ) , ⋯ , V i D ( k ) ) ,</p><p>X i ( k ) = ( X i 1 ( k ) , X i 2 ( k ) , ⋯ , X i D ( k ) ) .</p><p>令 P i = ( P i 1 , P i 2 , ⋯ , P i D ) 表示第i个粒子的最优位置， P G = ( P G 1 , P G 2 , ⋯ , P G D ) 表示种群全局最优位置 [<xref ref-type="bibr" rid="hanspub.41242-ref16">16</xref>]。在搜索的过程中，所有的粒子都朝着全局最优的方向移动。第i个粒子在k + 1时刻的速度和位置的更新公式为：</p><p>V i ( k + 1 ) = ω V i ( k ) + c 1 r 1 ( P i ( k ) − X i ( k ) ) + c 2 r 2 ( P G ( k ) − X i ( k ) ) , X i ( k + 1 ) = X i ( k ) + V i ( k + 1 ) . (1)</p><p>在公式(1)中， ω 是惯性权重； r 1 , r 2 都是D维向量，其每个分量都是 [ 0 , 1 ] 上的随机数； c 1 , c 2 分别表示个体认知加速度系数和社会认知加速度系数。</p><p>为了提高搜索速度，Clerc和Kennedy (2002)提出了PSO-CK算法 [<xref ref-type="bibr" rid="hanspub.41242-ref6">6</xref>]；在此算法中通过大量的实验证明当 c 1 = c 2 = 1.49 , ω = 0.729 时性能最优。为了平衡当前速度、认知和社会等方面的性能，Shi和Eberhart博士先后在1998年和1999年提出了PSO-LDIW算法 [<xref ref-type="bibr" rid="hanspub.41242-ref3">3</xref>] [<xref ref-type="bibr" rid="hanspub.41242-ref4">4</xref>] [<xref ref-type="bibr" rid="hanspub.41242-ref5">5</xref>]，该算法采用了线性下降的惯性权重：</p><p>ω = ω max − ( ω max − ω min ) &#215; i t e r m a x i t e r , (2)</p><p>这里 ω max ( ω min )为在整个搜索过程中惯性权重的最大(最小)的值； i t e r ( m a x i t e r )表示当前(最大)的迭代次数。受时变惯性权重的启发，Ratnaweera等人在2004年提出了PSO-TVAC算法 [<xref ref-type="bibr" rid="hanspub.41242-ref7">7</xref>]，将加速度因子改进为：</p><p>c 1 = ( c 1 i − c 1 f ) &#215; m a x i t e r − i t e r m a x i t e r + c 1 f (3)</p><p>c 2 = ( c 2 i − c 2 f ) &#215; m a x i t e r − i t e r m a x i t e r + c 2 f (4)</p><p>上式中 c 1 i ( c 1 f )和 c 2 i ( c 2 f )分别是个体认知加速度系数和社会认知加速度系数的初值(终值)，这些参数的取值为：</p><p>c 1 i = 2.5 , c 1 f = 0.5 , c 2 i = 0.5 , c 2 f = 2.5.</p></sec><sec id="s7"><title>3. 改进的粒子群算法</title><p>本文提出一个带有分布式自适应时延和与由预测状态所确定的强度因子的粒子群优化(PSO-DW)算法。</p><sec id="s7_1"><title>3.1. 进化状态的刻画与预测</title><p>进化状态这一概念先后由Zhan [<xref ref-type="bibr" rid="hanspub.41242-ref10">10</xref>]、Tang [<xref ref-type="bibr" rid="hanspub.41242-ref11">11</xref>] 等人根据种群分布信息提出。整个搜索过程包含四种状态：收敛、开发、勘探和跳出，分别用 ξ = 1 , 2 , 3 , 4 表示。记</p><p>d i = 1 S − 1 ∑ j = 1 , i ≠ j S ∑ l = 1 D ( x i l − x j l ) 2 , i ∈ I (5)</p><p>表示第i个粒子和其余粒子间的平均距离， d min , d max 是集合 { d i | i ∈ I } 中的最小值和最大值，用G表示全局最优粒子。定义</p><p>E f = d G − d min d max − d min , (6)</p><p>显然 E f ∈ [ 0 , 1 ] 且在收敛状态下粒子群将紧跟当前全局最优粒子飞向最优解，此时 E f 会逐渐减小；而在跳出状态下全局最优粒子倾向于远离种群，此时 E f 相对较大。因此 E f 能恰当刻画种群的进化状态，称 E f 为进化因子。根据 E f 的取值，规定：</p><p>ξ = { 1 ,               0.00 ≤ E f &lt; 0.25 , 2 ,             0.25 ≤ E f &lt; 0.50 , 3 ,             0.50 ≤ E f &lt; 0.75 , 4 ,             0.75 ≤ E f ≤ 1. (7)</p><p>在种群进化过程中，下一进化状态不可避免的受到当前状态的影响，本文引入一种预测机制，利用概率转移矩阵来通过当前进化状态对下一状态进行预测。记 ξ ( k ) 为第k次迭代时的当前进化状态， ξ ′ ( k ) 为预计的下一进化状态。取概率转移矩阵为：</p><p>M ( k ) = [ φ 1 − φ 0 0 1 − φ 2 φ 1 − φ 2 0 0 1 − φ 2 φ 1 − φ 2 0 0 1 − φ φ ] (8)</p><p>其中</p><p>M i j ( k ) = P { ξ ′ ( k ) = j | ξ ( k ) = i } , ∀ i , j = 1 , 2 , 3 , 4</p><p>表示种群根据当前进化状态i去预测下一状态j的概率，满足 ∑ j = 1 4 M i j ( 4 ) = 1 。这里 φ 是一个非常重要的参数。为既保持种群进化的惯性，也增加其多样性，本文参考Zeng [<xref ref-type="bibr" rid="hanspub.41242-ref12">12</xref>]，选取 φ = 0.9 。这意味着种群有很大的可能维持当前的状态，而以较小的概率转移到另一进化状态。</p></sec><sec id="s7_2"><title>3.2. 新算法的构建</title><p>传统的粒子群算法专注于当前信息对寻找最优解的影响而忽略了过去的信息。但在实际搜索过程中每一个粒子对每次迭代的速度、位置、个体最优以及全局最优等信息都保留有记忆，充分综合这些信息更有利于种群搜索最优解。2019年Liu等人引入随机分布式时延项，提出RODDPSO算法 [<xref ref-type="bibr" rid="hanspub.41242-ref9">9</xref>]，此算法不仅考虑种群当前状态的个体最优和全局最优信息，还充分考虑历史上个体最优和全局最优信息，但是忽略了不同阶段的历史信息对当前状态的影响是不同。事实上，离当前状态越近的历史信息对当前状态的影响较大，而越远的历史信息对当前状态的影响相对较小。基于这一事实，本文提出一种带有分布式自适应时延的粒子群算法(PSO-DW)，其更新公式为：</p><p>V i ( k + 1 ) = ω V i ( k ) + c 1 r 1 ( P i ( k ) − X i ( k ) ) + c 2 r 2 ( P G ( k ) − X i ( k ) )                       + m l ( ξ ′ ( k ) ) c 3 r 3 ∑ τ = 1 N ω 1 α ( τ ) ( P i ( k − τ ) − X i ( k ) )                       + m G ( ξ ′ ( k ) ) c 4 r 4 ∑ τ = 1 N ω 1 α ( τ ) ( P G ( k − τ ) − X i ( k ) ) , X i ( k + 1 ) = X i ( k ) + V i ( k + 1 ) . (9)</p><p>对比式(1)，这里引进了关于个体认知和社会认知的分布式时延项。其中 τ 是时延的步数，可取值 1 , 2 , ⋯ , N ，N为分布式时延步数的上限值； ω 1 是当时延发生时的自适应权重，它决定了每个时延影响的大小； α ( τ ) 从 { 0 , 1 } 中随机选取，以增加粒子的多样性； c 3 , c 4 是加速度系数； r 3 , r 4 是 [ 0 , 1 ] 上服从均匀分布的随机向量； m l ( ξ ′ ( k ) ) 和 m G ( ξ ′ ( k ) ) 是分布式时延项的强度因子，由预测的进化状态 ξ ′ ( k ) 确定，主要用来提高算法的搜索能力和加快收敛速度。需要说明的是当 τ ≥ k 时约定 P i ( k − τ ) = P i ( k ) ， P G ( k − τ ) = P G ( k ) 。</p></sec><sec id="s7_3"><title>3.3. 参数配置</title><p>新的粒子群算法带有两个权重参数 ω 和 ω 1 。其中惯性权重 ω 由式(2)确定；自适应权重 ω 1 用来控制时延项对速度的影响，它是时变的，为关于 τ 的递减函数，本文取</p><p>ω 1 = N − τ N , (10)</p><p>加速度系数 c 1 , c 2 由式(3)、(4)确定， c 3 , c 4 与 c 1 , c 2 所起作用类似，本文取 c 3 = c 1 ， c 4 = c 2 。强度因子 m l ( ξ ′ ( k ) ) 和 m G ( ξ ′ ( k ) ) 主要用来提高算法的搜索能力，加快算法的收敛速度，初值都取为0，在进化过程中，其大小由预测状态所确定(见表1)。当根据k次迭代后种群的状态预测到下一状态是收敛状态时，粒子将紧跟全局最优粒子快速到达最优解，为保持这种趋势，忽略时延项的影响而取 m l ( 1 ) = m G ( 1 ) = 0 ；当预测到下一状态是开发状态时，粒子将在个体最优位置仔细搜索，因此个体的历史最优位置有着重要的参考意义，取 m l ( 2 ) = 0.01 ， m G ( 2 ) = 0 。当预测到下一状态是勘探状态时，粒子将在整个搜索空间尽可能的探索全局最优解，此时需充分考虑全局历史最优信息，取 m l ( 3 ) = 0 ， m G ( 3 ) = 0.01 ；当预测到下一状态是跳出状态时，个体和全局的历史最优位置需要综合考虑，取 m l ( 4 ) = 0.01 ， m G ( 4 ) = 0.01 。需指出的是参数0.01是个经验值。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Intensity factor selection strateg</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >状态</th><th align="center" valign="middle" >状态值</th><th align="center" valign="middle" >m l ( ξ ′ ( k ) )</th><th align="center" valign="middle" >m l ( ξ ′ ( k ) )</th></tr></thead><tr><td align="center" valign="middle" >收敛</td><td align="center" valign="middle" >ξ ′ ( k ) = 1</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0</td></tr><tr><td align="center" valign="middle" >开发</td><td align="center" valign="middle" >ξ ′ ( k ) = 2</td><td align="center" valign="middle" >0.01</td><td align="center" valign="middle" >0</td></tr><tr><td align="center" valign="middle" >勘探</td><td align="center" valign="middle" >ξ ′ ( k ) = 3</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0.01</td></tr><tr><td align="center" valign="middle" >跳出</td><td align="center" valign="middle" >ξ ′ ( k ) = 4</td><td align="center" valign="middle" >0.01</td><td align="center" valign="middle" >0.01</td></tr></tbody></table></table-wrap><p>表1. 强度因子选择策略</p></sec></sec><sec id="s8"><title>4. 仿真实验与结果分析</title><sec id="s8_1"><title>4.1. 实验环境</title><p>为验证新算法的性能，本文引入九个基准函数进行测试，其中既有单峰函数又有多峰函数，基准函数的具体信息见表2；本文实验在高维搜索空间进行，取维数 D = 150 ，粒子数 S = 20 ，最大迭代次数为20,000次，为消除随机因素的影响，每次实验重复40次，最后取平均值。每次实验之初随机初始化粒子的速度 V i 和位置 X i , i ∈ I ，然后计算出每一个粒子的适应度值，根据适应度值确定个体最优粒子的位置 P i 和全局最优粒子的位置 P G 。</p></sec><sec id="s8_2"><title>4.2. 上限值N的选取</title><p>在PSO-DW算法中，分布式时延步数的上限值N是一个非常重要的参数，不同的N将影响算法的收敛速度和最终的收敛值。本文将通过实验，对比N取75、100、125、150、175、200时，根据算法在150维空间中的九个基准函数上的不同表现，选取鲁棒性最强的N。实验结果如图1所示。在图1中，纵坐标是平均适应度值的对数值，横坐标是迭代次数。</p><p>从图1中可以看出，当分布时延项数的上限值N取125时算法在 f 1 ( x ) ， f 3 ( x ) ， f 8 ( x ) ， f 9 ( x ) 相对于其他的N性能更优，不仅拥有较好的适应度值,而且相对而言较早开始收敛。对于函数 f 2 ( x ) ， f 4 ( x ) ， f 5 ( x ) ， f 6 ( x ) ， f 7 ( x ) ，虽然N取125没有最优的适应度值，但与其它适应度值相差不大，而 N = 125 时有更早的收敛趋势，因此本文选取 N = 125 。</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> Benchmark functio</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >函数</th><th align="center" valign="middle" >名字</th><th align="center" valign="middle" >搜索空间</th></tr></thead><tr><td align="center" valign="middle" >f 1 ( x )</td><td align="center" valign="middle" >Griewank</td><td align="center" valign="middle" >[−600, 600]</td></tr><tr><td align="center" valign="middle" >f 2 ( x )</td><td align="center" valign="middle" >Penalized 1</td><td align="center" valign="middle" >[−50, 50]</td></tr><tr><td align="center" valign="middle" >f 3 ( x )</td><td align="center" valign="middle" >Schwefel 1.2</td><td align="center" valign="middle" >[−100, 100]</td></tr><tr><td align="center" valign="middle" >f 4 ( x )</td><td align="center" valign="middle" >Rastrigin</td><td align="center" valign="middle" >[−5.12, 5.12]</td></tr><tr><td align="center" valign="middle" >f 5 ( x )</td><td align="center" valign="middle" >Schwefel</td><td align="center" valign="middle" >[−500, 500]</td></tr><tr><td align="center" valign="middle" >f 6 ( x )</td><td align="center" valign="middle" >Penalized 2</td><td align="center" valign="middle" >[−50, 50]</td></tr><tr><td align="center" valign="middle" >f 7 ( x )</td><td align="center" valign="middle" >Step</td><td align="center" valign="middle" >[−100, 100]</td></tr><tr><td align="center" valign="middle" >f 8 ( x )</td><td align="center" valign="middle" >Schwefel2.22</td><td align="center" valign="middle" >[−10, 10]</td></tr><tr><td align="center" valign="middle" >f 9 ( x )</td><td align="center" valign="middle" >Schwefel2.21</td><td align="center" valign="middle" >[−100, 100]</td></tr></tbody></table></table-wrap><p>表2. 基准函数</p><p>图1. 由PSO-DW算法训练N</p></sec><sec id="s8_3"><title>4.3. 实验结果与分析</title><p>为验证算法性能在高维搜索空间中的优越性，本文选用PSO-CK、PSO-TVAC、PSO-LDIW、RODDPSO四种算法作对比，评价指标为最小值、均值、方差。实验结果如表3和图2所示。表3表明，在相同的实验环境下，PSO-DW算法在九个基准函数上表现出明显优势。首先九个平均适应度值都是最小的，这表明PSO-DW算法有较好的寻优质量，其收敛精度更高；其次除了在 f 4 ( x ) 上，PSO-DW算法的方差也是最小的，这说明PSO-DW算法的稳定性较好；就最小值而言PSO-DW算法的仅在 f 3 ( x ) 上略逊于PSO-CK算法。进一步仔细比较，算法性能表现次优的是RODDPSO算法，而PSO-CK、PSO-TVAC、PSO-LDIW算法精确度普遍较差，这表明在高维搜索空间中，PSO-CK、PSO-TVAC、PSO-LDIW算法容易收敛于局部极值，而引入时延项的PSO算法，充分考虑了种群的个体最优历史信息和全局历史信息，更加有利于增加粒子的多样性，表现出更好的跳出局部最优的能力。</p><table-wrap-group id="3"><label><xref ref-type="table" rid="table3">Table 3</xref></label><caption><title> Comparison of performance of five algorithms in 150 D search spac</title></caption><table-wrap id="3_1"><table><tbody><thead><tr><th align="center" valign="middle" >函数</th><th align="center" valign="middle" >评价指标</th><th align="center" valign="middle" >PSO-CK</th><th align="center" valign="middle" >PSO-LDIW</th><th align="center" valign="middle" >PSO-TVAC</th><th align="center" valign="middle" >RODDPSO</th><th align="center" valign="middle" >PSO-DW</th></tr></thead><tr><td align="center" valign="middle"  rowspan="3"  >f 1 ( x )</td><td align="center" valign="middle" >最小值</td><td align="center" valign="middle" >2.71 &#215; 10<sup>2</sup></td><td align="center" valign="middle" >3.43 &#215; 10<sup>−2</sup></td><td align="center" valign="middle" >2.99 &#215; 10<sup>2</sup></td><td align="center" valign="middle" >2.32 &#215; 10<sup>−11</sup></td><td align="center" valign="middle" >8.66 &#215; 10<sup>−15</sup></td></tr><tr><td align="center" valign="middle" >均值</td><td align="center" valign="middle" >5.50 &#215; 10<sup>2</sup></td><td align="center" valign="middle" >3.27 &#215; 10<sup>2</sup></td><td align="center" valign="middle" >4.13 &#215; 10<sup>2</sup></td><td align="center" valign="middle" >1.43 &#215; 10<sup>−1</sup></td><td align="center" valign="middle" >2.15 &#215; 10<sup>−2</sup></td></tr><tr><td align="center" valign="middle" >方差</td><td align="center" valign="middle" >1.83 &#215; 10<sup>2</sup></td><td align="center" valign="middle" >1.63 &#215; 10<sup>2</sup></td><td align="center" valign="middle" >4.13 &#215; 10<sup>2</sup></td><td align="center" valign="middle" >1.43 &#215; 10<sup>−1</sup></td><td align="center" valign="middle" >2.15 &#215; 10<sup>−2</sup></td></tr><tr><td align="center" valign="middle"  rowspan="3"  >f 2 ( x )</td><td align="center" valign="middle" >最小值</td><td align="center" valign="middle" >4.17 &#215; 10<sup>−2</sup></td><td align="center" valign="middle" >2.51 &#215; 10<sup>−4</sup></td><td align="center" valign="middle" >5.71 &#215; 10<sup>6</sup></td><td align="center" valign="middle" >4.93 &#215; 10<sup>−9</sup></td><td align="center" valign="middle" >1.88 &#215; 10<sup>−15</sup></td></tr><tr><td align="center" valign="middle" >均值</td><td align="center" valign="middle" >8.96 &#215; 10<sup>7</sup></td><td align="center" valign="middle" >1.92 &#215; 10<sup>7</sup></td><td align="center" valign="middle" >2.23 &#215; 10<sup>7</sup></td><td align="center" valign="middle" >4.42 &#215; 10<sup>−1</sup></td><td align="center" valign="middle" >7.98 &#215; 10<sup>−2</sup></td></tr><tr><td align="center" valign="middle" >方差</td><td align="center" valign="middle" >1.79 &#215; 10<sup>8</sup></td><td align="center" valign="middle" >6.83 &#215; 10<sup>7</sup></td><td align="center" valign="middle" >9.90 &#215; 10<sup>6</sup></td><td align="center" valign="middle" >5.66 &#215; 10<sup>−1</sup></td><td align="center" valign="middle" >1.51 &#215; 10<sup>−1</sup></td></tr><tr><td align="center" valign="middle"  rowspan="3"  >f 3 ( x )</td><td align="center" valign="middle" >最小值</td><td align="center" valign="middle" >3.30 &#215; 10<sup>3</sup></td><td align="center" valign="middle" >1.54 &#215; 10<sup>5</sup></td><td align="center" valign="middle" >2.12 &#215; 10<sup>5</sup></td><td align="center" valign="middle" >1.70 &#215; 10<sup>4</sup></td><td align="center" valign="middle" >8.04 &#215; 10<sup>3</sup></td></tr><tr><td align="center" valign="middle" >均值</td><td align="center" valign="middle" >9.21 &#215; 10<sup>4</sup></td><td align="center" valign="middle" >2.29 &#215; 10<sup>5</sup></td><td align="center" valign="middle" >3.07 &#215; 10<sup>5</sup></td><td align="center" valign="middle" >6.00 &#215; 10<sup>4</sup></td><td align="center" valign="middle" >1.45 &#215; 10<sup>4</sup></td></tr><tr><td align="center" valign="middle" >方差</td><td align="center" valign="middle" >5.69 &#215; 10<sup>4</sup></td><td align="center" valign="middle" >6.01 &#215; 10<sup>4</sup></td><td align="center" valign="middle" >4.69 &#215; 10<sup>4</sup></td><td align="center" valign="middle" >2.30 &#215; 10<sup>4</sup></td><td align="center" valign="middle" >4.01 &#215; 10<sup>3</sup></td></tr><tr><td align="center" valign="middle"  rowspan="3"  >f 4 ( x )</td><td align="center" valign="middle" >最小值</td><td align="center" valign="middle" >7.26 &#215; 10<sup>2</sup></td><td align="center" valign="middle" >5.49 &#215; 10<sup>2</sup></td><td align="center" valign="middle" >1.23 &#215; 10<sup>3</sup></td><td align="center" valign="middle" >3.69 &#215; 10<sup>2</sup></td><td align="center" valign="middle" >2.71 &#215; 10<sup>2</sup></td></tr><tr><td align="center" valign="middle" >均值</td><td align="center" valign="middle" >9.01 &#215; 10<sup>2</sup></td><td align="center" valign="middle" >7.72 &#215; 10<sup>2</sup></td><td align="center" valign="middle" >1.40 &#215; 10<sup>3</sup></td><td align="center" valign="middle" >5.24 &#215; 10<sup>2</sup></td><td align="center" valign="middle" >3.80 &#215; 10<sup>2</sup></td></tr><tr><td align="center" valign="middle" >方差</td><td align="center" valign="middle" >1.20 &#215; 10<sup>2</sup></td><td align="center" valign="middle" >1.14 &#215; 10<sup>2</sup></td><td align="center" valign="middle" >8.44 &#215; 10<sup>1</sup></td><td align="center" valign="middle" >7.11 &#215; 10<sup>1</sup></td><td align="center" valign="middle" >8.17 &#215; 10<sup>1</sup></td></tr></tbody></table></table-wrap><table-wrap id="3_2"><table><tbody><thead><tr><th align="center" valign="middle"  rowspan="3"  >f 5 ( x )</th><th align="center" valign="middle" >最小值</th><th align="center" valign="middle" >2.55 &#215; 10<sup>4</sup></th><th align="center" valign="middle" >2.56 &#215; 10<sup>4</sup></th><th align="center" valign="middle" >3.88 &#215; 10<sup>4</sup></th><th align="center" valign="middle" >2.20 &#215; 10<sup>4</sup></th><th align="center" valign="middle" >2.18 &#215; 10<sup>4</sup></th></tr></thead><tr><td align="center" valign="middle" >均值</td><td align="center" valign="middle" >3.09 &#215; 10<sup>4</sup></td><td align="center" valign="middle" >3.07 &#215; 10<sup>4</sup></td><td align="center" valign="middle" >4.44 &#215; 10<sup>4</sup></td><td align="center" valign="middle" >3.05 &#215; 10<sup>4</sup></td><td align="center" valign="middle" >2.59 &#215; 10<sup>4</sup></td></tr><tr><td align="center" valign="middle" >方差</td><td align="center" valign="middle" >2.28 &#215; 10<sup>3</sup></td><td align="center" valign="middle" >2.50 &#215; 10<sup>3</sup></td><td align="center" valign="middle" >4.52 &#215; 10<sup>3</sup></td><td align="center" valign="middle" >9.51 &#215; 10<sup>3</sup></td><td align="center" valign="middle" >1.98 &#215; 10<sup>3</sup></td></tr><tr><td align="center" valign="middle"  rowspan="3"  >f 6 ( x )</td><td align="center" valign="middle" >最小值</td><td align="center" valign="middle" >1.59 &#215; 10<sup>0</sup></td><td align="center" valign="middle" >6.42 &#215; 10<sup>−1</sup></td><td align="center" valign="middle" >4.17 &#215; 10<sup>7</sup></td><td align="center" valign="middle" >4.61 &#215; 10<sup>−8</sup></td><td align="center" valign="middle" >1.40 &#215; 10<sup>−12</sup></td></tr><tr><td align="center" valign="middle" >均值</td><td align="center" valign="middle" >5.33 &#215; 10<sup>8</sup></td><td align="center" valign="middle" >1.33 &#215; 10<sup>8</sup></td><td align="center" valign="middle" >9.14 &#215; 10<sup>7</sup></td><td align="center" valign="middle" >1.81 &#215; 10<sup>0</sup></td><td align="center" valign="middle" >3.51 &#215; 10<sup>−1</sup></td></tr><tr><td align="center" valign="middle" >方差</td><td align="center" valign="middle" >4.17 &#215; 10<sup>8</sup></td><td align="center" valign="middle" >2.35 &#215; 10<sup>8</sup></td><td align="center" valign="middle" >3.44 &#215; 10<sup>7</sup></td><td align="center" valign="middle" >2.31 &#215; 10<sup>0</sup></td><td align="center" valign="middle" >9.70 &#215; 10<sup>−1</sup></td></tr><tr><td align="center" valign="middle"  rowspan="3"  >f 7 ( x )</td><td align="center" valign="middle" >最小值</td><td align="center" valign="middle" >4.13 &#215; 10<sup>4</sup></td><td align="center" valign="middle" >1.00 &#215; 10<sup>4</sup></td><td align="center" valign="middle" >2.42 &#215; 10<sup>4</sup></td><td align="center" valign="middle" >2.70 &#215; 10<sup>1</sup></td><td align="center" valign="middle" >1.20 &#215; 10<sup>1</sup></td></tr><tr><td align="center" valign="middle" >均值</td><td align="center" valign="middle" >7.75 &#215; 10<sup>4</sup></td><td align="center" valign="middle" >3.53 &#215; 10<sup>4</sup></td><td align="center" valign="middle" >4.18 &#215; 10<sup>4</sup></td><td align="center" valign="middle" >2.04 &#215; 10<sup>2</sup></td><td align="center" valign="middle" >4.06 &#215; 10<sup>1</sup></td></tr><tr><td align="center" valign="middle" >方差</td><td align="center" valign="middle" >1.93 &#215; 10<sup>4</sup></td><td align="center" valign="middle" >1.65 &#215; 10<sup>4</sup></td><td align="center" valign="middle" >7.92 &#215; 10<sup>3</sup></td><td align="center" valign="middle" >1.05 &#215; 10<sup>2</sup></td><td align="center" valign="middle" >3.03 &#215; 10<sup>1</sup></td></tr><tr><td align="center" valign="middle"  rowspan="3"  >f 8 ( x )</td><td align="center" valign="middle" >最小值</td><td align="center" valign="middle" >9.07 &#215; 10<sup>1</sup></td><td align="center" valign="middle" >1.60 &#215; 10<sup>2</sup></td><td align="center" valign="middle" >3.55 &#215; 10<sup>2</sup></td><td align="center" valign="middle" >2.40 &#215; 10<sup>−1</sup></td><td align="center" valign="middle" >9.20 &#215; 10<sup>−9</sup></td></tr><tr><td align="center" valign="middle" >均值</td><td align="center" valign="middle" >1.89 &#215; 10<sup>2</sup></td><td align="center" valign="middle" >2.79 &#215; 10<sup>2</sup></td><td align="center" valign="middle" >4.67 &#215; 10<sup>2</sup></td><td align="center" valign="middle" >3.41 &#215; 10<sup>1</sup></td><td align="center" valign="middle" >4.19 &#215; 10<sup>−6</sup></td></tr><tr><td align="center" valign="middle" >方差</td><td align="center" valign="middle" >4.52 &#215; 10<sup>1</sup></td><td align="center" valign="middle" >9.75 &#215; 10<sup>1</sup></td><td align="center" valign="middle" >3.45 &#215; 10<sup>2</sup></td><td align="center" valign="middle" >2.13 &#215; 10<sup>1</sup></td><td align="center" valign="middle" >1.51 &#215; 10<sup>−5</sup></td></tr><tr><td align="center" valign="middle"  rowspan="3"  >f 9 ( x )</td><td align="center" valign="middle" >最小值</td><td align="center" valign="middle" >2.93 &#215; 10<sup>1</sup></td><td align="center" valign="middle" >2.98 &#215; 10<sup>1</sup></td><td align="center" valign="middle" >5.52 &#215; 10<sup>1</sup></td><td align="center" valign="middle" >1.64 &#215; 10<sup>1</sup></td><td align="center" valign="middle" >6.34 &#215; 10<sup>0</sup></td></tr><tr><td align="center" valign="middle" >均值</td><td align="center" valign="middle" >3.31 &#215; 10<sup>1</sup></td><td align="center" valign="middle" >3.48 &#215; 10<sup>1</sup></td><td align="center" valign="middle" >6.13 &#215; 10<sup>1</sup></td><td align="center" valign="middle" >2.36 &#215; 10<sup>1</sup></td><td align="center" valign="middle" >8.17 &#215; 10<sup>0</sup></td></tr><tr><td align="center" valign="middle" >方差</td><td align="center" valign="middle" >1.87 &#215; 10<sup>0</sup></td><td align="center" valign="middle" >2.32 &#215; 10<sup>0</sup></td><td align="center" valign="middle" >3.42 &#215; 10<sup>0</sup></td><td align="center" valign="middle" >2.77 &#215; 10<sup>0</sup></td><td align="center" valign="middle" >1.42 &#215; 10<sup>0</sup></td></tr></tbody></table></table-wrap></table-wrap-group><p>表3. 五种算法在150D的搜索空间中的性能比较</p><p>图2表明在150维搜索空间中，五种算法都有较好的收敛，但PSO-DW的优势更加明显。由于分布式时延的引入，历史最优信息被充分考虑，PSO-DW和RODDPSO算法在寻优前期都表现出较好的全局搜索能力，快速朝最优解方向搜索，并且在寻优中期和晚期中表现出较好的局部搜索和跳出局部最优的能力，实现收敛能力的提升。对比RODDPSO算法，一方面由于考虑了时延的时变性，PSO-DW算法具有更加准确的搜索性能，大大提升了收敛精确度；另一方面，由预计状态确定的强度因子的引入，促使种群由当前状态快速向下一进化状态转化，加快了算法的收敛速度。综上所述，在150维的搜索空间中，改进的PSO-DW算法在搜索过程中较好地平衡了全局搜索和局部搜索的能力，降低了陷入局部最优的可能性，实现了收敛速度和收敛精度的提升。</p><p>图2. 五种算法在150维的搜索空间中的对比图</p></sec></sec><sec id="s9"><title>5. 结论</title><p>考虑到种群的进化状态和历史最优信息，本文提出一种带分布式自适应时延的粒子群优化算法(PSO-DW)，该算法大大降低了种群在搜索过程中陷入局部最优的可能性，提升了收敛速度和收敛精度。实验在150维搜索空间进行，迭代20,000次，每次实验重复40次，工作量较大；实验结果表明在高维搜索空间中新算法有较好的寻优能力和稳定性。</p></sec><sec id="s10"><title>基金项目</title><p>本项目由国家自然科学基金项目：61873169资助。</p></sec><sec id="s11"><title>文章引用</title><p>胡建华,熊伟利. 一种带分布式自适应时延的粒子群算法A Particle Swarm Optimization Algorithm with Distributed Adaptively Weighted Delays[J]. 应用数学进展, 2021, 10(03): 753-762. https://doi.org/10.12677/AAM.2021.103083</p></sec><sec id="s12"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.41242-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">陈贵敏, 贾建援, 韩琪. 粒子群优化算法的惯性权重递减策略研究[J]. 西安交通大学学报, 2006, 40(1): 53-56.</mixed-citation></ref><ref id="hanspub.41242-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Eberhart, R. and Kennedy, J. (1995) A New Optimizer Using Particle Swarm Theory. Proceedings of the 6th International Symposium on Micro Machine and Human Science, Nagoya, 4-6 October 1995, 39-43.</mixed-citation></ref><ref id="hanspub.41242-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Shi, Y. and Eberhart, R.C. (1998) Parameter Selection in Particle Swarm Optimization. Proceedings of the 7th International Conference on Evolutionary Programming, San Diego, 25-27 March 1998, 591-600.  
&lt;br&gt;https://doi.org/10.1007/BFb0040810</mixed-citation></ref><ref id="hanspub.41242-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Shi, Y. and Eberhart, R. (1998) A Modified Particle Swarm Optimizer. Proceedings of IEEE International Conference on Evolutionary Computation, Anchorage, 4-9 May 1998, 69-73.</mixed-citation></ref><ref id="hanspub.41242-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Shi, Y. and Eberhart, R.C. (1999) Empirical Study of Particle Swarm Optimization. Proceedings of the 1999 Congress on Evolutionary Computation, Washington DC, Vol. 3, 1945-1950.</mixed-citation></ref><ref id="hanspub.41242-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Clerk, M. and Kennedy, J. (2002) The Particle Swarm: Explosion, Stability, and Convergence in a Multidimensional Complex Space. IEEE Transactions on Evolutionary Computation, 6, 58-73. &lt;br&gt;https://doi.org/10.1109/4235.985692</mixed-citation></ref><ref id="hanspub.41242-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Ratnaweera, A., Halaamuge, S. and Watson, H.C. (2004) Self Organizing Hierarchical Particle Swarm Optimizer with Time-Varying Acceleration Coefficients. IEEE Transactions on Evolutionary Computation, 8, 240-255.  
&lt;br&gt;https://doi.org/10.1109/TEVC.2004.826071</mixed-citation></ref><ref id="hanspub.41242-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">蔡燕敏. 一种新的混沌粒子群优化算法[J]. 智能计算机与应用, 2017, 7(2): 63-66.</mixed-citation></ref><ref id="hanspub.41242-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Liu, W., Wang, Z. and Liu, X.H. (2019) A Novel Particle Swarm Optimization Approach for Patient Clustering from Emergency Departments. IEEE Transactions on Evolutionary Computation, 23, 632-644.  
&lt;br&gt;https://doi.org/10.1109/TEVC.2018.2878536</mixed-citation></ref><ref id="hanspub.41242-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Zhan, Z., Zhang, J., Li, Y. and Chung, H. (2009) Adaptive Particle Swarm Optimization. IEEE Transactions on Systems, 39, 1362-1381. &lt;br&gt;https://doi.org/10.1109/TSMCB.2009.2015956</mixed-citation></ref><ref id="hanspub.41242-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Tang, Y., Wang, Z. and Fang, J. (2011) Parameters Identification of Unknown Delayed Genetic Regulatory Networks by a Switching Particle Swarm Optimization Algorithm. Expert Systems with Applications, 38, 2523-2535.  
&lt;br&gt;https://doi.org/10.1016/j.eswa.2010.08.041</mixed-citation></ref><ref id="hanspub.41242-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Zeng, N.Y., Wang, Z., Zhang, H. and Alsaadi, F.E. (2016) A Novel Switching Delayed PSO Algorithm for Estimating Unknown Parameters of Lateral Flow Immunoassay. Cognitive Computation, 8, 143-152.  
&lt;br&gt;https://doi.org/10.1007/s12559-016-9396-6</mixed-citation></ref><ref id="hanspub.41242-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Song, B.Y., Wang, Z. and Zou, L. (2017) On Global Smooth Path Planning for Mobile Robots Using a Novel Multimodal Delayed PSO Algorithm. Cognitive Computation, 9, 5-17. &lt;br&gt;https://doi.org/10.1007/s12559-016-9442-4</mixed-citation></ref><ref id="hanspub.41242-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">Song, B.Y., Xu, J.W. and Xu, L. (2018) PSO-Based Extended Kalman Filtering for Speed Estimation of an Induction Motor. 2018 37th Chinese Control Conference (CCC), Wuhan, 25-27 July 2018, 3803-3807.  
&lt;br&gt;https://doi.org/10.23919/ChiCC.2018.8482581</mixed-citation></ref><ref id="hanspub.41242-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">张文成, 周穗华, 吴志东, 等. 改进策略的粒子群算法及其实验测试[J]. 计算机工程与设计, 2012, 33(10): 3945-3948.</mixed-citation></ref><ref id="hanspub.41242-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">杜江, 袁中华, 王景芹. 动态改变惯性权重的新模式粒子群算法[J]. 安徽大学学报(自然科学版), 2018, 42(2): 60-62.</mixed-citation></ref></ref-list></back></article>