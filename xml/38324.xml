<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2020.1010194</article-id><article-id pub-id-type="publisher-id">CSA-38324</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20201000000_59604075.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  用于人脸表情识别的卷积神经网络研究
  Research on Facial Expression Recognition Based on Convolutional Neural Network
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>孙</surname><given-names>丽萍</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>陈</surname><given-names>红倩</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>李</surname><given-names>慧</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff3"><addr-line>北京联合大学管理学院，北京</addr-line></aff><aff id="aff2"><addr-line>北京工商大学计算机学院，北京</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>10</day><month>10</month><year>2020</year></pub-date><volume>10</volume><issue>10</issue><fpage>1843</fpage><lpage>1852</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   为了研究卷积神经网络在人脸表情识别中的应用，设计了一种10层的卷积神经网络模型识别人脸表情，最后一层用Softmax函数将表情的分类结果输出。首先，研究了卷积神经网络的卷积和池化算法并设计了模型的结构。其次，为了更形象地展示卷积层提取的特征，把提取的特征做了可视化处理并以特征图的形式展示。本文的卷积神经网络模型在Fer-2013数据集上进行了实验，实验结果展示了识别率的优越性。为了验证模型识别的泛化能力，最后自制了一个自然状态下的人脸表情数据集，并对人脸图片做了裁剪，灰度化以及像素调整等一系列的预处理。用本文模型识别该数据集中的人脸表情图片，识别的准确率达85.1010%。 In order to study the application of CNN in the field of facial expression recognition, the 10-layer CNN model is designed. The last layer of said model employs Softmax function to output the expression classification results. Firstly, this study concentrates on the convolution and pooling algorithm as well as the design structure of the model. In addition, the study visualized the extracted features and displayed them in the form of feature maps to show the features extracted by every convolutional layer. The study conducted experiments on the Fer-2013 dataset, and the result demonstrated the efficacy of the model. It is known that the Fer-2013 dataset contains data collected in an experimental environment. Therefore, to prove the effectiveness of the model, the study created a facial expression dataset by collecting facial expression images in a natural, spontaneous setting. The trained model, which was previously applied to the Fer-2013 dataset, was tested out on the new dataset. The experiment yielded promising results, one of which in the form of a recognition accu-racy rate as high as 85.1010%. 
   
   
    
  
 
</p></abstract><kwd-group><kwd>表情识别，卷积神经网络，深度学习，特征提取，图像分类, Expression Recognition</kwd><kwd> CNN</kwd><kwd> Deep Learning</kwd><kwd> Feature Extraction</kwd><kwd> Image Classification</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>摘要</title><p>为了研究卷积神经网络在人脸表情识别中的应用，设计了一种10层的卷积神经网络模型识别人脸表情，最后一层用Softmax函数将表情的分类结果输出。首先，研究了卷积神经网络的卷积和池化算法并设计了模型的结构。其次，为了更形象地展示卷积层提取的特征，把提取的特征做了可视化处理并以特征图的形式展示。本文的卷积神经网络模型在Fer-2013数据集上进行了实验，实验结果展示了识别率的优越性。为了验证模型识别的泛化能力，最后自制了一个自然状态下的人脸表情数据集，并对人脸图片做了裁剪，灰度化以及像素调整等一系列的预处理。用本文模型识别该数据集中的人脸表情图片，识别的准确率达85.1010%。</p></sec><sec id="s2"><title>关键词</title><p>表情识别，卷积神经网络，深度学习，特征提取，图像分类</p></sec><sec id="s3"><title>Research on Facial Expression Recognition Based on Convolutional Neural Network<sup> </sup></title><p>Liping Sun<sup>1</sup>, Hongqian Chen<sup>1</sup>, Hui Li<sup>2*</sup></p><p><sup>1</sup>School of Computer and Information Engineering, Beijing Technology and Business University, Beijing</p><p><sup>2</sup>School of Management, Beijing Union University, Beijing</p><p><img src="//html.hanspub.org/file/15-1541880x5_hanspub.png" /></p><p>Received: Oct. 6<sup>th</sup>, 2020; accepted: Oct. 21<sup>st</sup>, 2020; published: Oct. 28<sup>th</sup>, 2020</p><p><img src="//html.hanspub.org/file/15-1541880x6_hanspub.png" /></p></sec><sec id="s4"><title>ABSTRACT</title><p>In order to study the application of CNN in the field of facial expression recognition, the 10-layer CNN model is designed. The last layer of said model employs Softmax function to output the expression classification results. Firstly, this study concentrates on the convolution and pooling algorithm as well as the design structure of the model. In addition, the study visualized the extracted features and displayed them in the form of feature maps to show the features extracted by every convolutional layer. The study conducted experiments on the Fer-2013 dataset, and the result demonstrated the efficacy of the model. It is known that the Fer-2013 dataset contains data collected in an experimental environment. Therefore, to prove the effectiveness of the model, the study created a facial expression dataset by collecting facial expression images in a natural, spontaneous setting. The trained model, which was previously applied to the Fer-2013 dataset, was tested out on the new dataset. The experiment yielded promising results, one of which in the form of a recognition accuracy rate as high as 85.1010%.</p><p>Keywords:Expression Recognition, CNN, Deep Learning, Feature Extraction, Image Classification</p><disp-formula id="hanspub.38324-formula39"><graphic xlink:href="//html.hanspub.org/file/15-1541880x7_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2020 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/15-1541880x8_hanspub.png" /> <img src="//html.hanspub.org/file/15-1541880x9_hanspub.png" /></p></sec><sec id="s5"><title>1. 引言</title><p>随着人工智能的发展，人机交互被广泛研究。根据人类的表情让机器去学习人类的情感是人机交互的一个重要研究部分。人脸表情识别从广义上来讲是一个交叉学科，它的研究涉及计算机视觉，图形图像处理以及心理学等。研究人脸表情识别能够促进更好的人机交互，也是人机交互中一个不可或缺的部分。</p><p>研究人脸表情识别的目的：1) 在人机交互中更好地理解人类的情感，从而提升人机交互的体验；2) 在视频片段中可以对人脸表情进行跟踪和识别；3) 研究人脸表情的编码模式，从而更有利于传输以及存储有人脸表情的图片。人脸表情识别在安防，心理学，医疗，客户满意度分析以及网络教学等领域有着广阔的应用前景。</p><p>从上世纪70年代开始研究人类面部表情，并对人类的表情进行了分类。在传统的表情识别系统中，把这一过程分为了特征提取和表情分类。提取脸部特征的方法有Gabor滤波器 [<xref ref-type="bibr" rid="hanspub.38324-ref1">1</xref>]；方向直方图HOG；离散余弦变换(DCT)和尺度不变特征变换(SIFT)等，然后利用SVM [<xref ref-type="bibr" rid="hanspub.38324-ref2">2</xref>] 或者PCA [<xref ref-type="bibr" rid="hanspub.38324-ref3">3</xref>] 对表情进行分类。随着深度学习的发展，深度学习被应用在了表情识别中。深度神经网络模型能够同时提取图像特征和图像分类，因此也为表情识别带来了极大的便利。</p><p>在计算机视觉中，卷积神经网络由于自身的卷积与池化操作，因此在处理图形图像中比其他的神经网络有更好的性能。本文设计了一种新颖的卷积神经网络结构进行表情特征的提取与分类。本文的模型借鉴了VGG网络的思想，设计了一个卷积网络结构，并对网络结构的参数进行了调整。我们受到GoogLeNet [<xref ref-type="bibr" rid="hanspub.38324-ref4">4</xref>] 网络的启发在卷积神经网络的第一层添加了一个1 * 1的卷积核来增加输入的非线性表示。最后在全连接层我们通过丢弃一部分神经元，来简化了模型的复杂性。</p><p>本文的贡献：1) 借鉴VGG网络思想设计了一种新的卷积神经网络结构。2) 通过Fer-2013数据集训练模型并验证模型识别的准确率。3) 自制了一个在自然状态下人脸表情数据集，并根据自制的数据集验证模型的识别泛化能力。</p></sec><sec id="s6"><title>2. 相关工作</title><p>卷积神经网络分为正向传播和反向传播两个过程，正向传播进行卷积和池化操作，这两个操作是为了提取图像特征和处理图像特征。反向传播是采用BP算法传递误差，从而使用优化算法进行模型参数的更新。</p><p>2012年在ILSVRC挑战赛中，Krizhevsky等人 [<xref ref-type="bibr" rid="hanspub.38324-ref5">5</xref>] 将深度卷积神经网络用于图像分类中，并在挑战赛取得了很好的效果，自此卷积神经网络被广泛应用在图像识别中。陈等人 [<xref ref-type="bibr" rid="hanspub.38324-ref6">6</xref>] 研究了卷积和池化算法识别人脸表情，指出固定池化的一些局限性，并提出动态自适应的池化算法。卢等人 [<xref ref-type="bibr" rid="hanspub.38324-ref7">7</xref>] 和Jeon等人 [<xref ref-type="bibr" rid="hanspub.38324-ref8">8</xref>] 分别通过设计一种卷积神经网络模型进行表情识别，表情识别的准确率不太理想。Arriaga [<xref ref-type="bibr" rid="hanspub.38324-ref9">9</xref>] 等人分别设计了同时识别性别和表情的卷积神经网络。徐等人 [<xref ref-type="bibr" rid="hanspub.38324-ref10">10</xref>] 设计了并行的卷积神经网络识别表情，在模型训练过程中减少了训练时间。为提高识别的准确率，卷积神经网络通常还会融合另一种模型进行表情识别 [<xref ref-type="bibr" rid="hanspub.38324-ref11">11</xref>] [<xref ref-type="bibr" rid="hanspub.38324-ref12">12</xref>]。例如王等人 [<xref ref-type="bibr" rid="hanspub.38324-ref11">11</xref>] 融合了卷积神经网络和支持向量机，卷积神经网络只提取特征，用支持向量机代替全连接层进行分类。黄等人 [<xref ref-type="bibr" rid="hanspub.38324-ref13">13</xref>] 和李等人 [<xref ref-type="bibr" rid="hanspub.38324-ref14">14</xref>] 分别提出了跨连接的卷积神经网络，不同卷积层提取的特征不同，利用跨连接保留不同层的特征从而提高识别率。钱等人 [<xref ref-type="bibr" rid="hanspub.38324-ref15">15</xref>] 使用卷积神经网络提取了不同视角下的人脸表情特征，从而提取的特征比较准确详细更有利于分类表情。</p></sec><sec id="s7"><title>3. CNN结构设计</title><p>卷积神经网络是一种在提取图像特征方面有独特优势的神经网络。表情识别是属于分类监督性学习，利用含有标签的表情图片训练一个卷积神经网络的分类模型。卷积神经网络模型的正向传播是卷积和池化操作，利用反向传播算法传递误差，使用随机梯度下降(stochastic gradient descent, SGD)优化算法对模型的参数进行训练和优化。本文设计的用于表情识别的卷积神经网络由输入层，4个卷积层，3个池化层，2个全连接层和SoftMax层组成，其结构如图1。</p><p>图1. 本文的卷积神经网络结构</p><sec id="s7_1"><title>3.1. 卷积层</title><p>卷积神经网络的卷积层在人脸表情图片上进行卷积操作，提取人脸表情特征。输入层直接用图片像素作为输入值，然后对输入值进行卷积操作。本文采用了不同大小的卷积核进行特征提取，不同大小的卷积核代表了感受野的不同，因而使用了不同的卷积核提取不同感受野的表情特征，卷积层的表达式如公式1。</p><p>C i = f ( x ∗ w i + b i ) (1)</p><p>其中C<sub>i</sub>表示第 个卷积得到的输出结果， 表示激活函数，激活函数选择了修正线性单元函数(Rectified Linear Units, ReLU)，x表示输入的图像值，*表示卷积操作，w<sub>i</sub>表示第 个卷积核，b<sub>i</sub>表示第 个卷积核的偏置。ReLU函数的表达式如公式2。</p><p>ReLU ( y ) = { y , y ≥ 0 0 , y &lt; 0 (2)</p><p>其中 y = x ∗ w i + b i 。本文总共使用了4个卷积层，卷积核大小依次为：1 * 1，5 * 5，3 * 3，3 * 3，卷积核个数依次为32-32-64-128。卷积层之后经过激励层输出，我们在第二层卷积之前使用了1 * 1的卷积核是为了增加输入的非线性表示，同时加深了模型的网络结构，提升模型的表达能力。图片的输入为48 * 48的矩阵，使用32个1 * 1的卷积核卷积后，输出32个48 * 48的特征图。第二层卷积使用5 * 5的卷积核是为了首先在大的感受野内提取特征，之后缩小卷积核的尺寸，在更小的区域内提取特征。在48 * 48的特征图上使用5 * 5的卷积核进行卷积，得到32个(48 – 5 + 1) * (48 – 5 + 1)的特征图，使用32个卷积核是提取了32个不同的局部表情特征，第三和第四个卷积层分别使用了3 * 3的卷积核，每一层网络具体的参数值见表1。</p><p>卷积神经网络的每一层卷积操作都进行了特征提取，本文对每一层不同卷积核提取的特征进行了融合，并对提取的特征图进行了可视化展示。使用了Fer2013数据集中的一张人脸表情图片做了演示，每一层卷积操作提取特征后的特征图如图2所示。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> The parameters of CN</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >网络层</th><th align="center" valign="middle" >输入尺寸</th><th align="center" valign="middle" >卷积核大小</th><th align="center" valign="middle" >池化区域</th><th align="center" valign="middle" >步长</th><th align="center" valign="middle" >有无填充</th><th align="center" valign="middle" >输出尺寸</th></tr></thead><tr><td align="center" valign="middle" >Layer 1 (卷积)</td><td align="center" valign="middle" >48*48</td><td align="center" valign="middle" >32@1*1</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >无</td><td align="center" valign="middle" >32@48*48</td></tr><tr><td align="center" valign="middle" >Layer 2 (卷积)</td><td align="center" valign="middle" >32@48*48</td><td align="center" valign="middle" >32@5*5</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >无</td><td align="center" valign="middle" >32@44*44</td></tr><tr><td align="center" valign="middle" >Layer 3 (池化)</td><td align="center" valign="middle" >32@44*44</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >2*2</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >无</td><td align="center" valign="middle" >32@22*22</td></tr><tr><td align="center" valign="middle" >Layer 4 (卷积)</td><td align="center" valign="middle" >32@22*22</td><td align="center" valign="middle" >64@3*3</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >无</td><td align="center" valign="middle" >64@20*20</td></tr><tr><td align="center" valign="middle" >Layer 5 (池化)</td><td align="center" valign="middle" >64@20*20</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >2*2</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >无</td><td align="center" valign="middle" >64@10*10</td></tr><tr><td align="center" valign="middle" >Layer 6 (卷积)</td><td align="center" valign="middle" >64@10*10</td><td align="center" valign="middle" >128@3*3</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >有</td><td align="center" valign="middle" >128@10*10</td></tr><tr><td align="center" valign="middle" >Layer 7 (池化)</td><td align="center" valign="middle" >128@10*10</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >2*2</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >无</td><td align="center" valign="middle" >128@5*5</td></tr><tr><td align="center" valign="middle" >Layer 8</td><td align="center" valign="middle" >1*3200</td><td align="center" valign="middle"  colspan="4"  >全连接层 Dropout(0.6)</td><td align="center" valign="middle" >1*2048</td></tr><tr><td align="center" valign="middle" >Layer 9</td><td align="center" valign="middle" >1*2048</td><td align="center" valign="middle"  colspan="4"  >全连接层 Dropout(0.4)</td><td align="center" valign="middle" >1*1024</td></tr><tr><td align="center" valign="middle" >Layer 10</td><td align="center" valign="middle" >1*1024</td><td align="center" valign="middle"  colspan="4"  >SoftMax层</td><td align="center" valign="middle" >1*7</td></tr></tbody></table></table-wrap><p>表1. 卷积神经网络结构的参数</p><p>图2. 卷积后的特征</p></sec><sec id="s7_2"><title>3.2. 池化层</title><p>卷积神经网络的池化层通常设计在卷积层之后，特征图的数量会随着卷积层数的增加而增加，然而特征维数的增加会造成维度灾难，因此在卷积层后面通常连接池化层进行降维。本文利用了最大池化操作保持一个池化区域中最显著的特征。池化层可表示为如公式3。</p><p>S i = d o w n ( max ( y a , b ) )       a , b ∈ p i (3)</p><p>其中S<sub>i</sub>表示第i个池化区域的最大池化结果，down(∙)表示下采样过程(保留池化区域的最大值)，y<sub>a</sub><sub>,b</sub>表示池化区域中的值，p<sub>i</sub>表示第i个池化区域。本文网络结构的第三层是池化层，输入第三层的特征图是44 * 44，池化区域为2 * 2，所以在特征图中，2 * 2代表一个池化窗口，每个池化窗口得出一个最大池化结果，因而特征图最终池化的结果为(44/2) * (44/2)。每一层池化层的参数详见表1。</p></sec><sec id="s7_3"><title>3.3. 全连接层</title><p>全连接层的神经元和上一层的神经元两两相连接，从而把特征维度转化为一维数据。本文最后一层池化层连接全连接层，最后一层池化层输出128个卷积的5 * 5的特征图，转化为一维数据为：128 &#215; 5 &#215; 5 = 3200，然后输入1 &#215; 3200的数据到全连接层，全连接层的表示如公式4。</p><p>Full = f ( w &#215; z + b ) (4)</p><p>其中Full表示全连接层输出结果，f(∙)是ReLU激活函数，w代表连接的权重值，z是输入全连接层的值，b是偏置，本文的网络结构设计了两个全连接层，为了降低网络结构的复杂度和防止过拟合，采用了神经元的随机失活(Dropout)。</p></sec><sec id="s7_4"><title>3.4. Softmax</title><p>本文网络结构的最后一层是SoftMax函数把人脸的7种表情进行分类。本层有7个神经元，每个神经元代表一个表情类别，针对每个输入的人脸图片，SoftMax层的7个神经元分别输入0到1之间的概率，输入概率值最大的神经元，则代表此神经元对应的表情概率最大。SoftMax分类的表示如公式5所示。</p><p>p ( y = c | m ; w ) = e w c &#215; m ∑ i = 1 k e w i &#215; m (5)</p><p>其中 p ( y = c | m ; w ) 表示输入的图片m是表情种类 的概率，w为权重参数值(待拟合)，k为类别总数7。表情种类c的取值为{0, 1, 2, 3, 4, 5, 6}。</p></sec></sec><sec id="s8"><title>4. 实验</title><p>本文的实验使用python实现，是基于Keras的深度学习平台上进行，另外我们把其中对比的两篇论文中的模型也使用了Python进行了复现，为了对实验结果公平比较，我们使用了统一数据集对不同模型进行了训练。</p><sec id="s8_1"><title>4.1. 数据集</title><p>本文使用了两个数据集，一个是Fer2013 [<xref ref-type="bibr" rid="hanspub.38324-ref16">16</xref>] 人脸表情数据集，另一个是我们自制的数据集。Fer2013表情数据库有35,886张人脸表情图片，其中训练集有28,708张，验证集和测试集各有3589张。每张灰度图片的大小都是48 * 48，数据集共有7种表情如：生气，厌恶，恐惧，开心，伤心，惊讶，中性。</p><p>Fer2013数据集是在实验室环境下进行的采取，从而不能很好的验证模型在自然状态下的人类表情的识别情况，因此我们从网络上搜索了人类在自然状态下一些表情图片，然后对图片的尺寸，像素，背景等进行了预处理，把图片统一转换为了灰度图。最终形成一个小型的数据集。自制数据集上人脸表情分为了7种表情，共396张图片。本文使用了以上两个数据集共同验证提出的卷积神经网络模型的性能。</p></sec><sec id="s8_2"><title>4.2. 模型的训练</title><p>为了训练更准确的模型，更高效率的利用表情图片，对表情图库经过一系列的随机变换进行了数据扩增，如图3。</p><p>图3. 数据增强</p><p>本文利用的损失函数是多分类的交叉熵损失函数，如公式6：</p><p>loss = − ∑ i = 1 n y i 1 log a i 1 + y i 2 log a i 2 + ⋯ + y i 7 log a i 7 (6)</p><p>其中a是神经元实际的输出值，y是期望输出值。</p><p>训练目标就是最小化损失值，用反向传播算法传播误差值，采用SGD优化算法沿着梯度下降的方向更新参数值。SGD算法如公式7：</p><p>∂ l o s s ∂ θ i 1 = − ∑ i = 1 n θ i 1 a i 1 (7)</p><p>故而参数更新如公式8：</p><p>θ j = θ j − a ∂ l o s s ∂ θ j (8)</p><p>其中θ<sub>j</sub>是待更新参数，a为学习率， ∂ l o s s ∂ θ j 在梯度下降方向减少的值。本模型中的学习率为0.01，为了让训练收敛到最佳结果，本文设置随着训练次数的增加学习率逐渐衰减，故而学习步长逐渐减小。</p><p>本文首先使用了Fer2013数据集中的训练集训练模型，然后用验证集验证识别的准确率，当验证集的准确率下降，损失值上升的时候，停止训练。</p></sec><sec id="s8_3"><title>4.3. 实验结果与分析</title><p>本文把卢 [<xref ref-type="bibr" rid="hanspub.38324-ref7">7</xref>] 等人提出的卷积神经网络模型，李 [<xref ref-type="bibr" rid="hanspub.38324-ref14">14</xref>] 等人提出的LeNet-5模型用python进行了复现。并用Fer2013数据集训练并在测试集上计算了准确率。本文的模型，卢 [<xref ref-type="bibr" rid="hanspub.38324-ref7">7</xref>] 等人的模型以及李 [<xref ref-type="bibr" rid="hanspub.38324-ref14">14</xref>] 等人的模型的训练结果分别如图4~6。</p><p>对于训练结果，我们分别选取在验证集上准确率最高的训练模型，各种模型在测试集中的准确率总结如表2。从表2中可以看出我们提出的模型在测试集上的准确率相对较高，准确率为：72.92%。</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> The accuracy of all mode</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" >迭代次数</th><th align="center" valign="middle" >验证集准确率</th><th align="center" valign="middle" >测试集准确率</th></tr></thead><tr><td align="center" valign="middle" >文献 [<xref ref-type="bibr" rid="hanspub.38324-ref7">7</xref>]</td><td align="center" valign="middle" >76</td><td align="center" valign="middle" >0.5811</td><td align="center" valign="middle" >0.6455</td></tr><tr><td align="center" valign="middle" >文献 [<xref ref-type="bibr" rid="hanspub.38324-ref8">8</xref>]</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" >0.7074</td></tr><tr><td align="center" valign="middle" >LetNet模型 [<xref ref-type="bibr" rid="hanspub.38324-ref14">14</xref>]</td><td align="center" valign="middle" >116</td><td align="center" valign="middle" >0.5646</td><td align="center" valign="middle" >0.7142</td></tr><tr><td align="center" valign="middle" >本文模型</td><td align="center" valign="middle" >76</td><td align="center" valign="middle" >0.6400</td><td align="center" valign="middle" >0.7292</td></tr></tbody></table></table-wrap><p>表2. 各模型的准确率</p><p>图4. 本文模型的训练结果</p><p>图5. 卢等人模型的训练结果</p><p>图6. 李等人模型的训练结果</p><p>本文的模型用Fer2013数据集训练后并保存训练模型，然后用训练的模型识别我们自制数据集中的图片，例如单个图片识别结果如图7。我们对整个我们自制的数据集进行识别，识别结果的混淆矩阵如表3。</p><table-wrap id="table3" ><label><xref ref-type="table" rid="table3">Table 3</xref></label><caption><title> Our dataset confusion matri</title></caption><table><tbody><thead><tr><th align="center" valign="middle"  colspan="10"  >预测</th></tr></thead><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" >生气</td><td align="center" valign="middle" >厌恶</td><td align="center" valign="middle" >恐惧</td><td align="center" valign="middle" >开心</td><td align="center" valign="middle" >伤心</td><td align="center" valign="middle" >惊讶</td><td align="center" valign="middle" >中性</td><td align="center" valign="middle" >识别率</td></tr><tr><td align="center" valign="middle"  rowspan="7"  >实际</td><td align="center" valign="middle" >生气</td><td align="center" valign="middle" >33</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >3</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >89.1891%</td></tr><tr><td align="center" valign="middle" >厌恶</td><td align="center" valign="middle" >5</td><td align="center" valign="middle" >10</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >3</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >45.4545%</td></tr><tr><td align="center" valign="middle" >恐惧</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >22</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >13</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >57.8947%</td></tr><tr><td align="center" valign="middle" >开心</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >134</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >5</td><td align="center" valign="middle" >95.0354%</td></tr><tr><td align="center" valign="middle" >伤心</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >20</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >7</td><td align="center" valign="middle" >66.6667%</td></tr><tr><td align="center" valign="middle" >惊讶</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >39</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >90.6977%</td></tr><tr><td align="center" valign="middle" >中性</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >79</td><td align="center" valign="middle" >92.9412%</td></tr></tbody></table></table-wrap><p>表3. 识别自制数据集的混淆矩阵</p><p>图7. 表情识别结果</p><p>从混淆矩阵中，我们可以看出开心，中性，惊讶表情的识别的准确率比较高，但是在识别厌恶和恐惧表情时识别效果比较差。对于厌恶表情，每个人的表达方式不同，面部表情也有很大差异，所以在识别厌恶表情时，识别结果比较零散，可能会识别成各类表情。识别恐惧表情时，易识别于惊讶，主要是提取眼睛部位的特征时，恐惧和惊讶都容易让人的瞳孔放大，因此恐惧会识别为惊讶。在自制的自然状态下的表情数据集上总体的准确率为337/396 = 85.1010%。</p><p>在表情识别中我们分析了人脸表情和表情识别中存在的几个难点，人类是一种复杂的动物，内心世界也是很丰富的，人脸上的表情有时是多种情感交织在一起，例如人脸表情可能同时存在惊讶，生气，无奈等多种表情，这对于识别就有一定难度。人类有时不同的表情可能表达相同的情感，相同的表情针对不同的人可能情感不同，这就要求严格的提取人脸的细微特征。最后，人类的五官特征都有各自的特色，不能一概而论，例如在表情识别过程中大眼睛的人的表情更容易识别成惊讶或者恐惧。</p></sec></sec><sec id="s9"><title>5. 结论</title><p>卷积神经网络能够自动隐式地学习人脸的表情特征，无需人为提取，可以使用图像的像素点作为输入进行训练模型。本文利用了卷积神经网络处理图片的优点，设计了一种卷积神经网络结构模型进行人脸表情的识别。使用表情数据集Fer2013训练模型，在该数据集上的实验结果表明了所提出方法的优越性。另外我们在自制的自然状态下的数据集上测试该模型的识别泛化能力，泛化能力相对较好。卷积神经网络需要大量的数据集训练，训练的模型才能学到很好的分类效果，因此收集更多自然状态下的人脸表情的图片训练模型，表情识别的模型将更具有泛化能力。</p></sec><sec id="s10"><title>基金项目</title><p>国家自然科学基金(31701517)；北京市社会科学基金(17GLC060)；“十三五”时期北京市属高校高水平教师队伍建设支持计划–青年拔尖人才培育计划项目(CIT&amp;TCD201704039)。</p></sec><sec id="s11"><title>文章引用</title><p>孙丽萍,陈红倩,李 慧. 用于人脸表情识别的卷积神经网络研究 Research on Facial Expression Recognition Based on Convolutional Neural Network[J]. 计算机科学与应用, 2020, 10(10): 1843-1852. https://doi.org/10.12677/CSA.2020.1010194</p></sec><sec id="s12"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.38324-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Kumbhar, M., Jadhav, A. and Patil, M. (2012) Facial Expression Recognition Based on Image Feature. International Journal of Computer and Communication Engineering, 1, 117-119. &lt;br&gt;https://doi.org/10.7763/IJCCE.2012.V1.33</mixed-citation></ref><ref id="hanspub.38324-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Reddy, C., Reddy, U. and Kishore, K. (2019) Facial Emotion Recognition Using NLPCA and SVM. Traitement Du Signal, 36, 13-22. &lt;br&gt;https://doi.org/10.18280/ts.360102</mixed-citation></ref><ref id="hanspub.38324-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">邓洪波, 金连文. 一种基于局部Gabor滤波器组及PCA+LDA的人脸表情识别方法[J]. 中国图象图形学报, 2007, 12(2): 322-329.</mixed-citation></ref><ref id="hanspub.38324-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Szegedy, C., Liu, W., Jia, Y.Q., et al. (2014) Going Deeper with Convolutions. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Columbus, 23-28 June 2014, 1-9.  
&lt;br&gt;https://doi.org/10.1109/CVPR.2015.7298594</mixed-citation></ref><ref id="hanspub.38324-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Krizhevsky, A., Sutskever, I. and Hinton, G. (2012) ImageNet Classification with Deep Convolutional Neural Networks. Advances in Neural Information Processing Systems, 25, 1106-1114.</mixed-citation></ref><ref id="hanspub.38324-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">陈航, 邱晓晖. 基于卷积神经网络和池化算法的表情识别研究[J]. 计算机技术与发展, 2019, 29(1): 61-65.</mixed-citation></ref><ref id="hanspub.38324-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">卢官明, 何嘉利, 闫静杰, 等. 一种用于人脸表情识别的卷积神经网络[J]. 南京邮电大学学报: 自然科学版, 2016, 36(1): 16-22.</mixed-citation></ref><ref id="hanspub.38324-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Jeon, J., et al. (2016) A Real-Time Facial Expression Recognizer Using Deep Neural Network. Proceedings of the 10th International Conference on Ubiquitous Information Management and Com-munication, 1-4.  
&lt;br&gt;https://doi.org/10.1145/2857546.2857642</mixed-citation></ref><ref id="hanspub.38324-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Arriaga, O., Valdenegro-Toro, M. and Plöger, P. (2017) Real-Time Convolutional Neural Networks for Emotion and Gender Classification.</mixed-citation></ref><ref id="hanspub.38324-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">徐琳琳, 张树美, 赵俊莉. 构建并行卷积神经网络的表情识别算法[J]. 中国图象图形学报, 2019, 24(2): 227-236.</mixed-citation></ref><ref id="hanspub.38324-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">王忠民, 李和娜, 张荣. 融合卷积神经网络与支持向量机的表情识别[J]. 计算机工程与设计, 2019, 40(12): 3594-3600.</mixed-citation></ref><ref id="hanspub.38324-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">孙晓, 潘汀, 任福继. 基于ROI-KNN卷积神经网络的面部表情识别[J]. 自动化学报, 2016, 42(6): 883-891.</mixed-citation></ref><ref id="hanspub.38324-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">黄倩露, 王强. 基于跨连特征融合网络的面部表情识别[J]. 计算机工程与设计, 2019, 40(10): 2969-2973.</mixed-citation></ref><ref id="hanspub.38324-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">李勇, 林小竹, 蒋梦莹. 基于跨连接LeNet-5网络的面部表情识别[J]. 自动化学报, 2018, 44(1): 176-182.</mixed-citation></ref><ref id="hanspub.38324-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">钱勇生, 邵洁, 季欣欣, 等. 基于改进卷积神经网络的多视角人脸表情识别[J]. 计算机工程与应用, 2018, 54(24): 12-19.</mixed-citation></ref><ref id="hanspub.38324-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">Goodfellow, I.J., Erhan, D., Carrier, P.L., et al. (2013) Challenges in Representation Learning: A Report on Three Machine Learning Con-tests. Neural Networks, 64, 59-63.</mixed-citation></ref></ref-list></back></article>