<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">OJNS</journal-id><journal-title-group><journal-title>Open Journal of Nature Science</journal-title></journal-title-group><issn pub-type="epub">2330-1724</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/OJNS.2015.32002</article-id><article-id pub-id-type="publisher-id">OJNS-15266</article-id><article-categories><subj-group subj-group-type="heading"><subject>OJNS20150200000_93080642.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>数学与物理</subject><subject> 地球与环境</subject><subject> 信息通讯</subject><subject> 生命科学</subject><subject> 人文社科</subject><subject> 化学与材料</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于块旋转和稀疏表示的图像超分辨率重建
  Image Super Resolution Based on Patch Rotation and Sparse Representation
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>夏</surname><given-names>静满</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>厉</surname><given-names>伟</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>汤</surname><given-names>捷</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>刘</surname><given-names>荣</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>李</surname><given-names>星灿</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff3"><addr-line>重庆长鹏实业(集团)有限公司，重庆</addr-line></aff><aff id="aff2"><addr-line>重庆华福车船电子设备制造有限公司，重庆</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>22</day><month>05</month><year>2015</year></pub-date><volume>03</volume><issue>02</issue><fpage>5</fpage><lpage>11</lpage><history><date date-type="received"><day>Oct.</day>	<month>17th,</month>	<year>2014</year></date><date date-type="rev-recd"><day>Oct.</day>	<month>30th,</month>	<year>2014</year>	</date><date date-type="accepted"><day>Nov.</day>	<month>7th,</month>	<year>2014</year></date></history><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   在智能车应用领域，高分辨率的图像已经成为汽车功能模块中不可或缺的一部分。然而传统的基于稀疏表示的高分辨率图像重建方法中所用的训练样本块特征单一，这就导致需要大量的样本块来训练字典。为了减少训练样本块，本文提出一种基于块旋转策略和稀疏表示的超分辨率重建算法。通过将图像块旋转不同的角度，从而减少样本块，增加特征数量，丰富训练字典的类型。在重建过程中，采用自适应加权求和的方式求得高分辨率图像。实验证明，所提出的方法较传统的方法，不仅在主观质量上有明显的提升，在客观质量上也有较大幅度的提高。 In the intelligent vehicle applications, high resolution image has become an integral part of auto-mobile function module. However, the feature of the training image patch of the traditional sparse representation based reconstruction method is unitary, which leads to a large number of sample patches to train a dictionary. In order to reduce the number of training samples, this paper pro-posed a method based on patch rotation and sparse representation. By rotating the patch for dif-ferent angle, the number of the patches is reduced, the feature of the patch is increased and the dictionary type becomes rich. During the reconstruction process, the adaptive weighted method is used to obtain the high resolution image. Experiments show that, the proposed method compared with the traditional method, not only has significant improvement in subjective quality, but also greatly improves the objective quality.
    
  
 
</p></abstract><kwd-group><kwd>旋转，自适应加权，高分辨率，稀疏表示, Rotation</kwd><kwd> Adaptive Weighted</kwd><kwd> High Resolution</kwd><kwd> Sparse Representation</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>基于块旋转和稀疏表示的图像超分辨率重建<sup> </sup></title><p>夏静满<sup>1</sup>，厉伟<sup>1</sup>，汤捷<sup>1,2</sup>，刘荣<sup>1</sup>，李星灿<sup>2</sup></p><p><sup>1</sup>重庆华福车船电子设备制造有限公司，重庆</p><p><sup>2</sup>重庆长鹏实业(集团)有限公司，重庆</p><p>Email: 515742230@qq.com</p><p>收稿日期：2015年5月3日；录用日期：2015年5月15日；发布日期：2015年5月22日</p><disp-formula id="hanspub.15266-formula2704"><graphic xlink:href="http://html.hanspub.org/file/1-2950059x5_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>在智能车应用领域，高分辨率的图像已经成为汽车功能模块中不可或缺的一部分。然而传统的基于稀疏表示的高分辨率图像重建方法中所用的训练样本块特征单一，这就导致需要大量的样本块来训练字典。为了减少训练样本块，本文提出一种基于块旋转策略和稀疏表示的超分辨率重建算法。通过将图像块旋转不同的角度，从而减少样本块，增加特征数量，丰富训练字典的类型。在重建过程中，采用自适应加权求和的方式求得高分辨率图像。实验证明，所提出的方法较传统的方法，不仅在主观质量上有明显的提升，在客观质量上也有较大幅度的提高。</p><p>关键词 :旋转，自适应加权，高分辨率，稀疏表示</p><disp-formula id="hanspub.15266-formula2705"><graphic xlink:href="http://html.hanspub.org/file/1-2950059x6_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s3"><title>1. 引言</title><p>在现代智能车应用领域，越来越需要高分辨率的图像。然而，在一些条件下，由车载成像设别所拍摄的图像分辨率不高，这就明显的给后续处理和智能控制带来不便。为了在不改变硬件水平的条件下，增加图像的分辨率，超分辨率重建技术越来越受到关注。图像的超分辨率重建方法主要可以分为三个主要的方面：基于插值的方法、基于重建的方法和基于学习的方法。</p><p>基于插值的假设低分辨率图像是由高分辨率图像直接下采样得到的，因此对低分辨率图像进行上采样可获得高分辨率图像。在上采样的过程中，去混叠能力是非常重要的。插值方法又可以分为最近邻插值，双线性插值和双三次插值。最近邻插值相对简单，但是容易出现块效应。双线性插值虽然比最近邻插值复杂，但是有振铃效应。双三次插值最复杂，但是容易出现过拟合现象。</p><p>基于重建的方法是建立在对图像退化模型的合理建模上。这种方法还要结合相关的一些先验信息来重建高分辨率图像。对多张低分辨率图像融合时，最重要的是图像之间的运动估计与配准，精确的运动估计和配准有利于重建出高质量的高分辨率图像[<xref ref-type="bibr" rid="hanspub.15266-ref1">1</xref>] 。目前广泛研究的基于重建的算法有迭代反向投影算法、凸集投影(POCS)算法、最大后验概率(MAP)算法，混合MAP/POCS法等[<xref ref-type="bibr" rid="hanspub.15266-ref2">2</xref>] -[<xref ref-type="bibr" rid="hanspub.15266-ref6">6</xref>] 。基于重建的方法需要大量的先验知识来保证重建图像的质量，但是这就极大的增加了重建所需要的时间，而且对重建过程中初始值的选取有很大的依赖，在重建倍数较大时，重建结果较差。</p><p>最近，基于学习的方法越来越受到关注。Freeman等[<xref ref-type="bibr" rid="hanspub.15266-ref7">7</xref>] 首次提出了基于学习的超分辨率重建概念，其基本思想是利用机器学习的方法训练得到高、低分辨率图像块之间的对应关系，然后利用这种相互之间的关系来预测高分辨率图像块。在文献[<xref ref-type="bibr" rid="hanspub.15266-ref7">7</xref>] 中Freeman等先分别从高、低分辨率图像库中采集对应的高、低分辨率图像块训练集，采用Markov网络模型估计低分辨率和高分辨率图像块间的关系，对于要重建的低分辨率图像将其分块后，用高、低分辨率图像块之间的关系去预测每个待重建图像块在Markov网络的位置，这样就能寻找到和每个待重建图像块对应的高分辨率块，将它们进行组合之后就可以得到一幅高分辨率图像。受流形学习方法的启发，Chang等[<xref ref-type="bibr" rid="hanspub.15266-ref8">8</xref>] 提出了基于局部邻域嵌入(Locally Linear Embeeding, LLE)的单幅图像超分辨率重建方法。为了克服大量的样本块对重建时间的影响，Yang等[<xref ref-type="bibr" rid="hanspub.15266-ref9">9</xref>] 提出的基于稀疏表示的图像超分辨算法。这种方法通过大量对应的高低分辨率图像块的联合学习，强迫它们具有同样的稀疏表示，得到一对高、低分辨率冗余字典。然后，利用稀疏分解可获得待重建低分辨率图像块在低分辨率冗余字典下的稀疏表示，这种稀疏表示可以对高分辨率冗余字典中的原子块进行线性组合，从而得到重建后的高分辨率图像块，然后高分辨率图像就可以通过将这些图像块在考虑块之间的重叠的条件下进行组合便可得到高分辨率图像。</p><p>但是这种传统的基于稀疏表示的方法在训练字典的时候，需要大量的样本，而且不能保证这些样本代表图像的大部分特征。为了克服这个问题，本文提出一种基于块旋转策略和稀疏表示的超分辨率重建算法。通过将图像块旋转不同的角度，从而减少样本块，增加特征数量，丰富训练字典的类型。在重建过程中，采用不同类别自适应加权求和的方式求得高分辨率图像。实验表明，所提出的方法与传统的方法相比，不仅在主观质量上有明显的提升，在客观质量上也有较大幅度的提高。</p></sec><sec id="s4"><title>2. 传统的基于稀疏表示的图像超分辨率重建</title><sec id="s4_1"><title>2.1. 字典训练</title><p>在传统的基于稀疏表示超分辨率重建方法中，首先要训练对应的字典，即高分辨率字典和低分辨率字典。在训练字典之前，需要从训练图像中选取对应的高分辨率图像块和低分辨率图像块。Yang等提出联合字典训练模型[<xref ref-type="bibr" rid="hanspub.15266-ref9">9</xref>] ：</p><disp-formula id="hanspub.15266-formula2706"><label>(1)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/1-2950059x7_hanspub.png"  xlink:type="simple"/></disp-formula><p>式中N和M分别代表高分辨率图像块和低分辨率图像块变换为列向量形式时的维度，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2950059x8_hanspub.png" xlink:type="simple"/></inline-formula>是稀疏表示系数，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2950059x9_hanspub.png" xlink:type="simple"/></inline-formula>表示高分辨率图像块构成的集合，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2950059x10_hanspub.png" xlink:type="simple"/></inline-formula>表示低分辨率图像块构成的集合。</p><p>更进一步的，可以将式(1)简化为如下的形式：</p><disp-formula id="hanspub.15266-formula2707"><label>(2)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/1-2950059x11_hanspub.png"  xlink:type="simple"/></disp-formula><p>式中，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2950059x12_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2950059x13_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2950059x14_hanspub.png" xlink:type="simple"/></inline-formula>。</p></sec><sec id="s4_2"><title>2.2. 约束重建</title><p>对低分辨率图像的重建是分别对每一个低分辨率图像块进行重建的。对于每一个待重建的低分辨率图像块<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2950059x15_hanspub.png" xlink:type="simple"/></inline-formula>，首先利用公式(3)求得在低分辨率字典<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2950059x16_hanspub.png" xlink:type="simple"/></inline-formula>下的稀疏表示系数：</p><disp-formula id="hanspub.15266-formula2708"><label>(3)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/1-2950059x17_hanspub.png"  xlink:type="simple"/></disp-formula><p>强迫高分辨率图像块与低分辨率图像块共享同一个稀疏表示系数，那么高分辨率图像块就可以根据公式(4)来求得：</p><disp-formula id="hanspub.15266-formula2709"><label>(4)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/1-2950059x18_hanspub.png"  xlink:type="simple"/></disp-formula><p>融合所有重建的高分辨率图像块，就得到最终的高分辨率图像输出：</p><disp-formula id="hanspub.15266-formula2710"><label>(5)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/1-2950059x19_hanspub.png"  xlink:type="simple"/></disp-formula></sec></sec><sec id="s5"><title>3. 所提出的方法</title><sec id="s5_1"><title>3.1. 训练块旋转策略</title><p>传统的基于稀疏表示的方法，虽然选取了大量的训练样本块来保证训练字典的质量，但是，当选取的样本块很多时，计算的复杂度明显上升，而且，这些图像块还不一定能够包含多种图像块的特征。所以为了克服这个缺点，本文提出基于块旋转策略的训练样本构成方法。</p><p>假设在某个图像中，选取的训练用高分辨率图像为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2950059x20_hanspub.png" xlink:type="simple"/></inline-formula>，则将这个图像块按照旋转算子作旋转处理。本文中，图像块分别做45度，135度，225度和315度的旋转操作，旋转之后，将这些图像块划归到同一个尺度，以保证训练过程的正确进行，即对这些快做列向量的处理。那么这些虽然在内容上是相同的，但是，进行列向量处理之后，相同的内容就有了不同的表现形式，那么训练得到的字典也就不相同。对于图像块<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2950059x21_hanspub.png" xlink:type="simple"/></inline-formula>，进过上述的旋转过程之后，构成了旋转集合<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2950059x22_hanspub.png" xlink:type="simple"/></inline-formula>。同样的，在低分辨率图像的对应位置，选取了低分辨率图像块集合<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2950059x23_hanspub.png" xlink:type="simple"/></inline-formula>。</p></sec><sec id="s5_2"><title>3.2. 字典训练模型</title><p>在2.1节中，将图像块做旋转之后，高分辨率图像块和低分辨率图像块的集合中所包含的样本数量是明显不同的。而且，高分辨率图像块的样本数是低分辨率图像块样本数的5倍。对于同一个低分辨率图像块<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2950059x24_hanspub.png" xlink:type="simple"/></inline-formula>来说，就会有5个高分辨率的图像块与之相对应。那么，在训练字典的时候，就有必要分别对每一种对应情况做字典训练。也就是说，共形成5种训练样本集：<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2950059x25_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2950059x26_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2950059x27_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2950059x28_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2950059x29_hanspub.png" xlink:type="simple"/></inline-formula>。这样，当选取的高分辨率图像块一定时，通过旋转处理，就得到不同的特征表现形式。对每一种情况做字典训练，就得到如下的联合字典训练模型：</p><disp-formula id="hanspub.15266-formula2711"><label>(6)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/1-2950059x30_hanspub.png"  xlink:type="simple"/></disp-formula><p>式中，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2950059x31_hanspub.png" xlink:type="simple"/></inline-formula>分别是未经旋转，旋转45度，旋转135度，旋转225度，以及旋转315度时所获得的字典。在训练字典的过程中，主要采用文献[<xref ref-type="bibr" rid="hanspub.15266-ref9">9</xref>] 中的联合字典训练的方法得到对应的字典。</p><p>通过旋转处理来训练字典一个明显的好处是，减少了从原始图像中提取的图像块的数量，以及保证了特征的多种表现形式。只需要选取少量的图像块，就可以实现字典表现的完整性。</p></sec><sec id="s5_3"><title>3.3. 加权重建模型</title><p>对于每一个待重建的低分辨率图像块<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2950059x32_hanspub.png" xlink:type="simple"/></inline-formula>，首先用训练得到的低分辨率字典<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2950059x33_hanspub.png" xlink:type="simple"/></inline-formula>求得其稀疏表示系数<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2950059x34_hanspub.png" xlink:type="simple"/></inline-formula>。然后，分别用训练得到的五个高分辨率字典得到对应的图像块：</p><disp-formula id="hanspub.15266-formula2712"><label>(7)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/1-2950059x35_hanspub.png"  xlink:type="simple"/></disp-formula><disp-formula id="hanspub.15266-formula2713"><label>(8)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/1-2950059x36_hanspub.png"  xlink:type="simple"/></disp-formula><disp-formula id="hanspub.15266-formula2714"><label>(9)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/1-2950059x37_hanspub.png"  xlink:type="simple"/></disp-formula><disp-formula id="hanspub.15266-formula2715"><label>(10)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/1-2950059x38_hanspub.png"  xlink:type="simple"/></disp-formula><disp-formula id="hanspub.15266-formula2716"><label>(11)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/1-2950059x39_hanspub.png"  xlink:type="simple"/></disp-formula><p>这五类高分辨率的图像块得到之后，一个可行的办法就是将这五类图像块进行融合，得到最终的高分辨率图像块。本文提出一种自适应加权的块融合方法。公式(7)就是传统的基于稀疏表示的图像重建公式。虽然由公式(7)重建的图像块可以作为高分辨率图像块的近似，但是，这种方法重建的结果中容易出现振铃和瑕疵。将此结果作为初始结果，本文提出的自适应加权的重建模型如下：</p><disp-formula id="hanspub.15266-formula2717"><label>(12)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/1-2950059x40_hanspub.png"  xlink:type="simple"/></disp-formula><p>式中，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2950059x41_hanspub.png" xlink:type="simple"/></inline-formula>是非常小的数，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2950059x42_hanspub.png" xlink:type="simple"/></inline-formula>是指数参数。通过融合所有的图像块，就得到初始的高分辨率图像<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2950059x43_hanspub.png" xlink:type="simple"/></inline-formula>。</p></sec><sec id="s5_4"><title>3.4. 后处理模型</title><p>低分辨率图像的获取模型一般表示为：</p><disp-formula id="hanspub.15266-formula2718"><label>(13)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/1-2950059x44_hanspub.png"  xlink:type="simple"/></disp-formula><p>为了使得重建的图像满足低分辨率图像的获取模型，以及提升重建图像的质量，采用全局约束后处理模型来优化最终的结果。这种全局优化模型表示为：</p><disp-formula id="hanspub.15266-formula2719"><label>(14)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/1-2950059x45_hanspub.png"  xlink:type="simple"/></disp-formula><p>此公式可以用简单的梯度下降算法来求解。</p></sec></sec><sec id="s6"><title>4. 实验验证分析</title><sec id="s6_1"><title>4.1. 实验设置</title><p>所有的实验都是在CPU为2.80 GHz和2.90 GB内存的台式电脑上实现。我们选择30幅图像作为训练图像，测试图像如图1所示。选取30,000个图像块来训练字典。字典大小设置为512。块大小设置为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2950059x46_hanspub.png" xlink:type="simple"/></inline-formula>，</p><p>图1. 测试图像</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> PSNR and SSIM by different method</title></caption><table><tbody><thead><tr><th align="center" valign="middle"  rowspan="2"  >Image</th><th align="center" valign="middle"  rowspan="2"  >Measures</th><th align="center" valign="middle"  colspan="4"  >Methods</th></tr></thead><tr><td align="center" valign="middle" >Bicubic</td><td align="center" valign="middle" >LLE</td><td align="center" valign="middle" >SCSR</td><td align="center" valign="middle" >所提方法</td></tr><tr><td align="center" valign="middle"  rowspan="2"  >Butterfly</td><td align="center" valign="middle" >PSNR</td><td align="center" valign="middle" >25.71</td><td align="center" valign="middle" >25.26</td><td align="center" valign="middle" >27.11</td><td align="center" valign="middle" >27.75</td></tr><tr><td align="center" valign="middle" >SSIM</td><td align="center" valign="middle" >0.889</td><td align="center" valign="middle" >0.870</td><td align="center" valign="middle" >0.910</td><td align="center" valign="middle" >0.921</td></tr><tr><td align="center" valign="middle"  rowspan="2"  >Peppers</td><td align="center" valign="middle" >PSNR</td><td align="center" valign="middle" >29.28</td><td align="center" valign="middle" >28.87</td><td align="center" valign="middle" >30.28</td><td align="center" valign="middle" >30.79</td></tr><tr><td align="center" valign="middle" >SSIM</td><td align="center" valign="middle" >0.898</td><td align="center" valign="middle" >0.882</td><td align="center" valign="middle" >0.910</td><td align="center" valign="middle" >0.919</td></tr><tr><td align="center" valign="middle"  rowspan="2"  >Lena</td><td align="center" valign="middle" >PSNR</td><td align="center" valign="middle" >29.79</td><td align="center" valign="middle" >29.95</td><td align="center" valign="middle" >30.76</td><td align="center" valign="middle" >31.01</td></tr><tr><td align="center" valign="middle" >SSIM</td><td align="center" valign="middle" >0.824</td><td align="center" valign="middle" >0.816</td><td align="center" valign="middle" >0.847</td><td align="center" valign="middle" >0.853</td></tr><tr><td align="center" valign="middle"  rowspan="2"  >Parrot</td><td align="center" valign="middle" >PSNR</td><td align="center" valign="middle" >30.70</td><td align="center" valign="middle" >29.99</td><td align="center" valign="middle" >31.86</td><td align="center" valign="middle" >32.01</td></tr><tr><td align="center" valign="middle" >SSIM</td><td align="center" valign="middle" >0.880</td><td align="center" valign="middle" >0.864</td><td align="center" valign="middle" >0.897</td><td align="center" valign="middle" >0.900</td></tr><tr><td align="center" valign="middle"  rowspan="2"  >Koala</td><td align="center" valign="middle" >PSNR</td><td align="center" valign="middle" >29.43</td><td align="center" valign="middle" >29.01</td><td align="center" valign="middle" >30.32</td><td align="center" valign="middle" >30.73</td></tr><tr><td align="center" valign="middle" >SSIM</td><td align="center" valign="middle" >0.806</td><td align="center" valign="middle" >0.787</td><td align="center" valign="middle" >0.841</td><td align="center" valign="middle" >0.845</td></tr><tr><td align="center" valign="middle"  rowspan="2"  >Moth</td><td align="center" valign="middle" >PSNR</td><td align="center" valign="middle" >25.99</td><td align="center" valign="middle" >25.95</td><td align="center" valign="middle" >27.16</td><td align="center" valign="middle" >27.71</td></tr><tr><td align="center" valign="middle" >SSIM</td><td align="center" valign="middle" >0.825</td><td align="center" valign="middle" >0.806</td><td align="center" valign="middle" >0.852</td><td align="center" valign="middle" >0.868</td></tr><tr><td align="center" valign="middle"  rowspan="2"  >Tiger</td><td align="center" valign="middle" >PSNR</td><td align="center" valign="middle" >24.53</td><td align="center" valign="middle" >23.85</td><td align="center" valign="middle" >25.49</td><td align="center" valign="middle" >25.74</td></tr><tr><td align="center" valign="middle" >SSIM</td><td align="center" valign="middle" >0.805</td><td align="center" valign="middle" >0.763</td><td align="center" valign="middle" >0.848</td><td align="center" valign="middle" >0.856</td></tr></tbody></table></table-wrap><p>表1. 不同方法的PSNR和SSIM值</p><p>重叠4个像素。用峰值信噪比(PSNR)和结构相似度(SSIM)来评价重建图像的客观质量。实验中，将双三次插值(Bicubic)、局部线性嵌入(LLE)和传统的基于稀疏表示的重建方法(SCSR)与本文方法对比。</p></sec><sec id="s6_2"><title>4.2. 实验结果</title><p>表1中展示了不同算法重建的图像其PSNR和SSIM值。从表1中可以看出SCSR方法相比Bicubic、LLE方法有明显提高，而且与学习方法中的LLE方法相比也有较大幅度的提高。本文所提出的方法与SCSR方法相比，在PSNR和SSIM上均有提高。这是由于将训练图像块做旋转处理之后，增加了特征数量，而且字典所表征的特征也更多。</p><p>为了展示不同算法的视觉效果，我们选取了Parrot的重建结果以及局部放大图像，如图2所示。从图中我们可以观察到双三次插值不能很好地重建高频细节，而且图像出现模糊。虽然LLE方法能够恢复一些高频细节，但是在重建结果中出现明显的块效应，重建结果不真实。SCSR方法能够复原大量的高频细节和尖锐的边缘，但是在重建结果中出现模糊的边缘和不准确的几何结构。本文所提的方法不仅能够重建较好的边缘，纹理和细节，而且视觉效果更好。</p></sec></sec><sec id="s7"><title>5. 结论</title><p>为了克服智能车应用领域，获取图像的分辨率较低的问题，本文提出一种基于块旋转策略和稀疏表示的图像超分辨率重建方法。在稀疏表示模型下，块旋转策略主要是为了减少样本量，增加样本特征数据。为了重建高分辨率图像，提出一种自适应加权融合的图像重建方法。实验结果证明了所提方法在汽</p><disp-formula id="hanspub.15266-formula2720"><graphic xlink:href="http://html.hanspub.org/file/1-2950059x48_hanspub.png"  xlink:type="simple"/></disp-formula><p>(a) (b) (c)</p><p>图2. 不同方法3倍重建的Parrot图像；(a) Bicubic；(b) LLE；(c) SCSR；(d) 所提方法；(e) 原始高分辨率图像</p><p>车功能模块的研发设计中具有一定的应用潜力。</p></sec><sec id="s8"><title>基金项目</title><p>重庆市应用开发计划项目(cstc2013yykfC60006)，重庆市应用开发计划项目(cstc2013yykfB60006)。</p></sec><sec id="s9"><title>文章引用</title><p>夏静满,厉 伟,汤 捷,刘 荣,李星灿, (2015) 基于块旋转和稀疏表示的图像超分辨率重建Image Super Resolution Based on Patch Rotation and Sparse Representation. 自然科学,02,5-11. doi: 10.12677/OJNS.2015.32002</p></sec><sec id="s10"><title>参考文献 (References)</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.15266-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">刘良辰 (2012) 基于整体到局部的分布式人脸超分辨率重建策略. 重庆大学硕士学论文, 重庆.</mixed-citation></ref><ref id="hanspub.15266-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Irani, M. and Peleg, S. (1991) Improving resolution by image registration. CVGIP: Graphical Models and Image Proceedings, 53, 231-239.</mixed-citation></ref><ref id="hanspub.15266-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Takeda, H. and Kskoui, P. (1989) High resolution image recovery from image-plane array using convex projections. Journal of the Optical Society of America A, 6, 715-726.</mixed-citation></ref><ref id="hanspub.15266-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">孟庆武 (2004) 预估计混叠度的 MAP 超分辨率处理算法. 软件学报, 2, 207-214.</mixed-citation></ref><ref id="hanspub.15266-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">杨妮 (2011) 基于混合MAP/POCS的序列图像超分辨率重建算法研究. 昆明理工大学, 昆明.</mixed-citation></ref><ref id="hanspub.15266-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Su, B.H. and Jin, W.Q. (2003) POCS-MAP based super-resolution image restoration. Acta Photonica Sinica, 32, 502- 504.</mixed-citation></ref><ref id="hanspub.15266-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Freeman, W.T., Jones, T.R. and Pasztor, E.C. (2002) Exam-ple-based super-resolution. IEEE Computer Graphics and Applications, 22, 56-65.</mixed-citation></ref><ref id="hanspub.15266-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Chang, H., Yenng, D.Y. and Xiong, Y. (2004) Super-resolution through neighbor embedding. IEEE Computer Society Conference on Computer Vi-sion and Pattern Recognition, 1, 275-282.</mixed-citation></ref><ref id="hanspub.15266-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Yang, J.C., Wright, J. and Huang, T. (2010) Image super-Resolution via sparse representation. IEEE Transaction on Image Processing, 19, 2861-2873.</mixed-citation></ref></ref-list></back></article>