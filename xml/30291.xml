<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2019.95101</article-id><article-id pub-id-type="publisher-id">CSA-30291</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20190500000_69445603.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  行人重识别算法研究与展望
  Research and Prospect of Person Re-Identification Algorithm
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>林</surname><given-names>染染</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib></contrib-group><aff id="aff1"><label>1</label><addr-line>null</addr-line></aff><aff id="aff2"><label>1</label><addr-line>中南民族大学电子信息工程学院，湖北 武汉</addr-line></aff><pub-date pub-type="epub"><day>08</day><month>05</month><year>2019</year></pub-date><volume>09</volume><issue>05</issue><fpage>896</fpage><lpage>903</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   针对视频监控中特定行人的检索、识别问题被称作行人重识别，是当前计算机视觉领域一个重要的研究课题。由于实际监控场景的复杂性，被拍摄到的行人图片会出现尺度变化、旋转、遮挡、光照差异等问题，给行人重识别研究带来了很大的挑战。提取鲁棒的行人特征、设计合适的度量方法、对查询的排序结果列表进行重新排序等是目前该领域研究的主要思路。针对行人重识别领域，本文主要调查研究了行人重识别领域的发展背景和研究现状并在结尾给出了对该领域的研究展望。 The retrieval and recognition of a specific pedestrian is called person re-identification, which has been an important topic in the field of computer vision. Since images captured in surveillance are often involved scale variation, rotation, occlusions and changing illumination, person re-identification remains very challenging. Current research mainly focuses on three aspects: robust feature representations, metric learning and re-Ranking. In this paper, we mainly focus on the history and related works of person re-identification and give the further work of this task. 
  
 
</p></abstract><kwd-group><kwd>行人重识别，特征表达，度量学习，重排序, Person Re-Identification</kwd><kwd> Feature Representation</kwd><kwd> Metric Learning</kwd><kwd> Re-Rank</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>行人重识别算法研究与展望<sup> </sup></title><p>林染染</p><p>中南民族大学电子信息工程学院，湖北 武汉</p><p><img src="//html.hanspub.org/file/9-1541393x1_hanspub.png" /></p><p>收稿日期：2019年5月1日；录用日期：2019年5月13日；发布日期：2019年5月20日</p><disp-formula id="hanspub.30291-formula75"><graphic xlink:href="//html.hanspub.org/file/9-1541393x5_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>针对视频监控中特定行人的检索、识别问题被称作行人重识别，是当前计算机视觉领域一个重要的研究课题。由于实际监控场景的复杂性，被拍摄到的行人图片会出现尺度变化、旋转、遮挡、光照差异等问题，给行人重识别研究带来了很大的挑战。提取鲁棒的行人特征、设计合适的度量方法、对查询的排序结果列表进行重新排序等是目前该领域研究的主要思路。针对行人重识别领域，本文主要调查研究了行人重识别领域的发展背景和研究现状并在结尾给出了对该领域的研究展望。</p><p>关键词 :行人重识别，特征表达，度量学习，重排序</p><disp-formula id="hanspub.30291-formula76"><graphic xlink:href="//html.hanspub.org/file/9-1541393x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2019 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/9-1541393x7_hanspub.png" /> <img src="//html.hanspub.org/file/9-1541393x8_hanspub.png" /></p></sec><sec id="s3"><title>1. 引言</title><sec id="s3_1"><title>1.1. 行人重识别研究背景</title><p>近三十年来，我国在经济发展方面取得了瞩目的成就，人民的生活水平得到了很大的提升。与此同时，我国违法犯罪活动的数量也在近些年来逐年攀升，发生恐怖袭击和暴力事件的次数也急剧增加，犯罪方法也呈现复杂化多样化。为了维护城市的稳定和安全，党和政府给予了高度重视，提出了“安全城市”等项目，在这样的大背景下，智能视频监控系统蓬勃发展。在2013年的数据报道中，我国已经建成世界上最大的监控系统 [<xref ref-type="bibr" rid="hanspub.30291-ref1">1</xref>] ，其中监控摄像头的数量超过了2000万，在600多个城市中投入了超过3200亿元的资金。</p><p>在轰动全国的周克华案件中，为了能够在海量的监控视频中快速的锁定嫌疑人的踪迹，警方调用了大量的人力物力，对成千上万的视频一一进行排查，花费了24小时才锁定犯罪嫌疑人的踪迹。在2013年波士顿马拉松恐怖袭击和2017年拉斯维加斯恐怖袭击中，城市摄像监控都拍摄到了和案件相关的信息，但是面对大量的数据，监控系统并不能完全分析、处理并给出相应的警告，因此无法避免悲剧。</p><p>可以看出，增强视频监控系统对视频内容的分析和处理等能力是极其重要的。仅仅依靠人工排查的方法，不仅耗时耗力，而且效率不高，耗费了大量的社会资源。这也暴露了建设智慧城市的一个重要的问题：具有完善的监控网络，但是监控系统却不能够有效的分析处理监控内容。因此建设一套智能监控系统成为一个亟待解决的问题。其中针对特定行人的检索和跟踪是很重要的一个研究课题，即行人重识别课题。</p></sec><sec id="s3_2"><title>1.2. 行人重识别研究意义</title><p>针对特定行人活动轨迹的跟踪、定位和检索是视频侦查中的关键技术，是模式识别及计算机视觉中重要的研究课题，受到国内外学者的广泛关注。分布式多摄像机监视系统的基本任务是把出现在不同位置和时刻的行人关联起来，我们把这种跨摄像头下针对特定行人对象的视频内容识别检索任务称为行人重识别，即判断某个摄像头下出现的行人是否出现在其他摄像头下。</p><p>传统依靠生物信息的行人识别方法，如人脸识别和虹膜识别在大规模的城市监控中往往是不可行的，因为城市监控摄像头难以捕捉到高清的行人图像信息。相反，基于视觉特征的识别方法往往比基于生物信息的识别方法更加可靠，基于人的外观，比如一个人携带的物品或者行人的衣服，可以更可靠地被利用在行人重新识别。</p><p>图1给出了行人重识别数据集中行人图像相关例子，其中每一列代表同一人。从该图中可以看出，不同摄像机拍摄的行人图片存在分辨率低、视角及光照变化、背景遮挡等问题，会导致行人的外观特征发生一定的变化；另外一个问题是由于摄像头视角不同、光照变化的影响，不同人之间的外观特征往往比相同人的外观更加相似，上述这些问题使得行人重识别具有挑战性。</p><p>行人重识别是计算机视觉中重要的研究方向，并且有着广泛的实际用途。由上述行人重识别中存在的难点，可以看出行人重识别任务具有挑战性的。本文针对行人重识别任务，首先论述该任务的研究背景和实际意义，其次会给出行人重识别任务的研究方向和研究现状，着重从三个(特征提取、度量学习、排序优化)方向介绍该领域中提出的主要的方法，并在文章的结尾给出了本文的总结和对未来工作的展望。</p><p>图1. 行人重识别数据集</p></sec></sec><sec id="s4"><title>2. 行人重识别算法研究</title><sec id="s4_1"><title>2.1. 研究方向</title><p>行人重识别具有广阔的应用前景，包括行人检索、行人跟踪、异常事件检测、行人、动作行为分析等，由于行人重识别具有重要的意义，因此该研究方向吸引了国内外一大批学者和研究机构的关注。国外知名的研究机构包伦敦玛丽女皇学院、悉尼科技大学、斯坦福大学、谷歌、微软等；国内则包括香港中文大学、中山大学、中国科学院自动化研究所、大连理工大学、武汉大学、华中科技大学、商汤科技、Face++等知名研究机构。针对行人重识别问题：研究方向主要集中在以下三个方面：行人的特征表达、相似性度量、排序优化</p><p>行人特征表达：特征表达的目的就把图像转化成便于计算机处理的形式。特征表达主要运用模式识别及计算机视觉中的相关算法提取行人的特征，这些特征可以是常见的纹理特征，颜色特征等。特征表达是行人重识别的重点研究方向，大量的特征被研究学者提出，不仅包括经典的手工设计的特征，如方向梯度直方图(Histogram of Oriented Gradients, HOG)、尺度不变特征变换(Scale Invariant Feature Transform, SIFT)等还包括大量的深度学习模型提取的特征。</p><p>距离度量：得到特征表达后，都需要计算特征之间的相似性，距离度量的作用是衡量两个物体的相似性,不同的度量方式会对相同的样本产生不同的度量结果。最常见的度量方式为欧氏距离度量，即平方和距离，还有如巴氏距离和马氏距离等度量方式。行人重识别中距离度量的目的是找到一个度量空间，使得在该空间可以有效的区分相同的人和不同的人，以此来有效的识别不同的行人。</p><p>排序优化：排序优化是检索任务中常用的手段，行人重识别问题也可以看成是检索问题，即给定待查询行人图片，在库图像检索出相关的行人图片。排序优化的目的是利用已经得到的排序列表中相邻样本间的相关性，对得到的排序列表进行再次排序，达到使排序列表有更高的准确率的目的。</p></sec><sec id="s4_2"><title>2.2. 研究现状</title><p>1) 特征表达</p><p>特征表达是模式识别和计算机视觉研究的重点问题，好的特征表达可以有效的解决识别、分类、分割、跟踪等问题。特征表达是行人重识别问题中重要的研究内容，近些年来，大量的特征提取算法被提出，包括传统手工设计的在简单场景中具有较好鲁棒性的特征，如HOG特征、SIFT特征等；同时，随着深度学习的发展，越来越多基于深度学习的特征提取方法也被大量的提出。</p><p>传统手工设计的特征包含以下典型代表：SDALF(Symmetry-driven Accumulation of Local Features)，由Farenzena等人 [<xref ref-type="bibr" rid="hanspub.30291-ref2">2</xref>] 提出。作者首先对给定的行人图像进行前后景分割，从而有效地去除背景对特征提取的影响，然后把前景行人分为五个部分，再对身体部件提取加权颜色直方图、最大稳定颜色区域和重复结构块特征，并用融合后的特征作为行人的特征表达。</p><p>Zheng等人 [<xref ref-type="bibr" rid="hanspub.30291-ref3">3</xref>] 针对行人图片分别提取Gabor纹理特征和HSV颜色特征，并使用多特征加权融合的方法进行行人特征表达，这种多特征融合方式的行人特征表达方法在行人重识别研究工作中被广泛的使用。</p><p>Kuo等人 [<xref ref-type="bibr" rid="hanspub.30291-ref4">4</xref>] 提出了使用颜色域(Color Name)的方法，来解决行人重识别中光照变化问题，作者使用11种基本颜色(Color Bin)来表示颜色域，使得行人在不同光照下的特征有更强的鲁棒性。作者首先把一张图片分为若干条带，针对每一个条带，把条带中的每一个像素映射到十一维的特征向量，再对条带中提取的特征进行池化操作，以减小维度，最后把不同条带的特征拼接表达行人；同时为了增强特征的鲁棒性，作者使用了不同的特征融合方法，使用高斯加权的方法来给背景像素赋予较小的权重，以降低背景噪声的干扰。该方法提取的特征在很多数据集上都取得了不错的效果。</p><p>中科院自动化所的Liao等人 [<xref ref-type="bibr" rid="hanspub.30291-ref5">5</xref>] 在2015年CVPR上人提出了LOMO(Local Maximal Occurrence Representation)特征。LOMO特征的提取遵循局部区域加权特征融合的方法，作者首先把行人图片划分为六个水平条带，这样做的目的是应对行人姿态的变化；同时图片要经过Retinex算法进行处理，以有效的滤除光照变化对颜色特征提取的影响。再对条带分别提取HSV颜色特征和尺度不变局部值纹理特征，最后融合条带特征，由此构成了行人的最终的特征表达。LOMO特征可以很好的减弱背景噪声的干扰，并且在提取特征的过程中不需要分割前后景，因此特征提取的所需要的时间大大减少。</p><p>相比于手工设计的特征深度学习提取的特征具有更好的鲁棒性，近些年很多基于深度学习的行人重识别算法被提出。</p><p>He等人 [<xref ref-type="bibr" rid="hanspub.30291-ref6">6</xref>] 提出使用空间金字塔(Spatial Pyramid)结构来提取样本特征，对于不同尺度的物体，单一尺度的卷积神经网络结构会导致小尺度物体特征不够鲁棒，为了解决上述问题，作者在网络中加入了金字塔池化结构，对特征图(Feature Map)使用不同尺度的池化模板，以解决上述问题。</p><p>Simonyan等人 [<xref ref-type="bibr" rid="hanspub.30291-ref7">7</xref>] 提出了层数更深的卷积神经网络，通过加深网络模型来增加模型的拟合能力，以提取更加鲁棒的特征表达。并且使用3*3卷积核替代5*5卷积核，用以提取更加精细的特征，同时有利于网络的加深。</p><p>Zheng等人 [<xref ref-type="bibr" rid="hanspub.30291-ref8">8</xref>] 提出使用孪生卷积神经网络来提取行人特征，首先把行人组合成不同的样本对，送入孪生卷积神经网络，分别提取行人特征，对于提取的行人特征，作者同时使用判别损失(Verification Loss)和分类损失(Classification Loss)去监督网络训练，其中判别损失用来判别样本对是否属于同一人，分类损失用来预测样本所属类别。</p><p>Lin等人 [<xref ref-type="bibr" rid="hanspub.30291-ref9">9</xref>] 提出使用行人属性信息和卷积神经网络来监督网络训练。作者首先在数据集上标注了行人的属性信息，随后使用标注的行人属性数据参加网络训练的训练过程；使用ResNet50网络作为特征模型，并且使用行人的身份信息和行人属性信息同时训练网络，以此来获取更加鲁棒的行人特征表达，该方法在两个常用数据集上都取得了不错的效果。</p><p>Liu等人 [<xref ref-type="bibr" rid="hanspub.30291-ref10">10</xref>] 提出一种权重自适应模型，用于处理输入的视频序列。作者首先使用卷积神经网络提取特征，同时通过特征生成注意力得分，再用生成的注意力得分指导特征的融合。</p><p>2) 度量学习</p><p>在传统的图像分类等任务中，最常使用的是欧氏距离，即平方和距离。欧式距离可以认为在进行距离度量时对特征空间的每个维赋予相同权重，但是这种度量方法用在行人重识别中效果并不理想，因为多个摄像头捕捉到的同一行人图片，往往会有不同角度的旋转和光照及姿态的变化，仅使用欧式度量往往不能很好地区分出不同的行人，因此很多度其他量学习方法被提出。</p><p>Weinberger等人 [<xref ref-type="bibr" rid="hanspub.30291-ref11">11</xref>] 于2006年提出了基于大间隔近邻的度量学习算法(Large Margin Nearest Neighbor, LMNN)。该算法把行人( x i )、与该行人相同身份的图片( x j )、和与该行人身份不同的图片( x k )组合起来，</p><p>构成一个三元组即 ( x i , x j , x k ) ，其中 ( x i , x j ) 属于相同类别， ( x i , x k ) 属于不同类别。并要求相同类别样本</p><p>的距离尽可能的近，不同类别样本的距离尽可能的远，并且不同样本的距离要比相同类样本距离大。作者使用hinge损失编码上面的约束条件，将问题变成一个凸优化问题，该算法的复杂度低，分类效果好，许多学者在该方法的基础上进行了相关改进。</p><p>Kostinger等人 [<xref ref-type="bibr" rid="hanspub.30291-ref12">12</xref>] 提出了KISSME(Keep It Simple and Straightforward Metric)度量学习算法，该方法通过对数几率判断两个行人是否相似，作者认为相同行人的不同图像特征之间的差值分布符合高斯分布，</p><p>即同一行人的样本特征之间的差值 Δ x i , j = x i − x j 符合均值为零，协方差为 ∑ I 的高斯分布；同理，不同行人之间样本特征差值 Δ x i , j = x i − x j 也符合这一规律，即均值为零协方差矩阵为 ∑ E 的高斯分布。通过计算两个样本对之间相似与不相似的概率比值，即几率(odds)，再对几率取对数，可以发现样本间的距离可以转化成马氏距离的形式 d ( x i , x j ) = Δ T x i , j ( ∑ I − 1 − ∑ E − 1 ) Δ x i , j ，可以看出 ∑ I − 1 − ∑ E − 1 正好可以看成马氏距离中的</p><p>半正定矩阵M。KISSME不同于传统的机器学习算法，很多传统的机器学习算法往往没有闭式解，需要迭代求得最优解；KISSME则可以求得闭式解，其求解过程可以节约大量的计算时间，因此KISSME算法的运算速度很快。</p><p>Liao等人 [<xref ref-type="bibr" rid="hanspub.30291-ref5">5</xref>] 在2015年CVPR上提出了跨视角二次判别分析(Cross-view Quadratic Discriminant Analysis, XQDA)距离度量算法。该方法首先通过优化目标函数，得到降维特征空间，再在降维后的特征空间中使用KISSME算法。降维过程仍然保留了大量的有效信息，因此和KISSME算法相比XQDA计算速度更快，而且精度损失不大。</p><p>Pedagadi等人 [<xref ref-type="bibr" rid="hanspub.30291-ref13">13</xref>] 提出了一种基于局部费歇尔判别分析(Local Fisher Discrimination Analysis, LFDA)的方法，作者首先对特征进行主成分分析(Principal Component Analysis, PCA)降维，并对降维后的特征行进Fisher判别分析，该方法进行相似性度量时并不是对所有样本给予相同的权重，因此可以很好的解决正负样本数据量不平衡的问题。</p><p>Hao等人 [<xref ref-type="bibr" rid="hanspub.30291-ref14">14</xref>] 提出了一种局部度量学习的方法，该方法使用KISSME对行人样本进行局部相似性判别分析，避免了传统的距离度量需要满足行人正负样本对间相似和不相似带来的冲突问题。</p><p>Sen等人 [<xref ref-type="bibr" rid="hanspub.30291-ref15">15</xref>] 将三元组约束用于深度神经网络，由于异常样本(Impostors)具有更好的判别性，因此该算法设计了一种对称最大间隔目标函数，该函数使异常样本和正样本对间的距离小于负样本对间的距离，较传统的只使用正负样本对的方法，该方法具有更好的度量性能。</p><p>Chen等人 [<xref ref-type="bibr" rid="hanspub.30291-ref16">16</xref>] 提出了四元组损失函数用于行人重识别，该损失函数是三元组的改进版本，需要四张图片组成四元组，包含了锚点图片A (Anchor)，和锚点图片相同标签的图片P(Positive)，和锚点不同标签的图片N1 (Negative)、N2 (Negative)，且N1、N2标签不同。四元组损失中考虑了负样本与负样本之间的距离约束，可以学到更优的度量空间。</p><p>3) 基于排序优化的方法</p><p>针对检索问题，由于算法层面的原因，很多时候无法通过一次排序就得到很好的结果，因此需要跟据相关方法对排序列表进行重新排序，利用样本间的相互关系，例如基于近邻关系样本相似性关系或不相似性关系，进一步优化排序结果，从而获得更加准确的排序结果。在行人重识别问题中，也常常使用排序优化方法，有大量的学者在进行排序优化方法的研究。</p><p>Ali等人 [<xref ref-type="bibr" rid="hanspub.30291-ref17">17</xref>] 在反馈查询阶段，手工标注出与查询样本相同和不相同的图像，并根据手工标注的样本对，对模型进行重新训练，从而得到更优的模型，最后得到优化后的排序列表。</p><p>Garcia等人 [<xref ref-type="bibr" rid="hanspub.30291-ref18">18</xref>] 提出了一种非监督位置排序(Post Ranking)的方法，以解决由于模糊而导致的排序精度下降的问题。一旦初步排序形成，提取排序列表中的上下文信息，以消除排序中因模糊而产生的错误排序。该工作通过正确的上下文排序样本消除错误排序样本，具有一定借鉴意义。</p><p>Hirzer [<xref ref-type="bibr" rid="hanspub.30291-ref19">19</xref>] 等运用隐式相关反馈方法，对初始结果进行优化排序。在初始的排序序列中，自动地将排在前面行人图像的作为正样本，排在末尾的作为负样本，并以此来不断更新度量方式，从而优化排序结果。该工作摆脱人工标记，自动通过手工的方式对初始结果进行排序优化，具有较强的借鉴和指导意义，在领域内得到了较大的关注。</p><p>Wang等人 [<xref ref-type="bibr" rid="hanspub.30291-ref20">20</xref>] 针对实际场景中训练样本不足的问题，提出了增量学习的行人重识别模型，该方法不需要大量的数据集对模型进行预训练，因此可以很好的适应实际应用场合。该方法首先人工标注查询列表中行人，再根据标注后的结果重新训练模型，再次人工标注相关样本，几轮的训练就可以得到不错的识别结果。</p><p>Wang等人 [<xref ref-type="bibr" rid="hanspub.30291-ref21">21</xref>] 提出了一种基于特征融合的深度排序模型，通过约束条件“同类行人之间的距离大于不同类别行人时间的距离”的约束条件来训练网络，利用深度模型进行优化排序，以学习到更好的特征。</p><p>Zhong等人 [<xref ref-type="bibr" rid="hanspub.30291-ref22">22</xref>] 提出一种基于互近邻(Reciprocal)的重排序方法。作者认为两张相似图像各自的查询列表中会大量存在相同的图片，即相似的图片会有大量的共同近邻图片。在具体实现中，一张图片的特征表达不仅和自身相关还和该图片的近邻图片相关，即用该图片和它的近邻图片共同表达该行人。</p></sec></sec><sec id="s5"><title>3. 总结</title><p>行人重识别技术在实际生活中有着广泛的应用，在维护治安协助案件侦破中起到了重要，因此得到了学术界的持续关注与研究。但是实际监控场景往往是复杂的，被拍摄到的行人会出现尺度和光照变化、旋转、遮挡等问题，这些难点使得行人重识别是一项具有挑战性的任务。本文主要介绍了行人重识别领域近些年来的研究成果及现状，着重从三点出发介绍了针对行人重识别中的难点问题，人们所采取的解决方案。当前行人重识别算法研究主要体现在行人特征的提取、度量学习和排序优化等环节，具体来说，首先对原始行人图像进行特征提取、变换而得到抽象的行人描述，然后通过学习一个距离度量函数，对行人的特征进行相识性判别，从而得到初步的排序列表，最后再跟据相关排序优化方法优化原始排序列表，得到最终的行人识别结果。</p><p>在特征提取、度量学习和排序优化的基础上，行人重识别技术研究还应该结合实际的应用场景，本文认为有以下几个方向可以作为研究的思路</p><p>1) 学术界研究使用的数据集，无法很好的代表实际场景，实际场景获取的视频或图像往往会存在低分辨率、光照严重不足等问题。因此需要在现有的鲁棒性特征提取方法的基础上继续做改进，以用于实际场景。</p><p>2) 大多数行人重识别算法都是监督学习，需要大量的标记数据集。训练样本的采集过程往往耗时耗力，基于半监督、无监督的方向进行行人重识别的研究是未来的一种趋势，这种方式也更加符合实际需求。</p><p>3) 由于实际场景的复杂性，实际应用中往往需要检测、识别、跟踪同时进行。因此，在识别的基础上加入检测和跟踪是行人重识别走向实际场景的必经之路。</p></sec><sec id="s6"><title>文章引用</title><p>林染染. 行人重识别算法研究与展望Research and Prospect of Person Re-Identification Algorithm[J]. 计算机科学与应用, 2019, 09(05): 896-903. https://doi.org/10.12677/CSA.2019.95101</p></sec><sec id="s7"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.30291-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">徐瑞哲. 我国视频监控网世界最大[N]. 解放日报, 2013-12-15.</mixed-citation></ref><ref id="hanspub.30291-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Farenzena, M., Bazzani, L., Perina, A., et al. (2010) Person Re-Identification by Symmetry-Driven Accumulation of Local Features. IEEE Computer Society Confer-ence on Computer Vision and Pattern Recognition, San Francisco, 13-18 June 2010, 2360-2367. https://doi.org/10.1109/CVPR.2010.5539926</mixed-citation></ref><ref id="hanspub.30291-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Zheng, L., Bie, Z., Sun, Y., et al. (2016) MARS: A Video Bench-mark for Large-Scale Person Re-Identification. In: Computer Vision, Springer International Publishing, Berlin, 868-884. https://doi.org/10.1007/978-3-319-46466-4_52</mixed-citation></ref><ref id="hanspub.30291-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Kuo, C.H., Khamis, S. and Shet, V. (2013) Person Re-Identification Using Semantic Color Names and Rank-Boost. 2013 IEEE Workshop on Applications of Computer Vision, Pinellas County, 15-17 January 2013, 281-287.  
https://doi.org/10.1109/WACV.2013.6475030</mixed-citation></ref><ref id="hanspub.30291-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Liao, S., Hu, Y., Zhu, X., et al. (2015) Person Re-Identification by Local Maximal Occurrence Representation and Metric Learning. IEEE Conference on Computer Vision and Pattern Recognition, Boston, 7-12 June 2015, 2197-2206.  
https://doi.org/10.1109/CVPR.2015.7298832</mixed-citation></ref><ref id="hanspub.30291-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">He, K., Zhang, X., Ren, S., et al. (2015) Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence, 37, 1904-1916.  
https://doi.org/10.1109/TPAMI.2015.2389824</mixed-citation></ref><ref id="hanspub.30291-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Simonyan, K. and Zisserman, A. (2014) Very Deep Convolutional Networks for Large-Scale Image Recognition.</mixed-citation></ref><ref id="hanspub.30291-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Zhang, L., Xiang, T. and Gong, S. (2016) Learning a Discrimina-tively Learn Discriminative Null Space for Person Re-Identification. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Las Vegas, 27-30 June 2016, 1239-1248. https://doi.org/10.1109/CVPR.2016.139</mixed-citation></ref><ref id="hanspub.30291-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Lin, Y., Zheng, L., Zheng, Z., et al. (2017) Improving Person Re-Identification by Attribute and Identity Learning.</mixed-citation></ref><ref id="hanspub.30291-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Liu, Y., Yan, J. and Ouyang, W. (2017) Quality Aware Net-work for Set to Set Recognition. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, 21-26 July 2017, 5790-5799.  
https://doi.org/10.1109/CVPR.2017.499</mixed-citation></ref><ref id="hanspub.30291-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Weinberger, K.Q. and Saul, L.K. (2009) Distance Metric Learning for Large Margin Nearest Neighbor Classification. Journal of Machine Learning Research, 10, 207-244.</mixed-citation></ref><ref id="hanspub.30291-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Koestinger, M., Hirzer, M., Wohlhart, P., et al. (2012) Large Scale Metric Learning from Equivalence Constraints. 2012 IEEE Con-ference on Computer Vision and Pattern Recognition, Providence, 16-21 June 2012, 2288-2295.  
https://doi.org/10.1109/CVPR.2012.6247939</mixed-citation></ref><ref id="hanspub.30291-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Pedagadi, S., Orwell, J., Velastin, S., et al. (2013) Local Fisher Dis-criminant Analysis for Pedestrian Re-Identification. Proceedings of the IEEE Conference on Computer Vision and Pat-tern Recognition, Portland, 23-28 June 2013, 3318-3325. https://doi.org/10.1109/CVPR.2013.426</mixed-citation></ref><ref id="hanspub.30291-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">Hao, C. (2014) Person Re-Identification via Locally Biased Metric Learning. Applied Mechanics and Materials, 687, 3932-3935. https://doi.org/10.4028/www.scientific.net/AMM.687-691.3932</mixed-citation></ref><ref id="hanspub.30291-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">Li, S., Jing, X.Y., Zhu, X., et al. (2017) Deep Metric Learning with Symmetric Triplet Constraint for Person Re-Identification. In: International Conference on Neural Information Processing, Springer, Cham, 632-641.  
https://doi.org/10.1007/978-3-319-70090-8_64</mixed-citation></ref><ref id="hanspub.30291-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">Chen, W., Chen, X., Zhang, J., et al. (2017) Beyond Triplet Loss: A Deep Quadruplet Network for Person Re-Identification. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, 21-26 July 2017, 403-412. &lt;br&gt;https://doi.org/10.1109/CVPR.2017.145</mixed-citation></ref><ref id="hanspub.30291-ref17"><label>17</label><mixed-citation publication-type="other" xlink:type="simple">Ali, S., Javed, O., Haering, N., et al. (2010) Interactive Retrieval of Targets for Wide Area Surveillance. In: Proceedings of the 18th ACM international conference on Multimedia, ACM, New York, 895-898.  
&lt;br&gt;https://doi.org/10.1145/1873951.1874106</mixed-citation></ref><ref id="hanspub.30291-ref18"><label>18</label><mixed-citation publication-type="other" xlink:type="simple">Garcia, J., Martinel, N., Gardel, A., et al. (2017) Discriminant Con-text Information Analysis for Post-Ranking Person Re-Identification. IEEE Transactions on Image Processing, 26, 1650-1665. &lt;br&gt;https://doi.org/10.1109/TIP.2017.2652725</mixed-citation></ref><ref id="hanspub.30291-ref19"><label>19</label><mixed-citation publication-type="other" xlink:type="simple">Hirzer, M., Roth, P.M. and Bischof, H. (2012) Person Re-Identification by Efficient Impostor-Based Metric Learning. International Conference on Advanced Video and Sig-nal-Based Surveillance, Beijing, 18-21 September 2012, 203-208.  
&lt;br&gt;https://doi.org/10.1109/AVSS.2012.55</mixed-citation></ref><ref id="hanspub.30291-ref20"><label>20</label><mixed-citation publication-type="other" xlink:type="simple">Wang, H., Gong, S., Zhu, X., et al. (2016) Human-in-the-Loop Person Re-Identification. In: European Conference on Computer Vision, Springer, Cham, 405-422. &lt;br&gt;https://doi.org/10.1007/978-3-319-46493-0_25</mixed-citation></ref><ref id="hanspub.30291-ref21"><label>21</label><mixed-citation publication-type="other" xlink:type="simple">Wang, J., Zhou, S., Wang, J., et al. (2018) Deep Ranking Model by Large Adaptive Margin Learning for Person Re-Identification. Pattern Recognition, 74, 241-252. &lt;br&gt;https://doi.org/10.1016/j.patcog.2017.09.024</mixed-citation></ref><ref id="hanspub.30291-ref22"><label>22</label><mixed-citation publication-type="other" xlink:type="simple">Zhong, Z., Zheng, L., Cao, D., et al. (2017) Re-Ranking Person Re-Identification with k-Reciprocal Encoding. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, 21-26 July 2017, 1318-1327.  
&lt;br&gt;https://doi.org/10.1109/CVPR.2017.389</mixed-citation></ref></ref-list></back></article>