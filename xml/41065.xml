<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2021.113060</article-id><article-id pub-id-type="publisher-id">CSA-41065</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20210300000_93591914.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于DO-Conv改进的端到端车牌识别算法
  An Improved End-to-End License Plate Recognition Algorithm Based on DO-Conv
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>赖</surname><given-names>珍向</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>丁</surname><given-names>磊</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>邓</surname><given-names>杰航</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>顾</surname><given-names>国生</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>广东工业大学，计算机学院，广东 广州</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>09</day><month>03</month><year>2021</year></pub-date><volume>11</volume><issue>03</issue><fpage>588</fpage><lpage>595</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   提出了基于DO-Conv改进的端到端车牌识别算法，该算法引入一种新颖的深度过参数化卷积(Depthwise Over-Parameterized Convolutional Layer, DO-Conv)，用于替换常规卷积，提升图像特征提取的有效性，从而提高车牌识别的准确率。研究结果表明：改进后的算法在合成数据集和SYSU数据集上的识别准确率分别为97.42%和95.08%，均优于使用传统卷积的端到端识别算法。 An improved end-to-end license plate recognition algorithm based on DO-Conv was proposed. A new Depthwise Over-Parameterized Convolutional Layer (DO-Conv) was introduced to replace the conventional convolution to improve the effectiveness of image feature extraction and the accuracy of license plate recognition. The results show that the recognition accuracy of the improved algorithm is 97.42% and 95.08% on the synthetic dataset and SYSU dataset respectively, both of which are better than the end-to-end recognition algorithm using traditional convolution. 
  
 
</p></abstract><kwd-group><kwd>车牌识别，端到端，深度过参数化卷积，DO-Conv, License Plate Recognition</kwd><kwd> End to End</kwd><kwd> Deep Over-Parameterized Convolution</kwd><kwd> DO-Conv</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>摘要</title><p>提出了基于DO-Conv改进的端到端车牌识别算法，该算法引入一种新颖的深度过参数化卷积(Depthwise Over-Parameterized Convolutional Layer, DO-Conv)，用于替换常规卷积，提升图像特征提取的有效性，从而提高车牌识别的准确率。研究结果表明：改进后的算法在合成数据集和SYSU数据集上的识别准确率分别为97.42%和95.08%，均优于使用传统卷积的端到端识别算法。</p></sec><sec id="s2"><title>关键词</title><p>车牌识别，端到端，深度过参数化卷积，DO-Conv</p></sec><sec id="s3"><title>An Improved End-to-End License Plate Recognition Algorithm Based on DO-Conv</title><p>Zhenxiang Lai, Lei Ding, Jiehang Deng, Guosheng Gu</p><p>School of Computer Science, Guangdong University of Technology, Guangzhou Guangdong</p><p><img src="//html.hanspub.org/file/14-1542027x4_hanspub.png" /></p><p>Received: Feb. 20<sup>th</sup>, 2021; accepted: Mar. 15<sup>th</sup>, 2021; published: Mar. 22<sup>nd</sup>, 2021</p><p><img src="//html.hanspub.org/file/14-1542027x5_hanspub.png" /></p></sec><sec id="s4"><title>ABSTRACT</title><p>An improved end-to-end license plate recognition algorithm based on DO-Conv was proposed. A new Depthwise Over-Parameterized Convolutional Layer (DO-Conv) was introduced to replace the conventional convolution to improve the effectiveness of image feature extraction and the accuracy of license plate recognition. The results show that the recognition accuracy of the improved algorithm is 97.42% and 95.08% on the synthetic dataset and SYSU dataset respectively, both of which are better than the end-to-end recognition algorithm using traditional convolution.</p><p>Keywords:License Plate Recognition, End to End, Deep Over-Parameterized Convolution, DO-Conv</p><disp-formula id="hanspub.41065-formula7"><graphic xlink:href="//html.hanspub.org/file/14-1542027x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2021 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/14-1542027x7_hanspub.png" /> <img src="//html.hanspub.org/file/14-1542027x8_hanspub.png" /></p></sec><sec id="s5"><title>1. 引言</title><p>随着我国汽车保有量的增加，城市面临的交通管理压力也越来越大，智能交通系统的建设迫在眉睫。车牌识别作为智能交通系统的重要组成部分，广泛应用于高速公路收费管理、停车场出入管理、道路交通监控等场景。</p><p>传统的车牌字符识别方法首先需要分割车牌字符，输出一组单个的字符图像，然后使用模板匹配 [<xref ref-type="bibr" rid="hanspub.41065-ref1">1</xref>]、特征提取 [<xref ref-type="bibr" rid="hanspub.41065-ref2">2</xref>] 和神经网络 [<xref ref-type="bibr" rid="hanspub.41065-ref3">3</xref>] 等识别算法对其进行识别，将各个字符图像的识别结果顺序组合起来便得到车牌的识别结果。这些方法很大程度上依赖字符分割的准确性，而且在识别时需要对大量的车牌特征进行提取，识别效率低。近年来，由于强大的特征学习能力，卷积神经网络(CNNs)在解决许多经典的计算机视觉问题上取得了巨大的成功，例如图像分类和语义分割。基于CNN的车牌识别算法 [<xref ref-type="bibr" rid="hanspub.41065-ref4">4</xref>] [<xref ref-type="bibr" rid="hanspub.41065-ref5">5</xref>] 也相继被提出来，用于解决错误的字符分割导致车牌识别率下降的问题。Li等人 [<xref ref-type="bibr" rid="hanspub.41065-ref6">6</xref>] 将车牌识别问题看作一个序列建模问题，利用CNN提取车牌区域特征，然后送入LSTM [<xref ref-type="bibr" rid="hanspub.41065-ref7">7</xref>] 网络提取上下文关联信息，最后利用CTC [<xref ref-type="bibr" rid="hanspub.41065-ref8">8</xref>] 算法进行判别得到车牌序列信息。Zherzdev等人 [<xref ref-type="bibr" rid="hanspub.41065-ref9">9</xref>] 提出一种无需使用递归神经网络(RNN)的轻型卷积神经网络，用于快速识别车牌字符。Zhang等人 [<xref ref-type="bibr" rid="hanspub.41065-ref10">10</xref>] 提出一个端到端的模型，直接通过CNN完成整个车牌的识别，比文献 [<xref ref-type="bibr" rid="hanspub.41065-ref6">6</xref>] 中的方法更为简单。</p><p>上述基于CNN的车牌识别算法主要研究不同的网络结构对识别准确率的影响，他们由传统的卷积层组成。卷积层是CNN的核心构建模块。因此，这些核心模块的改进通常可以提高CNN的性能。一些用于替代传统卷积层的方法相继被提出来，这些方法可以提高CNN的特征学习能力或效率 [<xref ref-type="bibr" rid="hanspub.41065-ref11">11</xref>] [<xref ref-type="bibr" rid="hanspub.41065-ref12">12</xref>]。深度过参数化卷积 [<xref ref-type="bibr" rid="hanspub.41065-ref13">13</xref>] (Depthwise Over-Parameterized Convolutional Layer, DO-Conv)由Cao等人提出，可以提高CNN在许多经典视觉任务上的性能，如图像分类、检测和分割。本文将其应用于车牌识别任务中，提出一种融合DO-Conv的车牌识别算法，用于提升车牌特征提取的有效性，从而提高车牌的识别准确率。</p></sec><sec id="s6"><title>2. 深度过参数化卷积</title><p>与常规卷积不同，深度过参数化卷积DO-Conv在常规卷积的基础上添加一个用于过参数化的组件：深度卷积。一般认为，通过在网络中添加线性层和非线性层来增加网络深度可以提高网络的表达能力，提升网络性能。但是使用更深层次的网络结构往往会增加神经节点的计算量。过参数化的一个明显优势就是过参数化使用的多层复合线性操作在训练阶段之后可以折叠为紧凑的单层形式。然后在推理阶段仅使用单层计算，从而减少了计算量。此外，DO-Conv不仅可以提升融合模型的性能，还可以加快CNN的训练速度。</p><p>深度过参数化卷积的结构如图1所示。深度卷积算子 ∘ 首先应用于深度卷积内核D和输入特征P，生成变换后的特征 P ′ = D ∘ P 。然后常规卷积运算符 ∗ 应用于常规卷积内核W和特征 P ′ ，生成变换后的特征 O = W ∗ P ′ 。因此，深度过参数化卷积的输出可表示为： O = W ∗ ( D ∘ P ) 。在图1中，M和N为输入向量的空间维度， C i n 为输入向量的通道数， C o u t 为输出的通道数， d m u l = M &#215; N 为深度卷积的深度乘数。</p><p>图1. 深度过参数化卷积结构</p></sec><sec id="s7"><title>3. 基于DO-Conv改进的端到端识别网络</title><p>本文提出的基于DO-Conv改进的端到端车牌识别模型包含3个模块：基于DO-Conv改进的特征提取模块、特征序列化模块和序列解码模块。图2给出了所提模型的流程图，图3给出了所提模型的网络结构，模型中3个模块说明如下。</p><p>图2. 所提模型流程图</p><p>图3. 所提模型网络结构</p><sec id="s7_1"><title>3.1. 基于DO-Conv改进的特征提取模块</title><p>随着卷积神经网络的发展，其网络结构使用的卷积层数也在不断增加，在增强网络的表达能力时也带来了更大的计算量。针对这种情况，本文设计了一种基于DO-Conv改进的卷积神经网络，通过引入DO-Conv替换传统的卷积方式，可以在不增加网络层数的情况下提升网络的特征提取能力。</p><p>本文网络结构以VGG网络作为基础网络框架，其网络结构如图3所示。其中，输入图像统一处理为110 &#215; 32大小的灰度图像。就网络卷积过程而言，整个卷积网络由7个DO-Conv层及最大池化层构成。此外，Batch Normalization和ReLU函数被用来加速训练过程，提高网络的泛化能力。该网络通过对样本进行卷积、池化操作进行特征提取。</p><p>DO-Conv层：卷积网络中的特征提取层。卷积过程如第1章所述，卷积操作之后传递给激活函数，得到的结果是一组特征图。不同的特征图提取不同的特征。</p><p>池化层：也叫下采样层，本文采用最大池化，主要操作是取区域上的一个值做下采样；其目的是进一步减少网络的参数，保持某种不变性(旋转、平移等)。</p><p>网络的具体参数设置如表1所示，其中filters表示卷积核的个数，k表示卷积核的尺寸，s表示步长，p表示填充。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Fusion of CNN parameter settings for DO-Con</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >Type</th><th align="center" valign="middle" >Configuration</th></tr></thead><tr><td align="center" valign="middle" >Input</td><td align="center" valign="middle" >110 &#215; 32 &#215; 1 gray-scale image</td></tr><tr><td align="center" valign="middle" >DO-Conv, ReLU</td><td align="center" valign="middle" >filters: 64, k: 3 &#215; 3, s: 1 &#215; 1, p: 1</td></tr><tr><td align="center" valign="middle" >Max pooling</td><td align="center" valign="middle" >k: 2 &#215; 2, s: 2 &#215; 2</td></tr><tr><td align="center" valign="middle" >DO-Conv, ReLU</td><td align="center" valign="middle" >filters: 128, k: 3 &#215; 3, s: 1 &#215; 1, p: 1</td></tr><tr><td align="center" valign="middle" >Max pooling</td><td align="center" valign="middle" >k: 2 &#215; 2, s: 2 &#215; 2</td></tr><tr><td align="center" valign="middle" >DO-Conv, BatchNorm, ReLU</td><td align="center" valign="middle" >filters: 256, k: 3 &#215; 3, s: 1 &#215; 1, p: 1</td></tr><tr><td align="center" valign="middle" >DO-Conv, ReLU</td><td align="center" valign="middle" >filters: 256, k: 3 &#215; 3, , s: 1 &#215; 1, p: 1</td></tr><tr><td align="center" valign="middle" >Max pooling</td><td align="center" valign="middle" >k: 2 &#215; 2, s: 2 &#215; 2</td></tr><tr><td align="center" valign="middle" >DO-Conv, BatchNorm, ReLU</td><td align="center" valign="middle" >filters: 512, k: 3 &#215; 3, s: 1 &#215; 1, p: 1</td></tr><tr><td align="center" valign="middle" >DO-Conv, ReLU</td><td align="center" valign="middle" >filters: 512, k: 3 &#215; 3, s: 1 &#215; 1, p: 1</td></tr><tr><td align="center" valign="middle" >Max pooling</td><td align="center" valign="middle" >k: 2 &#215; 2, s: 2 &#215; 2</td></tr><tr><td align="center" valign="middle" >DO-Conv, BatchNorm, ReLU</td><td align="center" valign="middle" >filters: 512, k: 3 &#215; 3, s: 1 &#215; 1, p: 0</td></tr></tbody></table></table-wrap><p>表1. 融合DO-Conv的CNN参数设置</p></sec><sec id="s7_2"><title>3.2. 特征序列化模块</title><p>特征序列化模块是将提取出来的图像特征进行序列化，并实现与输入标签的序列到序列映射。本文采用长短时记忆网络(Long Short-Term Memory, LSTM)来进行序列化。整个模块由两层双向LSTM和全连接层组成，如图2所示。其中，每个双向LSTM层均由两个相对的LSTM构成，每个LSTM都有128个隐藏节点。全连接层有71个由Relu激活的神经元，对应71个类别(即37个中文字符，10个数字，24个字母，不含“I”、“O”)。当输入特征序列X时，全连接层的输出可表示为 C = { c 1 , c 2 , ⋯ , c T } ，其中 c t ∈ R 71 为第t个特征序列对应的序列标签。</p></sec><sec id="s7_3"><title>3.3. 序列解码模块</title><p>本文采用链接时序主义分类(Connectionist Temporal Classification, CTC)来对特征序列化模块的输出进行解码，预测最终的识别结果。CTC通过使用Softmax层将循环层的输出 C = { c 1 , ⋯ , c T } 转换成概率序列 Y = { y 1 , y 2 , ⋯ , y T } ，其中T是特征序列的长度且</p><p>y t = softmax ( c t ) (1)</p><p>首先，用L表示任务中的所有标签。定义一组长度为T的序列 L ′ ， L ′ = L ∪ ∅ 。 L ′ 包含所有预定义的标签，包括一个“blank”标签 ∅ 。我们将在全部时间步长里依次观察到的标签作为路径π。</p><p>为了处理路径π和目标序列l之间的关系，CTC定义了多对一映射β。β首先删除重复的标签，然后删除所有的空白标签。给定标签序列l，将可行路径定义为能够从l映射到β的所有π。每个目标的条件概率被定为所有可行路径概率的和，即：</p><p>p ( l | Y ) = ∑ π ∈ β ( π ) = l p ( π | Y ) (2)</p><p>其中</p><p>p ( π | Y ) = ∏ t = 1 T y t π t , ∀ π ∈ L ′ (3)</p><p>其中 π t 是路径 π 中的第t个元素， y t π t 是标签 π t 的评估概率。</p></sec></sec><sec id="s8"><title>4. 实验结果分析</title><sec id="s8_1"><title>4.1. 数据集</title><p>由于没有公开的大型中文数据集，本文使用opencv根据国内车牌规则生成各种类型的合共12万张车牌图像的合成数据集，图像的分辨率均为110 &#215; 32。部分生成图像如图4所示。训练集和测试集之比为8:2，即训练集104,000张，测试集26,000张。</p><p>图4. 合成车牌图像</p><p>为了验证所提模型在真是环境中的性能，本文还使用了开源中文车牌数据集SYSU [<xref ref-type="bibr" rid="hanspub.41065-ref14">14</xref>]。SYSU数据集采集了超过3000张来自道路交通监控探头的车牌图像样本。由于该数据集未标注车牌位置，采用开源软件HyperLPR对车牌区域进行定位，成功定位3671张图像，其中2939张被用于训练，剩余732张被用于测试。</p></sec><sec id="s8_2"><title>4.2. 实验设置</title><p>本文实验算法采用编程语言Python、C++编写，使用pytorch框架实现。其他软硬件配置如下：Intel Core i7-8700k 3.70 GHZ 12核8G内存，NVIDIA 1080ti显卡，显存11 GB，ubuntu16.04LTS系统。</p><p>网络训练的学习率为1e-5，模型的batch size为128，模型使用RMS优化器进行优化。</p></sec><sec id="s8_3"><title>4.3. 评价指标</title><p>本文采用识别准确率(RA) [<xref ref-type="bibr" rid="hanspub.41065-ref15">15</xref>] 来评估车牌识别模型的性能，计算公式如下：</p><p>R A = R N (4)</p><p>其中R是正确识别所有字符的车牌数量，N是用于测试的车牌数量。</p></sec><sec id="s8_4"><title>4.4. 实验结果</title><p>为了探讨DO-Conv卷积层对车牌识别准确率的影响，本文将模型中的DO-Conv层替换为常规卷积，然后分别在SYSU数据集和合成车牌数据集上进行消融实验。实验结果如表2所示。</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> Comparison of structural performance of different model</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >模型结构</th><th align="center" valign="middle" >SYSU数据集识别准确率</th><th align="center" valign="middle" >合成数据集识别准确率</th></tr></thead><tr><td align="center" valign="middle" >使用常规卷积的模型</td><td align="center" valign="middle" >94.81%</td><td align="center" valign="middle" >96.90%</td></tr><tr><td align="center" valign="middle" >本文模型</td><td align="center" valign="middle" >95.08%</td><td align="center" valign="middle" >97.42%</td></tr></tbody></table></table-wrap><p>表2. 不同模型结构性能对比</p><p>由表2可知，本文所提模型在SYSU数据集和合成数据集上分别比使用常规卷积的模型高0.27%和0.52%，两者的性能差距证实了本文提出的识别模型有助于提升车牌识别的准确率。绘制了合成数据集中测试准确率与训练次数关系图，如图5所示。从该图中可以看出，在训练过程中使用Do-Conv卷积层的网络的准确率上升速度更快，且明显高于使用传统卷积层Conv的准确率曲线，表明使用DO-Conv层不仅可以提高车牌识别的准确率，还可以加快神经网络的训练。</p><p>图5. 合成数据集中测试准确率与训练次数关系</p><p>此外，为了进一步验证本文模型的有效性，还与文献 [<xref ref-type="bibr" rid="hanspub.41065-ref9">9</xref>] 的方法进行了对比，实验的结果如表3所示。与文献 [<xref ref-type="bibr" rid="hanspub.41065-ref9">9</xref>] 的方法相比，本文提出的基于DO-Conv改进的端到端车牌识别方法在两个数据集里都获得了较高的准确率。</p><p>表3. 不同方法性能对比</p></sec></sec><sec id="s9"><title>5. 结论</title><p>由于大多数基于CNN的车牌识别算法主要研究不同网络结构对车牌识别准确率的影响，很少有方法研究不同卷积层对识别准确率的影响。本文提出了基于DO-Conv改进的端到端车牌识别算法。该算法对传统的端到端算法进行改进，在特征提取阶段将原有的卷积方式替换为为深度过参数化卷积DO-Conv，提升图像特征提取的有效性，然后使用LSTM网络对提取的特征进行序列化，最后使用CTC算法进行解码输出。通过在合成车牌数据集和SYSU数据集上的实验表明，改进后的网络模型对于车牌识别的准确率更高，分别达到了97.42%和95.08%。同时，改进后的模型的训练效果更好。与现有方法的对比也进一步表明了本文所提方法的有效性。</p></sec><sec id="s10"><title>文章引用</title><p>赖珍向,丁 磊,邓杰航,顾国生. 基于DO-Conv改进的端到端车牌识别算法An Improved End-to-End License Plate Recognition Algorithm Based on DO-Conv[J]. 计算机科学与应用, 2021, 11(03): 588-595. https://doi.org/10.12677/CSA.2021.113060</p></sec><sec id="s11"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.41065-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">楚天鸿, 唐瑞尹. 基于MATLAB平台下的车牌识别系统设计[J]. 科技与创新, 2020(14): 20-22.</mixed-citation></ref><ref id="hanspub.41065-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">肖雄, 黄樟灿. 基于统计的车牌字符识别[J]. 数字技术与应用, 2016(4): 74.</mixed-citation></ref><ref id="hanspub.41065-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">杨洪臣, 党京, 蔡能斌, 王华鹏, 翟金良. BP神经网络车牌识别技术优化研究[J]. 中国刑警学院学报, 2019(3): 120-124.</mixed-citation></ref><ref id="hanspub.41065-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Wang, W.W., Yang, J., Chen, M. and Wang, P. (2019) A Light CNN for End-to-End Car License Plates Detection and Recognition. IEEE Access, 7, 173875-173883. &lt;br&gt;https://doi.org/10.1109/ACCESS.2019.2956357</mixed-citation></ref><ref id="hanspub.41065-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Zou, Y.J., Zhang, Y.J., Yan, J., Jiang, X.X., Huang, T.J., Fan, H.S., et al. (2020) A Robust License Plate Recognition Model Based on Bi-LSTM. IEEE Access, 8, 211630-211641. &lt;br&gt;https://doi.org/10.1109/ACCESS.2020.3040238</mixed-citation></ref><ref id="hanspub.41065-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Li, H., Wang, P., You, M.Y. and Shen, C.H. (2018) Reading Car License Plates Using Deep Neural Networks. Image &amp; Vision Computing, 72, 14-23. &lt;br&gt;https://doi.org/10.1016/j.imavis.2018.02.002</mixed-citation></ref><ref id="hanspub.41065-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Wang, X., Han, Y., Leung, V.C.M., Niyato, D., Yan, X.Q. and Chen, X. (2020) Convergence of Edge Computing and Deep Learning: A Comprehensive Survey. IEEE Communica-tions Surveys &amp; Tutorials, 22, 869-904.  
&lt;br&gt;https://doi.org/10.1109/COMST.2020.2970550</mixed-citation></ref><ref id="hanspub.41065-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Huang, X.H., Qiao, L.S., Yu, W.T., Li, J. and Ma, Y.Z. (2020) End-to-End Sequence Labeling via Convolutional Recurrent Neural Network with a Connectionist Temporal Classification Layer. International Journal of Computational Intelligence Systems, 13, 341-351. &lt;br&gt;https://doi.org/10.2991/ijcis.d.200316.001</mixed-citation></ref><ref id="hanspub.41065-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Zherzdev, S. and Gruzdev, A. (2018) LPRNet: License Plate Recognition via Deep Neural Networks. arXiv preprint arXiv:1806.10447.</mixed-citation></ref><ref id="hanspub.41065-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Zhang, L.J., Wang, P., Li, H., Li, Z., Shen, C.H. and Zhang, Y.N. (2020) A Robust Attentional Framework for License Plate Recognition in the Wild. IEEE Transactions on Intelligent Transportation Systems, 1-10. 
&lt;br&gt;https://doi.org/10.1109/TITS.2020.3000072</mixed-citation></ref><ref id="hanspub.41065-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Chen, Y.P., Fan, H.Q., Xu, B., Yan, Z.C., Kalantidis, Y., Rohrbach, M., et al. (2019) Drop an Octave: Reducing Spatial Redundancy in Convolutional Neural Networks with Oc-tave Convolution. Proceedings of the IEEE/CVF International Conference on Computer Vision, Seoul, 27 October-2 November 2019, 3434-3443. 
&lt;br&gt;https://doi.org/10.1109/ICCV.2019.00353</mixed-citation></ref><ref id="hanspub.41065-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Zhu, X.Z., Hu, H., Lin, S. and Dai, J.F. (2019) Deformable Con-vNets V2: More Deformable, Better Results. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Long Beach, 15-20 June 2019, 9300-9308. &lt;br&gt;https://doi.org/10.1109/CVPR.2019.00953</mixed-citation></ref><ref id="hanspub.41065-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Cao, J., Li, Y., Sun, M., Chen, Y., Lischinski, D., Cohen-Or, D., et al. (2020) DO-Conv: Depthwise over Parameterized Convo-lutional Layer. arXiv preprint arXiv:2006.12030.</mixed-citation></ref><ref id="hanspub.41065-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">Zhao. Y., Yu, Z., Li, X. and Cai, M. (2019) Chinese License Plate Image Database Building Methodology for License Plate Recognition. Journal of Electronic Imaging, 28, Article ID: 013001. &lt;br&gt;https://doi.org/10.1117/1.JEI.28.1.013001</mixed-citation></ref><ref id="hanspub.41065-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">Wang, J., Huang, H., Qian, X., Cao, J. and Dai, Y. (2018) Sequence Recognition of Chinese License Plates. Neurocomputing, 317, 149-158. &lt;br&gt;https://doi.org/10.1016/j.neucom.2018.08.023</mixed-citation></ref></ref-list></back></article>