<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2017.79097</article-id><article-id pub-id-type="publisher-id">CSA-22009</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20170900000_78317415.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于后验概率和滤色阵列特性的图像篡改检测算法
  An Image Tampering Detection Algorithm Based on the Posterior Probability and Color Filter Array Artifacts
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>魏</surname><given-names>金巧</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>王</surname><given-names>英</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>青岛大学电子信息学院，山东 青岛</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>31</day><month>08</month><year>2017</year></pub-date><volume>07</volume><issue>09</issue><fpage>850</fpage><lpage>857</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   针对图像采集过程中插值算法对图像三原色之间所引入的插值特性，论文提出一种基于后验概率和滤色阵列特性的图像篡改检测算法。首先提取待测图像绿色通道分量，引入二维预测滤波构建预测误差函数；然后分块提取特征，分析原始与篡改图像所提特征的直方图特性，从而建立特征的高斯混合统计模型，并借助EM算法估计模型参数；计算子块特征作为原始块的后验概率，定义似然率并应用到每个子块中，从而可得到篡改区域映射图，完成本次检测。仿真结果表明，该算法具有较强的鲁棒性，能够对图像篡改区域进行较准确地定位。 Focused on the artifacts between the three primaries of an image introduced by the interpolation algorithm during its acquisition process, an image tampering detection algorithm based on the posterior probability and the color filter array artifacts is proposed. Firstly, the green channel component of the image is extracted, and the two-dimensional predictive filter is used to construct the predictive error function. Then the histograms’ character of original and tampering images is analyzed, and then the Gaussian mixture statistical model is established. EM algorithm is applied to estimate the model parameters. Then the posterior probability of each sub-block as an original block is calculated, and the feature likelihood is defined and it is applied to every sub-block, so that the tampering-area map can be obtained to complete the detection. The simulation results show that the algorithm has strong robustness and can locate the image’s tampered region more accurately.  
   
 
  
 
</p></abstract><kwd-group><kwd>后验概率，滤色阵列特性，高斯混合模型，似然率，图像篡改检测, Posterior Probability</kwd><kwd> Color Filter Array Artifacts</kwd><kwd> Gaussian Mixture Model</kwd><kwd> Likelihood Ratio</kwd><kwd> Image Tempering Detection</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>基于后验概率和滤色阵列特性的图像 篡改检测算法 <sup> </sup></title><p>魏金巧，王英</p><p>青岛大学电子信息学院，山东 青岛</p><p>收稿日期：2017年8月29日；录用日期：2017年9月9日；发布日期：2017年9月13日</p><disp-formula id="hanspub.22009-formula49"><graphic xlink:href="http://html.hanspub.org/file/6-1540838x5_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>针对图像采集过程中插值算法对图像三原色之间所引入的插值特性，论文提出一种基于后验概率和滤色阵列特性的图像篡改检测算法。首先提取待测图像绿色通道分量，引入二维预测滤波构建预测误差函数；然后分块提取特征，分析原始与篡改图像所提特征的直方图特性，从而建立特征的高斯混合统计模型，并借助EM算法估计模型参数；计算子块特征作为原始块的后验概率，定义似然率并应用到每个子块中，从而可得到篡改区域映射图，完成本次检测。仿真结果表明，该算法具有较强的鲁棒性，能够对图像篡改区域进行较准确地定位。</p><p>关键词 :后验概率，滤色阵列特性，高斯混合模型，似然率，图像篡改检测</p><disp-formula id="hanspub.22009-formula50"><graphic xlink:href="http://html.hanspub.org/file/6-1540838x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2017 by authors and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="http://image.hanspub.org:8080\Html/htmlimages\1-2890033x\e70a10f1-7c93-45ea-9603-062237856e4b.png" /><img src="http://image.hanspub.org:8080\Html\htmlimages\1-2890033x\e898c85e-ffc4-45c9-b817-14224a4d6960.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>图像取证是一项多学科综合的科学，其旨在获取与数字图像相关的重要“历史”信息，主要包括其编码进程和可能的编辑修改过程 [<xref ref-type="bibr" rid="hanspub.22009-ref1">1</xref>] 。随着图像编辑软件的日益强大，人们能够很轻易地修饰和篡改一幅图像。因此，鉴别图像的真伪及篡改区域的精细定位变得日趋重要。</p><p>T. Bianch等 [<xref ref-type="bibr" rid="hanspub.22009-ref2">2</xref>] 对JPEG图像压缩过程进行建模，使用后验概率法估计量化步长，最后通过篡改区域和未篡改区域量化表的不一致性来定位篡改区域。Swaminathan等 [<xref ref-type="bibr" rid="hanspub.22009-ref3">3</xref>] 提出了一种通过估计CFA模式和插值内核进行识别相机型号的方法，紧接着又在文献 [<xref ref-type="bibr" rid="hanspub.22009-ref4">4</xref>] 中将去马赛克模型中估计出的参数之间的不一致性作为篡改检测的依据。H. Farid等 [<xref ref-type="bibr" rid="hanspub.22009-ref5">5</xref>] 提出用期望最大化算法来估计去马赛克算法内插核参数，实现了借助每个像素与其相邻像素相关性的概率图来检测篡改区域，但这种方法需要预先知道图像篡改区域的尺寸。S. Vinoth等 [<xref ref-type="bibr" rid="hanspub.22009-ref6">6</xref>] 提出将反向传播神经网络作为非线性模型来描述CFA插值特性并进行分类的方法。Peng Shuang等 [<xref ref-type="bibr" rid="hanspub.22009-ref7">7</xref>] 提出一种利用自然图像颜色通道之间的相关性来检测图像篡改操作的方法，但对经模糊篡改的检测存在一定的误差。</p><p>面对错综复杂的图像篡改方式，很多方法的鲁棒性很差甚至会失效。本文从图像生成的过程出发，通过分析数码相机的一般成像体系(如图1)发现，图像经过滤色阵列(Color Filter Array, CFA)插值后三颜色分量具有很强的相关性，而且这种相关性会在图像的原始区域表现得很明显，但在被篡改过的图像区域却会消失 [<xref ref-type="bibr" rid="hanspub.22009-ref8">8</xref>] 。所以，可以此作为判断图像篡改与否的依据。</p><p>基于文献 [<xref ref-type="bibr" rid="hanspub.22009-ref5">5</xref>] [<xref ref-type="bibr" rid="hanspub.22009-ref6">6</xref>] [<xref ref-type="bibr" rid="hanspub.22009-ref7">7</xref>] 以及对成像体系的分析，发现CFA插值过程引入的噪声会使图像篡改检测的精度降低，而且一般的算法对模糊篡改后的平滑区域的检测总会有误差。所以，本文提出一种基于后验概率和滤色阵列特性的图像篡改检测方法，对篡改区域实行较高精度的定位。首先提取待测图像绿色通道分量，引入二维预测滤波构建预测误差函数；然后分块提取特征，分析原始与篡改图像所提特征的直方图</p><p>图1. 数码相机一般成像体系</p><p>特性，从而建立特征的高斯混合统计模型(Gaussian Mixture Model, GMM)，并借助EM (Expectation Maximization)算法估计模型参数；计算块特征作为原始块的后验概率，定义似然率并应用到每个子块中，从而可得到篡改区域映射图，映射图上每个像素的灰度值分别对应于待测图像上该子块的似然率值，该值越小，表明该区域被篡改的可能性越高，而被篡改过的区域将以灰度值极低的黑色区域显现出来，完成本次检测。</p></sec><sec id="s4"><title>2. 滤色阵列</title><p>数码相机的图像传感器通过CFA来感应不同光的强度。现存的阵列，包括Bayer CFA，Mosic CFA, Stripe CFA，其中Bayer CFA作为最经典的阵列，应用最为广泛，它交替使用一组红色和绿色滤镜及一组绿色和蓝色滤镜，其中绿色像素是红、蓝像素数量的两倍，如图2(a)所示。这是由于人眼对于绿色更为敏感，且绿色在可见光谱中占据着最重要和最宽的位置。所以本文的研究以绿色通道分量为焦点。</p><p>Bayer CFA传感器的原始输出图像的每个像素只有红、绿、蓝中的一种颜色分量，俗称“马赛克图像”，因此，必须采用插值算法将单色的马赛克图像转换成逼真的全彩色图像，这个过程通常被称为“去马赛克(Demosaicing)”。插值通常在缺失值的邻域应用一个加权矩阵(核)来实现，常见的CFA插值算法分两类：一类是以双线性和双三次插值 [<xref ref-type="bibr" rid="hanspub.22009-ref9">9</xref>] 为代表的非自适应插值算法，另一类则是以梯度插值 [<xref ref-type="bibr" rid="hanspub.22009-ref10">10</xref>] 为代表的自适应插值算法。但无论采用哪种插值算法，数码相机拍摄出的原始自然图像往往都会存在一定的滤色阵列特性，也称“去马赛克效应”，而被修改过的图像区域则不具备这些特性。</p><p>所提取绿色通道的像素构成如图2(b)所示，获得像素和插值像素分别对应于晶格A和晶格I。如果图像是原始的自然图像，则晶格A和I的绿色像素值具有一定的规律，即晶格A处绿色像素的预测误差方差要高于晶格I处；相反，如果图像被篡改过，这种规律被破坏，则两个晶格的预测误差方差会变成相似的值。因此，可通过评估两类不同晶格处绿色像素值的预测误差方差的不平衡性，来检测CFA插值特性的存在与否，从而判定图像是否受到篡改。</p></sec><sec id="s5"><title>3. 算法介绍</title><p>本文所提算法的检测流程如图3所示。检测算法主要包含：1) 提取待测图像绿色通道分量；2) 计算预测误差及其加权方差；3) 建立篡改特征统计模型；4) 估计特征模型参数；5) 引入后验概率模型，定义似然率，输出篡改映射图。</p><p>这里引入权重因子和二维预测器来构建预测误差及其加权方差的统计模型，从模型中的不重叠像素块中提取出特征。如果这个特征明显大于零值，则认为它是一个原始像素块；反之，如果特征很接近于零值，则认为该子块为一个篡改块。</p><p>图2. Bayer CFA及绿色通道获得和插值像素分布</p><p>图3. 所提算法的检测流程</p><sec id="s5_1"><title>3.1. 特征提取</title><p>待测图像的绿色通道分量为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x13_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x14_hanspub.png" xlink:type="simple"/></inline-formula>，引入二维预测滤波，得其预测误差为：</p><disp-formula id="hanspub.22009-formula51"><label>(1)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/6-1540838x15_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x16_hanspub.png" xlink:type="simple"/></inline-formula>为二维预测滤波，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x17_hanspub.png" xlink:type="simple"/></inline-formula>为像素<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x18_hanspub.png" xlink:type="simple"/></inline-formula>周围像素的横、纵坐标。在理想情况下，可令<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x19_hanspub.png" xlink:type="simple"/></inline-formula>，其中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x20_hanspub.png" xlink:type="simple"/></inline-formula>为插值算法的插值内核。由于相机的插值算法往往是未知的，所以令<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x21_hanspub.png" xlink:type="simple"/></inline-formula>。</p><p>因为余量局部平稳，并且预测误差<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x22_hanspub.png" xlink:type="simple"/></inline-formula>的方差在插值或获得像素的邻域像素位置可以被逐个局部估计，所以预测误差<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x23_hanspub.png" xlink:type="simple"/></inline-formula>具有局部平稳性，假设其在<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x24_hanspub.png" xlink:type="simple"/></inline-formula>窗口内有效，则其局部加权方差可定义为：</p><disp-formula id="hanspub.22009-formula52"><label>(2)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/6-1540838x25_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x26_hanspub.png" xlink:type="simple"/></inline-formula>为预测误差的局部方差均值；<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x27_hanspub.png" xlink:type="simple"/></inline-formula>为一尺度因子，可使参数评估更准确，例如对于每一个像素都有<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x28_hanspub.png" xlink:type="simple"/></inline-formula>；<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x29_hanspub.png" xlink:type="simple"/></inline-formula>是合适的权重因子：</p><disp-formula id="hanspub.22009-formula53"><label>(3)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/6-1540838x30_hanspub.png"  xlink:type="simple"/></disp-formula><disp-formula id="hanspub.22009-formula54"><label>(4)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/6-1540838x31_hanspub.png"  xlink:type="simple"/></disp-formula><p>式中，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x32_hanspub.png" xlink:type="simple"/></inline-formula>为一<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x33_hanspub.png" xlink:type="simple"/></inline-formula>的高斯窗，其标准偏差为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x34_hanspub.png" xlink:type="simple"/></inline-formula>。</p><p>若待测图像大小为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x35_hanspub.png" xlink:type="simple"/></inline-formula>，将其分割成<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x36_hanspub.png" xlink:type="simple"/></inline-formula>大小的非重叠子块，B与Bayer CFA的周期相关，最小块尺寸为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x37_hanspub.png" xlink:type="simple"/></inline-formula>。任意位置<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x38_hanspub.png" xlink:type="simple"/></inline-formula>处的子块<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x39_hanspub.png" xlink:type="simple"/></inline-formula>(<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x40_hanspub.png" xlink:type="simple"/></inline-formula>)都是由获得像素和插值像素的非相交集<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x41_hanspub.png" xlink:type="simple"/></inline-formula>、<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x42_hanspub.png" xlink:type="simple"/></inline-formula>构成，由此提取特征<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x43_hanspub.png" xlink:type="simple"/></inline-formula>并定义为：</p><disp-formula id="hanspub.22009-formula55"><label>(5)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/6-1540838x44_hanspub.png"  xlink:type="simple"/></disp-formula><disp-formula id="hanspub.22009-formula56"><label>(6)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/6-1540838x45_hanspub.png"  xlink:type="simple"/></disp-formula><disp-formula id="hanspub.22009-formula57"><label>(7)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/6-1540838x46_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x47_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x48_hanspub.png" xlink:type="simple"/></inline-formula>分别为获得像素和插值像素预测误差局部加权方差的几何均值。式(5)中的<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x49_hanspub.png" xlink:type="simple"/></inline-formula>是非连续的，可用于评估预测误差局部方差的不平衡性。若待测块是未被篡改过的原始块，则其获得像素的局部方差要远大于插值像素的局部方差，即特征<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x50_hanspub.png" xlink:type="simple"/></inline-formula>的期望值为一个正量；反之，当图像块被篡改过，则获得像素与插值像素局部方差之间的差异消失，特征<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x51_hanspub.png" xlink:type="simple"/></inline-formula>的期望值为0。</p></sec><sec id="s5_2"><title>3.2. 建立特征模型</title><p>为了准确描述提取出的特征，需建立一个简单的统计模型，对每个子块<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x52_hanspub.png" xlink:type="simple"/></inline-formula>，应用贝叶斯的方法可评估其CFA插值特性出现的概率。假设存在CFA插值特性时为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x53_hanspub.png" xlink:type="simple"/></inline-formula>，不存在CFA插值特性时为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x54_hanspub.png" xlink:type="simple"/></inline-formula>。已知篡改图像和未篡改图像中提取出的特征L的统计直方如图4所示。</p><p>经分析，特征<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x55_hanspub.png" xlink:type="simple"/></inline-formula>在这两种假设下均服从高斯分布。若分块尺寸B固定，可以用下面这两个条件概率密度函数来描述所提特征：</p><disp-formula id="hanspub.22009-formula58"><label>(8)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/6-1540838x56_hanspub.png"  xlink:type="simple"/></disp-formula><disp-formula id="hanspub.22009-formula59"><label>(9)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/6-1540838x57_hanspub.png"  xlink:type="simple"/></disp-formula><p><inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x58_hanspub.png" xlink:type="simple"/></inline-formula>， <inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x59_hanspub.png" xlink:type="simple"/></inline-formula>和 <inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x60_hanspub.png" xlink:type="simple"/></inline-formula>分别表示 <inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x61_hanspub.png" xlink:type="simple"/></inline-formula>在假设 <inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x62_hanspub.png" xlink:type="simple"/></inline-formula>、 <inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x63_hanspub.png" xlink:type="simple"/></inline-formula>下的先验概率。 <inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x64_hanspub.png" xlink:type="simple"/></inline-formula>代表该区域存在CFA插值特性， <inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x65_hanspub.png" xlink:type="simple"/></inline-formula>则代表该区域CFA插值特性已被擦除。如果一幅图像包含了一些CFA特征被破坏的篡改区域，则以上两种假设均存在，此时特征 <inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x66_hanspub.png" xlink:type="simple"/></inline-formula>服从高斯混合分布(如图4(b)示)。为了估计出该高斯混合模型的参数，引入EM方法来估计参数 <inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x67_hanspub.png" xlink:type="simple"/></inline-formula>的值。</p><p>图4. 所提特征统计直方图。(a)原始图像特征统计直方图；(b)篡改图像特征统计直方图</p></sec><sec id="s5_3"><title>3.3. 生成篡改映射图</title><p>本算法最终的目标是针对每一个子块，都能基于CFA插值特性的存在与否来获得它是原始块的概率，并以不同子块灰度值的高低显示，从而来定位出篡改区域。根据(8)式和(9)式，且已知先验概率<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x70_hanspub.png" xlink:type="simple"/></inline-formula>，则可得该子块作为原始块的后验概率为：</p><disp-formula id="hanspub.22009-formula60"><label>(10)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/6-1540838x71_hanspub.png"  xlink:type="simple"/></disp-formula><p>也可改写成：</p><disp-formula id="hanspub.22009-formula61"><label>(11)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/6-1540838x72_hanspub.png"  xlink:type="simple"/></disp-formula><p><inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x73_hanspub.png" xlink:type="simple"/></inline-formula>为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x74_hanspub.png" xlink:type="simple"/></inline-formula>的似然率，定义式为：</p><disp-formula id="hanspub.22009-formula62"><label>(12)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/6-1540838x75_hanspub.png"  xlink:type="simple"/></disp-formula><p>(11)式和(12)式具有相同的统计意义。将(12)式作用于图像的每个子块中，则可得到一映射图，图中的每个像素值分别对应于一个<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x76_hanspub.png" xlink:type="simple"/></inline-formula>块的似然率，且似然率越低，则该子块为篡改块的概率越高。然而，似然率图往往包含通道噪声，为了消除这些噪声，需在更大的块上计算其累计特征值，块大小为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x77_hanspub.png" xlink:type="simple"/></inline-formula>，且满足<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x78_hanspub.png" xlink:type="simple"/></inline-formula>。假设<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x79_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x80_hanspub.png" xlink:type="simple"/></inline-formula>之间条件独立，则可定义累计似然率为：</p><disp-formula id="hanspub.22009-formula63"><label>(13)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/6-1540838x81_hanspub.png"  xlink:type="simple"/></disp-formula><p>在实际篡改图像中，篡改区域通常是连通的。为了进一步提高定位性能，对生成的似然图先取对数后应用一个中值滤波器，既能保证数值的稳定性，还能将这些关联区域都强调出来。</p></sec></sec><sec id="s6"><title>4. 仿真结果及分析</title><p>为了检测本文算法对图像篡改区域的定位性能，在篡改图像库中进行实验。原始样本均由 Nikon D90 获得，经PS软件对样本进行复制-粘贴篡改，同时对图像做后处理操作，如平滑，滤波，尺度、旋转等可更好的移除篡改区域的CFA特征。关键参数设置：<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x82_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x83_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-1540838x84_hanspub.png" xlink:type="simple"/></inline-formula>。与文献 [<xref ref-type="bibr" rid="hanspub.22009-ref11">11</xref>] 所提出方法进行了检测效果的对比，图5和图6为两种方法仿真结果的对比图。</p><p>从图5可看出，两种方法都能定位出篡改区域，但文献 [<xref ref-type="bibr" rid="hanspub.22009-ref11">11</xref>] 方法篡改区域的边界污染较严重，即检测的精度不够高，本文算法对篡改区域的边界轮廓定位得很精确，且本文算法和文献 [<xref ref-type="bibr" rid="hanspub.22009-ref11">11</xref>] 方法输出映射图的最低似然率分别为−28.8988和−23.4673，也充分说明了本文算法检测性能的优越性；图6中的篡改图像后期经过了模糊处理，虽然两种算法的检测均存在较明显的误判区域，即对天空处平滑区域的检测失效，俩算法在篡改区域输出的最低似然率分别为−7.8577 (本文)和−6.5299 (文献 [<xref ref-type="bibr" rid="hanspub.22009-ref11">11</xref>] )，但本文算法较文献 [<xref ref-type="bibr" rid="hanspub.22009-ref11">11</xref>] 算法而言，依旧能够更清晰地将真正的篡改区域定位出来。综上可得，本文所提算法较文献 [<xref ref-type="bibr" rid="hanspub.22009-ref11">11</xref>] 算法的检测性能更好，且精确度达到更高。</p></sec><sec id="s7"><title>5. 结语</title><p>针对当前数字图像被动取证算法易受噪声影响致使检测精度不高情况，本文提出了基于后验概率和滤色阵列特性的图像篡改检测算法。对每个子块中提取的特征引入其后验概率，然后建立高斯混合模型，</p><p>图5. 图像篡改区域定位。(a)原始图像；(b)篡改图像；(c)本文算法检测结果；(d)文献 [<xref ref-type="bibr" rid="hanspub.22009-ref11">11</xref>] 算法检测结果</p><p>图6. 图像篡改区域定位。(a)原始图像；(b)篡改图像；(c)本文算法检测结果；(d)文献 [<xref ref-type="bibr" rid="hanspub.22009-ref11">11</xref>] 算法检测结果</p><p>定义似然率，输出篡改映射图并中值滤波去噪，最后输出的映射值越低表明被篡改的概率越大。实验结果显示该算法不仅能准确检测和定位篡改区域，而且具有较强的鲁棒性。但是对图像模糊篡改进行检测时，在平滑区域存在误检，这也是后续研究工作中的重点之一。</p></sec><sec id="s8"><title>致谢</title><p>本研究是在我的导师王教授的亲切关怀和悉心指导下完成的。王教授不仅在学业上给我以精心指导，同时还在思想、生活上给我以无微不至的关怀，在此谨向她致以诚挚的谢意和崇高的敬意。我还要感谢同在一个实验室的小伙伴们，正是由于你们的帮助和支持，我才能克服一个一个的困难和疑惑，直至本文的顺利完成。最后我还要感谢培养我长大含辛茹苦的父母，谢谢你们！</p><p>最后，再次对关心、帮助我的老师和同学表示衷心地感谢！</p></sec><sec id="s9"><title>文章引用</title><p>魏金巧,王 英. 基于后验概率和滤色阵列特性的图像篡改检测算法 An Image Tampering Detection Algorithm Based on the Posterior Probability and Color Filter Array Artifacts[J]. 计算机科学与应用, 2017, 07(09): 850-857. http://dx.doi.org/10.12677/CSA.2017.79097</p></sec><sec id="s10"><title>参考文献 (References)</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.22009-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">周琳娜, 王东明. 数字图像取证技术[M]. 北京: 北京邮电大学出版社, 2008: 1-6.</mixed-citation></ref><ref id="hanspub.22009-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Bianchi, T. and Piva, A. (2012) Image Forgery Localization via Block-Grained Analysis of JPEG Artifacts. IEEE Transactions on Information Forensics and Security, 7, 1003-1017. &lt;br&gt;https://doi.org/10.1109/TIFS.2012.2187516</mixed-citation></ref><ref id="hanspub.22009-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Swaminathan, A., Wu, M. and Liu, K.R. (2007) Nonintrusive Component Forensics of Visual Sensors Using Output Images. IEEE Transactions on Information Forensics and Security, 2, 91-106.  
&lt;br&gt;https://doi.org/10.1109/TIFS.2006.890307</mixed-citation></ref><ref id="hanspub.22009-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Swaminathan, A., Wu, M. and Liu, K.J.R. (2008) Digital Image Forensics via Intrinsic Fingerprints. IEEE Transactions on Information Forensics and Security, 3, 101-117. &lt;br&gt;https://doi.org/10.1109/TIFS.2007.916010</mixed-citation></ref><ref id="hanspub.22009-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Popescu, A.C. and Farid, H. (2005) Exposing Digital Forgeries in Color Filter Array Interpolated Images. IEEE Transactions on Signal Processing, 53, 3948-3959. &lt;br&gt;https://doi.org/10.1109/TSP.2005.855406</mixed-citation></ref><ref id="hanspub.22009-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Vinoth, S., et al. (2013) Neural Network Modeling of Color Array Filter for Digital Forgery Detection Using Kernel LDA. Procedia Technology, 10, 498-504.</mixed-citation></ref><ref id="hanspub.22009-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">彭双, 彭圆圆, 肖长燕. 基于CFA插值的图像篡改检测算法[J]. 传感器与微系统, 2015, 32(6): 0141-0144.</mixed-citation></ref><ref id="hanspub.22009-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">张雯, 李学明. 改进的基于颜色滤波陈列特性的篡改检测[J]. 计算机工程与应用, 2009, 45(6): 176-179.</mixed-citation></ref><ref id="hanspub.22009-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Ng, T.T., Chang, S.F. and Sun, Q. (2004) Blind Detection of Photomontage Using Higher Order Statistics. Proceeding of the 2004 International Symposium on Circuits and Systems, Columbia, 23-26 May 2004, 688-691.</mixed-citation></ref><ref id="hanspub.22009-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Ng, T.T. and Chang, S.F. (2004) A Model for Image Splicing. Proceedings on 2004 International Conference on Image Processing, Singapore, 24-27 October 2004, 1169-1172.</mixed-citation></ref><ref id="hanspub.22009-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Ferrara, P., Bianchi, T., Rosa, D.A., et al. (2012) Image Forgery Localization via Fine-Grained Analysis of CFA Artifacts. IEEE Transactions on Information Forensics and Security, 7, 1566-1577. 
&lt;br&gt;https://doi.org/10.1109/TIFS.2012.2202227</mixed-citation></ref></ref-list></back></article>