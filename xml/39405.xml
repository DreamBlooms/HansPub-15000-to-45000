<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2020.1012248</article-id><article-id pub-id-type="publisher-id">CSA-39405</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20201200000_66443417.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于卷积神经网络的国兰种类识别系统
  Chinese Orchid Species Recognition System Based on Convolutional Neural Network
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>张</surname><given-names>子赫</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>赵</surname><given-names>吟吟</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff3"><addr-line>浙江农林大学，环境与资源学院，浙江 杭州</addr-line></aff><aff id="aff2"><addr-line>浙江农林大学，信息工程学院，浙江 杭州</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>09</day><month>12</month><year>2020</year></pub-date><volume>10</volume><issue>12</issue><fpage>2346</fpage><lpage>2353</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   针对兰花品种众多，外表相似，导致没法准确识别兰花的种类这一问题，本文构建了基于卷积神经网络的国兰识别模型，设计并实现了模型在移动端的应用。文中通过多种途径完成常见国兰数据集的创建，进而以Inception-ResNet-v2为卷积神经网络预训练模型，使用迁移学习技术完成模型训练，并基于Android平台完成系统的开发和测试。测试结果显示，对传统国兰图像分类识别准确率达到91.51%。 Aiming at the problem that there are many varieties of orchids with similar appearances, which makes it impossible to accurately identify the types of orchids, a Chinese orchid recognition model based on convolutional neural network is constructed, and its transplantation to the mobile terminal is designed and implemented. First, this paper completes the creation of the common Chinese orchid data set through multiple channels, and then uses the Inception-ResNet-v2 convolutional neural network as the pretraining model, uses the transfer learning technology to complete the model construction, and develops and tests the system based on the Android platform. Through experiments and actual tests, the accuracy of classification and recognition of traditional Chinese orchid images reached 91.51%. 
  
 
</p></abstract><kwd-group><kwd>国兰，Inception-ResNet-v2网络，图像识别，Android, Chinese Orchid</kwd><kwd> Inception-Resnet-V2 Network</kwd><kwd> Image Identification</kwd><kwd> Android</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>摘要</title><p>针对兰花品种众多，外表相似，导致没法准确识别兰花的种类这一问题，本文构建了基于卷积神经网络的国兰识别模型，设计并实现了模型在移动端的应用。文中通过多种途径完成常见国兰数据集的创建，进而以Inception-ResNet-v2为卷积神经网络预训练模型，使用迁移学习技术完成模型训练，并基于Android平台完成系统的开发和测试。测试结果显示，对传统国兰图像分类识别准确率达到91.51%。</p></sec><sec id="s2"><title>关键词</title><p>国兰，Inception-ResNet-v2网络，图像识别，Android</p></sec><sec id="s3"><title>Chinese Orchid Species Recognition System Based on Convolutional Neural Network</title><p>Zihe Zhang<sup>1</sup>, Yinyin Zhao<sup>2</sup></p><p><sup>1</sup>College of Information Engineering, Zhejiang A&amp;F University, Hangzhou Zhejiang</p><p><sup>2</sup>College of Environmental and Resource Sciences, Zhejiang A&amp;F University, Hangzhou Zhejiang</p><p><img src="//html.hanspub.org/file/23-1541969x4_hanspub.png" /></p><p>Received: Nov. 27<sup>th</sup>, 2020; accepted: Dec. 21<sup>st</sup>, 2020; published: Dec. 28<sup>th</sup>, 2020</p><p><img src="//html.hanspub.org/file/23-1541969x5_hanspub.png" /></p></sec><sec id="s4"><title>ABSTRACT</title><p>Aiming at the problem that there are many varieties of orchids with similar appearances, which makes it impossible to accurately identify the types of orchids, a Chinese orchid recognition model based on convolutional neural network is constructed, and its transplantation to the mobile terminal is designed and implemented. First, this paper completes the creation of the common Chinese orchid data set through multiple channels, and then uses the Inception-ResNet-v2 convolutional neural network as the pre-training model, uses the transfer learning technology to complete the model construction, and develops and tests the system based on the Android platform. Through experiments and actual tests, the accuracy of classification and recognition of traditional Chinese orchid images reached 91.51%.</p><p>Keywords:Chinese Orchid, Inception-Resnet-V2 Network, Image Identification, Android</p><disp-formula id="hanspub.39405-formula29"><graphic xlink:href="//html.hanspub.org/file/23-1541969x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2020 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/23-1541969x7_hanspub.png" /> <img src="//html.hanspub.org/file/23-1541969x8_hanspub.png" /></p></sec><sec id="s5"><title>1. 引言</title><p>随着时代的发展，人们越来越注重精神世界的培养。国人对于兰花的需求与日俱增，基于兰花的观赏价值以及药用价值 [<xref ref-type="bibr" rid="hanspub.39405-ref1">1</xref>]，加上国际市场的影响，我国兰花市场的发展十分迅速。根据海关数据统计，2017年我国兰花出口量约为六千万株，带来了巨大的经济价值。因而正确区分兰花的种类，确定其合理的价值十分重要。</p><p>近年来，深度学习发展迅速，基于各类神经网络的图像识别研究越来越广泛，然而由于数据量的缺乏，兰花方面的识别存在重大空缺。针对这一问题，本文通过网络搜集、实地拍摄和书籍扫描三种途径完成常见国兰数据集的创建，该数据集由春兰、蕙兰、建兰、墨兰、寒兰5类常见国兰种类构建得到。在此基础上基于迁移学习完成Inception-ResNet-v2 [<xref ref-type="bibr" rid="hanspub.39405-ref2">2</xref>] 深度卷积模型的国兰识别训练，并将训练好的模型移植到移动端，验证兰花识别的效果。</p></sec><sec id="s6"><title>2. Inception-ResNet-v2网络</title><p>Inception-ResNet-v2吸收了Inception V4和ResNet [<xref ref-type="bibr" rid="hanspub.39405-ref3">3</xref>] 的优点，在ImageNet数据集上的测试更加准确。该模型将Inception-ResNet-A、Inception-ResNet-B、Inception-ResNet-C 3种Inception-ResNet块加入直连，从而使得通道多样化。相较Inception V4，Inception-ResNet-v2参数少，收敛快，同时对机器的性能要求也有一定的降低，可以在同实验环境下进行更高的参数设置；Inception-ResNet-v2设计了BN层，这样可以有效实现数据的输出不会发生偏移，数据规范化传输可以有效提高识别的准确度。该模型卷积核的体积很小，但是功能却很强大。Inception-ResNet-v2网络结构如图1所示。</p></sec><sec id="s7"><title>3. 数据集</title><p>针对国兰图像数据集空缺的现状，本文通过中国兰花交易网下载、经典书籍《中国兰花精粹》扫描以及实地拍摄三种途径相结合初步获取5类3000余张国兰图像。经过筛选和预处理，保留1982张高质量的国兰图像进行数据集的构建。为解决因国兰图像不足造成的过拟合现象，本文采用水平翻转，随机裁剪，添加高斯噪声：对原始图像添加了30%的高斯噪声，图像亮度调节(调亮或者调暗)，随机旋转变换(60˚、90˚、180˚、270˚)五种数据增强方式 [<xref ref-type="bibr" rid="hanspub.39405-ref4">4</xref>] 对数据集进行扩充，最终得到12,150张国兰图像。以春建兰为例，数据增强前后对比如图2所示。</p><p>图1. Inception-Resnet-v2网络结构</p><p>图2. 春剑兰图像增强前后对比图</p></sec><sec id="s8"><title>4. 实验及结果分析</title><p>为检验模型效果，分别使用VGG16、VGG19、InceptionV3、InceptionV4、ResNet-50、ResNet-101、ResNet-152、InceptionResNet-v2，8种预训练的卷积神经网络模型进行兰花识别实验，实验方案编号记为1-8，实验结果如表1所示。其中卷积神经网络优化器均为Adam [<xref ref-type="bibr" rid="hanspub.39405-ref5">5</xref>]，迁移训练策略为重新训练预训练网络模型的全部网络层。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Comparison of different CNN model</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >实验编号 Experiment No.</th><th align="center" valign="middle" >网络模型 network models</th><th align="center" valign="middle" >Top-1准确率/% Top-1 accuracy/%</th><th align="center" valign="middle" >平均训练时间/s Average Training time/s</th></tr></thead><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" >VGG16</td><td align="center" valign="middle" >88.33</td><td align="center" valign="middle" >0.675</td></tr><tr><td align="center" valign="middle" >2</td><td align="center" valign="middle" >VGG19</td><td align="center" valign="middle" >86.20</td><td align="center" valign="middle" >0.625</td></tr><tr><td align="center" valign="middle" >3</td><td align="center" valign="middle" >InceptionV3</td><td align="center" valign="middle" >87.95</td><td align="center" valign="middle" >0.297</td></tr><tr><td align="center" valign="middle" >4</td><td align="center" valign="middle" >InceptionV4</td><td align="center" valign="middle" >89.20</td><td align="center" valign="middle" >0.547</td></tr><tr><td align="center" valign="middle" >5</td><td align="center" valign="middle" >ResNet-50</td><td align="center" valign="middle" >85.87</td><td align="center" valign="middle" >0.187</td></tr><tr><td align="center" valign="middle" >6</td><td align="center" valign="middle" >ResNet-101</td><td align="center" valign="middle" >88.58</td><td align="center" valign="middle" >0.312</td></tr><tr><td align="center" valign="middle" >7</td><td align="center" valign="middle" >ResNet-152</td><td align="center" valign="middle" >89.37</td><td align="center" valign="middle" >0.453</td></tr><tr><td align="center" valign="middle" >8</td><td align="center" valign="middle" >Inception-ResNet-V2</td><td align="center" valign="middle" >91.51</td><td align="center" valign="middle" >0.676</td></tr></tbody></table></table-wrap><p>表1. 不同网络模型比较</p><p>从表1中可以看出，ResNet-50网络模型训练结果准确率最低，而Inception-ResNet-v2最高，可以发现当模型深度逐渐上升时，模型的准确率是总体呈现上升趋势的，这也说明了卷积层的深度会对模型识别的准确率造成一定的影响，更深的网络结构会有更高的识别准确率。</p><p>本文使用识别效果最佳的Inception-ResNet-v2网络作为本文的预训练模型，设置初始学习率为0.01，批处理量为16，选取Relu [<xref ref-type="bibr" rid="hanspub.39405-ref6">6</xref>] 函数作为激活函数，并在此基础上，使用Adam优化算法对网络参数进行优化，采用迁移学习方法重新训练网络所有参数层。</p><p>本文研究目标是要完成国兰图像分类识别问题，因此采用多分类交叉熵(Cross entropy)作为损失函数，其表达式如公式1所示：</p><p>C l o s s = − 1 m ∑ j = 1 m ∑ i = 1 n y j i log ( y ^ j i ) (1)</p><p>式中，m为当前一批输入网络的国兰样本数量，n为国兰类别的总数， y j i 为国兰图像真实的标签， y ^ j i 为国兰图像预测的标签， C l o s s 为损失值。交叉熵刻画了实际输出概率与期望输出概率分布之间的距离，交叉熵的值越小，表示模型训练过程的中学习效果越好。</p><p>图3. 常见国兰数据集损失曲线</p><p>由图3训练结果可知，随着迭代次数的增加，交叉熵损失函数呈整体下降趋势，当迭代次数达到40,000步时，交叉熵损失函数基本完成收敛，故选取40,000步作为本模型训练的迭代次数。经测试，在迭代结束时交叉熵损失值为0.1165，经验证对应的准确率为91.51%，具有较高的识别准确率，可以辅助人们更好的识别兰花种类，达到预期目标。</p></sec><sec id="s9"><title>5. 系统设计与实现</title><p>本文国兰识别系统的流程如图4所示，主要由图片获取模块和识别模块组成，最终由信息展示模块输出。通过前文对比实验结果展示，采用迁移学习训练Inception-ResNet-v2预训练模型的全部参数可以达到识别精度高并且训练时间短的要求，其中主要利用该模型卷积层的特征提取功能完成对国兰图像颜色花型等局部特征的提取。</p><p>此系统中，用户可以通过手机拍摄和相册上传两种途径将国兰图片上传到Web服务器端，此后服务端会通过国兰模型对接收到的图片进行识别分类。并根据识别结果将对应的国兰品种详情以及相应的养护知识一起打包发送给手机端屏幕显示。</p><p>图4. 国兰识别系统流程图</p><sec id="s9_1"><title>5.1. 图像获取模块</title><p>图像获取模块主要负责国兰图像的采集 [<xref ref-type="bibr" rid="hanspub.39405-ref7">7</xref>]，以供识别模块调用识别，该模块需能调用智能手机的相机拍摄功能和手机本地相册读取功能，其工作流程如图5所示。</p><p>OpenCV提供的库函数可以完成图像采集部分，主要是由于它所在的图像获取模块由摄像头承接主要任务，而该函数可以很好地完成对摄像头的调用 [<xref ref-type="bibr" rid="hanspub.39405-ref8">8</xref>]。OpenCV是一个可以在很多开发环境上进行运行的开源视觉库，这是由于很大数目的Java接口存在的结构，而且API接口函数获得方法比较简单即在线获得，还能很轻松的对Android应用主要使用的Android NDK [<xref ref-type="bibr" rid="hanspub.39405-ref9">9</xref>] 库进行调用｡结合JNI接口实现本地功能代码，由Android NDK对其进行编译，生成可由Java调用的动态库文件，该动态库文件可被打包编译，以实现国兰识别Android 程序｡</p></sec><sec id="s9_2"><title>5.2. 图像识别模块</title><p>图像识别模块的组成主要有三部分，包括模型的部署、结果的预测和信息的查询这几个部分。这一模块也可以算得上是本应用程序的核心模块，工作流程如图6所示。在接受到国兰图像后，服务器端会将收到的图像输入到国兰识别模型中去，然后根据预测出的结果到数据库中找寻对应种类的国兰信息和养护信息等，其中国兰识别模型部分由前文提到的改进的Inception-ResNet-v2网络国兰图像识别模型来承接。</p><p>图5. 图像获取模块流程图</p><p>图6. 国兰识别模块流程图</p></sec><sec id="s9_3"><title>5.3. 信息展示模块</title><p>信息展示模块的组成相对简单，主要包含接受和展示两部分，工作流程见图7。接受部分首先需要判断网络的状况是否良好，如果网络连接有问题，则直接显示出错，并提示及时检查网络连接。如果检查网络状况正常，则接受从Web服务器端 [<xref ref-type="bibr" rid="hanspub.39405-ref10">10</xref>] 传输来的关于国兰图像种类的详情以及对应养护知识，显示到屏幕上，完成本次识别操作。</p><p>图7. 结果展示模块流程图</p></sec><sec id="s9_4"><title>5.4. 系统界面</title><p>为了对该系统应用进行测试，并且对本研究的实时便捷性进行验证。使用型号为OPPO R9s PLus，搭载Android 6.0.1操作系统的智能手机来完成本次对系统的测试，如果发现不足，及时进行改进和调整。图8展示了系统运行的所有界面。整体页面设计相对简单清晰且易于操作，满足设计该应用程序的初衷。</p><p>图8. 国兰识别系统测试图</p><p>使用者点击开始识别之后，系统会跳转到相机功能页面进行拍照。拍照完成后，系统对接收到的兰花图像自动分类查询，并将对应的国兰种类信息等反馈到详情页面。或者根据需要选择本地相册中的兰花图像进行识别，只需在拍照识别界面点击左下角的相册按钮便可进入国兰相册界面进行选择，选定待识别图像后，点击确定按钮便可自动识别并获得对应的兰花种类详情和养护信息。也可以对相册中的待识别图像重新进行选择，只需点击重选按钮即可撤回操作。兰花详情页面，可以点击页面上的养护知识按获取该种类兰花更多的养护知识。实验显示，从选定图片到获得对应的种类信息大概需要2.5秒，表明该系统较快速便捷，达到了设计的预期。</p></sec></sec><sec id="s10"><title>6. 结束语</title><p>本文通过多种途径获取国兰图像完成了常见国兰图像数据集的构建，并且基于Inception-ResNet-v2网络和迁移学习优化训练完成国兰识别模型。经过实验表明，所设计的模型对兰花品种具有较高的识别准确率，填补了深度学习应用于国兰识别的空缺，同时Android端的应用能够达到辅助人们进行国兰识别的目的。通过多次实验验证，该系统在目前搭载的Android 6.0.1操作系统上具有较强的稳定性，识别准确率较为理想。但由于IOS操作系统的不开源问题，该系统的兼容性还有待进一步提升，这也是未来的研究的重点。</p></sec><sec id="s11"><title>文章引用</title><p>张子赫,赵吟吟. 基于卷积神经网络的国兰种类识别系统 Chinese Orchid Species Recognition System Based on Convolutional Neural Network[J]. 计算机科学与应用, 2020, 10(12): 2346-2353. https://doi.org/10.12677/CSA.2020.1012248</p></sec><sec id="s12"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.39405-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">邵伟丽. 福建省野生兰科植物种质资源调查与保育策略研究[D]: [硕士学位论文]. 福州: 福建农林大学, 2008.</mixed-citation></ref><ref id="hanspub.39405-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Szegedy, C., Ioffe, S., Vanhoucke, V., et al. (2016) Inception-v4, Inception-ResNet and the Impact of Re-sidual Connections on Learning. Thirty-First AAAI Conference on Artificial Intelligence, 4278-4284.</mixed-citation></ref><ref id="hanspub.39405-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">He, K., Zhang, X., Ren, S., et al. (2016) Deep Residual Learning for Image Recognition. Proceedings of the IEEE Conference on Com-puter Vision and Pattern Recognition, Las Vegas, NV, 770-778.  
&lt;br&gt;https://doi.org/10.1109/CVPR.2016.90</mixed-citation></ref><ref id="hanspub.39405-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">杨明欣, 张耀光, 刘涛. 基于卷积神经网络的玉米病害小样本识别研究[J/OL]. 石家庄: 中国生态农业学报(中英文): 1-9. &lt;br&gt;https://doi.org/10.13930/j.cnki.cjea.200375, 2020-11-19.</mixed-citation></ref><ref id="hanspub.39405-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">汤烨, 陆卫忠, 陈成, 等. 基于Adam算法和神经网络的照度计算方法[J]. 照明工程学报, 2019, 30(2): 50-54.</mixed-citation></ref><ref id="hanspub.39405-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">郭子琰, 舒心, 刘常燕, 等. 基于ReLU函数的卷积神经网络的花卉识别算法[J]. 计算机技术与发展, 2018, 28(5): 154-157.</mixed-citation></ref><ref id="hanspub.39405-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">周毅敏, 陈榕. Dalvik虚拟机进程模型分析[J]. 计算机技术与发展, 2010, 20(2): 83-86.</mixed-citation></ref><ref id="hanspub.39405-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Sivkov, S., Novikov, L., Romanova, G., et al. (2020) The Algorithm Development for Operation of a Computer Vision System via the OpenCV Library. Procedia Computer Science, 169, 662-667. 
&lt;br&gt;https://doi.org/10.1016/j.procs.2020.02.193</mixed-citation></ref><ref id="hanspub.39405-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">岳智慧. Android平台上的细分插值算法研究[D]: [硕士学位论文]. 郑州: 郑州大学, 2019.</mixed-citation></ref><ref id="hanspub.39405-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">李群. 基于OkHttp的文件传输设计与实现[J]. 电子技术与软件工程, 2018(13): 180-181.</mixed-citation></ref></ref-list></back></article>