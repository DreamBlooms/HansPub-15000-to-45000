<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2021.115129</article-id><article-id pub-id-type="publisher-id">CSA-42276</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20210500000_32369534.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于深度学习的无监督磁共振图像去噪方法
  An Unsupervised Deep Learning Method for MRI Image Denoising
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>唐</surname><given-names>凡</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>符</surname><given-names>颖</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>李</surname><given-names>燕</given-names></name><xref ref-type="aff" rid="aff4"><sup>4</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff3"><addr-line>成都信息工程大学，四川 成都;四川省图形图像与空间信息2011协同创新中心，四川 成都</addr-line></aff><aff id="aff2"><addr-line>成都信息工程大学，四川 成都</addr-line></aff><aff id="aff4"><addr-line>重庆中烟工业有限责任公司重庆卷烟厂，重庆</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>08</day><month>05</month><year>2021</year></pub-date><volume>11</volume><issue>05</issue><fpage>1268</fpage><lpage>1280</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   近年来，基于深度学习的方法在医学图像去噪方面取得了很好的表现。然而，大多数基于深度学习的方法都需要成对的训练数据，这将影响如新型冠状病毒肺炎等病症的临床诊断。本文提出了一种用于磁共振成像(magnetic resonance image，简称MRI)去噪的无监督学习方法。首先，我们通过内容编码器和随机噪声编码器分离受噪声影响的低质MRI图像的内容信息和噪声信息。其次，利用Kullback-Leibler (KL)散度损失对噪声的分布进行正则化。第三，向模型加入对抗损失，使生成的去噪图像看起来更加真实。最后，我们增加了循环一致损失和感知损失来确保带噪图像和去噪图像内容信息的一致性。实验结果表明，我们提出的方法取得了良好的视觉效果。 Recently, medical image denoising methods based on deep learning have performed well. However, one challenge for most of these methods needs paired synthetic training data, which will affect clinic diagnosis such as COVID-19. In this paper, we proposed an unsupervised learning method for Magnetic Resonance Imaging (MRI) denoising. Firstly, we separated the content and noise of low-quality MRI images affected by noise through the content encoder and random noise encoder. Secondly, we used Kullback-Leibler (KL) loss to regularize the distribution of noise. Thirdly, we apply the adversarial loss on the model to make the denoising images look more realistic. Finally, we added cycle-consistency loss and perception loss to ensure the consistency of the noisy image and the denoised image. Experimental results showed the method we proposed achieved good visual results. 
  
 
</p></abstract><kwd-group><kwd>MRI去噪，莱斯噪声，无监督深度学习，解缠表示, MRI Denoising</kwd><kwd> Rician Noise</kwd><kwd> Unsupervised Deep Learning</kwd><kwd> Disentangled Representations</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>摘要</title><p>近年来，基于深度学习的方法在医学图像去噪方面取得了很好的表现。然而，大多数基于深度学习的方法都需要成对的训练数据，这将影响如新型冠状病毒肺炎等病症的临床诊断。本文提出了一种用于磁共振成像(magnetic resonance image，简称MRI)去噪的无监督学习方法。首先，我们通过内容编码器和随机噪声编码器分离受噪声影响的低质MRI图像的内容信息和噪声信息。其次，利用Kullback-Leibler (KL)散度损失对噪声的分布进行正则化。第三，向模型加入对抗损失，使生成的去噪图像看起来更加真实。最后，我们增加了循环一致损失和感知损失来确保带噪图像和去噪图像内容信息的一致性。实验结果表明，我们提出的方法取得了良好的视觉效果。</p></sec><sec id="s2"><title>关键词</title><p>MRI去噪，莱斯噪声，无监督深度学习，解缠表示</p></sec><sec id="s3"><title>An Unsupervised Deep Learning Method for MRI Image Denoising</title><p>Fan Tang<sup>1</sup>, Ying Fu<sup>1</sup><sup>,2</sup><sup>*</sup>, Yan Li<sup>3</sup></p><p><sup>1</sup>Chengdu University of Information and Technology, Chengdu Sichuan</p><p><sup>2</sup>Image and Spatial Information 2011 Collaborative Innovation Center of Sichuan Province, Chengdu Sichuan</p><p><sup>3</sup>Chongqing China Tobacco Industry Co., Ltd. Chongqing Cigarette Factory, Chongqing</p><p><img src="//html.hanspub.org/file/6-1542150x5_hanspub.png" /></p><p>Received: Apr. 10<sup>th</sup>, 2021; accepted: May 7<sup>th</sup>, 2021; published: May 14<sup>th</sup>, 2021</p><p><img src="//html.hanspub.org/file/6-1542150x6_hanspub.png" /></p></sec><sec id="s4"><title>ABSTRACT</title><p>Recently, medical image denoising methods based on deep learning have performed well. However, one challenge for most of these methods needs paired synthetic training data, which will affect clinic diagnosis such as COVID-19. In this paper, we proposed an unsupervised learning method for Magnetic Resonance Imaging (MRI) denoising. Firstly, we separated the content and noise of low-quality MRI images affected by noise through the content encoder and random noise encoder. Secondly, we used Kullback-Leibler (KL) loss to regularize the distribution of noise. Thirdly, we apply the adversarial loss on the model to make the denoising images look more realistic. Finally, we added cycle-consistency loss and perception loss to ensure the consistency of the noisy image and the denoised image. Experimental results showed the method we proposed achieved good visual results.</p><p>Keywords:MRI Denoising, Rician Noise, Unsupervised Deep Learning, Disentangled Representations</p><disp-formula id="hanspub.42276-formula24"><graphic xlink:href="//html.hanspub.org/file/6-1542150x7_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2021 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/6-1542150x8_hanspub.png" /> <img src="//html.hanspub.org/file/6-1542150x9_hanspub.png" /></p></sec><sec id="s5"><title>1. 引言</title><p>MRI图像是一种以不同灰度显示不同结构的解剖和病理的断面图像，广泛应用于疾病的检测、诊断以及治疗监测。然而，MRI图像的成像过程往往伴随着随机噪声，这导致了低质MRI图像的产生。MRI图像的质量不仅会影响医生对患者病情的判断，还会降低图像配准、图像分割和图像分类等工作的准确性。图像去噪可以提高给定图像的质量，解决随机噪声引起的图像退化的问题。</p><p>为了在去除噪声的同时保持图像内容信息的完整性，研究人员提出了高斯滤波、双边滤波、算术均值滤波等经典空间像素特征去噪算法。与上述方法利用图像的局部信息不同，非局部均值去噪算法利用整个图像的信息进行图像去噪 [<xref ref-type="bibr" rid="hanspub.42276-ref1">1</xref>]。2008年，Jos&#233; V等人成功地将改进的非局部均值去噪算法应用于MRI图像去噪 [<xref ref-type="bibr" rid="hanspub.42276-ref2">2</xref>]。变换域去噪算法是先进行图像域变换，然后再进行图像去噪的一种间接去噪算法，具有代表性的去噪算法包括傅里叶变换、离散余弦变换、小波变换和多尺度几何分析等。Dabov等人将非局部均值算法中相似块的计算与小波变换域 [<xref ref-type="bibr" rid="hanspub.42276-ref3">3</xref>] 中的去噪方法相结合提出了BM3D算法。基于BM3D算法，Eksioglu等人提出了MRI重建算法 [<xref ref-type="bibr" rid="hanspub.42276-ref4">4</xref>]。此外，图像矩阵的低秩约束也是值得注意的 [<xref ref-type="bibr" rid="hanspub.42276-ref5">5</xref>] [<xref ref-type="bibr" rid="hanspub.42276-ref6">6</xref>]。张禹涵等人提出了一种将低秩约束和稀疏梯度先验 [<xref ref-type="bibr" rid="hanspub.42276-ref7">7</xref>] 相结合的磁共振图像去噪模型。</p><p>卷积神经网络在图像识别 [<xref ref-type="bibr" rid="hanspub.42276-ref8">8</xref>] [<xref ref-type="bibr" rid="hanspub.42276-ref9">9</xref>] 领域取得了良好的成果。随后，基于卷积神经网络的图像去噪算法并 [<xref ref-type="bibr" rid="hanspub.42276-ref10">10</xref>] [<xref ref-type="bibr" rid="hanspub.42276-ref11">11</xref>] 也引起了研究人员的注意。其中，DnCNN [<xref ref-type="bibr" rid="hanspub.42276-ref10">10</xref>] [<xref ref-type="bibr" rid="hanspub.42276-ref12">12</xref>]，PRI-PB-CNN [<xref ref-type="bibr" rid="hanspub.42276-ref13">13</xref>]，MIFCN [<xref ref-type="bibr" rid="hanspub.42276-ref14">14</xref>] 等方法具有很强的扩展性，不仅对自然图像有很好的去噪效果，而且可以很好地应用于MRI图像去噪。</p><p>生成对抗网络在生成真实图像 [<xref ref-type="bibr" rid="hanspub.42276-ref15">15</xref>] [<xref ref-type="bibr" rid="hanspub.42276-ref16">16</xref>] 方面有很大的优势，因此研究人员将生成对抗网络和卷积神经网络结合起来进行图像去噪 [<xref ref-type="bibr" rid="hanspub.42276-ref17">17</xref>]。主流去噪算法属于监督领域，需要配对的训练数据 [<xref ref-type="bibr" rid="hanspub.42276-ref18">18</xref>] [<xref ref-type="bibr" rid="hanspub.42276-ref19">19</xref>]。然而，我们很难在现实生活中获得配对数据来训练模型。迁移学习是一种在医学图像分析领域 [<xref ref-type="bibr" rid="hanspub.42276-ref20">20</xref>] 广泛使用的方法，陆思源等人将其用于医学图像检测 [<xref ref-type="bibr" rid="hanspub.42276-ref21">21</xref>]。在训练数据不配对的情况下，我们也利用迁移学习来训练模型。我们提出了一种基于深度学习 [<xref ref-type="bibr" rid="hanspub.42276-ref22">22</xref>] 的无监督图像去噪方法来获得高质量的自然图像和MRI图像。</p><p>本文的主要贡献可以总结如下：1) 提出了一种基于生成对抗网络的无监督学习方法用于医学图像去噪，并且该方法不需要成对训练的数据；2) 用解缠表示分离低质MRI图像的内容信息和噪声信息。</p></sec><sec id="s6"><title>2. 方法</title><p>本模型由以下部分组成，如图1所示：1) 受随机噪声影响的低质图像域的内容编码器 E L C ；高质图像域的内容编码器 E H c ；2) 随机噪声编码器 E n ；3) 低质图像判别器 D L 和高质图像判别器 D H ；4) 低质图像生成器 G L 和高质图像生成器 G H 。</p><p>此外，样本数据如图2所示，样本 l ∈ L 属于低质图像域；样本属于高质图像域 h ∈ H ； z N = E n ( l ) 是噪声特征的分布。</p><p>图1. 去噪模型框架图</p><p>图2. 从SBD获取的用于实验的合成数据。(a)、(b)、(c)、(d)分别截取自(A)、(B)、(C)、(D)。(A)和(C)是干净的MRI图像。(B)和(D)是带有噪声的MRI图像</p><sec id="s6_1"><title>2.1. 解缠表示</title><p>在无监督域中，由于数据是不成对的 [<xref ref-type="bibr" rid="hanspub.42276-ref23">23</xref>] [<xref ref-type="bibr" rid="hanspub.42276-ref24">24</xref>] [<xref ref-type="bibr" rid="hanspub.42276-ref25">25</xref>]，所以我们很难将图像的内容信息与噪声信息分开。本文从两个方面提高带噪图像内容信息和噪声信息的分离程度。一方面，尽可能多的从低质图像中提取有效的内容信息。由于高质图像未受噪声影响，所以 E H c 可从中提取到不带噪声的内容信息。为了能从低质图像中更好的提取内容信息，我们采用了 E L C 和 E H c 共享权重参数的策略。另一方面，我们通过添加KL散度损失来约束噪声特征的分布 z N ，使其近似正态分布 p ( z ) ~ N ( 0 , 1 ) ，KL散度损失如式(1)所示：</p><p>K L ( q ( z N ) | | p ( z ) ) = − ∫ q ( z N ) log p ( z ) q ( z N ) d z (1)</p><p>最小化KL散度和式(2)等价：</p><p>L K L = 1 2 ∑ i = 1 N ( μ i 2 + σ i 2 − log ( σ i 2 ) − 1 ) (2)</p><p>μ 是 z N 的标准差， σ 是 z N 的均值，N是 z N 的维数。 z N 从 z N = μ + z ∗ σ 中采样，其中*是按元素进行的矩阵乘法。</p></sec><sec id="s6_2"><title>2.2. 对抗损失</title><p>为了生成更真实的高质量图像，我们将对抗损失应用于低质图像域和高质图像域 [<xref ref-type="bibr" rid="hanspub.42276-ref22">22</xref>]，如式(3)所示：</p><p>L D h = E h ~ p ( h ) [ log D H ( h ) ] + E l ~ p ( l ) [ log ( 1 − D H ( f a k e h ) ) ] (3)</p><p>f a k e h 如式(4)所示：</p><p>f a k e h = G H ( E L c ( l ) , z N ) (4)</p><p>在训练模型的过程中， G H 试图使生成的图像 f a k e h 看起和来自高质图像域的图像更加相似， D H 希望能够区分 f a k e h 和真实样本h。 G H 在训练中希望尽量减少损失，同时 D H 希望尽量扩大损失，我们将低质图像域中的对抗性损失定义为式(5)：</p><p>L D l = E l ~ p ( l ) [ log D L ( l ) ] + E h ~ p ( h ) [ log ( 1 − D L ( f a k e l ) ) ] (5)</p><p>f a k e l 如式(6)所示：</p><p>f a k e l = G L ( E H c ( h ) , z N ) (6)</p></sec><sec id="s6_3"><title>2.3. 循环一致损失</title><p>在无监督条件下，仅有对抗损失并不能保证原始图像和去噪图像内容信息的一致性。受CycleGAN [<xref ref-type="bibr" rid="hanspub.42276-ref22">22</xref>] 的启发，我们向模型中添加了循环一致性损失，如式(7)所示：</p><p>L c y c = E h ~ p ( h ) [ ‖ h − f a k e h h ‖ 1 ] + E l ~ p ( l ) [ ‖ l − f a k e l l ‖ 1 ] (7)</p><p>在2.2节中，我们生成了 f a k e l 和 f a k e h 。在本节中，我们需要将输入的 f a k e l 重新生成为高质域的图像。重构的高质量图像定义为式(8)：</p><p>f a k e h h = G H ( E L c ( f a k e l ) , E n ( f a k e l ) ) (8)</p><p>与以上类似，我们将 f a k e h 重构为原来的低质域的图像。重构的低质量图像定义如式(9)所示：</p><p>f a k e l l = G L ( E H c ( f a k e h ) , E n ( f a k e l ) ) (9)</p></sec><sec id="s6_4"><title>2.4. 感知损失</title><p>我们希望生成的图像 f a k e l 只包含低质图像l的噪声信息，但是实际实验结果与我们的期望不一致。事实上，由于解缠并不彻底，所以生成的 f a k e l 也包含低质图像l中的内容信息。为了生成更好的 f a k e l ，我们利用感知损失来进一步约束模型。感知损失如式(10)所示：</p><p>L p e = ‖ f e l − l a y e r ( f a k e l ) − f e l − l a y e r ( l ) ‖ 2 2 (10)</p><p>f e l − l a y e r ( x ) 是预训练的卷积神经网络 [<xref ref-type="bibr" rid="hanspub.42276-ref26">26</xref>] 的第l层的特征。</p><p>模型目标函数描述如式(11)所示：</p><p>L o s s = λ D h l ( L D h + L D l ) + λ K L L K L + λ c y c L c y c + λ p e L p e (11)</p><p>给定带有噪声的MRI图像 l t ，我们需要将其输入 G H 到以获得高质量的图像，如式(12)所示：</p><p>d e i m g = G H ( E L c ( l t ) , E n ( l t ) ) (12)</p></sec></sec><sec id="s7"><title>3. 实验结果</title><p>不为了验证我们提出模型的性能，我们将其与经典的图像去噪方法各向异性扩散滤波(Anisotic Diffusion Filter，简称ADF)和基于深度学习的无监督图像去噪方法CycleGAN进行了比较。我们使用从SBD获得的合成MRI数据(T1w和PDw)进行实验。测试数据为带有5%、10%、15%、20%、25%、30%的莱斯噪声的T1w图像和PDw图像。</p><p>图3~8给出了T1w图像的实验结果，从对比图中可以看出我们的去噪方法达到了良好的视觉效果。随着莱斯噪声强度的增加，ADF去噪结果中包含的噪声越来越明显。当噪声强度超过20%后，残余噪声已严重影响到了视觉性能。CycleGAN和我们提出的方法能够有效地除去噪声。</p><p>图3. 带5%莱斯噪声的T1w图像的实验结果</p><p>图4. 带10%莱斯噪声的T1w图像的实验结果</p><p>图5. 带15%莱斯噪声的T1w图像的实验结果</p><p>图6. 带20%莱斯噪声的T1w图像的实验结果</p><p>图7. 带25%莱斯噪声的T1w图像的实验结果</p><p>图8. 带30%莱斯噪声的T1w图像的实验结果</p><p>如表1所示，ADF算法的PSNR和SSIM低于CycleGAN和我们提出的方法。当噪声水平低于25%时，我们提出的算法取得了比其他方法更高的PSNR值。当噪声强度增加到30%时，CycleGAN的PSNR值略优于我们的算法，但是我们提出的算法仍然得到了具有竞争力的SSIM值，结果如表2所示。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> PSNR results for different methods on the T1w image with different Rician noise level</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >方法</th><th align="center" valign="middle" >5%</th><th align="center" valign="middle" >10%</th><th align="center" valign="middle" >15%</th><th align="center" valign="middle" >20%</th><th align="center" valign="middle" >25%</th><th align="center" valign="middle" >30%</th></tr></thead><tr><td align="center" valign="middle" >ADF</td><td align="center" valign="middle" >20.6106</td><td align="center" valign="middle" >20.3751</td><td align="center" valign="middle" >19.8617</td><td align="center" valign="middle" >18.9694</td><td align="center" valign="middle" >17.9012</td><td align="center" valign="middle" >16.8302</td></tr><tr><td align="center" valign="middle" >CycleGAN</td><td align="center" valign="middle" >20.0163</td><td align="center" valign="middle" >20.1530</td><td align="center" valign="middle" >20.2088</td><td align="center" valign="middle" >20.1578</td><td align="center" valign="middle" >20.0792</td><td align="center" valign="middle" >19.7676</td></tr><tr><td align="center" valign="middle" >Ours</td><td align="center" valign="middle" >22.5134</td><td align="center" valign="middle" >22.4281</td><td align="center" valign="middle" >22.3678</td><td align="center" valign="middle" >21.4129</td><td align="center" valign="middle" >20.4036</td><td align="center" valign="middle" >19.3042</td></tr></tbody></table></table-wrap><p>表1. T1w图像的PSNR结果</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> SSIM results for different methods on the T1w image with different Rician noise level</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >方法</th><th align="center" valign="middle" >5%</th><th align="center" valign="middle" >10%</th><th align="center" valign="middle" >15%</th><th align="center" valign="middle" >20%</th><th align="center" valign="middle" >25%</th><th align="center" valign="middle" >30%</th></tr></thead><tr><td align="center" valign="middle" >ADF</td><td align="center" valign="middle" >0.7497</td><td align="center" valign="middle" >0.7125</td><td align="center" valign="middle" >0.6368</td><td align="center" valign="middle" >0.5044</td><td align="center" valign="middle" >0.3906</td><td align="center" valign="middle" >0.3104</td></tr><tr><td align="center" valign="middle" >CycleGAN</td><td align="center" valign="middle" >0.7606</td><td align="center" valign="middle" >0.7339</td><td align="center" valign="middle" >0.6901</td><td align="center" valign="middle" >0.6397</td><td align="center" valign="middle" >0.5897</td><td align="center" valign="middle" >0.5404</td></tr><tr><td align="center" valign="middle" >Ours</td><td align="center" valign="middle" >0.7604</td><td align="center" valign="middle" >0.7259</td><td align="center" valign="middle" >0.6768</td><td align="center" valign="middle" >0.6191</td><td align="center" valign="middle" >0.5569</td><td align="center" valign="middle" >0.4986</td></tr></tbody></table></table-wrap><p>表2. T1w图像的SSIM结果</p><p>图9. 带5%莱斯噪声的PDw图像的实验结果</p><p>图10. 带10%莱斯噪声的PDw图像的实验结果</p><p>图11. 带15%莱斯噪声的PDw图像的实验结果</p><p>图12. 带20%莱斯噪声的PDw图像的实验结果</p><p>图13. 带25%莱斯噪声的PDw图像的实验结果</p><p>图14. 带30%莱斯噪声的PDw图像的实验结果</p><table-wrap id="table3" ><label><xref ref-type="table" rid="table3">Table 3</xref></label><caption><title> PSNR results for different methods on the PDw image with different Rician noise level</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >Method</th><th align="center" valign="middle" >5%</th><th align="center" valign="middle" >10%</th><th align="center" valign="middle" >15%</th><th align="center" valign="middle" >20%</th><th align="center" valign="middle" >25%</th><th align="center" valign="middle" >30%</th></tr></thead><tr><td align="center" valign="middle" >ADF</td><td align="center" valign="middle" >15.7612</td><td align="center" valign="middle" >15.7056</td><td align="center" valign="middle" >15.5447</td><td align="center" valign="middle" >15.2093</td><td align="center" valign="middle" >14.7566</td><td align="center" valign="middle" >14.2606</td></tr><tr><td align="center" valign="middle" >CycleGAN</td><td align="center" valign="middle" >20.1043</td><td align="center" valign="middle" >20.1353</td><td align="center" valign="middle" >20.1436</td><td align="center" valign="middle" >20.1450</td><td align="center" valign="middle" >20.1828</td><td align="center" valign="middle" >20.1941</td></tr><tr><td align="center" valign="middle" >Ours</td><td align="center" valign="middle" >21.2514</td><td align="center" valign="middle" >20.9109</td><td align="center" valign="middle" >20.4918</td><td align="center" valign="middle" >20.0560</td><td align="center" valign="middle" >19.6652</td><td align="center" valign="middle" >19.1893</td></tr></tbody></table></table-wrap><p>表3. PDw图像的PSNR结果</p><table-wrap id="table4" ><label><xref ref-type="table" rid="table4">Table 4</xref></label><caption><title> SSIM results for different methods on the PDw image with different Rician noise level</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >Method</th><th align="center" valign="middle" >5%</th><th align="center" valign="middle" >10%</th><th align="center" valign="middle" >15%</th><th align="center" valign="middle" >20%</th><th align="center" valign="middle" >25%</th><th align="center" valign="middle" >30%</th></tr></thead><tr><td align="center" valign="middle" >ADF</td><td align="center" valign="middle" >0.7807</td><td align="center" valign="middle" >0.7548</td><td align="center" valign="middle" >0.6819</td><td align="center" valign="middle" >0.5378</td><td align="center" valign="middle" >0.4159</td><td align="center" valign="middle" >0.3358</td></tr><tr><td align="center" valign="middle" >CycleGAN</td><td align="center" valign="middle" >0.7249</td><td align="center" valign="middle" >0.7094</td><td align="center" valign="middle" >0.6855</td><td align="center" valign="middle" >0.6581</td><td align="center" valign="middle" >0.6302</td><td align="center" valign="middle" >0.6027</td></tr><tr><td align="center" valign="middle" >Ours</td><td align="center" valign="middle" >0.6588</td><td align="center" valign="middle" >0.6457</td><td align="center" valign="middle" >0.6296</td><td align="center" valign="middle" >0.6120</td><td align="center" valign="middle" >0.5940</td><td align="center" valign="middle" >0.5721</td></tr></tbody></table></table-wrap><p>表4. PDw图像的SSIM结果</p><p>为了证明我们提出方法的鲁棒性，我们对不同莱斯噪声水平的PDw图像进行了实验。实验结果如图9~14所示，从图中可以看出我们的方法可以适应不同噪声强度下的去噪工作。随着噪声强度的增加，HDF结果残余的噪声逐渐增大。当噪声强度超过20%时，未去除的噪声已严重影响视觉性能。随着噪声水平的增加，Cyclegan的去噪结果显示出奇怪的纹理。</p><p>如表3所示，当噪声强度小于15%时，我们的方法达到了最佳的PSNR值。当噪声强度增大时，我们的算法仍能得到较高的PSNR值。如表4所示，当噪声强度小于10%时，使用ADF得到的去噪结果SSIM值最优。之后，Cyclegan的结果超过ADF达到了最优值。</p></sec><sec id="s8"><title>4. 结论</title><p>除去低质MRI图像中的噪声获得高质MRI图像具有重要意义。本文提出了一种基于生成对抗网络的无监督图像去噪算法。模型通过解缠表示将噪声图像的内容信息和噪声信息分开，并使用KL散度损失对噪声的分布进行正则化。模型采用感知损失和循环一致损失来保证噪声图像和去噪图像之间内容信息的一致性。将对抗损失添加到模型中，以生成更真实的MRI图像。实验结果表明我们提出的方法具有较好的去噪效果。</p><p>由于该模型的参数量比较大，所以对训练平台有一定要求。因此，我们计划优化网络结构，在不影响去噪性能的前提下减少模型参数的数量。</p></sec><sec id="s9"><title>基金项目</title><p>四川省科技计划资助项目(2019ZDZX0005)；国家留学基金管理委员会资助项目(201908515022)。</p></sec><sec id="s10"><title>文章引用</title><p>唐 凡,符 颖,李 燕. 基于深度学习的无监督磁共振图像去噪方法An Unsupervised Deep Learning Method for MRI Image Denoising[J]. 计算机科学与应用, 2021, 11(05): 1268-1280. https://doi.org/10.12677/CSA.2021.115129</p></sec><sec id="s11"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.42276-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Buades, A., Coll, B. and Morel, J.-M. (2005) A Non-Local Algorithm for Image Denoising. 2005 IEEE Computer Soci-ety Conference on Computer Vision and Pattern Recognition (CVPR’05), San Diego, 20-25 June 2005, 60-65.</mixed-citation></ref><ref id="hanspub.42276-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Manjón, J.V., Carbonell-Caballero, J., A, Lull, J.J., García-Martí, G., Martí-Bonmatí, L. and Robles, M. (2008) MRI Denoising Using Non-Local Means. Medical Image Analysis, 12, 514-523.  
&lt;br&gt;https://doi.org/10.1016/j.media.2008.02.004</mixed-citation></ref><ref id="hanspub.42276-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Dabov, K., Foi, A., Katkovnik, V. and Egiazarian, K. (2007) Image Denoising by Sparse 3-D Transform-Domain Collaborative Filtering. IEEE Transactions on Image Processing, 16, 2080-2095.  
&lt;br&gt;https://doi.org/10.1109/TIP.2007.901238</mixed-citation></ref><ref id="hanspub.42276-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Eksioglu, E.M. (2016) Decoupled Algorithm for MRI Reconstruc-tion Using Nonlocal Block Matching Model: BM3D-MRI. Journal of Mathematical Imaging &amp; Vision, 56, 430-440. &lt;br&gt;https://doi.org/10.1007/s10851-016-0647-7</mixed-citation></ref><ref id="hanspub.42276-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Dong, W., Shi, G. and Li, X. (2013) Nonlocal Image Restoration with Bilateral Variance Estimation: A Low-Rank Approach. IEEE Transactions on Image Processing, 22, 700-711. &lt;br&gt;https://doi.org/10.1109/TIP.2012.2221729</mixed-citation></ref><ref id="hanspub.42276-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Dong, W., Shi, G., Li, X., Ma, Y. and Huang, F. (2014) Compres-sive Sensing via Nonlocal Low-Rank Regularization. IEEE Transactions on Image Processing, 23, 3618-3632. &lt;br&gt;https://doi.org/10.1109/TIP.2014.2329449</mixed-citation></ref><ref id="hanspub.42276-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Zhang, Y., Yang, Z., Hu, J., Zou, S. and Fu, Y. (2019) MRI De-noising Using Low Rank Prior and Sparse Gradient Prior. IEEE Access, 7, 45858-45865. &lt;br&gt;https://doi.org/10.1109/ACCESS.2019.2907637</mixed-citation></ref><ref id="hanspub.42276-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Krizhevsky, A., Sutskever, I. and Hinton, G.E. (2017) ImageNet Classification with Deep Convolutional Neural Networks. Communications of the ACM, 60, 84-90. &lt;br&gt;https://doi.org/10.1145/3065386</mixed-citation></ref><ref id="hanspub.42276-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Vanhoucke, V. and Rabinovich, A. (2015) Going Deeper with Convolutions. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Boston, 7-12 June 2015, 1-9. &lt;br&gt;https://doi.org/10.1109/CVPR.2015.7298594</mixed-citation></ref><ref id="hanspub.42276-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Zhang, K., Zuo, W., Chen, Y., Meng, D. and Zhang, L. (2016) Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising. IEEE Transactions on Image Pro-cessing, 26, 3142-3155.  
&lt;br&gt;https://doi.org/10.1109/TIP.2017.2662206</mixed-citation></ref><ref id="hanspub.42276-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Zhang, K., Zuo, W. and Zhang, L. (2017) FFDNet: Toward a Fast and Flexible Solution for CNN Based Image Denoising. IEEE Transactions on Image Processing, 27, 4608-4622.</mixed-citation></ref><ref id="hanspub.42276-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Jiang, D., Dou, W., Vosters, L., et al. (2018) Denoising of 3D Magnetic Resonance Images with Mul-ti-Channel Residual Learning of Convolutional Neural Network. Japanese Journal of Radiology, 36, 566-574. 
&lt;br&gt;https://doi.org/10.1007/s11604-018-0758-8</mixed-citation></ref><ref id="hanspub.42276-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Manjón, J.V. and Coupé, P. (2018) MRI Denoising Using Deep Learning. In: Bai, W., Sanroma, G., Wu, G., Munsell, B., Zhan, Y. and Coupé, P., Eds., International Workshop on Patch-Based Techniques in Medical Imaging, Springer, Cham, 12-19. &lt;br&gt;https://doi.org/10.1007/978-3-030-00500-9_2</mixed-citation></ref><ref id="hanspub.42276-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">Abbasi, A., Monadjemi, A., Fang, L., Rabbani, H. and Zhang, Y. (2019) Three-Dimensional Optical Coherence Tomography Image Denoising through Multi-Input Ful-ly-Convolutional Networks. Computers in Biology and Medicine, 108, 1-8. &lt;br&gt;https://doi.org/10.1016/j.compbiomed.2019.01.010</mixed-citation></ref><ref id="hanspub.42276-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">Goodfellow, I.J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., et al. (2014) Generative Adversarial Networks. Advances in Neural Information Processing Systems, 3, 2672-2680.</mixed-citation></ref><ref id="hanspub.42276-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">Radford, A., Metz, L. and Chintala, S. (2015) Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks. arXiv preprint arXiv:1511.06434.</mixed-citation></ref><ref id="hanspub.42276-ref17"><label>17</label><mixed-citation publication-type="other" xlink:type="simple">Arjovsky, M., Chintala, S. and Bottou, L. (2017) Wasserstein Gan. arXiv preprint arXiv:1701.07875.</mixed-citation></ref><ref id="hanspub.42276-ref18"><label>18</label><mixed-citation publication-type="other" xlink:type="simple">Chen, J., Chen, J., Chao, H. and Yang, M. (2018) Image Blind Denoising with Generative Adversarial Network Based Noise Modeling. 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Salt Lake City, 18-23 June 2018, 3155-3164. &lt;br&gt;https://doi.org/10.1109/CVPR.2018.00333</mixed-citation></ref><ref id="hanspub.42276-ref19"><label>19</label><mixed-citation publication-type="other" xlink:type="simple">Yeh, R.A., Lim, T.Y., Chen, C., Schwing, A.G., Hasega-wa-Johnson, M. and Do, M. (2018) Image Restoration with Deep Generative Models. 2018 IEEE International Confer-ence on Acoustics, Speech and Signal Processing (ICASSP), Calgary, 15-20 April 2018, 6772-6776. &lt;br&gt;https://doi.org/10.1109/ICASSP.2018.8462317</mixed-citation></ref><ref id="hanspub.42276-ref20"><label>20</label><mixed-citation publication-type="other" xlink:type="simple">Lu, S., Lu, Z. and Zhang, Y.D. (2019) Pathological Brain De-tection Based on AlexNet and Transfer Learning. Journal of Computational Science, 30, 41-47. &lt;br&gt;https://doi.org/10.1016/j.jocs.2018.11.008</mixed-citation></ref><ref id="hanspub.42276-ref21"><label>21</label><mixed-citation publication-type="other" xlink:type="simple">Lu, S., Wang, S.H. and Zhang, Y.D. (2020) Detection of Abnormal Brain in MRI via Improved AlexNet and ELM Optimized by Chaotic Bat Algorithm. Neural Computing and Applica-tions. &lt;br&gt;https://doi.org/10.1007/s00521-020-05082-4</mixed-citation></ref><ref id="hanspub.42276-ref22"><label>22</label><mixed-citation publication-type="other" xlink:type="simple">Zhu, J.Y., Park, T., Isola, P. and Efros, A.A. (2017) Un-paired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks. 2017 IEEE International Conference on Computer Vision (ICCV), Venice, 22-29 October 2017, 2242-2251. &lt;br&gt;https://doi.org/10.1109/ICCV.2017.244</mixed-citation></ref><ref id="hanspub.42276-ref23"><label>23</label><mixed-citation publication-type="other" xlink:type="simple">Tran, L., Yin, X. and Liu, X. (2017) Disentangled Representation Learning GAN for Pose-Invariant Face Recognition. 2017 IEEE Conference on Computer Vision and Pattern Recogni-tion (CVPR), Honolulu, 21-26 July 2017, 1283-1292.  
&lt;br&gt;https://doi.org/10.1109/CVPR.2017.141</mixed-citation></ref><ref id="hanspub.42276-ref24"><label>24</label><mixed-citation publication-type="other" xlink:type="simple">Liu, Y., Wei, F., Shao, J., Sheng, L., Yan, J. and Wang, X. (2018) Exploring Disentangled Feature Representation Beyond Face Identification. 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Salt Lake City, 18-23 June 2018, 2080-2089. &lt;br&gt;https://doi.org/10.1109/CVPR.2018.00222</mixed-citation></ref><ref id="hanspub.42276-ref25"><label>25</label><mixed-citation publication-type="other" xlink:type="simple">Kingma, D.P. and Welling, M. (2013) Auto-Encoding Variational Bayes. arXiv preprint arXiv:1312.6114.</mixed-citation></ref><ref id="hanspub.42276-ref26"><label>26</label><mixed-citation publication-type="other" xlink:type="simple">Simonyan, K. and Zisserman, A. (2014) Very Deep Convolutional Net-works for Large-Scale Image Recognition. arXiv preprint arXiv:1409.1556.</mixed-citation></ref></ref-list></back></article>