<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2020.101012</article-id><article-id pub-id-type="publisher-id">CSA-34009</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20200100000_23248912.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于LPQ特征的视网膜OCT图像分类算法
  Algorithm for Classification of the Retinal OCT Images with LPQ Features
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>任</surname><given-names>岚</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>穆</surname><given-names>国旺</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>河北工业大学理学院，天津</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>31</day><month>12</month><year>2019</year></pub-date><volume>10</volume><issue>01</issue><fpage>112</fpage><lpage>117</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   为缓解我国眼科疾病患者多、医生少、医疗压力巨大的国情，提出一种基于局部相位量化(local phase quantization, LPQ)特征的视网膜OCT图像分类算法。首先对图像进行预处理，主要包括对感兴趣区域探测阶段、拟合阶段和切割阶段；其次提取切割后图像的LPQ特征；然后利用PCA方法对其降维；最后，利用SVM进行分类。在Duke视网膜数据集上对算法进行了验证，并和现有文献中提到的LBP特征、Gabor特征及SIFT特征进行了对比研究。实验结果表明，利用LPQ特征可以得到相对更好的分类结果。 In order to alleviate the situation of more ophthalmology patients, few doctors and huge medical pressure in China, an algorithm for classification of retinal OCT images with LPQ features is proposed. Firstly, the acquired OCT images are preprocessed in three steps including the perceiving phase, the fitting phase and the cutting phase; Secondly, LPQ features are extracted; Then PCA method is used to reduce the dimensionality; Finally, the SVM is employed for classification of images. The algorithm is verified on Duke retinal data set, and is compared with those methods which use LBP feature, Gabor feature or SIFT feature. Experimental results show that the LPQ feature can obtain relatively better classification results. 
  
 
</p></abstract><kwd-group><kwd>计算机辅助诊断，视网膜OCT图像，局部相位量化，主成分分析，支持向量机, Computer Aided Diagnosis</kwd><kwd> Retinal OCT Image</kwd><kwd> Local Phase Quantization</kwd><kwd> Principal Component Analysis</kwd><kwd> Support Vector Machine</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>基于LPQ特征的视网膜OCT图像分类算法<sup> </sup></title><p>任岚，穆国旺</p><p>河北工业大学理学院，天津</p><p>收稿日期：2019年12月29日；录用日期：2020年1月10日；发布日期：2020年1月17日</p><disp-formula id="hanspub.34009-formula17"><graphic xlink:href="//html.hanspub.org/file/12-1541646x5_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>为缓解我国眼科疾病患者多、医生少、医疗压力巨大的国情，提出一种基于局部相位量化(local phase quantization, LPQ)特征的视网膜OCT图像分类算法。首先对图像进行预处理，主要包括对感兴趣区域探测阶段、拟合阶段和切割阶段；其次提取切割后图像的LPQ特征；然后利用PCA方法对其降维；最后，利用SVM进行分类。在Duke视网膜数据集上对算法进行了验证，并和现有文献中提到的LBP特征、Gabor特征及SIFT特征进行了对比研究。实验结果表明，利用LPQ特征可以得到相对更好的分类结果。</p><p>关键词 :计算机辅助诊断，视网膜OCT图像，局部相位量化，主成分分析，支持向量机</p><disp-formula id="hanspub.34009-formula18"><graphic xlink:href="//html.hanspub.org/file/12-1541646x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2020 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/12-1541646x7_hanspub.png" /> <img src="//html.hanspub.org/file/12-1541646x8_hanspub.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>光学相干断层扫描(Optical coherence tomography, OCT)可以用来观察视网膜的形态，所以近些年被广泛应用于眼科疾病的诊断。目前，视网膜疾病的诊断，如年龄相关性黄斑变性(Age-related macular degeneration, AMD)和糖尿病视网膜病变(分别是老年人和糖尿病患者失明的主要原因)主要基于临床检查和专业的眼科医生对OCT图像的主观分析 [<xref ref-type="bibr" rid="hanspub.34009-ref1">1</xref>]。在我国，眼科疾病患者多、医生少的矛盾非常突出，为了减轻医生负担、提高诊断的效率和准确度，开发基于OCT图像的视网膜疾病计算机辅助诊断系统具有重要的意义，其中涉及到的关键技术问题是视网膜OCT图像的分割和分类问题 [<xref ref-type="bibr" rid="hanspub.34009-ref2">2</xref>]。</p><p>近些年，许多研究者致力于视网膜疾病分类算法的研究。在2011年，Liu等人 [<xref ref-type="bibr" rid="hanspub.34009-ref3">3</xref>] 利用LBP特征和多尺度空间金字塔，提出了在视网膜中心凹OCT图像中检测视网膜疾病的算法。2012年，Zheng等人 [<xref ref-type="bibr" rid="hanspub.34009-ref4">4</xref>] 提出了一个利用图论来帮助分类视网膜疾病的算法。2013年，Zhang等人 [<xref ref-type="bibr" rid="hanspub.34009-ref5">5</xref>] 利用核主成分分析(KPCA)对正常的眼睛和晚期AMD眼睛进行分类，分类精度达到92%；2014年，Mookiah等人 [<xref ref-type="bibr" rid="hanspub.34009-ref6">6</xref>] 基于Gabor特征提出一种自动检测干性AMD的算法，并经过两组数据的验证，得到了一个相对不错的分类精度；Srinivasan等人 [<xref ref-type="bibr" rid="hanspub.34009-ref7">7</xref>] 设计了基于方向梯度直方图(HOG)特征的OCT视网膜病变图像分类方法，对健康视网膜、AMD、DME进行分类，取得了较高的分类精度；2017年，孙延奎等人 [<xref ref-type="bibr" rid="hanspub.34009-ref8">8</xref>] 在Srinivasan等人 [<xref ref-type="bibr" rid="hanspub.34009-ref7">7</xref>] 研究的基础上，提出了一个基于稀疏编码和字典学习的全自动检测AMD和DME的框架，并且分别采用Duke光谱域数据与北京某医院的临床数据对算法进行验证，分类精度比较理想。近年来，由于深度学习在计算机视觉、语音识别、自然语言处理方面的成功应用，很多学者开始将深度学习方法应用于视网膜疾病的分类方面 [<xref ref-type="bibr" rid="hanspub.34009-ref9">9</xref>] [<xref ref-type="bibr" rid="hanspub.34009-ref10">10</xref>] [<xref ref-type="bibr" rid="hanspub.34009-ref11">11</xref>] [<xref ref-type="bibr" rid="hanspub.34009-ref12">12</xref>]。</p><p>这些算法无论是从准确性还是减轻工作量的角度都可以极大地帮助医生对眼科疾病进行诊断。但仍然存在一些问题：1) 对于视网膜OCT图像，现有文献中采用的特征有LBP特征 [<xref ref-type="bibr" rid="hanspub.34009-ref3">3</xref>] 、Gabor特征 [<xref ref-type="bibr" rid="hanspub.34009-ref6">6</xref>] 、SIFT特征 [<xref ref-type="bibr" rid="hanspub.34009-ref8">8</xref>] 等少数几种，因此，还有必要尝试新的特征，以进一步提高诊断的准确率；2) 现有文献中的高精度算法，其算法的效率比较低，计算复杂度比较高，不利于对眼科疾病的实时诊断。本文在孙延奎等人 [<xref ref-type="bibr" rid="hanspub.34009-ref8">8</xref>] 的研究基础上，提出了一种基于局部相位量化(local phase quantization, LPQ)特征的视网膜OCT图像分类算法，算法的主要步骤如图1所示。</p><p>图1. 本文算法流程</p></sec><sec id="s4"><title>2. 预处理</title><p>视网膜OCT图像在获取过程中不可避免地会受到外界因素的影响，在图像上产生噪声，尤其是斑点噪声，严重影响后期对图像的分析。其次，在OCT成像过程中，视网膜的形态、位置会发生大幅度的变化，这使得无法将全部的视网膜对齐到一个相对统一的位置上，并且OCT图像中包含了大量的无关部分，这些问题都严重影响之后的图像特征提取以及分类的准确度。因此，在提取特征前，需要对图像进行必要的预处理操作。本文参照孙延奎等人在文献 [<xref ref-type="bibr" rid="hanspub.34009-ref8">8</xref>] 中的操作，将预处理过程分成三部分：感兴趣区域探测阶段、拟合阶段、切割阶段。</p><p>在感兴趣区域探测阶段，主要的目的是获取整个视网膜形态，具体步骤如下：1) 利用BM3D [<xref ref-type="bibr" rid="hanspub.34009-ref13">13</xref>] 滤波器对原图像去噪；2) 去除左右空白边缘，并用OCT图像中背景像素的平均值填补图像上下部分的无关空白图像；3) 利用Otsu算法 [<xref ref-type="bibr" rid="hanspub.34009-ref14">14</xref>]，对去噪后图像进行全局阈值处理，获取视网膜结构；4) 对阈值处理后的图像进行中值滤波，去除视网膜周边的黑色斑点；5) 利用形态学闭操作去除视网膜内部的大的黑色斑点，这些斑点无法用中值滤波来去除；6) 利用形态学开操作去除视网膜外的白色斑点。</p><p>在拟合阶段，为了将不同图像中视网膜区域对齐，本文从形态学开操作后得到的图像中提取两组数据点：中间数据点(在每列像素中，通过对白色像素的坐标取平均值得到中间数据点的坐标)和底部数据点(在每列像素中，取最下边的白色像素作为底部数据点)。然后，对中间数据点作二次多项式拟合，如果拟合开口向上则选用中间数据点，否则选用底部数据点。</p><p>当选择中间数据点时，继续用数据点作线性拟合，比较两种拟合点集与原中间数据点的相关系数，最终选择相关系数高的拟合方法。当选择底部数据点集时，对底部数据点作二次多项式拟合，如果开口向上，则继续用数据点作线性拟合，然后选用相关系数大的拟合方法；如果开口向下，则直接选用线性拟合方法 [<xref ref-type="bibr" rid="hanspub.34009-ref8">8</xref>]。</p><p>在切割阶段，根据上述拟合的结果，将视网膜对齐，然后切割掉对识别视网膜类型无关紧要的部分。具体过程为：对每一列像素向上或向下平移若干像素，使得拟合曲线上的像素点位于一条水平线上，然后根据对齐后白色像素的最高点和最低点，切割出图像的感兴趣部分。根据此方法，可以保留有利于分类的视网膜形态结构，并且去除无关紧要的干扰部分。</p><p>图2为视网膜OCT图像预处理过程的示例。</p><p>图2. 图像预处理示例：(a) 原OCT图像；(b) 去噪；(c) 去除、填充空白；(d) 阈值化；(e) 中值滤波；(f) 形态学闭操作；(g) 形态学开操作；(h) 多项式拟合；(i) 视网膜对齐</p></sec><sec id="s5"><title>3. 特征提取和分类</title><sec id="s5_1"><title>3.1. LPQ特征</title><p>LPQ是一种处理空间模糊图像纹理的特征描述子，该特征描述子具有模糊不变性 [<xref ref-type="bibr" rid="hanspub.34009-ref15">15</xref>] [<xref ref-type="bibr" rid="hanspub.34009-ref16">16</xref>]。LPQ特征通过在灰度图像 f ( x ) 上的每个像素点x的 M &#215; M 的矩形邻域 N x 进行离散傅里叶变换提取相位信息，即</p><p>F ( u , x ) = ∑ y ∈ N x f ( x ) e − j 2 π u T ( y − x ) = W u T f x (1)</p><p>其中 W u 为频率 u 的2维离散傅里叶变换的基向量， f x 为 N x 中 M 2 个像素的灰度值所组成的向量。</p><p>LPQ只在 u 1 = [ a , 0 ] T ， u 2 = [ 0 , a ] T ， u 3 = [ a , a ] T ， u 4 = [ a , − a ] T 四个频率点上考虑傅里叶系数，其中a为一个足够小的数。令</p><p>F x = [ F ( u 1 , x ) , F ( u 2 , x ) , F ( u 3 , x ) , F ( u 4 , x ) ]</p><p>傅里叶系数中的相位信息由 F x 中每个分量的实部和虚部表示，可以通过一个简单的分级量化方法量化：</p><p>q j ( x ) = { 1 g j ( x ) ≥ 0 0 否 则</p><p>其中 g j ( x ) 为 G x = [ R e { F x } , l m { F x } ] 向量中的第j个分量。量化系数通过二进制编码 b = ∑ j = 1 8 q j 2 j − 1 表示</p><p>为一个[0,255]的整数。在提取图像的LPQ特征时，需要首先将图像分割成一些小的矩形块，在每个矩形块上，计算每个像素的量化系数，然后再在每个块上生成量化系数的直方图，最后将所有矩形块的直方图向量串联起来，得到图像的LPQ特征。</p></sec><sec id="s5_2"><title>3.2. 特征降维和分类</title><p>对图像进行特征提取后，由于特征维数过高，不仅加大了计算的复杂度，而且特征中包含冗余信息以及噪音信息，使得在识别过程中造成误差，降低准确度。降维可以帮助减少冗余信息所造成的误差，提高效率，增强准确度。本文选用主成分分析(Principal Component Analysis, PCA)对提取的LPQ特征进行降维，之后选用线性的SVM对数据进行分类。PCA是最常用的线性降维方法，它的目标是通过某种线性投影，将高维的数据映射到低维的空间中表示，并期望在所投影的维度上数据的方差最大，以此使用较少的数据维度，同时保留住较多的原数据点的特性。</p></sec></sec><sec id="s6"><title>4. 数值实验</title><p>本文选用Duke视网膜OCT数据对算法进行验证。该数据集包含45名志愿者的视网膜OCT图像，其中包含15名正常人，15名AMD患者，15名DME患者的视网膜OCT图像 [<xref ref-type="bibr" rid="hanspub.34009-ref7">7</xref>]。和其他文献一样，本文采用留三法交叉验证，即每次随机从每个类别中选出一个志愿者的数据作为测试样本，其余42名志愿者的数据作为训练样本。为了得到的结论具有一般性，我们按照此种方法选取20组训练样本和测试样本。</p><p>在预处理阶段的操作及参数设置如下：选用BM3D对原视网膜OCT图像去噪，其中 取25；使用Otsu算法自动地对每个图像进行阈值处理；选用35 &#215; 35的中值滤波器进行滤波；利用大小为40的圆形结构元进行形态学闭操作，利用大小为5的圆形结构元进行形态学开操作。最后，将分割后的图像大小统一缩放为40 &#215; 200。在特征提取阶段，本文采用LPQ特征，然后再利用PCA对所得的特征向量进行降维，最后，采用线性支持向量机对图像进行分类。为了更为客观地评价本文所提出的算法，我们对于随机选取的20组训练样本和测试样本，分别采用LPQ特征和现有文献中提到的LBP特征 [<xref ref-type="bibr" rid="hanspub.34009-ref3">3</xref>] 、Gabor特征 [<xref ref-type="bibr" rid="hanspub.34009-ref6">6</xref>] 以及SIFT特征 [<xref ref-type="bibr" rid="hanspub.34009-ref8">8</xref>] 进行实验，并统计在20组测试样本上的平均识别率。</p><p>图3给出了采用这四种特征时，平均识别率随PCA降维后维数变化的曲线。从图中可以看出，对于不同的维数，选用LBP特征的平均识别率整体最低且幅度最大，而LPQ、SIFT与Gabor三种特征的平均识别率相对比较平稳，总的来讲，LPQ特征的平均识别率相对于其他三种特征要更高。可见LPQ特征在视网膜疾病分类方面，表现出更好的优势，具有很好的鲁棒性。四种特征的最高平均识别率如表1所示。从表中可见LPQ特征在800维时平均精度可以达到92.23%，明显高于其他三种特征，可见LPQ特征要更适用于视网膜OCT图像，可以很好的表征视网膜图像的纹理特征，能够更好的结合分类算法对视网膜图像进行分类，提高分类精度。</p><p>图3. 平均识别率随维数变化的曲线</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Comparison of classification result</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >特征名称</th><th align="center" valign="middle" >特征大小</th><th align="center" valign="middle" >最佳维数</th><th align="center" valign="middle" >平均最高识别率</th></tr></thead><tr><td align="center" valign="middle" >LBP</td><td align="center" valign="middle" >7375</td><td align="center" valign="middle" >550</td><td align="center" valign="middle" >89.45%</td></tr><tr><td align="center" valign="middle" >Gabor</td><td align="center" valign="middle" >20,000</td><td align="center" valign="middle" >500</td><td align="center" valign="middle" >91.64%</td></tr><tr><td align="center" valign="middle" >SIFT</td><td align="center" valign="middle" >22,528</td><td align="center" valign="middle" >350</td><td align="center" valign="middle" >91.85%</td></tr><tr><td align="center" valign="middle" >LPQ</td><td align="center" valign="middle" >32,000</td><td align="center" valign="middle" >800</td><td align="center" valign="middle" >92.51%</td></tr></tbody></table></table-wrap><p>表1. 分类结果对比</p></sec><sec id="s7"><title>5. 结论</title><p>本文将LPQ特征应用于对视网膜OCT图像分类，提出了基于OCT图像与LPQ特征的视网膜疾病检测算法，并在Duke视网膜数据集上进行了实验，并与现有文献中所用的特征，包括LBP特征、Gabor特征和SIFT特征进行了比较研究。实验结果表明，本文提出的算法具有较高的精度。本文提出的算法对视网膜疾病的计算机辅助诊断具有重要的意义。在今后的研究中，我们将考虑将多种特征进行融合，或者尝试将LPQ特征与更优的分类算法进行结合，以进一步提高视网膜OCT图像分类的准确性和鲁棒性。</p></sec><sec id="s8"><title>基金项目</title><p>本文受到河北省自然科学基金项目(A2019202135)资助。</p></sec><sec id="s9"><title>文章引用</title><p>任 岚,穆国旺. 基于LPQ特征的视网膜OCT图像分类算法Algorithm for Classification of the Retinal OCT Images with LPQ Features[J]. 计算机科学与应用, 2020, 10(01): 112-117. https://doi.org/10.12677/CSA.2020.101012</p></sec><sec id="s10"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.34009-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Rickman, C.B., Farsiu, S., Toth, C.A., et al. (2013) Dry Age-Related Macular Degeneration: Mechanisms, Therapeutic Targets, and Imaging. Investigative Ophthalmology &amp; Visual Science, 54, ORSF68-ORSF80.  
&lt;br&gt;https://doi.org/10.1167/iovs.13-12757</mixed-citation></ref><ref id="hanspub.34009-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Hee, M.R., Izatt, J.A., Swanson, E.A., et al. (1995) Optical Coherence Tomography of the Human Retina. Archives of Ophthalmology, 113, 325-332. &lt;br&gt;https://doi.org/10.1001/archopht.1995.01100030081025</mixed-citation></ref><ref id="hanspub.34009-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Liu, Y.Y., Chen, M., Ishikawa, H., et al. (2011) Au-tomated Macular Pathology Diagnosis in Retinal OCT Images Using Multi-Scale Spatial Pyramid and Local Binary Pat-terns in Texture and Shape Encoding. Medical Image Analysis, 15, 748-759. &lt;br&gt;https://doi.org/10.1016/j.media.2011.06.005</mixed-citation></ref><ref id="hanspub.34009-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Zheng, Y., Hijazi, M.H.A. and Coenen, F. (2012) Automated “Disease/No Disease” Grading of Age-Related Macular Degeneration by an Image Mining Approach. Investigative Ophthalmology &amp; Visual Science, 53, 8310-8318.  
&lt;br&gt;https://doi.org/10.1167/iovs.12-9576</mixed-citation></ref><ref id="hanspub.34009-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Zhang, Y., Zhang, B., Coenen, F., et al. (2014) One-Class Kernel Sub-space Ensemble for Medical Image Classification. EURASIP Journal on Advances in Signal Processing, 2014, Article No. 17.  
&lt;br&gt;https://doi.org/10.1186/1687-6180-2014-17</mixed-citation></ref><ref id="hanspub.34009-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Mookiah, M.R.K., Acharya, U.R., Koh, J.E.W., et al. (2014) Au-tomated Diagnosis of Age-Related Macular Degeneration Using Greyscale Features from Digital Fundus Images. Com-puters in Biology and Medicine, 53, 55-64.  
&lt;br&gt;https://doi.org/10.1016/j.compbiomed.2014.07.015</mixed-citation></ref><ref id="hanspub.34009-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Srinivasan, P.P., Kim, L.A., Mettu, P.S., et al. (2014) Fully Automated Detection of Diabetic Macular Edema and Dry Age-Related Macular Degeneration from Optical Co-herence Tomography Images. Biomedical Optics Express, 5, 3568-3577. &lt;br&gt;https://doi.org/10.1364/BOE.5.003568</mixed-citation></ref><ref id="hanspub.34009-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Sun, Y., Li, S. and Sun, Z. (2017) Fully Automated Macular Pathology Detection in Retina Optical Coherence Tomography Images Using Sparse Coding and Dictionary Learning. Journal of Biomedical Optics, 22, Article ID: 016012.  
&lt;br&gt;https://doi.org/10.1117/1.JBO.22.1.016012</mixed-citation></ref><ref id="hanspub.34009-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Kermany, D.S., Goldbaum, M., Cai, W., et al. (2018) Identifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning. Cell, 172, 1122-1131. &lt;br&gt;https://doi.org/10.1016/j.cell.2018.02.010</mixed-citation></ref><ref id="hanspub.34009-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">De Fauw, J., Ledsam, J.R., Romera-Paredes, B., et al. (2018) Clini-cally Applicable Deep Learning for Diagnosis and Referral in Retinal Disease. Nature Medicine, 24, 1342-1350. &lt;br&gt;https://doi.org/10.1038/s41591-018-0107-6</mixed-citation></ref><ref id="hanspub.34009-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Schlegl, T., Waldstein, S.M., Bogunovic, H., et al. (2018) Fully Automated Detection and Quantification of Macular Fluid in OCT Using Deep Learning. Ophthalmology, 125, 549-558. &lt;br&gt;https://doi.org/10.1016/j.ophtha.2017.10.031</mixed-citation></ref><ref id="hanspub.34009-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Lee, C.S., Baughman, D.M. and Lee, A.Y. (2017) Deep Learn-ing Is Effective for Classifying Normal versus Age-Related Macular Degeneration OCT Images. Ophthalmology Retina, 1, 322-327.  
&lt;br&gt;https://doi.org/10.1016/j.oret.2016.12.009</mixed-citation></ref><ref id="hanspub.34009-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Dabov, K., Foi, A., Katkovnik, V., et al. (2007) Image Denoising by Sparse 3-D Transform-Domain Collaborative Filtering. IEEE Transactions on Image Processing, 16, 2080-2095. &lt;br&gt;https://doi.org/10.1109/TIP.2007.901238</mixed-citation></ref><ref id="hanspub.34009-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">Otsu, N. (1979) A Threshold Selection Method from Gray-Level Histograms. IEEE Transactions on Systems, Man, and Cybernetics, 9, 62-66. &lt;br&gt;https://doi.org/10.1109/TSMC.1979.4310076</mixed-citation></ref><ref id="hanspub.34009-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">Ojansivu, V., Rahtu, E. and Heikkila, J. (2008) Rotation Invar-iant Local Phase Quantization for Blur Insensitive Texture Analysis. IEEE 19th International Conference on Pattern Recognition, Tampa, 8-11 December 2008, 1-4.  
&lt;br&gt;https://doi.org/10.1109/ICPR.2008.4761377</mixed-citation></ref><ref id="hanspub.34009-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">Lei, Z., Ahonen, T., Pietikäinen, M., et al. (2011) Local Fre-quency Descriptor for Low-Resolution Face Recognition. IEEE Face and Gesture, Santa Barbara, 21-25 March 2011, 161-166. &lt;br&gt;https://doi.org/10.1109/FG.2011.5771391</mixed-citation></ref></ref-list></back></article>