<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">JISP</journal-id><journal-title-group><journal-title>Journal of Image and Signal Processing</journal-title></journal-title-group><issn pub-type="epub">2325-6753</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/JISP.2019.84026</article-id><article-id pub-id-type="publisher-id">JISP-32497</article-id><article-categories><subj-group subj-group-type="heading"><subject>JISP20190400000_86829757.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于深度学习的果蔬识别系统
  Fruit and Vegetable Identification System Based on Deep Learning
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>薛</surname><given-names>桐</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>陈</surname><given-names>辉</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>徐</surname><given-names>娜</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>浙江理工大学信息学院，浙江 杭州</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>12</day><month>10</month><year>2019</year></pub-date><volume>08</volume><issue>04</issue><fpage>203</fpage><lpage>214</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
  
    在农产品分拣过程中，果蔬的分类大多还停留在传统的分类模式，由人工进行果蔬筛选，这不但增加了成本，还可能给劳动者带来不便的体验。得益于计算机视觉相关技术的不断发展，以机器代替人工劳动的运营模式逐渐成为可能。本文探讨了以Tensorflow深度学习框架为核心，利用OpenCV进行图像处理的果蔬识别系统。基于收集的果蔬图像数据，通过多次调参及训练获得了准确率较高的模型。在系统构建上对图像数据集的使用、模型参数调整、训练结果以及应用性能进行了可视化设计与分析，通过Web App实现并展示了图像识别、目标检测、语义分割、实时检测四大功能模块。
    In the processing of sorting agricultural products, the classification of fruits and vegetables mostly stays in the traditional classification mode. This mode increases the labor cost on the one hand and the inconvenience to the workers on the other hand. Thanks to the continuous development of computer vision technologies, replacing labor with machines has gradually become possible. The paper studies the model structure and principle used in the development of fruit and vegetable recognition systems. Tensorflow is applied as core deep learning framework and OpenCV is used as in image processing. Based on the collected images of fruits and vegetables, a model with high accuracy was obtained through multiple adjustments and training. Image datasets, model parameter adjustment, training results and application performance are visualized and analyzed in the system. Four functional modules of image recognition, object detection, semantic segmentation and real-time detection are realized in the Web APP. 
   
   
  
 
</p></abstract><kwd-group><kwd>图像识别，目标检测，语义分割，实时检测, Image Recognition</kwd><kwd> Object Detection</kwd><kwd> Semantic Segmentation</kwd><kwd> Real-Time Detection</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>基于深度学习的果蔬识别系统<sup> </sup></title><p>薛桐，陈辉，徐娜</p><p>浙江理工大学信息学院，浙江 杭州</p><p><img src="//html.hanspub.org/file/1-2670203x1_hanspub.png" /></p><p>收稿日期：2019年9月20日；录用日期：2019年10月5日；发布日期：2019年10月12日</p><disp-formula id="hanspub.32497-formula7"><graphic xlink:href="//html.hanspub.org/file/1-2670203x5_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>在农产品分拣过程中，果蔬的分类大多还停留在传统的分类模式，由人工进行果蔬筛选，这不但增加了成本，还可能给劳动者带来不便的体验。得益于计算机视觉相关技术的不断发展，以机器代替人工劳动的运营模式逐渐成为可能。本文探讨了以Tensorflow深度学习框架为核心，利用OpenCV进行图像处理的果蔬识别系统。基于收集的果蔬图像数据，通过多次调参及训练获得了准确率较高的模型。在系统构建上对图像数据集的使用、模型参数调整、训练结果以及应用性能进行了可视化设计与分析，通过Web App实现并展示了图像识别、目标检测、语义分割、实时检测四大功能模块。</p><p>关键词 :图像识别，目标检测，语义分割，实时检测</p><disp-formula id="hanspub.32497-formula8"><graphic xlink:href="//html.hanspub.org/file/1-2670203x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2019 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/1-2670203x7_hanspub.png" /> <img src="//html.hanspub.org/file/1-2670203x8_hanspub.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>随着社会信息化程度的提升和AI技术的广泛普及，人们对美好生活的向往迫切要求社会向智能化、便捷化发展 [<xref ref-type="bibr" rid="hanspub.32497-ref1">1</xref>] 。计算机视觉技术在人民生活的各方各面起着越来越重要的作用，果蔬识别技术作为其中的一环，与商品零售、智能农业、智慧医疗等方向密切联系，既可有效减少劳动力开销，又能使人民在享受便捷精致生活服务的同时得到膳食引导 [<xref ref-type="bibr" rid="hanspub.32497-ref2">2</xref>] ，其广泛需求推动着相关领域的发展。</p><p>果蔬识别技术凭借其高效便捷的特性广泛应用于智能农业和产品分拣中。卡内基梅隆大学机器人学院科学家已提出建立农业机器人队伍来实现对农作物生产的辅助管理，通过AI技术判断农作物的成熟度等特性 [<xref ref-type="bibr" rid="hanspub.32497-ref3">3</xref>] ；比利时已通过视觉识别技术识别成熟果蔬并采摘，对未成熟果蔬的成熟时间给以预测 [<xref ref-type="bibr" rid="hanspub.32497-ref4">4</xref>] ；中国部分地区在茶叶采摘过程中利用视觉技术识别茶树嫩芽并实现定位及采摘以保证叶片完整性。</p><p>本文以果蔬识别为中心，探索智能分类功能的实现与应用，并结合基于深度学习的计算机视觉技术与传统互联网技术进行项目应用与展示，完成一个较为完善的果蔬识别系统。</p></sec><sec id="s4"><title>2. 数据集</title><p>论文研究中通过数据增强技术取得2500张源自自行拍摄的果蔬图像作为主要训练集，16854张源自Kaggle平台Fruits360 dataset中的果蔬图像作为辅助训练集。</p><p>考虑到图像像素大小对识别的准确率会产生一定的影响，需要选择较为合适的像素大小对图像进行输入来达到提高准确率的目的 [<xref ref-type="bibr" rid="hanspub.32497-ref5">5</xref>] 。由于所用计算机性能一般，为提升训练速度并使后期调用模型能够有较快的速度，选用像素大小分别为299 &#215; 299、300 &#215; 300、400 &#215; 400、500 &#215; 500、600 &#215; 600、700 &#215; 700的图像数据集测试图像像素大小对识别准确率的影响，验证结果如图1所示，对比分析选择大小为400 &#215; 400像素的图像数据集作为开发数据集。</p></sec><sec id="s5"><title>3. 图像识别</title><p>如图2所示 [<xref ref-type="bibr" rid="hanspub.32497-ref6">6</xref>] ，图像识别我们采用了常规卷积模型和Inception v3模型。在常规卷积模型构建上选用辅助训练集进行训练，包含三类不同品种苹果、黄桃、樱桃、荔枝、山竹、橘子、梨、火龙果共10类果蔬图像共16854张图像，其中80%作为训练集，20%作为测试集。由于数据量较多，训练所需时间较长，考虑到计算机性能、时间因素等多方面原因，论文采用的网络较为简单，使用综合性能较好的AdamOptimizer作为优化器，分别采用神经元为32 &#215; 64、64 &#215; 16的卷积层，使用3 &#215; 3卷积核，步长为2的max_pool，128个神经元的全连接层和softmax回归层进行实现。</p><p>图1. 不同像素大小图像对验证准确率影响图</p><p>图2. 常规卷积模型功能实现流程图</p><p>根据如图3训练结果所示，64-16结构能比32-64结构取得更好的效果，在测试时二者训练集准确率分别为0.9654和0.9318，测试集准确率分别为0.9231和0.8990，选择64-16结构进行后续优化，分别使用值为0.9、0.85、0.8的dropout来降低过拟合。如表1所示当dropout值为0.9时效果较好，既提升了测试集准确率，又缩小了测试集与训练集准确率的差距，降低了过拟合。</p><p>在Inception v3模型构建上选用主要数据集进行训练，包含香蕉、橘子、黄桃、柠檬、梨子五种较为相近的水果共2500张图像，将80%的数据集作为训练集，10%的数据集作为验证集，10%的数据作为测试集。</p><p>模型构建所使用的优化器分别选用较为常见的Gradient Descent Optimizer和Adam Optimizer。其中Gradient Descent Optimizer分别采用值为0.005、0.01的学习率训练，Adam Optimizer分别采用值为0.0001、0.0003、0.0005的学习率进行训练，训练集训练情况如图3所示。当训练3000步时Adam-0.0005结构和Adam-0.0003结构准确率较为突出且较快达到收敛，而两个GradientDescent结构均训练效果较差。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Convolution model effect compariso</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >结构</th><th align="center" valign="middle" >32-64</th><th align="center" valign="middle" >64-16</th><th align="center" valign="middle" >64-16-d0.9</th><th align="center" valign="middle" >64-16-d0.85</th><th align="center" valign="middle" >64-16-d0.8</th></tr></thead><tr><td align="center" valign="middle" >训练集准确率</td><td align="center" valign="middle" >0.9318</td><td align="center" valign="middle" >0.9651</td><td align="center" valign="middle" >0.9601</td><td align="center" valign="middle" >0.9388</td><td align="center" valign="middle" >0.9414</td></tr><tr><td align="center" valign="middle" >测试集准确率</td><td align="center" valign="middle" >0.8990</td><td align="center" valign="middle" >0.9231</td><td align="center" valign="middle" >0.9349</td><td align="center" valign="middle" >0.9133</td><td align="center" valign="middle" >0.8720</td></tr></tbody></table></table-wrap><p>表1. 卷积模型效果对比</p><p>图3. 常规卷积模型训练准确率展示图</p><p>如图4所示，在训练3000步时验证集中各结构均基本收敛。Adam结构网络在该案例上明显优于Gradient Descent结构网络，均达到了较高的准确率，由于学习率的不同达到收敛时间有所差异。如图5所示。在测试集上测试最终结果时，Adam-0.0001结构、Adam-0.0003结构、Adam-0.0005结构均达到了98.8%准确率，GradientDescent-0.005结构和GradientDescent-0.01结构均达到98.4%准确率。最终选择Adam-0.0005结构生成的模型完成系统应用功能开发。</p></sec><sec id="s6"><title>4. 目标检测</title><p>分析测试中使用了Faster RCNN模型 [<xref ref-type="bibr" rid="hanspub.32497-ref7">7</xref>] 和SSD模型 [<xref ref-type="bibr" rid="hanspub.32497-ref8">8</xref>] ，通过对二者进行分析，选用综合时间、mAP性能较好的faster_rcnn_inception_v2_coco模型、ssd_mobilenet_v1_coco模型和ssd_inception_v2_coco模型作为预训练模型对主要数据集进行测试，在loss值趋势不再降低时停止训练。</p><p>如图6、图7所示，ssd_mobilenet_v1结构的loss相比ssd_inception_v2结构的loss值较低，训练效果相比较好，因此选用ssd_mobilenet_v1结构进行后续对比。</p><p>如图8所示，对ssd_mobilenet_v1结构与faster_rcnn_inception_v2结构进行目标检测结果对比，faster_rcnn_inception_v2结构的loss值明显低于ssd_mobilenet_v1结构的loss值。如图9所示，准确率测试结果中faster_rcnn_inception_v2结构也取得了明显的优势。这两个模型的检测准确率有一定差异，但基于Faster RCNN和SSD的基本特性，该SSD模型虽然准确率较低，但在模型调用速度上有一定优势，在实时性和mAP综合性能上可能超过该Faster RCNN模型。</p><p>图4. Inception v3训练准确率趋势图</p><p>图5. Inception v3验证准确率趋势图</p><p>图6. ssd_mobilenet_v1 loss趋势图</p><p>图7. ssd_inception_v2 loss趋势图</p><p>图8. 目标检测loss对比图</p><p>图9. 目标检测模型准确率对比图</p></sec><sec id="s7"><title>5. APP实现</title><p>1. APP应用模块主要用于对系统功能的可视化应用展示和性能分析。通过对图像识别模块、目标检测模块训练生成的模型进行对比分析，分别选择较优模型投入APP应用模块进行实际应用，更直观地展示果蔬识别情况，对模型的优化和模型调用算法的改善提供分析依据。APP应用模块在对两种识别模式进行常规实现的基础上，对实际问题进行思考，延伸拓展实现语义分割模块和视频实时检测功能模块。系统实现架构如图10示。</p><p>图10. 系统实现架构图</p><p>为了提高APP应用的灵活性，APP可使用相册图片和摄像头拍摄两种方式上传图片，并允许多张图片上传识别。APP对输入的图像数据进行后端存储，便于数据集扩充，为后期模型的调整与优化做准备。当系统完成识别时，对结果进行可视化输出展示，提供识别准确率、识别时间等参数供模型优化和模型调用算法优化进行参考。APP主页、图像识别模块、目标检测模块效果图如图11、图12、图13所示。</p><p>图11. APP主页效果图</p><p>图12. 图像识别效果图</p><p>图13. 目标检测效果图</p></sec><sec id="s8"><title>6. 实验结果分析</title><p>本文实验环境为Windows操作系统，GTX950M显卡，使用Python-3.5和Tensorflow-gpu-1.9.0进行神经网络模型构建，使用Django-1.11实现Web APP进行系统可视化应用展示。通过对不同模型及其相关因素进行分析，结论如下：</p><p>(1) 输入图像大小对性能的影响。输入图像的大小直接影响APP功能完成所需时间，图像越大，识别所需处理的数据就越多。APP在后台将输入的图像数据resize为400 &#215; 400大小，一方面防止图像过大时影响性能，另一方面使用与模型数据集相似的图像数据易于实现更好的识别准确率。</p><p>(2) 图像识别应用模块性能分析与优化。通过对模型调用算法的调整，测试发现进行图像识别时模型的调用花费了较多的时间，因此考虑能否对模型调用时间进行分离，使模型在APP上有更好的应用性能。重复测试10次模型调用时间分离前后识别1张、2张图像所需时间情况如图14示。</p><p>将每种测试结果的后五次数值取均值，结果如表2、表3所示，对比可见分离模型调用对缩短识别时间能起到较好的作用，单张识别速度可提升约119%，2张识别速度可提升约85%，随着单次识别的图像数目增加，识别所需总时间增加，模型调用分离对速度的提升将逐渐减小。</p><p>(3) 目标检测应用模块性能分析与优化。</p><p>faster_rcnn_inception_v2结构模型与ssd_mobilenet_v1结构模型目标检测耗时对比。SSD模型在综合性能上常优于Faster RCNN模型，在本系统对比中由于部分原因未能够使用相当模型进行对比，仅以faster_rcnn_inception_v2结构模型和ssd_mobilenet_v1结构模型进行对比供参考作用。</p><p>如图15所示，10次测试中使用ssd_mobilenet_v1结构模型进行目标检测耗时明显少于使用faster_rcnn_inception_v2结构模型，各使用测试的后五次结果取均值，faster_rcnn_inception_v2结构模型平均耗时15.31秒，ssd_mobilenet_v1结构模型平均耗时8.22秒，后者耗时仅为前者53.7%，且亦有较高的准确率，有较好的应用性能。</p><p>图14. 图像识别调用优化前后时间对比图</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> 1 comparison of recognition time before and after image adjustmen</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >方式</th><th align="center" valign="middle" >未分离-1张</th><th align="center" valign="middle" >分离-1张</th><th align="center" valign="middle" >速度提升率</th></tr></thead><tr><td align="center" valign="middle" >平均时间(秒)</td><td align="center" valign="middle" >3.48</td><td align="center" valign="middle" >1.59</td><td align="center" valign="middle" >119%</td></tr></tbody></table></table-wrap><p>表2. 1张图像调整前后识别时间对比</p><table-wrap id="table3" ><label><xref ref-type="table" rid="table3">Table 3</xref></label><caption><title> Comparison of recognition time before and after image adjustmen</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >方式</th><th align="center" valign="middle" >未分离-2张</th><th align="center" valign="middle" >分离-2张</th><th align="center" valign="middle" >速度提升率</th></tr></thead><tr><td align="center" valign="middle" >速度提升率</td><td align="center" valign="middle" >3.53</td><td align="center" valign="middle" >1.91</td><td align="center" valign="middle" >85%</td></tr></tbody></table></table-wrap><p>表3. 2张图像调整前后识别时间对比</p><p>模型调用算法优化。为使对比结果更为直观，该部分选用了目标检测耗时较长的Faster RCNN模型进行测试。将所有图像数据一起送入目标检测算法，从原先的每张图像数据进行一次模型调用转化为所有图像数据进行一次模型调用，极大缩短了目标检测功能实现时间，提升了功能实现效率。重复测试10次模型调用算法优化前后识别1张、2张图像所需时间情况如图16。</p><p>将每种测试结果的后五次数值取均值，结果如表4所示，对比可见分离模型调用对缩短识别时间能起到较好的作用，2张图像的识别速度可提升约83%，分离模型调用后每张图像的检测时间约0.93秒，随着单次识别图像数目增加，识别速度提升率将更高。</p><p>(4) 深入优化模型调用算法思考：</p><p>模型调用需要消耗大量时间，在输入图像较少时占用时间更加明显，如果可以使模型在系统环境中长存，使每次进行识别或检测操作时可直接调用，将有效提升应用效率。</p><p>模型最初几次调用时间明显较长，可尝试在应用程序运行前对模型进行多次预使用，从而达到模型预热的效果。</p><p>图15. 标检测不同模型时间对比图</p><p>图16. 目标检测调用优化前后时间对比图</p><table-wrap id="table4" ><label><xref ref-type="table" rid="table4">Table 4</xref></label><caption><title> Comparison of detection times before and after adjustmen</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >方式</th><th align="center" valign="middle" >1张</th><th align="center" valign="middle" >未分离-2张</th><th align="center" valign="middle" >分离-2张</th><th align="center" valign="middle" >2张速度提升率</th></tr></thead><tr><td align="center" valign="middle" >平均时间(秒)</td><td align="center" valign="middle" >15.31</td><td align="center" valign="middle" >29.66</td><td align="center" valign="middle" >16.24</td><td align="center" valign="middle" >83%</td></tr></tbody></table></table-wrap><p>表4. 调整前后检测时间对比</p></sec><sec id="s9"><title>7. 结论</title><p>本文基于深度学习的果蔬识别系统研究了模型的构建、分析与应用展示。模型分析模块使用了自行搭建的分析平台，结合Tensorboard对模型进行精准分析。在果蔬识别模块分别采用了常规图像识别、目标检测两个功能模块，实现单果蔬分类、多果蔬定位分类，且能达到较好的识别准确率，并将功能延伸到语义分割和视频实时检测上，满足大部分果蔬识别需求。系统采用Web APP对识别结果进行直观展示，便于后期分析、改善及应用。虽然在果蔬识别以及其他应用场景中，识别已经能达到较高的准确度，但在缩小训练数据集、提升识别速度上还有待继续提升，以便更好满足人们对美好生活的向往 [<xref ref-type="bibr" rid="hanspub.32497-ref9">9</xref>] 。</p></sec><sec id="s10"><title>致谢</title><p>本文的工作得到2018国家级创新创业训练项目(编号：201810338028)和教育部协同创新项目(编号：201801200045)的资助，特此感谢。</p></sec><sec id="s11"><title>文章引用</title><p>薛 桐,陈 辉,徐 娜. 基于深度学习的果蔬识别系统Fruit and Vegetable Identification System Based on Deep Learning[J]. 图像与信号处理, 2019, 08(04): 203-214. https://doi.org/10.12677/JISP.2019.84026</p></sec><sec id="s12"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.32497-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">王先庆, 雷韶辉. 新零售环境下人工智能对消费及购物体验的影响研究——基于商业零售变革和人货场体系重构视角[J]. 商业经济研究, 2018(17): 5-8.</mixed-citation></ref><ref id="hanspub.32497-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">王前程. 基于深度学习的水果图像识别算法研究[D]: [硕士学位论文]. 保定: 河北大学, 2016.</mixed-citation></ref><ref id="hanspub.32497-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">驱动中国. 计算机视觉+机器学习进入农业, 未来要用手机种田吗[EB/OL].  
https://mobile.qudong.com/article/435835.shtml, 2017-09-18.</mixed-citation></ref><ref id="hanspub.32497-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">芝麻仓库. 当农业遇上人工智能[EB/OL]. https://baijiahao.baidu.com/s?id=1596167014452729008, 2018-03-28.</mixed-citation></ref><ref id="hanspub.32497-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">博客园. 深度学习调参技巧[EB/OL]. https://www.cnblogs.com/ranjiewen/p/7682309.html.</mixed-citation></ref><ref id="hanspub.32497-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">DexterLei. TensorFlow学习笔记: 使用Inception v3进行图像分类[EB/OL]. 
https://www.jianshu.com/p/cc830a6ed54b, 2017-10-03.</mixed-citation></ref><ref id="hanspub.32497-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Ren, S., He, K., Girshick, R., et al. (2015) Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks. IEEE Trans Pattern Anal Mach Intell, 39, 1137-1149.</mixed-citation></ref><ref id="hanspub.32497-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Liu, W., Anguelov, D., Erhan, D., et al. (2016) SSD: Single Shot MultiBox Detector. European Conference on Computer Vision, Springer, Cham, 21-37.</mixed-citation></ref><ref id="hanspub.32497-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">前瞻经济学人. 2018年计算机视觉技术三大发展趋势分析[EB/OL]. 
https://www.qianzhan.com/analyst/detail/220/181012-a8dab736.html, 2018-10-15.</mixed-citation></ref></ref-list></back></article>