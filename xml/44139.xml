<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">AAM</journal-id><journal-title-group><journal-title>Advances in Applied Mathematics</journal-title></journal-title-group><issn pub-type="epub">2324-7991</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/AAM.2021.107266</article-id><article-id pub-id-type="publisher-id">AAM-44139</article-id><article-categories><subj-group subj-group-type="heading"><subject>AAM20210700000_72424404.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>数学与物理</subject></subj-group></article-categories><title-group><article-title>
 
 
  一种基于序列分解和神经网络的供电成本预测方法
  A Method for Power Supply Cost Prediction Based on Time-Series Decomposition and Neural Network
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>金</surname><given-names>绍君</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>孙</surname><given-names>泉辉</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>程</surname><given-names>嵩</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>姚</surname><given-names>日权</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff3"><addr-line>国网浙江省电力有限公司湖州供电公司，浙江 湖州</addr-line></aff><aff id="aff2"><addr-line>国网浙江省电力有限公司，浙江 杭州</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>01</day><month>07</month><year>2021</year></pub-date><volume>10</volume><issue>07</issue><fpage>2561</fpage><lpage>2571</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
  随着国内各企业生产环境的变化，精益财务管理，智慧财务运营越来越重要，寻找一种更有效的成本计算方法成为各企业突破困境的方向，这对于企业发展规划、战略部署有着非常重要的作用。本文提出一种新颖的Prophet与LSTNet的组合模型，应用于电网成本分摊，该模型首先使用序列分解模型将数据解构，生成平稳光滑的子序列，以提升后续神经网络模型的训练效果，其次在LSTNet神经网络中加入注意力机制，学习序列的长短周期模式，充分发挥神经网络模型的非线性优势。实验结果表明，本文模型能够良好地预测具有长短周期性的非平稳成本序列。
   With the changes in the production environment of domestic enterprises, lean financial management and smart financial operation are becoming more and more important. Finding a more effective cost calculation method has become the direction for enterprises to break through the dilemma, which plays a very important role in enterprise development planning and strategic deployment. In this paper, a novel combination model of prophet and LSTNet is proposed for power grid cost allocation. Firstly, the model uses the sequence decomposition model to deconstruct the data and generate smooth sub-sequences to improve the training effect of the subsequent neural network model. And then, the attention mechanism is added to the LSTNet neural network to learn the long and short period pattern of the sequence, giving full play to the nonlinear advantage of neural network model. The experimental results show that the proposed model can well predict the non-stationary cost series with long and short periodicity.
 
</p></abstract><kwd-group><kwd>序列分解，神经网络，组合模型，成本预测，电网, Sequence Decomposition</kwd><kwd> Neural Network</kwd><kwd> Combination Model</kwd><kwd> Cost Prediction</kwd><kwd> Power Grid</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>摘要</title><p>随着国内各企业生产环境的变化，精益财务管理，智慧财务运营越来越重要，寻找一种更有效的成本计算方法成为各企业突破困境的方向，这对于企业发展规划、战略部署有着非常重要的作用。本文提出一种新颖的Prophet与LSTNet的组合模型，应用于电网成本分摊，该模型首先使用序列分解模型将数据解构，生成平稳光滑的子序列，以提升后续神经网络模型的训练效果，其次在LSTNet神经网络中加入注意力机制，学习序列的长短周期模式，充分发挥神经网络模型的非线性优势。实验结果表明，本文模型能够良好地预测具有长短周期性的非平稳成本序列。</p></sec><sec id="s2"><title>关键词</title><p>序列分解，神经网络，组合模型，成本预测，电网</p></sec><sec id="s3"><title>A Method for Power Supply Cost Prediction Based on Time-Series Decomposition and Neural Network<sup> </sup></title><p>Shaojun Jin<sup>1</sup>, Quanhui Sun<sup>1*</sup>, Song Chen<sup>1</sup>, Riquan Yao<sup>2</sup></p><p><sup>1</sup>State Grid Zhejiang Electric Power Co., Ltd., Hangzhou Zhejiang</p><p><sup>2</sup>Huzhou Power Supply Company, State Grid Zhejiang Electric Power Co., Ltd., Huzhou Zhejiang</p><p><img src="//html.hanspub.org/file/32-2621720x5_hanspub.png?20210727093052377" /></p><p>Received: Jun. 21<sup>st</sup>, 2021; accepted: Jul. 11<sup>th</sup>, 2021; published: Jul. 26<sup>th</sup>, 2021</p><p><img src="//html.hanspub.org/file/32-2621720x6_hanspub.png?20210727093052377" /></p></sec><sec id="s4"><title>ABSTRACT</title><p>With the changes in the production environment of domestic enterprises, lean financial management and smart financial operation are becoming more and more important. Finding a more effective cost calculation method has become the direction for enterprises to break through the dilemma, which plays a very important role in enterprise development planning and strategic deployment. In this paper, a novel combination model of prophet and LSTNet is proposed for power grid cost allocation. Firstly, the model uses the sequence decomposition model to deconstruct the data and generate smooth sub-sequences to improve the training effect of the subsequent neural network model. And then, the attention mechanism is added to the LSTNet neural network to learn the long and short period pattern of the sequence, giving full play to the nonlinear advantage of neural network model. The experimental results show that the proposed model can well predict the non-stationary cost series with long and short periodicity.</p><p>Keywords:Sequence Decomposition, Neural Network, Combination Model, Cost Prediction, Power Grid</p><disp-formula id="hanspub.44139-formula19"><graphic xlink:href="//html.hanspub.org/file/32-2621720x7_hanspub.png?20210727093052377"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2021 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/32-2621720x8_hanspub.png?20210727093052377" /> <img src="//html.hanspub.org/file/32-2621720x9_hanspub.png?20210727093052377" /></p></sec><sec id="s5"><title>1. 引言</title><p>智能电网已成为全世界能源新战略，当下我国众多科研机构和企业积极开展相关的技术研究，自改革以来，电网企业积极适应市场变化，研究建设合适自身的成本管控体系，大大地促进电力行业的发展。2006年，国家电网提出了实行成本标准化、管理精益化，并将标准作业用以年度测算中；2009年国家电网又提出“人、财、物”集约化管理，稳健实施标准作业化管理，建立企业集约化管理方式。成本分摊能够为企业提供详细精确的成本数据信息，有利于优化成本管控，提高效益，有利于电网企业长久发展。随着计算机技术的快速发展，基于人工智能大数据分析技术愈发成熟，数据的价值越来越受到重视，籍此开启了一次重大的时代转型。通过当下机器学习方法，挖掘出电力数据背后隐藏的信息，对于电网和民生具有重要的研究意义。</p><p>电网供电所成本分摊预测是指根据以往的运维成本，包括人工成本、检修运维成本、营销运维成本、其他运营费用情况对未来的形式分析，实现对未来特定时间内的成本消耗的估计，它的准确预测对于国家电网对使用成本的总体把握、资金部署和投资建设等有着非常重要的意义。目前相关研究很少，主要原因是电网规模庞大、分布地域广阔、运行条件繁琐，造成电网供电所数据波动特别大，数据短期无连续性，使得其预测非常困难。本文基于人工智能相关理论知识，提出一种自适应的无监督神经网络方法，应用于供电所成本预测。</p><p>数据分析中常用方法有时间序列分析 [<xref ref-type="bibr" rid="hanspub.44139-ref1">1</xref>]、线性与非线性回归模型 [<xref ref-type="bibr" rid="hanspub.44139-ref2">2</xref>]、灰色系统模型 [<xref ref-type="bibr" rid="hanspub.44139-ref3">3</xref>]、最大熵马尔可夫模型 [<xref ref-type="bibr" rid="hanspub.44139-ref4">4</xref>] 等。其中时间序列因其时间特性，应用最多的是自回归移动平均模型(Auto-regressive Integrated Moving Average Model, ARIMA) [<xref ref-type="bibr" rid="hanspub.44139-ref5">5</xref>]。但是以下两方面原因使得传统统计模型不能很好的预测成本变化。一方面是当数据量很大时，构建有效的输入数据结构来刻画相应成本金额非常有必要，然而传统方法要么是选取其中少量数据维度，要么忽略已有数据之间的总体关联性质，这都导致了数据的信息缺失，使得进一步的建模受到先验限制；另一方面，基于能获取的所有数据维度，传统方法无法有效提取出其中有利于预测的高维的、相互作用的有效特征。这使得利用ARIMA模型预测变化较大的陈本值会出现较大偏差。这些原因导致统计预测的不精确，也就限制了传统方法的实际应用。为了很好的利用历史数据(大数据)预测成本，构建有效的输入数据结构来刻画相应成本金额是非常有必要的，因此对大数据处理和挖掘的需求也应运而生，其中代表性的方法是神经网络方法。</p><p>Hochreiter在1997年提出的长短期记忆网络(Long Short-Term Memory, LSTM)模型 [<xref ref-type="bibr" rid="hanspub.44139-ref6">6</xref>] 解决循环神经网络中梯度消失与爆炸，据此优点，LSTM被用在时间序列预测 [<xref ref-type="bibr" rid="hanspub.44139-ref7">7</xref>]，手写识别 [<xref ref-type="bibr" rid="hanspub.44139-ref8">8</xref>]，语音识别 [<xref ref-type="bibr" rid="hanspub.44139-ref9">9</xref>] 等多个方面。然而实际上LSTM无法捕获非常长期的序列关系，因此相关研究人员设计LSTNet模型以解决此问题。LSTNet包括卷积组件、循环神经网络组件、跳跃循环神经网络组件以及自回归组件，可以捕捉数据的多尺度周期规律。但是LSTNet只能挖掘不同时段的序列特征，对序列噪音并不具有鲁棒性。因此本文提出了一种融合时间序列分解和LSTNet神经网络模型的成本预测方案，可以帮助电网很好的预估未来一定时间内的成本，以便用于成本管理和投资决策。</p></sec><sec id="s6"><title>2. 预备知识</title><sec id="s6_1"><title>2.1. 神经网络简介</title><p>人工神经网络(Artificial Neural Network, ANN)，又称神经网络，是当下最为有效的一类机器学习算法，受益于计算机硬件，特别是图形处理器(Graphics processing unit, GPU)的巨大发展，基于人工神经网络的方法目前广泛应用于各个领域，如人工智能、机器学习、模式识别等。该结构包含输入层、隐藏层、输出层，见图1。输入层负责接收外部的信息和数据；隐藏层负责对信息进行处理，不断调整神经元之间的连接属性，如权值、反馈等。输出层负责对计算的结果进行输出。其中，权值反映了单元间的连接强度，反馈反映了单元间的正负相关性，在单元间的连接关系中，通过这些信息反应出信息的处理过程。</p><p>图1. 人工神经网络模型</p></sec><sec id="s6_2"><title>2.2. Prophet模型</title><p>Prophet模型 [<xref ref-type="bibr" rid="hanspub.44139-ref10">10</xref>] 是由Facebook数据科学团队于2018年发布的一款针对时间序列预测的算法模型。它的算法原理是将数据分解成非线性趋势成分、周(日)季节性成分以及假日成分，从而对序列进行预测。与其他模型相比，Prophet模型对于缺失数据、异常数据、变动趋势具有较强的鲁棒性，在拥有多季节性以及节假日效应明显的序列上表现更好。该模型对于各种业务时间序列都具有足够的灵活性，并且可以由对数据生成过程和时间序列模型知之甚少的非专家进行配置。</p><p>该模型进行业务预测的“循环–分析”方法见图2，首先对时间序列建模，模型中的每个参数都具有直观的人工解释。然后，针对此模型生成预测，并在各种历史模拟预测日期中生成一组合理的基线，并评估预测效果。当效果不佳或预测的其他方面需要人工干预时，会按先后顺序将这些潜在问题标记给分析人员。然后，分析人员可以检查预测过程，并根据此反馈调整模型。</p><p>图2. Prophet预测流程图 [<xref ref-type="bibr" rid="hanspub.44139-ref11">11</xref>]</p><p>Prophet是由趋势、季节性、假日这三个主要模型组成的可分解时间序列模型。它们按式(1)组合：</p><p>y ( t ) = g ( t ) + s ( t ) + h ( t ) + ε t (1)</p><p>其中， g ( t ) 是趋势成分，用来拟合数据的非周期性变化， s ( t ) 是季节性成分， h ( t ) 是假日成分，表示当天是否是节假日， ε ( t ) 代表误差项。这种定义类似于具备潜在的非线性平滑回归模型，即广义加性模型。每个成分的计算将在下文展开。</p></sec><sec id="s6_3"><title>2.3. LSTNet模型</title><p>Long- and Short-term Time-series network (LSTNet) [<xref ref-type="bibr" rid="hanspub.44139-ref11">11</xref>] 使用了卷积层、循环神经网络、跳跃循环神经网络以及自回归机制，具体结构见图3。LSTNet利用卷积层的优势来发现局部多维输入变量和循环层之间的依赖关系模式，以捕获复杂的长期依赖关系。它通过一种新颖的递归结构(即递归跳跃)来捕获非常长期的依赖模式，并利用输入时间序列信号的周期性来简化优化过程。最后，LSTNet结合了与非线性神经网络部分并行的传统自回归线性模型，这使得非线性深度学习模型对于违反尺度变化的时间序列更具鲁棒性。</p></sec><sec id="s6_4"><title>2.4. 注意力机制</title><p>注意力模型(Attention Model) [<xref ref-type="bibr" rid="hanspub.44139-ref12">12</xref>] 的本质思想和命名方式与人脑的选择性注意力模式相似，它的主要目的就是从众多信息源中快速挑选出感兴趣的重要信息。人类的视觉注意力机制会在浏览过图片后自动聚焦在特别关心的区域，在关键部分注入更多的精力资源以取得更详细信息，同时忽视其他无用信息。通过这种方式节约时间资源，提高工作效率与准确性。神经网络中的Attention机制与人类相似，能够帮助模型快速获得与目标任务有关的核心信息，自适应地提取每个时刻的相关特征以提高模型性能。基于特征输入的注意力机制结构见图4。</p><p>图3. LSTNet网络结构</p><p>图4. Attention结构示意图</p><p>对于每个时刻的输入 x ( t ) ，可以根据上一时刻编码器的隐层状态 h t − 1 和细胞状态 s t − 1 计算得到。然后利用式(2)得到 e t k 后，用Softmax函数归一化，即 α t k = exp ( e t k ) ∑ i − 1 n exp ( e t i ) ， α t k 衡量了时刻 t 的第 k 个特征的重要性，更新后的 x ˜ t 作为下一层网络的输入，计算公式见式(3)。</p><p>e t k = v e T tanh ( W e [ h t − 1 ; s t − 1 ] + U e x k ) (2)</p><p>x ˜ t = ( α t 1 x t 1 , α t 2 x t 2 , ⋯ , α t n x t n ) T (3)</p><p>通过输入注意力机制，神经网络模型可以有选择地专注于某些序列特征，而不必平等地对待所有输入序列特征。</p></sec></sec><sec id="s7"><title>3. 模型和算法实现</title><sec id="s7_1"><title>3.1. 数据采集</title><p>采用某省供电所高压用户的日现金流和日用电量流水数据作为实验数据，时间跨度为2013年1月1日至2019年6月30日。其中历史缴费流水数据包括用户行业、识别码、缴费到账日期区间、实际缴费日期、缴费方式、缴费金额等；历史用电量数据包括每位用户每月实际用电量。多种综合信息可以有效的帮助用户分类，增加了每日消费数据的特征。对采集得到的部分时间序列进行可视化分析见图5，从图中可以看出数据具有复杂的长短周期模式，分别以周和月为周期，并且数据的波动很大，平稳性较差。</p><p>图5. 2015年~2018年日现金流热图</p></sec><sec id="s7_2"><title>3.2. 数据预处理</title><p>首先进行数据清洗，再进行用户的数据挖掘及分类，最后得到所需的特征数据。除了2014年2月2日以外，采集的数据皆为按日连续的。由于预计到账时间为2014年2月2日的用户只有一个，所以一个合理的解决方案是使用金额0来填充该日现金流。同时对于某些具体日期，存在用户支付金额为负数的情况，这是由于这些用户终止缴费，为了完成销户，原有的预存金额被退回。为了避免数据噪声影响训练生成模型的准确性，对这部分干扰数据进行剔除。</p><p>对于用户数据挖掘及分类，主要过程为：</p><p>1. 对用户分类</p><p>1) 综合每次缴费信息，按照缴费金额将用户分为八类；</p><p>2) 综合每月用电量信息，按照用电量将用户分为八类；</p><p>3) 按照用户实际缴费时间与通知缴费周期的匹配程度进行分类，得到稳定缴费用户和非稳定缴费用户；</p><p>4) 按照用户实际缴费时间间隔进行分类，得到高频缴费用户和低频缴费用户。</p><p>2. 统计每日缴费用户中各类别所占比例，综合往期信息，得到用户群体的分布以及特征，包括缴费金额信息、时间周期特征、用户分布特征等；</p><p>3. 将所有数据按时间分类，以天为单位，其中每一天的特征包含单日总售电金额、当日对应周几以及相应月份、当日缴费的各种用户类别占比分布；</p><p>通过使用如下的数据结构，尽可能多地保留数据中的有效信息，从而使预测更加准确。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Data structur</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >1</th><th align="center" valign="middle" >2</th><th align="center" valign="middle" >3</th><th align="center" valign="middle" ></th><th align="center" valign="middle" >4</th><th align="center" valign="middle" >5~13</th><th align="center" valign="middle" >14~22</th><th align="center" valign="middle" >23~30</th></tr></thead><tr><td align="center" valign="middle" >日总金额</td><td align="center" valign="middle" ></td><td align="center" valign="middle"  colspan="3"  >评估分布</td><td align="center" valign="middle" >行业分布</td><td align="center" valign="middle" >用电量分布</td><td align="center" valign="middle" >支付金额分布</td></tr><tr><td align="center" valign="middle" >31</td><td align="center" valign="middle" ></td><td align="center" valign="middle"  colspan="3"  >32</td><td align="center" valign="middle" >33</td><td align="center" valign="middle" >34</td><td align="center" valign="middle" >35</td></tr><tr><td align="center" valign="middle" >周几</td><td align="center" valign="middle" ></td><td align="center" valign="middle"  colspan="3"  >公历月</td><td align="center" valign="middle" >公历日</td><td align="center" valign="middle" >农历月</td><td align="center" valign="middle" >农历日</td></tr></tbody></table></table-wrap><p>表1. 数据结构</p><p>数据结构见表1，共35维，为依次拼接的1维日现金流金额估计和29维的用户特征估计以及5维的日期时间特征。其中用户特征包括四类分类变量特征：</p><p>评估分布——支付时间位于最小至最大到账日期闭区间之内，记为0；小于最小到账日期， 记为 1；大于最大到账日期，记为2，从而对电力系统的入账能力情况进行评估。</p><p>行业分布——杭州市高压电用户一共有九大行业，按照预先设定的排序，某一用户的这一特征，定义为行业在此排序中的序号，值为0~8。</p><p>用电量分布——为了考察预计到账日当天对应的用户组的用电量分布，取预计到账日的上一个月作为“年月”日期标签，找到对应用户的用电量，根据用电量的多少划分为九个区间，从而定义该用户的这一特征的值为0~8。</p><p>支付金额——将用户支付金额划分为九个区间，</p><p>从而定义该用户的这一特征的值为0~8。</p><p>该用户特征估计方案结合了月用电量和日现金流的多模态信息，最大程度保证了样本信息的有效性和正则性。由于季节、工作日和休息日以及传统假日会对用电量产生很大的影响，时间特征必须被纳入到数据结构中。此外，时间特征的每一维需进行归一化处理。</p></sec><sec id="s7_3"><title>3.3. 序列成分分解</title><p>本文使用序列成分分解(Seasonal and Trend decomposition using Loess, STL)将原始序列分成趋势、季节、残差三项。STL可以处理任何类型的季节性，不仅仅是月度数据和季度数据，季节项可以随时间变化而变换，并且变化的速率可以由用户掌控。</p><p>对于趋势预测，其核心组成部分是一个逻辑增长模型，用于说明序列如何变化以及预计如何继续变化。这种建模方式与社会人口增长相似，增长到一定程度后社会承受能力抵达饱和状态，它的基本形式如式(4)。</p><p>g ( t ) = C ( t ) 1 + exp ( − k ( t − m ) ) (4)</p><p>其中 C 代表负荷容量， k 代表增长率， m 表示曲线的中点。</p><p>对于季节项，通过傅立叶级数来模拟灵活的周期效应模型，假设序列拥有周期P (如果数据以天为单位，则年度数据P = 365.25，周度数据P = 7)，使用式(5)中的傅立叶级数逼近任意平滑的季节性效应。</p><p>s ( t ) = ∑ n = 1 N ( a n cos ( 2 π n t P ) + b n sin ( 2 π n t P ) ) (5)</p><p>分解后序列见图6，与原始序列相比，分解后的子序列更加平稳。</p><p>图6. 序列成分分解示意图</p></sec><sec id="s7_4"><title>3.4. 模型构建</title><p>使用LSTNet模型对分解后的时间序列各个分量进行建模，目的是学习序列复杂的长短周期模式。LSTNet的输入包括分解后的历史日现金流序列以及构建的数据特征。模型框架见图7。</p><p>图7. LSTNet模型框架</p><p>该模型的具体运行流程为：</p><p>1) 输入数据；</p><p>2) 用网格法对模型的超参数进行遍历，模型的超参数包括往期天数、网络层数、学习率、迭代算法及次数等；</p><p>3) 遍历结束，记录最优超参数，建立最优模型；</p><p>4) 输出预测值。</p></sec></sec><sec id="s8"><title>4. 模型应用及评价</title><p>下面将结合实际数据对本文提出的预测模型进行验证。将2013年1月1日至2019年4月31日浙江省高压用户的日现金流和日用电量流水数据作为训练数据集，将2019年5月1日至2019年6月30日的数据作为测试集。本文神经网络中的损失函数为平均绝对误差(Mean Absolute Error, MAE)，即</p><p>L l o s s = 1 n ∑ i = 1 n | x i − y i | (6)</p><p>其中 x i , y i ( i = 1 , ⋯ , n ) 分别表示第 i 天的预测值和真实值， n 为测试集天数。</p><p>实验环境GPU为GTX 1080，CPU为Intel酷睿i5，2.6 GHz，内存为8 GB，软件平台为Tensorflow。为了说明本文模型的有效性，本文模型与传统的STL、LSTM、LSTNet模型作为对照实验。</p><p>2019年4月至5月本文模型与对比模型的每日预测结果对比见图8，蓝色线表示每日真实，绿色线表示本文模型的每日预测值。从图8可以看到，真实值每月有4至5个峰值和峰谷，但并非精确的以一周为一个周期，要预测准确比较困难；对照模型在峰值和峰谷的预测会产生偏差，说明其对日预测误差较大；相比之下本文模型的预测结果更加接近真实值，其精度也更高，对趋势预测的也更加准确，尤其是对峰值的预测更加准确。</p><p>图8. 预测结果对比图</p><p>为了更加直观地评估预测值与真实值的误差，我们采用加权平均绝对误差百分比(Weighted Mean Absolute Percentage Error, WMAPE)和相关系数(Empirical Correlation Coefficient, CORR)来评价模型的预测性能。</p><p>W M A P E = 1 ∑ i = 1 n y i | x i − y i | (7)</p><p>C O R R = 1 n ∑ i = 1 n ( y i − mean ( y i ) ) ( x i − mean ( x i ) ) ( ( y i − mean ( y i ) ) ) 2 ( ( x i − mean ( x i ) ) ) 2 (8)</p><p>其中 x i , y i ( i = 1 , ⋯ , n ) 分别表示第 i 天的预测值和真实值。</p><p>各模型的预测结果指标对比见表2。本文模型的预测值和真实值MAE、WMAPE指标最小，同时相关指数CORR最大。且与其他模型相比有显著的提升，证明了本文模型在电网日现金流预测问题上的优越性。</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> Comparison of prediction results of this mode</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >模型</th><th align="center" valign="middle" >MAE</th><th align="center" valign="middle" >WMAPE</th><th align="center" valign="middle" >CORR</th></tr></thead><tr><td align="center" valign="middle" >STL</td><td align="center" valign="middle" >14386640034</td><td align="center" valign="middle" >0.40</td><td align="center" valign="middle" >0.75</td></tr><tr><td align="center" valign="middle" >LSTM</td><td align="center" valign="middle" >13715179100</td><td align="center" valign="middle" >0.37</td><td align="center" valign="middle" >0.78</td></tr><tr><td align="center" valign="middle" >LSTNet</td><td align="center" valign="middle" >12566004012</td><td align="center" valign="middle" >0.35</td><td align="center" valign="middle" >0.83</td></tr><tr><td align="center" valign="middle" >本文模型</td><td align="center" valign="middle" >9713756181</td><td align="center" valign="middle" >0.26</td><td align="center" valign="middle" >0.88</td></tr></tbody></table></table-wrap><p>表2. 本文模型预测结果对比</p></sec><sec id="s9"><title>5. 结语</title><p>电网系统中保存有海量的历史成本数据，亟待被挖掘处理，通过对过去发生的各类成本与成本动因参数分析研究，利用现行的大数据与人工智能方法，分析数据背后的价值，掌握公司的成本发生规律，确定每一项成本产生的动因和其影响因素，建立完善成本与成本动因之间的数学函数模型，并验证和评估其有效性，对未来企业分配成本预算和管控提供参考依据。</p><p>本文设计了一种融合时间序列分解和神经网络模型来预测电力部门日现金流，构建的模型简单实用，相比传统模型学习复杂序列能力更强，结果更加鲁棒，并可以自动学习、提取出有价值的特征组合，有利于找到隐藏的规律。最后通过实验验证了该方法的有效性和实用性。</p><p>我国现在正处于电力改革的关键时期，面对市场的风险和挑战，电力企业必须从自身挖掘潜力，不断提高核心竞争力。面对世界经济格局的不断变化，标准化、精益化管理是企业增强竞争力，构建科学企业制度，树立良好企业文化，向现代化、国际化企业迈进的必然选择。</p></sec><sec id="s10"><title>文章引用</title><p>金绍君,孙泉辉,程 嵩,姚日权. 一种基于序列分解和神经网络的供电成本预测方法A Method for Power Supply Cost Prediction Based on Time-Series Decomposition and Neural Network[J]. 应用数学进展, 2021, 10(07): 2561-2571. https://doi.org/10.12677/AAM.2021.107266</p></sec><sec id="s11"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.44139-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Oliveira, J.F.L.D. and Ludermir, T.B. (2016) A Hybrid Evolutionary Decomposition System for Time Series Forecasting. Neurocomputing, 180, 27-34. &lt;br&gt;https://doi.org/10.1016/j.neucom.2015.07.113</mixed-citation></ref><ref id="hanspub.44139-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Lin, F., Liang, D., Yeh, C.C., et al. (2014) Novel Feature Selection Methods to Financial Distress Prediction. Expert Systems with Applications, 41, 2472-2483. &lt;br&gt;https://doi.org/10.1016/j.eswa.2013.09.047</mixed-citation></ref><ref id="hanspub.44139-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Han, M., Zhang, R., Qiu, T., et al. (2019) Multivariate Chaotic Time Series Prediction Based on Improved Grey Relational Analysis. IEEE Transactions on Systems, Man, and Cybernetics: Systems, 49, 2144-2154.  
&lt;br&gt;https://doi.org/10.1109/TSMC.2017.2758579</mixed-citation></ref><ref id="hanspub.44139-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Zhao, X., Zhang, J., Chen, Y., et al. (2014) Promoter Recognition Based on the Maximum Entropy Hidden Markov Model. Computers in Biology &amp; Medicine, 51, 73-81. &lt;br&gt;https://doi.org/10.1016/j.compbiomed.2014.04.003</mixed-citation></ref><ref id="hanspub.44139-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Box, G.E.P. and Jenkins, G.M. (1970) Time Series Analysis: Forecasting and Control. Journal of Time Series Analysis, 3, 3228.</mixed-citation></ref><ref id="hanspub.44139-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Hochreiter, S. and Schmidhuber, J. (1997) Long Short-Term Memory. Neural Computation, 9, 1735-1780.  
&lt;br&gt;https://doi.org/10.1162/neco.1997.9.8.1735</mixed-citation></ref><ref id="hanspub.44139-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Palang, H., et al. (2016) Distributed Compressive Sensing: A Deep Learning Approach. IEEE Transactions on Signal Processing, 64, 4504-4518. &lt;br&gt;https://doi.org/10.1109/TSP.2016.2557301</mixed-citation></ref><ref id="hanspub.44139-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Alex, G., Marcus, L., Santiago, F., et al. (2009) A Novel Connectionist System for Unconstrained Handwriting Recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence, 31, 855-868.  
&lt;br&gt;https://doi.org/10.1109/TPAMI.2008.137</mixed-citation></ref><ref id="hanspub.44139-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Li, X. and Wu, X. (2015) Constructing Long Short-Term Memory Based Deep Recurrent Neural Networks for Large Vocabulary Speech Recognition. IEEE International Conference on Acoustics, South Brisbane, 19-24 April 2015, 4520- 4524. &lt;br&gt;https://doi.org/10.1109/ICASSP.2015.7178826</mixed-citation></ref><ref id="hanspub.44139-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Taylor, S.J. and Letham, B. (2018) Forecasting at Scale. American Statistician, 72, 37-45.  
&lt;br&gt;https://doi.org/10.1080/00031305.2017.1380080</mixed-citation></ref><ref id="hanspub.44139-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Lai, G., Chang, W.C., Yang, Y., et al. (2018) Modeling Long and Short Term Temporal Patterns with Deep Neural Networks. The 41st International ACM SIGIR Conference, 95-104. &lt;br&gt;https://doi.org/10.1145/3209978.3210006</mixed-citation></ref><ref id="hanspub.44139-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Nguyen, T.V., et al. (2018) Attentive Systems: A Survey. International Journal of Computer Vision, 126, 86-110.  
&lt;br&gt;https://doi.org/10.1007/s11263-017-1042-6</mixed-citation></ref></ref-list></back></article>