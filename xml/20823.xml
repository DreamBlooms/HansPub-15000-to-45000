<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">AP</journal-id><journal-title-group><journal-title>Advances in Psychology</journal-title></journal-title-group><issn pub-type="epub">2160-7273</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/AP.2017.75091</article-id><article-id pub-id-type="publisher-id">AP-20823</article-id><article-categories><subj-group subj-group-type="heading"><subject>AP20170500000_10484830.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>人文社科</subject><subject> 合作期刊</subject></subj-group></article-categories><title-group><article-title>
 
 
  学习时的情绪图片背景对词语再认记忆的影响：SOA和背景呈现时间的调节作用
  Recognition Memory of Words Can Be Impaired by Task-Irrelevant Emotional Encoding Contexts: The Moderating Effect of SOA and Context Duration
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>郭</surname><given-names>新宇</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>李</surname><given-names>云云</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>张</surname><given-names>钦</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib></contrib-group><aff id="aff1"><addr-line>首都师范大学心理系，北京市“学习与认知”重点实验室，北京 </addr-line></aff><aff id="aff2"><addr-line>null</addr-line></aff><author-notes><corresp id="cor1">* E-mail:<email>737378798@qq.com(郭新)</email>;</corresp></author-notes><pub-date pub-type="epub"><day>18</day><month>05</month><year>2017</year></pub-date><volume>07</volume><issue>05</issue><fpage>730</fpage><lpage>738</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   本研究采用学习—再认范式，考察编码阶段与任务无关的图片背景的情绪唤醒程度、呈现时长、以及背景与目标词语呈现的时间间隔等对词语再认记忆的影响，探讨情绪背景对词语记忆的损害作用发生的条件。在学习阶段，单词叠加呈现在背景图片中央，只要求被试记忆单词。测验阶段，词语单独呈现，要求被试做新旧判断。结果发现，相对于中性背景，情绪背景损害了词语的再认。且情绪背景对词语再认的损害效应受到背景呈现时间的影响。 The present study attempted to investigate the influences of emotional arousal, stimulus onset asynchrony (SOA) of context and target, context duration of task-irrelevant picture and context on recognition memory of words using study-test paradigm. During study, words were superimposed centrally onto emotional contexts, and subjects were asked to just remember the words. During test, both studied and new words were presented without the emotional contexts and subjects had to make “old/new” judgments for those words. We found that, compared with the neutral context, the emotional context impaired recognition of words. And the impairing effect of the emotional contexts was influenced by the context duration. 
  
 
</p></abstract><kwd-group><kwd>情绪背景，词语，再认，SOA，背景呈现时间, Emotional Context</kwd><kwd> Words</kwd><kwd> Recognition</kwd><kwd> SOA</kwd><kwd> Context Duration</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>学习时的情绪图片背景对词语再认记忆的影响：SOA和背景呈现时间的调节作用<sup> </sup></title><p>郭新宇，李云云，张钦<sup>*</sup><sup> </sup></p><p>首都师范大学心理系，北京市“学习与认知”重点实验室，北京</p><p>收稿日期：2017年5月9日；录用日期：2017年5月20日；发布日期：2017年5月31日<sup> </sup></p><disp-formula id="hanspub.20823-formula30"><graphic xlink:href="http://html.hanspub.org/file/17-1130944x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>摘 要</p><p>本研究采用学习—再认范式，考察编码阶段与任务无关的图片背景的情绪唤醒程度、呈现时长、以及背景与目标词语呈现的时间间隔等对词语再认记忆的影响，探讨情绪背景对词语记忆的损害作用发生的条件。在学习阶段，单词叠加呈现在背景图片中央，只要求被试记忆单词。测验阶段，词语单独呈现，要求被试做新旧判断。结果发现，相对于中性背景，情绪背景损害了词语的再认。且情绪背景对词语再认的损害效应受到背景呈现时间的影响。</p><p>关键词 :情绪背景，词语，再认，SOA，背景呈现时间</p><disp-formula id="hanspub.20823-formula31"><graphic xlink:href="http://html.hanspub.org/file/17-1130944x7_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2017 by authors and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="http://image.hanspub.org:8080\Html/htmlimages\1-2890033x\e70a10f1-7c93-45ea-9603-062237856e4b.png" /><img src="http://image.hanspub.org:8080\Html\htmlimages\1-2890033x\e898c85e-ffc4-45c9-b817-14224a4d6960.png" /></p></sec><sec id="s2"><title>1. 引言</title><p>在现实生活中，情绪事件既可能是我们要学习记忆的目标，也可能成为我们学习记忆的背景。当把情绪材料作为背景，考察其对中性目标项目的记忆的影响时，部分研究发现，情绪背景促进了目标项目的记忆(Erk et al., 2003; Smith et al., 2004)。在这些研究中，学习阶段通常首先呈现背景，然后将中性目标项目叠加在背景上，要求被试想象目标项目和背景之间的联结。测验阶段则检测被试对目标项目的记忆。研究显示，在积极情绪背景下编码的项目的记忆效果好于中性背景下编码的项目。Chiu等人(2013)指出，这些研究鼓励被试将项目和背景表征为一个统一体，在这种情况下，有可能被观察到情绪导致的记忆增强效应。</p><p>然而，Zhang等人(2015)在不要求被试将背景和目标项目联系起来的情况下，发现情绪背景损害了而不是提高了对目标项目的记忆。她们使用消极低唤醒、消极高唤醒、积极低唤醒、积极高唤醒和中性的图片作为学习阶段的情绪背景材料，在学习阶段，将中性目标词语叠加到情绪图片背景中央，情绪背景图片和词语同时呈现，要求被试忽略背景图片，只对词语进行记忆。学习结束之后，单独对词语进行再认测验。结果显示，相比于中性背景，被试对消极背景和积极高唤醒背景下编码的中性词有更低的再认正确率。这一研究结果意味着，在要求被试忽略背景的情况下，高唤醒图片背景，不管是积极的还是消极的，都会妨碍被试对目标项目的学习记忆。Zhang等人认为，高唤醒图片，即使只是作为任务无关的背景，仍然会捕获被试的注意(M&#252;ller et al., 2008; Bocanegra &amp; Zeelenberg, 2009)。因此，在学习阶段，相对于中性背景，被试需要更多的注意资源来抑制情绪背景的干扰，从而损害了对目标项目的记忆。</p><p>那么，在不要求被试将目标项目与情绪背景联系起来的情况下，高唤醒情绪背景对项目记忆的损害效应就一定会出现吗？或者说，情绪背景对项目记忆的损害效应会不会受到其它因素的调节呢？为了回答这一问题，本研究拟操纵两个时间变量即背景呈现时间以及背景出现与目标出现之间的间隔时间(SOA)，来探讨情绪背景损害项目记忆的时间条件。在以往的研究中，不同实验设置的背景呈现时间和SOA并不相同，这可能是导致研究结果不一致的原因之一。例如，在Smith等人(2004)和Jaeger等人(2009)的研究中，背景呈现时间为8000 ms, SOA设置为3000 ms，没有发现情绪背景对中性项目记忆的损害作用。Erk等人(2005)在实验中采用的背景呈现时间为12,000 ms，SOA为4100 ms~6400 ms，也没有发现积极和消极情绪背景对中性项目的记忆有不同影响。虽然这些研究都要求被试将背景与项目联系起来，这可能是影响实验结果的原因之一，但是，背景呈现时间因素也可能影响背景的效应。在不要求被试将背景和项目联系起来的情况下，Zhang等人(2015)的研究采用相对较短的SOA条件(SOA = 0 ms)和相对较短的背景呈现时间(1000 ms)，发现了情绪背景对中性项目记忆的损害作用。另外，在有关注意抑制的研究中人们发现，在短SOA (SOA = 0~300 ms)条件下，高、低认知控制被试均表现出了注意捕获效应；而在长SOA (SOA = 600 ms)条件下，则只有低认知控制个体仍表现出注意捕获效应(徐展等，2016)。根据这些研究，我们推测，背景呈现时间和SOA可能会调节情绪背景对目标项目学习记忆的影响。SOA越短，情绪背景对目标项目的损害效应可能越大。类似的，在被试能够看清背景图片的基础上，背景呈现时间越短，情绪背景对目标项目学习记忆的损害效应也可能越大。</p><p>另外，之前关于情绪背景对项目记忆影响的研究大都是从情绪的效价维度出发进行考察的(Maratos &amp; Rugg, 2001; Jaeger et al., 2009)，较少关注唤醒度的作用。虽然Zhang等人(2015)在研究中引入了情绪唤醒维度这一变量，但其研究中存在效价和唤醒度的混淆。有研究者认为，情绪的唤醒程度才是影响记忆的关键。许多研究已经证明，情绪唤醒与信息加工中的注意捕获和认知资源分配有关(Lang et al., 1993; Schupp et al., 2003, 2007; Kissler et al., 2007), Mather等人(2009)总结多项研究发现，与非唤醒的刺激相比，人们对唤醒的情绪刺激的细节记忆更为准确，并且这与效价无关。研究者认为对高唤醒信息的编码是自动发生的(康诚，王振宏，2013)，高唤醒信息在杏仁核、海马及感觉相关脑区(例如，中枕回、梭状回)的激活程度和关联程度更强(Steinmetz, Addis, &amp; Kensinger, 2010)。因此，个体可能自动注意到唤醒背景的特征，进而对目标项目的加工产生影响。因此，有必要进一步考察不同情绪唤醒度背景对项目记忆的影响。</p><p>综上所述，本研究将采用学习—再认范式，研究不同唤醒度情绪图片背景对双字词语记忆的影响，并且探讨SOA和背景呈现时间对这种影响的调节作用。我们预期，随着唤醒度的提高，情绪背景对双字词语学习记忆的损害会增大。并且，SOA和背景呈现时间会调节情绪背景对词语记忆的损害效应。即当SOA和背景呈现时间较短时，可能表现出更强烈的情绪背景对中性词的损害效应；当SOA和背景呈现时间较长时，这种损害效应可能减弱甚至消失。</p></sec><sec id="s3"><title>2. 研究方法</title><sec id="s3_1"><title>2.1. 被试</title><p>21名大学生被试(5男，16女)参加本实验，被试平均年龄为21.7岁(年龄范围为20到28岁)，所有被试均为右利手，视力或矫正视力正常，无严重身心疾病史。实验后给予一定报酬。</p></sec><sec id="s3_2"><title>2.2. 实验设计</title><p>采用3 (背景图片的唤醒度：中性，低唤醒，高唤醒) &#215; 3 (SOA即背景出现与目标出现之间的间隔时间：0 ms，600 ms, 1000 ms) &#215; 2 (背景图片呈现时间即background picture duration 简称BPD: 1000 ms, 1800 ms)的被试内设计，因变量是再认测验中的再认准确率和反应时。</p></sec><sec id="s3_3"><title>2.3. 实验材料</title><p>从国际情绪图片库(IAPS; Lang, Bradley, &amp; Cuthbert, 1999)中选取中性图片、低唤醒情绪图片和高唤醒情绪图片各156张作为背景图片。低唤醒情绪图片和高唤醒情绪图片中积极和消极图片均各占一半。三类图片的平均效价和唤醒度见表1。统计结果显示，三类图片在效价上差异不显著[F(2,310) = 2.47, p &gt; 0.05]，但在唤醒度上差异显著, [F(2, 310) = 1818.45, p &lt; 0.001]。进一步分析发现，在唤醒度上三类图片两</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Mean (SD) valence and arousal for three types of background picture</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >背景图片类型</th><th align="center" valign="middle" >效价</th><th align="center" valign="middle" >唤醒</th></tr></thead><tr><td align="center" valign="middle" >中性</td><td align="center" valign="middle" >5.14 &#177; 0.58</td><td align="center" valign="middle" >3.16 &#177; 0.53</td></tr><tr><td align="center" valign="middle" >低唤醒</td><td align="center" valign="middle" >5.08 &#177; 1.78</td><td align="center" valign="middle" >4.75 &#177; 0.39</td></tr><tr><td align="center" valign="middle" >高唤醒</td><td align="center" valign="middle" >4.74 &#177; 2.18</td><td align="center" valign="middle" >6.38 &#177; 0.45</td></tr></tbody></table></table-wrap><p>表1. 三类背景图片的平均效价和唤醒度(M &#177; SD)</p><p>两之间均有显著差异(ps &lt; 0.001)。</p><p>从汉语情感词评价系统(CAWS, Luo &amp; Wang, 2004)里选出936个双字词语(效价范围：3.38~6.62)，其中468个词既出现在编码阶段也出现在再认阶段(称为旧词)，另外468个词只用于再认阶段(称为新词)。新词和旧词在效价、唤醒度和熟悉度上均没有显著差异(ps &gt; 0.05)。将旧词随机分配到学习阶段的18种(3 &#215; 3 &#215; 2)实验处理条件下，这18组旧词之间在效价[F (17, 450) = 0.09，p &gt; 0.05]、唤醒度[F (17, 450) = 0.70, p &gt; 0.05]和熟悉度[F (17, 450) = 0.14，p &gt; 0.05]上均没有显著差异。将新词随机分成6组，分别用于6个block的再认测试中。6组新词之间在效价[F (5, 462) = 0.09，p &gt; 0.05]、唤醒度[F (5, 462) = 0.28，p &gt; 0.05]和熟悉度[F (5, 462) = 0.93，p &gt; 0.05]上均没有显著差异。另外选择了42个城市名称和42张背景图片作为填充刺激，只出现在学习阶段，被试对填充刺激的反应不进入统计分析。</p></sec><sec id="s3_4"><title>2.4. 实验程序</title><p>被试坐在隔音、亮度适中的实验室中，眼睛距离屏幕约60厘米，通过鼠标的左右键进行按键反应。本实验采用学习–再认范式，每个block都包含一个学习阶段、分心阶段和测验阶段。每个被试完成6个block，block的顺序在被试间平衡。</p><p>在学习阶段，每个试次以呈现在屏幕中央的“+”字注视点开始，注视点呈现300 ms。之后的流程在不同的block中略有不同。在Block 1 [SOA = 0 ms, BPD = 1000 ms]中，图片和词语一起呈现300 ms，词语呈现在图片中心，然后词语从图片上消失，图片继续呈现700 ms。在Block 2 (SOA = 0 ms，BPD = 1800 ms)中，图片和词语一起呈现300 ms，然后词语从图片上消失，图片继续呈现1500 ms。在Block 3 (SOA = 600 ms, BPD = 1000 ms)中，图片先呈现600 ms，然后图片和词语一起呈现300 ms，然后词语从图片上消失，图片继续呈现100 ms。在Block 4 (SOA = 600 ms，BPD = 1800 ms)中，图片先呈现600 ms，然后图片和词语一起呈现300 ms，然后词语从图片上消失，图片继续呈现900 ms。在Block 5 (SOA = 1000 ms，BPD = 1000 ms)中，图片先呈现1000 ms，然后图片消失后，词语再呈现300 ms。在Block 6 (SOA = 1000 ms，BPD = 1800 ms)中，图片先呈现1000 ms，然后图片和词语一起呈现300 ms，然后词语从图片上消失，图片继续呈现500 ms。在所有的block中都要求被试，如果看到城市名称就做出按键反应。试次之间的时间间隔为1400~1700 ms。具体实验流程见图1。</p><p>学习阶段之后是分心任务阶段，被试进行60 s的倒减3运算，并进行口头报告。然后进入测验阶段，新、旧词混合呈现，每个词呈现1000 ms，刺激间距(ISI)是1400 ms~1700 ms。要求被试看到新词用右手拇指按右键，看到旧词用左手拇指按左键，左右手按键在不同被试之间平衡。</p></sec></sec><sec id="s4"><title>3. 研究结果</title><p>计算每个被试对词语的再认正确率和平均反应时，在平均反应时的计算中排除了错误反应的试次。被试对新词和不同条件下学过的旧词的再认正确率和平均反应时如表2所示。下面分别对其进行统计分析。在对反应时数据的初步整理中，删除了三个标准差之外的极端值(删除数据占总数据的0.26%)。</p><p>图1. 实验流程图(以Block 1为例)</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> Mean accuracies and RTs (ms) of new words and old words encoded indifferent context</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >Block</th><th align="center" valign="middle" >背景类型</th><th align="center" valign="middle" >反应时</th><th align="center" valign="middle" >正确率</th></tr></thead><tr><td align="center" valign="middle"  rowspan="4"  >Block 1 (SOA = 0 ms, BPD = 1000 ms)</td><td align="center" valign="middle" >中性</td><td align="center" valign="middle" >683.61 &#177; 49.85</td><td align="center" valign="middle" >0.54 &#177; 0.22</td></tr><tr><td align="center" valign="middle" >低唤醒</td><td align="center" valign="middle" >700.37 &#177; 55.25</td><td align="center" valign="middle" >0.49 &#177; 0.18</td></tr><tr><td align="center" valign="middle" >高唤醒</td><td align="center" valign="middle" >703.91 &#177; 47.16</td><td align="center" valign="middle" >0.53 &#177; 0.19</td></tr><tr><td align="center" valign="middle" >新词</td><td align="center" valign="middle" >723.02 &#177; 47.91</td><td align="center" valign="middle" >0.66 &#177; 0.17</td></tr><tr><td align="center" valign="middle"  rowspan="4"  >Block 2 (SOA = 0 ms, BPD = 1800 ms)</td><td align="center" valign="middle" >中性</td><td align="center" valign="middle" >689.29 &#177; 62.16</td><td align="center" valign="middle" >0.55 &#177; 0.21</td></tr><tr><td align="center" valign="middle" >低唤醒</td><td align="center" valign="middle" >706.04 &#177; 68.12</td><td align="center" valign="middle" >0.58 &#177; 0.21</td></tr><tr><td align="center" valign="middle" >高唤醒</td><td align="center" valign="middle" >712.13 &#177; 58.60</td><td align="center" valign="middle" >0.54 &#177; 0.18</td></tr><tr><td align="center" valign="middle" >新词</td><td align="center" valign="middle" >713.75 &#177; 62.84</td><td align="center" valign="middle" >0.68 &#177; 0.18</td></tr><tr><td align="center" valign="middle"  rowspan="4"  >Block 3 (SOA = 600 ms, BPD = 1000 ms)</td><td align="center" valign="middle" >中性</td><td align="center" valign="middle" >682.55 &#177; 69.80</td><td align="center" valign="middle" >0.62 &#177; 0.17</td></tr><tr><td align="center" valign="middle" >低唤醒</td><td align="center" valign="middle" >703.98 &#177; 71.90</td><td align="center" valign="middle" >0.58 &#177; 0.21</td></tr><tr><td align="center" valign="middle" >高唤醒</td><td align="center" valign="middle" >705.62 &#177; 73.54</td><td align="center" valign="middle" >0.55 &#177; 0.21</td></tr><tr><td align="center" valign="middle" >新词</td><td align="center" valign="middle" >705.18 &#177; 53.59</td><td align="center" valign="middle" >0.71 &#177; 0.18</td></tr><tr><td align="center" valign="middle"  rowspan="4"  >Block 4 (SOA = 600 ms, BPD = 1800 ms)</td><td align="center" valign="middle" >中性</td><td align="center" valign="middle" >679.08 &#177; 58.19</td><td align="center" valign="middle" >0.63 &#177; 0.21</td></tr><tr><td align="center" valign="middle" >低唤醒</td><td align="center" valign="middle" >681.39 &#177; 60.78</td><td align="center" valign="middle" >0.60 &#177; 0.19</td></tr><tr><td align="center" valign="middle" >高唤醒</td><td align="center" valign="middle" >677.52 &#177; 70.28</td><td align="center" valign="middle" >0.58 &#177; 0.22</td></tr><tr><td align="center" valign="middle" >新词</td><td align="center" valign="middle" >698.29 &#177; 50.71</td><td align="center" valign="middle" >0.70 &#177; 0.17</td></tr><tr><td align="center" valign="middle"  rowspan="4"  >Block 5 (SOA = 1000 ms, BPD = 1000 ms)</td><td align="center" valign="middle" >中性</td><td align="center" valign="middle" >680.75 &#177; 59.49</td><td align="center" valign="middle" >0.60 &#177; 0.21</td></tr><tr><td align="center" valign="middle" >低唤醒</td><td align="center" valign="middle" >689.45 &#177; 56.58</td><td align="center" valign="middle" >0.62 &#177; 0.21</td></tr><tr><td align="center" valign="middle" >高唤醒</td><td align="center" valign="middle" >697.70 &#177; 69.97</td><td align="center" valign="middle" >0.60 &#177; 0.22</td></tr><tr><td align="center" valign="middle" >新词</td><td align="center" valign="middle" >703.71 &#177; 52.35</td><td align="center" valign="middle" >0.72 &#177; 0.15</td></tr><tr><td align="center" valign="middle"  rowspan="4"  >Block 6 (SOA = 1000 ms, BPD = 1800 ms)</td><td align="center" valign="middle" >中性</td><td align="center" valign="middle" >678.48 &#177; 54.24</td><td align="center" valign="middle" >0.61 &#177; 0.22</td></tr><tr><td align="center" valign="middle" >低唤醒</td><td align="center" valign="middle" >661.45 &#177; 69.54</td><td align="center" valign="middle" >0.60 &#177; 0.21</td></tr><tr><td align="center" valign="middle" >高唤醒</td><td align="center" valign="middle" >662.89 &#177; 57.73</td><td align="center" valign="middle" >0.65 &#177; 0.23</td></tr><tr><td align="center" valign="middle" >新词</td><td align="center" valign="middle" >696.78 &#177; 50.01</td><td align="center" valign="middle" >0.66 &#177; 0.18</td></tr></tbody></table></table-wrap><p>表2. 不同条件下学过的旧词和新词的再认反应时(ms)和正确率(M &#177; SD)</p><sec id="s4_1"><title>3.1. 反应时</title><p>对每个block中不同背景下学过的旧词的反应时与其所在block中新词的反应时进行单因素(四个水平)方差分析，结果显示，在Block 1 (SOA = 0 ms，BPD = 1000 ms)中，主效应显著[F(3,60) = 3.53，p &lt; 0.05]，事后比较显示，中性图片背景下学过的旧词的再认反应时显著快于新词(p &lt; 0.01)。其它block里没有发现显著的主效应。</p><p>对旧词的再认反应时进行3(唤醒：中性，低唤醒，高唤醒) &#215; 3(SOA: 0 ms，600 ms，1000 ms) &#215; 2(背景图片呈现时间：1000 ms，1800 ms)的重复测量方差分析，结果显示，唤醒的主效应显著[F(2, 40) = 3.24，p = 0.05]，事后比较发现，中性背景下学过的旧词的再认反应时显著短于高唤醒背景下学过的旧词(p &lt; 0.05)，也有短于低唤醒背景下学过的旧词的趋势(p = 0.09)。SOA的主效应显著[F(2,40) = 4.50, p &lt; 0.05]，事后比较发现，SOA为0 ms条件下学过的旧词的再认反应时显著长于SOA等于1000 ms条件下学过的旧词，如图2所示。背景呈现时间的主效应显著[F(1, 20) = 8.48, p &lt; 0.01]，背景呈现1000 ms条件下学过的旧词的再认反应时显著长于背景呈现1800 ms条件下学过的旧词。唤醒 &#215; 背景呈现时间的交互作用显著[F(2, 40) = 4.50, p &lt; 0.05]，简单效应分析发现：当背景呈现1000 ms时，中性背景下学过的旧词的再认反应时显著短于低唤醒(p &lt; 0.05)和高唤醒(p &lt; 0.01)背景下学过的旧词；当背景呈现1800 ms时，三种唤醒条件间无显著差异，如图3所示。唤醒 &#215; SOA的交互作用不显著[F(4, 80) = 4.50, p = 0.245]。SOA &#215; 背景呈现时间的交互作用接近显著[F(2, 40) = 2.66, p = 0.083]，简单效应分析发现，当背景呈现1000 ms时，SOA各水平间无显著差异；当背景呈现1800 ms时，SOA为0 ms条件下学过的旧词的再认反应时显著长于SOA等于600 ms(p &lt; 0.05)和SOA等于1000 ms(p &lt; 0.001)条件下学过的旧词。另外，当SOA等于0 ms和600 ms时，背景呈现1000 ms条件下学过的旧词的再认反应时和背景呈现1800 ms条件下学过的旧词没有显著差异；当SOA等于1000 ms时，背景呈现1000 ms条件下学过的旧词的再认反应时显著长于背景呈现1800 ms条件下学过的旧词(p &lt; 0.05)。唤醒 &#215; SOA &#215; 背景呈现时间的交互作用不显著[F(4, 80) = 0.70, p = 0.60]。</p></sec><sec id="s4_2"><title>3.2. 正确率</title><p>对每个block中不同背景下学过的旧词的再认正确率与其所在block中新词的正确率进行单因素(四</p><p>图2. 不同SOA条件下学过的旧词的再认反应时</p><p>图3. 在不同唤醒和不同背景呈现时间条件下学过的旧词的反应时</p><p>个水平)方差分析，结果显示，在Block 1 (SOA = 0 ms, BPD = 1000 ms)中，主效应显著[F(3.60) = 3.77, p &lt; 0.05]，事后比较显示，低唤醒图片背景下学过的旧词的再认正确率显著低于新词(p &lt; 0.05)。在Block 2 (SOA = 0 ms, BPD = 1800 ms)中，主效应边缘显著[F(3.60) = 2.47, p = 0.071]，事后比较显示，高唤醒图片背景下学过的旧词的再认正确率显著低于新词(p = 0.05)。在Block 3 (SOA = 600 ms，BPD = 1000 ms)中，主效应显著[F(3.60) = 2.81, p &lt; 0.05]，事后比较显示，高唤醒图片背景下学过的旧词的再认正确率显著低于新词(p &lt; 0.05)。其它block里没有发现显著的主效应。</p><p>对旧词的再认正确率进行3(唤醒：中性，低唤醒，高唤醒) &#215; 3(SOA: 0 ms, 600 ms, 1000 ms) &#215; 2(背景呈现时间：1000 ms, 1800 ms)的重复测量方差分析，结果显示，SOA的主效应显著[F(2.40) = 4.50, p = 0.001]，事后比较发现，SOA为0 ms条件下学过的旧词的再认正确率显著低于SOA等于600 ms (p &lt; 0.01)和SOA等于1000 ms (p = 0.001)条件下学过的旧词的正确率。其它主效应和交互作用均不显著。</p></sec></sec><sec id="s5"><title>4. 讨论</title><p>本研究运用学习—再认实验范式，探讨了编码阶段呈现的任务无关情绪图片背景对词语再认记忆的影响以及背景呈现时间和SOA对这种影响的调节作用。与我们的假设一致，研究显示了情绪背景对再认记忆的损害效应，并且这种效应受到了某些时间变量的影响。下面对本研究的结果做具体的阐述和讨论。</p><p>首先，在与被试对新词的反应进行比较时，在SOA等于0 ms、背景呈现1000 ms条件下，一方面是中性背景下学过的旧词的再认反应时快于新词，另一方面是低唤醒背景下学过的旧词的再认正确率低于新词。在SOA等于0 ms、背景呈现1800 ms以及SOA等于600 ms、背景呈现1000 ms条件下，高唤醒背景下学过的旧词的再认正确率低于新词。这些结果暗示，在SOA较短的条件下，背景图片的情绪性不利于对词语的记忆。</p><p>本研究结果进一步显示，在对旧词的再认反应时上存在显著的唤醒效应，与中性背景相比，高唤醒背景下学过的旧词的再认反应显著更慢，低唤醒背景下学过的旧词的再认反应也有更慢的趋势。这表明随着编码时情绪背景唤醒度的提高，情绪背景对词语记忆的损害程度会更大。这与Zhang等人(2015)发现情绪背景损害中性词再认的结果一致。前人研究发现，高唤醒情绪刺激对认知操作起破坏作用(Nadel et al., 1998)，并且能够分散对目标刺激的注意(Schimmack, 2005)。这说明在不要求被试将背景和项目联系起来的情况下，高唤醒情绪背景仍然占用了被试更多的心理资源，干扰了对目标词语的编码加工，因而可能造成了对词语记忆的损害。</p><p>另外，本研究发现，在长SOA(1000 ms)条件下存在显著的背景呈现时间效应，即背景呈现1000 ms条件下学过的旧词的再认反应慢于背景呈现1800 ms条件下学过的旧词。这表明随着背景呈现时间的增长，对词语的再认有更好的表现。我们认为，这可能是由于当背景呈现时间较长时，被试能够对任务无关的背景进行比较充分的抑制，使需要记忆的词语获得相对较好的加工，进而提高了再认效率。但是，在短SOA(0 ms和600 ms)条件下没有发现显著的背景呈现时间效应。短SOA意味着背景图片与目标词语同时呈现或者连续快速呈现，被试不能像在长SOA条件下那样，在学习词语之前已经对背景图片进行了较充分的加工。因此，不论背景呈现时间是1000 ms还是1800 ms，其对目标词语编码加工的干扰都会比较强，因而可能会掩盖相对较弱的背景呈现时间效应。</p><p>更重要的结果是，背景呈现时间调节了唤醒效应。在背景呈现1000 ms条件下，与中性背景相比，高、低唤醒背景下学过的旧词的再认反应显著更慢；在背景呈现1800 ms条件下，则没有发现显著的唤醒效应。如前言所述，Zhang等人(2015)在研究中设置了较短的背景呈现时间，结果发现了情绪背景对中性词记忆的损害效应。而设置较长背景呈现时间的研究则没有显示出情绪背景对记忆的损害效应(Smith et al., 2004; Jaeger et al., 2009)。我们认为，当背景呈现时间较短时，被试对背景情绪信息的抑制还不够充分，相对于中性背景，情绪背景会干扰被试对词语的编码加工，从而损害了词语的记忆。而当背景呈现时间较长时，被试能够对背景情绪信息进行比较充分的抑制，因而目标词语受到的情绪背景损害效应减弱以致消失。</p><p>再者，本研究结果还显示，SOA为0 ms条件下学过的旧词的再认正确率低于SOA为600 ms和1000 ms条件下学过的旧词，而且在背景呈现1800 ms条件下SOA为0 ms条件下学过的旧词的再认反应慢于SOA为600 ms和1000 ms条件下学过的旧词。也就是说，随着SOA的增长，词语的记忆效果更好。这一结果不难理解，SOA越长，被试越有可能避免背景和目标词语之间的知觉竞争，从而更好地完成词语的编码加工。本研究没有发现SOA对唤醒效应的调节作用，这与我们的假设不符。我们认为，这可能与本实验设置的SOA条件差异较小有关(0 ms~1000 ms)。如果扩大SOA条件间的差异，可能会获得更理想的结果。我们将在未来的研究中进一步探究这一问题。</p><p>总之，本研究表明，随着情绪背景唤醒度的提高，其对目标词语记忆的损害效应会越强。并且SOA的减少和背景呈现时间的缩短也都会损害被试对目标词语的记忆表现。尤为重要的是，情绪背景相对于中性背景的记忆损害效应会受到背景呈现时间的影响，背景呈现时间的延长会降低情绪背景的损害效应。本研究结果扩展了人们对任务无关情绪背景在学习记忆中的作用的认识，确定了情绪背景的唤醒维度对中性项目记忆的影响，并明确了情绪背景对中性项目记忆损害作用发生的条件。</p></sec><sec id="s6"><title>致 谢</title><p>本研究得到国家自然科学基金(31470980)的资助。</p></sec><sec id="s7"><title>文章引用</title><p>郭新宇,李云云,张 钦. 学习时的情绪图片背景对词语再认记忆的影响：SOA和背景呈现时间的调节作用Recognition Memory of Words Can Be Impaired by Task-Irrelevant Emotional Encoding Contexts: The Moderating Effect of SOA and Context Duration[J]. 心理学进展, 2017, 07(05): 730-738. http://dx.doi.org/10.12677/AP.2017.75091</p></sec><sec id="s8"><title>参考文献 (References)</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.20823-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">康诚, 王振宏(2013). 依赖于唤醒与效价的情绪记忆增强效应: 自动与控制加工. 心理学报, 45(9), 970-980.</mixed-citation></ref><ref id="hanspub.20823-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">徐展, 皇甫柏会, 佐堃(2016). 高低工作记忆容量个体脱离注意捕获的时间差异. 西南大学学报(自然科学版), 38(5), 174-181.</mixed-citation></ref><ref id="hanspub.20823-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Bocanegra, B. R., &amp; Zeelenberg, R. (2009). Dissociating Emotion-Induced Blindness and Hypervision. Emotion, 9, 865-873. &lt;br&gt;https://doi.org/10.1037/a0017749</mixed-citation></ref><ref id="hanspub.20823-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Chiu, Y. C., Dolcos, F., Gonsalves, B. D., &amp; Cohen, N. J. (2013). On Opposing Effects of Emotion on Contextual or Relational Memory. Frontiers in Psychology, 4, 103. &lt;br&gt;https://doi.org/10.3389/fpsyg.2013.00103</mixed-citation></ref><ref id="hanspub.20823-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Erk, S., Kiefer, M., Grothe, J, Wunderlich, A. P., Spitzer, M., &amp; Walter, H. (2003). Emotional Context Modulates Subsequent Memory Effect. NeuroImage, 18, 439-447.</mixed-citation></ref><ref id="hanspub.20823-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Erk, S., Martin, S., &amp; Walter, H. (2005). Emotional Context during Encoding of Neutral Items Modulates Brain Activation Not Only during Encoding but Also During Recognition. NeuroImage, 26, 829-838.</mixed-citation></ref><ref id="hanspub.20823-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Jaeger, A., Johnson, J. D., Corona, M., &amp; Rugg, M. D. (2009). ERP Correlates of the Incidental Retrieval of Emotional Information: Effects of Study-Test Delay. Brain Research, 1269, 105-113.</mixed-citation></ref><ref id="hanspub.20823-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Kissler, J., Herbert, C., Peyk, P., &amp; Junghofer, M. (2007). Buzzwords: Early Cortical Responses to Emotional Words during Reading. Psychological Science, 18, 475-480. &lt;br&gt;https://doi.org/10.1111/j.1467-9280.2007.01924.x</mixed-citation></ref><ref id="hanspub.20823-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Lang, P. J., Bradley, M. M., &amp; Cuthbert, B. (1999). International Affective Picture System (IAPS): Instruction Manual and Affective Ratings. Technical Report No. A-4, Gainsville, FL: The Center for Research in Psychophysiology, University of Florida,.</mixed-citation></ref><ref id="hanspub.20823-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Lang, P. J., Greenwald, M. K., Bradley, M. M., &amp; Hamm, A. O. (1993). Looking at Pictures: Affective, Facial, Visceral, and Behavioral Reactions. Psychophysiology, 30, 261-273. &lt;br&gt;https://doi.org/10.1111/j.1469-8986.1993.tb03352.x</mixed-citation></ref><ref id="hanspub.20823-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Luo, Y. J., &amp; Wang, Y. N. (2004). Chinese Affective Words System (CAWS). Beijing: Institute of Psychology, CAS.</mixed-citation></ref><ref id="hanspub.20823-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Maratos, E. J., &amp; Rugg, M. D. (2001). Electrophysiological Correlates of the Retrieval of Emotional and Non-Emotional Context. Journal of Cognitive Neuroscience, 13, 877-891. &lt;br&gt;https://doi.org/10.1162/089892901753165809</mixed-citation></ref><ref id="hanspub.20823-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Mather, M., &amp; Sutherland, M. (2009). Disentangling the Effects of Arousal and Valence on Memory for Intrinsic Details. Emotion Review, 1, 118-119. &lt;br&gt;https://doi.org/10.1177/1754073908100435</mixed-citation></ref><ref id="hanspub.20823-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">Müller, M. M., Andersen, S. K., &amp; Keil, A. (2008). Time Course of Competition for Visual Processing Resources between Emotional Pictures and Foreground Task. Cerebral Cortex, 18, 1892-1899. &lt;br&gt;https://doi.org/10.1093/cercor/bhm215</mixed-citation></ref><ref id="hanspub.20823-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">Nadel, L., &amp; Jacobs, W. J. (1998). Traumatic Memory Is Special. Current Directions in Psychological Science, 7, 154-157.  
&lt;br&gt;https://doi.org/10.1111/1467-8721.ep10836842</mixed-citation></ref><ref id="hanspub.20823-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">Schupp, H. T., Junghöfer, M., Weike, A. I., &amp; Hamm, A. O. (2003). Attention and Emotion: An ERP Analysis of Facilitated Emotional Stimulus Processing. NeuroReport, 14, 1107-1110. &lt;br&gt;https://doi.org/10.1097/00001756-200306110-00002</mixed-citation></ref><ref id="hanspub.20823-ref17"><label>17</label><mixed-citation publication-type="other" xlink:type="simple">Schupp, H. T., Stockburger, J., Codispoti, M., Junghöfer, M., Weike, A. I., &amp; Hamm, A. O. (2007). Selective Visual Attention to Emotion. Journal of Neuroscience, 27, 1082-1089. &lt;br&gt;https://doi.org/10.1523/JNEUROSCI.3223-06.2007</mixed-citation></ref><ref id="hanspub.20823-ref18"><label>18</label><mixed-citation publication-type="other" xlink:type="simple">Smith, A., Dolan, R., &amp; Rugg, M. (2004). Event-Related Potential Correlates of the Retrieval of Emotional and Nonemotional Context. Journal of Cognitive Neuroscience, 16, 760-775. &lt;br&gt;https://doi.org/10.1162/089892904970816</mixed-citation></ref><ref id="hanspub.20823-ref19"><label>19</label><mixed-citation publication-type="other" xlink:type="simple">Steinmetz, K. R. M., Addis, D. R., &amp; Kensinger, E. A. (2010). The Effect of Arousal on the Emotional Memory Network Depends on Valence. NeuroImage, 53, 318-324.</mixed-citation></ref><ref id="hanspub.20823-ref20"><label>20</label><mixed-citation publication-type="other" xlink:type="simple">Zhang, Q., Liu, X., An, W., Yang, Y., &amp; Wang, Y. (2015). Recognition Memory of Neutral Words Can Be Impaired by Task-Irrelevant Emotional Encoding Contexts: Behavioral and Electrophysiological Evidence. Frontiers in Human Neuroscience, 9, 73.</mixed-citation></ref></ref-list></back></article>