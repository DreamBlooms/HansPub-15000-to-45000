<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2015.58036</article-id><article-id pub-id-type="publisher-id">CSA-16089</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20150800000_18815109.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  张量投票在目标跟踪中的应用
  Application of Tensor Voting in Object Tracking
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>邵</surname><given-names>晓芳</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>李</surname><given-names>大龙</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib></contrib-group><aff id="aff1"><addr-line>海军航空工程学院青岛校区，山东 青岛 </addr-line></aff><aff id="aff2"><addr-line>null</addr-line></aff><author-notes><corresp id="cor1">* E-mail:<email>pugongying_0532@163.com    (邵晓)</email>;</corresp></author-notes><pub-date pub-type="epub"><day>24</day><month>09</month><year>2015</year></pub-date><volume>05</volume><issue>08</issue><fpage>278</fpage><lpage>284</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
  目标跟踪就是在视频序列的每幅图像中找到所感兴趣的运动目标的位置，建立起运动目标在各幅图像中的联系。在分类总结相关工作的基础上，介绍了张量投票方法在目标跟踪中的应用，给出了算法流程和实验结果并进行了分析和展望。
   
  Object tracking is a process to locate an interested object in a series of image, so as to reconstruct the moving object’s track. This paper presents a summary of related works and introduces how to apply the tensor voting method in object tacking. The algorithm’s flowchart and typical experimental result are demonstrated. At last, we analyze the characteristics of the algorithm and suggest some future directions.
 
</p></abstract><kwd-group><kwd>目标跟踪，轨迹校正，目标检测, Object Tracking</kwd><kwd> Track Alignment</kwd><kwd> Object Detection</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>张量投票在目标跟踪中的应用<sup> </sup></title><p>邵晓芳，李大龙</p><p>海军航空工程学院青岛校区，山东 青岛</p><p>Email: pugongying_0532@163.com</p><p>收稿日期：2015年9月2日；录用日期：2015年9月20日；发布日期：2015年9月24日</p><disp-formula id="hanspub.16089-formula313"><graphic xlink:href="http://html.hanspub.org/file/2-1540486x5_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>目标跟踪就是在视频序列的每幅图像中找到所感兴趣的运动目标的位置，建立起运动目标在各幅图像中的联系。在分类总结相关工作的基础上，介绍了张量投票方法在目标跟踪中的应用，给出了算法流程和实验结果并进行了分析和展望。</p><p>关键词 :目标跟踪，轨迹校正，目标检测</p><disp-formula id="hanspub.16089-formula314"><graphic xlink:href="http://html.hanspub.org/file/2-1540486x6_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s3"><title>1. 引言</title><p>目标跟踪是在一段视频序列中定位感兴趣的运动目标，并形成目标运动的路径或轨迹。作为计算机视觉领域中视频分析的基本内容之一，目标跟踪起到承上启下的作用，它在目标检测的基础之上，又是目标行为分析的基础，是在捕获到的目标初始状态和通过特征提取得到的目标特征基础上，进行一种时空结合的目标状态估计。目标跟踪在智能监控、视频检索、人机交互、智能交通和基于运动的目标识别等领域均有广泛的应用[<xref ref-type="bibr" rid="hanspub.16089-ref1">1</xref>] 。</p><p>尽管目标跟踪已经获得很多研究成果，包括一些实时性和鲁棒性都很好的算法，但是很多算法都是在一定约束条件下进行的，因而与目标跟踪有关的特征选择、目标表示、运动估计等问题都值得进一步深入研究，尤其是特征的选择、遮挡的处理和轨迹误差的校正。张量投票方法应用于目标跟踪正是针对目标跟踪面临的难题。</p><p>本文旨在总结目标跟踪的相关算法的基础上，具体描述张量投票方法在目标跟踪中的应用。主要内容安排如下：第二节是相关工作；第三节介绍张量投票在目标跟踪中的应用，并给出实验结果示例；最后是总结与展望。</p></sec><sec id="s4"><title>2. 相关工作</title><p>为了克服由噪音、遮挡和复杂环境下引起的目标或背景的变化，已有许多目标跟踪算法被提出。不同算法对目标(外观、形状、数目)、相机数目及运动形式、目标运动形式、光照条件等都有不同要求。根据在目标检测所选择的特征不同，可以将跟踪算法分为点跟踪、核跟踪、轮廓跟踪和形状匹配。下面进行分别描述。</p><p>点跟踪选取点特征作为目标检测的依据，以预测目标在下一帧的位置再根据实际图像进行修正为主要解决思路，一般情况下施加的运动约束为邻近性、最大速度、最小速度改变、共同运动、三维结构约束等。这类方法可以进一步分为确定性方法和统计性方法，确定性方法以MGE tracker [<xref ref-type="bibr" rid="hanspub.16089-ref2">2</xref>] 、GOA tracker [<xref ref-type="bibr" rid="hanspub.16089-ref3">3</xref>] 为典型；而统计性方法则以Kalman滤波[<xref ref-type="bibr" rid="hanspub.16089-ref4">4</xref>] 、粒子滤波[<xref ref-type="bibr" rid="hanspub.16089-ref5">5</xref>] 、联合概率数据关联(JPDAF) [<xref ref-type="bibr" rid="hanspub.16089-ref6">6</xref>] (建立多目标的联合概率分布)、PMHT [<xref ref-type="bibr" rid="hanspub.16089-ref7">7</xref>] (在跟踪过程中保留多种匹配假设MHT，通过概率估计减小MHT的计算量)、条件随机场模型[<xref ref-type="bibr" rid="hanspub.16089-ref8">8</xref>] 为代表。上述方法中，只有Kalman滤波是针对单一目标，而MGE、PMHT是其中可以处理进入摄像机镜头的新目标和消失的目标，并可以处理一些遮挡。不过其中应用较广的还是Kalman滤波和粒子滤波，在实际应用中应该根据实际需要来选择合适的滤波器：若无须考虑系统的非线性强度和非高斯环境，则优先采用EKF (Extended Kalman Filter，扩展卡尔曼滤波)；对于一般的非线性高斯模型，宜采用(UKF，Unscented Kalman Filter，不敏卡尔曼滤波)；实时性要求不高，状态维数小的非线性非高斯问题中，可选用粒子滤波(Particle Filter) [<xref ref-type="bibr" rid="hanspub.16089-ref9">9</xref>] 。</p><p>核跟踪方法可以选择模板、颜色直方图、光流场或混合模型等特征，典型算法有简单模板匹配、均值平移(Mean-shift) [<xref ref-type="bibr" rid="hanspub.16089-ref10">10</xref>] 、外观模型的KLT变换[<xref ref-type="bibr" rid="hanspub.16089-ref11">11</xref>] 、分层算法[<xref ref-type="bibr" rid="hanspub.16089-ref12">12</xref>] ；也可以采用多视点外观模型，典型方法有Eigentracking [<xref ref-type="bibr" rid="hanspub.16089-ref13">13</xref>] 、支持矢量机[<xref ref-type="bibr" rid="hanspub.16089-ref14">14</xref>] 等。这类方法的主要目的是通过匹配的方式估计目标的运动，一般对目标采用模板表示法或概率密度模型表示法，施加的约束条件有运动模型约束(匀速或常加速等)和光流约束条件。这类方法的评价标准为目标数目、遮挡处理、是否需要训练、是否需要人工初始化等。从这些角度来看，分层算法的性能最优，不但能够处理多目标和完全遮挡，而且可以处理旋转、平移和尺度等类型的运动，不需要训练和初始化；其余算法都是针对单目标，能够处理平移或仿射变换型的运动以及部分遮挡。</p><p>轮廓跟踪的方法以活动轮廓模型为典型代表，基于活动轮廓的跟踪思想是利用封闭的曲线轮廓来表达运动目标，并且该轮廓能够自动连续的更新。这些算法的目的是直接提取目标的形状，相对于基于区域的算法提供针对目标更有效的描述。相对基于区域的跟踪，此类方法对于描述物体较为简单而有效率，可以减少运算的复杂程度，由于轮廓是一种封闭曲线，即使存在干扰或是部分遮挡，该算法也可以实现对目标的连续跟踪。但是，跟踪精度只限在轮廓级水平，并且仅是从轮廓上对三维目标进行形态描述也比较困难，再加上跟踪效果与初步轮廓的检测或选取密切相关，较难用于全自动的检测跟踪系统。比较突出的计算方法有状态空间模型(State space models) [<xref ref-type="bibr" rid="hanspub.16089-ref15">15</xref>] 、变分法(Variational methods) [<xref ref-type="bibr" rid="hanspub.16089-ref16">16</xref>] 、启发式方法(Heuristic methods) [<xref ref-type="bibr" rid="hanspub.16089-ref17">17</xref>] 等。</p><p>像人体目标这样的复杂目标一般不能用简单几何形状来表示，一般根据前几帧的检测结果生成复杂的形状模型来表示。比如，人体形状除了可以用线图法和二维轮廓简单近似外，还有利用广义锥台、椭圆柱、球等三维模型来描述人体的结构细节的立体模型和层次模型(包括四个层次：骨架、椭圆球体模拟组织和脂肪、多边形表面代表皮肤、阴影渲染)。形状匹配法通过将目标模型投影到图像数据进行匹配来完成目标跟踪，而形状模型则可以根据先验知识获取，通常利用离线的人工测量、计算机辅助设计(CAD)和计算机视觉技术来构造模型。在车辆跟踪方面，目前主要使用雷丁大学(University of Reading)提出的三维线框车辆模型[<xref ref-type="bibr" rid="hanspub.16089-ref18">18</xref>] 。模式识别国家重点实验室(NLPR)、德国卡尔斯鲁厄大学(University of Karlsruhe)的研究小组也基于该模型的车辆定位和跟踪方面做出了重要贡献。这类方法的匹配策略以Hausdorff 形状匹配法[<xref ref-type="bibr" rid="hanspub.16089-ref19">19</xref>] 、Hough变换 [<xref ref-type="bibr" rid="hanspub.16089-ref20">20</xref>] 、直方图法等为代表[<xref ref-type="bibr" rid="hanspub.16089-ref21">21</xref>] 。</p></sec><sec id="s5"><title>3. 张量投票方法在目标跟踪中的应用</title><p>在目标跟踪方面，张量投票方法主要针对静止相机拍摄到的一系列运动目标图像的跟踪问题，通过投票施加运动轨迹的平滑性约束，从而进行不确定区域的合并以及提取出特征显著度、滤除噪声点、处理部分遮挡等[<xref ref-type="bibr" rid="hanspub.16089-ref22">22</xref>] [<xref ref-type="bibr" rid="hanspub.16089-ref23">23</xref>] ，其计算框架如图1所示，算法首先对输入图像进行运动区域检测，然后生成各运动区域的包围框集合；关键步骤在于生成输入数据的(2D + t)维的张量表示，进而通过张量投票过程进行运动速度估计，主要特点在于可以通过张量投票施加运动曲线的平滑性约束优化目标运动速度的计算。</p><p>图1中，运动区域检测采用的是文献[<xref ref-type="bibr" rid="hanspub.16089-ref23">23</xref>] 中的基于偏微分方程的方法，输出为检测到的运动区域及其包围框。</p><p>张量投票算法的输入即为前面检测到的运动区域的包围框集合，其2D + t的表示方法中包含了包围盒中心在t时刻的坐标(<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540486x7_hanspub.png" xlink:type="simple"/></inline-formula>)、包围盒中包含的运动元素和包围盒本身，如式(1)所示：</p><disp-formula id="hanspub.16089-formula315"><label>(1)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/2-1540486x8_hanspub.png"  xlink:type="simple"/></disp-formula><p>式中，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540486x9_hanspub.png" xlink:type="simple"/></inline-formula>为运动图像序列的帧数，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540486x10_hanspub.png" xlink:type="simple"/></inline-formula>表示<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540486x11_hanspub.png" xlink:type="simple"/></inline-formula>时刻包围盒中包含的相连元素的数目，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540486x12_hanspub.png" xlink:type="simple"/></inline-formula>代表包围盒中心的2D + t坐标，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540486x13_hanspub.png" xlink:type="simple"/></inline-formula>代表运动元素的集合，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540486x14_hanspub.png" xlink:type="simple"/></inline-formula>表示包围盒。</p><p>包围盒的位置和速度是用3D张量表示的，设根据帧间对应点的位置计算出的包围盒速度为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540486x15_hanspub.png" xlink:type="simple"/></inline-formula>，则其3D棒形张量表示为：</p><p>图1. 目标跟踪的计算流程</p><disp-formula id="hanspub.16089-formula316"><label>(2)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/2-1540486x17_hanspub.png"  xlink:type="simple"/></disp-formula><p>式中，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540486x18_hanspub.png" xlink:type="simple"/></inline-formula>即为该张量的非零特征值对应的特征矢量，该张量的显著度为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540486x19_hanspub.png" xlink:type="simple"/></inline-formula>。</p><p>投票过程是在帧间进行的，也就是说，各数据点不会对同一帧的数据点进行投票。投票域的取向根据目标是匀速运动还是匀加速运动分别建立了线性模型和抛物线模型，线性模型的投票域取向即为两点连线方向，抛物线模型的取向则为曲线的切线方向；投票的权重(幅度大小)综合了四个方面的因素，即投票点和接收点之间的瞬时距离、投票者的显著度、抛物线模型中体现的加速度和两点邻域的遮挡问题。具体来说，投票点<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540486x20_hanspub.png" xlink:type="simple"/></inline-formula>对接收点<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540486x21_hanspub.png" xlink:type="simple"/></inline-formula>的速度估计为：</p><disp-formula id="hanspub.16089-formula317"><label>(3)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/2-1540486x22_hanspub.png"  xlink:type="simple"/></disp-formula><p>为防止对速度过大者或相关程度低的帧间投票，这里还对投票域作了范围限定，令<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540486x23_hanspub.png" xlink:type="simple"/></inline-formula>为各帧间速度点的最大位置偏差，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540486x24_hanspub.png" xlink:type="simple"/></inline-formula>为投票点之间帧数的限制，则要求两点之间满足以下条件方可进行投票：</p><disp-formula id="hanspub.16089-formula318"><label>(4)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/2-1540486x25_hanspub.png"  xlink:type="simple"/></disp-formula><p>假设运动区域存在遮挡和分裂，可通过不确定区域检测来解决这一问题。不确定区域定义为相关的包围盒<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540486x26_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540486x27_hanspub.png" xlink:type="simple"/></inline-formula>之间的且属于<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540486x28_hanspub.png" xlink:type="simple"/></inline-formula>的匹配候选点集。如计算得出包围盒<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540486x29_hanspub.png" xlink:type="simple"/></inline-formula>与所有相关包围盒的不确定区域总和占包围盒<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540486x30_hanspub.png" xlink:type="simple"/></inline-formula>的比例为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540486x31_hanspub.png" xlink:type="simple"/></inline-formula>，则投票的权重计算公式为：</p><disp-formula id="hanspub.16089-formula319"><label>(5)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/2-1540486x32_hanspub.png"  xlink:type="simple"/></disp-formula><p>式中，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540486x33_hanspub.png" xlink:type="simple"/></inline-formula>为预先设定的常数，与张量投票域的衰减常数功能类似。</p><p>计算出投票域的速度取向和权重之后，即可开始投票过程。初始输入的数据点会对不确定区域中的数据点进行松散投票，投票之后保留显著度最大点为包围盒<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540486x34_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540486x35_hanspub.png" xlink:type="simple"/></inline-formula>之间的公共区域的最佳匹配点。在此基础上，再进行稠密投票，根据运动目标点在各帧中的位置获得目标的运动轨迹。在此，可发挥张量投票算法的优势来对运动轨迹施加平滑性约束并修复部分缺口。</p><p>示例应用如图2 [<xref ref-type="bibr" rid="hanspub.16089-ref22">22</xref>] 所示，一般过程是先在运动图像序列中检测运动区域；然后应用张量投票进行处理，目标的三维空间位置数据构成三维张量，再加上不同时刻的位置变化就构成了融合运动轨迹的四维数据，但是对运动估计的滤波处理以及运动估计都是通过三维张量投票来实现的；最后获得的就是选出跟踪区域的图像序列以及优化的运动轨迹曲线。</p></sec><sec id="s6"><title>4. 结束语</title><p>总体说来，目前跟踪的目标主要是人和车辆，点跟踪是对运动目标作了最高程度的抽象，其中基于Kalman滤波及预测的目标跟踪算法是目标跟踪的主流算法，研究比较广泛；核跟踪综合了目标的一些外观特征，与点跟踪方法可以结合使用；轮廓跟踪法和形状匹配法考虑目标的完整形状，但是一般没有考虑遮挡情况的处理，只是可以处理目标的分离和合并，比如：一个人拿了一件东西走了一段时间又将东西放下[<xref ref-type="bibr" rid="hanspub.16089-ref24">24</xref>] 。尽管目标跟踪已经获得很多研究成果，包括一些实时性和鲁棒性都很好的算法，但是很多算法都是在一定约束条件下进行的，因而与目标跟踪有关的特征选择、目标表示、运动估计等问题都值得进一步深入研究。时至今日，实现复杂场景下的稳健跟踪依然是一个具挑战意义的研究课题。这种挑战绝大多数是来自视频序列中的图像变化和多个运动目标存在。目前所有的流行方法都不足以做到对光照、多运动目标的鲁棒性。所以说，张量投票方法针对的正是目标跟踪中的难点问题。</p><p>张量投票方法除了可以应用于目标跟踪之外，其思想还可应用于图像序列的插值，现有的方法如灰度平均法、选择粘贴法、遗传算法和高维数值计算中的样条插值等方法均忽略了图像序列内在的几何构造。由于图像序列可以将不同的背景和运动的前景区分开来，因而可在一定范围内仅对运动目标进行插值。于是可利用张量投票将运动目标的可能轨迹找出，再结合一些限制条件选取目标合适的过渡位置，</p><p>图2. 目标跟踪过程</p><p>最后在保持原有几何元素不变的情况下重建过渡图像，对于直线运动，确定端点后即可找出运动方式；对于曲线运动，用若干较短的线段逼近曲线即可确定轨迹上的一些插值点。</p></sec><sec id="s7"><title>文章引用</title><p>邵晓芳,李大龙, (2015) 张量投票在目标跟踪中的应用Application of Tensor Voting in Object Tracking. 计算机科学与应用,08,278-284. doi: 10.12677/CSA.2015.58036</p></sec><sec id="s8"><title>参考文献 (References)</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.16089-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Yilmaz, A., Javed, O. and Shah, M. (2006) Object tracking: A survey. ACM Computing Surveys, 38, 1-45.  
&lt;br&gt;http://dx.doi.org/10.1145/1177352.1177355</mixed-citation></ref><ref id="hanspub.16089-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Salari, V. and Sethi, I.K. (1990) Feature point correspondence in the presence of occlusion. IEEE Transaction Pattern Analysis Machine Intelligence, 12, 87-91. &lt;br&gt;http://dx.doi.org/10.1109/34.41387</mixed-citation></ref><ref id="hanspub.16089-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Veenman, C., Reinders, M. and Backer, E. (2001) Resolving motion correspondence for densely moving points. IEEE Transaction Pattern Analysis Machine Intelligence, 23, 54-72. &lt;br&gt;http://dx.doi.org/10.1109/34.899946</mixed-citation></ref><ref id="hanspub.16089-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Lochner, M. and Trick, L. (2014) Multiple-object tracking while driving: The multiple-vehicle tracking task. Attention. Perception, &amp; Psychophysics, 76, 2326-2345. &lt;br&gt;http://dx.doi.org/10.3758/s13414-014-0694-3</mixed-citation></ref><ref id="hanspub.16089-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Meyerhoff, H., Papenmeier, F. and Huff, M. (2013) Ob-ject-based integration of motion information during attentive tracking. Perception, 42, 119-121. &lt;br&gt;http://dx.doi.org/10.1068/p7273</mixed-citation></ref><ref id="hanspub.16089-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Chevalier, F., Dragicevic, P. and Franconeri, S. (2014) The not-so-staggering effect of staggered animated transitions on visual tracking. IEEE Transactions on Visualization and Computer Graphics, 20, 2241-2250.  
&lt;br&gt;http://dx.doi.org/10.1109/TVCG.2014.2346424</mixed-citation></ref><ref id="hanspub.16089-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Feria, C. (2013) Speed has an effect on multiple-object tracking independently of the number of close encounters between targets and distractors. Attention, Perception, &amp; Psychophysics, 75, 53-67.  
&lt;br&gt;http://dx.doi.org/10.3758/s13414-012-0369-x</mixed-citation></ref><ref id="hanspub.16089-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">高琳, 唐鹏, 盛鹏, 等 (2010) 复杂场景下基于条件随机场的视觉目标跟踪. 光学学报, 6, 1721-1728.</mixed-citation></ref><ref id="hanspub.16089-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">郭晓松, 李奕芃, 郭君斌 (2009) 贝叶斯目标跟踪方法的研究. 计算机工程, 12, 138-141.</mixed-citation></ref><ref id="hanspub.16089-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Comaniciu, D., Ramesh, V. and Andmeer, P. (2003) Kernel-based object tracking. IEEE Transaction Pattern Analysis Machine Intelligence, 25, 564-575. &lt;br&gt;http://dx.doi.org/10.1109/TPAMI.2003.1195991</mixed-citation></ref><ref id="hanspub.16089-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Shi, J. and Tomasi, C. (1994) Good features to track. Pro-ceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, Seattle, 21-23 Jun 1994, 593-600.</mixed-citation></ref><ref id="hanspub.16089-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Tao, H., Sawhney, H. and Kumar, R. (2002) Object tracking with Bayesian estimation of dynamic layer representations. IEEE Transactions on Pattern Analysis Machine Intelligence, 24, 75-89. &lt;br&gt;http://dx.doi.org/10.1109/34.982885</mixed-citation></ref><ref id="hanspub.16089-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Lukavsky, J. (2013) Eye movements in repeated multiple object tracking. Journal of Vision, 13, 1-16. 
&lt;br&gt;http://dx.doi.org/10.1167/13.7.9</mixed-citation></ref><ref id="hanspub.16089-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">Avidan, S. (2001) Support vector tracking. Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, Kauai, 8-14 December 2001, 184-191. &lt;br&gt;http://dx.doi.org/10.1109/cvpr.2001.990474</mixed-citation></ref><ref id="hanspub.16089-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">Isard, M. and Blake, A. (1998) Condensation—Conditional density propagation for visual tracking. International Journal of Computer Vision, 29, 5-28. &lt;br&gt;http://dx.doi.org/10.1023/A:1008078328650</mixed-citation></ref><ref id="hanspub.16089-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">Bertalmio, M., Sapiro, G. and Randall, G. (2000) Morphing ac-tive contours. IEEE Transactions on Pattern Analysis Machine Intelligence, 22, 733-737. &lt;br&gt;http://dx.doi.org/10.1109/34.865191</mixed-citation></ref><ref id="hanspub.16089-ref17"><label>17</label><mixed-citation publication-type="other" xlink:type="simple">Ronfard, R. (1994) Region based strategies for active contour models. International Journal of Computer Vision, 13, 229-251. &lt;br&gt;http://dx.doi.org/10.1007/BF01427153</mixed-citation></ref><ref id="hanspub.16089-ref18"><label>18</label><mixed-citation publication-type="other" xlink:type="simple">Gardner, W.F. and Lawton, D.T. (1996) Interactive model-based vehicle tracking. IEEE Transactions on Pattern Analysis Machine Intelligence, 18, 1115-1121. &lt;br&gt;http://dx.doi.org/10.1109/34.544082</mixed-citation></ref><ref id="hanspub.16089-ref19"><label>19</label><mixed-citation publication-type="other" xlink:type="simple">Rowley, H., Baluja, S. and kanade, T. (2014) Tracking by location and features: Object correspondence across spatiotemporal discontinuities during multiple object tracking. Journal of Experimental Psychology: Human Perception and Performance, 40, 159-171. &lt;br&gt;http://dx.doi.org/10.1037/a0033117</mixed-citation></ref><ref id="hanspub.16089-ref20"><label>20</label><mixed-citation publication-type="other" xlink:type="simple">Sato, K. and Aggarwal, J. (2004) Temporal spatio-velocity transform and its application to tracking and interaction. Computation Vision Image Understanding, 96, 100-128. &lt;br&gt;http://dx.doi.org/10.1016/j.cviu.2004.02.003</mixed-citation></ref><ref id="hanspub.16089-ref21"><label>21</label><mixed-citation publication-type="other" xlink:type="simple">Kang, J., Cohen, I. and Medioni, G. (2004) Object reacquisi-tion using geometric invariant appearance model. Proceedings of the International Conference on Pattern Recognition, Cambridge, 23-26 August 2004, 759-762. 
&lt;br&gt;http://dx.doi.org/10.1109/ICPR.2004.1333883</mixed-citation></ref><ref id="hanspub.16089-ref22"><label>22</label><mixed-citation publication-type="other" xlink:type="simple">Kornprobst, P. and Medioni, G. (2000) A 2D+t tensor voting based approach for tracking. Proceedings of the 15th International Conference on Pattern Recognition, Barcelona, 3-8 September 2000, 1092-1095.</mixed-citation></ref><ref id="hanspub.16089-ref23"><label>23</label><mixed-citation publication-type="other" xlink:type="simple">Kornprobst, P., Deriche, R. and Aubert, G. (1999) Image sequence analysis via partial differential equations. Journal of Mathematical Imaging and Vision, 11, 5-26. &lt;br&gt;http://dx.doi.org/10.1023/A:1008318126505</mixed-citation></ref><ref id="hanspub.16089-ref24"><label>24</label><mixed-citation publication-type="other" xlink:type="simple">张宇, 韩振军, 焦建彬 (2010) 一种基于综合特征评估的运动目标跟踪算法. 中国科学技术大学学报, 5, 491- 495. &lt;br&gt;http://dx.doi.org/10.1109/ICPR.2000.903736</mixed-citation></ref></ref-list></back></article>