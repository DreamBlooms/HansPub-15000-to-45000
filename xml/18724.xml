<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">JISP</journal-id><journal-title-group><journal-title>Journal of Image and Signal Processing</journal-title></journal-title-group><issn pub-type="epub">2325-6753</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/JISP.2016.54019</article-id><article-id pub-id-type="publisher-id">JISP-18724</article-id><article-categories><subj-group subj-group-type="heading"><subject>JISP20160400000_36617282.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于颜色空间纹理融合特征的SOAMST人脸跟踪算法
  SOAMST Face Tracking Algorithm Based on the Combined Feature of Color Space and Texture
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>周</surname><given-names>真真</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>冯</surname><given-names>子亮</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>null</addr-line></aff><aff id="aff1"><addr-line>四川大学计算机学院，成都 四川；视觉合成图形图像技术国家重点学科实验室，成都 四川</addr-line></aff><author-notes><corresp id="cor1">* E-mail:<email>2474674200@qq.com(周真)</email>;</corresp></author-notes><pub-date pub-type="epub"><day>07</day><month>10</month><year>2016</year></pub-date><volume>05</volume><issue>04</issue><fpage>166</fpage><lpage>173</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   针对人脸跟踪中存在的人脸目标与背景颜色相似、光照变化对跟踪算法鲁棒性的影响，本文提出基于颜色空间纹理融合特征的SOAMST跟踪算法，将二阶空间直方图代替SOAMST建立目标模型中的颜色直方图，二阶直方图融合了目标颜色信息和颜色的空间分布信息，比传统颜色直方图更具有目标鉴别能力。此外与MBLBP特征进行融合，构建有效的联合直方图建立目标模型。不同场景下的实验结果表明，与原算法比较，本文的改进算法在人脸颜色与背景相似，光照变化，旋转大小变化等复杂环境下，抗干扰性更强，有更好的跟踪效果，具有更高的准确性和鲁棒性。 In view of the existing question that in the human face tracking, face target is similar to the back-ground color, and light changes impact on the robustness of tracking algorithm, in this paper we put forward a SOAMST face tracking algorithm based on the combined feature of color space and texture, which chooses the second-order spatial histogram instead of SOAMST color histogram to build target model. The second-order histogram is combined with color’s information and color spatial distribution’s information, compared to the traditional color histogram with more target identification ability. In addition to the fusion of MBLBP characteristics, it can build effective joint histogram to establish target model. Experimental results in different scenarios show that compared with the original algorithm, the improved algorithm has better anti-interference performance, better tracking effect, and a higher accuracy and robustness under the complex environment which face color is similar to the background, light changes, and the size of the changes.
    
  
 
</p></abstract><kwd-group><kwd>人脸跟踪，SOAMST，二阶空间直方图，MBLBP，颜色直方图, Face Tracking</kwd><kwd> SOAMST</kwd><kwd> The Second-Order Spatial Histogram</kwd><kwd> MBLBP</kwd><kwd> Color Histogram</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>基于颜色空间纹理融合特征的SOAMST 人脸跟踪算法<sup> </sup></title><p>周真真<sup>1,2</sup>，冯子亮<sup>1,2</sup></p><p><sup>1</sup>四川大学计算机学院，成都 四川</p><p><sup>2</sup>视觉合成图形图像技术国家重点学科实验室，成都 四川</p><disp-formula id="hanspub.18724-formula36"><graphic xlink:href="http://html.hanspub.org/file/3-2670092x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>收稿日期：2016年9月26日；录用日期：2016年10月11日；发布日期：2016年10月14日</p><disp-formula id="hanspub.18724-formula37"><graphic xlink:href="http://html.hanspub.org/file/3-2670092x7_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>针对人脸跟踪中存在的人脸目标与背景颜色相似、光照变化对跟踪算法鲁棒性的影响，本文提出基于颜色空间纹理融合特征的SOAMST跟踪算法，将二阶空间直方图代替SOAMST建立目标模型中的颜色直方图，二阶直方图融合了目标颜色信息和颜色的空间分布信息，比传统颜色直方图更具有目标鉴别能力。此外与MBLBP特征进行融合，构建有效的联合直方图建立目标模型。不同场景下的实验结果表明，与原算法比较，本文的改进算法在人脸颜色与背景相似，光照变化，旋转大小变化等复杂环境下，抗干扰性更强，有更好的跟踪效果，具有更高的准确性和鲁棒性。</p><p>关键词 :人脸跟踪，SOAMST，二阶空间直方图，MBLBP，颜色直方图</p><disp-formula id="hanspub.18724-formula38"><graphic xlink:href="http://html.hanspub.org/file/3-2670092x8_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s3"><title>1. 引言</title><p>人脸跟踪对计算机视觉、模式识别等领域的发展具有重大的促进作用，近年来，人脸跟踪技术在电视电话会议、远程教学、监控等场合都需要对人脸目标进行实时跟踪。目前已经提出了MeanShift算法 [<xref ref-type="bibr" rid="hanspub.18724-ref1">1</xref>] ，Camshift算法，粒子滤波 [<xref ref-type="bibr" rid="hanspub.18724-ref2">2</xref>] 等经典算法，怎样在目标与背景颜色相似，光照变化，遮挡等条件下快速准确跟踪人脸依旧是需要解决的难题。</p><p>SOAMST算法基于Mean Shift算法，能够解决跟踪过程中不能估计目标的尺寸和方向变化问题。同时此算法利用颜色直方图特征建立模型，人脸颜色区别于其他背景颜色存在一定范围区域内，因此适用于对人脸进行跟踪，但在复杂环境下仍然存在跟踪失败问题。</p><p>本文针对背景与目标颜色相似与视频光照变化问题，提出在SOAMST算法中将二阶直方图代替颜色直方图，同时结合MBLBP特征建立目标模型，在跟踪过程中自适应调节两种特征值的权重比例。以提高跟踪的准确性。</p></sec><sec id="s4"><title>2. SOAMST原理</title><p>SOAMST算法是Ning等 [<xref ref-type="bibr" rid="hanspub.18724-ref3">3</xref>] [<xref ref-type="bibr" rid="hanspub.18724-ref4">4</xref>] 在Mean Shift算法基础上提出的，针对目标尺度和方向变化问题，该算法结合权重的零阶矩和Bhattacharyya系数来估计目标尺度，并对权重图像的二阶矩进行奇异分解，最终得到跟踪目标的位置和具体大小。</p><sec id="s4_1"><title>2.1. 目标面积估计</title><p>通常在目标跟踪过程中连续帧之间目标的尺寸变化是连续光滑的过程，可令当前一帧候选目标的尺寸比上一帧稍微大一点；考虑到目标尺寸变化一般是连续光滑的，所以当前帧目标区域不管是变大或者变小都会在大的跟踪结果候选区域内。</p><p>如图1所示，以三种灰度组成矩形代表目标(a)，在一个大于目标尺寸的候选目标区域(b)内分别存在</p><p>图1. 目标区域估计</p><p>着小于(图c)、等于(d图)和大于(图e)真实目标尺寸的目标,并根据Mean Shift算法计算出这三个候选目标中三种灰度颜色的权重。</p><p>候选区域的像素权重代表着成为目标的可能性，因此，使用所有像素权重之和代表权重的零阶矩，来估计候选目标的真实面积，定义如下：</p><disp-formula id="hanspub.18724-formula39"><label>(1)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/3-2670092x10_hanspub.png"  xlink:type="simple"/></disp-formula><p>式中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670092x11_hanspub.png" xlink:type="simple"/></inline-formula>表示候选目标点的个数，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670092x12_hanspub.png" xlink:type="simple"/></inline-formula>为每个点的权重。</p><p>在最后的跟踪结果中，目标由两部分组成，真实目标和被错误判断为目标区域的背景部分。候选区域一般都大于真实目标尺寸，所以在候选模型中计算出来属于目标部分的概率密度将小于真实目标模型中的概率密度，因此由权重图像计算出的零阶矩<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670092x13_hanspub.png" xlink:type="simple"/></inline-formula>的面积也将大于真实目标面积，因此需要提高目标权重减少背景部分，以提高<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670092x14_hanspub.png" xlink:type="simple"/></inline-formula>估计目标面积的可靠性。此外，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670092x15_hanspub.png" xlink:type="simple"/></inline-formula>估计目标面积与真实面积差距越小，则候选模型和目标模型之间的相似度即Bhattacharyya系数越大，因此估计目标面积和具有反比例关系。估计目标实际面积可通过定义下式得到</p><disp-formula id="hanspub.18724-formula40"><label>(2)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/3-2670092x16_hanspub.png"  xlink:type="simple"/></disp-formula><p>式中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670092x17_hanspub.png" xlink:type="simple"/></inline-formula>(<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670092x18_hanspub.png" xlink:type="simple"/></inline-formula>)是关于Bhattacharyya系数s的单调递增函数。当相似度很高时<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670092x19_hanspub.png" xlink:type="simple"/></inline-formula>接近1，此时，权重的零阶矩便能准确的估计实际目标面积。</p></sec><sec id="s4_2"><title>2.2. 目标尺寸和方向估计</title><p>估计出目标区域后，由矩特征通过对权值图像进行分析可以得到目标的尺寸和方向，基于权值图像可以得到下列矩特征：</p><disp-formula id="hanspub.18724-formula41"><label>(3)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/3-2670092x20_hanspub.png"  xlink:type="simple"/></disp-formula><disp-formula id="hanspub.18724-formula42"><label>(4)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/3-2670092x21_hanspub.png"  xlink:type="simple"/></disp-formula><p>式中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670092x22_hanspub.png" xlink:type="simple"/></inline-formula>是候选区域中点的坐标。</p><p>由式(3)、(4)可以得到实际上是一阶矩和零阶矩的比值。</p><disp-formula id="hanspub.18724-formula43"><label>(5)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/3-2670092x23_hanspub.png"  xlink:type="simple"/></disp-formula><p>式中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670092x24_hanspub.png" xlink:type="simple"/></inline-formula>表示候选目标区域的质心。</p><p>由于要求出目标的尺寸和方向，所以需要将二阶矩转换为二阶中心距。</p><disp-formula id="hanspub.18724-formula44"><label>(6)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/3-2670092x25_hanspub.png"  xlink:type="simple"/></disp-formula><p>式(6)写成协方差矩阵的形式，便于对该矩阵进行奇异分解从而估计目标的尺寸和方向。</p><disp-formula id="hanspub.18724-formula45"><label>(7)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/3-2670092x26_hanspub.png"  xlink:type="simple"/></disp-formula><disp-formula id="hanspub.18724-formula46"><label>(8)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/3-2670092x27_hanspub.png"  xlink:type="simple"/></disp-formula><p>式中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670092x28_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670092x29_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670092x30_hanspub.png" xlink:type="simple"/></inline-formula>是<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670092x31_hanspub.png" xlink:type="simple"/></inline-formula>的特征值。矩阵U的第一列和第二列分别表示目标的</p><p>坐标轴方向。假设目标区域用椭圆表示，长半轴和短半轴的长度分别用a，b表示，那么<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670092x32_hanspub.png" xlink:type="simple"/></inline-formula>，根据已经估计的面积A，得到如下公式：</p><disp-formula id="hanspub.18724-formula47"><label>(9)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/3-2670092x33_hanspub.png"  xlink:type="simple"/></disp-formula><p>所以</p><disp-formula id="hanspub.18724-formula48"><label>(10)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/3-2670092x34_hanspub.png"  xlink:type="simple"/></disp-formula><p>将真实目标区域的长半轴和短半轴替换到原来的协方差分解后的奇异矩阵中，便得到真实目标宽度、高度和方向向量的协方差矩阵，如下式。</p><disp-formula id="hanspub.18724-formula49"><label>(11)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/3-2670092x35_hanspub.png"  xlink:type="simple"/></disp-formula></sec></sec><sec id="s5"><title>3. 对SOAMST算法的改进</title><p>SOAMST跟踪算法在开始前首先需要对跟踪目标进行建模。针对跟踪过程中由于颜色模型在背景和人脸颜色相似和视频光照变化时无法准确计算权值图像，导致目标跟踪不准确问题。本文提出使用二阶直方图和MBLBP特征两种模型对人脸目标进行建模。MBLBP特征是对目标纹理的描述，特征值的计算不受光照和颜色的影响。二阶直方图在包含颜色信息的前提下包含了像素的均值和协方差，抗干扰性更强，受光照影响低。所以二阶直方图和MBLBP特征结合能够解决该问题。</p><sec id="s5_1"><title>3.1. 二阶直方图</title><p>设二阶直方图 [<xref ref-type="bibr" rid="hanspub.18724-ref5">5</xref>] [<xref ref-type="bibr" rid="hanspub.18724-ref6">6</xref>] 分布即目标模型为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670092x36_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670092x37_hanspub.png" xlink:type="simple"/></inline-formula>，其中，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670092x38_hanspub.png" xlink:type="simple"/></inline-formula>为每个区间的概率，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670092x39_hanspub.png" xlink:type="simple"/></inline-formula>是均值向量，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670092x40_hanspub.png" xlink:type="simple"/></inline-formula>为协方差矩阵。B为直方图横坐标空间，在灰度图像中B = 256。当忽略<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670092x41_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670092x42_hanspub.png" xlink:type="simple"/></inline-formula>时，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670092x43_hanspub.png" xlink:type="simple"/></inline-formula>就是零阶直方图，即颜色直方图，两个直方图采用的是加权相似度。</p><disp-formula id="hanspub.18724-formula50"><label>(12)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/3-2670092x44_hanspub.png"  xlink:type="simple"/></disp-formula><p>图2形象地说明了颜色直方图和二阶直方图两者的相似和区别之处。</p><p>图2. 颜色直方图和二阶空间直方图</p><p>针对权值<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670092x46_hanspub.png" xlink:type="simple"/></inline-formula>，假设图像成正态分布，用高斯函数来描述权值<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670092x47_hanspub.png" xlink:type="simple"/></inline-formula>。</p><disp-formula id="hanspub.18724-formula51"><label>(13)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/3-2670092x48_hanspub.png"  xlink:type="simple"/></disp-formula><p>式中，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670092x49_hanspub.png" xlink:type="simple"/></inline-formula>为高斯常数，而<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670092x50_hanspub.png" xlink:type="simple"/></inline-formula>；<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670092x51_hanspub.png" xlink:type="simple"/></inline-formula>就是到的Mahalannobis距离平均值。仍然用Bhattacharyya相似度描述两颜色直方图的相似度。得到如下式子：</p><disp-formula id="hanspub.18724-formula52"><label>(14)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/3-2670092x52_hanspub.png"  xlink:type="simple"/></disp-formula><p>因此，目标和候选目标模型之间的二阶空间直方图相似度可以进一步表示为</p><disp-formula id="hanspub.18724-formula53"><label>(15)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/3-2670092x53_hanspub.png"  xlink:type="simple"/></disp-formula><p>至此，由基于二阶直方图的均值漂移向量可以得到目标的跟踪点：</p><disp-formula id="hanspub.18724-formula54"><label>(16)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/3-2670092x54_hanspub.png"  xlink:type="simple"/></disp-formula><p>式中，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670092x55_hanspub.png" xlink:type="simple"/></inline-formula>。</p></sec><sec id="s5_2"><title>3.2. MBLBP特征</title><p>纹理特征是图像中由于灰度和颜色的不同而表现出的一种特征，与其他特征相比，不仅包含了灰度信息的空间特性，其特征值的计算不受光照和颜色的影响。</p><p>MBLBP特征值是在LBP [<xref ref-type="bibr" rid="hanspub.18724-ref7">7</xref>] [<xref ref-type="bibr" rid="hanspub.18724-ref8">8</xref>] 的基础上通过中心区域矩形内像素的平均值<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670092x56_hanspub.png" xlink:type="simple"/></inline-formula>和该矩形区域的八邻域矩形<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670092x57_hanspub.png" xlink:type="simple"/></inline-formula>进行比较，如果八邻域矩形平均值大于中心区域像素点平均值标记为1，反之标记为0，将八个邻域标记按照从左上角顺时针方向进行组合得到MBLBP二进制编码值。计算公式如下：</p><disp-formula id="hanspub.18724-formula55"><label>(17)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/3-2670092x58_hanspub.png"  xlink:type="simple"/></disp-formula><disp-formula id="hanspub.18724-formula56"><label>(18)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/3-2670092x59_hanspub.png"  xlink:type="simple"/></disp-formula><p>式(17)中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670092x60_hanspub.png" xlink:type="simple"/></inline-formula>是中心矩形内像素点的平均值，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670092x61_hanspub.png" xlink:type="simple"/></inline-formula>是中心矩形的八邻域方向每个矩形的均值。</p><p>MBLBP图像纹理特征 [<xref ref-type="bibr" rid="hanspub.18724-ref9">9</xref>] 的计算过程如下图3所示。</p><p>统计MBLBP特征直方图的方法和颜色直方图基本相同，最后进行归一化后便得到人脸的MBLBP特征直方图。</p></sec><sec id="s5_3"><title>3.3. 基于颜色空间纹理融合特征的SOAMST算法</title><p>我们利用包含颜色和空间信息的二阶空间直方图与提取的MBLBP特征代替SOAMST原算法的颜色直方图 [<xref ref-type="bibr" rid="hanspub.18724-ref10">10</xref>] 来建立目标模型，解决目标颜色与背景相似，光照，尺度变化等复杂环境问题。</p><p>在跟踪过程中，多特征融合时如果采用固定的权值计算，当空间颜色纹理各特征发生明显变化时，特征融合进行建模得到的目标模型是不准确的。为此，我们分别计算各特征的概率密度函数得到各特征直方图所占权重 [<xref ref-type="bibr" rid="hanspub.18724-ref11">11</xref>] 。如下式定义：</p><disp-formula id="hanspub.18724-formula57"><label>(19)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/3-2670092x62_hanspub.png"  xlink:type="simple"/></disp-formula><p><inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670092x63_hanspub.png" xlink:type="simple"/></inline-formula>表示某一特征的归一化直方图，根据特征概率密度函数建立概率分布图，在各特征直方图的概率分布图中，分别计算目标与背景的Bhattacharyya系数，设为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670092x64_hanspub.png" xlink:type="simple"/></inline-formula>。</p><p>最后，计算各特征对应权重为：</p><disp-formula id="hanspub.18724-formula58"><label>(20)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/3-2670092x65_hanspub.png"  xlink:type="simple"/></disp-formula></sec></sec><sec id="s6"><title>4. 实验结果分析</title><p>使用多组视频对本文改进算法进行试验。试验中包括了目标与背景颜色相似，光照变化，遮挡，以及人脸尺度和方向变化复杂情况，跟踪效果如下图4~6所示。</p><p>对比图4~6实验结果可以发现当目标颜色和背景颜色基本相似时，图像的概率密度梯度基本不再变化，基于颜色模型的原SOAMST算法也就不再收敛，认为当前位置就是最佳目标位置，但是实际情况是，背景颜色和目标颜色相似的原因。</p><p>同时在光照变化情况下，颜色模型的SOAMST算法在跟踪过程中开始阶段能够准确跟踪，但是当光线逐渐变化时，人脸跟踪不再准确。因为光线变化后人脸颜色信息发生变化，颜色模型不能够得到准确的相似信息，所以跟踪效果不好。</p><p>图3. MBLBP计算过程</p><p>图4. 算法比较(1)</p><p>图5. 算法比较(2)</p><p>图6. 算法比较(3)</p><p>而本文算法将颜色空间信息即二阶空间直方图和纹理信息即MBLBP特征结合起来对目标进行建模。当颜色信息相似度低时，也就是颜色信息不再可靠时，空间信息和MBLBP纹理特征会对颜色信息起到补偿作用。所以本文算法在复杂条件下比原算法具有更好的跟踪效果。</p></sec><sec id="s7"><title>5. 总结</title><p>本文以SOAMST算法为基础，针对人脸跟踪过程中背景和人脸肤色相似、光照变化问题；提出了将二阶空间直方图结合MBLBP特征直方图代替SOAMST的颜色直方图建立目标模型，同时在颜色信息基础上增加空间和人脸纹理特征信息 [<xref ref-type="bibr" rid="hanspub.18724-ref12">12</xref>] ，使得当人脸和背景颜色相似和光照变化等复杂条件下也有很好的区分度。实验结果显示本文算法相比原算法有更好的跟踪效果，更好的鲁棒性和准确性。</p></sec><sec id="s8"><title>文章引用</title><p>周真真,冯子亮. 基于颜色空间纹理融合特征的SOAMST人脸跟踪算法SOAMST Face Tracking Algorithm Based on the Combined Feature of Color Space and Texture[J]. 图像与信号处理, 2016, 05(04): 166-173. http://dx.doi.org/10.12677/JISP.2016.54019</p></sec><sec id="s9"><title>参考文献 (References)</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.18724-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Comaniciu, D., Ramesh, V. and Meer, P. (2000) Real-Time Tracking of Using Nonrigid Objects Using Mean Shift. IEEE Conference on Computer Vision and Pattern Recognition, 15-15 June 2000, 2142.</mixed-citation></ref><ref id="hanspub.18724-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Gordon, N., Salmond, D. and Smith, A. (2002) Novel Approach to Nonlinear and Non-Gaussian Bayesian State Estimation. IEE Proceedings F, 140, 107-113.</mixed-citation></ref><ref id="hanspub.18724-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Ning, J., Zhang, L., Zhang, D., et al. (2012) Scale and Orientation Adaptive Mean Shift Tracking. IET Computer Vision, 6, 52-61. http://dx.doi.org/10.1049/iet-cvi.2010.0112</mixed-citation></ref><ref id="hanspub.18724-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">侯建华, 黄奇, 郑桂林, 等. 一种尺度和方向适应性的Mean Shift跟踪算法[J]. 中南民族大学学报(自然科学版), 2015, 34(1): 83-88.</mixed-citation></ref><ref id="hanspub.18724-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">朱志宇. 粒子滤波算法及其应用[M]. 北京: 科学出版社, 2010: 194-195.</mixed-citation></ref><ref id="hanspub.18724-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Birchfield, S. and Rangarajan, S. (2005) Spatiograms versus Histograms for Region-Based Tracking. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, San Diego, 20-25 June 2005, 1158-1163. 
http://dx.doi.org/10.1109/cvpr.2005.330</mixed-citation></ref><ref id="hanspub.18724-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Ojala, T., Pietikäinen, M. and Harwood, D. (1994) Performance Evaluation of Texture Measures with Classification Based on Kullback Discrimination of Distributions. Proceedings of the 12th IAPR International Conference on Pattern Recognition (ICPR 1994), 1, 582-585. http://dx.doi.org/10.1109/ICPR.1994.576366</mixed-citation></ref><ref id="hanspub.18724-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Ojala, T., Pietikäinen, M. and Harwood, D. (1976) A Comparative Study of Texture Measures with Classification Based on Feature Distributions. Pattern Recognition, 29, 51-59. http://dx.doi.org/10.1016/0031-3203(95)00067-4</mixed-citation></ref><ref id="hanspub.18724-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Liao, S.C., Zhu, X.X., Lei, Z., Zhang, L. and Li, S.Z. (2007) Learning Multi-Scale Block Local Binary Patterns for Face Recognition. International Conference on Biometrics (ICB), 828-837.  
http://dx.doi.org/10.1007/978-3-540-74549-5_87</mixed-citation></ref><ref id="hanspub.18724-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">刘明宝, 姚鸿勋, 高文. 彩色图像的实时人脸跟踪方法[J]. 计算机学报, 1998, 21(6): 527-532.</mixed-citation></ref><ref id="hanspub.18724-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">李菊, 余烨. 基于颜色和LBP多特征的mean shift的跟踪算法[J]. 合肥工业大学学报(自然科学版), 2014, 5(37): 578-581.</mixed-citation></ref><ref id="hanspub.18724-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">王保云, 范保杰. 基于颜色纹理联合特征直方图的自适应Meanshift跟踪算法[J]. 南京邮电大学学报(自然科学版), 2013(3): 18-25.</mixed-citation></ref></ref-list></back></article>