<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">JISP</journal-id><journal-title-group><journal-title>Journal of Image and Signal Processing</journal-title></journal-title-group><issn pub-type="epub">2325-6753</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/JISP.2021.102009</article-id><article-id pub-id-type="publisher-id">JISP-41853</article-id><article-categories><subj-group subj-group-type="heading"><subject>JISP20210200000_70772760.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  一种基于生成对抗网络的无人机图像去雾算法
  UAV Image Dehazing Algorithm Based on Generative Adversarial Network
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>庄</surname><given-names>子尤</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>徐</surname><given-names>成华</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff3"><sup>3</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>魏</surname><given-names>育成</given-names></name><xref ref-type="aff" rid="aff4"><sup>4</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>蔡</surname><given-names>刚</given-names></name><xref ref-type="aff" rid="aff5"><sup>5</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff5"><addr-line>中国科学院空天信息创新研究院，北京</addr-line></aff><aff id="aff2"><addr-line>中国科学院空天信息创新研究院，北京；中国科学院大学，北京</addr-line></aff><aff id="aff4"><addr-line>中科九度(北京)空间信息技术有限责任公司，北京；北京市数字城市工程技术研究中心，北京</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><aff id="aff3"><addr-line>中国科学院空天信息创新研究院，北京；中科九度(北京)空间信息技术有限责任公司，北京</addr-line></aff><pub-date pub-type="epub"><day>06</day><month>04</month><year>2021</year></pub-date><volume>10</volume><issue>02</issue><fpage>80</fpage><lpage>87</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
  
    无人机所采集的图像容易受到雾霾、雾气等阴霾天气干扰，造成图像质量下降。针对阴霾天气下无人机采集图像的质量下降问题，提出了一种新颖的基于生成对抗网络的图像去雾方法。本方法设计了新式生成网络和判别网络，生成网络由多层编码器和解码器对称分布构成，判别网络由全卷积网络构成，为了提高生成图像的清晰度，引入了一种新的对抗和平滑损失函数来优化整个网络。最后，通过大量实验表明，基于本文方法进行图像去雾取得了良好的效果，在结构相似度和峰值信噪比等评价指标以及主观视觉效果上优于已有的图像去雾方法。
    The image collected by UAV is easy to be disturbed by fog, which leads to the degradation of image quality. Aiming at the image degradation of UAV in foggy scenes, a novel image defogging method based on generative adversarial network is proposed. Anew generator and discriminator are designed. The generating network consists of multi-layer encoder and decoder; then the discriminator network consists of fully convolutional network. In order to improve the clarity of the generated image, a new loss function is introduced to optimize the whole network, including adversarial loss and smooth loss. Through training and testing, it can be concluded that the image defogging method based on generative adversarial networks has achieved good results, and it is better than traditional methods in structural similarity index measurement (SSIM) and peak signal to noise ratio (PSNR). 
  
 
</p></abstract><kwd-group><kwd>无人机，图像去雾，深度学习，生成对抗网络, UAV</kwd><kwd> Image Defogging</kwd><kwd> Deep Learning</kwd><kwd> Generative Adversarial Networks</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>摘要</title><p>无人机所采集的图像容易受到雾霾、雾气等阴霾天气干扰，造成图像质量下降。针对阴霾天气下无人机采集图像的质量下降问题，提出了一种新颖的基于生成对抗网络的图像去雾方法。本方法设计了新式生成网络和判别网络，生成网络由多层编码器和解码器对称分布构成，判别网络由全卷积网络构成，为了提高生成图像的清晰度，引入了一种新的对抗和平滑损失函数来优化整个网络。最后，通过大量实验表明，基于本文方法进行图像去雾取得了良好的效果，在结构相似度和峰值信噪比等评价指标以及主观视觉效果上优于已有的图像去雾方法。</p></sec><sec id="s2"><title>关键词</title><p>无人机，图像去雾，深度学习，生成对抗网络</p></sec><sec id="s3"><title>UAV Image Dehazing Algorithm Based on Generative Adversarial Network</title><p>Ziyou Zhuang<sup>1,2</sup>, Chenghua Xu<sup>1,3</sup>, Yucheng Wei<sup>3,4</sup>, Gang Cai<sup>1</sup></p><p><sup>1</sup>Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing</p><p><sup>2</sup>University of Chinese Academy of Sciences, Beijing</p><p><sup>3</sup>GeoDo(Beijing) Spatial Information Technology Co. Ltd., Beijing</p><p><sup>4</sup>Beijing Engineering Research Center of Digital City, Beijing</p><p><img src="//html.hanspub.org/file/4-2670255x4_hanspub.png" /></p><p>Received: Mar. 29<sup>th</sup>, 2021; accepted: Apr. 19<sup>th</sup>, 2021; published: Apr. 26<sup>th</sup>, 2021</p><p><img src="//html.hanspub.org/file/4-2670255x5_hanspub.png" /></p></sec><sec id="s4"><title>ABSTRACT</title><p>The image collected by UAV is easy to be disturbed by fog, which leads to the degradation of image quality. Aiming at the image degradation of UAV in foggy scenes, a novel image defogging method based on generative adversarial network is proposed. Anew generator and discriminator are designed. The generating network consists of multi-layer encoder and decoder; then the discriminator network consists of fully convolutional network. In order to improve the clarity of the generated image, a new loss function is introduced to optimize the whole network, including adversarial loss and smooth loss. Through training and testing, it can be concluded that the image defogging method based on generative adversarial networks has achieved good results, and it is better than traditional methods in structural similarity index measurement (SSIM) and peak signal to noise ratio (PSNR).</p><p>Keywords:UAV, Image Defogging, Deep Learning, Generative Adversarial Networks</p><disp-formula id="hanspub.41853-formula31"><graphic xlink:href="//html.hanspub.org/file/4-2670255x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2021 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/4-2670255x7_hanspub.png" /> <img src="//html.hanspub.org/file/4-2670255x8_hanspub.png" /></p></sec><sec id="s5"><title>1. 引言</title><p>随着人类社会的不断发展与科技的不断进步，人们已经进入了信息时代。无人机作为这个时代信息获取的独特载体，凭借自身优势，在航拍、农业、救灾防灾、野生动物观测、测绘、电力巡线、电影电视、新闻报道等领域都有很大的应用 [<xref ref-type="bibr" rid="hanspub.41853-ref1">1</xref>]。</p><p>但随着人类文明的不断发展和工业化进程，出现雾霾天气的概率大幅增加，无人机飞行作业时所搭载的载荷在采集图像时往往都会受到不同程度的雾气的干扰。空气中存在着一些小水珠和灰尘等小颗粒物，当这些颗粒物数量增多到一定程度时，就会对光线的传播造成影响，会吸收并散射一部分光线，肉眼可见时便形成了雾霾天气。这种对光线的吸收和散射作用，会使得无人机所搭载的载荷采集的图像成像质量变差，具体表现为清晰度下降、对比度和饱和度降低、动态范围变小、细节信息丢失等问题，导致视觉效果差，后续难以有效提取和分析图像细节信息，不能满足应用需求，图1为大气光衰减示意图。</p><p>图1. 大气光衰减示意图</p><p>为了降低雾霾对图像采集工作的影响，提高无人机所搭载载荷采集的图像的清晰度，加强其实用性和有效性，因此图像去雾是亟待解决的问题，同时也能保障无人机飞行作业系统能够在较差的天气条件下的正常运行。</p><p>随着图像处理领域的不断发展，各种图像去雾算法被学者相继提出，卢汉明等人 [<xref ref-type="bibr" rid="hanspub.41853-ref2">2</xref>] 提出将小波变换法与中值滤波法和直方图匹配法结合起来进行去雾；朱锡芳等人 [<xref ref-type="bibr" rid="hanspub.41853-ref3">3</xref>] 提出按照带雾图像的熵来决定不同频段处理的参量来去雾；Fattal等人 [<xref ref-type="bibr" rid="hanspub.41853-ref4">4</xref>] 提出了透射率与物体颜色局部不相关的假设，并利用马尔科夫模型计算颜色信息，从而达到去雾的效果；Tan等人 [<xref ref-type="bibr" rid="hanspub.41853-ref5">5</xref>] 研究后发现，无雾的图像比带雾图像相比普遍具有更高的对比度，可以通过提高图像的对比度进行去雾，并提出了最大化图片局部对比度的方法；He等人 [<xref ref-type="bibr" rid="hanspub.41853-ref6">6</xref>] 提出了基于暗通道先验理论对图像进行去雾。</p><p>近年来，深度学习发展迅猛，由于其可以自动提取特征，在各个研究领域发挥着越来越重要的作用，在计算机视觉领域也取得了很大的进展，受到了大家的广泛关注和讨论。越来越多的研究者开始利用深度学习的方法取代传统方法来解决图像去雾的问题。Cai等人 [<xref ref-type="bibr" rid="hanspub.41853-ref7">7</xref>] 提出了一种端到端的去雾网络DehazeNet，设计了一个三层卷积神经网络用于带雾图像透射率图的估计，融合了传统去雾方法和深度学习去雾方法；Tang等人 [<xref ref-type="bibr" rid="hanspub.41853-ref8">8</xref>] 将带雾图像的先验条件作为输入，提出了一个随机森林模型用于带雾图像透射率图的估计；Ren等人 [<xref ref-type="bibr" rid="hanspub.41853-ref9">9</xref>] 设计了一种多层级卷积神经网络，将细粒度估计和粗粒度估计相结合，可得到更加精细的透射率图；Li等人 [<xref ref-type="bibr" rid="hanspub.41853-ref10">10</xref>] 提出了AOD-Net，通过数学方法将大气光和透射率的估计合成为了一个变量，避免了额外估计大气光的操作。</p><p>综上所述，目前的各种图像处理方法都存在一定的不足，基于图像增强的直方图均衡化相关算法容易丢失图像的细节信息，基于先验信息的算法处理图片后常常产生光晕和过饱和现象，暗通道算法存在透射率估计不精确和颜色退化等问题，已有的神经网络算法一部分需要依赖已有的物理模型或先验假设，另一部分处理效果不够理想。因此，本文提出了一种新颖的基于生成对抗网络的无人机图像去雾算法。</p></sec><sec id="s6"><title>2. 网络模型设计</title><p>图像去雾的目的是在不损失图像基本细节信息的条件下，尽量多地处理掉目标图像的雾气信息 [<xref ref-type="bibr" rid="hanspub.41853-ref11">11</xref>]。使用传统方法进行图像去雾在去雾效果上有一定的局限性，但大多数方法都不会破坏图像的基本细节信息，不容易出现严重的图像失真。但对于基于深度学习的图像去雾方法，网络的设计非常关键，一旦设计不当，处理后的图像会严重失真，后续调整参数也无法有效改善其处理效果。生成对抗网络最重要的三个关键方向就是生成网络、对抗网络和损失函数LOSS。</p><sec id="s6_1"><title>2.1. 生成网络</title><p>本文采用深度学习中生成对抗网络的方法，可以对带雾图像进行端到端的去雾，输入目标带雾图像经过处理后即可得到相应的去雾图像，在去雾过程中不需要估计额外的物理参数。如图2所示，生成网</p><p>图2. 生成网络结构</p><p>络的前半部分可以当成一个数据编码器，用来对原始图像的特征进行提取，在此部分，每一个密度块后边放置一个下采样层。生成网络的后半部分可以当成一个与前半部分编码器对应的解码器，在此部分，每一个密度块后边放置一个上采样层，对前半部分传递的图像特征进行上采样，可以把经下采样缩小的图像特征重新放大到图像的原始尺寸，以确保网络输出正确。每次上采样步骤完成后，通过卷积层进行学习，丰富信息，可以使在编码操作时丢失的图像特征信息在解码操作时能够部分找回。对解码器和对称编码器中的特征图采取融合处理操作，可以确保解码器的特征能够正常表达。</p></sec><sec id="s6_2"><title>2.2. 对抗网络</title><p>对抗网络的作用是可以对生成网络生成的图像和数据集原始不带雾图像进行对比判断，用来甄别生成网络生成无雾图像的好坏，同时也将参数逆传递，辅助生成网络生成质量更好的无雾图像。本文建立了一个五层的卷积神经网络，结构如图3所示，对生成的图像与无雾图像进行逐块比较，提高了判别的准确性。对抗网络的输出为一个[0, 1]之间的概率值，当生成网络生成的图像越接近真实无雾图像时，判别器的输出越靠近0；当生成的图像越靠近原始带雾图像时，判别器的输出越靠近1。</p><p>图3. 对抗网络结构</p></sec><sec id="s6_3"><title>2.3. 损失函数</title><p>对于深度学习图像去雾模型来说，生成网络生成的无雾图像与原始带雾图像之间有很多相似的图像信息，在训练过程中容易发生过拟合。为了确保网络生成无雾图像的清晰度以及与原带雾图像之间的相似性，不发生图像失真，总的损失函数Loss [<xref ref-type="bibr" rid="hanspub.41853-ref12">12</xref>] [<xref ref-type="bibr" rid="hanspub.41853-ref13">13</xref>] 由两部分组成，其中L<sub>1</sub>是对抗Loss，L<sub>2</sub>是平滑Loss，W分别代表权重。</p><p>L o s s = W 1 ⋅ L 1 + W 2 ⋅ L 2 (1)</p><p>对抗Loss的定义如下：</p><p>L 1 = E ( x , y ) [ log ( D ( x , y ) ) ] + E ( x , z ) [ log ( 1 − D ( x , G ( x , z ) ) ) ] (2)</p><p>平滑Loss的定义如下：</p><p>L 2 = E ( x , y , z ) [ ‖ y − G ( x , z ) ‖ 1 ] (3)</p><p>其中G为生成器，D为判别器，x为输入带雾的图像，y为x所对应的无雾图像，z为随机噪声。</p></sec></sec><sec id="s7"><title>3. 模型训练实验</title><sec id="s7_1"><title>3.1. 数据集与实验设置</title><p>本方法训练中所用的数据集采用D-HAZY DATASET。进行训练之前，先对数据集中的待训练数据进行预处理，为了确保训练时网络能正常进行梯度计算和更新，将图像统一分割调整为256 &#215; 256像素的图像，并做成对化处理，形成了1472对包含同一场景有雾和无雾图像的对比数据集。训练环境基于搭载了NVIDIA GTX1080 GPU计算机的Tensorflow上，训练过程中采用Adam优化，学习率设置为0.0001，benchsize设置为4，epoch设置为400。</p></sec><sec id="s7_2"><title>3.2. 实验流程</title><p>本方法流程如下：首先设计去雾所需的生成对抗网络模型，并建立训练网络模型所需要的数据集，进行整理和预处理；</p><p>将数据集中的带雾样本图像输入已设计的生成网络中，生成器对该样本图像进行去雾处理；</p><p>将生成网络去雾处理的样本图像和数据集中对应的无雾样本图像输入已设计的对抗网络中，判别器对两幅图像进行判别，设定阈值判断图像的真假，计算损失函数Loss等模型参数；</p><p>将参数反馈给生成网络，生成网络调整参数，并更新生成网络模型；</p><p>重复上述步骤，直到训练完成，获得训练模型；</p><p>将需要去雾的带雾图片输入到该已训练完成的模型中，得到去雾后的无雾图片，图4为网络模型训练流程。</p><p>图4. 模型训练流程</p></sec></sec><sec id="s8"><title>4. 实验结果分析与评价</title><p>对于图像去雾效果好坏的评价，选取其他图像去雾算法与之比较是比较直观的办法，本文列举了几种典型场景下不同的图像去雾方法对图像进行去雾的效果，如图5所示。</p><p>图5. 多种去雾方法对比效果图</p><p>图像去雾方法的去雾效果需要有一定的评价指标，而评价一幅图像的质量有两种方法，按照评价者是否为人类，可以分为主观评价方法和客观评价方法 [<xref ref-type="bibr" rid="hanspub.41853-ref14">14</xref>] [<xref ref-type="bibr" rid="hanspub.41853-ref15">15</xref>]。本文选取图像的结构相似度(structural similarity index measurement, SSIM) [<xref ref-type="bibr" rid="hanspub.41853-ref16">16</xref>] 和峰值信噪比(peak signal to noise ratio, PSNR) [<xref ref-type="bibr" rid="hanspub.41853-ref17">17</xref>] 这两个指标进行计算，通过量化的结果对各图像去雾算法进行评价。</p><p>从主观上来看，在城市场景中，四种方法都能有效的去除雾气，但基于中值滤波方法和基于暗通道先验方法还有少量残余，DehazeNet方法亮度较低，基于生成对抗网络的去雾方法对比度较高，效果较好。</p><p>在交通场景中，四种去雾方法效果差距不大，都能较为清晰的还原铁路的细节和机车的轮廓。</p><p>在农田场景中，中值滤波方法偏离原图的色彩较大，色彩失真，而且雾气没有去除干净，效果不理想；基于暗通道先验的方法，主体部分效果不错，但是在远处高光部分有色斑，细节丢失，DehazeNet方法去雾不彻底，这个场景中基于生成对抗网络的去雾方法效果更好。</p><p>在森林场景中，中值滤波方法依旧色偏较大，色彩失真，处理结果不甚理想，而基于暗通道先验的方法和基于生成对抗网络的去雾方法能清晰的看到树叶和树干的细节，效果令人满意，DehazeNet方法的效果稍逊一筹。同时可以看到，树林深处还是有没有处理干净的雾气，这说明当雾过于浓导致带雾图像上部分细节几乎完全丢失时，这些算法都无法很好的应对，因此，在后续的研究中，应当针对浓雾问题继续改进算法。</p><p>表1为多种去雾方法的客观评价结果，从上述客观评价指标可以看出，在大多数场景下，基于生成对抗网络的方法去雾后的图像不论是在结构相似度还是在峰值信噪比的得分都相对较高，证明图像显得更加明亮和生动，具有更清晰的边缘和细节信息，效果较好。这与主观评价中通过肉眼观察到的结论是一致的，相互得到了印证。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Objective evaluation result</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >客观评价指标</th><th align="center" valign="middle" >中值滤波方法</th><th align="center" valign="middle" >暗通道先验方法</th><th align="center" valign="middle" >DehazeNet</th><th align="center" valign="middle" >本文方法</th></tr></thead><tr><td align="center" valign="middle" >SSIM</td><td align="center" valign="middle" >0.674</td><td align="center" valign="middle" >0.758</td><td align="center" valign="middle" >0.763</td><td align="center" valign="middle" >0.776</td></tr><tr><td align="center" valign="middle" >PSNR</td><td align="center" valign="middle" >15.07</td><td align="center" valign="middle" >17.07</td><td align="center" valign="middle" >17.31</td><td align="center" valign="middle" >18.06</td></tr></tbody></table></table-wrap><p>表1. 客观评价结果</p></sec><sec id="s9"><title>5. 结语</title><p>深度学习方法为很多图像处理问题打开了新的天地，本文构建了新的生成器和判别器，提出了构建一个生成对抗网络GAN来对图像进行去雾的方法，在典型场景中与其他其他去雾方法进行对比，无论主观评价指标还是客观评价指标都表现出了较好的效果，本文算法得到的去雾图像具有更清晰的边缘和细节信息，在部分场景生成的去雾图像更接近无雾图像，结构相似度与峰值信噪比的得分更高，具有较好的图像质量，体现了神经网络的优势。但在分析中可以看到，本方法对特别浓厚的雾的去除效果不太好，而其他对比的方法也无法去除浓雾，因此浓雾的去除是未来值得研究的一个方向。</p></sec><sec id="s10"><title>基金项目</title><p>“科技助力经济2020”重点专项(高分时空信息承载平台在园区管理和服务中的推广应用)、国家重点研发计划资助(No. 2017YFF0107700)。</p></sec><sec id="s11"><title>文章引用</title><p>庄子尤,徐成华,魏育成,蔡 刚. 一种基于生成对抗网络的无人机图像去雾算法UAV Image Dehazing Algorithm Based on Generative Adversarial Network[J]. 图像与信号处理, 2021, 10(02): 80-87. https://doi.org/10.12677/JISP.2021.102009</p></sec><sec id="s12"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.41853-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">钟伟雄, 韦凤, 邹仁, 等. 无人机概论[M]. 北京: 清华大学出版社, 2019.</mixed-citation></ref><ref id="hanspub.41853-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">卢汉明. 基于融合技术的遥感影像质量改善与修补[D]: [硕士学位论文]. 西安: 西安电子科技大学, 2010.</mixed-citation></ref><ref id="hanspub.41853-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">朱锡芳, 吴峰, 陶纯堪. 基于小波阈值理论的光学图像去云处理新算法[J]. 光子学报, 2009, 38(12): 3312-3317.</mixed-citation></ref><ref id="hanspub.41853-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Fattal, R. (2008) Single Image Dehazing. ACM Transactions on Graphics, 27, 721-729.  
https://doi.org/10.1145/1360612.1360671</mixed-citation></ref><ref id="hanspub.41853-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Tan, R. (2008) Visibility in Bad Weather from a Single Image. IEEE Conference on Vision and Pattern Recognition, Anchorage, 23-28 June 2008, 1-8. https://doi.org/10.1109/CVPR.2008.4587643</mixed-citation></ref><ref id="hanspub.41853-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">He, K.M., Sun, J. and Tang, X.O. (2013) Guided Image Filtering. IEEE Transactions on Pattern Analysis and Machine Intelligence, 35, 1397-1409. https://doi.org/10.1109/TPAMI.2012.213</mixed-citation></ref><ref id="hanspub.41853-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Cai, B., Xu, X., Jia, K., et al. (2016) Dehaze-Net: An End-to-End System for Single Image Haze Removal. IEEE Transactions on Image Processing, 25, 5187-5198. https://doi.org/10.1109/TIP.2016.2598681</mixed-citation></ref><ref id="hanspub.41853-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Tang, K., Yang, J. and Wang, J. (2014) Investigating Haze-Relevant Features in a Learning Framework for Image Dehazing. IEEE Conference on Computer Vision and Pattern Recognition, Columbus, 23-28 June 2014, 2995-3002.  
https://doi.org/10.1109/CVPR.2014.383</mixed-citation></ref><ref id="hanspub.41853-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Ren, W., Liu, S., Zhang, H., et al. (2016) Single Image Dehazing via Multi-Scale Convolutional Neural Net-Works. In: Leibe, B., Matas, J., Sebe, N. and Welling, M., Eds., European Conference on Computer Vision, Springer, Cham, 154-169. https://doi.org/10.1007/978-3-319-46475-6_10</mixed-citation></ref><ref id="hanspub.41853-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Li, B.Y., Peng, X.L., Wang, Z.Y., et al. (2017) AOD-Net: All-in-One Dehazing Network. Proceedings of IEEE International Conference on Computer Vision (ICCV), Venice, 22-29 October 2017, 4780-4788.  
https://doi.org/10.1109/ICCV.2017.511</mixed-citation></ref><ref id="hanspub.41853-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">吴迪, 朱青松. 图像去雾的最新研究进展[J]. 自动化学报, 2015, 41(2): 221-239.</mixed-citation></ref><ref id="hanspub.41853-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Gatys, L., Ecker, A. and Bethge, M. (2016) A Neural Algorithm of Artistic Style. Journal of Vision, 16, 326.  
https://doi.org/10.1167/16.12.326</mixed-citation></ref><ref id="hanspub.41853-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Johnson, J., Alahi, A. and Li, F.F. (2016) Perceptual Losses for Real-Time Style Transfer and Super-Resolution. In: Leibe, B., Matas, J., Sebe, N. and Welling, M., Eds., European Conference on Computer Vision, Springer, Cham, 694-711. https://doi.org/10.1007/978-3-319-46475-6_43</mixed-citation></ref><ref id="hanspub.41853-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">Stępień, I., Obuchowicz, R., Piórkowski, A. and Oszust, M. (2021) Fusion of Deep Convolutional Neural Networks for No-Reference Magnetic Resonance Image Quality Assessment. Sensors, 21, 1043. https://doi.org/10.3390/s21041043</mixed-citation></ref><ref id="hanspub.41853-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">Hautilere, N., Tarel, J.-P., Aubert, D. and Dumont, E. (2011) Blind Contrast Enhancement Assessment by Gradient Ratioing at Visible Edges. Image Analysis &amp; Stereology Journal, 27, 87-95. https://doi.org/10.5566/ias.v27.p87-95</mixed-citation></ref><ref id="hanspub.41853-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">Setiadi, D. (2020) PSNR vs SSIM: Imperceptibility Quality Assessment for Image Steganography. Multimedia Tools and Applications, 80, 8423-8444. https://doi.org/10.1007/s11042-020-10035-z</mixed-citation></ref><ref id="hanspub.41853-ref17"><label>17</label><mixed-citation publication-type="other" xlink:type="simple">Hodges, C., Bennamoun, M. and Rahmani, H. (2019) Single Image Dehazing Using Deep Neural Networks. Pattern Recognition Letters, 128, 70-77. https://doi.org/10.1016/j.patrec.2019.08.013</mixed-citation></ref></ref-list></back></article>