<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">JAST</journal-id><journal-title-group><journal-title>Journal of Aerospace Science and Technology</journal-title></journal-title-group><issn pub-type="epub">2330-474X</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/JAST.2021.91003</article-id><article-id pub-id-type="publisher-id">JAST-41244</article-id><article-categories><subj-group subj-group-type="heading"><subject>JAST20210100000_90863970.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject><subject> 工程技术</subject></subj-group></article-categories><title-group><article-title>
 
 
  视觉导航在扑翼飞行器避障中的应用
  Visual Navigation for Obstacle Avoidance of Flapping Wing Micro-Air Vehicles
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>候</surname><given-names>慧敏</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>印</surname><given-names>明威</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>危</surname><given-names>威</given-names></name><xref ref-type="aff" rid="aff4"><sup>4</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>王</surname><given-names>贤宇</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff4"><addr-line>北京清航紫荆装备科技有限公司，北京</addr-line></aff><aff id="aff3"><addr-line>清华大学航天航空学院，北京</addr-line></aff><aff id="aff2"><addr-line>长春理工大学光电信息科学与工程系，吉林 长春</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>03</day><month>03</month><year>2021</year></pub-date><volume>09</volume><issue>01</issue><fpage>22</fpage><lpage>29</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
  视觉传感器本身具有独立性、准确性和可靠性等优点，使得它在无人机视觉导航的应用领域中具有独特的作用，但是传统的视觉导航设备质量过大，无法应用在扑翼飞行器上。针对此问题，本项目利用FPGA芯片设计基于Census变换的局部立体匹配算法的立体视觉模块，该模块质量轻，并且能够进行图像的实时处理，满足避障场景的实时性要求。通过扑翼飞行器实际的飞行实验结果表明，本项目设计的视觉导航模块可以为无人机的自主避障飞行提供技术支持和决策依据。
   The visual sensor itself has the advantages of independence, accuracy and reliability, which makes it play a unique role in the application field of UAV visual navigation. However, the quality of traditional visual navigation equipment is too heavy to be applied in the bionic bird micro aircraft. In view of this problem, this project uses FPGA chip to design a stereo vision module based on Census transform local stereo matching algorithm. This module is light in weight and can carry out real-time image processing to meet the real-time requirements of obstacle avoidance scene. The actual flight experiment results of the Flapping Wing Micro-air Vehicles show that the visual navigation module designed in this project can provide technical support and decision-making basis for the autonomous obstacle avoidance flight of UAV.
 
</p></abstract><kwd-group><kwd>视觉导航，自主避障，FPGA，局部立体匹配算法, Visual Navigation</kwd><kwd> Automatic Obstacle Avoiding</kwd><kwd> FPGA</kwd><kwd> Local Stereo Matching Algorithm</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>摘要</title><p>视觉传感器本身具有独立性、准确性和可靠性等优点，使得它在无人机视觉导航的应用领域中具有独特的作用，但是传统的视觉导航设备质量过大，无法应用在扑翼飞行器上。针对此问题，本项目利用FPGA芯片设计基于Census变换的局部立体匹配算法的立体视觉模块，该模块质量轻，并且能够进行图像的实时处理，满足避障场景的实时性要求。通过扑翼飞行器实际的飞行实验结果表明，本项目设计的视觉导航模块可以为无人机的自主避障飞行提供技术支持和决策依据。</p></sec><sec id="s2"><title>关键词</title><p>视觉导航，自主避障，FPGA，局部立体匹配算法</p></sec><sec id="s3"><title>Visual Navigation for Obstacle Avoidance of Flapping Wing Micro-Air Vehicles</title><p>Huiming Hou<sup>1</sup>, Mingwei Yin<sup>2*</sup>, Wei Wei<sup>3</sup>, Xianyu Wang<sup>2</sup></p><p><sup>1</sup>Department of Optoelectronic Information Science and Engineering, Changchun University of Science and Technology, Changchun Jilin</p><p><sup>2</sup>Department of Aerospace Engineering, Tsinghua University, Beijing</p><p><sup>3</sup>TsingAero Armament Technology Co., Ltd., Beijing</p><p><img src="//html.hanspub.org/file/3-2980147x4_hanspub.png" /></p><p>Received: Feb. 5<sup>th</sup>, 2021; accepted: Mar. 15<sup>th</sup>, 2021; published: Mar. 29<sup>th</sup>, 2021</p><p><img src="//html.hanspub.org/file/3-2980147x6_hanspub.png" /></p></sec><sec id="s4"><title>ABSTRACT</title><p>The visual sensor itself has the advantages of independence, accuracy and reliability, which makes it play a unique role in the application field of UAV visual navigation. However, the quality of traditional visual navigation equipment is too heavy to be applied in the bionic bird micro aircraft. In view of this problem, this project uses FPGA chip to design a stereo vision module based on Census transform local stereo matching algorithm. This module is light in weight and can carry out real-time image processing to meet the real-time requirements of obstacle avoidance scene. The actual flight experiment results of the Flapping Wing Micro-air Vehicles show that the visual navigation module designed in this project can provide technical support and decision-making basis for the autonomous obstacle avoidance flight of UAV.</p><p>Keywords:Visual Navigation, Automatic Obstacle Avoiding, FPGA, Local Stereo Matching Algorithm</p><disp-formula id="hanspub.41244-formula19"><graphic xlink:href="//html.hanspub.org/file/3-2980147x7_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2021 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/3-2980147x8_hanspub.png" /> <img src="//html.hanspub.org/file/3-2980147x9_hanspub.png" /></p></sec><sec id="s5"><title>1. 引言</title><p>随着计算机技术的不断提高，视觉导航技术发展迅速 [<xref ref-type="bibr" rid="hanspub.41244-ref1">1</xref>]。视觉系统具有独立性、准确性、可靠性以及信息完整性等优点，可完成目标识别、障碍物回避及路径规划等功能 [<xref ref-type="bibr" rid="hanspub.41244-ref2">2</xref>]。在复杂环境中飞行时，利用视觉系统可以尽早发现周围环境中对飞行构成威胁的障碍物，提高飞行安全系数 [<xref ref-type="bibr" rid="hanspub.41244-ref3">3</xref>]。</p><p>由于单目视觉无法得到目标物体的深度信息，难以估计三维位置信息，为了满足无人机飞行器复杂环境下的导航需求，国内外学者逐步将双目视觉导航方法引入无人飞行器自主导航领域 [<xref ref-type="bibr" rid="hanspub.41244-ref4">4</xref>]。基于双目视觉的三维测量技术就是利用双目相机拍摄的图像，将目标在图像上的二维像素坐标转化为三维世界坐标 [<xref ref-type="bibr" rid="hanspub.41244-ref5">5</xref>]，双目视觉的视觉里程计技术目前在车载导航领域已经得到了验证和应用 [<xref ref-type="bibr" rid="hanspub.41244-ref6">6</xref>]。</p><p>目前市面上成熟的双目视觉模块，如国内小米公司的深度相机，大疆公司的视觉传感导航模块，国外如英特尔的RealSense D435和微软的kinect2等设备，都包含深度芯片而导致质量过大，有的产品还需要外接图像处理器。这些铲平包含深度芯片的原因是双目视觉进行图像处理时，为了应用于避障场景，实时性的要求非常严格，实时图像处理需要大量的存储空间和计算速度，所以市面上双目相机需要集成深度计算芯片或者外接处理器，从而导致双目相机的重量过大，无法应用于对质量有严格要求的微型飞行器上。</p><p>因此，本项目设计出一款能够用于扑翼飞行器上的双目视觉模块，该模块解决重量过大的问题，同时满足实时性避障场景的要求。</p></sec><sec id="s6"><title>2. 硬件设计</title><p>双目视觉导航的硬件设计主要需考虑图像处理主芯片和传感器的设计。为了解决两相机不同步的问题，本项目从最前端的图像传感器进行开发，这就要求所依靠的嵌入式平台不仅具备能完成对图像传感器的驱动和配置的逻辑时序控制能力、一定的信号处理能力和计算能力，还需要具备灵活的外设接口和方便的可升级能力。FPGA不仅具备强大的逻辑控制能力，还具备唯一的并行处理能力。因此考虑选用FPGA芯片作为图像处理的主芯片，即能保证实时处理双目图像的匹配，输出深度图，又能满足质量轻、功耗小的要求。另一方面，图像传感器的主要类型有CCD和CMOS。相比之下，COMS传感器的优点为几何尺寸较小，并且CMOS传感器的制造技术与CMOS工艺兼容，CMOS的整合度和帧速率比较高、成本和功耗比较低 [<xref ref-type="bibr" rid="hanspub.41244-ref7">7</xref>]，所以本项目选择CMOS图像传感器。</p><p>本项目图像处理主芯片和传感器的设计具体如下。</p><sec id="s6_1"><title>2.1. FPGA图像处理主芯片</title><p>本项目中采用的FPGA芯片是Altera公司的Cyclone系列芯片EP4CE10F17C8N，该芯片拥有10K的逻辑单元，两个独立锁相环，180个用户I/O管脚，423936bit嵌入式RAM，46个9位嵌入式硬件乘法器等丰富的资源，可以满足目前的设计要求。</p><p>FPGA设计的特点是自顶而下及模块化的思想，先将系统框架的总体思路列出，再展示核心模块的细节内容。如图1所示，FPGA通过I2C配置两个CMOS图像传感器，读取拍摄到的场景，输入给图像处理模块，图像处理模块包括Census变换模块和Hamming距离计算模块，计算出Hamming距离后通过WTA策略决策出视差并输入至SDRAM中存储起来，为了实验方便，通过VGA显示其效果。</p><p>图1. 系统总体框架</p><p>FPGA的最大特点是流水线计算和并行计算。流水线计算体现在像素自图像传感器读入，然后经过各个模块处理为视差图后又输出至VGA，类似于工厂中的流水线过程。其好处在于，一旦设置好输入输出端的传输频率，整个过程就已经确定了，与数据量的大小无关，即只要传输速率满足要求，处理图像的大小不会影响帧率。另一方面，流水线的计算过程方便发现计算结果的错误，将算法的修改层层分割为某一个模块中的某一个部分，方便修改和迁移。FPGA的并行计算则体现在Verilog语言的特点上，由于硬件描述语言与芯片中的具体电路布线是相对应的，因此可以并行计算出Hamming距离。</p></sec><sec id="s6_2"><title>2.2. OV7620图像传感器</title><p>图像传感器的工作方式分为主动模式和被动模式。在主动模式中，图像采集所需要的时序由相机产生，每个相机均按照自身的时序独立采集，因此容易导致两相机采集不同步。被动模式中，图像采集的部分控制时序由外部逻辑控制，相机依据控制时序来完成图像采集工作，在该模式下若把同一个控制信号输入给两个相机，便可以实现相机的同步采集。因此该系统中所选用的图像传感器必须能工作在被动模式下，其中Omnivision公司生产的OV7620符合要求。</p><p>OV7620是一种1/3”CMOS黑白/彩色图像传感器，在图像采集过程中支持连续、隔行扫描方式；工作方式可以配置成主动/被动模式；输出图像数据有VGA/QVGA两种模式；最高像素可以达到664 &#215; 492；最高帧速率为30 fps；支持YUV数据格式。通过其内建的SCCB (Serial Camera Control Bus)通讯接口可以方便地控制其内部寄存器。</p><p>OV7620与FPGA的连接如图2所示，其中SCLK、SDTA为FPGA根据I2C协议产生的用来模拟SCCB配置寄存器的时钟和数据信号；同步时序Vsync和Hsync是图像采集中需要的帧同步和行同步信号，在被动模式下，这两个信号是FPGA依据被动时序要求来设计产生的；PCLK是OV7620的像素时钟；DATA[7:0]为相机的8位有效数据。</p><p>图2. FPGA与OV7620的逻辑连接图</p></sec></sec><sec id="s7"><title>3. 算法设计</title><p>双目立体匹配的目的是在左右视图中寻找恰当的匹配点，其算法中的关键部分是先建立一个有效的基于能量的代价评估函数，紧接着通过对该函数做最小化处理来计算图像对在成像过程中的匹配像素点的视差值 [<xref ref-type="bibr" rid="hanspub.41244-ref8">8</xref>]。立体匹配算法的实质就是最优化求解问题，通过建立合理的能量函数，增加一些约束，采用最优化理论的方法进行方程求解。为了满足扑翼飞行器自主避障的实时性要求，本项目考虑选用的是局部匹配算法，该算法的特点是简便快捷、容易实现 [<xref ref-type="bibr" rid="hanspub.41244-ref9">9</xref>]。</p><p>为了获得更好的匹配效果，将Census变换引入立体匹配中。Census变换是充分考虑了图像局部相关的特性，而不是直接使用灰度值做差，具有抗光影畸变的作用，效率高、稳定性强，是一种非常有效的代价计算方法，此变换方法能较好地检测出图像中的局部结构特征，如边缘、角点特征等，其核心思想是使用像素邻域内的局部灰度差异，用比特串来表示编码后像素灰度变换信息 [<xref ref-type="bibr" rid="hanspub.41244-ref10">10</xref>]。由于Census变换能够更好地检测出图像中的纹理空间分布信息，因而具有更好的鲁棒性和适用性 [<xref ref-type="bibr" rid="hanspub.41244-ref11">11</xref>]。</p><p>算法的具体步骤如下：</p><p>1) Census图像变换</p><p>将两个OV7620图像传感器测得的两幅图像都进行Census变换，即将图像像素的灰度值编码成二进制码流，以此来获取邻域像素灰度值相对于中心像素灰度值的大小关系。变换过程通过如下公式进行计算：</p><p>T ( p ) = ⊗ q ∈ N p ξ ( I ( p ) , I ( q ) )</p><p>ξ ( I ( p ) , I ( q ) ) = { 0     I ( q ) ≤ I ( p ) 1     I ( q ) &gt; I ( p )</p><p>其中p是窗口中心像素，q是窗口中心像素以外的其他像素， N p 表示中心像素 的邻域。 I ( p ) 、 I ( q ) 表示像素点p、q处的灰度值，符号<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/3-2980147x17_hanspub.png" xlink:type="simple"/></inline-formula>表示比特位的逐位连接运算。</p><p>2) 计算匹配代价</p><p>经过Census变换后的两幅图像使用Hamming距离计算左右视图的匹配度。可将两个视图相应两点的Census值逐位进行异或运算，然后记录结果为1的个数，然后将此个数记为两点之间的Hamming距离。Hamming距离是两点间匹配度的一种体现，Hamming距离越小即匹配度越高。Hamming距离的公式如下：</p><p>H ( T l e f t , T r i g h t ) = ∑ i = 1 n T l e f t ⊕ T r i g h t</p><p>其中， T l e f t 和 T r i g h t 分别表示左视图和右视图进过Census变换后的二进制编码流， ⊕ 表示异或运算，n表示二进制编码流的位数， H ( T l e f t , T r i g h t ) 表示Hamming距离。</p><p>3) 代价聚合</p><p>局部算法需要对一个支持窗口内的匹配代价进行聚合而得到参考图像上一点在视差处的累积代价。通过匹配代价聚合，可以降低异常点的影响，提高信噪比进而提高匹配精度。</p><p>4) 视差计算</p><p>通常采用“胜者为王”策略，即在视差搜索范围内选择累积代价最优的点作为对应匹配点，与之对应的视差即为所求的视差。</p><p>5) 后续处理</p><p>通过以上四个步骤后得到左右两幅视差图像。但此时的视差图存在诸多问题，如存在噪声、障碍区域视差不准确、匹配点之间不匹配等，还不能进行应用，因此本项目对视差图进行优化的方法是图像滤波法。</p></sec><sec id="s8"><title>4. 理论验证</title><p>本项目的理论验证实验对双目图像摄像头采集到的图像进行分析。采集的图像如图3所示，其中该图的两幅图像分别是双目摄像头得到的左眼视图和右眼视图。</p><p>图3. 左右视图</p><p>图4中的两幅图分别是上述设计的基于Census变换的局部立体匹配算法在PC端和FPGA硬件系统处理完的结果，其中左图是在PC端用MATLAB语言编写的程序输出的图像，右图是FPGA硬件系统处理输出的图像。</p><p>图4. 立体视觉结果图</p><p>利用直方图匹配计算的方法对图4的两幅图进行相似度计算，这种计算方法是基于向量之间的差异来进行图像相似程度的度量，计算量小，而且图像能很好的进行归一化处理。两幅图的相似度计算结果如图5所示。</p><p>图5. 仿真结果图</p><p>从图5可以看出，基于Census变换的局部立体匹配算法在PC端利用Matlab处理得到的图像，和在FPGA硬件系统处理得到的图像，两幅图的相似程度高达91%。理论实验的结果表明，基于Census变换的局部立体匹配算法的立体视觉导航模块在理论层面是可行的。</p></sec><sec id="s9"><title>5. 实验验证</title><p>本项目利用FPGA芯片设计的基于Census变换和局部立体匹配算法的视觉导航模块应用在扑翼飞行器上，并结合开源飞控PX4实现了一套成熟可用的控制系统。通过设计的视觉导航模块将图像信息发送给开源飞控PX4，为扑翼飞行器的自主飞行提供决策依据，同时利用PX4软件系统的地面站，即QGroundControl软件可以实现预先的路径规划，通过设置航点可以实现自动起飞降落和按计划轨迹飞行。通过该软件可以输入航路点和其他命令，规划好航迹后，PX4会利用L1制导路径跟随算法实现沿曲线路径制导。</p><p>本实验任务是在QGroundControl软件上预先设置航点，让扑翼飞行器自主飞行控制。设置航点时，将其中的一个航点设置在烂尾楼上，观察扑翼飞行器是否能识别障碍物，并进行自主避障。</p><p>实验任务的整个过程路径如图6所示，从图中可以看出，在第二个航点与第三个航点之间存在障碍物烂尾楼，扑翼飞行器在检测到障碍物之后，自主向左做出避障动作，成功绕开烂尾楼，并继续前往第三个航点，最终顺利完成全部任务，验证了扑翼飞行器可以识别障碍物，并进行自主避障。</p><p>图6. 自主避障任务过程</p></sec><sec id="s10"><title>6. 结论</title><p>本项目利用FPGA芯片设计了一款基于Census变换的立体视觉导航模块，该模块质量轻，图像处理速度快，可进行图像的实时处理，能应用于扑翼飞行器的视觉导航。结合开源飞控PX4，本项目设计了一款能实现自动起降、按航迹飞行和自主避障功能的扑翼飞行器，最后通过实验验证了该立体视觉模块的可行性。结果表明，该视觉导航模块具有很强的工程实用价值，可以为无人机的自主避障飞行提供技术支持和决策依据。</p></sec><sec id="s11"><title>文章引用</title><p>候慧敏,印明威,危 威,王贤宇. 视觉导航在扑翼飞行器避障中的应用Visual Navigation for Obstacle Avoidance of Flapping Wing Micro-Air Vehicles[J]. 国际航空航天科学, 2021, 09(01): 22-29. https://doi.org/10.12677/JAST.2021.91003</p></sec><sec id="s12"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.41244-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">夏凌楠, 张波, 王营冠, 魏建明. 基于惯性传感器和视觉里程计的机器人定位[J]. 仪器仪表学报, 2013, 34(1): 166-172.</mixed-citation></ref><ref id="hanspub.41244-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">李红岩, 毛征, 袁建建, 曲劲松, 吴珍荣. 一种基于算法融合的运动目标跟踪算法[J]. 国外电子测量技术, 2013, 32(12): 36-40.</mixed-citation></ref><ref id="hanspub.41244-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">黄楠楠, 刘贵喜, 张音哲, 姚李阳. 无人机视觉导航算法[J]. 红外与激光工程, 2016, 45(7): 269-277.</mixed-citation></ref><ref id="hanspub.41244-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Lategahn, H., Derendarz, W., Graf, T., et al. (2010) Occupancy Grid Computation from Dense Stereo and Sparse Structure and Motion Points for Automotive Applications. 2010 IEEE Intelligent Vehicles Symposium, La Jolla, 21-24 June 2010, 819-824. &lt;br&gt;https://doi.org/10.1109/IVS.2010.5548078</mixed-citation></ref><ref id="hanspub.41244-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">周科杰, 冯常. 基于双目视觉的三维测量技术研究[J]. 计算机测量与控制, 2019, 27(1): 22-25+31.</mixed-citation></ref><ref id="hanspub.41244-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Kitt, B., Geiger, A. and Lategahn, H. (2010) Visual Odometry Based on Stereo Image Sequences with RANSAC- Based Outlier Rejection Scheme. 2010 IEEE Intelligent Vehicles Symposium, La Jolla, 21-24 June 2010, 486-492.  
&lt;br&gt;https://doi.org/10.1109/IVS.2010.5548123</mixed-citation></ref><ref id="hanspub.41244-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">宋海吒, 唐立军, 谢新辉. 基于FPGA和OV7620的图像采集及VGA显示[J]. 电视技术, 2011, 35(5): 45-47+61.</mixed-citation></ref><ref id="hanspub.41244-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">苏东. 基于双目视觉的小型无人飞行器的导航与避障[D]: [硕士学位论文]. 电子科技大学, 2014.</mixed-citation></ref><ref id="hanspub.41244-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">陈华, 王立军, 刘刚. 立体匹配算法研究综述[J]. 高技术通讯, 2020, 30(2): 157-165.</mixed-citation></ref><ref id="hanspub.41244-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">欧永东, 谢小鹏. 基于改进Census变换的多特性立体匹配算法[J]. 计算机工程与科学, 2020, 42(6): 1030-1036..</mixed-citation></ref><ref id="hanspub.41244-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">孙延坤, 李彩林, 王佳文, 苏本娅, 崔志婷. 融合绝对误差和与Census变换的双目立体图像匹配算法[J]. 科学技术与工程, 2020, 20(29): 12035-12041.</mixed-citation></ref></ref-list></back></article>