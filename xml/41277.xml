<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">AP</journal-id><journal-title-group><journal-title>Advances in Psychology</journal-title></journal-title-group><issn pub-type="epub">2160-7273</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/AP.2021.113091</article-id><article-id pub-id-type="publisher-id">AP-41277</article-id><article-categories><subj-group subj-group-type="heading"><subject>AP20210300000_31504986.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>人文社科</subject><subject> 合作期刊</subject></subj-group></article-categories><title-group><article-title>
 
 
  视觉注意负荷对视听整合的影响
  Effects of Visual Attention Load on Audiovisual Integration
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>毕</surname><given-names>浚皓</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>李</surname><given-names>君缘</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>平</surname><given-names>航</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>null</addr-line></aff><aff id="aff1"><addr-line>贵州中医药大学人文与管理学院，贵州 贵阳 </addr-line></aff><pub-date pub-type="epub"><day>10</day><month>03</month><year>2021</year></pub-date><volume>11</volume><issue>03</issue><fpage>796</fpage><lpage>800</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   研究表明，视觉负荷减弱视听整合效应。然而，以往研究未考察低视觉负荷下是否发生视听整合效应。本研究结合Go/no-go和RSVP范式进行视觉注意负荷下的听觉、视觉辨别任务，通过操纵视觉注意负载，将实验分为低注意负载、高注意负载两个任务。平均反应时和正确率分析显示，低负荷下反应时和正确率分别低于和高于高负荷(P &lt; 0.05)。竞争模型进一步的研究发现，低负荷下发生视听整合效应，高负荷下未发生视听整合效应，这可能是由于注意力资源的有限性所造成的。 Studies have shown that visual load reduces the effect of audiovisual integration. However, it is not clear whether audiovisual integration occurred under low attention load conditions. Go/no-go and RSVP paradigms were combined to conduct an auditory/visual discrimination task under visual attention load in this research. By manipulating visual attention load, the experiment was divided into two tasks: low attention load and high attention load. The average response time and accuracy rate show that the response time and accuracy rate under low load are lower and higher than high load respectively (P &lt; 0.05). Further research of the race model found that the audiovisual integration effect occurs under low load, but not occurs in high load, which may be affected by the limited attention resources. 
  
 
</p></abstract><kwd-group><kwd>视觉负荷，视听整合，竞争模型，注意负荷, Audiovisual Integration</kwd><kwd> Race Model</kwd><kwd> Attention Load</kwd><kwd> Visual Attention Load</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>摘要</title><p>研究表明，视觉负荷减弱视听整合效应。然而，以往研究未考察低视觉负荷下是否发生视听整合效应。本研究结合Go/no-go和RSVP范式进行视觉注意负荷下的听觉、视觉辨别任务，通过操纵视觉注意负载，将实验分为低注意负载、高注意负载两个任务。平均反应时和正确率分析显示，低负荷下反应时和正确率分别低于和高于高负荷(P &lt; 0.05)。竞争模型进一步的研究发现，低负荷下发生视听整合效应，高负荷下未发生视听整合效应，这可能是由于注意力资源的有限性所造成的。</p></sec><sec id="s2"><title>关键词</title><p>视觉负荷，视听整合，竞争模型，注意负荷</p></sec><sec id="s3"><title>Effects of Visual Attention Load on Audiovisual Integration</title><p>Junhao Bi, Junyuan Li, Hang Ping</p><p>Medical Humanities College, Guizhou University of Traditional Chinese Medicine, Guiyang Guizhou</p><p><img src="//html.hanspub.org/file/20-1132204x4_hanspub.png" /></p><p>Received: Feb. 26<sup>th</sup>, 2021; accepted: Mar. 18<sup>th</sup>, 2021; published: Mar. 29<sup>th</sup>, 2021</p><p><img src="//html.hanspub.org/file/20-1132204x5_hanspub.png" /></p></sec><sec id="s4"><title>ABSTRACT</title><p>Studies have shown that visual load reduces the effect of audiovisual integration. However, it is not clear whether audiovisual integration occurred under low attention load conditions. Go/no-go and RSVP paradigms were combined to conduct an auditory/visual discrimination task under visual attention load in this research. By manipulating visual attention load, the experiment was divided into two tasks: low attention load and high attention load. The average response time and accuracy rate show that the response time and accuracy rate under low load are lower and higher than high load respectively (P &lt; 0.05). Further research of the race model found that the audiovisual integration effect occurs under low load, but not occurs in high load, which may be affected by the limited attention resources.</p><p>Keywords:Audiovisual Integration, Race Model, Attention Load, Visual Attention Load</p><disp-formula id="hanspub.41277-formula14"><graphic xlink:href="//html.hanspub.org/file/20-1132204x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2021 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/20-1132204x7_hanspub.png" /> <img src="//html.hanspub.org/file/20-1132204x8_hanspub.png" /></p></sec><sec id="s5"><title>1. 引言</title><p>人们驾车时需同时处理视觉、听觉和其他感官信息。因此，驾驶实际包含了多感觉整合的过程。多感觉整合是指个体能够更有效地将来自不同感官通道(如视觉、嗅觉、听觉、触觉等)的信息整合成统一高效的感知信号(顾吉有，2016)。视觉信息和听觉信息在两个不同的通道上的整合称为视听整合。例如，经典的视听整合现象McGurk效应(Mcgurk &amp; Macdonald, 1976)，当ba-ba的声音与ga-ga的动作相匹配时，个体就会报道da-da。</p><p>视觉负荷对视听整合具有重要的调节作用，近年来，视觉负荷下的视听整合得到大量的研究和关注。</p><p>Basil Wahn等人研究表明注意力负荷不会破坏视听整合(Wahn &amp; K&#246;nig, 2015)。在其研究中分为单对象预测任务(LOC)与多对象跟踪任务(MOT)。LOC任务要求被试通过单独视觉、单独听觉以及视听结合的方式预测小球的运动方向；MOT任务则要求被试分别在单独视觉、单独听觉以及视听结合刺激的干扰下同时跟踪三只小球的运动轨迹。结果表明高注意力负荷不会影响视听通道多感官信息的整合，这提示多感官整合可能独立于注意过程并在注意过程之前运行。</p><p>而Alsius等人曾证明在视觉负荷的情况下视听整合效应会大大减弱(Tiippana et al., 2004; Alsius et al., 2007)。在其研究中刺激有三种呈现方式，分别为视听结合、单独视觉、单独听觉。同时设置了以叠加在视频之上的线描图谱和音频材料分别作为视觉干扰刺激和听觉干扰刺激。被试的任务是复述材料中内容。结果表明，当视觉或听觉注意力资源减少时，视听整合的能力就会下降。但因为负荷刺激的任务是探测重复呈现的刺激，所以不免混入了记忆因素。为了克服记忆因素对研究的影响，顾吉有设计了另一个实验，将负荷刺激改为对10以内的数字奇偶的判断，排除了记忆的影响。结果同样表明在视觉负荷情况下视听整合效应会大大降低。</p><p>研究表明在简单视听觉加工任务中，视听整合效应产生；然而，以往研究均未对视觉负荷水平作进一步划分，特别是低视觉负荷下是否存在视听整合效应还不得而知。本研究基于易混淆的数字和字母作干扰刺激设置了低、高视觉负荷两种情况，要求被试对单视觉、单听觉和视听整合任务做出最快的反应。</p></sec><sec id="s6"><title>2. 方法</title><sec id="s6_1"><title>2.1. 被试</title><p>共二十名被试(男性10名，女性10名)参与实验，平均年龄19.434 &#177; 1岁。所有参与者均为贵州中医药大学本科生，都有正常的听力和视力。</p></sec><sec id="s6_2"><title>2.2. 实验刺激与装置</title><p>如图1所示，视觉目标刺激(VT)为白色方格内有两个黑点的黑白棋盘图像(52 &#215; 52 mm，视角为5˚)，听觉目标刺激(AT)为60 dB的白噪音，视听目标刺激(VAT)是二者的结合。视觉标准刺激(VS)是黑白棋盘图像，听觉标准刺激(AS)是60 dB的1000赫兹正弦音，视听标准刺激(VAS)是二者的结合。干扰刺激由3个阿拉伯数字和5个英语字母组成。</p><p>图1. 实验流程示意图</p><p>实验采用2 (低视觉负荷、高视觉负荷) &#215; 3 (视觉通道、听觉通道、视听整合通道)的被试内设计。实验中，标准刺激数与目标刺激数的比例为1:4。实验共有272个试次，整个实验约持续30分钟。在实验开始之前有20个试次的练习。低负荷下有一次随机休息，高负荷下有两次随机休息。</p><p>视觉刺激被呈现在距离被试60 cm的21寸的显示器的四个角(位于中心左侧或右侧12˚，中心点上方或下方5˚)，持续100 ms，背景为黑色。听觉刺激用扬声器呈现，持续100 ms。干扰刺激呈现在屏幕中央，持续100 ms。</p></sec><sec id="s6_3"><title>2.3. 实验程序</title><p>如图1所示，在每个试次中，首先在黑色屏幕上呈现一个白色注视点(持续1000 ms)后，呈现线索刺激(持续100 ms)，随后呈现一个注视点作为掩蔽刺激(持续1000~1500 ms)。低负荷下，对VT、AT、VAT按左键反应。对VS、AS、VAS不做反应；对干扰刺激不做任何反应。高负荷下，除对VT、AT、VAT按左键反应，对VS、AS、VAS不反应外，并对干扰刺激中出现的数字“7”和字母“B”按右键反应。</p></sec></sec><sec id="s7"><title>3. 数据分析</title><p>在每种条件下，分别计算每个被试的正确率和反应时。根据不同的负荷对每个被试的反应时和SD进行重组并取平均值。随后，对目标刺激的反应时和正确率进行重复测量方差分析。</p><p>对每个受试者的数据建立独立的竞争模型(Miller, 1986; H&#252;bner &amp; Bennemann, 1973)。独立竞争模型是基于对单独视觉和听觉刺激的视觉和听觉反应的概率之和的统计预测模型。并将视听整合模型与基于个体视觉和听觉的综合概率模型进行比较。如果视听整合模型明显快于预测概率模型，则发生视听整合效应(Miller, 1986; H&#252;bner &amp; Bennemann, 1973)。</p></sec><sec id="s8"><title>4. 结果</title><sec id="s8_1"><title>4.1. 正确率</title><p>低、高负荷下目标刺激正确率均高于90%。2 (低视觉负荷、高视觉负荷) &#215; 3 (视觉通道、听觉通道、视听整合通道)的重复测量方差分析表明被试间效应显著F(1,19) = 131495.603，P &lt; 0.001， η p 2 = 1。不同负荷之间被试正确率差异显著F(3,57) = 46.06，P &lt; 0.05， η p 2 = 0.708，且低负荷下正确率高于高负荷。不同感觉通道间差异显著F(2,38) = 4.149，P &lt; 0.05，视听结合反应时快于单独听觉和单独视觉。</p></sec><sec id="s8_2"><title>4.2. 反应时</title><p>2 (低视觉负荷、高视觉负荷) &#215; 3 (视觉通道、听觉通道、视听整合通道)的重复测量方差分析表明被试间效应显著F(1,19) = 431.168，P &lt; 0.001， η p 2 =0.958。且不同负荷之间差异显著F(3,57) = 65.026，P &lt; 0.001， η p 2 = 0.774，低负荷反应时快于高负荷。不同感觉通道间差异显著F(2,38) = 16.737，P &lt; 0.001， η p 2 = 0.468，视听结合反应时快于单独视觉和单独听觉。</p></sec><sec id="s8_3"><title>4.3. 竞争模型(Race Model)分析</title><p>结果表明，低负荷在250 ms到430 ms之间视听结合模型反应概率显著高于竞争模型(P &lt; 0.05)，发生视听整合效应(见图2、图3)；高负荷未发生视听整合效应。</p><p>图2. 不同负荷下的竞争模型。(a) 低负荷；(b) 高负荷</p><p>图3. 视听结合模型与预测竞争模型的直接比较</p></sec></sec><sec id="s9"><title>5. 讨论</title><p>本研究旨在明确在简单视听觉刺激的加工任务中低视觉负荷是否会发生视听整合。因此，在两种负荷下进行听觉、视觉辨别任务。结果显示，低负荷下目标刺激的反应时快于高负荷，这与前人的研究结果一致。可能的原因是注意资源的有限性(Tipper, 1985)，即当视觉负载加大，所占用的注意资源增多，对目标刺激的关注减少，反应时间相应延长。</p><p>同时，低负荷下目标刺激的正确率高于高负荷，这与前人的研究结果一致。可能的原因是任务难度的差异，即当任务难度增加，标准刺激较目标刺激占用注意资源的比重增大，对目标刺激反应犯错的概率上升。</p><p>另外，低视觉负荷下发生视听整合而高视觉负荷下没有发生，这与顾吉有报道的结论不一致(顾吉有，2016)。在她的研究中，视听整合效应只在无视觉负荷下产生。对此可能的解释是负荷设置的差异，即顾吉有实验中的干扰刺激属于高视觉负荷水平，对注意力资源的占用较大，从而减弱了视听整合效应。</p><p>通过本实验，完善了前人关于视听整合的实验研究，验证了前人的研究结果，证明了低负荷下对目标刺激的反应时快于高负荷，且低视觉负荷时发生显著的视听整合效应；同时该结果提示我们，在日常生活中我们应当合理安排工作，有意识地按序解决问题，从而提升工作的速度与正确率；但需注意，该研究中负荷水平的设置尚不能支持研究探讨视听整合发生的临界点的位置，未来可以进一步划分负荷水平做进一步的研究。</p></sec><sec id="s10"><title>文章引用</title><p>毕浚皓,李君缘,平 航. 视觉注意负荷对视听整合的影响Effects of Visual Attention Load on Audiovisual Integration[J]. 心理学进展, 2021, 11(03): 796-800. https://doi.org/10.12677/AP.2021.113091</p></sec><sec id="s11"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.41277-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">顾吉有(2016). 注意对视听整合加工的影响. 博士学位论文. 天津: 天津师范大学.</mixed-citation></ref><ref id="hanspub.41277-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Alsius, A., Navarra, J., &amp; Soto-Faraco, S. (2007). Attention to Touch Weakens Audiovisual Speech Integration. Experimental Brain Research, 183, 399-404. &lt;br&gt;https://doi.org/10.1007/s00221-007-1110-1</mixed-citation></ref><ref id="hanspub.41277-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Hübner, W., &amp; Bennemann, K. H. (1973). Attention and Effort. Upper Saddle River: Prentice-Hall.</mixed-citation></ref><ref id="hanspub.41277-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Mcgurk, H., &amp; Macdonald, J. (1976). Hearing Lips and Seeing Voices. Nature, 264, 746-748.  
&lt;br&gt;https://doi.org/10.1038/264746a0</mixed-citation></ref><ref id="hanspub.41277-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Miller, J. (1986). Timecourse of Coactivation in Bimodal Divided Attention. Perception &amp; Psychophysics, 40, 331-343.  
&lt;br&gt;https://doi.org/10.3758/BF03203025</mixed-citation></ref><ref id="hanspub.41277-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Tiippana, K., Andersen, T. S., &amp; Sams, M. (2004). Visual Attention Modulates Audiovisual Speech Perception. European Journal of Cognitive Psychology, 16, 457-472. &lt;br&gt;https://doi.org/10.1080/09541440340000268</mixed-citation></ref><ref id="hanspub.41277-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Tipper, S. P. (1985). The Negative Priming Effect: Inhibitory Priming by Ignored Objects. Quarterly Journal of Experimental Psychology, 37, 571-590. &lt;br&gt;https://doi.org/10.1080/14640748508400920</mixed-citation></ref><ref id="hanspub.41277-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Wahn, B., &amp; König, P. (2015). Audition and Vision Share Spatial Attentional Resources, Yet Attentional Load Does Not Disrupt Audiovisual Integration. Frontiers in Psychology, 6, 1084. &lt;br&gt;https://doi.org/10.3389/fpsyg.2015.01084</mixed-citation></ref></ref-list></back></article>