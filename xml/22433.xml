<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2017.710112</article-id><article-id pub-id-type="publisher-id">CSA-22433</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20171000000_30722012.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  拟阵约束下最大化子模函数的模型及其算法的一种熵聚类方法
  An Entropy Clustering Method for the Model and Its Algorithm of the Maximizing a Submodular Function Subject to a Matroid Constraint
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>梁</surname><given-names>国宏</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>李</surname><given-names>映</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>叶</surname><given-names>萌</given-names></name><xref ref-type="aff" rid="aff4"><sup>4</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>李</surname><given-names>炳杰</given-names></name><xref ref-type="aff" rid="aff5"><sup>5</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff4"><addr-line>94826部队，上海</addr-line></aff><aff id="aff5"><addr-line>空军工程大学理学院，陕西 西安</addr-line></aff><aff id="aff2"><addr-line>西北工业大学计算机学院，陕西 西安;空军工程大学理学院，陕西 西安</addr-line></aff><aff id="aff3"><addr-line>西北工业大学计算机学院，陕西 西安</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>13</day><month>10</month><year>2017</year></pub-date><volume>07</volume><issue>10</issue><fpage>994</fpage><lpage>1001</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   本文提出了一个新的带有信息熵的聚类目标函数，它是由基于图论的随机路径的熵率和平衡项两部分组成。熵率有利于形成紧凑和均匀的聚类，平衡函数鼓励相似度比较高的对象才能聚类，并惩罚那些相似度比较低的对象。首先构造了与数据关联的赋权无向图，并发现这种构造诱导出一个拟阵，它是一个组合在向量空间中推广线性独立概念的结构。接着得到了拟阵约束下最大化子模函数的模型。最后根据目标函数的单调性、递增性和下模性，开发了一个高效的贪婪算法并讨论了它的性能保证。最后根据数值实验，与已有的算法做了比较，说明了该算法的有效性。 This paper proposes a new clustering objective function with information entropy, which is composed of entropy rate of random path based on graph theory and balance item. Entropy rate is conducive to compact and uniform clustering, the balance function encourages objects with high similarity to cluster, and punishes those objects with low similarity. First, the weighted undirected graph associated with data is constructed, and it is found that this structure induces a matroid, a combination of the structure of linear independent concept in vector space. Then, the model of which is maximizing a submodular function under the constraints of the matroid is obtained. Finally, according to the monotonicity, increment and submodular of the objective function, an efficient greedy algorithm is developed and its performance guarantee is discussed.
    
  
 
</p></abstract><kwd-group><kwd>聚类，图理论，信息理论，子模函数，离散优化, Clustering</kwd><kwd> Graph Theory</kwd><kwd> Information Theory</kwd><kwd> Submodular Function</kwd><kwd> Discrete Optimization</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>拟阵约束下最大化子模函数的模型及其算法的一种熵聚类方法<sup> </sup></title><p>梁国宏<sup>1,2</sup>，李映<sup>1</sup>，叶萌<sup>3</sup>，李炳杰<sup>2</sup></p><p><sup>1</sup>西北工业大学计算机学院，陕西 西安</p><p><sup>2</sup>空军工程大学理学院，陕西 西安</p><p><sup>3</sup>94826部队，上海</p><p>收稿日期：2017年10月6日；录用日期：2017年10月19日；发布日期：2017年10月24日</p><disp-formula id="hanspub.22433-formula40"><graphic xlink:href="//html.hanspub.org/file/9-1540841x5_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>本文提出了一个新的带有信息熵的聚类目标函数，它是由基于图论的随机路径的熵率和平衡项两部分组成。熵率有利于形成紧凑和均匀的聚类，平衡函数鼓励相似度比较高的对象才能聚类，并惩罚那些相似度比较低的对象。首先构造了与数据关联的赋权无向图，并发现这种构造诱导出一个拟阵，它是一个组合在向量空间中推广线性独立概念的结构。接着得到了拟阵约束下最大化子模函数的模型。最后根据目标函数的单调性、递增性和下模性，开发了一个高效的贪婪算法并讨论了它的性能保证。最后根据数值实验，与已有的算法做了比较，说明了该算法的有效性。</p><p>关键词 :聚类，图理论，信息理论，子模函数，离散优化</p><disp-formula id="hanspub.22433-formula41"><graphic xlink:href="//html.hanspub.org/file/9-1540841x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2017 by authors and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/9-1540841x7_hanspub.png" /> <img src="//html.hanspub.org/file/9-1540841x8_hanspub.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>聚类是在机器学习中的一种无监督学习方式，既是数据挖掘的重要部分，又是模式识别领域的基础问题 [<xref ref-type="bibr" rid="hanspub.22433-ref1">1</xref>] [<xref ref-type="bibr" rid="hanspub.22433-ref2">2</xref>] ，在统计学里也有广泛的引用。在几乎每个处理经验数据的科学领域里，研究人员试图通过识别相似字符组的数据获得第一印象。在不同的领域已经提出了很多种聚类方法，并且都有性能保证。然而，它们通常是基于不同的假设，而且很难在同一个标准下比较。此外，最理想的标准会导致成NP-hard问题。因此聚类的进一步发展就是对存在理论证明或更新的问题的目标函数的精细化设计。</p><p>在各种各样的聚类算法中，一些使用单个目标函数，一些递归地使用中间成本函数，以及一些基于数据点的投影(子空间，流形)。制定聚类问题作为一个图拓扑选择问题，当数据点及其对应关系分别映射到图中的顶点和边。然后通过查找图拓扑来解决聚类问题。主要考虑紧凑的、均匀的、平衡的类别。在一个紧凑的类别中，数据点彼此接近。为了获得以上这些性质，我们提出了一个新的由两部分组成的目标函数：一是图上的随机路径的熵率；二是类分布的平衡项。熵率 [<xref ref-type="bibr" rid="hanspub.22433-ref3">3</xref>] 有利于形成紧凑和均匀的聚类，平衡函数鼓励相似度比较高的聚类，并惩罚那些相似度比较差的对象。根据图中的随机路径和类别的分布有很大的不确定性，构造一个图拓扑。</p><p>本文把聚类作为一个图划分问题，将图划分为 k 个群，研究具有 k 连通子图的图拓扑，并最大化所提出的目标函数。</p></sec><sec id="s4"><title>2. 模型</title><sec id="s4_1"><title>2.1. 基础知识</title><p>图：无向图表示为 G = ( V , E ) ，其中 V 是顶点的集合， E 是边的集合。 v i 和 e i , j 表示顶点与边。 w i , j 表示顶点 v i 和 v j 之间边 e i , j 上的权重。在无向图中边的权重是对称的，即 w i , j = w j , i 。</p><p>图的划分 [<xref ref-type="bibr" rid="hanspub.22433-ref4">4</xref>] ：在 G = ( V , E ) 中，如果 V = { V 1 , V 2 , ⋯ , V K } ，且满足：</p><p>(1) V i ∩ V j = Φ , i ≠ j ；(2) ∪ i = 1 K V i = V ，</p><p>则称 V 1 , V 2 , ⋯ , V K 为 V 的一个划分。图的顶点的子集的选择问题就是图的划分问题。</p><p>本文的目标是选择边的子集 A ∈ E ，使得子图 ( V , A ) 是K-连通的。</p><p>熵：用来度量随机变量的不确定性。设离散随机变量 X ，概率密度函数为 p X ，则它的熵定义为：</p><p>H ( X ) = − ∑ p X ( x ) log p X ( x ) , (1)</p><p>相应的，条件熵 H ( X | Y ) 的定义为：</p><p>H ( X | Y ) = − ∑ p Y ( y ) H ( X | Y = y ) = − ∑ p Y ( y ) ∑ p X | Y ( x | y ) log p X | Y ( x | y ) , (2)</p><p>其中 p X | Y 是条件概率密度函数 [<xref ref-type="bibr" rid="hanspub.22433-ref5">5</xref>] [<xref ref-type="bibr" rid="hanspub.22433-ref6">6</xref>] 。</p><p>熵率：用来度量随机过程 X = { X t | t ∈ T } 的不确定性。对于一个离散的随机过程，熵率定义为一个渐近测度 [<xref ref-type="bibr" rid="hanspub.22433-ref7">7</xref>] ：</p><p>H ( X ) = lim t → ∞ H ( X t | X t − 1 , X t − 2 , ⋯ , X 1 ) , (3)</p><p>对于一阶平稳的马尔可夫过程，熵率有一个简单的形式 [<xref ref-type="bibr" rid="hanspub.22433-ref8">8</xref>] [<xref ref-type="bibr" rid="hanspub.22433-ref9">9</xref>] ：</p><p>H ( X ) = lim t → ∞ H ( X t | X t − 1 ) = lim t → ∞ H ( X 2 | X 1 ) = H ( X 2 | X 1 ) . (4)</p><p>第一个等式是由于一阶马尔可夫性，而第二个等式是平稳性的结果。有关更多详细信息，可以参考 [<xref ref-type="bibr" rid="hanspub.22433-ref10">10</xref>] 。</p><p>图上的随机路径：设 X = { X t | t ∈ T , X t ∈ V } 是带有非负的相似权 ω 的图 G = ( V , E ) 上的随机路径。转移概率定义为：</p><p>p i , j = P ( X t + 1 = v j | X t = v i ) = ω i , j ω i , (5)</p><p>其中 ω i = ∑ k : e i . k ∈ E ω i , k 是顶点 v i 发生事件之和，并且平稳分布为：</p><p>μ = ( μ 1 , μ 2 , ⋯ , μ | V | ) T = ( ω 1 ω T , ω 2 ω T , ⋯ , ω | V | ω T ) T , (6)</p><p>其中 ω T = ∑ i = 1 | V | ω i 是归一化常数。对于一个非连通图，平稳分布不是唯一的。但是，(6)式中的 μ 总是</p><p>平稳分布，容易证明得到 μ = P T μ ，其中 P = [ p ] i , j 是转移矩阵。随机路径的熵率为：</p><p>H ( X ) = H ( X 2 | X 1 ) = ∑ i μ i H ( X 2 | X 1 = v i ) = − ∑ i ∑ j ω i , j ω T log ω i , j ω T + ∑ i ω i ω T log ω i ω T (7)</p><p>下模性 [<xref ref-type="bibr" rid="hanspub.22433-ref11">11</xref>] ：设 E 是有限集，函数 f : 2 E → R 是下模函数当且仅当 ∀   A , B ⊆ E , ∀   a 1 , a 2 ∈ E ，有</p><p>f ( A ) + f ( B ) ≥ f ( A ∪ B ) + f ( A ∩ B ) .</p><p>或 f ( A ∪ { a 1 } ) − f ( A ) ≥ f ( A ∪ { a 1 , a 2 } ) − f ( A ∪ { a 2 } ) (8)</p><p>等价于： δ f a 1 ( A ) ≥ δ f a 1 ( A ∪ { a 2 } ) ，对于所有的 A ⊆ E 和 a 1 , a 2 ∈ E \ A ，其中</p><p>δ f a 1 ( A ) = f ( A ∪ { a 1 } ) − f ( A )</p><p>进一步地，如果 f ( A ) ≤ f ( A ∪ { a 1 } ) ，则称 f 是单调递增函数 [<xref ref-type="bibr" rid="hanspub.22433-ref12">12</xref>] 。</p><p>拟阵：设 E 是有限集， I 是 E 的子集组成的集合，拟阵是一个有序对 M = ( E , I ) ，并且满足：</p><p>1) Φ ∈ I 。</p><p>2) 如果 I 1 ∈ I 且 I ′ ⊆ I 1 ，则 I ′ ∈ I 。</p><p>3) 如果 I 1 ∈ I , I 2 ∈ I 且 | I 1 | &lt; | I 2 | ，则存在元素 e ∈ I 2 − I 1 ，使得 I 1 ∪ e ∈ I 。</p><p>我们提出聚类作为一个图的划分问题。将图划分为 k 个类，搜索图具有 k 连通子图的拓扑，然后最大化提出的目标函数。</p></sec><sec id="s4_2"><title>2.2. 图的构造</title><p>将数据集映射到图 G = ( V , E ) ，顶点表示该数据点和边权重表示两数据点之间的相似性。为了聚类，将数据集映射成K-最近邻域图。目标是划分图成为几个连通分支。选择一个边的子集 A ⊆ E ，产生一个子图 G ′ = ( V , A ) ，包含K-连通子图。再者，我们也假设每个顶点具有自环。虽然自环不影响图的划分，但它们对提出的随机路径模型是必要的。当某边不包含在 A 内时，增加与该边关联顶点的自环的权重，这样每个顶点的总发生的权保持常数。</p><p>如果边 e i , j 是被聚类时选择了，则顶点 v i 的自环的权为 ω i , i ，顶点 v j 的自环的权为 ω j , j ，边 e i , j 的权为 ω i , j 。</p><p>如果边 e i , j 是被聚类时未选择，则顶点 v i 的自环的权为 ω i , i → ω i , i + ω i , j ，顶点 v j 的自环的权为 ω j , j ← ω j , j + ω i , j ，边 e i , j 的权为 ω i , j ← 0 。</p></sec><sec id="s4_3"><title>2.3. 平衡函数</title><p>利用平衡函数鼓励大小相似的数据点分到同一个聚类中。设 A 是已经被选择的边集， N A 是图中被划分部分的数量， Z A 是聚类的分布。例如，设图对边集 A 的划分是 S A = { S 1 , S 2 , ⋯ , S N A } ，有</p><p>p Z A ( i ) = | S i | | V | ,   i = { 1 , 2 , ⋯ , N A } , (9)</p><p>并且平衡项为：</p><p>Β ( A ) ≡ H ( Z A ) − N A = − ∑ i p Z A ( i ) log ( p Z A ( i ) ) − N A . (10)</p><p>熵 H ( Z A ) 将大小相似的聚为一类，同时通过类与类数据点之间的最小化可以得到聚类数目 N A 。</p><p>推论2：2.2中构造的图上的平衡函数 Β : 2 E → R 是一个单调递增的下模函数。</p></sec><sec id="s4_4"><title>2.4. 聚类函数</title><p>目标函数是熵率和平衡函数的结合，因此得到了更加紧凑的、均匀的和平衡的聚类。</p><p>max A ⊆ E   F ( A ) s .t .   N A ≥ K (11)</p><p>其中 F ( A ) = H ( A ) + λ Β ( A ) 是目标函数。参数 λ ≥ 0 是平衡项的权重。目标函数也是单调递增的下模函数。</p><p>推论3：设 E 是边集， I 是边集的集合， A ⊆ E 满足：1) A 是无循环的；2) A 构成一个大于或等于K-连通分支的图划分，则 M = ( E , I ) 是一个拟阵。</p><p>在无循环的约束下，图的划分问题变成了在拟阵约束下子模函数的最大化问题，即：</p><p>max A ⊆ E   F ( A ) s .t .         A ∈ I (12)</p></sec></sec><sec id="s5"><title>3. 算法</title><p>对于求解模型(12)的贪婪算法如下：</p><disp-formula id="hanspub.22433-formula42"><graphic xlink:href="//html.hanspub.org/file/9-1540841x113_hanspub.png"  xlink:type="simple"/></disp-formula><p>拟阵约束的下模函数的最大化问题是组合优化研究中活跃的领域 [<xref ref-type="bibr" rid="hanspub.22433-ref13">13</xref>] ，Fisher [<xref ref-type="bibr" rid="hanspub.22433-ref14">14</xref>] 等给出了单调递增下模函数的最大化问题的以 1 2 近似上界的贪婪算法。同样地，我们也给出如下的性能保证：</p><p>定理：设 A o p t 是问题(15)的最优解， A g r e e d y 是应用上述算法得到的一个近似解，则</p><p>F ( A g r e e d y ) − F ( ∅ ) F ( A o p t ) − F ( ∅ ) ≥ 1 2</p><p>证明利用 [<xref ref-type="bibr" rid="hanspub.22433-ref14">14</xref>] theorem2.1直接得到。</p></sec><sec id="s6"><title>4. 实验</title><p>在聚类方面我们进行了大量的实验来评估所提出的算法方法，在整个实验中，使用了 λ ′ = 0.5 来测定平衡权重。该算法需要成对相似性数作为输入，这里使用的是高斯核 ω ( v i , v j ) = exp ( − d ( v i , v j ) 2 2 σ 2 ) ，这里 d ( v i , v j ) 是样本 i 和 j 之间的距离， σ 是核带宽。然后构造一个邻域图1，其中在群集之前，每个示例都连接到其30个最近的邻域。</p><p>在实验中，我们设置了聚类的个数对于所有算法的数字K，为了比较，使用以下两个标准的群集性能指标：1) 聚类精度(ca)和2) rand指数(ri)：</p><p>聚类精度是一种分类精度性能指标。设 ℂ = { C 1 , C 2 , ⋯ , C K } 是聚类的真分布。类似地，设 S = { S 1 , S 2 , ⋯ , S K } 是计算的聚类的分布。聚类精度为：</p><p>C A = max J 1 n ∑ i | C i ∩ S J ( i ) | ,</p><p>其中 n 是数据中的样本总数和 J 表示任意可能的排列 { 1 , 2 , ⋯ , K } 。</p><p>聚类指数是两者之间的相似性度量。设TP是相同的样本对的数量群集的真实性和估计聚类，设TN是在中的样本对的数目真实与估计的不同聚类聚类，设FP是对的示例对的数量在不同的集群中为真实的集群在同一个组中进行估计聚类，FN是样本对的数目这在同一个群中是真实的聚类，但在不同的集群中估计的聚类输出。聚类指数为：</p><p>R I = TP + TN TP + TN + FP + FN</p><p>我们比较我们的结果和已有的聚类算法包括AP、k-means、ncut，以及平面最大间隔聚类算法(cpmmc)<sup> </sup> [<xref ref-type="bibr" rid="hanspub.22433-ref16">16</xref>] ，它们代表了各种各样的聚类，结果如下：</p><p>图1. 图像来自自然场景识别数据集 [<xref ref-type="bibr" rid="hanspub.22433-ref15">15</xref>] 。从左到右，图像类是海岸、森林、高速公路、内部城市，山，开放的乡村，街道和高楼。由于不同的成像条件，相同类的图像表现出很大的变化地点和季节</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Clustering performance comparison: clustering accurac</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >数据</th><th align="center" valign="middle" >新方法</th><th align="center" valign="middle" >ncut</th><th align="center" valign="middle" >AP</th><th align="center" valign="middle" >k-means</th><th align="center" valign="middle" >cpmmc</th></tr></thead><tr><td align="center" valign="middle" >Ionosphere</td><td align="center" valign="middle" >92.54</td><td align="center" valign="middle" >83.19</td><td align="center" valign="middle" >70.94</td><td align="center" valign="middle" >70.00</td><td align="center" valign="middle" >75.48</td></tr><tr><td align="center" valign="middle" >Letters</td><td align="center" valign="middle" >94.44</td><td align="center" valign="middle" >94.28</td><td align="center" valign="middle" >91.83</td><td align="center" valign="middle" >93.38</td><td align="center" valign="middle" >95.02</td></tr><tr><td align="center" valign="middle" >Sattellite</td><td align="center" valign="middle" >98.50</td><td align="center" valign="middle" >97.50</td><td align="center" valign="middle" >62.30</td><td align="center" valign="middle" >94.10</td><td align="center" valign="middle" >98.79</td></tr><tr><td align="center" valign="middle" >Digits 0689</td><td align="center" valign="middle" >97.34</td><td align="center" valign="middle" >91.83</td><td align="center" valign="middle" >90.31</td><td align="center" valign="middle" >78.46</td><td align="center" valign="middle" >96.74</td></tr><tr><td align="center" valign="middle" >Digits 1279</td><td align="center" valign="middle" >98.23</td><td align="center" valign="middle" >91.70</td><td align="center" valign="middle" >85.51</td><td align="center" valign="middle" >89.32</td><td align="center" valign="middle" >94.52</td></tr><tr><td align="center" valign="middle" >Breast Cancers</td><td align="center" valign="middle" >95.78</td><td align="center" valign="middle" >92.09</td><td align="center" valign="middle" >93.32</td><td align="center" valign="middle" >91.04</td><td align="center" valign="middle" >n/a</td></tr><tr><td align="center" valign="middle" >Iris</td><td align="center" valign="middle" >93.01</td><td align="center" valign="middle" >86.67</td><td align="center" valign="middle" >86.00</td><td align="center" valign="middle" >83.33</td><td align="center" valign="middle" >n/a</td></tr><tr><td align="center" valign="middle" >Wine</td><td align="center" valign="middle" >96.63</td><td align="center" valign="middle" >98.31</td><td align="center" valign="middle" >93.82</td><td align="center" valign="middle" >96.63</td><td align="center" valign="middle" >n/a</td></tr><tr><td align="center" valign="middle" >Glass</td><td align="center" valign="middle" >50.98</td><td align="center" valign="middle" >55.41</td><td align="center" valign="middle" >40.19</td><td align="center" valign="middle" >45.33</td><td align="center" valign="middle" >n/a</td></tr><tr><td align="center" valign="middle" >Movement Libras</td><td align="center" valign="middle" >52.98</td><td align="center" valign="middle" >50.83</td><td align="center" valign="middle" >46.94</td><td align="center" valign="middle" >44.44</td><td align="center" valign="middle" >n/a</td></tr><tr><td align="center" valign="middle" >Natural Scenes</td><td align="center" valign="middle" >47.45</td><td align="center" valign="middle" >56.36</td><td align="center" valign="middle" >43.64</td><td align="center" valign="middle" >47.70</td><td align="center" valign="middle" >n/a</td></tr><tr><td align="center" valign="middle" >MPEG-7 Shapes</td><td align="center" valign="middle" >73.56</td><td align="center" valign="middle" >71.64</td><td align="center" valign="middle" >69.14</td><td align="center" valign="middle" >n/a</td><td align="center" valign="middle" >n/a</td></tr></tbody></table></table-wrap><p>表1. 聚类性能比较：聚类精度</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> Clustering performance comparison: clustering inde</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >数据</th><th align="center" valign="middle" >新方法</th><th align="center" valign="middle" >ncut</th><th align="center" valign="middle" >AP</th><th align="center" valign="middle" >k-means</th><th align="center" valign="middle" >cpmmc</th></tr></thead><tr><td align="center" valign="middle" >Ionosphere</td><td align="center" valign="middle" >0.87</td><td align="center" valign="middle" >0.72</td><td align="center" valign="middle" >0.59</td><td align="center" valign="middle" >0.58</td><td align="center" valign="middle" >0.65</td></tr><tr><td align="center" valign="middle" >Letters</td><td align="center" valign="middle" >0.89</td><td align="center" valign="middle" >0.89</td><td align="center" valign="middle" >0.85</td><td align="center" valign="middle" >0.88</td><td align="center" valign="middle" >0.92</td></tr><tr><td align="center" valign="middle" >Sattellite</td><td align="center" valign="middle" >0.98</td><td align="center" valign="middle" >0.95</td><td align="center" valign="middle" >0.53</td><td align="center" valign="middle" >0.89</td><td align="center" valign="middle" >0.97</td></tr><tr><td align="center" valign="middle" >Digits 0689</td><td align="center" valign="middle" >0.99</td><td align="center" valign="middle" >0.93</td><td align="center" valign="middle" >0.92</td><td align="center" valign="middle" >0.87</td><td align="center" valign="middle" >0.97</td></tr><tr><td align="center" valign="middle" >Digits 1279</td><td align="center" valign="middle" >0.95</td><td align="center" valign="middle" >0.92</td><td align="center" valign="middle" >0.87</td><td align="center" valign="middle" >0.90</td><td align="center" valign="middle" >0.96</td></tr><tr><td align="center" valign="middle" >Breast Cancers</td><td align="center" valign="middle" >0.86</td><td align="center" valign="middle" >0.85</td><td align="center" valign="middle" >0.88</td><td align="center" valign="middle" >0.84</td><td align="center" valign="middle" >n/a</td></tr><tr><td align="center" valign="middle" >Iris</td><td align="center" valign="middle" >0.92</td><td align="center" valign="middle" >0.86</td><td align="center" valign="middle" >0.85</td><td align="center" valign="middle" >0.83</td><td align="center" valign="middle" >n/a</td></tr><tr><td align="center" valign="middle" >Wine</td><td align="center" valign="middle" >0.97</td><td align="center" valign="middle" >0.98</td><td align="center" valign="middle" >0.92</td><td align="center" valign="middle" >0.95</td><td align="center" valign="middle" >n/a</td></tr><tr><td align="center" valign="middle" >Glass</td><td align="center" valign="middle" >0.72</td><td align="center" valign="middle" >0.70</td><td align="center" valign="middle" >0.66</td><td align="center" valign="middle" >0.70</td><td align="center" valign="middle" >n/a</td></tr><tr><td align="center" valign="middle" >Movement Libras</td><td align="center" valign="middle" >0.91</td><td align="center" valign="middle" >0.92</td><td align="center" valign="middle" >0.91</td><td align="center" valign="middle" >0.91</td><td align="center" valign="middle" >n/a</td></tr><tr><td align="center" valign="middle" >Natural Scenes</td><td align="center" valign="middle" >0.80</td><td align="center" valign="middle" >0.84</td><td align="center" valign="middle" >0.81</td><td align="center" valign="middle" >0.83</td><td align="center" valign="middle" >n/a</td></tr><tr><td align="center" valign="middle" >MPEG-7 Shapes</td><td align="center" valign="middle" >0.98</td><td align="center" valign="middle" >0.99</td><td align="center" valign="middle" >0.99</td><td align="center" valign="middle" >n/a</td><td align="center" valign="middle" >n/a</td></tr></tbody></table></table-wrap><p>表2. 聚类性能比较：聚类指数</p><p>从表1和表2，我们看到了所提出的算法在聚类中产生略好的性能。根据聚类精度度量，在12个数据集中的7个数据集上的算法优于其它算法。我们还获得更好的性能索引：在12个数据集中有8个更好。</p></sec><sec id="s7"><title>基金项目</title><p>陕西省自然科学基金资助项目(20125153025)；中国高等教育博士生研究基金资助项目(20126102110041)。</p></sec><sec id="s8"><title>文章引用</title><p>梁国宏,李 映,叶 萌,李炳杰. 拟阵约束下最大化子模函数的模型及其算法的一种熵聚类方法An Entropy Clustering Method for the Model and Its Algorithm of the Maximizing a Submodular Function Subject to a Matroid Constraint[J]. 计算机科学与应用, 2017, 07(10): 994-1001. http://dx.doi.org/10.12677/CSA.2017.710112</p></sec><sec id="s9"><title>参考文献 (References)</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.22433-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Liu, M.Y., Tuzel, O., Ramalingam, S. and Chellappa, R. (2014) Entropy-Rate Clustering: Cluster Analysis via Maximizing a Submodular Function Subject to a Matroid Constraint. IEEE Transactions on Pattern Analysis and Machine Intelligence.</mixed-citation></ref><ref id="hanspub.22433-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Ye, X. and Guo, L.J. (2012) Consructing Affinity Matrix in Spectral Clustering Based on Neighbor Propagation. Neu-rocomputing.</mixed-citation></ref><ref id="hanspub.22433-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Lin, H. and Bilmes, J. (2011) Word Alignment via Submodular Maximization over Matroids. Proceedings of the 49th Annual Meeting of the Association Computational Linguistics: Human Language Technologies—Short Papers, 2, 170-175.</mixed-citation></ref><ref id="hanspub.22433-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Cao, J., Chen, P., Zheng, Y. and Dai, Q. (2013) A Max-Flow-Based Similarity Measure for Spectral Clustering. ETRI Journal, 35.</mixed-citation></ref><ref id="hanspub.22433-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Chakrabarti, A. and Kale, S. (2013) Submodular Maximization Meets Streaming: Matchings, Matroids, and More. Data Structures and Algorithms.</mixed-citation></ref><ref id="hanspub.22433-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Liu, M.Y., Tuzel, O., Ramalingam, S. and Chellappa, R. (2011) Entropy Rate Superpixel Segmentation. IEEE Conference on Compute Vision and Pattern Recognition.</mixed-citation></ref><ref id="hanspub.22433-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Zhang, X., Li, J. and Yu, H. (2011) Local Density Adaptive Similarity Measurement for Spectral Clustering. IEEE Transactions on Pattern Analysis and Machine Intelligence, 32, 352-358.</mixed-citation></ref><ref id="hanspub.22433-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Cover, T.M. and Thomas, J.A. (1991) Elements of Information Theory. 2nd Edition, John Wiley &amp; Sons.  
&lt;br&gt;https://doi.org/10.1002/0471200611</mixed-citation></ref><ref id="hanspub.22433-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Hua, L. (2014) Application of Spectral Clustering and Entropy in Clustering. Zhejiang University, 25-29.</mixed-citation></ref><ref id="hanspub.22433-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Liu, M.-Y., Tuzel, O., Ramalingam, S. and Chellappa, R. (2014) Entropy-Rate Clustering: Cluster Analysis via Maximizing a Submodular Function Subject to a Matroid Constraint. Pattern Analysis and Machine Intelligence, 36, 99-105.</mixed-citation></ref><ref id="hanspub.22433-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Nemhauser, G.L., Wolsey, L.A. and Fisher, M.L. (1978) An Analysis of the Approximations for Maximizing Submodular Set Functions. Mathematical Programming, 14, 265-294. &lt;br&gt;https://doi.org/10.1007/BF01588971</mixed-citation></ref><ref id="hanspub.22433-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Oxley, J. (1992) Matroid Theory. Oxford Univ. Press, Oxford.</mixed-citation></ref><ref id="hanspub.22433-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Badanidoyuri, A. and Vondrak, J. (2014) Fast Algorithms for Maximizing Submodular Functions. Proceedings of the 25th Annual ACM-SIAM Symposium on Discrete Algorithms, 1497-1514.  
&lt;br&gt;https://doi.org/10.1137/1.9781611973402.110</mixed-citation></ref><ref id="hanspub.22433-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">Fisher, M.L., Nemhauser, G.L. and Wolsey, L.A. (1978) An Analysis of the Approximations for Maximizing Submodular Set Functions. Mathematical Programming, 8, 73-87. &lt;br&gt;https://doi.org/10.1007/BFb0121195</mixed-citation></ref><ref id="hanspub.22433-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">Oliva, A. and Torralba, A. (2001) Modeling the Shape of the Scene: A Holistic Representation of the Spatial Envelope. International Journal of Computer Vision, 42, 145-175. &lt;br&gt;https://doi.org/10.1023/A:1011139631724</mixed-citation></ref><ref id="hanspub.22433-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">Frey, B.J. and Dueck, D. (2007) Clustering by Passing Messages between Data Points. Science, 315, 972-976.  
&lt;br&gt;https://doi.org/10.1126/science.1136800</mixed-citation></ref></ref-list></back></article>