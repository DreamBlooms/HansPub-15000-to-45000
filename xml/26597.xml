<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2018.88133</article-id><article-id pub-id-type="publisher-id">CSA-26597</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20180800000_30247939.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于线纹尺的视觉检测标定方法
  The Calibrating Method of Linear-Structural Visual System Based on Line Scale Device
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>陈</surname><given-names>应松</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>崔</surname><given-names>州平</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>张</surname><given-names>慧洁</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>曾</surname><given-names>凤</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>成都工业学院，机械工程学院，四川 成都</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>31</day><month>07</month><year>2018</year></pub-date><volume>08</volume><issue>08</issue><fpage>1217</fpage><lpage>1223</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   设计了一种基于线纹尺的线结构光视觉传感器直接标定法，提出了线纹平面靶标与特征点提取算法，不需要建立几何成像数学模型，通过获取已知三维空间坐标特征点的图像坐标，建立亚像素物像索引表，直接在物像索引表中查找相应的图像坐标，得到相应的三维空间坐标实现系统的直接标定。本标定方法对平台运动控制操作方便、算法实现简洁。实验结果验证了本方法的有效性。 The paper designs a calibrating measurement method based on linear-structural visual sensor of line scale device. The paper proposes a calculation method, which combines line scale planar reference and special points. Through special graphical points in three-dimensional coordinates, we establish subpixel-image index table to directly calibrate the system. The calibrating measurement method is feasible in terms of operating the system, and the calculation process is more convenient. The results of the experiment also prove the effectiveness of this method. 
  
 
</p></abstract><kwd-group><kwd>视觉传感器，线纹尺，标定，线结构光, Visual Sensor</kwd><kwd> Line Scale Device</kwd><kwd> Calibration Method</kwd><kwd> Linear-Structural Light</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>基于线纹尺的视觉检测标定方法<sup> </sup></title><p>陈应松，崔州平，张慧洁，曾凤</p><p>成都工业学院，机械工程学院，四川 成都</p><p><img src="//html.hanspub.org/file/8-1541118x1_hanspub.png" /></p><p>收稿日期：2018年8月5日；录用日期：2018年8月20日；发布日期：2018年8月27日</p><disp-formula id="hanspub.26597-formula86"><graphic xlink:href="//html.hanspub.org/file/8-1541118x5_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>设计了一种基于线纹尺的线结构光视觉传感器直接标定法，提出了线纹平面靶标与特征点提取算法，不需要建立几何成像数学模型，通过获取已知三维空间坐标特征点的图像坐标，建立亚像素物像索引表，直接在物像索引表中查找相应的图像坐标，得到相应的三维空间坐标实现系统的直接标定。本标定方法对平台运动控制操作方便、算法实现简洁。实验结果验证了本方法的有效性。</p><p>关键词 :视觉传感器，线纹尺，标定，线结构光</p><disp-formula id="hanspub.26597-formula87"><graphic xlink:href="//html.hanspub.org/file/8-1541118x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2018 by authors and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/8-1541118x7_hanspub.png" /> <img src="//html.hanspub.org/file/8-1541118x8_hanspub.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>当今社会，基于图像的视觉检测作为非接触式方法已成为一种新的自动化检测技术，常用的方法包括：激光三角法、双目视觉法、相位法等。其中，激光三角法是一种发展较早的非接触三维测量技术，其具有速度快、精度高、抗干扰能力强、结构简单、维护方便，但是其价格昂贵、产品通用性差，制约着激光测量技术在国内的推广与应用。线结构光视觉传感器因价格低、精度高，使用方便已被广泛应用。</p><p>常用视觉传感器标定主要分为传统标定法和直接标定法两种。传统标定法先建立几何成像数学模型，分步求解模型中的未知参数值，最后标定光平面与摄像机的位置关系。直接标定方法先设置标定点，建立亚像素物像索引表，再在物像索引表中查找一一相应的图像坐标，不需要建立几何成像模型。</p><p>本文在基于现有直接标定算法的研究基础上，提出了一种基于线纹尺的线结构光视觉传感器直接标定，设计了线纹式的平面靶标与特征点提取算法，通过获取已知三维空间坐标特征点的图像坐标，实现系统的直接标定。</p></sec><sec id="s4"><title>2. 线纹式靶标的标定</title><sec id="s4_1"><title>2.1. 直接标定法原理</title><p>传统摄像机标定的基本方法是基于激光三角法测量，如图1所示。</p><p>分别做H<sub>1</sub>和M<sub>1</sub>到反射光H<sub>0</sub>M<sub>0</sub>上的垂线，得到点B和D，根据三角形相似原理，可以得到如下关系式：</p><p>H 1 B M 1 D = B Q D Q (1)</p><p>即：</p><p>y sin α x sin β = a − y cos α b + x cos β (2)</p><p>即：</p><p>y = a x sin β b sin α + x sin ( α + β ) (3)</p><p>y为被测物体表面高度的变化，x是像点M<sub>1</sub>和M<sub>2</sub>之间的相移，a是H<sub>0</sub>点的成像物距，b是H<sub>1</sub>点的成像相距。</p><p>在实际应用中的传统标定法，为了简化计算，常常忽略相机、线结构光中其他非线性畸变因素，从而标定精度较低，本文使用了不建立几何成像数学模型的直接标定法，直接建立三维空间坐标与图像坐标之间的映射关系，实现系统的直接标定，标定原理如图2所示。</p><p>图1. 激光三角法测量原理</p><p>图2. 直接标定方法原理</p><p>摄像机标定就是从二维图像获取三维信息，利用给定的标定点坐标(X, Y, Z)确定其相应的图像坐标(U,V)。选用4个特征点 a 1 , a 2 , b 1 , b 2 ，构成一个矩形区域，在像平面的对应点分别为 a ′ 1 , a ′ 2 , b ′ 1 , b ′ 2 ，缺失的矩形区域内的各像素点通过插值运算法获得，以获得与特征点一一对应的关系，这样建立该矩形区域的物像索引表I。为了确定不同高度的特征点c<sub>1</sub>、c<sub>2</sub>，，可在a<sub>1</sub>、a<sub>2</sub>所在平面与b<sub>1</sub>、b<sub>2</sub>所在平面之间增加标定面，相应特征点的增加，Z轴方向的标定精也随之提高，从而建立精度更高的物像索引表I。在实际测量中，将被测物体表面放置在矩形工作区域内，直接在I中查找对应的图像坐标，就可获得三维空间坐标进而完成测量。</p></sec><sec id="s4_2"><title>2.2. 线纹靶标特征点的提取</title><p>摄像机标定中最常用的平面靶标主要有棋盘靶标、网格靶标和圆点阵列靶标等，本文设计了线纹靶标，由一系列的平行线组成，相邻平行线的间距为1 mm，为保证线结构光与平面靶标上的平行线垂直，在靶标左右两端设置一组对齐刻线用于调整线结构光，如图3所示。进行标定时，将线结构光投射到平面靶标上产生一条光条，光条与平行线相交形成一组交点，平行线之间的间距为1 mm，所得交点的点间距也为1 mm，因此交点即可作为标定所需的特征点 [<xref ref-type="bibr" rid="hanspub.26597-ref1">1</xref>] - [<xref ref-type="bibr" rid="hanspub.26597-ref10">10</xref>] 。</p><p>获取特征点在图像坐标系下的坐标，其步骤如下：</p><p>1、提取光条中心</p><p>固定线纹尺，开启线结构光，获取如图4(a)的有光条投射靶标图像；关闭线结构光，得到如图4(b)的无光条投射的靶标图像。对两幅靶标图像进行相减，得到如图4(c)所示光条的投射区域。图像坐标系U轴沿光条方向分布，图像坐标系V轴即为光条的宽度，本文设置在10个像素以内，在V轴的列方向用9 &#215; 1的滑窗搜索，设阀值T = 100，计算每一列的灰度和，在进行搜索时，找到每一列滑窗内像素点的灰度和的最大值Max(sum(j))，且Max(sum(j)) &gt; T时，取该滑窗中心点作为该列光条中心点M<sub>j</sub>，在V</p><p>轴列方向区间设为 [ M j − 2 , M j + 2 ] ，为精确获得第j列光条中心的亚像素V轴坐标C<sub>j</sub>，本文采用了灰度重心法 [<xref ref-type="bibr" rid="hanspub.26597-ref10">10</xref>] ：</p><p>C j = ∑ i = M j − 2 M j + 2 [ i g r a y ( i , j ) ] ∑ i = M j − 2 M j + 2 g r a y ( i , j ) (4)</p><p>2、提取特征点图像坐标</p><p>当已知光条中心V轴坐标点集ΩC时，使用1&#215;4的滑窗逐列搜索图4(b)的点集ΩC，计算滑窗内像素点的灰度和分布曲线，并在灰度和分布曲线中的灰度和波谷，即黑色平行线与光条交点的U轴坐标。在提取过程中，首先对图4(b)采用2 &#215; 2方形模块进行平滑处理。对提取出来的灰度和波谷点重复步骤1中的灰度重心法，提取更为精确的交点U轴坐标。结合步骤1得到的光条中心V轴坐标点集ΩC，即可得到特征点点集ΩP的图像坐标值(U, V)，提取结果如图4(d)所示。</p><p>3、确定特征点三维空间坐标。</p><p>视场左侧的第一行是0刻度线，与光带的交点对应的第一行的x轴坐标是0，依次往右，可从等式(4)获得对应每个交叉点的三维坐标：</p><p>x n = ( n − 1 ) d (5)</p><p>式中，d = 1 mm， n = 1 , 2 , ⋯ , n ，n为特征点点集ΩP的元素个数。</p><p>图3. 线纹靶标</p><p>图4. 特征点提取</p></sec></sec><sec id="s5"><title>3. 标定过程及结果</title><p>为验证本文的标定方法的有效性，采用自主研发的线纹尺自动检定平台进行验证试验。标定Z轴高度为5 mm，标定X轴宽度为60 mm。</p><sec id="s5_1"><title>3.1. 标定过程</title><p>1、将线结构光视觉传感器安装在线纹尺自动检定平台上，将基于平面靶标制作成的线纹尺固定放置在位移平台的工作台上。开启线结构光视觉传感器，将线结构光投射到线纹尺上产生如图4(a)的光条，为保证光条在线纹尺两端的刻线上的读数一致并保证光条垂直于线纹尺上的平行线，可以调整线纹尺的位置。</p><p>2、采集三维空间坐标系XYZ平面上光平面内不同高度的靶标图像，分以下两步：</p><p>1) 确定Z轴的0基准面，调整位移平台Z轴的初始位置，使光条落在目标图像索引表的起始位置。</p><p>2) 以0.05 mm的步进距离操作位移平台以改变Z轴的位置，并在同一位置上，获取有光条投射和无光条投射两幅靶标图像。</p><p>3、提取靶标图像的特征点，得到各个Z轴上的特征点的三维空间X轴坐标和图像坐标值(U,V)坐标值。</p><p>4、建立一个二维数组I，确立的图像坐标值(U,V)与三维空间坐标值(X,Z)之间的对应关系。由于Z轴步进距离和相邻平行线间距的限制，相邻特征点元素在二维数组I中可能存在无赋值的元素，使用插值运算进行赋值，本文采用的是基于三角形的三次插值法。</p></sec><sec id="s5_2"><title>3.2. 实验结果</title><p>1、对Z轴高度的精度分析：将线结构光视觉传感器已标定的工作区域分成8个区域，由于量块材料的高反光性，会在实验过程中会产生光斑，测量区域没有使用中间区域。测量时用1.0000 mm的量块放置于工作台划分的区域上，测量高度为量块中心平面与工作台之间的高度差，重复测量多次，实验结果如表1所示。</p><p>2、对Z轴宽度的精度分析：在上述标定的工作区域，实验测量点为光条与平行线的交点，重复测量多次，部分实验结果如表2所示。</p><p>综合以上实验结果可知，采用文中提出的直接标定新方法标定的线结构光视觉传感器在Z轴、X轴方向上均具有较高的测量精度，Z轴方向的测量误差均值为0.053 mm，X轴方向的测量误差均值为0.180 mm，初步验证了标定方法的有效性。</p></sec></sec><sec id="s6"><title>4. 结束语</title><p>本文对平面靶标的直接标定法进行了改进，设计了基于线纹尺的平面靶标与特征点提取算法，不需要建立几何成像数学模型，通过获取已知三维空间坐标特征点的图像坐标，建立亚像素物像索引表，直</p><p>Table1. Measurement data in Z axis</p><p>表1. Z轴测量数据</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> Measurement data in X axi</title></caption><table><tbody><thead><tr><th align="center" valign="middle"  rowspan="2"  >序号</th><th align="center" valign="middle"  colspan="6"  >测量值</th></tr></thead><tr><td align="center" valign="middle" >L = 10.000</td><td align="center" valign="middle" >L = 20.000</td><td align="center" valign="middle" >L = 30.000</td><td align="center" valign="middle" >L = 40.000</td><td align="center" valign="middle" >L = 50.000</td><td align="center" valign="middle" >L = 60.000</td></tr><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" >9.876</td><td align="center" valign="middle" >20.037</td><td align="center" valign="middle" >30.192</td><td align="center" valign="middle" >40.120</td><td align="center" valign="middle" >50.196</td><td align="center" valign="middle" >60.241</td></tr><tr><td align="center" valign="middle" >2</td><td align="center" valign="middle" >10.198</td><td align="center" valign="middle" >21.764</td><td align="center" valign="middle" >30.056</td><td align="center" valign="middle" >39.978</td><td align="center" valign="middle" >49.387</td><td align="center" valign="middle" >60.173</td></tr><tr><td align="center" valign="middle" >3</td><td align="center" valign="middle" >10.076</td><td align="center" valign="middle" >19.864</td><td align="center" valign="middle" >29.762</td><td align="center" valign="middle" >40.387</td><td align="center" valign="middle" >49.637</td><td align="center" valign="middle" >59.912</td></tr><tr><td align="center" valign="middle" >4</td><td align="center" valign="middle" >10.127</td><td align="center" valign="middle" >19.931</td><td align="center" valign="middle" >29.872</td><td align="center" valign="middle" >39.721</td><td align="center" valign="middle" >49.879</td><td align="center" valign="middle" >59.892</td></tr><tr><td align="center" valign="middle" >5</td><td align="center" valign="middle" >9.679</td><td align="center" valign="middle" >20.182</td><td align="center" valign="middle" >30.216</td><td align="center" valign="middle" >39.578</td><td align="center" valign="middle" >50.174</td><td align="center" valign="middle" >59.886</td></tr><tr><td align="center" valign="middle" >6</td><td align="center" valign="middle" >9.96</td><td align="center" valign="middle" >19.587</td><td align="center" valign="middle" >29.031</td><td align="center" valign="middle" >40.201</td><td align="center" valign="middle" >50.132</td><td align="center" valign="middle" >60.167</td></tr><tr><td align="center" valign="middle" >平均值</td><td align="center" valign="middle" >9.986</td><td align="center" valign="middle" >20.2275</td><td align="center" valign="middle" >29.8548</td><td align="center" valign="middle" >39.9975</td><td align="center" valign="middle" >49.9008</td><td align="center" valign="middle" >60.0452</td></tr></tbody></table></table-wrap><p>表2. X轴测量数据</p><p>接在物像索引表中查找相应的图像坐标，得到相应的三维空间坐标实现系统的直接标定。该方法在自主研发的线纹尺标定实验平台上进行了验证，与传统方法相比，它具有更好的灵活性和实用性，易于操作和实现。实验证明，能够满足工业生产与测量的基本需求。</p></sec><sec id="s7"><title>文章引用</title><p>陈应松,崔州平,张慧洁,曾 凤. 基于线纹尺的视觉检测标定方法 The Calibrating Method of Linear-Structural Visual System Based on Line Scale Device[J]. 计算机科学与应用, 2018, 08(08): 1217-1223. https://doi.org/10.12677/CSA.2018.88133</p></sec><sec id="s8"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.26597-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">邝泳聪, 崔亮纯. 基于线纹尺的线结构光视觉传感器标定新方法[J]. 华南理工大学学报: 自然科学版, 2016, 44(1): 71-77.</mixed-citation></ref><ref id="hanspub.26597-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">徐德, 王麟琨, 谭民. 基于运动的手眼系统结构光参数标定[J]. 仪器仪表学报, 2005, 26(11): 1101-1106.</mixed-citation></ref><ref id="hanspub.26597-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">陈应松, 肖世德, 王文玺, 林静. 自主导航移动机器人视觉系统的一种标定方法[J]. 计算机工程与应用, 2009, 45(23): 190-192.</mixed-citation></ref><ref id="hanspub.26597-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">胥磊. 机器视觉技术的发展现状与展望[J]. 设各管理与维修, 2016(9): 7-9.</mixed-citation></ref><ref id="hanspub.26597-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">李炳银. 机器视觉及其在制造业中的应用分析[J]. 数字通信世界, 2017(9): 95.</mixed-citation></ref><ref id="hanspub.26597-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">王运哲, 白雁兵, 张博. 机器视觉系统的设计方法[J]. 现代显示, 2011, 22(11): 24-27.</mixed-citation></ref><ref id="hanspub.26597-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">叶青松. 基于机器视觉的工业检测研究[D]: [硕士学位论文]. 无锡: 江南大学, 2008.</mixed-citation></ref><ref id="hanspub.26597-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">董迪. 基于机器视觉的高精度测量系统研究[D]: [硕士学位论文]. 沈阳: 沈阳工业大学, 2016</mixed-citation></ref><ref id="hanspub.26597-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">聂振宇. 金属部件表面缺陷视觉检测系统研究[D]: [硕士学位论文]. 长沙: 中南大学, 2013.</mixed-citation></ref><ref id="hanspub.26597-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">贾波, 苏湿渝. 采用激光光刀的叶片三维面形测量方法[J]. 中国激光. 1992, 19(4): 271-275.</mixed-citation></ref></ref-list></back></article>