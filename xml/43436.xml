<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2021.116181</article-id><article-id pub-id-type="publisher-id">CSA-43436</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20210600000_91591782.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于非下采样轮廓波的红外与可见光图像融合
  Fusion of Infrared and Visible Images Based on NSCT
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>王</surname><given-names>雪梅</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>陈</surname><given-names>立</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>汪</surname><given-names>君</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>王</surname><given-names>琴</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>湖北省市场监督管理局行政许可技术评审中心，湖北 武汉</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>02</day><month>06</month><year>2021</year></pub-date><volume>11</volume><issue>06</issue><fpage>1755</fpage><lpage>1762</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   传统图像融合方法主要聚焦于图像细节信息整合，容易损失图像背景信息，本文借助于非下采样轮廓波的多尺度分解能力和模糊逻辑特性，提出一种红外与可见光图像融合的算法。首先，使用非下采样轮廓波获取图像高频成分和低频成分；其次，利用模糊逻辑规则整合低频成分，使用区域空间频率整合图像高频成分；最后，经过非下采样轮廓波逆变换得到融合图像。实验结果表明，与传统图像融合方法相比，本文算法能够较好地保留可见光图像的背景信息，同时凸显红外目标信息。 Traditional image fusion methods mainly focus on the integration of image details, which is easy to lose the background information. In this paper, by means of the multi-scale decomposition ability of non-subsampled contour waves and the characteristics of fuzzy logic, an algorithm of infrared and visible image fusion is proposed. Firstly, the high-frequency and low-frequency components of the image are obtained by using non-subsampled contour waves. Secondly, fuzzy rules were used to integrate low-frequency components, and regional clarity was used to integrate high-frequency components. Finally, the fused image is obtained by the inverse contourwave transform. Experimental results show that, compared with traditional image fusion methods, the proposed algorithm can retain the background information of visible images and highlight the infrared target information. 
  
 
</p></abstract><kwd-group><kwd>图像融合，红外与可见光图像，非下采样轮廓波，模糊逻辑, Image Fusion</kwd><kwd> Infrared and Visible Images</kwd><kwd> NSCT</kwd><kwd> Fuzzy Logic</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>摘要</title><p>传统图像融合方法主要聚焦于图像细节信息整合，容易损失图像背景信息，本文借助于非下采样轮廓波的多尺度分解能力和模糊逻辑特性，提出一种红外与可见光图像融合的算法。首先，使用非下采样轮廓波获取图像高频成分和低频成分；其次，利用模糊逻辑规则整合低频成分，使用区域空间频率整合图像高频成分；最后，经过非下采样轮廓波逆变换得到融合图像。实验结果表明，与传统图像融合方法相比，本文算法能够较好地保留可见光图像的背景信息，同时凸显红外目标信息。</p></sec><sec id="s2"><title>关键词</title><p>图像融合，红外与可见光图像，非下采样轮廓波，模糊逻辑</p></sec><sec id="s3"><title>Fusion of Infrared and Visible Images Based on NSCT<sup> </sup></title><p>Xuemei Wang, Li Chen, Jun Wang, Qin Wang</p><p>Administrative Licensing Technology Evaluation Center of Hubei Market Supervision Administration, Wuhan Hubei</p><p><img src="//html.hanspub.org/file/16-1542202x4_hanspub.png" /></p><p>Received: May 21<sup>st</sup>, 2021; accepted: Jun. 18<sup>th</sup>, 2021; published: Jun. 25<sup>th</sup>, 2021</p><p><img src="//html.hanspub.org/file/16-1542202x5_hanspub.png" /></p></sec><sec id="s4"><title>ABSTRACT</title><p>Traditional image fusion methods mainly focus on the integration of image details, which is easy to lose the background information. In this paper, by means of the multi-scale decomposition ability of non-subsampled contour waves and the characteristics of fuzzy logic, an algorithm of infrared and visible image fusion is proposed. Firstly, the high-frequency and low-frequency components of the image are obtained by using non-subsampled contour waves. Secondly, fuzzy rules were used to integrate low-frequency components, and regional clarity was used to integrate high-frequency components. Finally, the fused image is obtained by the inverse contour-wave transform. Experimental results show that, compared with traditional image fusion methods, the proposed algorithm can retain the background information of visible images and highlight the infrared target information.</p><p>Keywords:Image Fusion, Infrared and Visible Images, NSCT, Fuzzy Logic</p><disp-formula id="hanspub.43436-formula10"><graphic xlink:href="//html.hanspub.org/file/16-1542202x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2021 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/16-1542202x7_hanspub.png" /> <img src="//html.hanspub.org/file/16-1542202x8_hanspub.png" /></p></sec><sec id="s5"><title>1. 引言</title><p>可见光图像依赖于可见光的反射模式成像，其纹理细节信息丰富，能尽量地揭示场景的外在信息，适应于人眼视觉。红外图像根据目标或场景的热辐射强成像，它能有效地探测到隐藏在背景中的目标物，然而图像中场景信息对比度低、背景模糊，不利于目标检测、定位和跟踪等。随着探测技术需求的不断提高，将上述两类图像进行有效整合以提升探测器的探测能力具有重要的现实意义。</p><p>随着信息技术快速进步，基于不同理论的图像融合算法不断涌现。其中，多尺度变换模拟、适应人眼视觉尺度分析模型，且具有简单、高效的优点，在图像融合领域获得了快速的发展。如拉普拉斯算法(LP) [<xref ref-type="bibr" rid="hanspub.43436-ref1">1</xref>]、小波分析算法(WT) [<xref ref-type="bibr" rid="hanspub.43436-ref2">2</xref>]、曲率变换算法(CVT) [<xref ref-type="bibr" rid="hanspub.43436-ref3">3</xref>]、双树复小波变换(DTCWT) [<xref ref-type="bibr" rid="hanspub.43436-ref4">4</xref>] 等。然而，传统多尺度算法中所需的滤波器不具有自适应性 [<xref ref-type="bibr" rid="hanspub.43436-ref5">5</xref>]，导致针对具有不同特征信息的融合对象，图像融合效果会发生很大的变化。比如传统小波变换滤波器的适应性较差，且只能识别4个方向的图像特征，容易产生严重的频率或尺度混叠效应，直接降低图像融合算法的性能 [<xref ref-type="bibr" rid="hanspub.43436-ref5">5</xref>]。非下采样轮廓波变换(NSCT)是由非采样金字塔结构(NSP)和非采样方向滤波器组结构(NSDFB)两部分组成，它不仅继承了轮廓波变换多分辨率、多方向、各向异性等特征，而且还具有平移不变性，是一种超完备的多尺度变换方法 [<xref ref-type="bibr" rid="hanspub.43436-ref6">6</xref>]，在图像融合领域得到了广泛的应用。本文借助于NSCT优良的图像分解方法，设计一种适宜于红外与可见光图像融合算法。</p><p>现有基于多尺度变换图像融合算法研究主要聚焦于多尺度变换分析，在选取尺度特征信息融合规则时，忽略了图像自身特点，通常使用简单的权重方法进行信息融合，如平均、区域能量、极大值等，这样不仅容易导致信息冗余，还会在融合图像中湮没有用的特征信息。尤其是多尺度分解的低频信息包含了图像的主要能量，简单的平均整合会导致融合图像趋于昏暗。有趣的是，多数红外图像的目标与背景灰度信息与高斯模糊逻辑隶属度具有相似的结构，将高斯模糊逻辑用于融合红外与可将光图像的低频信息，不仅能有效地突出红外目标信息，还能保留细节丰富的可见光背景信息 [<xref ref-type="bibr" rid="hanspub.43436-ref7">7</xref>]。</p><p>为提高红外探测系统的探测能力，本文基于非下采样轮廓波和红外图像的灰度分布特点，提出了一种红外与可见光图像融合算法。实验结果表明本文算法对红外与可见光图像融合问题具有较强的适应性。</p></sec><sec id="s6"><title>2. 非下采样轮廓波</title><p>非采样轮廓波变换理论由Cunha 、Zhou J. P.提出 [<xref ref-type="bibr" rid="hanspub.43436-ref6">6</xref>]，由于它具有多尺度、多方向、各向异性等特征，以及平移不变性，已广泛地应用于图像融合领域。</p>非采样Contourlet变换的结构<p>非采样轮廓波变换是由非采样金字塔滤波器组(Non-subsampled Pyramid Filter Banks, NSPFB)和非采样方向滤波器组(Non-subsampled Directional Filter Bank, NSDFB)两部分所组成。如图1所示，其方法是先由NSP对图像信息进行多尺度，多分辨率变换，再由NSDFB进行多方向变换，即可实现图像的多尺度分解，分离图像的低频和高频信息。</p><p>图1. (a) NSCT变换结构示意图；(b) 理想频域划分</p><p>NSCT基于&#224;trous算法思想 [<xref ref-type="bibr" rid="hanspub.43436-ref6">6</xref>] 实现信息的分解和重构。在NSCT分解信息时虽然也是塔式结构，但每一层分解滤波器先完成上采样操作，构成了非下采样金字塔滤波器组NSP，如图2所示，同样在信息重构过程中，对合成滤波器先做上采样操作，再将信息输入合成滤波器。同时，在分解各层的方向信息时，也先完成上采样操作，构成非下采样方向滤波器组NSDFB，如图3所示，它是由在拉普拉斯变换中加入上采样操作设计形成，具备双通道非采样的塔式分解、重构能力。NSCT的特殊构造避免了对信息的上、下采样操作，使NSCT分解的子带信息与原信息尺寸大小相同，同时具有平移不变性的特点，可作为一种优秀的信息分析工具。</p><p>图2. 非下采样金字塔滤波器组</p><p>图3. 非下采样方向滤波器组</p></sec><sec id="s7"><title>3. 图像融合方法</title><p>图4为本文提出的红外与可见光图像融合框架。首先，使用NSCT对源图像进行多尺度分析，得到图像的高频成分和低频成分；然后，使用区域平均空间频率融合规则整合高频成分，使用高斯模糊逻辑整合低频成分；最后，使用NSCT的逆变换得到融合图像。</p><p>图4. 图像融合框架</p><sec id="s7_1"><title>3.1. 基于区域空间频率的高频成分融合</title><p>经NSCT分解获得的图像高频成分主要包含图像的细节纹理信息，因此有必要针对细节纹理信息选择合适的整合方法。空间频率能有效地反映图像的纹理细节丰富程度，在图像质量评价、图像增强等方面有众多的应用。根据高频信息的纹理、细节特点，本文选择区域空间频率为整合源图像的高频信息。图像区域空间频率可由下式表达。</p><p>S F ( x , y ) = ( 1 M &#215; N ∑ m = ( M − 1 ) / 2 ( M + 1 ) / 2 ∑ n = ( N − 1 ) / 2 ( N + 1 ) / 2 ( f ( x + m , y + n ) − f ( x + m − 1 , y + n − 1 ) ) 2 ) 1 / 2 (3-1)</p><p>分别获取红外与可见光图像的区域空间频率 S F i r 和 S F v i ，利用式(2)对高频系数进行整合：</p><p>F H ( x , y ) = S F v i ( x , y ) S F v i ( x , y ) + S F i r ( x , y ) f v i ( x , y ) + S F i r ( x , y ) S F v i ( x , y ) + S F i r ( x , y ) f i r ( x , y ) (3-2)</p><p>式(2)中 f v i ( x , y ) 和 f i r ( x , y ) 为源可见光图像和红外图像， F H ( x , y ) 为融合的高频信息。</p></sec><sec id="s7_2"><title>3.2. 基于高斯模糊逻辑的低频成分融合</title><p>图像经过多尺度分解获得的低频信息包含了图像的主要能量，简单的平均整合会导致融合图像趋于昏暗。而多数红外图像的目标与背景灰度信息与高斯模糊逻辑隶属度具有相似的结构，因此利用高斯模糊逻辑能很好地区分红外低频信息中的目标和背景区域信息，在信息整合时可以自适应地保留红外目标信息和可见光图像的背景细节信息。</p><p>F L ( i , j ) = η i r ( i , j ) A L ( i , j ) + η v i ( i , j ) B L ( i , j ) (3-3)</p><p>式(3-3)中的下标A、B和F分别代表红外，可见光和融合图像。 A L ( i , j ) 是低频成分在 ( i , j ) 位置的系数。 η i r 和 η v i 分别是红外低频信息中目标和背景的隶属度(权值)。确定红外低频成分隶属度的方法如公式(3-4)、(3-5)。</p><p>η v i ( i , j ) = exp [ − ( A L ( i , j ) − μ ) 2 2 ( k σ ) 2 ] (3-4)</p><p>η i r ( i , j ) = 1 − η v i ( i , j ) (3-5)</p><p>式(3-4)中的μ和σ分别是红外信息的均值和方差。k是一个用于优化融合结果的常数，其取值范围为1~3。在我们的试验中，k值均设置为1.5。</p><p>红外图像的灰度分布特性可用高斯模糊函数有效地表征，使用高斯模糊逻辑隶属度权重能很好地分配红外与可见光低频信息整合的权重信息，能在融合结果中凸显红外目标信息，同时保留丰富的可见光图像细节信息，提升红外与可见光图像融合算法的性能。</p><p>分别得到高频和低频成分的融合信息后，使用NSCT逆变换，即可获得最后的红外与可见光融合图像。</p></sec></sec><sec id="s8"><title>4. 实验与分析</title><p>为了验证本文算法的可行性和有效性，本文针对4组红外与可见光图像 [<xref ref-type="bibr" rid="hanspub.43436-ref1">1</xref>] [<xref ref-type="bibr" rid="hanspub.43436-ref5">5</xref>] [<xref ref-type="bibr" rid="hanspub.43436-ref7">7</xref>]，选取3种常用的性能较优的多尺度融合算法DTCWT [<xref ref-type="bibr" rid="hanspub.43436-ref4">4</xref>]，NSCT [<xref ref-type="bibr" rid="hanspub.43436-ref6">6</xref>] 和CVT [<xref ref-type="bibr" rid="hanspub.43436-ref3">3</xref>] 与本文算法进行比较。使用信息熵、标准差、空间频率和平均梯度 [<xref ref-type="bibr" rid="hanspub.43436-ref3">3</xref>] [<xref ref-type="bibr" rid="hanspub.43436-ref4">4</xref>] [<xref ref-type="bibr" rid="hanspub.43436-ref6">6</xref>]，4种客观指标对融合结果进行评价。</p><p>由各组融合结果可知，选取的参考融合算法的性能比较相近，这些融合结果普遍损失了源图像的部分细节信息，导致融合结果趋于平滑，图像层次感较差。相比于参考算法，本文算法融合结果中，红外目标信息更显著，可见光背景细节信息更丰富，图像对比度更优，视觉效果最佳，见图5~图8。</p><p>图5. 第1组可见光与红外图像融合结果对比</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Objective value comparison of the first fusion experimen</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >Methods</th><th align="center" valign="middle" >熵</th><th align="center" valign="middle" >平均梯度</th><th align="center" valign="middle" >空间频率</th><th align="center" valign="middle" >标准差</th></tr></thead><tr><td align="center" valign="middle" >CVT</td><td align="center" valign="middle" >6.704</td><td align="center" valign="middle" >4.3735</td><td align="center" valign="middle" >10.9842</td><td align="center" valign="middle" >29.1967</td></tr><tr><td align="center" valign="middle" >DTCWT</td><td align="center" valign="middle" >6.6894</td><td align="center" valign="middle" >4.1929</td><td align="center" valign="middle" >10.9001</td><td align="center" valign="middle" >28.9651</td></tr><tr><td align="center" valign="middle" >NSCT</td><td align="center" valign="middle" >6.7165</td><td align="center" valign="middle" >4.4055</td><td align="center" valign="middle" >11.0619</td><td align="center" valign="middle" >29.4857</td></tr><tr><td align="center" valign="middle" >本文方法</td><td align="center" valign="middle" >7.0426</td><td align="center" valign="middle" >4.4324</td><td align="center" valign="middle" >11.1526</td><td align="center" valign="middle" >36.8326</td></tr></tbody></table></table-wrap><p>表1. 第1组融合实验客观评价值比较</p><p>图6. 第2组可见光与红外图像融合结果对比</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> Objective value comparison of the second fusion experimen</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >Methods</th><th align="center" valign="middle" >熵</th><th align="center" valign="middle" >平均梯度</th><th align="center" valign="middle" >空间频率</th><th align="center" valign="middle" >标准差</th></tr></thead><tr><td align="center" valign="middle" >CVT</td><td align="center" valign="middle" >6.1286</td><td align="center" valign="middle" >3.2834</td><td align="center" valign="middle" >8.8807</td><td align="center" valign="middle" >18.4183</td></tr><tr><td align="center" valign="middle" >DTCWT</td><td align="center" valign="middle" >6.1046</td><td align="center" valign="middle" >3.2224</td><td align="center" valign="middle" >8.8281</td><td align="center" valign="middle" >18.2672</td></tr><tr><td align="center" valign="middle" >NSCT</td><td align="center" valign="middle" >6.1175</td><td align="center" valign="middle" >3.3456</td><td align="center" valign="middle" >8.9637</td><td align="center" valign="middle" >18.4548</td></tr><tr><td align="center" valign="middle" >本文方法</td><td align="center" valign="middle" >6.3767</td><td align="center" valign="middle" >3.3169</td><td align="center" valign="middle" >8.8521</td><td align="center" valign="middle" >25.009</td></tr></tbody></table></table-wrap><p>表2. 第2组融合实验客观评价值比较</p><p>图7. 第3组可见光与红外图像融合结果对比</p><table-wrap id="table3" ><label><xref ref-type="table" rid="table3">Table 3</xref></label><caption><title> Objective value comparison of the three fusion experimen</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >Methods</th><th align="center" valign="middle" >熵</th><th align="center" valign="middle" >平均梯度</th><th align="center" valign="middle" >空间频率</th><th align="center" valign="middle" >标准差</th></tr></thead><tr><td align="center" valign="middle" >CVT</td><td align="center" valign="middle" >6.7814</td><td align="center" valign="middle" >8.1701</td><td align="center" valign="middle" >20.8959</td><td align="center" valign="middle" >40.314</td></tr><tr><td align="center" valign="middle" >DTCWT</td><td align="center" valign="middle" >6.7571</td><td align="center" valign="middle" >8.1317</td><td align="center" valign="middle" >21.1552</td><td align="center" valign="middle" >40.6221</td></tr><tr><td align="center" valign="middle" >NSCT</td><td align="center" valign="middle" >6.7692</td><td align="center" valign="middle" >8.3571</td><td align="center" valign="middle" >21.4802</td><td align="center" valign="middle" >41.2466</td></tr><tr><td align="center" valign="middle" >本文方法</td><td align="center" valign="middle" >6.9436</td><td align="center" valign="middle" >8.2031</td><td align="center" valign="middle" >21.0525</td><td align="center" valign="middle" >42.2562</td></tr></tbody></table></table-wrap><p>表3. 第3组融合实验客观评价值比较</p><p>图8. 第4组可见光与红外图像融合结果对比</p><table-wrap id="table4" ><label><xref ref-type="table" rid="table4">Table 4</xref></label><caption><title> Objective value comparison of the four fusion experimen</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >Methods</th><th align="center" valign="middle" >熵</th><th align="center" valign="middle" >平均梯度</th><th align="center" valign="middle" >空间频率</th><th align="center" valign="middle" >标准差</th></tr></thead><tr><td align="center" valign="middle" >CVT</td><td align="center" valign="middle" >5.7627</td><td align="center" valign="middle" >2.0369</td><td align="center" valign="middle" >6.937</td><td align="center" valign="middle" >16.9105</td></tr><tr><td align="center" valign="middle" >DTCWT</td><td align="center" valign="middle" >5.7147</td><td align="center" valign="middle" >1.9872</td><td align="center" valign="middle" >6.9218</td><td align="center" valign="middle" >16.9808</td></tr><tr><td align="center" valign="middle" >NSCT</td><td align="center" valign="middle" >5.7353</td><td align="center" valign="middle" >2.0342</td><td align="center" valign="middle" >6.9658</td><td align="center" valign="middle" >17.2383</td></tr><tr><td align="center" valign="middle" >本文方法</td><td align="center" valign="middle" >6.0956</td><td align="center" valign="middle" >2.0586</td><td align="center" valign="middle" >7.3695</td><td align="center" valign="middle" >19.9347</td></tr></tbody></table></table-wrap><p>表4. 第4组融合实验客观评价值比较</p><p>为了进一步验证本文算法的有效性，使用熵、平均梯度、空间频率和标准差4类图像质量指标对各算法融合结果进行客观评价，这些指标的值越大，表明图像融合效果越好。由表1~4的数据可知，本文算法的平均梯度、空间频率和标准差明显优于其他参考算法，说明本文算法具有更优的对比度和清晰度，图像层次分明。尽管本文算法结果的平均梯度和空间频率不总是最优，但从各表中数据可知，本文算法的平均梯度和空间频率是较优的，表明图像细节信息较为丰富。</p></sec><sec id="s9"><title>5. 结论</title><p>本文针对传统多尺度图像融合方法容易弱化红外目标信息和降低图像对比度的问题，基于非下采样轮廓波变换和高斯模糊逻辑，提出一种简单、高效的红外与可见光图像融合算法。实验结果表明，本文提出的方法使融合结果拥有丰富的细节信息、显著的目标信息、更高的清晰度和对比度，其性能优于传统的多尺度融合方法。</p></sec><sec id="s10"><title>文章引用</title><p>王雪梅,陈 立,汪 君,王 琴. 基于非下采样轮廓波的红外与可见光图像融合Fusion of Infrared and Visible Images Based on NSCT[J]. 计算机科学与应用, 2021, 11(06): 1755-1762. https://doi.org/10.12677/CSA.2021.116181</p></sec><sec id="s11"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.43436-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">汪玉美, 陈代梅, 赵根保. 基于目标提取与拉普拉斯变换的红外和可见光图像融合算法[J]. 激光与光电子学进展, 2017, 54(1): 011002-1-011002-9.</mixed-citation></ref><ref id="hanspub.43436-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">张雨晨, 李江勇. 基于小波变换的中波红外偏振图像融合[J]. 激光与红外, 2020, 500(5): 68-72.</mixed-citation></ref><ref id="hanspub.43436-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">蒋婷婷, 周洁静. 基于改进Curvelet变换的图像融合算法研究[J]. 信息化研究, 2020, 45(3): 23-27.</mixed-citation></ref><ref id="hanspub.43436-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">王亚杰, 李殿起, 徐心和. 基于双树复小波变换的夜视图像融合[J]. 系统仿真学报, 2008(10): 2757-2761.</mixed-citation></ref><ref id="hanspub.43436-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Li, S., Yang, B. and Hu, J. (2011) Performance Comparison of Different Multi-Resolution Transforms for Image Fusion. Information Fusion, 12, 74-84. &lt;br&gt;https://doi.org/10.1016/j.inffus.2010.03.002</mixed-citation></ref><ref id="hanspub.43436-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">颜正恕, 王璟. 基于非下采样轮廓波变换耦合对比度特征的遥感图像融合算法[J]. 电子测量与仪器学报, 2020, 231(3): 33-40.</mixed-citation></ref><ref id="hanspub.43436-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Yin, S.F., Cao, L.C., Tan, Q.F., et al. (2010) Infrared and Visible Image Fusion Based on NSCT and Fuzzy Logic. IEEE International Conference on Mechatronics and Automation (ICMA), Xi’an, 4-7 August 2010, 671-675.  
&lt;br&gt;https://doi.org/10.1109/ICMA.2010.5588318</mixed-citation></ref></ref-list></back></article>