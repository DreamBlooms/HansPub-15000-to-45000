<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2018.87124</article-id><article-id pub-id-type="publisher-id">CSA-26097</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20180700000_55304784.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于优化图的半监督学习的行人检测
  Pedestrian Detection Based on Optimized Semi-Supervised Learning Method
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>杨</surname><given-names>绍红</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>李</surname><given-names>俊</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>姚</surname><given-names>拓中</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>宁波工程学院电子与信息工程学院，浙江 宁波</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>17</day><month>07</month><year>2018</year></pub-date><volume>08</volume><issue>07</issue><fpage>1125</fpage><lpage>1133</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   行人检测是当前机器视觉领域的挑战性课题之一。为了提高行人检测效率，提出一种基于优化图的半监督学习的行人检测算法。首先，提取每幅图像的形状上下文特征，并采用选择性搜索提取出行人候选区域建议框；然后，提出一种优化图的半监督学习方法，该方法融合包含行人的建议框之间距离尽量小，而不包含行人的建议框和包含行人的建议框之间的距离尽量大的先验知识构建模型，解决在行人检测过程中普遍存在训练数据不足，挖掘不到足够的先验知识，没有很好的泛化性问题；最后，将提出的算法与现有的行人检测方法进行实验比较，验证算法的有效性。 Pedestrian detection remains one of the challenging tasks in the area of computer vision. In order to improve the effectiveness of pedestrian detection, this paper proposes a new approach to pedestrian detection. First, the shape context features of each image are represented. Then, we specifically design a novel optimized graph-based semi-supervised learning for pedestrian detection, in which we maximize the average weighed distance between the suggestion box with pedestrians and the suggestion box without pedestrians, and minimize the average weighed distance between the suggestion boxes with pedestrian. Training data insufficiency and lack of generalization of learning method can be resolved. Compared with several other approaches, the experimental results show that this approach performs more effectively and accurately.
    
  
 
</p></abstract><kwd-group><kwd>行人检测，形状上下文特征，机器学习，半监督学习, Pedestrian Detection</kwd><kwd> Shape Context Features</kwd><kwd> Machine Learning</kwd><kwd> Semi-Supervised Learning</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>基于优化图的半监督学习的行人检测 <sup> </sup></title><p>杨绍红，李俊，姚拓中</p><p>宁波工程学院电子与信息工程学院，浙江 宁波</p><p><img src="//html.hanspub.org/file/8-1541082x1_hanspub.png" /></p><p>收稿日期：2018年7月4日；录用日期：2018年7月19日；发布日期：2018年7月26日</p><disp-formula id="hanspub.26097-formula77"><graphic xlink:href="//html.hanspub.org/file/8-1541082x5_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>行人检测是当前机器视觉领域的挑战性课题之一。为了提高行人检测效率，提出一种基于优化图的半监督学习的行人检测算法。首先，提取每幅图像的形状上下文特征，并采用选择性搜索提取出行人候选区域建议框；然后，提出一种优化图的半监督学习方法，该方法融合包含行人的建议框之间距离尽量小，而不包含行人的建议框和包含行人的建议框之间的距离尽量大的先验知识构建模型，解决在行人检测过程中普遍存在训练数据不足，挖掘不到足够的先验知识，没有很好的泛化性问题；最后，将提出的算法与现有的行人检测方法进行实验比较，验证算法的有效性。</p><p>关键词 :行人检测，形状上下文特征，机器学习，半监督学习</p><disp-formula id="hanspub.26097-formula78"><graphic xlink:href="//html.hanspub.org/file/8-1541082x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2018 by authors and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/8-1541082x7_hanspub.png" /> <img src="//html.hanspub.org/file/8-1541082x8_hanspub.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>行人检测是图像处理和计算机视觉领域中的研究热点，具有广阔的应用前景，例如智能公共安全、车辆辅助驾驶、人体行为分析、人机交互、机器人视觉导航等。目前有很多学者和研究机构热衷于行人检测的研究，有许多算法被提出，例如基于图像低层信息(颜色、形状、纹理等)的方法，Oren等 [<xref ref-type="bibr" rid="hanspub.26097-ref1">1</xref>] 提出的Haar行人特征描述子，利用水平、垂直、对角线三个方向的小波在不同尺度上提取特征。Ojala等 [<xref ref-type="bibr" rid="hanspub.26097-ref2">2</xref>] 提出的LBP是用于纹理分类的特征提取方法。Tuzel等 [<xref ref-type="bibr" rid="hanspub.26097-ref3">3</xref>] 利用多种不同特征的协方差矩阵来描述行人的局部特征。由于统计机器学习具有良好的函数学习和泛化能力，基于统计机器学习的行人检测方法是目前研究的热点，例如Szaras等 [<xref ref-type="bibr" rid="hanspub.26097-ref4">4</xref>] 利用卷积神经网络，通过学习算法自动选取分类特征。Grubb等 [<xref ref-type="bibr" rid="hanspub.26097-ref5">5</xref>] 利用两个SVM分类器进行行人检测。Viola等 [<xref ref-type="bibr" rid="hanspub.26097-ref6">6</xref>] 利用矩阵特征、AdaBoost和级联分类器实现了行人检测。还有一些算法将人体看成部位(头部、躯干、上肢和下肢)分类器进行行人检测，例如Mohan等 [<xref ref-type="bibr" rid="hanspub.26097-ref7">7</xref>] 将人体划分4个部分，将各个部分的分类器作为SVM的输入，建立一个组合的多层次的分类器检测行人。Felzenszwalb等 [<xref ref-type="bibr" rid="hanspub.26097-ref8">8</xref>] 基于图案结构模型，将滑动窗口与部位法相结构检测行人。Ali等 [<xref ref-type="bibr" rid="hanspub.26097-ref9">9</xref>] 利用Adaboost将姿态估计和特征选择结合的方法来实现行人检测。近年来采用深度学习进行行人检测的方法相继被提出，例如Jung等 [<xref ref-type="bibr" rid="hanspub.26097-ref10">10</xref>] 提出了用指导网络来协助训练深度卷积神经网络来提高行人检测的准确性。Tom&#232;等 [<xref ref-type="bibr" rid="hanspub.26097-ref11">11</xref>] 提出了一种基于深度学习的行人检测系统。</p><p>本文提出一种基于优化图的半监督学习的行人检测算法，首先提取每幅图像的形状上下文特征，并采用选择性搜索提取出行人候选区域建议框,然后融合包含行人的建议框之间距离尽量小，而不包含行人的建议框和包含行人的建议框之间的距离尽量大的先验知识构建一种优化图的半监督行人检测模型，利用该模型对图像的行人进行检测。</p></sec><sec id="s4"><title>2. 图的半监督学习理论</title><p>半监督学习算法是指给定一组训练样本，包括已标记的样本 { ( x 1 , y 1 ) , ⋯ , ( x l , y l ) } ∈ X l &#215; Y l 和未标记的样本 { x l + 1 , ⋯ , x l + u } ∈ X u ，通过对训练样本学习得到一个函数 F : X → Y ，使得基于该函数得到的决策函数在所有的点上预测准确。为了能够利用未标注样本所提供的有用信息，使学习模型得到理想的效果，半监督学习需要满足群聚假设和流形假设来进行机器学习。群聚假设是指聚在一起的样本点应该具有相同的类别。流形假设是指所有样本点基本上落在一个低维的流形面上，沿着流形相近的点具有较高的相似性。满足群聚假设和流形假设的半监督学习模型可以通过一个图的方法来表示出来，采用图的方法来逼近流形,利用图的理论来求解 [<xref ref-type="bibr" rid="hanspub.26097-ref12">12</xref>] [<xref ref-type="bibr" rid="hanspub.26097-ref13">13</xref>] 。</p><p>通过图的拉普拉斯矩阵的正则化方法介绍图的半监督学习算法的工作过程。</p><p>定义无向图的相似度矩阵W，其中w<sub>ij</sub>表示样本i和样本j的相似度，一般通过一个距离度量 d ( ⋅ , ⋅ ) 和正参数σ来定义，通过调整正参数σ来达到更好的效果：</p><p>w i j = { exp ( − ‖ x i − x j ‖ 2 σ ) ,   if     x i ≠ x j 0                   otherwise (1)</p><p>图的拉普拉斯矩阵定义为：</p><disp-formula id="hanspub.26097-formula79"><label>(2)</label><graphic position="anchor" xlink:href="//html.hanspub.org/file/8-1541082x14_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中，D是对角阵，第(i, i)个元素为矩阵W的第i行的和，即 d i = ∑ j = 1 n w i j 。</p><p>为了使机器学习f(x<sub>i</sub>)所有已标记点上取值接近于其真实值，选取合适的损失函数 L ( ⋅ , ⋅ ) 来惩罚预测值和真实值之间的差异，即一个好的分类器要求损失最小化：</p><p>L * ( f ) = min { ∑ i = 1 l L ( f ( x i ) , y i ) } (3)</p><p>其中，y<sub>i</sub>是训练样本的准确值，f(x<sub>i</sub>)是分类器的预测值。</p><p>基于图的正则化项定义为：</p><p>s ( f ) = f ′ L f = ∑ i , j = 1 n w i j ( f ( x i ) d i − f ( x j ) d j ) 2 (4)</p><p>基于图的拉普拉斯半监督学习的正则化框架定义为:</p><p>f * = arg min f ( x i ) { s + γ L * } = arg min f ( x i ) { f ′ L f + γ ∑ i = 1 l L ( f ( x i ) , y i ) } (5)</p><p>上面的正则化框架中共有两项，第一项表示样本在图上的平滑性，第二项表示损失函数。</p></sec><sec id="s5"><title>3. 基于优化的半监督学习的行人检测算法</title><sec id="s5_1"><title>3.1. 特征提取和行人候选区域选取</title><p>在人类视觉中，行人的轮廓特征为人类视觉识别物体提供了重要信息，即使在背景非常复杂的环境下或目标信息不是很完整的情况下，人类也可以轻易、准确的依据轮廓特征识别出行人，所以行人的轮廓特征是视觉识别重要的特征之一，可以为识别行人提供稳定和有效的信息。其中形状上下文特征(shape context, SC)方法是物体轮廓的重要描述方法之一 [<xref ref-type="bibr" rid="hanspub.26097-ref14">14</xref>] [<xref ref-type="bibr" rid="hanspub.26097-ref15">15</xref>] ，它以目标轮廓的有限点集合表示物体特征。形状上下文特征原理简单、易于实现，并且实验也证明了在自适应选取边界点的基础上，利用形状上下文特征计算得到的相似度可较好地反映图像目标类别，具有较强的可分性。</p><p>形状上下文特征方法在对目标图像进行轮廓检测的基础上，选择轮廓上的一组离散的有限点的集合 P = { p 1 , p 2 , ⋯ , p n } 表示物体，然后对于所选取的离散点集p中的任意一个点p<sub>i</sub>，计算与p中其他n − 1个点在图像形状中的相对位置关系，即以图像中特征点p<sub>i</sub>为坐标原点进行对数极坐标变换，假设以特征点p<sub>i</sub>为坐标原点，极坐标的半径上有n<sub>r</sub>个直方图区间(bin)和n<sub>θ</sub>个角度方向上的直方图区间，并且把边界方向也加入到了直方图的采样维度中，假设有n<sub>e</sub>个边界方向上的直方图区间，那么就构成了 r &#215; θ &#215; e 个区间，然后计算落在特征点p<sub>i</sub>每个区间中的边界点的数目h<sub>i</sub>(k)，这样就得到了特征点p的形状上下文特征，可以把其定义为：</p><p>(6)</p><p>类似，把p中的每个点表示成一组向量，就可以描述出目标图像的整个形状上下文特征。</p><p>选择性搜索(Selective Search) [<xref ref-type="bibr" rid="hanspub.26097-ref16">16</xref>] 是一种基于设计好的低级特征的区域建议框提取方法，是目前最流行的区域建议框提取方法之一。本文采用该方法对原始图像提取出行人候选区域建议框，然后根据行人候选区域建议框映射到图像的特征图上，在特征图中找到行人候选区域建议框对应图像的形状上下文特征。</p></sec><sec id="s5_2"><title>3.2. 优化图的半监督学习模型的构建</title><sec id="s5_2_1"><title>3.2.1. 构建优化图的半监督行人检测模型</title><p>设给定l个已标注训练样本 T l = { ( x 1 , y 1 ) , ⋯ , ( , x l , y l ) } ∈ X l &#215; Y l 和u个未标注训练样本 T u = { x l + 1 , ⋯ , x l + u } ∈ X u ，其中 x ∈ R d ，d为样本的维数。设训练样本中的前l<sup>+</sup>个为已标注的正样本 x i + ( 1 ≤ i ≤ l + ) ，中间的l<sup>−</sup>个为已标注的负样本 x i − ( l + &lt; i ≤ l + + l − ) ，后u个为未标注样本 x i ( l + + l − &lt; i ≤ l + u ) 。<sup>−</sup>令 ，表示已标注训练样本总数。令n = l + u，表示训练样本总数。一般令 y i ∈ { − 1 , 0 , 1 } 表示x<sub>i</sub>的准确标注，其中对于已标注的正样本 x i + ( 1 ≤ i ≤ l + ) ，令y<sub>i</sub> = 1；对于已标注的负样本 x i − ( l + &lt; i ≤ l + + l − ) ，令y<sub>i</sub> = −1；对于未标注样本 x i ( l + + l − &lt; i ≤ n ) ，令y<sub>i</sub> = 0。</p><p>为了提高行人检测的准确率，挖掘训练样本中具有行人的样本之间距离会较小，而具有行人的样本和不具有行人的样本之间距离会较大的知识，为构造行人检测提供有效的信息。具有行人样本之间的距离尽量小的优化问题为：</p><p>min ∑ i = 1 l + ∑ j = 1 l + w i , j (7)</p><p>具有行人的样本和不具有行人的样本之间距离尽量大的优化问题为：</p><p>max ∑ i = 1 l + ∑ j = l + l − w i , j (8)</p><p>公式(7)和公式(8)协同工作得到的优化目标函数可刻画为</p><p>W = arg min w i , j ∑ i = 1 l ∑ j = 1 l h i , j w i , j (9)</p><p>其中，h<sub>i,j</sub>代表样本x<sub>i</sub>和样本x<sub>j</sub>是否同类型，如果样本x<sub>i</sub>和样本x<sub>j</sub>同为正样本或同为负样本， h i , j = 1 ;如果样本x<sub>i</sub>和样本x<sub>j</sub>一个是正样本一个是负样本， h i , j = − 1 ；其它 ，即</p><p>h i j = { 1 ,     if   1 ≤ i , j ≤ l + − 1 ,     if   1 ≤ i ≤ l + ;   l + &lt; j ≤ l − 0 ,   otherwise (10)</p><p>把训练样本中具有行人的样本之间距离会较小，而具有行人的样本和不具有行人的样本之间距离会较大的知识作为判别的先验知识引入到图的半监督学习模型中，得到优化目标函数</p><disp-formula id="hanspub.26097-formula80"><label>(11)</label><graphic position="anchor" xlink:href="//html.hanspub.org/file/8-1541082x41_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中，D为对角阵，第(i,i)个元素为矩阵W第i行的和，即 d i = ∑ j = 1 n w i j ，F<sup>*</sup>为优化图半监督模型的优化函数。上面的优化模型中共有三项，第一项表示损失函数，第二项表示样本之间的距离，第三项表示样本在图上的平滑性。</p></sec><sec id="s5_2_2"><title>3.2.2. 优化图的半监督行人检测模型的分析</title><p>对公式(11)模型求解要比传统的图的半监督学习求解复杂，因为传统的半监督学习模型中优化的目标函数只求解f(x)，而在本文中，优化的目标函数中除了求解f(x)外，相似矩阵W也是求解的一部分。对优化模型的解法分析是先对W进行最小优化处理，得到的W的优化解后再用迭代正则化方法求解f(x)。</p><p>对于W进行最小优化处理的算法如下所示：</p><p>选取优化W的训练样本 D = { ( x 1 , 2 , w ′ 1 , 2 ) , ( x 1 , 3 , w ′ 1 , 3 ) , ⋯ , ( x l + , l − , w ′ l + , l − ) } ， ( x i , j ⊂ R m , w i , j ∈ R ) ,优化的目的是得到一个函数 W ″ 。假设 w ″ i , j 可以限制在一个不太复杂的函数类中，可以用输入量线性表示<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/8-1541082x47_hanspub.png" xlink:type="simple"/></inline-formula>，解决这一优化问题就变为寻找尽可能满足 w ″ i , j = w ′ i , j , i , j = 1 , 2 , ⋯ , l 的 w ″ i , j 。实际上解决这个问题的一个直观方法是用一个线性函数来回归(拟合、逼近)样本点。支持向量回归机具有非常好的非线性拟合能力，能够成功的应用于函数逼近方面，所以利用支持向量回归机解该函数，采用硬 ε -带支持向量回归机方法，原问题转化为</p><p>min ω , b ∑ i = 1 l ∑ j = 1 l ( w ′ i , j − 〈 ω ⋅ x i , j 〉 − b ) 2 (12)</p><p>采用最大间隔法的特征，可以表示为如下的原始优化问题</p><p>min w , b       1 2 ‖ ω ‖ 2 s .t .         ( ( ω ⋅ x i , j ) + b ) − w ′ i , j ≤ ε , i , j = 1 , ⋯ , l               w ′ i , j − ( ( ω ⋅ x i , j ) + b ) ≤ ε , i , j = 1 , ⋯ , l (13)</p><p>其中， 是事先取定的一个正数， ε 不敏感损失函数的含义是，当真实值与预测值之差不超过事先给定的 ε 时，则认为在该点的预测值是无损失的。</p><p>使用拉格朗日乘子法将其转化为对偶问题。对于公式(13)的每个约束引入拉格朗日乘子，得到如下拉格朗日函数</p><p>L ( ω , b , α ( * ) ) = 1 2 ‖ ω ‖ 2 − ∑ i = 1 l ∑ j = 1 l α i , j ( ε + w ′ i , j − ( ω ⋅ x i , j ) − b )                 − ∑ i = 1 l ∑ j = 1 l α i , j * ( ε − w ′ i , j + ( ω ⋅ x i , j ) + b ) (14)</p><p>其中<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/8-1541082x57_hanspub.png" xlink:type="simple"/></inline-formula>称为Lagrange乘子。</p><p>由极值条件： ∇ b L ( ω , b , α ( * ) ) = 0 ， ∇ ω L ( ω , b , α ( * ) ) = 0 得到</p><disp-formula id="hanspub.26097-formula81"><label>(15)</label><graphic position="anchor" xlink:href="//html.hanspub.org/file/8-1541082x60_hanspub.png"  xlink:type="simple"/></disp-formula><p>将上式代入拉格朗日函数，则原始的优化问题转化为如下的对偶问题(使用极小形式)</p><p>min a , a ( * )     1 2 ∑ i = 1 l ∑ j = 1 l ∑ m = 1 l ∑ n = 1 l ( a i , j * − a i , j ) ( a m , n * − a m , n ) ( x i , j ⋅ x m , n ) − ε ∑ i , j = 1 l ( a i , j * + a i , j ) s .t .   ∑ i = 1 , j l ( a i , j − a i , j * ) = 0 ,     a i , j ( * ) ≥ 0 , i , j = 1 , ⋯ , l (16)</p><p>求解上述对偶问题，得到回归函数：</p><p>w ″ ( x i , j ) = ∑ i = 1 l ∑ j = 1 l ( α i , j * − α i , j ) ( x ⋅ x i , j ) + b (17)</p><p>得到两个样本之间的距离预测函数 W ″ 后，用该函数计算训练样本中两个样本之间的距离 W * 作为训练样本两点之间的相似度，即得到无向图的相似度矩阵 W * ，图的拉普拉斯矩阵定义为</p><disp-formula id="hanspub.26097-formula82"><label>(18)</label><graphic position="anchor" xlink:href="//html.hanspub.org/file/8-1541082x66_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中D是对角阵，其中 D ( i , i ) 元素为矩阵 W * 第i行的和，即 d i ∑ j = 1 n w i j * 。然后，把得到的 W * 和D带入到公式(11)中，得到如下结果</p><p>(19)</p><p>最后，用图迭代的方法求解公式(19)。</p></sec></sec></sec><sec id="s6"><title>4. 实验结果及分析</title><p>为了验证算法的性能，本文选用二组数据集进行实验，一组是TUD行人数据库，该数据库的训练集提供了行人的矩形框信息、分割掩膜及其各部位(脚、小腿、大腿、躯干和头部)的大小和位置信息，训练集的正样本为1092个图像，负样本为192个非行人图像，测试集有508个图像；另一组是为了检测算法在实际应用中的性能，从《美丽心灵》、《老友记》等影视剧中选取200张图像帧作为测试数据，其中150张是有行人的图像，50张为没有行人的图像。</p><p>查全率(recall)和查准率(precision)能够很好的评价算法的错误检测和漏检测情况，所以本文采用查全率和查准率检测算法的性能，查全率和查准率分别定义如下：</p><p>(20)</p><p>precision = N c N c + N f (21)</p><p>其中，N<sub>c</sub>为正确的检测数量,N<sub>m</sub>为漏掉的检测数量，N<sub>f</sub>为错误的检测数量。好的标注算法应该具有较高的查全率和查准率。</p><p>实验中形状上下文特征提取的相关参数取值为：极坐标半径上的直方图区间r取值2；角度方向上的直方图区间θ取值12；边界方向上的直方图区间e取值为4(分别是边缘方向为0˚，45˚，90˚，135˚)，这样每一个特征点的形状上下文由2 &#215; 12 &#215; 4 = 96个区间来描述，如图1所示。为了表达清晰，我们把图1的对数极坐标直方图转化为图2的形式，一个格代表形状上下文的一个区间。</p><p>在实验中，对于优化的图的半监督学习，我们首先规定训练样本中两个样本之间的距离为0或1，</p><p>图1. 对数极坐标变换图。(a) 方向为0˚边缘的对数极坐标变换图；(b) 方向为45˚边缘的对数极坐标变换图；(c) 方向为90˚边缘的对数极坐标变换图；(d) 方向为135˚边缘的对数极坐标变换图</p><p>图2. 对数极坐标直方图</p><p>如果两个样本都是正样本，则样本之间的距离为0；如果两个样本是异样本，则样本之间的距离为1，然后对样本进行学习，得到样本之间的距离预测函数，再用预测函数对训练样本集进行计算得到样本之间的距离矩阵，最后用优化图的半监督学习算法对训练样本进行训练，得到行人检测模型。</p><p>为了验证基于优化图的半监督学习的行人检测算法的性能，选取基于图的拉普拉斯半监督学习方法(GLSS)的行人检测算法进行了比较。基于图的拉普拉斯半监督学习的行人检测算法同样采用图像的形状上下文特征作为图像的特征，用基于图的拉普拉斯半监督学习进行行人检测，用SC + GLSS表示该算法。实验结果比较如表1所示。从表中可以看出用本文提出的算法对行人检测的平均准确率高于用图的拉普拉斯半监督学习的平均准确率，所以通过挖掘训练样本中具有行人的样本之间距离会较小，而具有行人的样本和不具有行人样本之间的距离会较大的先验知识可以有效地提高行人检测的准确率。</p><p>为了测试算法的性能，本文也选取了传统的HOG + SVM行人检测算法与本算法进行比较。传统的HOG + SVM行人检测算法是目前行人检测的经典方法。实验结果比较如表2所示。从表2中可以看出本文提出的行人检测算法具有一定的准确性。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Experiment Comparison with SC + GLS</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" >Recall</th><th align="center" valign="middle" >Precision</th></tr></thead><tr><td align="center" valign="middle" >Our method</td><td align="center" valign="middle" >0.762</td><td align="center" valign="middle" >0.613</td></tr><tr><td align="center" valign="middle" >SC+GLSS</td><td align="center" valign="middle" >0.719</td><td align="center" valign="middle" >0.497</td></tr></tbody></table></table-wrap><p>表1. 本算法与SC + GLSS的实验比较</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> Experiment Comparison with HOG + SV</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" >Recall</th><th align="center" valign="middle" >Precision</th></tr></thead><tr><td align="center" valign="middle" >Our method</td><td align="center" valign="middle" >0.764</td><td align="center" valign="middle" >0.613</td></tr><tr><td align="center" valign="middle" >HOG+SVM</td><td align="center" valign="middle" >0.734</td><td align="center" valign="middle" >0.560</td></tr></tbody></table></table-wrap><p>表2. 本算法与HOG + SVM的实验比较</p></sec><sec id="s7"><title>5. 结束语</title><p>本文提出一种新的基于优化图的半监督学习的行人检测算法。该算法使用形状上下文特征作为视觉特征，考虑目前机器学习算法中普遍存在训练数据不足和忽略了类间和类内信息问题，提出结合具有行人的建议框之间距离会较小，而含有行人的建议框和不含行人的建议框之间距离会较大的先验知识构建一个优化图的半监督机器学习模型，通过构建的优化的半监督学习模型对行人检测进行学习和检测，实验结果表明本算法对行人检测具有一定的准确性。</p></sec><sec id="s8"><title>基金项目</title><p>浙江省大学生科技创新活动计划暨新苗人才计划(2017R424001)；浙江省自然科学基金(LY18F010020)；浙江省重点研发计划项目(2018C01086)。</p></sec><sec id="s9"><title>文章引用</title><p>杨绍红,李 俊,姚拓中. 基于优化图的半监督学习的行人检测Pedestrian Detection Based on Optimized Semi-Supervised Learning Method[J]. 计算机科学与应用, 2018, 08(07): 1125-1133. https://doi.org/10.12677/CSA.2018.87124</p></sec><sec id="s10"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.26097-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Oren, M., Papageorgiou, C., Sinha, P., et al. (1997) Pedestrian Detection Using Wavelet Template. 17-19 June 1997, San Juan, 193-199.</mixed-citation></ref><ref id="hanspub.26097-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Ojala, T. and Harwood, I. (1996) A Comparative Study of Texture Measures with Classification Based on Feature Dis-tributions. Pattern Recognition, 29, 51-59. &lt;br&gt;https://doi.org/10.1016/0031-3203(95)00067-4</mixed-citation></ref><ref id="hanspub.26097-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Tuzel, O., Porikli, F. and Meer, P. (2008) Pedestrian Detection via Classification on Riemannian Manifolds. IEEE Transactions on Pattern Analysis &amp; Machine Intelli-gence, 30, 1713. &lt;br&gt;https://doi.org/10.1109/TPAMI.2008.75</mixed-citation></ref><ref id="hanspub.26097-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Szarvas, M., Yoshizawa, A., Yamamoto, M., et al. (2005) Pedes-trian Detection with Convolutional Neural Networks. IEEE Proceedings Intelligent Vehicles Symposium, 224-229.</mixed-citation></ref><ref id="hanspub.26097-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Grubb, G., Zelinsky, A., Nilsson, L., et al. (2004) 3D Vision Sensing for Improved Pedestrian Safety. Intelligent Vehicles Symposium, 19-24.</mixed-citation></ref><ref id="hanspub.26097-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Viola, P. and Jones, M.J. (2004) Robust Real-Time Face Detection. International Journal of Computer Vision, 57, 137-154. &lt;br&gt;https://doi.org/10.1023/B:VISI.0000013087.49260.fb</mixed-citation></ref><ref id="hanspub.26097-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Mohan, A., Papageorgiou, C. and Poggio, T. (2001) Exam-ple-Based Object Detection in Images by Components. IEEE Transactions on Pattern Analysis and Machine Intelligence, 23, 349-361. &lt;br&gt;https://doi.org/10.1109/34.917571</mixed-citation></ref><ref id="hanspub.26097-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Felzenszwalb, P.F., Girshick, R.B., Mcallester, D., et al. (2014) Object Detection with Discriminatively Trained Part-Based Models. IEEE Transactions on Pattern Analysis &amp; Machine Intelligence, 47, 6-7.</mixed-citation></ref><ref id="hanspub.26097-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Ali, K., Fleuret, F., Hasler, D., et al. (2009) Joint Pose Estimator and Feature Learning for Object Detection. IEEE International Conference on Computer Vision, 1373-1380.</mixed-citation></ref><ref id="hanspub.26097-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Jung, S.I. and Hong, K.S. (2017) Deep Network Aided by Guiding Network for Pedestrian Detec-tion. Pattern Recognition Letters, 90. &lt;br&gt;https://doi.org/10.1016/j.patrec.2017.02.018</mixed-citation></ref><ref id="hanspub.26097-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Tomè, D., Monti, F., Baroffio, L., et al. (2015) Deep Convolutional Neural Networks for Pedestrian Detection. Signal Processing Image Communication, 47, 482-489.</mixed-citation></ref><ref id="hanspub.26097-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">胡崇海. 基于图的半监督机器学习[D]: [博士学位论文]. 杭州: 浙江大学, 2008.</mixed-citation></ref><ref id="hanspub.26097-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">高隽, 谢昭. 图像理解理论与方法[M]. 北京: 科学出版社, 2009.</mixed-citation></ref><ref id="hanspub.26097-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">Belongie, S., Malik, J., et al. (2002) Shape Matching and Object Recognition Using Shape Contexts. IEEE Transactions on Pattern Analysis and Machine Intelligence, 24, 509-522. &lt;br&gt;https://doi.org/10.1109/34.993558</mixed-citation></ref><ref id="hanspub.26097-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">Mori, G., Belongi, S., et al. (2005) Efficient Shape Matching Using Shape Contexts. IEEE Transactions on Pattern Analysis and Machine Intel-ligence, 27, 1832-1837. &lt;br&gt;https://doi.org/10.1109/TPAMI.2005.220</mixed-citation></ref><ref id="hanspub.26097-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">Uijlings, J.R., Sande, K.E., Gevers, T., et al. (2013) Se-lective Search for Object Recognition. International Journal of Computer Vision, 104, 154-171. &lt;br&gt;https://doi.org/10.1007/s11263-013-0620-5</mixed-citation></ref></ref-list></back></article>