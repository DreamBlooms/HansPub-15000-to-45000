<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2019.98177</article-id><article-id pub-id-type="publisher-id">CSA-31836</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20190800000_79681001.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于分水岭和强度分层的机器人视觉认知方法
  Robot Visual Cognition Method Based on Watershed and Intensity Stratification
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>王</surname><given-names>天琪</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>贺</surname><given-names>乃宝</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>高</surname><given-names>倩</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>赵</surname><given-names>俊杰</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>江苏理工学院，江苏 常州</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>09</day><month>08</month><year>2019</year></pub-date><volume>09</volume><issue>08</issue><fpage>1576</fpage><lpage>1583</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   应用图像矩进行工件识别时，对于随机放置或重叠的工件，由于手眼相机拍摄的原始图像中不可避免地存在各类噪声和灰度值相同但不属于同一工件的情况，因而无法直接计算目标工件的图像矩。针对这类问题，本文提出了一种基于分水岭分割和强度分层算法的视觉认知方法。该方法首先通过手眼相机获取实时图像，由专用的分水岭算法分割工件图像；将分割后的图像转换为灰度图像；然后根据不同的灰度值，将分割出来的工件图像进行强度分层，得到不同强度的切片，即各个工件的二值图像。最后使用基于边界的方法计算其中一个工件的图像矩。实验结果表明，该方法能够满足特定的视觉伺服作业。 When the image moment is applied for workpiece recognition, for the randomly placed or overlapping workpiece, because of the unavoidable existence of all kinds of noise and gray value in the original image taken by the hand-eye camera, but not the same workpiece, therefore, the image moments of the target workpiece cannot be calculated directly. In this paper, a visual cognitive method based on watershed segmentation and intensity delamination is proposed. Firstly, the real-time image is obtained by hand-eye camera, and the workpiece image is segmented by a special watershed algorithm; the segmented image is converted into gray image; then, according to different gray values, the segmented workpiece image is stratified with intensity. Different strength slices are obtained, that is, binary images of each workpiece. Finally, an example is given to calculate the image moments of one of the workpieces. Experimental results show that the proposed method can meet specific visual servo operations. 
   
   
    
  
 
</p></abstract><kwd-group><kwd>视觉伺服，分水岭，强度分层，图像矩, Visual Servo</kwd><kwd> Watershed</kwd><kwd> Strength Stratification</kwd><kwd> Image Moment</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>基于分水岭和强度分层的机器人视觉认知方法<sup> </sup></title><p>王天琪<sup>*</sup>，贺乃宝，高倩，赵俊杰</p><p>江苏理工学院，江苏 常州</p><disp-formula id="hanspub.31836-formula23"><graphic xlink:href="//html.hanspub.org/file/14-1541506x5_hanspub.png"  xlink:type="simple"/></disp-formula><p>收稿日期：2019年8月1日；录用日期：2019年8月16日；发布日期：2019年8月23日</p><disp-formula id="hanspub.31836-formula24"><graphic xlink:href="//html.hanspub.org/file/14-1541506x6_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>应用图像矩进行工件识别时，对于随机放置或重叠的工件，由于手眼相机拍摄的原始图像中不可避免地存在各类噪声和灰度值相同但不属于同一工件的情况，因而无法直接计算目标工件的图像矩。针对这类问题，本文提出了一种基于分水岭分割和强度分层算法的视觉认知方法。该方法首先通过手眼相机获取实时图像，由专用的分水岭算法分割工件图像；将分割后的图像转换为灰度图像；然后根据不同的灰度值，将分割出来的工件图像进行强度分层，得到不同强度的切片，即各个工件的二值图像。最后使用基于边界的方法计算其中一个工件的图像矩。实验结果表明，该方法能够满足特定的视觉伺服作业。</p><p>关键词 :视觉伺服，分水岭，强度分层，图像矩</p><disp-formula id="hanspub.31836-formula25"><graphic xlink:href="//html.hanspub.org/file/14-1541506x7_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2019 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/14-1541506x8_hanspub.png" /> <img src="//html.hanspub.org/file/14-1541506x9_hanspub.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>Hutchinson [<xref ref-type="bibr" rid="hanspub.31836-ref1">1</xref>] 等将视觉伺服按照目标值输入法的不同，分为位置基准法和特征基准法。其中，特征基准法在图像空间直接进行反馈控制，利用提取的视觉信息获得被识别目标在图像空间上的特征量，与期望的图像特征量形成误差，使用任务函数法控制机器人运动。特征基准法因为不需要对图像进行解释，故实时性好；不必计算目标对象和机器人末端执行器的位姿，故对机器人机构学模型的精确度具有很高的容忍度。Chaumette [<xref ref-type="bibr" rid="hanspub.31836-ref2">2</xref>] 等推导了最易提取的点、线和圆特征的雅克比矩阵。此后Chaumette提出了将图像矩 [<xref ref-type="bibr" rid="hanspub.31836-ref3">3</xref>] 应用到视觉伺服，采用基于二阶矩的方向和两个不变量矩，实现了对姿态的视觉伺服控制。Lin [<xref ref-type="bibr" rid="hanspub.31836-ref4">4</xref>] 等结合先验知识定义了4个最低矩不变量，实现了图像追踪。基于图像矩的视觉伺服，利用全局描述子与期望图像矩进行匹配，鲁棒性强 [<xref ref-type="bibr" rid="hanspub.31836-ref5">5</xref>] 。近年来，有叶国强 [<xref ref-type="bibr" rid="hanspub.31836-ref6">6</xref>] 等结合学习特征，毛优新等 [<xref ref-type="bibr" rid="hanspub.31836-ref7">7</xref>] 结合神经网络将图像矩用于视觉伺服，在应用方面则有具有代表性的需要实现眼注视任务的喷雾机器人等 [<xref ref-type="bibr" rid="hanspub.31836-ref8">8</xref>] 取得了实验验证。</p><p>为了将基于图像矩的视觉伺服技术广泛地应用于各种作业环境下，必须寻找一种适用于复杂环境的图像分割算法，从而有效地计算图像矩。为此，本文针对堆叠工件图像特点，给出了一种图像信息提取算法。利用基于Canny边缘检测为梯度函数的分水岭算法分割出目标的区域，然后利用强度分层算法，以切片的形式得到各个工件的二值图像。最后举例计算工件的相关特征矩，提取目标工件数量、位姿信息。该方法能够为堆叠目标下的图像矩提供参考，不同于单个的目标检测，能够提高视觉信息的获取效率。</p></sec><sec id="s4"><title>2. 分水岭分割(Watershed Segmentation)</title><p>S. Beucher [<xref ref-type="bibr" rid="hanspub.31836-ref9">9</xref>] 等最早提出将分水岭算法用于图像处理，因其在图像边缘检测中独到的思想，独立于其他的分割算法。分水岭算法可以得到单一像素宽度的连续的边界，能检测出图像中粘连物体的微弱边缘并形成连续封闭的分割边缘，特别适用于堆叠工件的图像分割。但是，传统的分水岭算法存在过分割问题，严重干扰了目标工件的真实边缘提取。高丽 [<xref ref-type="bibr" rid="hanspub.31836-ref10">10</xref>] 等人提出在梯度图像低频部分标记局部极小值，然后将标记的极小值叠加到原始梯度图像形成标记图像，由此设计了一种结合频域低通滤波和H-minima技术的改进分水岭算法。虽然过分割现象得到明显抑制，但存在边缘定位不准和弱边缘提取困难等问题，不利于进行相似目标在堆叠情况下的边缘检测。为了解决这类问题，本文采用Canny算子 [<xref ref-type="bibr" rid="hanspub.31836-ref11">11</xref>] 进行边缘检测代替传统的梯度图像，并通过标记局部极大值来得到更好的前景标记。</p><sec id="s4_1"><title>2.1. Canny边缘检测(Canny Edge Detection)</title><p>Canny边缘检测算子对于不同类型的边缘，均具有良好的性噪比，优异的定位性能、对单一边缘产生多个相应的低概率性和对虚假边缘相应的最大抑制能力。这些性能对具有重叠工件的工件堆图像的边缘提取有很好的效果。其流程图如图1所示。</p><p>图1. Canny算子流程图</p><p>针对工件堆图像中出现的重叠边缘，Canny算法具有较高的性噪比，</p><p>S N R = | ∫ − ω + ω G ( − x ) f ( x ) d x | n 0 ∫ − ω + ω f 2 ( x ) d x (1)</p><p>其中 f ( x ) 是区间为 [ − ω , + ω ] 的滤波脉冲相应， G ( − x ) 为边缘函数， n 0 为高斯噪声均方根。由此可知，信噪比越大，提取边缘的精度越大。Canny算子不但能够准确检测出图像真实边缘，而且不会检测出非边缘点。</p><p>为了便于提取工件的位姿信息，需要准确定位工件的边缘信息， L o c a l i z a t i o n 数值越大，定位精度将越高。Canny算子检测出的边缘点能够极大程度接近实际边缘的中心越大。</p><p>L o c a l i z a t i o n = | ∫ − ω + ω G ′ ( − x ) f ′ ( x ) d x | n 0 ∫ − ω + ω f ′ 2 ( x ) d x (2)</p><p>因为工件是堆叠放置的，所以会形成遮挡、阴影等不利于边缘检测的因素，进而导致相关工件的边缘距离较小，Canny对单个边缘的检测出现多个响应的概率很低，使得其能够很好地抑制虚假边缘响应对边缘检测的影响。检测算子的脉冲响应导数的零交叉点平均距离 D ( f ′ ) 满足公式(3)，就能够保证单边缘只有一个响应。</p><p>D ( f ′ ) = π [ ∫ − ∞ + ∞ f 1 / 2 ( x ) d x ∫ − ∞ + ∞ f ( x ) d x ] 1 2 (3)</p><p>输入的图像经过二维高斯函数 G ( x , y ) = 1 2 π σ 2 exp [ − x 2 + y 2 2 σ 2 ] 平滑处理后，会变得更加平滑，噪声也能够得到较好的抑制。式中 σ 是平滑参数，当其较小时，虽然对噪声的鲁棒性能、对图像的平滑能力都较低，但是却有较高的边缘定位精度；当 σ 较大时，高斯平滑模板也会随其增大，随之而来的就是运算量的大幅度增加和边缘位置的大幅度偏移，进而 σ 的值应该在1.0和2.0之间。梯度计算，能够完成对平滑后数据阵列的梯度方向 H ( x , y ) 和梯度幅值 M ( x , y ) 的计算。可以采用2 &#215; 2领域一阶偏导的有限差分计算，如式(4)、(5)所示：</p><p>M ( x , y ) = E x ( x , y ) + E y ( x , y ) (4)</p><p>H ( x , y ) = arctan E y ( x , y ) E x ( x , y ) (5)</p><p>其中 E x 和 E y 分别是原图像被滤波器 f x = [ − 0.5 0.5 − 0.5 0.5 ] 和 f y = [ 0.5 0.5 − 0.5 − 0.5 ] 沿行、列作用的结果。</p><p>图2. 四种边缘检测算法的效果比较</p><p>将使用Canny算子处理后的工件堆图像与Sobel算子、Roberts算子、Prewitt算子分割的图像进行效果对比分析。图2所示为上述3种边缘检测算子和Canny算子处理后的工件堆边缘检测效果图。Sobel算子、Roberts算子和Prewitt算子对工件的边缘检测效果都很差，几乎没有封闭的区域；Canny边缘检测各工件区域边缘效果非常好，不但精准检测出了各个工件的边缘，而且形成了连续封闭的区域，为下一步分水岭分割提供了有效的分割函数。</p></sec><sec id="s4_2"><title>2.2. 标记局部极大值(Marked Local Maximum)</title><p>传统H-minima技术 [<xref ref-type="bibr" rid="hanspub.31836-ref12">12</xref>] [<xref ref-type="bibr" rid="hanspub.31836-ref13">13</xref>] 存在因h值取值过小而造成虚假种子点不能有效抑制而造成过分割；取值过大而造成欠分割的矛盾。方红萍 [<xref ref-type="bibr" rid="hanspub.31836-ref14">14</xref>] 等提出一种自适应H-minima的改进分水岭算法，有效改善了分割性能。摄像机获取的原始图像比较复杂，图中灰度极值点比较多，不利于选择种子像素。为此，使用形态学中的基于重建的开闭操作 [<xref ref-type="bibr" rid="hanspub.31836-ref15">15</xref>] 来清理图像。</p><p>开闭操作可以去除较小的非目标结构的特定图像细节，同时保证用于描述工件信息的全局不失真。基于开闭的重建操作是腐蚀后再进行形态学重建。设原始图像 Q ( i , j ) 及模板图像<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/14-1541506x34_hanspub.png" xlink:type="simple"/></inline-formula>，对每一个像素 ( i , j ) 满足 q &#175; ( i , j ) ≥ Q ( i , j ) 。定义用结构元素B对像素 q &#175; 的腐蚀如下： q &#175; ( i , j ) 的每个像素与B的领域具有相同的形状和尺寸，选择该领域中的最小值并将其赋给<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/14-1541506x39_hanspub.png" xlink:type="simple"/></inline-formula>的中心像素，迭代公式为：</p><p>q &#175; k + 1 ( i , j ) = min { Q ( i , j ) , q &#175; k ( i , j ) Θ B } (6)</p><p>结果如图3所示，左图为局部极大值检测的结果，右图是将其叠加在原始图像上的效果。</p><p>图3. 局部极大值标记结果</p><p>基于上述处理，使用MATLAB软件中的watershed函数对图像进行基于分水岭的图像分割，结果如图4所示。右图中位于顶端的工件均被检测出来，并且背景也被很好的分离出来。左图为灰度化图像，是下一步强度分层的输入图像。</p><p>图4. 分水岭分割结果</p></sec></sec><sec id="s5"><title>3. 强度分层(Intensity Stratification)</title><p>强度分层是由Papakostas等人 [<xref ref-type="bibr" rid="hanspub.31836-ref15">15</xref>] 提出的。这一方法的思想是把图像按照切片的形式进行分解。一个切片是具有相同灰度值的像素集合。原始图像可以看出由切片及其对应的灰度值的乘积再累加求和：</p><p>f ( x , y ) = ∑ k = 1 L − 1 k f k ( x , y ) (7)</p><p>其中L是灰度级(通常L = 256)并且切片 f k ( x , y ) 只包含灰度级为k的像素，即</p><p>f k ( x , y ) = { 1             ( f ( x , y ) = k ) 0         ( f ( x , y ) ≠ k ) (8)</p><p>通过这一方法，把计算灰度图像矩这一问题转换为二值图像矩的计算。每一个切片是一个二值图像，并且可以确定每一个切片 f ( x , y ) 的矩：</p><p>m p q ( f ) = ∑ k = 1 L − 1 k m p q ( f k ) (9)</p><p>把分割好的图像分解成切片如图5所示，根据 是灰度图像的第K个强度切片，计算出最适合机器人抓取的工件的深度及中心坐标。</p><p>图5. 工件二值图像及特征参数</p></sec><sec id="s6"><title>4. 基于边界的图像矩计算(Image moment Calculation Based on Boundary)</title><p>在离散域，对边界的离散化和线积分的计算的不同会使每一种方法各不相同。Philips [<xref ref-type="bibr" rid="hanspub.31836-ref16">16</xref>] 提出使用离散格林定理而不是使用连续情况下的离散化形式。该方法在没有使用如何逼近的情况下得到了准确的结果。Philips使用连续域格林定理的不同表达方法来设计算法：</p><p>∮ ∂ Ω h ( x , y ) d x + g ( x , y ) d y = ∯ Ω ( ∂ g ∂ x − ∂ h ∂ y ) d x d y (10)</p><p>其中， g ( x , y ) 和 h ( x , y ) 是具有连续偏导数的任意函数。按照该定理的离散化形式，Philips证明了离散矩可以由边界像素表示如下：</p><p>m &#175; p , q Ω = ∑ ( x , y ) ∈ ∂ Ω + y p ∑ i = 1 x i p − ∑ ( x , y ) ∈ ∂ Ω − y p ∑ i = 1 x i p (11)</p><p>其中 ∂ Ω + 和 ∂ Ω − 分别是右手边和左手边边界。它们定义如下：</p><p>{ ∂ Ω + = { ( x , y ) | ( x , y ) ∈ Ω , ( x + 1 , y ) ∉ Ω } ∂ Ω − = { ( x , y ) | ( x , y ) ∉ Ω , ( x + 1 , y ) ∈ Ω }</p><p>式(12)定义了区域的形心。该坐标用于唯一地检测目标工件在图像平面上的位置。</p><p>x &#175; = m 1 , 0 m 0 , 0 ，   y &#175; = m 0 , 1 m 0 , 0 (12)</p><p>式(11)中矩 m &#175; p , q Ω 的值取决于目标工件在图像平面中的位置。因此常常要用到所谓中心距，其定义为</p><p>μ i , j = ∑ X I , Y I ∈ R ( X I − x &#175; ) i ( Y I − y &#175; ) j (13)</p><p>若区域是不对称的，可以用对应于最大矩的主轴和轴X之间的夹角 α 的形式来表示R的方向。该角度可用以下方程计算</p><p>α = 1 2 arctan ( 2 μ 1 , 1 μ 2 , 0 − μ 0 , 2 ) (14)</p><p>以参考文献 [<xref ref-type="bibr" rid="hanspub.31836-ref4">4</xref>] 为例，为了实现四自由度机器人的末端执行器定位作业，计算出图4中工件的相关图像矩特征集：</p><p>{ 形 心 坐 标 ( x &#175; , y &#175; ) = ( 231.28 , 195.74 ) 面 积 m 00 = 171390 夹 角 α = 47.55 ∘</p></sec><sec id="s7"><title>5. 结论(Conclusion)</title><p>1) 通过对比Canny算子和3种经典边缘检测算子的边缘检测效果，发现Canny算子边缘检测效果最好，可以作为分水岭分割的分割函数。</p><p>2) 利用基于重建的开闭操作得到最佳的种子区域，并进行分水岭分割。结果表明，该方法可进行有效的图像分割。</p><p>对分水岭分割后的工件图像进行强度分层，计算其图像矩特征集，获得用于四自由度机器人的抓取任务的视觉信息。</p></sec><sec id="s8"><title>基金项目</title><p>江苏省研究生科研与实践创新计划项目(SJCX18_1052)，国家自然基金(61803186)。</p></sec><sec id="s9"><title>文章引用</title><p>王天琪,贺乃宝,高 倩,赵俊杰. 基于分水岭和强度分层的机器人视觉认知方法Robot Visual Cognition Method Based on Watershed and Intensity Stratification[J]. 计算机科学与应用, 2019, 09(08): 1576-1583. https://doi.org/10.12677/CSA.2019.98177</p></sec><sec id="s10"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.31836-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Hutchinson, S., Hager, G.D. and Corke, P.I. (1996) A Tutorial on Visual Servo Control. IEEE Transactions on Robotics and Automa-tion, 12, 651-670. &lt;br&gt;https://doi.org/10.1109/70.538972</mixed-citation></ref><ref id="hanspub.31836-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Espiau, B., Chaumette, F. and Rives, P. (1992) A New Approach to Visual Servoing in Robotics. IEEE Transactions on Robotics and Automation, 8, 313-326. &lt;br&gt;https://doi.org/10.1109/70.143350</mixed-citation></ref><ref id="hanspub.31836-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Tahri, O. and Chaumette, F. (2005) Point-Based and Region-Based Image Moments for Visual Servoing of Planar Objects. IEEE Transactions on Robotics, 21, 1116-1127. &lt;br&gt;https://doi.org/10.1109/TRO.2005.853500</mixed-citation></ref><ref id="hanspub.31836-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Lin, F., Dong, X.X., Chen, B.M., Lum, K.Y. and Lee, T.H. (2012) A Robust Real-Time Embedded Vision System on an Unmanned Rotorcraft for Ground Target Following. IEEE Transactions on Industrial Electronics, 59, 1038-1049.  
&lt;br&gt;https://doi.org/10.1109/TIE.2011.2161248</mixed-citation></ref><ref id="hanspub.31836-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Tahri, O., Araujo, H., Chaumette, F. and Mezouar, Y. (2013) Robust Im-age-Based Visual Servoing Using Invariant Visual Information. Robotics and Autonomous Systems, 61, 1588-1600. &lt;br&gt;https://doi.org/10.1016/j.robot.2013.06.010</mixed-citation></ref><ref id="hanspub.31836-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">叶国强, 等. 结合学习特征的图像矩视觉伺服方法[J]. 华南理工大学学报, 2017, 2(45): 99-106.</mixed-citation></ref><ref id="hanspub.31836-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">毛优新, 等. 基于图像矩与神经网络的机器人四自由度视觉伺服[J]. 控制理论与应用, 2009, 26(10): 1162-1166.</mixed-citation></ref><ref id="hanspub.31836-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">赵栋杰, 张宾, 王学雷, 郭洪红, 张松兵. 基于图像矩的室内喷雾机器人自动对靶研[J]. 农业机械学报, 2016, 47(12): 22-29.</mixed-citation></ref><ref id="hanspub.31836-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Mayer, S.B. (1990) Morphology Segmentation. Journal of Visual Communication and Image Representation, 1, 21-46.  
&lt;br&gt;https://doi.org/10.1016/1047-3203(90)90014-M</mixed-citation></ref><ref id="hanspub.31836-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">高丽, 杨树元, 夏杰, 等. 基于标记的Watershed图像分割新算法[J]. 电子学报, 2006 , 34(11): 2018-2023.</mixed-citation></ref><ref id="hanspub.31836-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Canny, J. (1986) A Computational Approach to Edge Detection. IEEE Transactions on Pattern Analysis and Machine Intelligence, PAMI-8, 679-698. &lt;br&gt;https://doi.org/10.1109/TPAMI.1986.4767851</mixed-citation></ref><ref id="hanspub.31836-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Soille, P. (1999) Morphological Image Analysis Principles and Applications. Springer Verlag, Berlin, 123-140.  
&lt;br&gt;https://doi.org/10.1007/978-3-662-03939-7</mixed-citation></ref><ref id="hanspub.31836-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Soille, P. (2000) Morphological Image Analysis Applied to Crop Field Mapping. Image and Vision Computing, 18, 1025-1032. &lt;br&gt;https://doi.org/10.1016/S0262-8856(00)00043-3</mixed-citation></ref><ref id="hanspub.31836-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">方红萍, 方康玲, 刘新海. 自适应H-minima的改进分水岭堆叠细胞分割方法[J]. 计算机应用研究, 2016, 33(5): 1587-1590.</mixed-citation></ref><ref id="hanspub.31836-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">Papakostas, G.A., Kara-kasis, E.G. and Koulouriotis, D.E. (2008) Efficient and Accurate Computation of Geometric Moments on Gray-Scale Image. Pattern Recognition, 41, 1895-1904. &lt;br&gt;https://doi.org/10.1016/j.patcog.2007.11.015</mixed-citation></ref><ref id="hanspub.31836-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">Philips, W.A. (1993) New Fast Algorithm for Moment Compution. Pattern Recognition, 26, 1619-1621.  
&lt;br&gt;https://doi.org/10.1016/0031-3203(93)90017-Q</mixed-citation></ref></ref-list></back></article>