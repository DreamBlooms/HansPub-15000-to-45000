<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2020.108153</article-id><article-id pub-id-type="publisher-id">CSA-37058</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20200800000_16860578.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  快速HAC聚类算法的改进及应用于无监督语音分割
  Improvement of Fast HAC Clustering Algorithm and Application to Unsupervised Speech Segmentation
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>韦</surname><given-names>占江</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>梁</surname><given-names>宇</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>云南大学软件学院，云南 昆明</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>04</day><month>08</month><year>2020</year></pub-date><volume>10</volume><issue>08</issue><fpage>1464</fpage><lpage>1470</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   HAC是一种常用的聚类方法。本文的目的是根据语音特征中的音素与连续时间的紧密关系，改进HAC快速算法提高无监督分割语音信号到类似音素单位。该算法是基于同一段特征相似度高于跨段特征的相似度。特征的相似度是通过计算相邻特征间的欧式距离，来得到输入语音特征相邻的距离双链表，链表中的每个节点由语音相邻特征的距离和指向前后相邻节点的指针组成。该算法也是通过遍历相邻距离节点链表，查找最小距离后，对相似的相邻特征进行合并，并重复迭代至最后一个类或满足某个阀值。整个过程完全基于无监督下完成，该方法优于快速HAC算法，与快速HAC算法相比能提升65倍以上的聚类速度，节约更多的内存空间，可应用于零资源的语音分割。 HAC is a commonly used clustering method. According to the close relationship between phonemes and continuous time in speech features, the purpose of this paper is to improve the HAC fast algorithm to improve the unsupervised segmentation of speech signals to similar phoneme units. The algorithm is based on the fact that the similarity of the same segment feature is higher than that of the cross-segment feature. The similarity of features is to calculate the Euclidean distance between adjacent features to obtain the adjacent distance double-linked list of input speech features. Each node in the linked list is composed of the distance of adjacent speech features and pointers pointing to the adjacent nodes before and after. The algorithm also traverses the linked list of adjacent distance nodes, finds the minimum distance, combines similar adjacent features, and iterates to the last class or satisfies a certain threshold. The whole process is completed completely without supervision. This method is better than the fast HAC algorithm. Compared with the fast HAC algorithm, it can improve the clustering speed by more than 65 times, save more memory space, and can be applied to zero-resource speech segmentation. 
  
 
</p></abstract><kwd-group><kwd>无监督，音素，HAC算法，语音分割，相邻, Unsupervised</kwd><kwd> Phoneme</kwd><kwd> HAC Algorithm</kwd><kwd> Speech Segmentation</kwd><kwd> Adjacent</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>快速HAC聚类算法的改进及应用于无监督语音分割<sup> </sup></title><p>韦占江，梁宇</p><p>云南大学软件学院，云南 昆明</p><p>收稿日期：2020年7月26日；录用日期：2020年8月10日；发布日期：2020年8月17日</p><disp-formula id="hanspub.37058-formula16"><graphic xlink:href="//html.hanspub.org/file/6-1541842x5_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>HAC是一种常用的聚类方法。本文的目的是根据语音特征中的音素与连续时间的紧密关系，改进HAC快速算法提高无监督分割语音信号到类似音素单位。该算法是基于同一段特征相似度高于跨段特征的相似度。特征的相似度是通过计算相邻特征间的欧式距离，来得到输入语音特征相邻的距离双链表，链表中的每个节点由语音相邻特征的距离和指向前后相邻节点的指针组成。该算法也是通过遍历相邻距离节点链表，查找最小距离后，对相似的相邻特征进行合并，并重复迭代至最后一个类或满足某个阀值。整个过程完全基于无监督下完成，该方法优于快速HAC算法，与快速HAC算法相比能提升65倍以上的聚类速度，节约更多的内存空间，可应用于零资源的语音分割。</p><p>关键词 :无监督，音素，HAC算法，语音分割，相邻</p><disp-formula id="hanspub.37058-formula17"><graphic xlink:href="//html.hanspub.org/file/6-1541842x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2020 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/6-1541842x7_hanspub.png" /> <img src="//html.hanspub.org/file/6-1541842x8_hanspub.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>人工智能对输入的未知事物进行分类判别，很大程度依据聚类将数据点按照一定规则进行分群 [<xref ref-type="bibr" rid="hanspub.37058-ref1">1</xref>]。根据距离或相似度对数据点聚类，是研究诸多自然和社会问题的有力工具。而在各种聚类算法中，分层聚类具有特别的优势 [<xref ref-type="bibr" rid="hanspub.37058-ref2">2</xref>]。聚类是一个把数据对象集划分成多个组或簇的过程，使得簇内的对象具有很高的相似性 [<xref ref-type="bibr" rid="hanspub.37058-ref2">2</xref>]。但与其他簇中的对象很不相似。数据间的距离通常使用距离度量。数据对象的簇可以看成隐含的类 [<xref ref-type="bibr" rid="hanspub.37058-ref3">3</xref>]。在这种意义下，聚类有时又称自动分类。聚类过程中可自动地发现这些分组，这是聚类分类的突出优点。也被称为无监督学习，因为在没有标签信息情况下，可实现自动分类。由于这种原因，聚类是通过观察学习，而不是通过有标签的示例学习。</p><p>语音信号可视为基本音素单元的序列。现今很多自动语音识别系统依赖于这些基本单元准确识别。当前成熟的百度搜索也是基于文字的检索，而基于语音对语音的搜索有巨大的市场需求。但无监督的语音研究困难重重，语音分割是声学片段建模中至关重要的初始步骤，该步骤在音频搜索和无监督声学建模得到了广泛应用。以语音分割成基本单位涉及声道系统从一种状态转换到另一种状态的时刻。但是，过渡并不是突然发生的，而是连续发生的 [<xref ref-type="bibr" rid="hanspub.37058-ref4">4</xref>] [<xref ref-type="bibr" rid="hanspub.37058-ref5">5</xref>] [<xref ref-type="bibr" rid="hanspub.37058-ref6">6</xref>] [<xref ref-type="bibr" rid="hanspub.37058-ref7">7</xref>]。</p><p>通常，聚类的方法有很多种常见的有K-means [<xref ref-type="bibr" rid="hanspub.37058-ref8">8</xref>] [<xref ref-type="bibr" rid="hanspub.37058-ref9">9</xref>]、层次聚类(Hierarchical clustering)、谱聚类(Spectral Clustering)、GMM等方法 [<xref ref-type="bibr" rid="hanspub.37058-ref8">8</xref>]。其中，ward’s method [<xref ref-type="bibr" rid="hanspub.37058-ref10">10</xref>] 是聚类中一种常用方法，该方法对不相邻的特征(样本)的距离都要一一计算，计算量大，内存开销大，需要好的算法来处理这个问题 [<xref ref-type="bibr" rid="hanspub.37058-ref7">7</xref>]。尤其，当输入的语音序列比较大时，常规的凝聚型层次聚类Hierarchical methods (HAC)方法就变得很慢。于是本文根据语音特征本身就具有相邻语音有较高的相似性，跨段语音差异更大的特点。提出基于HAC算法基础上相邻快速HAC算法解决时间长、内存开销大等问题，并应用到语音分割中来。</p></sec><sec id="s4"><title>2. 层次聚类的原理及分类</title><sec id="s4_1"><title>2.1. 层次法(Hierarchical methods)</title><p>系统聚类也称层次聚类法。该算法先计算特征之间的距离，如欧式距离。在迭代过程中，每次查找到距离最近的点并合并到同一个类。然后，再计算新类与剩余类之间的距离，继续将距离最近的类合并为一个大类。不停的合并，直到合并到一个类或满足某个阀值。其中类与类的距离的计算方法有：最短距离法，最长距离法，中间距离法，类平均法等。比如最短距离法，将类与类的距离定义为类与类之间样本的最短距离 [<xref ref-type="bibr" rid="hanspub.37058-ref11">11</xref>]。</p><p>根据层次分解的顺序层次聚类算法可分为：自下向上和自上向下两种方法，即凝聚的层次聚类算法和分裂的层次聚类算法，也可以理解为自下而上法(bottom-up)和自上而下法(top-down)。</p><p>自下而上法的凝聚型层次聚类初始化时每个个体(object)都是一个类，然后根据linkage寻找同类，最后形成一个“类” [<xref ref-type="bibr" rid="hanspub.37058-ref12">12</xref>]。</p><p>而分裂型层次聚类采用自上而下法，就是反过来，初始化时所有个体都属于一个“类”，然后根据linkage排除相似度不高的类，最后每个个体都成为一个“类” [<xref ref-type="bibr" rid="hanspub.37058-ref11">11</xref>]。</p></sec><sec id="s4_2"><title>2.2. 层次聚类的流程</title><p>凝聚型层次聚类的策略是先将每个对象作为一个簇，然后合并这些原子簇为越来越大的簇，直到所有对象都在一个簇中，或者某个终结条件被满足。绝大多数层次聚类属于凝聚型层次聚类，它们只是在簇间相似度的定义上有所不同。这里给出采用最小距离的凝聚层次聚类算法流程 [<xref ref-type="bibr" rid="hanspub.37058-ref13">13</xref>] [<xref ref-type="bibr" rid="hanspub.37058-ref14">14</xref>] 如下：</p><p>从上面算法1可以看出凝聚的层次聚类并没有类似基本K均值的全局目标函数，没有局部极小问题或是很难选择初始点的问题。合并的操作往往是最终的，一旦合并两个簇之后就不会撤销。当然其计算存储的代价是昂贵的。</p></sec><sec id="s4_3"><title>2.3. 层次聚类的优缺点</title><p>层次聚类算法的优点有：距离和规则的相似度容易定义，限制少；不需预设聚类数k；可以发现类的层次关系；可以聚类成其它形状。缺点有：计算复杂度太高，当特征(样本)数量很多就需要很多时间；奇异值也能产生很大影响；算法很可能聚类成链状。</p><p>这个方法其实效率比较低，特别是算cluster的ESS值还要先求均值点，然后算距离的平方再求和，不过有一个快速的计算方法叫Lance-Williams Algorithm [<xref ref-type="bibr" rid="hanspub.37058-ref15">15</xref>] (快速HAC)可以大大简化ward method的计算。该算法可以不用ESS的公式计算ESS，直接套用下面的公(1)。</p><p>D k , i + j = 1 2 ( D k i + D k j − | D k i − D k j | ) (1)</p><p>其中，初始的ESS由两点之间的距离决定，也就是说完全不需要算ESS了。但计算量和内存开销也大。因此，根据语音特征分割所具有的特点，进一步改进HAC算法有效解决语音特征分割面临的时间和空间的问题。</p></sec></sec><sec id="s5"><title>3. 改进HAC算法</title><p>从以上分析可以看出，原来的HAC或快速HAC算法都先把所有样本当成初始类，计算出样本之间的距离，并存储在矩阵中形成一个上三角矩阵 [<xref ref-type="bibr" rid="hanspub.37058-ref16">16</xref>]，从距离矩阵中找到最小的，合并成一个类，更新全部其他点到该新类的距离矩阵，再迭代上述步骤直到只剩一个类。整个过程的计算存储代价是昂贵的，耗时也严重，因语音特征中可能一长段语音特征对应同一个phoneme，段内的语音特征相似度高，段外语音特征相似度不高的特点，只需关注相邻两两语音的相似，即左右特征的距离，不用关注不相邻样本间不相邻特征之间的距离来改进HAC算法并应用到语音分割中 [<xref ref-type="bibr" rid="hanspub.37058-ref17">17</xref>] [<xref ref-type="bibr" rid="hanspub.37058-ref18">18</xref>]。</p><sec id="s5_1"><title>3.1. 算法设计</title><p>根据语音分割的特殊性，不用矩阵来存储距离，而是改用字典双链表来存储相邻特征距离，其伪代码如下：</p><p>N o d e = N o d e ( i ,     j ,     d i s t ) (2)</p><p>其中，i，j为相邻两两语音特征向量下标，dist其相邻语音特征的欧式距离 [<xref ref-type="bibr" rid="hanspub.37058-ref19">19</xref>]。欧式距离计算如下：</p><p>d i s t ( X , Y ) = ∑ i n ( x i − y i ) 2 (3)</p><p>其中，X, Y为n维的语音特征(样本)，如39维的MFCC。</p><p>同样，该算法初始时，每个特征是独立的phoneme，在距离双链表中找到最小距离，和相邻语音特征下标，再根据下标来更新合并后的新数据点。</p><p>n e w d i s t a n c e [ c l u s t e r C o u n t ] = n e w d i s t a n c e [ f r o n t ] + n e w d i s t a n c e [ b a c k ] 2 (4)</p><p>其中，front，back为相邻的两个特征下标， n e w d i s t a n c e [ c l u s t e r C o u n t ] 为用平均法把front和back特征合并为新特征，就由合并的两个相邻特征的平均值来取代。</p></sec><sec id="s5_2"><title>3.2. 算法流程</title><p>该算法中，凡是两个相邻的特征都计算它们的欧式距离 [<xref ref-type="bibr" rid="hanspub.37058-ref18">18</xref>]，相并逐一求出输入语音特征的相邻欧式距离，然后存表双链表中。先从相邻距离双链表中查找出距离最小的两个特征并合并成一个段，这个段就是那两个特征的平均值，接着再求新段与相邻特征的距离。层次聚类算法对语音特征分割结果示意图 [<xref ref-type="bibr" rid="hanspub.37058-ref19">19</xref>] 如图1所示。</p><p>图1. 层次聚类算法对语音特征分割结果示意图</p><p>对如图1，横轴是时间，时间轴上为语音特征信号，如39维的MFFC序列。Merge Loss Li为与合并前的那两个特征相差多少，最后长一整个树。当这棵树长好后，可以在这棵树上切一刀，就可以切出一个个段来。从虚线处切，虚线下一条线对应的每个子树就对应一个segment，这样就得到8个segment。如果觉得切的太细，可往上移再切。就可做任意精细度的切割法 [<xref ref-type="bibr" rid="hanspub.37058-ref7">7</xref>] [<xref ref-type="bibr" rid="hanspub.37058-ref20">20</xref>] [<xref ref-type="bibr" rid="hanspub.37058-ref21">21</xref>] [<xref ref-type="bibr" rid="hanspub.37058-ref22">22</xref>]。</p><p>对快速HAC算法改进的相邻HAC算法流程如下所示：</p><p>其改进的相邻HAC算法伪代码如下：</p><p>1：clusterMap[k] = 1# 存放cluster的情况，形如'1'：4表示cluster1里面有4个元素(样本)</p><p>2：single_obj。append(i，i+1，dist)#存放cluster之间的距离，形如'1，2'：3。22表示cluster1与cluster2之间的距离为3。22</p><p>#查找距离最短的两个cluster，并迭代合并</p><p>3：while True：</p><p>4：minnode， min = link。min() #查找距离最短的两个cluster</p><p>5：front， back = minnode。getName()#取得相邻特征的下标</p><p>6：clusterMap[clusterCount]= ni + nj #合并相似段</p><p>#更新最小相邻距离cluster到新cluster的距离</p><p>7：newdistance[clusterCount] = (newdistance[front] + newdistance[back]) /2</p><p>#更新最小距离节点与相邻节点间的距离，并更新</p><p>8：Update_dist(minnode，left，right)</p><p>9：Update_link(minnode，left，right)</p><p>#删除最小节点和两个cluster</p><p>10：del minnode，clusterMap[front，back]</p><p>#只剩一个子类或满足某个阀值</p><p>11：if len(clusterMap) == 2：</p><p>12：break# 合并到只剩一个集合为止，然后退出</p><p>其中，伪代码第行和第行的两个函数update_dist()和update_link()分别为更新计算查找到距离最短的两个cluster并用平均法表示为一个新节点后与相邻类间的距离，以及重新更新查找到距离最短的两个cluster与相邻cluster的链表。</p></sec></sec><sec id="s6"><title>4. 实验对比与分析</title><sec id="s6_1"><title>4.1. 实验平台</title><p>本实验采用python 3.6，硬件配置：CPU Intel(R) Xeon(R) E3-1231 v3 @ 3.4 GHz，16 G内存，NVIDIA GeForce GTX 1060 3 GB；软件配置：pycharm64。</p></sec><sec id="s6_2"><title>4.2. 实验结果</title><p>使用62 Kb、199 Kb和1367 Kb的39维的MFCC语音特征数据文件分别用快速HAC和改进的相邻HAC算法进行实验，得到对比结果，如表1所示。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Fast HAC (GPU acceleration) and the performance comparison table of the improved adjacent HAC algorith</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >算法名称</th><th align="center" valign="middle" >文件大小(KB)</th><th align="center" valign="middle" >理论时间复杂度(T(n))</th><th align="center" valign="middle" >实际运行时间</th><th align="center" valign="middle" >理论空间复杂度(S(n))</th></tr></thead><tr><td align="center" valign="middle"  rowspan="3"  >快速HAC (GPU加速)</td><td align="center" valign="middle" >62</td><td align="center" valign="middle"  rowspan="3"  >O(n2)</td><td align="center" valign="middle" >20.53 s</td><td align="center" valign="middle"  rowspan="3"  >O(n2)</td></tr><tr><td align="center" valign="middle" >199</td><td align="center" valign="middle" >395.328 s</td></tr><tr><td align="center" valign="middle" >1367</td><td align="center" valign="middle" >35.62 h</td></tr><tr><td align="center" valign="middle"  rowspan="3"  >改进的相邻HAC</td><td align="center" valign="middle" >62</td><td align="center" valign="middle"  rowspan="3"  >O(n)</td><td align="center" valign="middle" >0.25 s</td><td align="center" valign="middle"  rowspan="3"  >O(n)</td></tr><tr><td align="center" valign="middle" >199</td><td align="center" valign="middle" >1.82 s</td></tr><tr><td align="center" valign="middle" >1367</td><td align="center" valign="middle" >81.49 s</td></tr></tbody></table></table-wrap><p>表1. 标准试验系统结果数据</p></sec></sec><sec id="s7"><title>5. 结束语</title><p>HAC层次聚类为无监督分类的重要工具，其默认分类算法中合并成本高，需要较大的计算力、较大的内存空间。如果总共有n个组，就必须把每个组合并都要算一遍，也要n &#215; (n − 1)/2，当特征(样本)数量增多时比较耗时，消耗内存也线性地增长。因此，为解决语音特征分割问题，提出相邻语音特征分割，只需关注相邻特征(样本)语音的合并问题，就无需要计算并更新所有特征或类间的距离，进而赢得了时间和空间，最后通过实验对比分析验证了算法的有效性。</p></sec><sec id="s8"><title>文章引用</title><p>韦占江,梁 宇. 快速HAC聚类算法的改进及应用于无监督语音分割Improvement of Fast HAC Clustering Algorithm and Application to Unsupervised Speech Segmentation[J]. 计算机科学与应用, 2020, 10(08): 1464-1470. https://doi.org/10.12677/CSA.2020.108153</p></sec><sec id="s9"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.37058-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">周涛, 袁飞, 庄旭. 最简数据挖掘[M]. 北京: 电子工业出版社, 2020.</mixed-citation></ref><ref id="hanspub.37058-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">邹臣嵩, 段桂芹. 基于改进K-medoids的聚类质量评价指标研究[J]. 计算机系统应用, 2019, 28(6): 235-242.</mixed-citation></ref><ref id="hanspub.37058-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Xie, W.-B., Lee, Y.-L., et al. (2020) Hi-erarchical Clustering Supported by Reciprocal Nearest Neighbors. Information Sciences, 527, 279-292. &lt;br&gt;https://doi.org/10.1016/j.ins.2020.04.016</mixed-citation></ref><ref id="hanspub.37058-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Lee, L.-S., Lee, H.-Y. and Chan, C.-A. (2015) Spoken Content Re-trieval—Beyond Cascading Speech Recognition with Text Retrieval. IEEE/ACM Transactions on Audio, Speech and Language Processing, 23, 1389-1420.</mixed-citation></ref><ref id="hanspub.37058-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Qiao, Y., Shimomura, N. and Minematsu, N. (2008) Unsupervised Optimal Phoneme Segmentation: Objectives, Algorithm and Comparisons. IEEE International Conference on Acoustics, Speech and Signal Processing, Las Vegas, 31 March-4 April 2008, 3989-3992. &lt;br&gt;https://doi.org/10.1109/ICASSP.2008.4518528</mixed-citation></ref><ref id="hanspub.37058-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Wang, H.P., et al. (2015) Acoustic Segment Modeling with Spectral Clustering Methods. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 23, 264-277. &lt;br&gt;https://doi.org/10.1109/TASLP.2014.2387382</mixed-citation></ref><ref id="hanspub.37058-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Yang, S.-W., Liu, A.T. and Lee, H.-Y. (2019) Understanding Self-Attention of Self-Supervised Audio Transformers. Computer Science, 8, 15-19.</mixed-citation></ref><ref id="hanspub.37058-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Jain, A.K. (2010) Data Clus-tering: 50 Years beyond k-Means. Pattern Recognition Letters, 31, 651-666.  
&lt;br&gt;https://doi.org/10.1016/j.patrec.2009.09.011</mixed-citation></ref><ref id="hanspub.37058-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Pratap, R., Deshmukh, A., Nair, P. and Dutt, T. (2018) A Faster Sampling Algorithm for Spherical k-Means. Proceedings of Machine Learning Research, Vol. 95, 343-358.</mixed-citation></ref><ref id="hanspub.37058-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">HAC with Minimum SSE Criterion. &lt;br&gt;https://hlab.stanford.edu/brian/error_sum_of_squares.html</mixed-citation></ref><ref id="hanspub.37058-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">李琳山. 数位语音处理概念. 2019. http://speech.ee.ntu.edu.tw/courses.html</mixed-citation></ref><ref id="hanspub.37058-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Novotney, S., Schwartz, R. and Ma, J. (2009) Unsuper-vised Acoustic and Language Model Training with Small Amounts of Labelled Data. IEEE International Conference on Acoustics, Speech and Signal Processing, Taipei, 19-24 April 2009, 4297-4300. &lt;br&gt;https://doi.org/10.1109/ICASSP.2009.4960579</mixed-citation></ref><ref id="hanspub.37058-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">吴信东, 库玛尔. 数据挖掘十大算法[M]. 北京: 清华大学出版社, 2014.</mixed-citation></ref><ref id="hanspub.37058-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">李勃昊, 张连海, 郑永军. 基于声学分段模型的无监督语音样例检测[J]. 数据采集与处理, 2016, 18(12): 41-44.</mixed-citation></ref><ref id="hanspub.37058-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">Yarmish, G., Listowsky, P. and Dexter, S. (2017) Distributed Lance-William Clustering Al-gorithm.  
&lt;br&gt;https://arxiv.org/ftp/arxiv/papers/1709/1709.06816.pdf</mixed-citation></ref><ref id="hanspub.37058-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">Bhati, S., Nayak, S., Sri Rama Murty, K. and Dehak, N. (2019) Unsupervised Acoustic Segmentation and Clustering Using Siamese Network Embeddings. INTERSPEECH 2019, Graz, 15-19 September 2019, 2668-2672.</mixed-citation></ref><ref id="hanspub.37058-ref17"><label>17</label><mixed-citation publication-type="other" xlink:type="simple">Jansen, A. and Van Durme, B. (2011) Efficient Spoken Term Discovery Using Randomized Algorithms. IEEE Automatic Speech Recognition and Understanding (ASRU), Hawaii, 11-15 December 2011, 401-406.  
&lt;br&gt;https://doi.org/10.1109/ASRU.2011.6163965</mixed-citation></ref><ref id="hanspub.37058-ref18"><label>18</label><mixed-citation publication-type="other" xlink:type="simple">Badino, L., Canevari, C., Fadiga, L. and Metta, G. (2014) An Autoencoder Based Approach to Unsupervised Learning of Subword Units. Acoustics, Speech and Signal Processing (ICASSP), Florence, 4-9 May 2014, 7634-7638.  
&lt;br&gt;https://doi.org/10.1109/ICASSP.2014.6855085</mixed-citation></ref><ref id="hanspub.37058-ref19"><label>19</label><mixed-citation publication-type="other" xlink:type="simple">詹竣安. 以口語查詢之非督導式口語詞彙偵測[D]: [博士学位论文]. 台北: 台湾大学, 2012.</mixed-citation></ref><ref id="hanspub.37058-ref20"><label>20</label><mixed-citation publication-type="other" xlink:type="simple">Mary, L. and Deekshitha, G. (2018) Searching Speech Databases: Features, Techniques and Evaluation Measures. Springer, Berlin. &lt;br&gt;https://doi.org/10.1007/978-3-319-97761-4</mixed-citation></ref><ref id="hanspub.37058-ref21"><label>21</label><mixed-citation publication-type="other" xlink:type="simple">Nazari, Z. and Kang, D. (2018) A New Hierarchical Clustering Algorithm with Intersection Points. IEEE Uttar Pradesh Section In-ternational Conference on Electrical, Electronics and Computer Engineering, Gorakhpur, 2-4 November 2018, 315-319. &lt;br&gt;https://doi.org/10.1109/UPCON.2018.8596795</mixed-citation></ref><ref id="hanspub.37058-ref22"><label>22</label><mixed-citation publication-type="other" xlink:type="simple">Chung, C.T. and Lee, L.S. (2018) Unsupervised Discovery of Structured Acoustic Tokens with Applications to Spoken Term Detection. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 26, 394-405.</mixed-citation></ref></ref-list></back></article>