<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">PM</journal-id><journal-title-group><journal-title>Pure  Mathematics</journal-title></journal-title-group><issn pub-type="epub">2160-7583</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/PM.2021.117148</article-id><article-id pub-id-type="publisher-id">PM-43763</article-id><article-categories><subj-group subj-group-type="heading"><subject>PM20210700000_79288002.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>数学与物理</subject></subj-group></article-categories><title-group><article-title>
 
 
  一种基于Tobit回归模型的序贯压缩估计方法研究
  A Sequential Shrinkage Estimate Based on Tobit Regression Model
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>鲁</surname><given-names>海波</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib></contrib-group><aff id="aff1"><label>1</label><addr-line>null</addr-line></aff><aff id="aff2"><label>1</label><addr-line>新疆师范大学数学科学学院，新疆 乌鲁木齐</addr-line></aff><pub-date pub-type="epub"><day>02</day><month>07</month><year>2021</year></pub-date><volume>11</volume><issue>07</issue><fpage>1320</fpage><lpage>1325</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
  
    Tobit回归模型在计量经济学等研究领域中有着广泛的应用。但是我们在处理面板数据以及时间序列数据时经常会遇到包含太多变量的数据集，而这些变量中只有少数变量对模型有贡献。为了去除这些“无效变量”的影响，在本文中，我们提出一种基于自适应压缩估计的序贯抽样策略来构造“有效”参数的固定长度的置信集，并在自适应设计下对所提出的序贯抽样策略进行数值模拟，最后数值模拟达到了预期的效果。&lt;br&gt;In the applications of Tobit regression models we always encounter the data sets which contain too many variables, but only a few of them contribute to the model. Therefore, it will waste much more samples to estimate the “non-effective” variables in the inference. In this paper, we use a sequential procedure for constructing the fixed size confidence set for the “effective” parameters to the model based on an adaptive shrinkage estimate such that the “effective” coefficients can be efficiently identified with the minimum sample size. Adaptive design is considered for numerical simulation. 
  
 
</p></abstract><kwd-group><kwd>Tobit模型，样本量，序贯压缩估计，停止法则, Tobit Models</kwd><kwd> Sample Size</kwd><kwd> Shrinkage Estimate</kwd><kwd> Stopping Rule</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>摘要</title><p>Tobit回归模型在计量经济学等研究领域中有着广泛的应用。但是我们在处理面板数据以及时间序列数据时经常会遇到包含太多变量的数据集，而这些变量中只有少数变量对模型有贡献。为了去除这些“无效变量”的影响，在本文中，我们提出一种基于自适应压缩估计的序贯抽样策略来构造“有效”参数的固定长度的置信集，并在自适应设计下对所提出的序贯抽样策略进行数值模拟，最后数值模拟达到了预期的效果。</p></sec><sec id="s2"><title>关键词</title><p>Tobit模型，样本量，序贯压缩估计，停止法则</p></sec><sec id="s3"><title>A Sequential Shrinkage Estimate Based on Tobit Regression Model<sup> </sup></title><p>Haibo Lu</p><p>School of Mathematics Science, Xinjiang Normal University, Urumqi Xinjiang</p><p><img src="//html.hanspub.org/file/9-1251353x4_hanspub.png" /></p><p>Received: May 31<sup>st</sup>, 2021; accepted: Jul. 1<sup>st</sup>, 2021; published: Jul. 8<sup>th</sup>, 2021</p><p><img src="//html.hanspub.org/file/9-1251353x5_hanspub.png" /></p></sec><sec id="s4"><title>ABSTRACT</title><p>In the applications of Tobit regression models we always encounter the data sets which contain too many variables, but only a few of them contribute to the model. Therefore, it will waste much more samples to estimate the “non-effective” variables in the inference. In this paper, we use a sequential procedure for constructing the fixed size confidence set for the “effective” parameters to the model based on an adaptive shrinkage estimate such that the “effective” coefficients can be efficiently identified with the minimum sample size. Adaptive design is considered for numerical simulation.</p><p>Keywords:Tobit Models, Sample Size, Shrinkage Estimate, Stopping Rule</p><disp-formula id="hanspub.43763-formula30"><graphic xlink:href="//html.hanspub.org/file/9-1251353x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2021 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/9-1251353x7_hanspub.png" /> <img src="//html.hanspub.org/file/9-1251353x8_hanspub.png" /></p></sec><sec id="s5"><title>1. 引言</title><p>Tobit回归模型 [<xref ref-type="bibr" rid="hanspub.43763-ref1">1</xref>] 是一种因变量受限模型，被称作样本选择模型，或者删失回归模型。Tobit回归模型被广泛应用于计量经济学等众多研究领域 [<xref ref-type="bibr" rid="hanspub.43763-ref2">2</xref>] [<xref ref-type="bibr" rid="hanspub.43763-ref3">3</xref>] [<xref ref-type="bibr" rid="hanspub.43763-ref4">4</xref>]，在面板数据和时间序列数据的分析中发挥着越来越重要的作用。假设 a + = max { a , c } ，我们可以如下定义Tobit回归模型</p><p>y i + = max { x i T β 0 + ε i , c } , i = 1 , 2 , ⋯ , n (1)</p><p>其中， β 0 ( p 维向量)是回归系数， x i 是 p 维协变量， ε i 是随机误差。然而，在计量经济学等领域对面板数据或者时间序列数据等分析研究中，常常会遇到数据集通常有大量的解释变量，但其中只有少数对模型有贡献。也就是说，在一个 p 维的回归系数中只有 p 0 ( p 0 &lt; p 且 p 0 未知)个分量是取非零值的，我们称之为有效变量 [<xref ref-type="bibr" rid="hanspub.43763-ref5">5</xref>]。目前有很多方法可以用来识别有效变量，如LASSO [<xref ref-type="bibr" rid="hanspub.43763-ref6">6</xref>] 和LARS [<xref ref-type="bibr" rid="hanspub.43763-ref7">7</xref>] 等等。但另外需要关注的问题是，用多少样本才能既识别出有效变量，同时又能使参数估计达到预定的精度。这对于计量经济学等领域需要考虑抽样成本的研究具有重要的意义。对于线性回归模型，Wang 和Zhang (2013) [<xref ref-type="bibr" rid="hanspub.43763-ref5">5</xref>] 提出了一种序贯压缩估计方法来识别有效变量，从而达到参数估计的精度。数值模拟结果表明，与传统的序贯抽样方法相比，序贯压缩估计不仅可以从所有变量中识别出有效变量，而且可以节省大量样本。对于Tobit回归模型，如何提出相应的序贯估计方法以及在自适应设计下给出相关性质和数据模拟有待进一步的研究。本文针对Tobit回归模型提出了一种基于自适应压缩估计(ASE)来构造有效变量的固定窗宽的置信集的序贯抽样方法，使有效变量能以最小样本量快速识别。本文将在适应性设计(adaptive design)下研究所提出的自适应压缩估计(ASE)的大样本性质，同时在自适应性设计下通过数值模拟得到了很好的模拟结果。</p></sec><sec id="s6"><title>2. 基于Tobit模型的序贯自适应压缩估计(ASE)</title><sec id="s6_1"><title>2.1. 最小一乘估计(LAD)</title><p>不失一般性在模型(1)中，令 c = 0 。假设随机误差 ε i , i = 1 , 2 , ⋯ , n 独立同分布且 ε i ∼ N ( 0 , σ 2 ) ，那么似然函数的形式为：</p><p>L = ∏ 0 ( 1 − Φ ( x i T β σ ) ) ∏ 1 σ − 1 ϕ ( x i T β σ )</p><p>其中 Φ 和 ϕ 分别为标准正态分布的概率分布函数和密度函数， Π 0 为集合 { i : y i ≤ 0 } 中若干元素的乘积， Π 1 为集合 { i : y i &gt; 0 } 中若干元素的乘积。记</p><p>Q n ( β ) = ∑ i = 1 n | y i + − max { x i T β , 0 } |</p><p>使 Q n ( β ) 达到最小的 β 被称为回归参数 β 的最小一乘估计 [<xref ref-type="bibr" rid="hanspub.43763-ref8">8</xref>]，记为 β ∼ n 。我们给定假设条件：</p><p>(A1) sup i ‖ x i ‖ &lt; ∞ ；</p><p>(A2) 若随机误差 ε i 的密度函数 f ( x ) 满足 f ( 0 ) = 0 和 m e d ( ε i ) = 0 ，那么存在 δ &gt; 0 使得 lim n → ∞ λ log n ∑ i = 1 n I ( x i T β &gt; δ ) x i x i T = ∞ 。</p><p>当 β ˜ n 满足(A1)和(A2)时，文献 [<xref ref-type="bibr" rid="hanspub.43763-ref9">9</xref>] 给出了 β ˜ n 的相合性和渐近正态性：</p><p>lim n → ∞ β ˜ n = β 0 , a . s .</p><p>( 2 f ( 0 ) M n 1 / 2 ) ⋅ n ( β ˜ n − β 0 ) → d N ( 0 , I n )</p><p>其中 I n 是单位阵，并且 M n = E ( 1 n ∑ i I ( x i T β 0 &gt; 0 ) x i x i T ) 。</p></sec><sec id="s6_2"><title>2.2. 自适应压缩估计(ASE)</title><p>设 κ = κ ( n ) ，当 n → ∞ 时，存在 0 &lt; δ &lt; 1 / 2 和 γ &gt; 0 使得 n 1 2 κ → 0 ， n 1 2 + γ δ κ → ∞ 。下面我们给出Tobit回归模型下回归系数的自适应压缩估计的定义：</p><p>定义2.2.1 设 β ˜ 为模型(1)的最小一乘估计，则称 β ^ n = I n ( ε ) β ˜ n 为回归系数 β 0 的自适应压缩估计(ASE)，其中 I n ( ε ) = d i a g { I n 1 ( ε ) , I n 2 ( ε ) , ⋯ , I n p ( ε ) } 是一个 p &#215; p 维对角阵。同时可以证明 β ^ n = I n ( ε ) β ˜ n 满足相合性和渐进正态性。</p></sec><sec id="s6_3"><title>2.3. 序贯抽样策略</title><p>依据文献 [<xref ref-type="bibr" rid="hanspub.43763-ref10">10</xref>] [<xref ref-type="bibr" rid="hanspub.43763-ref11">11</xref>] 中的结论我们可以证明 n ( β ^ n − β 0 ) , n = 1 , 2 , ⋯ 是依概率一致连续的，由此可得如下定理：</p><p>定理2.3.1 设随机变量N(t)取正整数值，当 t → ∞ 有 N ( t ) / t 依概率收敛于1，且条件(A1)和(A2)成立，则当 t → ∞ 时，</p><p>N ( t ) ( β ^ N ( t ) − β 0 ) → N ( 0 , I 0 Σ I 0 − 1 )</p><p>由定理2.3.1我们可以构造 β 0 的置信集和能够决定最小样本量的停止法则的序贯抽样策略。设 { ( y i , x i ) : i = 1 , 2 , ⋯ , k } 是最先进入研究的 k 个样本，用 C k 来表示。在任意给定小正数 ε 下，</p><p>p ^ 0 ( k ) = ∑ j = 1 p I k j ( ε )</p><p>是回归系数 p 0 基于条件 C k 的估计量。令 a k 2 ∈ R 对任意 α &gt; 0 ，有 P ( χ p ^ 0 ( k ) 2 ≤ a k 2 | C k ) = 1 − α 成立。现在定义停时法则 N d 为</p><p>N = N d ≡ inf { k : k ≥ n 0 and d 2 a k 2 ≥ ν k } , (2)</p><p>其中 ν k 是 k I k ( ε ) ( Σ ) − 1 I k ( ε ) 的最大特征值， d 是置信集的预设精度。在本文的序贯估计策略中，一次只有一个新的观测进入研究直到满足(2)式的停止法则时就停止抽样，此时 β 0 的置信集为</p><p>R N = { Z ∈ R p : S N N ≤ d 2 ν N 且 当 I N j ( ε ) = 0 时 , z j = 0 , 1 ≤ j ≤ p } (3)</p><p>其中 S N = ( Z N 1 − β ^ N 1 ) T Σ ˜ 11 ( Z N 1 − β ^ N 1 ) 。我们所提出的序贯抽样方法致力于找到有效变量的同时忽略无效变量的影响，这是和传统序贯方法相比我们能够节省大量样本的关键，在下面的定理中我们给出停时 N d 和置信集 R N 的相关性质。</p><p>定理2.3.2 假定条件(A1)和(A2)都成立，设N是满足(2)式的停时，则：</p><p>i) lim d → 0 d 2 N a 2 ν = 1 ，a.s.；ii) lim d → 0 P ( β 0 ∈ R N ) = 1 − α ；</p><p>iii) lim d → 0 d 2 E ( N ) a 2 ν = 1 ；iv) lim d → 0 p ^ 0 ( N ) = p 0 ，a.s.且 lim d → 0 E ( p ^ 0 ( N ) ) = p 0 ，</p><p>其中 ν 是矩阵 I 0 Σ − 1 I 0 的最大特征值。</p></sec></sec><sec id="s7"><title>3. 数值模拟</title><p>在固定样本量下用所提方法对随机数据集合进行分析，以此来验证所提出的序贯压缩估计方法的性能。按照停止法则的定义，当抽样停止时，最终的置信集将满足预设精度和覆盖概率，因此我们可以比较分别基于LAD和ASE的序贯抽样方法的平均停时。由于序贯压缩估计方法忽略无效变量的影响，故理论上平均所需停时应该显著小于不考虑变量选择的序贯方法。如果事先已知有效变量为 p 0 个同时无无效变量，那么只使用这 p 0 个有效变量的序贯方法无疑是效率最高的。所以，为便于比较，我们将所有( p 0 个)变量全部为有效变量的序贯估计方法作为基准线，在此情况下所获得的样本量应该是最小的。在自适应设计下，随机模拟数据集中的 x 1 仍然由多元标准正态分布生成， x j ( j &gt; 1 ) 由均值为 ∑ i = 1 j − 1 [ x j / ( j − 1 ) ] ，方差协方差矩阵为单位阵的多元正态分布生成。不失一般性，选择模型(1)中的常数 c = 0 。回归系数真值取 ( − 1.2 , 2.0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ) ，其中含有八个无效变量，回归系数置信集的预设精度 d ∈ { 0.3 , 0.4 , 0.5 , 0.6 } ，取 α = 0.05 ， γ = 1 ， δ = 0.45 ， θ = 0.75 。另外当用ASE方法时我们用BIC方法来确定 ε 。</p><p>表1描述了Tobit回归模型下的序贯抽样方法的数值模拟结果。在表1中我们列出了最终样本量N (停</p><p>时)， κ * = d 2 N / ( a 2 ν ) 和95%置信集的经验覆盖概率 R N 。所有三种情况( LAD p 0 , ASE, LAD)下的 κ 值都非</p><p>常接近1，并且当d不断减小时经验覆盖概率CP越来越接近95%，正如定理2.3.2描述的一样。然而，应用LAD方法所得的样本量N比应用ASE方法和 LAD p 0 都大得多。而应用ASE的抽样策略所需的样本量和应用 LAD p 0 的抽样策略所需样本量差不多，这说明我们所提方法在变量选择的同时效率和回归参数中只有有效变量无无效变量的情况下的效率非常接近，而比不做变量选择情况下(即LAD)的抽样效率提高很多。</p><p>表2比较了在估计Tobit回归模型的回归系数时分别应用ASE和LAD的抽样策略对识别回归系数中的有效变量和无效变量的效率。从结果可以看出应用ASE的抽样策略时不能被正确识别的零变量的平均个数几乎趋向于0，而能被正确识别的非0变量的平均个数和模型中有效变量个数的真值非常接近(2和8)。结果表明基于ASE的序贯抽样策略下 p ^ 0 是 p 0 的优良估计。而基LAD的序贯抽样策略不能识别有效变量，因此无法获得 N c * 和 N i c * 的值。此外，所有参数的估计值和它们的真值都非常接近。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Results of sequential sampling method based on ASE, LAD with all variables and LAD with only p 0 non-zero variables for Tobit regression mode</title></caption><table><tbody><thead><tr><th align="center" valign="middle"  colspan="11"  ><inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/9-1251353x119_hanspub.png" xlink:type="simple"/></inline-formula></th></tr></thead><tr><td align="center" valign="middle"  colspan="2"  ></td><td align="center" valign="middle"  colspan="3"  ><inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/9-1251353x120_hanspub.png" xlink:type="simple"/></inline-formula></td><td align="center" valign="middle"  colspan="3"  ><inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/9-1251353x121_hanspub.png" xlink:type="simple"/></inline-formula></td><td align="center" valign="middle"  colspan="3"  ><inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/9-1251353x122_hanspub.png" xlink:type="simple"/></inline-formula></td></tr><tr><td align="center" valign="middle" >Design</td><td align="center" valign="middle" >d</td><td align="center" valign="middle" ><inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/9-1251353x123_hanspub.png" xlink:type="simple"/></inline-formula></td><td align="center" valign="middle" ><inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/9-1251353x124_hanspub.png" xlink:type="simple"/></inline-formula></td><td align="center" valign="middle" ><inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/9-1251353x125_hanspub.png" xlink:type="simple"/></inline-formula></td><td align="center" valign="middle" ><inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/9-1251353x126_hanspub.png" xlink:type="simple"/></inline-formula></td><td align="center" valign="middle" ><inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/9-1251353x127_hanspub.png" xlink:type="simple"/></inline-formula></td><td align="center" valign="middle" ><inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/9-1251353x128_hanspub.png" xlink:type="simple"/></inline-formula></td><td align="center" valign="middle" ><inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/9-1251353x129_hanspub.png" xlink:type="simple"/></inline-formula></td><td align="center" valign="middle" ><inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/9-1251353x130_hanspub.png" xlink:type="simple"/></inline-formula></td><td align="center" valign="middle" ><inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/9-1251353x131_hanspub.png" xlink:type="simple"/></inline-formula></td></tr><tr><td align="center" valign="middle" >Adaptive</td><td align="center" valign="middle" >0.6</td><td align="center" valign="middle" >93.58 (12.36)</td><td align="center" valign="middle" >1.021</td><td align="center" valign="middle" >0.95</td><td align="center" valign="middle" >111.75 (19.04)</td><td align="center" valign="middle" >1.040</td><td align="center" valign="middle" >0.935</td><td align="center" valign="middle" >292.71 (30.16)</td><td align="center" valign="middle" >1.006</td><td align="center" valign="middle" >0.95</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >0.5</td><td align="center" valign="middle" >127.55 (18.89)</td><td align="center" valign="middle" >1.014</td><td align="center" valign="middle" >0.96</td><td align="center" valign="middle" >154.15 (23.01)</td><td align="center" valign="middle" >1.031</td><td align="center" valign="middle" >0.92</td><td align="center" valign="middle" >371.82 (33.36)</td><td align="center" valign="middle" >1.005</td><td align="center" valign="middle" >0.93</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >0.4</td><td align="center" valign="middle" >192.02 (28.9)</td><td align="center" valign="middle" >1.011</td><td align="center" valign="middle" >0.95</td><td align="center" valign="middle" >224.6 (24.90)</td><td align="center" valign="middle" >1.019</td><td align="center" valign="middle" >0.935</td><td align="center" valign="middle" >598.85 (43.25)</td><td align="center" valign="middle" >1.003</td><td align="center" valign="middle" >0.93</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >0.3</td><td align="center" valign="middle" >349.08 (31.57)</td><td align="center" valign="middle" >1.000</td><td align="center" valign="middle" >0.95</td><td align="center" valign="middle" >352.98 (39.08)</td><td align="center" valign="middle" >1.016</td><td align="center" valign="middle" >0.93</td><td align="center" valign="middle" >983.90 (65.16)</td><td align="center" valign="middle" >1.002</td><td align="center" valign="middle" >0.97</td></tr></tbody></table></table-wrap><p>表1. Tobit回归模型下分别应用ASE，LAD和 LAD p 0 的序贯抽样方法的结果分析</p><p><inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/9-1251353x132_hanspub.png" xlink:type="simple"/></inline-formula>；<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/9-1251353x133_hanspub.png" xlink:type="simple"/></inline-formula>是95%置信集<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/9-1251353x134_hanspub.png" xlink:type="simple"/></inline-formula>的经验覆盖概率；<sup>**</sup>经验标准差在括号内。</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> Power of variable identification and estimation of nonzero components under sequential sampling method based on ASE and LAD with Tobit regression mode</title></caption><table><tbody><thead><tr><th align="center" valign="middle"  colspan="10"  ><inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/9-1251353x135_hanspub.png" xlink:type="simple"/></inline-formula></th></tr></thead><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle"  colspan="4"  ><inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/9-1251353x136_hanspub.png" xlink:type="simple"/></inline-formula></td><td align="center" valign="middle"  colspan="4"  ><inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/9-1251353x137_hanspub.png" xlink:type="simple"/></inline-formula></td></tr><tr><td align="center" valign="middle" >Design</td><td align="center" valign="middle" >d</td><td align="center" valign="middle" ><inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/9-1251353x138_hanspub.png" xlink:type="simple"/></inline-formula></td><td align="center" valign="middle" ><inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/9-1251353x139_hanspub.png" xlink:type="simple"/></inline-formula></td><td align="center" valign="middle" ><inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/9-1251353x140_hanspub.png" xlink:type="simple"/></inline-formula></td><td align="center" valign="middle" ><inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/9-1251353x141_hanspub.png" xlink:type="simple"/></inline-formula></td><td align="center" valign="middle" ><inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/9-1251353x142_hanspub.png" xlink:type="simple"/></inline-formula></td><td align="center" valign="middle" ><inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/9-1251353x143_hanspub.png" xlink:type="simple"/></inline-formula></td><td align="center" valign="middle" ><inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/9-1251353x144_hanspub.png" xlink:type="simple"/></inline-formula></td><td align="center" valign="middle" ><inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/9-1251353x145_hanspub.png" xlink:type="simple"/></inline-formula></td></tr><tr><td align="center" valign="middle" >Adaptive</td><td align="center" valign="middle" >0.6</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >7.76</td><td align="center" valign="middle" >−1.28 (0.16)</td><td align="center" valign="middle" >2.07 (0.18)</td><td align="center" valign="middle" >-</td><td align="center" valign="middle" >-</td><td align="center" valign="middle" >−1.258 (0.09)</td><td align="center" valign="middle" >2.074 (0.117)</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >0.5</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >7.92</td><td align="center" valign="middle" >−1.21 (0.19)</td><td align="center" valign="middle" >2.104 (0.113)</td><td align="center" valign="middle" >-</td><td align="center" valign="middle" >-</td><td align="center" valign="middle" >−1.226 (0.07)</td><td align="center" valign="middle" >2.031 (0.095)</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >0.4</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >7.97</td><td align="center" valign="middle" >−1.23 (0.11)</td><td align="center" valign="middle" >2.061 (0.015)</td><td align="center" valign="middle" >-</td><td align="center" valign="middle" >-</td><td align="center" valign="middle" >−1.213 (0.069)</td><td align="center" valign="middle" >2.021 (0.079)</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >0.3</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >7.985</td><td align="center" valign="middle" >−1.21 (0.07)</td><td align="center" valign="middle" >2.013 (0.006)</td><td align="center" valign="middle" >-</td><td align="center" valign="middle" >-</td><td align="center" valign="middle" >−1.208 (0.044)</td><td align="center" valign="middle" >2.01 (0.068)</td></tr></tbody></table></table-wrap><p>表2. Tobit回归模型下分别应用ASE和LAD的序贯抽样策略的变量识别和非零参数估计效率</p><p><inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/9-1251353x146_hanspub.png" xlink:type="simple"/></inline-formula>：<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/9-1251353x147_hanspub.png" xlink:type="simple"/></inline-formula>中零分量(无效变量)被错误识别的平均个数；<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/9-1251353x148_hanspub.png" xlink:type="simple"/></inline-formula>：<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/9-1251353x149_hanspub.png" xlink:type="simple"/></inline-formula>中非零分量(有效变量)被正确识别的平均个数。</p></sec><sec id="s8"><title>4. 结论</title><p>在Tobit回归模型下基于自适应压缩估计(ASE)建立的序贯抽样方法不仅能够用最少的样本识别出回归参数中的有效变量，同时可以使回归参数的估计值达到预设的精度 [<xref ref-type="bibr" rid="hanspub.43763-ref12">12</xref>]。我们在自适应设计下对相关性质做数值模拟，结果表明和传统的序贯抽样方法相比，我们提出的方法能够节省大量样本。然而，本文中所提方法涉及到的变量维数是固定的，后期我们将研究当变量维数随样本量变化时的序贯抽样方法的相关性质。</p></sec><sec id="s9"><title>基金项目</title><p>1) 新疆师范大学博士科研启动基金项目：“基于广义线性模型的序贯分析研究”XJNUBS1539；</p><p>2) 新疆维吾尔自治区高校科研计划项目：“基于Cox比例风险回归模型的序贯分析研究”(XJEDU2016I033)。</p></sec><sec id="s10"><title>文章引用</title><p>鲁海波. 一种基于Tobit回归模型的序贯压缩估计方法研究A Sequential Shrinkage Estimate Based on Tobit Regression Model[J]. 理论数学, 2021, 11(07): 1320-1325. https://doi.org/10.12677/PM.2021.117148</p></sec><sec id="s11"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.43763-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Tobin, J. (1958) Estimation of Relationships for Limited Dependent Variables. Econometrica, 26, 24-36.  
&lt;br&gt;https://doi.org/10.2307/1907382</mixed-citation></ref><ref id="hanspub.43763-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Adams, J.D. (1980) Personal Wealth Transfers. Quarterly Journal of Eco-nomics, 95, 159-179.  
&lt;br&gt;https://doi.org/10.2307/1885354</mixed-citation></ref><ref id="hanspub.43763-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Ashenfelter, O. and Ham, J. (1979) Education, Unemployment, and Earnings. Journal of Political Economy, 87, S99-S116. &lt;br&gt;https://doi.org/10.1086/260824</mixed-citation></ref><ref id="hanspub.43763-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Fair, R.C. (1978) A Theory of Extramarital Affairs. Journal of Political Economy, 86, 45-61.  
&lt;br&gt;https://doi.org/10.1086/260646</mixed-citation></ref><ref id="hanspub.43763-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Wang, Z.F. and Chang, Y.I. (2013) Sequential Estimate for Linear Regression Models with Uncertain Number of Effective Variables. Metrika, 76, 949-978. &lt;br&gt;https://doi.org/10.1007/s00184-012-0426-4</mixed-citation></ref><ref id="hanspub.43763-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Tibshirani, R. (1996) Regression Shrinkage and Selection via the Lasso. Journal of the Royal Statistical Society, Series B, 58, 267-288. &lt;br&gt;https://doi.org/10.1111/j.2517-6161.1996.tb02080.x</mixed-citation></ref><ref id="hanspub.43763-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Efron, B., Hastie, T., Johnstone, I. and Tibshirani, R. (2004) Least Angle Regression. Journal of Annals of Statistics, 32, 407-499. &lt;br&gt;https://doi.org/10.1214/009053604000000067</mixed-citation></ref><ref id="hanspub.43763-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Powell, J.L. (1984) Least Absolute Deviations Estimation for the Censored Regression Model. Journal of Econometrics, 25, 303-325. &lt;br&gt;https://doi.org/10.1016/0304-4076(84)90004-6</mixed-citation></ref><ref id="hanspub.43763-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Chen, X.R. and Wu, Y.H. (1994) Consistency of l1 Estimates in Censored Linear Regression Models. Communications in Statistics, 23, 1847-1858. &lt;br&gt;https://doi.org/10.1080/03610929408831360</mixed-citation></ref><ref id="hanspub.43763-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Anscombe, F.J. (1952) Large Sample Theory of Sequential Es-timation. Mathematical Proceedings of the Cambridge Philosophical Society, 48, 600-607. &lt;br&gt;https://doi.org/10.1017/S0305004100076386</mixed-citation></ref><ref id="hanspub.43763-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Woodroofe, M. (1982) Nonlinear Renewal Theory in Sequential Analysis. Society for Industrial and Applied Mathematics, Philadelphia. &lt;br&gt;https://doi.org/10.1137/1.9781611970302</mixed-citation></ref><ref id="hanspub.43763-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Chow, Y.S. and Robbins, H. (1965) On the Asymptotic Theory of Fixed-Width Sequential Confidence Intervals for the Mean. Annals of Mathematical Statistics, 36, 457-462. &lt;br&gt;https://doi.org/10.1214/aoms/1177700156</mixed-citation></ref></ref-list></back></article>