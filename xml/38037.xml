<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">MET</journal-id><journal-title-group><journal-title>Mechanical Engineering and Technology</journal-title></journal-title-group><issn pub-type="epub">2167-6631</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/MET.2020.95048</article-id><article-id pub-id-type="publisher-id">MET-38037</article-id><article-categories><subj-group subj-group-type="heading"><subject>MET20200500000_83335652.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>工程技术</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于单目视觉的零件表面网格节点坐标测量
  Extraction of Surface Grid Node Based on Monocular Vision
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>史</surname><given-names>珂</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>刘</surname><given-names>倩倩</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>项</surname><given-names>辉宇</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>null</addr-line></aff><aff id="aff1"><addr-line>北京工商大学，北京</addr-line></aff><pub-date pub-type="epub"><day>11</day><month>09</month><year>2020</year></pub-date><volume>09</volume><issue>05</issue><fpage>445</fpage><lpage>454</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
  本文提出一种新的基于几何运算的网格节点提取方法，首先对获得的图像进行二值化及均值滤波等处理，然后运用Halcon强大的算子函数库，获得网格线的亚像素精度，然后进行网格线的合并，像素点的提取，网格交点的提取等，用此种方法获得的零件表面网格节点图像坐标受灰度值的影响会比较小。最后对不同的实际零件进行平移实验，验证了基于平移的方法的可行性，为研究基于一般运动的零件的三维坐标测量提供了理论基础。
   In this paper, a new mesh node extraction method based on geometric operation is proposed. Firstly, the obtained images are binary and mean filtered, and then the sub-pixel accuracy of the mesh line is obtained by using Halcon powerful operator function library. Then the mesh line is merged, pixel point is extracted and mesh intersection is extracted. Finally, the translation ex-periments of different practical parts are carried out to verify the feasibility of the translation-based method, which provides a theoretical basis for the study of three-dimensional coordinate measurement of parts based on general motion.
 
</p></abstract><kwd-group><kwd>单目视觉，节点提取，曲线相交法，Halcon, Monocular Vision</kwd><kwd> Node Extraction</kwd><kwd> Curve Intersection</kwd><kwd> Halcon</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>摘要</title><p>本文提出一种新的基于几何运算的网格节点提取方法，首先对获得的图像进行二值化及均值滤波等处理，然后运用Halcon强大的算子函数库，获得网格线的亚像素精度，然后进行网格线的合并，像素点的提取，网格交点的提取等，用此种方法获得的零件表面网格节点图像坐标受灰度值的影响会比较小。最后对不同的实际零件进行平移实验，验证了基于平移的方法的可行性，为研究基于一般运动的零件的三维坐标测量提供了理论基础。</p></sec><sec id="s2"><title>关键词</title><p>单目视觉，节点提取，曲线相交法，Halcon</p></sec><sec id="s3"><title>Extraction of Surface Grid Node Based on Monocular Vision</title><p>Ke Shi, Qianqian Liu, Huiyu Xiang</p><p>Beijing Business University, Beijing</p><p><img src="//html.hanspub.org/file/9-2340789x4_hanspub.png" /></p><p>Received: Sep. 23<sup>rd</sup>, 2020; accepted: Oct. 7<sup>th</sup>, 2020; published: Oct. 14<sup>th</sup>, 2020</p><p><img src="//html.hanspub.org/file/9-2340789x5_hanspub.png" /></p></sec><sec id="s4"><title>ABSTRACT</title><p>In this paper, a new mesh node extraction method based on geometric operation is proposed. Firstly, the obtained images are binary and mean filtered, and then the sub-pixel accuracy of the mesh line is obtained by using Halcon powerful operator function library. Then the mesh line is merged, pixel point is extracted and mesh intersection is extracted. Finally, the translation experiments of different practical parts are carried out to verify the feasibility of the translation-based method, which provides a theoretical basis for the study of three-dimensional coordinate measurement of parts based on general motion.</p><p>Keywords:Monocular Vision, Node Extraction, Curve Intersection, Halcon</p><disp-formula id="hanspub.38037-formula34"><graphic xlink:href="//html.hanspub.org/file/9-2340789x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2020 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/9-2340789x7_hanspub.png" /> <img src="//html.hanspub.org/file/9-2340789x8_hanspub.png" /></p></sec><sec id="s5"><title>1. 引言</title><p>零件表面网格特征点三维坐标的测量在板金属应变测量与逆向工程中的应用越来越重要，传统的用三维坐标测量机来获得零件表面网格节点三维坐标的测量方法虽然测量精度高，但存在对测量环境要求高、测量效率低等缺陷，不满足现场测量的需求。视觉测量技术具有测量效率高，适应现场测量等显著优点，单目视觉测量方法应用于三维零件的非接触坐标测量，能够在很大程度上减少工作量，同时具有较高准确度的测量结果。视觉测量技术有利于零件表面网格节点的准确提取，而节点的提取是准确测量的前提。</p><p>通常基于灰度图像的特征提取算法有Harris角点检测算法 [<xref ref-type="bibr" rid="hanspub.38037-ref1">1</xref>] 、SUSAN角点检测算法 [<xref ref-type="bibr" rid="hanspub.38037-ref2">2</xref>] 以及SIFT算法 [<xref ref-type="bibr" rid="hanspub.38037-ref3">3</xref>] 等。其中使用Harris算法进行特征点检测是一种简单可行的点提取方法。图像中的特征点主要指图像中灰度值变化剧烈的点，该像素点和周围的邻近点有着明显的灰度差异。采用上述理论提取到的特征点如图1所示，一方面由于采集到的图像具有一定的噪声，即使采用图像平滑滤波的操作也不一定能将噪声完全消除，因此采用Harris特征点检测算法受噪声的影响较大，另一方面网格的线条具有一定的宽度，两条曲线相交，交点处由很多的像素点组成，使用Harris算法提取到的是曲线相交处的四个角点，不符合论文主要提取网格节点的目标。本文将用曲线相交法提取网格节点。</p><p>图1. Harris提取的特征点</p></sec><sec id="s6"><title>2. 网格节点的提取</title><sec id="s6_1"><title>2.1. 图像处理</title><p>对于机器视觉系统来说摄像机所采集到的图像只是一些灰度值不同的像素点，为了能够从图像中得到有用的信息，要求对图像进行处理。图像采集过程中，外界条件和摄像机本身的结构等因素均会造成图像存在噪声和成像不均匀的现象，为了能够保证图像信息的准确性、易提取性，需要提前对图像进行平滑滤波、二值化、灰度直方图计算、前景与背景分割等处理操作。图像中一般含有的噪声，其中均值滤波和中值滤波是两种比较简单的消除噪声的方法。</p><p>均值滤波主要采用的是平均领域灰度值，然后替代的方法，用像素邻域(2n + 1) &#215; (2m + 1)窗口内像素的平均值替换原图像中的该像素值，均值滤波在平滑噪声方面比较理想，但是会使图像的清晰度受到影响。</p><p>中值滤波在算法上比较简单，与均值滤波不同，它是一种非线性的消除噪声的方法。中值滤波是根据排序的理论获取移动窗口的中值，然后替换图像中像素点的值，能够有效抑制噪声，还可以平滑图像，消除比较严重的噪声点 [<xref ref-type="bibr" rid="hanspub.38037-ref4">4</xref>]。</p><p>中值滤波在一定程度上解决了图像清晰度受损的问题，能够做到既去除噪声又保持原有的图像清晰度 [<xref ref-type="bibr" rid="hanspub.38037-ref5">5</xref>]。在Halcon图像处理软件中算子median_image(Image : ImageMedian : MaskType, Radius, Margin)可以直接对图像进行中值滤波。</p></sec><sec id="s6_2"><title>2.2. 曲线相交法</title><p>本文主要研究的是基于平移的三维坐标测量，由于网格线条具有一定幅值，因此交点处应该是一系列的像素点，并不是唯一的。为了能够提取曲线相交处的交点中心，因此需要对线条进行处理。基本思路是提取出网格线的亚像素精度，然后合并在同一条直线上的网格线，对网格线进行水平和竖直方向的分别排序，提取出网格线的交点即是网格节点坐标。网格节点提取的具体步骤如图2所示。</p><p>图2. 网格节点提取步骤</p><sec id="s6_2_1"><title>2.2.1. 提取网格线</title><p>图像采集得到的曲线均具有一定的幅值，使用骨架化的方法获得曲线的亚像素精度的中心线。Halcon中lines_gauss(Image : Lines : Sigma, Low, High, LightDark, ExtractWidth, LineModel, CompleteJunctions:)算子能根据曲线的幅值提取出曲线的亚像素精度的中心线也是曲线的骨架，提取到的网格曲线骨架如图3所示。</p><p>图3. 提取到的网格曲线</p></sec><sec id="s6_2_2"><title>2.2.2. 合并网格线</title><p>由图3可以看出，提取出的网格曲线是分段离散的，为了方便提取网格曲线的交点，需要将位于同一曲线上的网格曲线合并成一起组成完整的曲线。Halcon中现有的union_collinear_contours_xld(Contours : UnionContours : MaxDistAbs, MaxDistRel, MaxShift, MaxAngle, Mode:)算子通过设置距离、偏离量、偏离角度、模式等参数可以较好的完成网格线的合并，合并后的网格曲线骨架如图4所示。</p><p>图4. 合并后的网格曲线</p></sec><sec id="s6_2_3"><title>2.2.3. 网格线排序</title><p>Halcon中存在的sort_contours_xld( )排序函数能够按行坐标或列坐标的大小进行排序，但是无法实现曲线在水平和竖直方向分别排序。本文中的水平方向指的是平均方向与水平轴的夹角在−45˚到45˚之间的曲线，其余方向的曲线均是竖直方向。根据角度的分类新编算子sort_rows_contours_xld( )和sort_cols_contours_xld( )能够实现水平线和竖直线的分别排序，最终网格曲线排序结果如图5所示。</p><p>图5. 网格曲线排序结果</p></sec><sec id="s6_2_4"><title>2.2.4. 网格点提取</title><p>在进行曲线回归的计算时，get_contour_xld算子可以得到曲线的像素个数及曲线上每个像素的像素坐标。使用如式(1)所示的曲线方程式作为像素点所形成直线的回归原形。</p><p>f ( x ,   y ) = a x 2 + b x y + c y 2 + d x + e y + f (1)</p><p>一方面根据拟合到的曲线方程求得曲线的交点，另一方面根据交点具有相同的像素坐标的特性，通过设置一定的约束条件寻找曲线上具有相同像素坐标的点，最后将得到的交点进行顺序编号，网格节点提取结果如图6所示。</p><p>图6. 网格节点提取结果</p></sec></sec></sec><sec id="s7"><title>3. 实验结果和分析</title><p>通过对圆柱标准零件，平面标准零件以及非标准零件进行平移试验，来验证理论的可行性及实验结果的精度。</p><sec id="s7_1"><title>3.1. 标准零件的平移实验</title><sec id="s7_1_1"><title>3.1.1. 圆柱零件的平移实验</title><p>所用零件为标准的圆柱形零件，外表面半径平均值为40.50 mm，方网格的边长平均值为5.0 mm，实验步骤及结果如下：</p><p>1) 首先摄像机采集平移前后的圆柱形零件，获得的图像如图7所示。</p><p>图7. 平移前后图像</p><p>2) 对圆柱形零件进行图像处理并进行网格节点的提取及编号，结果如图8所示。</p><p>图8. 网格节点提取</p><p>3) 对实验结果进行精度分析，试验中所采用的圆柱形零件半径为40.50 mm，所以行方向的网格节点具有有共圆性，通过对圆拟合可得出圆半径和实际测得的圆半径做比较进行精度分析，网格点圆拟合结果如图9所示。试验中采用的网格是边长为5.0 mm的正方形，网格节点在列方向上具有共线性，通过判断竖直方向的节点距离与实际距离的差值可以得出实验的测量精度，最终结果数据如表1所示。</p><p>图9. 网格点圆拟合</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Precision analysis of 3D coordinates of grid nod</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >类型</th><th align="center" valign="middle" >理论长度(mm)</th><th align="center" valign="middle" >最小长度(mm)</th><th align="center" valign="middle" >最大长度(mm)</th><th align="center" valign="middle" >平均长度(mm)</th><th align="center" valign="middle" >长度标准差</th></tr></thead><tr><td align="center" valign="middle" >半径R</td><td align="center" valign="middle" >40.50</td><td align="center" valign="middle" >40.23</td><td align="center" valign="middle" >40.24</td><td align="center" valign="middle" >40.23</td><td align="center" valign="middle" >7.49486e−18</td></tr><tr><td align="center" valign="middle" >边长L</td><td align="center" valign="middle" >5.0</td><td align="center" valign="middle" >4.93</td><td align="center" valign="middle" >5.05</td><td align="center" valign="middle" >5.01</td><td align="center" valign="middle" >2.7623e−005</td></tr></tbody></table></table-wrap><p>表1. 网格节点三维坐标的精度分析</p></sec><sec id="s7_1_2"><title>3.1.2. 平面零件的平移实验</title><p>所用零件为标准的平面零件，方网格的边长平均值为5.0 mm，平移距离为19.66 mm，实验步骤及结果如下：</p><p>1) 首先摄像机采集平移前后的平面零件，获得的图像如图10所示。</p><p>2) 对平面零件进行图像处理并进行网格节点的提取及编号，结果如图11所示。</p><p>图10. 平移前后图像</p><p>图11. 网格节点提取</p></sec></sec><sec id="s7_2"><title>3.2. 非标准零件的平移实验</title><p>标准零件主要是为了验证理论的可行性及实验结果的精度，非标准零件的实验与实际工况更加接近，可以用来验证理论方法具有实际工程应用的意义与价值。实验中使用的贴有方网格的非标准零件如图12所示。实验过程中，将非标准零件平移20 mm，选取其中的一部分感兴趣区域进行实验，感兴趣区域中包含119个网格节点。具体实验步骤如下：</p><p>图12. 非标准零件</p><p>1) 首先摄像机采集平移前后的非标准零件，获得的图像如图13所示。</p><p>图13. 平移前后图像</p><p>2) 对非标准零件进行图像处理，使用算子draw_region (ROI, WindowHandle)选取其中一部分的感兴趣区域ROI，ROI如图14所示，然后进行网格线的提取、合并、排序，最后进行网格节点的提取及编号，结果如图15所示。</p><p>图14. ROI</p><p>图15. 网格节点提取</p><p>3) 在Matlab中进行三维坐标的计算及将三维坐标重建，重建结果如图16所示，由于非标准零件的形状不规则，原本规则的网格纸印制到板料上，在零件成形的过程中网格形状发生改变，平面、距离等发生改变，因此不易进行精度分析的操作。</p><p>图16. 重建结果</p></sec></sec><sec id="s8"><title>4. 结论</title><p>根据网格节点的特点，使用一种新的基于几何运算的网格节点提取方法。通过二值化、均值滤波，中值滤波等进行图像处理，将图像处理软件Halcon引入到网格节点三维坐标测量中，大大提高了效率和准确度。在测量过程中，根据单目视觉的非线性模型得到了准确的标定结果，采用新的网格交点的提取，舍弃以往的受灰度值影响较大的特征点提取的算法，通过进行曲线的骨架化操作，精确地提取出网格线的中心线，进而求出网格线的交点。最后对不同的实际零件进行实验，根据实验结果验证了基于平移方法的可行性，为研究基于一般运动的零件的三维坐标测量提供理论基础。</p></sec><sec id="s9"><title>文章引用</title><p>史 珂,刘倩倩,项辉宇. 基于单目视觉的零件表面网格节点坐标测量Extraction of Surface Grid Node Based on Monocular Vision[J]. 机械工程与技术, 2020, 09(05): 445-454. https://doi.org/10.12677/MET.2020.95048</p></sec><sec id="s10"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.38037-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Harris, C. and Stephens, M. (1981) A Combine Corner and Edge Detector. Fourth Alvey Vision Conference, 147-151.</mixed-citation></ref><ref id="hanspub.38037-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Amith, S.M. and Brady, M. (2015) A New Approach to Low Level Image Processing. International Journal of Computer Vision, 23, 45-78.</mixed-citation></ref><ref id="hanspub.38037-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Nguyen, T., Park, E.A., Han, J., et al. (2014) Object Detection Using Scale Invariant Feature Transform. Springer International Publishing, 65-72. &lt;br&gt;https://doi.org/10.1007/978-3-319-01796-9_7</mixed-citation></ref><ref id="hanspub.38037-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">张克兵. 基于双目视觉的特征目标三维信息构建[D]: [硕士学位论文]. 哈尔滨: 哈尔滨工业大学, 2012.</mixed-citation></ref><ref id="hanspub.38037-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">吴玉莲. 图像处理的中值滤波方法及其应用[D]: [硕士学位论文]. 西安: 西安电子科技大学, 2006.</mixed-citation></ref></ref-list></back></article>