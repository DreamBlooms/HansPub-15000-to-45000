<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2019.91013</article-id><article-id pub-id-type="publisher-id">CSA-28539</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20190100000_90498048.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  改进运动模板与直方图匹配的视频典型目标检测方法
  Typical Video Target Detection Method Based on Improved Motion Template and Histogram Matching
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>张</surname><given-names>永梅</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>冯</surname><given-names>超</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>马</surname><given-names>健喆</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff3"><addr-line>北京华龙通科技有限公司，北京</addr-line></aff><aff id="aff2"><addr-line>北方工业大学计算机学院，北京</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>08</day><month>01</month><year>2019</year></pub-date><volume>09</volume><issue>01</issue><fpage>106</fpage><lpage>118</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   针对经典运动模板法提取运动目标轮廓出现的空洞和不能提取完整轮廓的问题，以及运动速度缓慢时误检率高的问题，本文提出了一种改进的运动模板和HSV直方图匹配相融合的视频运动目标检测方法。采用三帧差分和改进的OSTU自适应阈值法获得潜在的运动目标轮廓，并根据每个像素点与目标轮廓滞留时间的时序关系构建运动历史模板，利用逐级洪水泛滥法分割目标潜在区域，并计算目标潜在区域与目标模板的Bhattacharyya距离，从而检测典型目标区域。实验结果表明，该方法有助于解决传统运动模板法提取运动目标轮廓产生的空洞和不能提取完整轮廓的问题，而且精确率比背景减除法、运动模板法明显提高。 The existing video moving target detection algorithms cannot detect the complete regions of moving targets and the hole phenomena in extracting the contour of video moving targets using classical motion template method and the false detection rate is higher when slower moving speed, the paper presents a video moving target detection method based on fusion of improved motion template and HSV histogram matching, adopts the three-frame difference and improved OSTU adaptive threshold method to obtain the contours of the potential moving targets, constructs the motion history template according to the time series relationship between each pixel point and the target contour retention time, segments the potential moving target areas using the stepwise flooding method, and calculates the Bhattacharyya distance between the potential target area and the target template area so as to detect the typical targets. The experiment results show the proposed method can help to solve the problems of the hole phenomena and incomplete contours for the typical target using classical motion template, and the average rate of detection accuracy is obviously higher than that of the background subtraction method and the motion template method respectively. 
  
 
</p></abstract><kwd-group><kwd>改进的运动模板，三帧差分法，改进的OSTU自适应阈值，逐级洪水泛滥法，Bhattacharyya距离, Improved Motion Template</kwd><kwd> Three-Frame Difference Method</kwd><kwd> Improved OSTU Adaptive Threshold</kwd><kwd> Stepwise Flooding Method</kwd><kwd> Bhattacharyya Distance</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>改进运动模板与直方图匹配的视频典型目标检测方法<sup> </sup></title><p>张永梅<sup>1</sup>，冯超<sup>1</sup>，马健喆<sup>2</sup></p><p><sup>1</sup>北方工业大学计算机学院，北京</p><p><sup>2</sup>北京华龙通科技有限公司，北京</p><p><img src="//html.hanspub.org/file/13-1541252x1_hanspub.png" /></p><p>收稿日期：2018年12月31日；录用日期：2019年1月14日；发布日期：2019年1月21日</p><disp-formula id="hanspub.28539-formula32"><graphic xlink:href="//html.hanspub.org/file/13-1541252x5_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>针对经典运动模板法提取运动目标轮廓出现的空洞和不能提取完整轮廓的问题，以及运动速度缓慢时误检率高的问题，本文提出了一种改进的运动模板和HSV直方图匹配相融合的视频运动目标检测方法。采用三帧差分和改进的OSTU自适应阈值法获得潜在的运动目标轮廓，并根据每个像素点与目标轮廓滞留时间的时序关系构建运动历史模板，利用逐级洪水泛滥法分割目标潜在区域，并计算目标潜在区域与目标模板的Bhattacharyya距离，从而检测典型目标区域。实验结果表明，该方法有助于解决传统运动模板法提取运动目标轮廓产生的空洞和不能提取完整轮廓的问题，而且精确率比背景减除法、运动模板法明显提高。</p><p>关键词 :改进的运动模板，三帧差分法，改进的OSTU自适应阈值，逐级洪水泛滥法，Bhattacharyya距离</p><disp-formula id="hanspub.28539-formula33"><graphic xlink:href="//html.hanspub.org/file/13-1541252x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2019 by authors and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/13-1541252x7_hanspub.png" /> <img src="//html.hanspub.org/file/13-1541252x8_hanspub.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>视频目标的检测与识别是计算机视觉领域的一个重要课题 [<xref ref-type="bibr" rid="hanspub.28539-ref1">1</xref>] ，引起了国内外学者的广泛关注，国内外学者在视频目标检测方面取得了一定成果。目前常用的视频目标检测方法包括基于帧差法的轮廓检测、基于直方图匹配法的运动目标检测、基于光流法的运动目标检测以及一些组合方法，这些方法虽然有很好的检测效果，但在某些方面仍存在一些缺陷。</p><p>为了更好地解决复杂场景中运动目标检测准确率低的问题，Qingyu Guo，Zheng Zhang提出一种融合高斯混合模型和帧间差分法的视频运动目标检测方法，该方法使用帧间差分法、高斯混合模型和K-means聚类检测视频运动目标的轮廓，利用C#和EmguCV框架检测运动目标 [<xref ref-type="bibr" rid="hanspub.28539-ref2">2</xref>] 。该方法实现简单，检测的准确率比经典的高斯混合模型和帧差法的准确率较高，但是该方法并不能检测视频中运动速度缓慢或静止的目标，而且当间隔时间设置不合理时，该方法检测的准确率较低。</p><p>为了解决动态场景中经典运动目标检测算法检测准确率低和鲁棒性差的问题，Wang Huibin、Chen Zhe、Lu Miao等人提出一种基于运动显著概率图的运动目标检测方法。该方法在时间尺度上构建了包含运动目标信息的长短期时间序列组，并利用TFT (Temporal Fourier Transform)方法计算运动目标的显著性值，根据显著性值得到条件运动的显著性概率图，采用全概率公式计算后验概率值，从而得到运动目标的显著性概率图，以概率图为基础，对像素的空间信息进行建模，检测运动目标。该方法能够在复杂噪声环境下准确检测运动目标区域，并且能够提高运动目标检测的鲁棒性和普适性，但是该方法并不能检测到运动目标的完整区域 [<xref ref-type="bibr" rid="hanspub.28539-ref3">3</xref>] 。</p><p>为了有效地解决运动目标检测出现的空洞现象以及无法得到完整运动目标的问题，贾建英、董安国提出了一种基于联合直方图的运动目标检测算法，利用联合直方图构造相邻帧的相似性，对相邻两帧视频进行分块，并计算每块的联合直方图，同时结合相似性指标消除背景块，从而检测视频中的运动目标 [<xref ref-type="bibr" rid="hanspub.28539-ref4">4</xref>] 。该方法在无背景遮挡的情况下能够很好地检测到完整的运动目标，但是当有背景遮挡时，并不能完整地检测到运动目标，检测效果比经典的检测算法还要差。</p><p>针对运动目标检测领域中帧差法和背景差分法的缺陷，孙挺、齐迎春、耿国华提出了一种融合帧差法和背景差分的运动目标检测算法，该算法采用混合高斯建立背景模型提取运动目标轮廓，利用连续三帧差分法以及自适应差分阈值的方法提取运动目标的轮廓，将得到的两种差分结果进行融合并进行形态学处理提取运动目标 [<xref ref-type="bibr" rid="hanspub.28539-ref5">5</xref>] 。该方法能够有效地抑制算法产生的噪声，解决产生的空洞现象，而且具有普适性，但是当有遮挡时，提取的运动目标区域并不完整。</p><p>目前视频目标检测方法主要存在两个问题：由于有遮挡或光照干扰时导致提取的运动目标轮廓出现空洞现象进而导致提取的轮廓不完整甚至无法检测到完整的运动目标轮廓；由于运动速度缓慢导致运动目标检测精确率低。</p><p>针对上述问题，本文提出一种基于改进的运动模板和直方图匹配的视频运动目标检测方法，本文使用三帧差分法和自适应阈值代替传统运动模板中的帧差和二值化法来提取运动目标的轮廓，有效地解决了提取运动目标轮廓时产生的空洞和提取运动目标轮廓不完整的问题。该方法既能克服运动模板检测不到视频中运动速度缓慢运动目标的缺陷，又能克服直方图匹配法对光线敏感的不足，同时又能够充分发挥运动模板和直方图匹配各自的优势。该方法不仅能够解决提取轮廓时产生的空洞和提取运动目标轮廓不完整的问题，而且能够有效地检测到运动目标的完整区域，从而提高了运动目标检测的精确率。</p></sec><sec id="s4"><title>2. 基于改进运动模板和直方图匹配的视频典型目标检测方法</title><p>本文提出了一种基于改进运动模板和直方图匹配的视频典型目标检测方法，利用改进运动模板法检测视频中运动目标的潜在区域，采用HSV直方图匹配法对潜在目标区域进行二次确认，从而检测最终的典型目标区域，该方法有助于提高视频中典型目标检测的精确率。本文的视频典型目标主要包括坦克和装甲车。</p><sec id="s4_1"><title>2.1. 传统运动模板法</title><p>运动模板法由麻省理工学院多媒体实验室的A. Bobick和J. Davis于1996年提出 [<xref ref-type="bibr" rid="hanspub.28539-ref6">6</xref>] ，为了提高该算法对运动目标检测的实时性，J. Davis对该算法进行了改进，并将运动目标的方向信息加入到运动模板算法，从而形成了现在常用的运动模板检测法。运动模板是一种检测运动目标并计算其运动方向的模型，该模型分为运动目标的轮廓图像(silhouette, silh)获取、运动历史图像(Motion History Image, mhi)的构建、计算运动目标的梯度方向和运动目标的分割四部分。</p><p>利用运动模板法检测运动目标时，需要获取运动目标的轮廓图像。采用帧差法对相邻两帧的灰度图像进行减法处理，从而获得差分图像，对差分图像进行二值化处理和去噪处理，从而获得运动目标的轮廓图像。</p><p>在获得运动目标的轮廓图像后，根据公式(1)对运动目标的轮廓图像进行处理，得到运动目标的运动历史图像。运动历史图像中的像素由运动目标轮廓图像中的像素和轮廓图像滞留时间确定，表示轮廓图像随时间的变化关系，具体的处理方法如公式(1)所示。</p><disp-formula id="hanspub.28539-formula34"><label>(1)</label><graphic position="anchor" xlink:href="//html.hanspub.org/file/13-1541252x9_hanspub.png"  xlink:type="simple"/></disp-formula><p>公式(1)中的 t i m e s t a m p 表示当前时间滞留值， d u r a t i o n 表示滞留时间的最大值 [<xref ref-type="bibr" rid="hanspub.28539-ref7">7</xref>] 。当轮廓图像在当前时间滞留值范围内出现时，mhi像素值设为当前时间滞留值；当运动目标轮廓图像未出现或在很长时间前出现过时，mhi像素值设为0。</p><p>本文利用运动模板法将mhi图像分割为独立的区域以便于运动目标检测。分割算法具体步骤如下：</p><p>(1) 扫描mhi图像直到寻找到当前时间滞留范围内的像素点，该像素点为最新当前时间的轮廓区域的边界点；</p><p>(2) 继续搜索当前时间最新轮廓区域的边界以寻找紧邻当前边界外围的最近运动区域。当发现这样的运动区域时，采用逐级洪水泛滥法分割感兴趣目标的当前位置，逐级洪水泛滥分割算法步骤如下：</p><p>① 选取mhi图像中的一点标记作为种子像素点；</p><p>② 检测种子像素点的颜色，并对该像素点进行8方向搜索，检测其邻近像素点的颜色是否满足设置的阈值范围，若满足，则将该像素点的颜色填充为种子像素点的颜色值，即合并当前像素点与种子像素点构成连通区域，否则不进行处理；</p><p>③ 重复①、②直至mhi图像都被处理；</p><p>④ 采用阈值分割法从mhi图像中分割感兴趣的目标，本文统计图像中各像素点的值，并计算图像中各像素点值的均值与方差，将均值与3倍方差之和作为分割阈值；</p><p>(3) 保存(2)分割的感兴趣目标的当前位置；</p><p>(4) 重复步骤(2)和(3)，直至找到所有区域。</p><p>采用运动模板法得到含有运动方向的运动目标的潜在区域，但是，这些潜在区域中可能没有含有运动目标，因此，为了提高运动目标的检测精确率，本文采用HSV直方图匹配法进一步检测潜在区域是否含有运动目标以降低误检率。</p></sec><sec id="s4_2"><title>2.2. 直方图匹配法</title><p>颜色特征最显著的特点是具有旋转不变性，并且在大小和方向上具有鲁棒性；另外，其处理速度较快，适合应用在对速度要求较高的领域 [<xref ref-type="bibr" rid="hanspub.28539-ref8">8</xref>] 。由于视频帧变化较快，帧与帧之间时间间隔较短，在检测视频运动目标时应采用速度较快的算法，因此，本文利用颜色直方图匹配算法来检测视频运动目标。</p><p>常用的颜色直方图匹配算法包括RGB直方图匹配算法、HSV直方图匹配算法。由于RGB颜色空间是由0~255这256个数值表示，不够直观，而且根据RGB数值很难判断该数值所代表的颜色，RGB颜色空间分布不均匀，当2个颜色相近时其R、G、B数值可能相差很大。HSV颜色空间更符合人类感知颜色的色彩空间，其表示方法类似于人类感知颜色的方式，具有很强的感知度 [<xref ref-type="bibr" rid="hanspub.28539-ref9">9</xref>] ，并且其计算相对简单。本文采用HSV颜色空间直方图匹配算法检测视频运动目标，检测结果更符合人眼观测效果。</p><p>HSV颜色空间将颜色分为3个独立的空间向量，H表示色彩的基本属性；S表示色彩的纯度，S值越高其色彩越纯；V表示色彩的明亮程度。由于色彩的明亮程度易受光照的影响，在有光照影响的条件下，V的检测值会与真实值相差很大，因此，本文选择使用H、S色彩向量作为直方图匹配算法的基础色彩向量。</p><p>由于视频帧为RGB彩色图像，因此，在使用HSV直方图匹配算法时，首先将RGB彩色图像转化为HSV图像，需要分别统计潜在区域的H、S色彩直方图以及目标的H、S色彩直方图。由于典型目标的颜色构成较单一，因此，本文将H的取值范围分成N = 10个区间，S的取值范围分成P = 5个区间，则H分量的每个区间的色度数量为k = 360/N，记作 K 1 , ⋯ , K k ，S分量的每个区间的色度数量为m = 1/P，记作 M 1 , ⋯ , M m ，分别统计每个区间的色度像素个数，建立颜色直方图，则H、S的色彩空间表示如公式(2)、(3)所示。</p><p>H = ( H 1 , H 2 , ⋯ , H 10 ) (2)</p><p>S = ( S 1 , S 2 , ⋯ , S 5 ) (3)</p><p>H、S色彩直方图中每个柱的值可以表示为 H i ( i = 1 , 2 , ⋯ , k ) ， S j ( j = 1 , 2 , ⋯ , m ) ，每个柱值的计算方法如公式(4)、(5)所示。</p><p>H i = ∑ f i ( h ( x , y ) ) , i = 1 , 2 , ⋯ , k (4)</p><p>S j = ∑ f i ( h ( x , y ) ) , j = 1 , 2 , ⋯ , m (5)</p><p>公式(4)、(5)中的 f 函数为分段函数，当像素满足相应的区间时，其值为1，反之则为0。当潜在区域和目标区域的H、S色彩直方图都计算完成后，根据Bhattacharyya距离计算潜在区域和目标区域在H、S色彩空间上的相似度，将H、S色彩空间上的相似度分别与相应权重相乘，得到一个新的相似度值，并根据相似度的大小来判别潜在区域是否含有典型目标，从而检测潜在区域是否含有典型目标。Bhattacharyya距离公式如公式(6)、(7)所示。</p><p>D B ( p , q ) = − ln ( B C ( p , q ) ) (6)</p><p>其中：</p><p>B C ( p , q ) = ∑ x ∈ X p ( x ) q ( x ) (7)</p><p>公式(6)中的 D B 为Bhattacharyya距离，表示潜在运动目标区域与目标区域的相似性， B C ( p , q ) 为Bhattacharyya系数，该系数可以用来表示两个样本相对接近的程度，其中 p 和 q 分别表示视频帧图像提取的潜在目标区域和模板图像在HSV色彩空间中<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/13-1541252x27_hanspub.png" xlink:type="simple"/></inline-formula>色彩分量上各像素值构成的向量。</p></sec><sec id="s4_3"><title>2.3. 融合改进运动模板和直方图匹配的视频典型目标检测方法</title><p>传统运动模板法是一种常用的运动目标检测算法，利用帧差和二值化法获得运动目标的轮廓，该算法具有帧差法对光线不敏感、能适应各种动态环境的优点 [<xref ref-type="bibr" rid="hanspub.28539-ref10">10</xref>] 。因此，运动模板法常被应用于姿态识别，是一种有效的识别运动目标方法。但该算法在提取运动目标轮廓时会形成空洞现象进而导致提取的目标轮廓不完整，因此，本文在传统运动模板的基础上进行了改进，采用基于三帧差分和自适应阈值法的运动模板来检测运动目标。三帧差分公式如(8)、(9)、(10)所示。</p><p>P k ( x , y ) = | f k ( x , y ) − f k − 1 ( x , y ) | (8)</p><p>R k ( x , y ) = { 0 , P k ( x , y ) &lt; T 3 1 , P ( x , y ) ≥ T 3 (9)</p><p>R k ( x , y ) = { 1 , R k ( x , y ) ∩ R k + 1 ( x , y ) = 1 0 , otherwise (10)</p><p>公式(8)表示相邻两帧帧间差分的计算公式，公式(8)中 P k ( x , y ) 表示帧间差分图像， R k ( x , y ) 表示1二值化图像， T 3 是分割阈值， f k ( x , y ) 、 f k − 1 ( x , y ) 分别表示第k帧、k – 1帧视频。</p><p>由于分割阈值的选择对运动目标轮廓的提取影响很大，传统方法阈值的选取需要根据视频、背景和运动目标的不同来相应地选择分割阈值。当三者中任何一个因素发生变化，选择的阈值可能就不再适用。为了消除固定分割阈值对提取的运动目标轮廓影响，本文采用自适应阈值方法来设定分割阈值，该方法充分考虑了视频中运动目标的类型、背景等因素，并按照一定的方式自动选取阈值。</p><p>本文采用改进的OSTU自适应阈值法进行分割，在设定阈值时首先统计视频帧图像中像素值的中位数、最大像素点值和最小像素点值，根据公式(11)求出初始阈值 T h 0 ，根据初始阈值进行分割，分别计算分割后图像非目标区域和目标区域各像素值的均值 μ 1 、 μ 2 ，根据公式(12)计算分割后两类间的差异度，并判断是否达到迭代数，若达到迭代数，则选择最大 s 值对应的 T h 0 作为分割阈值，否则将 T h 0 增加一个步长，迭代数加1，继续执行迭代，直至达到迭代数。一般设置的迭代数为15，步长值为0.1。阈值选取的具体步骤如下。</p><p>1) 设定初始阈值 T h 0 、迭代数 T = 0 及每步阈值增加的步长step，阈值的设定如公式(11)所示；</p><p>T h 0 = ( median [ P k ( x , y ) ] + max [ P k ( x , y ) ] + min [ P k ( x , y ) ] ) / 4 (11)</p><p>公式(11) median函数表示帧差图像各像素点的中位数，max函数表示各像素点的最大值，min函数表示各像素点的最小值。</p><p>2) 按照公式(12)计算分割后两类间的差异度；</p><p>S = ( T h 0 − μ 1 ) ( μ 2 − T h 0 ) ( μ 2 − μ ) 2 (12)</p><p>公式(12)中， μ 1 、 μ 2 分别表示分割后两部分对应像素的均值。</p><p>3) 检查是否达到迭代数，若达到迭代数则停止迭代，并选取最大的 s 对应的阈值 T h 0 作为分割阈值 ，否则继续执行步骤(4)；</p><p>4) 按照公式(13)增加阈值，公式(14)增加迭代数，并重复步骤(2)、(3)；</p><p>T h 0 = T h 0 + step (13)</p><p>T = T + 1 (14)</p><p>改进后的运动模板提取视频中运动目标轮廓的实验结果如图1所示。由图1可以看到，改进的运动模板法能够较为完整地提取视频中运动目标的轮廓，而且提取的目标轮廓比传统运动模板法提取的目标轮廓较好。传统运动模板法虽然提取了视频中运动目标的轮廓，但是由于视频速度较快，相邻帧背景变换较大，因此，传统运动模板法检测到的目标轮廓存在较多的非运动目标区域，会对后续运动目标潜在区域的检测造成很大影响。本文改进的运动模板法采用三帧差分法和改进的OSTU自适应阈值法提取目标潜在区域，从图(c)、(f)可以看到本文方法可以很好地提取目标的轮廓区域，尤其在复杂背景时，效果更为明显，提取的运动目标轮廓更加清晰，从而有助于提高运动目标检测的精确率。</p><p>针对逐级洪水泛滥分割法需要人工选择初始像素点作为种子像素点带来的不便，本文提出了一种直方图阈值法选择种子像素点的逐级洪水泛滥的分割方法，从而提高逐级洪水泛滥分割法的自动化程度。本文首先通过直方图阈值法来选取种子像素点，然后对种子像素点进行8方向搜索并合并像素点颜色处于设定阈值范围内的邻近像素点构成连通域，最后采用阈值分割法从当前背景区域分割感兴趣目标。</p><p>由于运动模板法对运动速度较慢的目标不敏感，甚至会丢失运动目标，因此，本文首先利用改进的运动模板法检测运动目标的潜在区域，利用HSV直方图匹配法对潜在区域进行二次确认，提高了运动目标检测的精确率。</p><p>颜色直方图描述的是色彩在图像中的分布，具有平移、旋转不变性，对图像中子对象所在的位置和方向的变化不敏感，具有很强的鲁棒性 [<xref ref-type="bibr" rid="hanspub.28539-ref11">11</xref>] 。直方图匹配算法利用图像局部直方图的颜色特征作为衡量标准，对比并计算图像局部区域与运动目标之间的相似度 [<xref ref-type="bibr" rid="hanspub.28539-ref12">12</xref>] ，从而得到图像局部区域与运动目标在颜色特征方面的相似度因子，该因子作为判别图像局部区域是否为运动目标的依据。该方法计算简单，只利用图像中的颜色特征不受运动目标运动速度的影响，具有很高的检测率。但是，该算法容易受到光照影响，在有光照影响时，会极大地降低运动目标检测的准确率。本文提出了一种融合改进运动模板和HSV直方图匹配法的视频典型目标检测方法，该融合方法的流程图如图2所示。</p><p>图1. 不同背景下提取的轮廓图像。(a) 原视频帧；(b) 传统运动模板法提取的轮廓图像；(c) 改进的运动模板提取的轮廓图像；(d) 原视频帧；(e) 传统运动模板提取的轮廓图像；(f) 改进后运动模板提取的轮廓图像</p><p>图2. 改进的运动模板和直方图匹配的典型目标检测方法流程图</p><p>首先读取视频图像，并对视频图像进行三帧差分处理和自适应阈值处理，获取典型目标的潜在轮廓图像，根据公式(1)对潜在轮廓图像进行处理，获取运动目标的历史图像，采用逐级洪水泛滥分割法将运动历史图像分割为子独立区域，从而得到可能包含有运动目标的潜在区域，提取子潜在区域的HSV色彩空间在H、S色彩向量的直方图，根据公式(6)计算子潜在区域与运动目标在H、S色彩向量上的Bhattacharyya距离，并根据公式(15)得到最终的相似度，并根据相似度值，判别子独立区域是否含有运动目标，从而有助于提高运动目标检测的精确率。HSV直方图匹配的阈值越低，表示两幅图像中的目标区域越相似，本文通过查阅大量文献将阈值设为0.2。</p><p>{ D B = D B H * w 1 + D B S * w 2 w 1 + w 2 = 1 (15)</p></sec></sec><sec id="s5"><title>3. 实验结果与分析</title><p>本文利用Python编程语言以及OpenCV-Contrib视频处理库设计实现了融合运动模板和HSV直方图匹配的视频运动目标检测。数据主要来自网上获取到的视频数据，主要利用两种场景下共100个视频来验证本文方法的有效性，每个视频大约2分钟时长，而且每个视频包含400多帧。两种场景分别为：典型目标运动缓慢的视频，以及有背景干扰的视频，并分别与运动模板法、背景减除法的检测结果进行了比较。检测结果如图3、4所示。</p><p>图3. 运动速度缓慢视频的实验结果。(a) 第90帧视频；(b) 背景减除法检测结果；(c) 历史运动模板；(d) 直方图匹配模板；(e) 运动模板法检测结果；(f) 本文方法检测结果；(g) 第95帧视频；(h) 背景减除法检测结果；(i) 历史运动模板；(j) 运动模板检测结果；(k) 本文方法检测结果</p><p>图4. 背景与运动目标颜色相似视频的实验结果。(a) 第130帧视频；(b) 背景减除法检测结果；(c) 历史运动模板；(d) 直方图匹配模板；(e) 运动模板法检测结果；(f) 本文方法检测结果；(g) 第205帧视频；(h) 背景减除法检测结果；(i) 历史运动模板；(j) 运动模板检测结果；(k) 本文方法检测结果</p><p>图3为同一类型的视频，采用(d)的直方图匹配模板。(c)、(i)分别表示第90帧和第95帧视频运动模板检测法采用的运动模板，图中白色区域表示运动模板法检测的潜在运动区域，图中若包含非连通区域，则该方法将相应部分的非连通区域标记出来作为检测结果。</p><p>从图3检测结果可以看到，本文方法的检测结果较好，能够较为完整地提取视频中的典型目标区域；由于背景减除法检测的结果易受背景模板的影响，而且检测准确率低，尽管背景减除法在第90帧完整地提取了目标区域，但也检测出了两个非目标区域，在第95帧时背景减除法并没有提取出目标区域；运动模板检测法易受运动速度影响，运动模板法在第90帧和第95帧虽然都提取出了目标，但是提取的非目标区域也较多，而且提取的目标区域并不完整。</p><p>图4是同一类型视频，采用(d)直方图匹配模板。(c)、(i)分别为第130帧和第205帧的历史运动模板，白色部分当前时刻表示运动目标，黑色部分表示非目标区域，或者过去时刻的运动区域。由(i)可以看到，白色部分较多，导致运动模板法检测准确率较低。</p><p>从图4检测结果可以看到，本文方法的检测结果较好，由于图4中的背景与目标的颜色较为相似，所以背景减除法检测的结果中包含了非目标区域，而且包含的非目标区域比检测正确的目标区域还多，所以导致其检测准确率较低；而运动模板使用帧差法来提取目标的轮廓，所以其检测结果也相应地受到了背景干扰，进而导致其检测结果也存在误检测的区域。本文方法融合了改进的运动模板和HSV直方图匹配法，虽然其检测结果也会受到背景的影响，但是HSV直方图匹配法则可以进一步对运动模板法检测的区域进行匹配，从而在一定程度上剔除了误检的区域，进而有助于提高运动模板法检测的准确率。</p><p>本文方法在理论上与文献 [<xref ref-type="bibr" rid="hanspub.28539-ref13">13</xref>] 方法进行了对比。为了解决混合高斯背景模型由于光照突变导致运动目标出现误检的问题，以及由于运动目标突然运动出现“鬼影”的问题，文献 [<xref ref-type="bibr" rid="hanspub.28539-ref13">13</xref>] 提出了一种基于三帧差分的混合高斯背景模型来检测运动目标 [<xref ref-type="bibr" rid="hanspub.28539-ref13">13</xref>] 。该方法使用三帧差分法对图像进行处理以获取目标的轮廓特征，采用混合高斯背景模型来检测运动目标。在构造混合高斯背景模型时，利用基于统计方法来初始化混合高斯模型的参数，在初始化模型参数过程中，该方法利用 A 1 、 A 2 两个累加器矩阵来记录灰度图像中满足相应规则的像素点的个数。 A 1 、 A 2 各个位置上的元素值的更新方式如公式(16)所示。</p><p>A ( x ) = { A 1 i + 1 | χ − μ | &lt; α λ A 2 i + 1 | χ − μ ′ | &lt; α λ (16)</p><p>利用公式(16)对 A 1 、 A 2 各个位置的元素值更新后，还需对其所对应的均值进行更新。式中的α、λ分别为常数，α取值为4~10，λ取值为2.5。</p><p>初始化模型参数后，需要挑选出混合高斯模型中的一个高斯分布，按公式(17)进行初始化，并计算其对应的方差 σ 2 。同时按照公式(18)初始化混合高斯模型中其他的高斯分布。</p><p>{ μ = { μ Α 1 i &gt; Α 2 i μ ′ Α 1 i ≤ Α 2 i ω κ = ω Μ (17)</p><p>{ μ Κ = 0 σ Κ 2 = σ Μ ω Κ = ε (18)</p><p>当获取到一帧新的图像后，且其像素点满足混合高斯模型中的某一高斯分布后，需要按照公式(19)更新该高斯分布参数。</p><p>{ ω k , t = ( 1 − α ) ω k , t − 1 + α μ k , t = ( 1 − ρ ) μ k , t − 1 + ρ χ t σ k , t = ( 1 − ρ ) σ k , t − 1 2 + ρ ( χ t − μ k , t ) (19)</p><p>式中 α 代表权重学习率， 0 ≤ α ≤ 1 ，且 决定权重的更新速度，并且该值也会影响高斯分布的更新速度， ρ 表示高斯分布参数的学习率， ρ = α / ω k , t 。</p><p>为了消除极端值的影响，更新混合高斯背景模型后，需要归一化混合高斯模型中各个高斯分布的权重参数。计算各个高斯分布权重参数的和，当求出的权重参数和大于给定阈值时，就判定对应的高斯分布为背景，其余的高斯分布为运动目标对应的高斯分布，从而检测图像中的运动目标。该方法虽然解决了混合高斯背景模型由于光照突变导致运动目标出现误检的问题，以及由于运动目标突然运动出现“鬼影”的问题，但其精确率并不高。</p><p>本文从精确率、召回率和运行时间等评测指标与背景减除法、运动模板法进行了定性比较 [<xref ref-type="bibr" rid="hanspub.28539-ref14">14</xref>] 。表中的平均检测精确率、平均检测召回率的计算方式如公式(20)、(21)所示。</p><p>平均检测精确率： Pre = 1 n ∑ i = 1 n T T i T T i + F T i (20)</p><p>平均检测召回率： Rec = 1 n ∑ i = 1 n T T i T T i + F F i (21)</p><p>公式(20)、(21)中的 T T i 表示实际为目标区域检测结果也为目标区域的个数， F T i 表示实际为非目标区域却检测为目标区域的个数， F F i 表示实际为目标区域却未检测出的区域个数，本文结合视觉观察效果统计上式中三个变量的值；平均检测精确率反映了检测到的目标区域个数与所检测区域总数的比例，该值用来评价目标检测算法检测效果的好坏，该值越大，表示该算法的检测效果越好；平均检测召回率反映了检测到的目标区域个数与正确目标区域总数的比例，该值用来评价目标检测算法的查全率，该值越大，表示该算法的检测效果越好；n表示检测的次数，本文取n为10次，三种方法对比结果如表1所示。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> The comparison result of three method</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >视频类型</th><th align="center" valign="middle" >算法</th><th align="center" valign="middle" >平均检测精确率(%)</th><th align="center" valign="middle" >平均检测召回率(%)</th><th align="center" valign="middle" >平均运行时间(s)</th></tr></thead><tr><td align="center" valign="middle"  rowspan="3"  >运行速度缓慢</td><td align="center" valign="middle" >背景减除法</td><td align="center" valign="middle" >78.33</td><td align="center" valign="middle" >56.04</td><td align="center" valign="middle" >20</td></tr><tr><td align="center" valign="middle" >运动模板法</td><td align="center" valign="middle" >84.47</td><td align="center" valign="middle" >62.52</td><td align="center" valign="middle" >15</td></tr><tr><td align="center" valign="middle" >本文方法</td><td align="center" valign="middle" >93.75</td><td align="center" valign="middle" >73.59</td><td align="center" valign="middle" >18</td></tr><tr><td align="center" valign="middle"  rowspan="3"  >复杂背景</td><td align="center" valign="middle" >背景减除法</td><td align="center" valign="middle" >73.07</td><td align="center" valign="middle" >58.42</td><td align="center" valign="middle" >22</td></tr><tr><td align="center" valign="middle" >运动模板法</td><td align="center" valign="middle" >82.52</td><td align="center" valign="middle" >60.58</td><td align="center" valign="middle" >14</td></tr><tr><td align="center" valign="middle" >本文方法</td><td align="center" valign="middle" >90.08</td><td align="center" valign="middle" >72.34</td><td align="center" valign="middle" >17</td></tr></tbody></table></table-wrap><p>表1. 三种方法对比统计表</p><p>由表1可以看到，在不同类型视频中，本文方法视频典型目标检测的精确率比其他两种方法较高，而且召回率也比其他两种方法较高，但是运行时间比运动模板法较长。</p><p>在检测精确率方面，由于背景减除法的检测结果与选择的背景模板有关，当选择的背景模板不合适时，会极大地降低检测的精确率。运动模板法对目标的运动速度极为敏感，当其速度运动缓慢时，会导致其检测精确率下降。本文方法采用融合运动模板和HSV直方图匹配方法，利用HSV直方图匹配法弥补了运动模板法对目标运动速度敏感的缺陷，在一定程度上提高了运动模板法检测的精确率。</p><p>在召回率方面，由于本文方法融合了运动模板和HSV直方图匹配，运动模板检测法易受运动速度影响，HSV直方图匹配法易受光照影响，两者融合在一定程度上提高了检测的准确率和召回率，但是召回率提高并不多。而背景减除法与其背景模板的选择有关，当背景模板选择的不合适，导致其召回率并不高。而在运行时间上，背景减除法的运行时间一部分花费在背景模板的构建，一部分花费在目标检测，所以其运行时间相对较长。本文方法融合了运动模板和HSV直方图匹配，所以其运行时间比运动模板法较高。</p><p>综合上述三种方法的平均检测精确率、平均检测召回率和平均运行时间来看，本文方法比其他两种方法较优。相对于其他两种方法，本文方法不仅可以检测到运动目标的完整区域，而且平均检测精确率、平均检测召回率比其他两种方法较高，虽然平均运行时间比运动模板法长，但比背景减除法短。因此，综合所有评价指标，本文方法较优。</p></sec><sec id="s6"><title>4. 结论</title><p>本文提出了一种基于改进运动模板和HSV直方图匹配的视频典型目标检测算法，融合方法能够解决传统运动模板在提取运动目标轮廓时出现的空洞现象和提取运动目标轮廓不完整的问题，而且具有较高的检测精确率，从而有利于后续的视频解析和视频挖掘。</p></sec><sec id="s7"><title>基金项目</title><p>本文由国家自然科学基金(61371143)，北方工业大学2018年教育教学改革和课程建设研究项目(18XN009-002)，教育部高等教育司产学合作协同育人项目(201801121002)，北方工业大学优势学科项目(217051360018XN044)资助。</p></sec><sec id="s8"><title>文章引用</title><p>张永梅,冯 超,马健喆. 改进运动模板与直方图匹配的视频典型目标检测方法 Typical Video Target Detection Method Based on Improved Motion Template and Histogram Matching[J]. 计算机科学与应用, 2019, 09(01): 106-118. https://doi.org/10.12677/CSA.2019.91013</p></sec><sec id="s9"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.28539-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Pan, F., Wang, X.J. and Wang, W.H. (2016) Research and Restoration Technology of Video Motion Target Detection Based on Kernel Method. International Journal on Smart Sensing and Intelligent Systems, 7, 1516-1534.</mixed-citation></ref><ref id="hanspub.28539-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Guo, Q.Y. and Zhang, Z. (2016) Im-provement of the Gaussian Mixture Model Based on EmguCV Motion Target Detection Design. International Conference on Man-agement, 10, 561-565.</mixed-citation></ref><ref id="hanspub.28539-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Wang, H.B., Chen, Z., Lu, M., et al. (2018) Object Detection Method Based on Motion Saliency Probabil-ity Map. Journal of Image and Graphics, 23, 79-88.</mixed-citation></ref><ref id="hanspub.28539-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">贾建英, 董安国. 基于联合直方图的运动目标检测算法[J]. 计算机工程与应用, 2016, 52(5): 199-203.</mixed-citation></ref><ref id="hanspub.28539-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">孙挺, 齐迎春, 耿国华. 基于帧间差分和背景差分的运动目标检测算法[J]. 吉林大学学报(工学版), 2016, 46(4): 1325-1329.</mixed-citation></ref><ref id="hanspub.28539-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Bobick, A., Davis, J., Intille, S., et al. (1996) Action Recognition in an Interactive Story Environment, PerCom TR 398. MIT Media Lab.</mixed-citation></ref><ref id="hanspub.28539-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Murtaza, F., Yousaf, M.H. and Velastin, S.A. (2017) Multi_view Human Ac-tion Recognition Using 2D Motion Templates Based on MHIs and Their HOG Description. IET Computer Vision, 10, 758-767.  
&lt;br&gt;https://doi.org/10.1049/iet-cvi.2015.0416</mixed-citation></ref><ref id="hanspub.28539-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">吴飞虎. 基于多摄像机的人体目标跟踪技术实现[D]: [硕士学位论文]. 杭州: 浙江理工大学, 2017.</mixed-citation></ref><ref id="hanspub.28539-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">张伟伟, 杨正洪, 牛少彰. 基于HSV和CLAHE的复制粘贴篡改检测算法[J]. 北京邮电大学学报, 2016, 39(6): 27-32.</mixed-citation></ref><ref id="hanspub.28539-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">王培玉, 李峰, 周书仁, 等. 复杂码头环境下的船舶检测与跟踪算法[J]. 计算机工程与科学, 2017, 39(5): 992-998.</mixed-citation></ref><ref id="hanspub.28539-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">王建文, 林劼. 基于颜色直方图金字塔的图像自动标注方法[J]. 计算机工程, 2016, 42(6): 235-240.</mixed-citation></ref><ref id="hanspub.28539-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">何颖妮, 邵党国, 刘东权. 直方图匹配算法在超声弹性成像上的应用研究[J]. 计算机应用研究, 2013, 30(4): 1266-1270.</mixed-citation></ref><ref id="hanspub.28539-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">李晓瑜, 马大中, 英杰. 基于三帧差分混合高斯背景模型运动目标检测[J]. 吉林大学学报(信息科学版), 2018, 36(4): 414-422.</mixed-citation></ref><ref id="hanspub.28539-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">王宝珠, 胡洋, 郭志涛, 等. 基于朗斯基函数的混合高斯模型运动目标检测[J]. 计算机应用研究, 2016, 33(12): 3880-3883.</mixed-citation></ref></ref-list></back></article>