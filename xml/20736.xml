<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">AAM</journal-id><journal-title-group><journal-title>Advances in Applied Mathematics</journal-title></journal-title-group><issn pub-type="epub">2324-7991</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/AAM.2017.63032</article-id><article-id pub-id-type="publisher-id">AAM-20736</article-id><article-categories><subj-group subj-group-type="heading"><subject>AAM20170300000_78413780.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>数学与物理</subject></subj-group></article-categories><title-group><article-title>
 
 
  一种改进的更准确的混合推荐算法
  An Improved and More Accurate Hybrid Recommendation Algorithm
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>王</surname><given-names>全民</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>谷</surname><given-names>实</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>李</surname><given-names>振国</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>王</surname><given-names>开阳</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>孙</surname><given-names>艳峰</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>北京工业大学，北京</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><author-notes><corresp id="cor1">* E-mail:<email>18800168633@163.com(谷实)</email>;</corresp></author-notes><pub-date pub-type="epub"><day>12</day><month>05</month><year>2017</year></pub-date><volume>06</volume><issue>03</issue><fpage>267</fpage><lpage>274</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
  推荐系统可以过滤一些无用信息，可以预测用户是否喜欢给定的资源。基于内容的推荐和协同过滤推荐算法是目前主要的个性化推荐方法。但是随着用户项目的不断增加，用户-项目评分矩阵存在着稀疏性、冷启动等问题。针对此问题，我们提出了一个独特的层叠混合推荐方法，使用评级数据，人口统计数据和特征数据来计算项目之间的相似度。实验表明我们的方法优于传统的推荐系统算法。
   Recommender system can filter some useless information and can predict whether the users love given resources. Content-based recommendation and collaborative filtering recommendation algorithm is the main personalized recommendation method. However, with the continuous increase of user projects, there are sparse, cold start and other issues in the user-project scoring matrix. In response to this problem, we propose a unique cascade hybrid recommendation method that uses rating data, demographic data, and feature data to calculate the similarity between projects. Experiments show that our method is superior to the traditional recommendation system algorithm.
 
</p></abstract><kwd-group><kwd>个性化，基于内容，协同过滤，推荐算法, Personalization</kwd><kwd> Content-Based</kwd><kwd> Collaborative Filtering</kwd><kwd> Demographic</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>一种改进的更准确的混合推荐算法<sup> </sup></title><p>王全民，谷 实，李振国，王开阳，孙艳峰</p><p>北京工业大学，北京</p><p>收稿日期：2017年5月6日；录用日期：2017年5月21日；发布日期：2017年5月27日</p><disp-formula id="hanspub.20736-formula540"><graphic xlink:href="http://html.hanspub.org/file/7-2620394x5_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>推荐系统可以过滤一些无用信息，可以预测用户是否喜欢给定的资源。基于内容的推荐和协同过滤推荐算法是目前主要的个性化推荐方法。但是随着用户项目的不断增加，用户-项目评分矩阵存在着稀疏性、冷启动等问题。针对此问题，我们提出了一个独特的层叠混合推荐方法，使用评级数据，人口统计数据和特征数据来计算项目之间的相似度。实验表明我们的方法优于传统的推荐系统算法。</p><p>关键词 :个性化，基于内容，协同过滤，推荐算法</p><disp-formula id="hanspub.20736-formula541"><graphic xlink:href="http://html.hanspub.org/file/7-2620394x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2017 by authors and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="http://image.hanspub.org:8080\Html/htmlimages\1-2890033x\e70a10f1-7c93-45ea-9603-062237856e4b.png" /><img src="http://image.hanspub.org:8080\Html\htmlimages\1-2890033x\e898c85e-ffc4-45c9-b817-14224a4d6960.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>近年来，数字信息、电子资源和在线服务的数量呈指数级增长。信息超载出现了一个潜在的问题，即如何给用户过滤和有效地传递相关信息。这是一个可以过滤用户不需要的信息和可以预测用户需要的物品的系统。这样的系统被称为推荐系统。</p><p>假设<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x9_hanspub.png" xlink:type="simple"/></inline-formula>是所有用户的集合，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x10_hanspub.png" xlink:type="simple"/></inline-formula>是所有可能的被推荐的项目，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x11_hanspub.png" xlink:type="simple"/></inline-formula>是用户m<sub>i</sub>对项目n<sub>j</sub>的评分。</p><disp-formula id="hanspub.20736-formula542"><label>(1)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/7-2620394x12_hanspub.png"  xlink:type="simple"/></disp-formula><p>R是一个完全有序的集合。对于每一个用户<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x13_hanspub.png" xlink:type="simple"/></inline-formula>，推荐系统的目的是选择最符合用户的兴趣的项目<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x14_hanspub.png" xlink:type="simple"/></inline-formula>。我们可以指定如下：</p><disp-formula id="hanspub.20736-formula543"><label>(2)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/7-2620394x15_hanspub.png"  xlink:type="simple"/></disp-formula><p>协同过滤系统可以分为两类：基于内存的协同过滤和基于模型的协同过滤。基于内存的协同过滤，其基本思想是用统计的方法得出所有用户对物品或者信息的偏好，然后发现与当前用户口味和偏好相似的邻居用户群 [<xref ref-type="bibr" rid="hanspub.20736-ref1">1</xref>] 。基于模型的方法就是基于样本的用户喜好信息，训练一个推荐模型，然后根据实时的用户喜好的信息进行预测，计算推荐。基于模型的方法比基于用户的协同过滤方法更有扩展性。</p><p>推荐系统有两个潜在的问题。一是可扩展性，即一个推荐系统多快可以产生推荐，第二是改善给一个用户的推荐准度。纯协同过滤推荐系统能够比纯基于内容和基于人口统计学推荐系统产生更好的推荐效果，但是，由于冷启动问题，导致推荐效果的偏差。</p><p>本文提出一个混合方案，能进行更准确的预测和推荐，并用来解决冷启动问题。我们提出的方案是基于一个级联的混合推荐技术，其基于项目的评分，特征和人口信息构建项目模型。评估算法的数据集是MovieLens和FilmTrust。</p></sec><sec id="s4"><title>2. 相关研究</title><sec id="s4_1"><title>2.1. 基于项目的协同过滤推荐系统：项目评分信息</title><p>基于项目的协同过滤推荐系统用离线平台建立一个计算项目相似度的模型 [<xref ref-type="bibr" rid="hanspub.20736-ref2">2</xref>] 。主要有以下三步：</p><p>1) 检索由活跃用户评价过的所有项目。</p><p>2) 使用检索的项目的集合计算目标项目的相似性。选择k个最相似的项目的集合，也称为具有它们的相似性的目标项目的邻居。</p><p>3) 通过计算对k个最相似的项目的活跃用户评价的加权和来进行对目标项目的预测。</p></sec><sec id="s4_2"><title>2.2. 基于内容的推荐系统：项目特征信息</title><p>基于内容的推荐系统是基于项目的文本信息推荐项目。在这些系统中，感兴趣的项目由其相关联的特征定义，例如新闻过滤系统使用文本的词作为特征。</p><p>我们从IMDB下载关于电影的信息，并应用TF-IDF方法从关于每部电影的信息中提取特征 [<xref ref-type="bibr" rid="hanspub.20736-ref3">3</xref>] 。我们构建了IMDB中的电影的关键字，标签，导演，男演员/女演员，以及用户评论的向量。此外，我们利用WordNet使用Java WordNet Interface克服特征之间的同义词问题，同时找到(文本)特征之间的相似性。</p></sec><sec id="s4_3"><title>2.3. 基于人口统计学推荐系统：项目人口统计信息</title><p>人口统计学推荐系统是基于用户或项目的个人属性对其进行分类，并基于人口统计分类进行推荐。在我们的工作中，我们使用关于电影的类型信息作为其人口统计信息，并构造一个矢量。</p></sec></sec><sec id="s5"><title>3. 改进的算法</title><p>令<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x16_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x17_hanspub.png" xlink:type="simple"/></inline-formula>，R，D，F分别为活动用户，目标项目，用户项目评级矩阵，项目<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x18_hanspub.png" xlink:type="simple"/></inline-formula>的人口统计矢量和项目<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x19_hanspub.png" xlink:type="simple"/></inline-formula>的特征向量。让<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x20_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x21_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x22_hanspub.png" xlink:type="simple"/></inline-formula>表示项目之间的评级，人口统计信息和项目间的特征相似性。 此外，令<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x23_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x24_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x25_hanspub.png" xlink:type="simple"/></inline-formula>分别表示在计算所有项目之后的特征相关性之后找到的候选项目之间的评级相似性，计算所有项目之后的特征相关性之后发现的候选项目之间的人口统计相似性，以及计算评分之后发现的候选项目之间的特征相似性。</p><p>提出的算法可以总结如下：</p><p>步骤1：使用评级数据，人口统计数据和特征数据来计算项目之间的相似度，并存储该信息 [<xref ref-type="bibr" rid="hanspub.20736-ref4">4</xref>] 。两个项目之间的修正的余弦相似性用于测量已经评过分的项目的相似度。两个项目之间的向量相似性用于测量使用人口统计和特征向量的相似性。</p><p>步骤2：提高的相似性<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x26_hanspub.png" xlink:type="simple"/></inline-formula>由函数<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x27_hanspub.png" xlink:type="simple"/></inline-formula>定义，其将<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x28_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x29_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x30_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x31_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x32_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x33_hanspub.png" xlink:type="simple"/></inline-formula>组合在训练集中的项目集合上。此函数使用公式(5)进行预测。它可以规定如下：</p><disp-formula id="hanspub.20736-formula544"><label>(3)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/7-2620394x34_hanspub.png"  xlink:type="simple"/></disp-formula><p>等式(3)告诉我们选择使训练集中的项目集(<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x35_hanspub.png" xlink:type="simple"/></inline-formula>)上的所有用户(<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x36_hanspub.png" xlink:type="simple"/></inline-formula>)的效用最大化(即减少MAE)的函数。表1给出了在训练集上检查的函数的不同组合以及观察到的它们各自最低的MAE。这表明在施加特征相关性后发现的候选邻居项目中对评级和人口统计相关性进行了级联混合设置后给出了最小误差。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> A SAMPLE OF FUNCTION(F)WITHk = 2</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >函数号</th><th align="center" valign="middle" >函数(f)</th><th align="center" valign="middle" >MAE(ML)</th><th align="center" valign="middle" >MAE(FT)</th></tr></thead><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" ><inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x37_hanspub.png" xlink:type="simple"/></inline-formula></td><td align="center" valign="middle" >0.793</td><td align="center" valign="middle" >1.443</td></tr><tr><td align="center" valign="middle" >2</td><td align="center" valign="middle" ><inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x38_hanspub.png" xlink:type="simple"/></inline-formula></td><td align="center" valign="middle" >0.788</td><td align="center" valign="middle" >1.437</td></tr><tr><td align="center" valign="middle" >…</td><td align="center" valign="middle" >…</td><td align="center" valign="middle" >…</td><td align="center" valign="middle" >…</td></tr><tr><td align="center" valign="middle" >32 …</td><td align="center" valign="middle" ><inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x39_hanspub.png" xlink:type="simple"/></inline-formula> …</td><td align="center" valign="middle" >0.736 …</td><td align="center" valign="middle" >1.378 …</td></tr><tr><td align="center" valign="middle" >83</td><td align="center" valign="middle" ><inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x40_hanspub.png" xlink:type="simple"/></inline-formula> <inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x41_hanspub.png" xlink:type="simple"/></inline-formula></td><td align="center" valign="middle" >0.835</td><td align="center" valign="middle" >1.452</td></tr></tbody></table></table-wrap><p>表1. k = 20的函数样本</p><p>令<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x42_hanspub.png" xlink:type="simple"/></inline-formula>是在应用特征相似性之后找到的k个候选邻居的集合 [<xref ref-type="bibr" rid="hanspub.20736-ref5">5</xref>] 。我们通过在训练集中的项目集合上的<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x43_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x44_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x45_hanspub.png" xlink:type="simple"/></inline-formula>的线性组合来定义提高的相似性<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x46_hanspub.png" xlink:type="simple"/></inline-formula>，如下：</p><disp-formula id="hanspub.20736-formula545"><label>(4)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/7-2620394x47_hanspub.png"  xlink:type="simple"/></disp-formula><p>公式(4)中，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x48_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x49_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x50_hanspub.png" xlink:type="simple"/></inline-formula>参数表示相互影响的三个相似点。我们假设<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x51_hanspub.png" xlink:type="simple"/></inline-formula>。</p><p>步骤3：通过使用以下公式来预测目标项目<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x52_hanspub.png" xlink:type="simple"/></inline-formula>上的活动用户<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x53_hanspub.png" xlink:type="simple"/></inline-formula>的评分<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x54_hanspub.png" xlink:type="simple"/></inline-formula>：</p><disp-formula id="hanspub.20736-formula546"><label>(5)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/7-2620394x55_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s6"><title>4. 实验</title><sec id="s6_1"><title>4.1. 数据集</title><p>我们使用MovieLens (ML)和FilmTrust (FT)数据集用于评估我们的算法。MovieLens数据集包含943个用户，1682个电影和100000个评分记录。规模为1 (差)至5 (优)。MovieLens数据集被用在很多研究</p><p>项目中。这个数据集的稀疏性约93.7% (<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x56_hanspub.png" xlink:type="simple"/></inline-formula>)。</p><p>我们通过FilmTrust创建了第二个数据集。检索的数据集包含1592位用户，1930电影和28645评级，</p><p>规模为1 (差)到10 (优)。此数据集的稀疏度约为99.06% (<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x57_hanspub.png" xlink:type="simple"/></inline-formula>)。</p></sec><sec id="s6_2"><title>4.2. 评价指标</title><p>我们在本文中的具体任务是预测已经被实际用户评分的项目的分数，并且检查该预测如何有助于用户选择高质量项目。考虑到这一点，我们使用平均绝对误差(MAE)。</p><p>MAE测量推荐系统的预测评级和用户分配的真实评级之间的平均绝对偏差。其计算如下：</p><disp-formula id="hanspub.20736-formula547"><graphic xlink:href="http://html.hanspub.org/file/7-2620394x58_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x59_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x60_hanspub.png" xlink:type="simple"/></inline-formula>分别是等级的预测值和实际值，N是已经评分的项目的总数。对于MovieLens数据集，如果用户对其评分为4分或更高，则认为该项目很好，否则为差 [<xref ref-type="bibr" rid="hanspub.20736-ref6">6</xref>] 。类似地，对于FilmTrust数据集，如果用户对其评分为7分或更高，则认为项目良好，否则为差。</p><p>此外，我们使用覆盖度来衡量推荐系统可以推荐多少项目。我们随机选择每个用户的20%评级作为测试集，并使用剩余的80%作为训练集。我们将训练集进一步细分为测试集和用于测量参数灵敏度的训练集。为了学习参数，我们通过随机选择在80%的训练集上进行5重交叉验证，每次随机选择不同的测试和训练集合，并取结果的平均值。</p><p>我们将我们的算法与几种不同的算法进行比较：使用皮尔逊相似性的基于用户的协同过滤，基于项目的协同过滤使用修正的余弦相似度，朴素贝叶斯分类方法使用项目特征信息，用于生成推荐的朴素混合方法，用于进行概率推荐的个性诊断算法 [<xref ref-type="bibr" rid="hanspub.20736-ref7">7</xref>] 。此外，我们调整了所有算法的参数。</p></sec><sec id="s6_3"><title>4.3. 正选择邻居大小的最优值(k)</title><p>我们将活动用户的邻居数目从0改到100，并计算<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x61_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x62_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x63_hanspub.png" xlink:type="simple"/></inline-formula>的相应MAE。结果如图1所示：</p><p>图1. 确定邻域大小的最优值k</p><p>图1表示对于MovieLens数据集的MAE对于k = 20是最小的。所以对于进一步的实验，我们选择邻域大小为20。</p></sec><sec id="s6_4"><title>4.4. 学习参数的最优值(α, β, γ)</title><p>通过产生参数值的所有可能组合产生36个参数集，范围从0.1到1.0，差值为0.1。表2给出了所学习的参数集的样本。参数设置α = 0.5，β = 0.3，γ = 0.2，α = 0.7，β = 0.2，γ = 0.1分别在MovieLens和FilmTrust数据集下给出最低的MAE。值得注意的是，组合相似性在很大程度上取决于特征相似性，即α。此外，对于MovieLens和FilmTrust数据集，参数的值是不同的，这是由于这两个数据集具有不同的密度，评分分布和评级量表。</p></sec><sec id="s6_5"><title>4.5. 改进的算法与其他算法的比较</title><p>1) MAE方面的性能评估：图2显示我们的算法明显优于其他算法。对于FilmTrust数据集我们观察到类似的结果。我们可以从项目集合的结果中得出结论，应用<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x65_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x66_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x67_hanspub.png" xlink:type="simple"/></inline-formula>后对推荐结果具有互补的作用。</p><p>2) MAE，ROC灵敏度，覆盖率与其他算法的在线成本的比较：表3显示了在线成本(在最坏情况下)每个算法具有的最低MAE和覆盖率。这里，P是针对训练示例的特征的数量(即针对电影的特征)。值得注意的是，对于FilmTrust数据集，与MovieLens数据集相比，对于所有算法，ROC灵敏度更高。我们认为这是由于评分分布的原因。此外在FilmTrust数据集下，算法的覆盖率低得多，这是由于其非常稀疏(99%)的原因 [<xref ref-type="bibr" rid="hanspub.20736-ref8">8</xref>] 。该表描述了Boosted<sub>DemoFeature</sub>是可扩展和实用的，因为其在线成本小于或等于其他算法的成本 [<xref ref-type="bibr" rid="hanspub.20736-ref9">9</xref>] 。</p><p>3) 新项目和新用户冷启动问题下的性能评估：当将新项目添加到系统时，则不可能从用户获得该项目的评分数据，因此协同过滤推荐系统不会推荐该项目。这个问题被称为新项目冷启动问题。为了在这种情况下测试我们的算法，我们选择1000个来自测试集的用户/项目对的随机样本 [<xref ref-type="bibr" rid="hanspub.20736-ref10">10</xref>] 。在对目标项目进行预测时，训练集中已经对目标项目进行评分的用户的数量被保持为1,2和5。在表4中，对应的MAE由MAE1，MAE2，MAE5表示。表4表明，所提出的方案在新项目冷启动中表现良好。</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> A sample of parameter set with k = 2</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >参数集号</th><th align="center" valign="middle" >α</th><th align="center" valign="middle" >β</th><th align="center" valign="middle" >γ</th><th align="center" valign="middle" >MAE (ML)</th><th align="center" valign="middle" >MAE (FT)</th></tr></thead><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" >0.1</td><td align="center" valign="middle" >0.1</td><td align="center" valign="middle" >0.8</td><td align="center" valign="middle" >0.738</td><td align="center" valign="middle" >1.382</td></tr><tr><td align="center" valign="middle" >…</td><td align="center" valign="middle" >…</td><td align="center" valign="middle" >…</td><td align="center" valign="middle" >…</td><td align="center" valign="middle" >…</td><td align="center" valign="middle" >…</td></tr><tr><td align="center" valign="middle" >29</td><td align="center" valign="middle" >0.5</td><td align="center" valign="middle" >0.3</td><td align="center" valign="middle" >0.2</td><td align="center" valign="middle" >0.732</td><td align="center" valign="middle" >1.379</td></tr><tr><td align="center" valign="middle" >…</td><td align="center" valign="middle" >…</td><td align="center" valign="middle" >…</td><td align="center" valign="middle" >…</td><td align="center" valign="middle" >…</td><td align="center" valign="middle" >…</td></tr><tr><td align="center" valign="middle" >35</td><td align="center" valign="middle" >0.7</td><td align="center" valign="middle" >0.2</td><td align="center" valign="middle" >0.1</td><td align="center" valign="middle" >0.739</td><td align="center" valign="middle" >1.374</td></tr><tr><td align="center" valign="middle" >36</td><td align="center" valign="middle" >0.8</td><td align="center" valign="middle" >0.1</td><td align="center" valign="middle" >0.1</td><td align="center" valign="middle" >0.742</td><td align="center" valign="middle" >1.379</td></tr></tbody></table></table-wrap><p>表2. k = 20的参数集样本</p><table-wrap id="table3" ><label><xref ref-type="table" rid="table3">Table 3</xref></label><caption><title> A comparison of the proposed algorith</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >Algorithm</th><th align="center" valign="middle" >Online Cost</th><th align="center" valign="middle" >MAE (ML)</th><th align="center" valign="middle" >MAE (FT)</th><th align="center" valign="middle" >ROC (ML)</th><th align="center" valign="middle" >ROC (FT)</th><th align="center" valign="middle" >Coverage (ML)</th><th align="center" valign="middle" >Coverage (FT)</th></tr></thead><tr><td align="center" valign="middle" >Userbased</td><td align="center" valign="middle" >NM<sup>2</sup></td><td align="center" valign="middle" >0.792</td><td align="center" valign="middle" >1.442</td><td align="center" valign="middle" >0.402</td><td align="center" valign="middle" >0.643</td><td align="center" valign="middle" >99.42</td><td align="center" valign="middle" >96.61</td></tr><tr><td align="center" valign="middle" >Itembased</td><td align="center" valign="middle" >N<sup>2</sup></td><td align="center" valign="middle" >0.791</td><td align="center" valign="middle" >1.441</td><td align="center" valign="middle" >0.384</td><td align="center" valign="middle" >0.623</td><td align="center" valign="middle" >99.22</td><td align="center" valign="middle" >92.31</td></tr><tr><td align="center" valign="middle" >Boosted<sub>RDF </sub></td><td align="center" valign="middle" >N<sup>2</sup></td><td align="center" valign="middle" >0.725</td><td align="center" valign="middle" >1.363</td><td align="center" valign="middle" >0.563</td><td align="center" valign="middle" >0.755</td><td align="center" valign="middle" >100</td><td align="center" valign="middle" >99.19</td></tr><tr><td align="center" valign="middle" >NaiveBayes</td><td align="center" valign="middle" >M (NP)</td><td align="center" valign="middle" >0.833</td><td align="center" valign="middle" >1.472</td><td align="center" valign="middle" >0.623</td><td align="center" valign="middle" >0.835</td><td align="center" valign="middle" >100</td><td align="center" valign="middle" >99.99</td></tr><tr><td align="center" valign="middle" >Naivehybrid</td><td align="center" valign="middle" >NM<sup>2</sup> + M</td><td align="center" valign="middle" >0.822</td><td align="center" valign="middle" >1.462</td><td align="center" valign="middle" >0.525</td><td align="center" valign="middle" >0.725</td><td align="center" valign="middle" >100</td><td align="center" valign="middle" >99.99</td></tr><tr><td align="center" valign="middle" >Personality diagnosis</td><td align="center" valign="middle" >NM</td><td align="center" valign="middle" >0.785</td><td align="center" valign="middle" >1.433</td><td align="center" valign="middle" >0.521</td><td align="center" valign="middle" >0.735</td><td align="center" valign="middle" >99.14</td><td align="center" valign="middle" >94.23</td></tr></tbody></table></table-wrap><p>表3. 各种算法成本，精度，覆盖率比较</p><table-wrap id="table4" ><label><xref ref-type="table" rid="table4">Table 4</xref></label><caption><title> Performance evaluation under new item cold-start proble</title></caption><table><tbody><thead><tr><th align="center" valign="middle"  rowspan="2"  >算法</th><th align="center" valign="middle"  colspan="2"  >MAE1</th><th align="center" valign="middle"  colspan="2"  >MAE2</th><th align="center" valign="middle"  colspan="2"  >MAE5</th></tr></thead><tr><td align="center" valign="middle" >(ML)</td><td align="center" valign="middle" >(FT)</td><td align="center" valign="middle" >(ML)</td><td align="center" valign="middle" >(FT)</td><td align="center" valign="middle" >(ML)</td><td align="center" valign="middle" >(FT)</td></tr><tr><td align="center" valign="middle" >User-based CF</td><td align="center" valign="middle" >1.64</td><td align="center" valign="middle" >2.66</td><td align="center" valign="middle" >1.23</td><td align="center" valign="middle" >2.24</td><td align="center" valign="middle" >0.95</td><td align="center" valign="middle" >1.94</td></tr><tr><td align="center" valign="middle" >Item-based CF</td><td align="center" valign="middle" >1.36</td><td align="center" valign="middle" >2.55</td><td align="center" valign="middle" >1.19</td><td align="center" valign="middle" >2.15</td><td align="center" valign="middle" >0.91</td><td align="center" valign="middle" >1.58</td></tr><tr><td align="center" valign="middle" >Boosted<sub>RDF</sub></td><td align="center" valign="middle" >0.98</td><td align="center" valign="middle" >1.61</td><td align="center" valign="middle" >0.84</td><td align="center" valign="middle" >1.58</td><td align="center" valign="middle" >0.82</td><td align="center" valign="middle" >1.45</td></tr></tbody></table></table-wrap><p>表4. 冷启动下的性能评估</p><p>图2. 不同邻域下改进算法与其他算法的MAE对比</p><p>图3. 不同稀疏水平下的算法性能</p><p>对于新用户冷启动问题，其中用户的信息不完整，我们使用线性回归模型来找到一个项目的活动用户的评分的近似值 [<xref ref-type="bibr" rid="hanspub.20736-ref11">11</xref>] 。我们使用的是此评分，而不是公式(5)中的活跃用户的实际评分预测生成的评分。</p><disp-formula id="hanspub.20736-formula548"><label>(6)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/7-2620394x70_hanspub.png"  xlink:type="simple"/></disp-formula><p>在(6)中，J的选择来自训练集，发现MovieLens为10，FilmTrust数据集为5。评分<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x71_hanspub.png" xlink:type="simple"/></inline-formula>通过线性回归模型：<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x72_hanspub.png" xlink:type="simple"/></inline-formula>，其中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x73_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x74_hanspub.png" xlink:type="simple"/></inline-formula>是目标项目的向量和相似项目的向量。参数<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x75_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2620394x76_hanspub.png" xlink:type="simple"/></inline-formula>可以通过两个相似矢量找到。这个模型用于克服基于项目的协同过滤中项目之间的误差。我们使用这种模型只有当我们有不完整的用户参数时才有意义。</p><p>4) 不同稀疏性下的性能评价：为了检查稀疏性的影响，我们通过丢弃一些随机选择的条目来增加训练集的稀疏度。但是我们保持每个稀疏训练集的相同的测试集。我们检查了提出的算法的性能与以纯用户为基础的协同过滤，基于项目的协同过滤和一个朴素的混合推荐算法。图3表示在所提出的不同算法的情况下，性能不会快速降低。这是因为项目的特征仍然可以用于找到类似的项目。此外，同义词检测算法了丰富项目特征，同时也可以找到项目之间的相似性。</p></sec></sec><sec id="s7"><title>5. 结束语</title><p>在本文中，我们提出了一个独特的层叠混合推荐方法，使用评级数据，人口统计数据和特征数据相结合的方法来计算项目之间的相似度。实验表明我们的方法优于传统的推荐算法。</p></sec><sec id="s8"><title>文章引用</title><p>王全民,谷实,李振国,王开阳,孙艳峰. 一种改进的更准确的混合推荐算法An Improved and More Accurate Hybrid Recommendation Algorithm[J]. 应用数学进展, 2017, 06(03): 267-274. http://dx.doi.org/10.12677/AAM.2017.63032</p></sec><sec id="s9"><title>参考文献 (References)</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.20736-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Adomavicius, G. (2005) Toward the Next Generation of Recommender Systems: A Survey of the State-of-the-Art and Possible Extensions. IEEE Transactions on Knowledge and Data Engineering, 17, 734-749. 
&lt;br&gt;https://doi.org/10.1109/TKDE.2005.99</mixed-citation></ref><ref id="hanspub.20736-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Breese, J.S., Heckerman, D. and Kadie, C. (1998) Empirical Analysis of Predictive Algorithms for Collaborative Filtering. Morgan Kaufmann, Burlington, Massachusetts, 43-52.</mixed-citation></ref><ref id="hanspub.20736-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Sarwar, B., Karypis, G., Konstan, J. and Reidl, J. Item-Based Collaborative Filtering Recommendation Algorithms. Proceedings of the 10th International Conference on World Wide Web, Hong Kong, 1-5 May 2001, 285-295. 
&lt;br&gt;https://doi.org/10.1145/371920.372071</mixed-citation></ref><ref id="hanspub.20736-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Vozalis, M. and Margaritis, K. (2007) Using SVD and Demographic Data for the Enhancement of Generalized Collaborative Filtering. Information Sciences, 177, 3017-3037. &lt;br&gt;https://doi.org/10.1016/j.ins.2007.02.036</mixed-citation></ref><ref id="hanspub.20736-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Burke, R. (2002) Hybrid Recommender Systems: Survey and Experiments. User Modeling and User-Adapted Interaction, 12, 331-370. &lt;br&gt;https://doi.org/10.1023/A:1021240730564</mixed-citation></ref><ref id="hanspub.20736-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Pazzani, M.J. (1999) A Framework for Collaborative, Content-Based and Demographic Filtering. Artificial Intelligence Review, 13, 393-408. &lt;br&gt;https://doi.org/10.1023/A:1006544522159</mixed-citation></ref><ref id="hanspub.20736-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Pennock, D., Horvitz, E., Lawrence, S. and Giles, C. (2000) Collaborative Filtering by Personality Diagnosis: A Hybrid Memory and Model-Based Approach. Proceedings of the 16th Conference on Uncertainty in Artificial Intelligence, Morgan Kaufmann, San Francisco, 2000, 473-480.</mixed-citation></ref><ref id="hanspub.20736-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Vozalis, M. and Margaritis, K. (2006) On the Enhancement of Collaborative Filtering by Demographic Data. Web Intelligence and Agent Systems, 4, 117-138.</mixed-citation></ref><ref id="hanspub.20736-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Jonathan, L.G.T., Herlocker, L., Konstan, J.A. and Riedl, J.T. (2004) Evaluating Collaborative Filtering Recommender Systems. ACM Transactions on Information Systems (TOIS) Archive, 22, 734-749.</mixed-citation></ref><ref id="hanspub.20736-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Lang, K. (1995) Newsweeder: Learning to Filter Netnews. Proceedings of the Twelfth International Conference on Machine Learning, Tahoe City, California, 9-12 July 1995, 331-339.  
&lt;br&gt;https://doi.org/10.1016/b978-1-55860-377-6.50048-7</mixed-citation></ref><ref id="hanspub.20736-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Melville, P., Mooney, R.J. and Nagarajan, R. (2002) Content-Boosted Collaborative Filtering for Improved Recommendations. Eighteenth National Conference on Artificial Intelligence, Edmonton, Canada 28 July-1 August 2002, 187-192.</mixed-citation></ref></ref-list></back></article>