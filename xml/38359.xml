<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">AAM</journal-id><journal-title-group><journal-title>Advances in Applied Mathematics</journal-title></journal-title-group><issn pub-type="epub">2324-7991</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/AAM.2020.910210</article-id><article-id pub-id-type="publisher-id">AAM-38359</article-id><article-categories><subj-group subj-group-type="heading"><subject>AAM20201000000_20539035.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>数学与物理</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于秩的逼近的张量鲁棒主成分分析
  Tensor Robust Principal Component Analysis via Non-Convex Rank Approximation
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>费</surname><given-names>靖斯</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>杨</surname><given-names>天旭</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>辽宁师范大学数学学院，辽宁 大连</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>13</day><month>10</month><year>2020</year></pub-date><volume>09</volume><issue>10</issue><fpage>1815</fpage><lpage>1820</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
  
    本文提出来一种新的张量秩近似并建立一种非凸TRPCA模型，使用一种有效的增广拉格朗日乘子优化算法对这个非凸最小化问题进行求解。实验结果表明，相对于基于核范数的张量鲁棒主成分分析算法，该算法得到的估计张量的偏差更小，在精度和效率上是有效的。
    In this paper, a new tensor rank approximation is proposed and a non-convex TRPCA model is established. An effective augmented Lagrangian multiplier optimization algorithm is used to solve this non-convex minimization problem. The experimental results show that compared with the tensor robust principal component analysis algorithm based on kernel norm, the estimated tensor obtained by this algorithm has smaller deviation and is effective in terms of accuracy and efficiency. 
  
 
</p></abstract><kwd-group><kwd>张量秩的非凸近似，非凸的张量鲁棒主成分分析，张量奇异值分解，图片去噪, Non-Convex Approximation of Tensor</kwd><kwd> Rank Non-Convex Tensor Robust Principal Component Analysis</kwd><kwd> Tensor Singular Value Decomposition</kwd><kwd> Image Denoising</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>摘要</title><p>本文提出来一种新的张量秩近似并建立一种非凸TRPCA模型，使用一种有效的增广拉格朗日乘子优化算法对这个非凸最小化问题进行求解。实验结果表明，相对于基于核范数的张量鲁棒主成分分析算法，该算法得到的估计张量的偏差更小，在精度和效率上是有效的。</p></sec><sec id="s2"><title>关键词</title><p>张量秩的非凸近似，非凸的张量鲁棒主成分分析，张量奇异值分解，图片去噪</p></sec><sec id="s3"><title>Tensor Robust Principal Component Analysis via Non-Convex Rank Approximation<sup> </sup></title><p>Jingsi Fei, Tianxu Yang</p><p>Department of Mathematics, Liaoning Normal University, Dalian Liaoning</p><p><img src="//html.hanspub.org/file/18-2621343x4_hanspub.png" /></p><p>Received: Oct. 7<sup>th</sup>, 2020; accepted: Oct. 21<sup>st</sup>, 2020; published: Oct. 28<sup>th</sup>, 2020</p><p><img src="//html.hanspub.org/file/18-2621343x5_hanspub.png" /></p></sec><sec id="s4"><title>ABSTRACT</title><p>In this paper, a new tensor rank approximation is proposed and a non-convex TRPCA model is established. An effective augmented Lagrangian multiplier optimization algorithm is used to solve this non-convex minimization problem. The experimental results show that compared with the tensor robust principal component analysis algorithm based on kernel norm, the estimated tensor obtained by this algorithm has smaller deviation and is effective in terms of accuracy and efficiency.</p><p>Keywords:Non-Convex Approximation of Tensor, Rank Non-Convex Tensor Robust Principal Component Analysis, Tensor Singular Value Decomposition, Image Denoising</p><disp-formula id="hanspub.38359-formula56"><graphic xlink:href="//html.hanspub.org/file/18-2621343x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2020 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/18-2621343x7_hanspub.png" /> <img src="//html.hanspub.org/file/18-2621343x8_hanspub.png" /></p></sec><sec id="s5"><title>1. 引言</title><p>张量鲁棒主成分分析(TRPCA：Tensor Robust Principal Component Analysis)在处理真实世界中图像数据如RGB图像，视频、高光谱图像，和磁共振图像是很有效的。张量的核范数，作为张量秩函数的凸近似，在TRPCA中得到了广泛的研究。但是，应用张量的核范数得到的近似误差不是可以忽略不计的，因此实验后得到的去噪效果不是很理想。为了解决上述核范数的局限性并寻求更近似的秩函数，我们提出了一种非凸秩近似。并用这个张量的非凸秩近似去替代张量核范数，从而提出一个非凸TRPCA算法。</p></sec><sec id="s6"><title>2. 预备知识</title><p>本节介绍张量的一些符号及其基本定义，对于一个三阶张量A，用 a i j k 表示其 ( i , j , k ) 个元素，用 A ( i , : , : ) , A ( : , i , : ) , A ( : , : , i ) 来分别表示第i个水平，垂直，前后切片，其中前后切片通常被称作正面切片，在本文中，用 A ( i ) 来表示张量的第i个正面切片。</p><p>定义2.1 张量的 l 1 范数： ‖ A ‖ 1 = ∑ i j k | a i j k | 。</p><p>定义2.2 张量的Frobenius范数： ‖ A ‖ F = ∑ i ∑ j ∑ k a i j k 2 。</p><p>定义2.3张量的核范数张量A的核范数定义为： ‖ A ‖ ∗ = 1 n 3 ∑ i = 1 ∑ j = 1 σ i ( A &#175; ( j ) ) 。</p><p>定义2.4块对角矩阵。</p><p>块对角矩阵 b d i a g ( A &#175; ) 的定义如下，其中对角线上的每一个块是 A &#175; 的正面切片</p><p>b d i a g ( A &#175; ) = [ A &#175; ( 1 ) A &#175; ( 2 ) ⋱ A &#175; ( n 3 ) ] ∈ C n 1 n 3 &#215; n 2 n 3</p><p>定义2.5块循环矩阵</p><p>b c i r c ( A ) = [ A ( 1 ) A ( n 3 ) ⋯ A ( 2 ) A ( 2 ) A ( 1 ) ⋯ A ( 3 ) ⋮ ⋮ ⋱ ⋮ A ( n 3 ) A ( n 3 − 1 ) ⋯ A ( 1 ) ] ∈ C n 1 n 3 &#215; n 2 n 3</p><p>其中 A &#175; 表示对三阶张量 A ∈ R n 1 &#215; n 2 &#215; n 3 使用命令fft，即将A沿第三维进行快速傅里叶变换得到的张量，即</p><p>A &#175; = f f t ( A , [ ] , 3 ) ，</p><p>同样， A &#175; 可以通过fft的逆变换反傅里叶变换ifft得到A，即 A = i f f t ( A &#175; , [ ] , 3 ) 。</p><p>定理2.1：张量的T-SVD分解：给定一个张量 A ∈ R n 1 &#215; n 2 &#215; n 3 ，可以有如下分解</p><p>A = U ∗ S ∗ V ∗</p><p>其中是 U ∈ R n 1 &#215; n 1 &#215; n 3 ， V ∈ R n 2 &#215; n 2 &#215; n 3 是正交张量， S ∈ R n 1 &#215; n 2 &#215; n 3 是f-对角张量，其每一个正面切片都是对角矩阵。</p></sec><sec id="s7"><title>3. 通过秩的非凸逼近的低秩张量RPCA算法</title><p>在这一部分中，我们提出了一种新的张量管秩逼近，并提出了一种非凸张量RPCA算法。</p><p>定义3.1张量的 γ -范数 [<xref ref-type="bibr" rid="hanspub.38359-ref1">1</xref>]。</p><p>假设张量 L ∈ R n 1 &#215; n 2 &#215; n 3 ，不妨设 n = min ( n 1 , n 2 ) 有T-SVD分解； L = U ∗ S ∗ V ∗ ，张量L的 γ -范数定义为：</p><p>‖ L ‖ γ = 1 n 3 ∑ i ∑ j ( 1 + γ ) σ i ( L &#175; ( j ) ) γ + σ i ( L &#175; ( j ) ) (3.1)</p><p>可以观察到 lim γ → ∞ ‖ L ‖ γ = ‖ L ‖ * ，并且 ‖ L ‖ γ 是一个正交不变范数，即对于任意的正交张量 U , V ，有 ‖ L ‖ γ = ‖ U L V ‖ γ 成立。</p><p>3.2张量RPCA的非凸优化模型</p><p>由于新定义的张量的 γ -范数 ‖ L ‖ γ 可以看作是张量的核范数的近似，不妨考虑RPCA的一般框架</p><p>min L , S ‖ L ‖ γ + ‖ S ‖ l 1     s .t .   X = L + S (3.2)</p><p>对于问题(3.2)，通过引入拉格朗日乘子Y和二次惩罚项可以构造增广拉格朗日函数</p><p>L ( L , S , Y , μ ) = ‖ L ‖ γ + λ ‖ S ‖ l 1 + 〈 Y , L + S − X 〉 + μ 2 ‖ L + S − X ‖ F 2 (3.3)</p><p>其中 μ 是正参数，我们采用交替方向乘子方法(ADMM)对L,S,Y进行迭代更新 [<xref ref-type="bibr" rid="hanspub.38359-ref2">2</xref>]，其中，在第 k + 1 步迭代时，我们更新 L k + 1 ：</p><p>L k + 1 = arg min L ‖ L ‖ γ + μ k 2 ‖ L − ( X − S k − Y k μ k ) ‖ F 2 (3.4)</p><p>对于S, Y, μ 的更新如下 [<xref ref-type="bibr" rid="hanspub.38359-ref3">3</xref>]：</p><p>更新S</p><p>S k + 1 = arg min S λ ‖ S ‖ l 1 + μ k 2 ‖ S − ( X − L k + 1 − Y k μ k ) ‖ F 2 (3.5)</p><p>更新Y</p><p>Y k + 1 = Y k + μ k ( L k + 1 − X + S k + 1 ) (3.6)</p><p>更新 μ</p><p>μ k + 1 = ρ μ k (3.7)</p><p>为了求解问题(3.4)，首先引入定理3.1。</p><p>定理3.1 假设矩阵 A ∈ R n 1 &#215; n 2 有奇异值分解 A = U Σ A V T ，其中 Σ A = d i a g ( σ A ) ，令 F ( X ) = f ∘ σ ( X ) ，则下述优化问题</p><p>min X F ( X ) + μ 2 ‖ X − A ‖ F 2</p><p>的最优解为 X * = U Σ X * V T ，其中 Σ X * = d i a g ( σ * ) ，而 σ * = p r o x f , μ ( σ A ) ，这里 p r o x f , μ ( σ A ) 定义为</p><p>p r o x f , μ ( σ A ) = arg min σ f ( σ ) + μ 2 ‖ σ − σ A ‖ 2 2</p><p>由于上述问题是凹凸函数的组合，这种内在结构促使我们使用DC算法(DCA: Difference of Convex Algorithm)，即将一个非凸函数分解为两个凸函数的差值，并在每次迭代时通过线性化凹项来迭代优化 [<xref ref-type="bibr" rid="hanspub.38359-ref4">4</xref>]。在第k+1步内部迭代时，</p><p>σ k + 1 = arg min 〈 w k , σ 〉 + μ t 2 ‖ σ − σ A ‖ 2 2</p><p>其封闭解为 σ k + 1 = ( σ A − w k μ t ) + , w k = ∂ f ( σ k ) 是 f ( σ ) 在 σ k 处的梯度。</p><p>设张量 A , X 的块对角矩阵分别为 A ^ , X ^ ，由块循环矩阵和块对角矩阵的关系，得到： ‖ A ‖ F = 1 n 3 ‖ A ^ ‖ F ， 〈 X , A 〉 = 1 n 3 〈 X ^ , A ^ 〉 。不妨记张量L的块对角矩阵为 L ^ ，则由矩阵的 γ -范数的定义，有 ‖ L ^ ‖ γ = ∑ i ( 1 + γ ) σ i ( L ^ ) γ + σ i ( L ^ ) ，其中 σ i ( L ^ ) 表示块对角矩阵 L ^ 的 n ⋅ n 3 个奇异值，而由块对角矩阵的定义可以得到</p><p>‖ L ^ ‖ γ = ∑ i ( 1 + γ ) σ i ( L ^ ) γ + σ i ( L ^ ) = ∑ j ∑ i ( 1 + γ ) σ i ( L &#175; ( j ) ) γ + σ i ( L &#175; ( j ) )</p><p>其中 i = 1 , 2 , ⋯ , n ; j = 1 , 2 , ⋯ , n 3 ，在这里 n = min ( n 1 , n 2 ) ，为了后文说明方便，不妨记 Q = X − S k − Y k μ k ，故可以将原始目标函数(3.4)转化为</p><p>min μ k 2 ⋅ 1 n 3 ‖ L ^ − Q ^ ‖ F 2 + 1 n 3 ⋅ ‖ L ^ ‖ γ (3.8)</p><p>则有</p><p>( L ^ ) k + 1 = arg min L ^ μ k 2 ⋅ 1 n 3 ‖ L ^ − Q ^ ‖ F 2 + 1 n 3 ⋅ ‖ L ^ ‖ γ = 1 n 3 arg min L ^ { μ k 2 ‖ L ^ − Q ^ ‖ F 2 + ‖ L ^ ‖ γ } (3.9)</p><p>由于 ‖ L ^ ‖ γ = f ∘ σ ( L ^ ) 是关于矩阵 L ^ 的正交不变函数，根据定理3.1优化问题 min { μ k 2 ‖ L ^ − Q ^ ‖ F 2 + ‖ L ^ ‖ γ } 的解为 ( L ^ ) * = U Σ L ^ * V T ，其中 Q ^ = U Σ Q ^ V T 是矩阵 Q ^ 的SVD分解。而 Σ L ^ * = d i a g ( σ * ) ，其中 σ * = p r o x f , μ ( σ Q ^ ) 。这里 p r o x f , μ ( σ Q ^ ) 定义为</p><p>p r o x f , μ ( σ Q ^ ) = arg min σ f ( σ ) + μ 2 ‖ σ − σ Q ^ ‖ 2 2 (3.10)</p><p>对于(3.10)，我们采取凸差算法，凸差算法旨在每次迭代时通过线性化凹项进行优化。在第 k + 1 步内部迭代时，有</p><p>σ k + 1 = arg min 〈 w k , σ 〉 + μ t 2 ‖ σ − σ Q ^ ‖ 2 2 (3.11)</p><p>其封闭解为</p><p>σ k + 1 = ( σ Q ^ − w k μ t ) + = max ( σ Q ^ − w k μ t , 0 ) (3.12)</p><p>其中， w k = ∂ f ( σ k ) 是 f ( σ ) 在 σ k 处的梯度，经过一系列的迭代以后， σ k + 1 收敛到局部最优点 σ * 。故(3.8)的解为 ( L ^ ) k + 1 = 1 n 3 U ∑ L ^ * V T 。</p></sec><sec id="s8"><title>4. 图像数据实验</title><p>在本文中，我们主要将所提出的新的非凸的低秩张量RPCA算法应用于图像去噪，并将其与传统的TRPCA [<xref ref-type="bibr" rid="hanspub.38359-ref5">5</xref>] 与SNN算法 [<xref ref-type="bibr" rid="hanspub.38359-ref6">6</xref>] 的去噪效果进行比较。具体来说，选取大小设置为 321 &#215; 481 &#215; 3 ，30%的像素被破坏一张彩色测试图像，通过对比彩色图片的恢复效果，来评价张量去噪模型的修复效果，实验结果如图1所示。</p><p>图1. 用不同方法进行图像恢复的比较(a)原始图片(b)噪声图片(c) (d) (e)分别表示经过TRPCA，SNN，NCTRPCA三种模型后恢复的图片</p><p>其中NCTRPCA表示本文所提出的基于秩的非凸逼近的TRPCA算法，通过观察恢复后的图片，我们可以证明所提出的新算法在图像去噪上是有效的。</p></sec><sec id="s9"><title>5. 结论</title><p>在本文中，我们提出了一个张量秩的非凸近似并建立了一个非凸张量鲁棒主成分分析模型，通过对图像去噪的实验证明，应用该非凸优化算法对于带有噪声的原始图片去噪是具有一定效果的。</p></sec><sec id="s10"><title>文章引用</title><p>费靖斯,杨天旭. 基于秩的逼近的张量鲁棒主成分分析Tensor Robust Principal Component Analysis via Non-Convex Rank Approximation[J]. 应用数学进展, 2020, 09(10): 1815-1820. https://doi.org/10.12677/AAM.2020.910210</p></sec><sec id="s11"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.38359-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Kang, Z., Peng, C. and Cheng, Q. (2015) Robust PCA via Nonconvex Rank Approximation. 2015 IEEE International Conference on Data Mining, Atlantic City, 14-17 November 2015. 
&lt;br&gt;https://doi.org/10.1109/ICDM.2015.15</mixed-citation></ref><ref id="hanspub.38359-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Boyd, S., Parikh, N., Chu, E., Peleato, B. and Eckstein, J. (2011) Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers. Foundations and Trends® in Machine Learning, 3, 1-122.  
&lt;br&gt;https://doi.org/10.1561/2200000016</mixed-citation></ref><ref id="hanspub.38359-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Candès, E.J., Li, X., Ma, Y. and Wright, J. (2011) Robust Principal Component Analysis? Journal of the ACM (JACM), 58, Article No. 11. &lt;br&gt;https://doi.org/10.1145/1970392.1970395</mixed-citation></ref><ref id="hanspub.38359-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Tao, P.D. and An, L.T.H. (1997) Convex Analysis Approach to DC Programming: Theory Algorithms and Applications. Acta Mathematica Vietnamica, 22, 289-355.</mixed-citation></ref><ref id="hanspub.38359-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Lu, C., Feng, J., Chen, Y., Liu, W., Lin, Z. and Yan, S. (2016) Tensor Robust Principal Component Analysis: Exact Recovery of Corrupted Low-Rank Tensors via Convex Optimization. 2016 Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Las Vegas, 27-30 June 2016, 5249-5257.  
&lt;br&gt;https://doi.org/10.1109/CVPR.2016.567</mixed-citation></ref><ref id="hanspub.38359-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Huang, B., Mu, C., Goldfarb, D. and Wright, J. (2014) Provable Low-Rank Tensor Recovery. Optimization-Online, 4252.</mixed-citation></ref></ref-list></back></article>