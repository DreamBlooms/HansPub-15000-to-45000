<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2020.105086</article-id><article-id pub-id-type="publisher-id">CSA-35446</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20200500000_90443521.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于图像纹理的空域富模型隐写分析研究
  Research on Steganalysis of Spatial Rich Model Based on Image Texture
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>刘</surname><given-names>子璇</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>吴</surname><given-names>建斌</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>伍</surname><given-names>迁</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>华中师范大学，湖北 武汉</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>29</day><month>04</month><year>2020</year></pub-date><volume>10</volume><issue>05</issue><fpage>832</fpage><lpage>840</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   图像纹理复杂度是隐写分析在攻击自适应隐写时常常关注的问题，而空域富模型(Spatial Rich Model)常用于针对传统非自适应图像空域隐写的攻击，但空域富模型却没有考虑图像纹理的纹理特征。考虑到空域富模型的准确率及图像纹理复杂度对自适应算法的作用，兼顾效率与准确率，本文结合两种思路，将图像纹理复杂度引入到空域富模型中，提出了一种基于图像纹理的空域富模型隐写分析方法。用MATLAB搭建了测试环境进行测试，通过实验结果可以看出，该方法能提高对于自适应隐写算法的检测准确率。 The complexity of image texture is often concerned when steganalysis is used for attacking adaptive steganography, while spatial rich model is often used to attack the traditional image steganalysis. But the spatial rich model does not consider the texture features of image texture. Considering the accuracy of the spatial rich model and the effect of the image texture complexity on the adaptive algorithm, considering both efficiency and accuracy, this paper combines two ideas, introduces the image texture complexity into the spatial rich model, and proposes a steganalysis method based on the image texture. The test environment is built by MATLAB. The experimental results show that this method can improve the detection accuracy of the adaptive steganography algorithm. 
  
 
</p></abstract><kwd-group><kwd>隐写术，隐写分析，空域富模型，空纹理复杂度, Steganography</kwd><kwd> Steganalysis</kwd><kwd> Spatial Rich Model</kwd><kwd> Texture Complexity</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>基于图像纹理的空域富模型隐写分析研究<sup> </sup></title><p>刘子璇，吴建斌<sup>*</sup>，伍迁</p><p>华中师范大学，湖北 武汉</p><p>收稿日期：2020年4月15日；录用日期：2020年4月30日；发布日期：2020年5月7日</p><disp-formula id="hanspub.35446-formula26"><graphic xlink:href="//html.hanspub.org/file/3-1541745x5_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>图像纹理复杂度是隐写分析在攻击自适应隐写时常常关注的问题，而空域富模型(Spatial Rich Model)常用于针对传统非自适应图像空域隐写的攻击，但空域富模型却没有考虑图像纹理的纹理特征。考虑到空域富模型的准确率及图像纹理复杂度对自适应算法的作用，兼顾效率与准确率，本文结合两种思路，将图像纹理复杂度引入到空域富模型中，提出了一种基于图像纹理的空域富模型隐写分析方法。用MATLAB搭建了测试环境进行测试，通过实验结果可以看出，该方法能提高对于自适应隐写算法的检测准确率。</p><p>关键词 :隐写术，隐写分析，空域富模型，空纹理复杂度</p><disp-formula id="hanspub.35446-formula27"><graphic xlink:href="//html.hanspub.org/file/3-1541745x7_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2020 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/3-1541745x8_hanspub.png" /> <img src="//html.hanspub.org/file/3-1541745x9_hanspub.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>图像隐写是将秘密信息按照一定的规律嵌入到载体图像中，生成含密图像，使得秘密信息传输难以被人察觉。传统的空域隐写算法LSB [<xref ref-type="bibr" rid="hanspub.35446-ref1">1</xref>] 或者JPEG域图像隐写方法Outgess [<xref ref-type="bibr" rid="hanspub.35446-ref2">2</xref>]、nsF5 [<xref ref-type="bibr" rid="hanspub.35446-ref3">3</xref>] 等，他们通过修改空域或DCT域系数，将二进制比特流嵌入到图像中。然而这样的隐写算法难以抵挡SRM [<xref ref-type="bibr" rid="hanspub.35446-ref4">4</xref>]、DCTR [<xref ref-type="bibr" rid="hanspub.35446-ref5">5</xref>] 等方法的攻击。</p><p>为抵抗隐写分析者的检测，隐写算法的设计者在设计隐写算法时引入STC编码方法 [<xref ref-type="bibr" rid="hanspub.35446-ref6">6</xref>] 及嵌入失真函数 [<xref ref-type="bibr" rid="hanspub.35446-ref7">7</xref>]，将秘密信息嵌入到图像中难以被统计建模的位置，而这些位置大多为纹理复杂度较高的区域，如HUGO [<xref ref-type="bibr" rid="hanspub.35446-ref8">8</xref>]、WOW [<xref ref-type="bibr" rid="hanspub.35446-ref9">9</xref>]、UNIWARD [<xref ref-type="bibr" rid="hanspub.35446-ref10">10</xref>] 等方法。为了针对此类自适应隐写算法，基于DCTR的SCA-DCTR [<xref ref-type="bibr" rid="hanspub.35446-ref11">11</xref>] 隐写分析方法也相应产生，此方法是由DCTR加入对于像素嵌入概率的估计，从而使得针对自适应隐写方式有着较高的检测准确率。但是基于SRM隐写分析方法却没有类似的方式提高其对于自适应隐写算法的分析准确率。</p><p>其中SRM是一种准确度较高的空域高维度图像特征，通过各种滤波器对图像进行滤波处理后得到相应的特征量。然而SRM只考虑的像素点及其相邻位置像素的相关性，并没有考虑图像的纹理特征，没有对隐写时的未知进行预测，故在对于自适应隐写方法进行分析的时候对于准确率会有一定的降低。</p><p>针对此问题，本文在SRM特征上进行一定的改进，将其与图像的纹理特征进行快速结合，使其对于自适应隐写算法进行隐写分析时准确率有所提高。</p></sec><sec id="s4"><title>2. 空域富模型</title><p>SRM是于2012年由Fridrich等人提出的一种高维度的空域隐写分析图像特征，是一种传统的通用隐写分析方法。通用隐写分析是不针对一种隐写算法的隐写分析方法，其步骤是通过提取已知图像的统计特征训练分类器，再利用训练好的分类器判别未知图像是否含密，隐写分析的步骤如图1所示。其中特征提取及分类器训练为传统通用隐写分析中较为重要的步骤，SRM即为一种建模的特征。</p><p>在文献 [<xref ref-type="bibr" rid="hanspub.35446-ref4">4</xref>] 中指出，SRM隐写分析特征的抽取步骤分为：提取残差图像、残差图像的量化及截断、提取共生矩阵。</p><sec id="s4_1"><title>2.1. 提取残差图像</title><p>由于图像隐写是将二进制比特流嵌入到载体图像的空域或JPEG域中，等同于是将一个微弱的噪声与载体图像叠加，生成一个含密图像。这样将噪声叠加进来就会改变原始图像中相邻像素的相关性，残差图像亦然，故使用残差图像作为特征抽取的基底，这样可以减少图像内容对于隐写分析特征抽取的影响。</p><p>图1. 通用隐写分析步骤</p><p>若灰度图像为 X = X i , j ∈ R n 1 &#215; n 2 , i = 1 , ⋯ , n 1 , j = 1 , ⋯ , n 2 ，经过SRM高通滤波器滤波可以得到残差图像 R = ( R i , j ) ∈ R n 1 &#215; n 2 ：</p><disp-formula id="hanspub.35446-formula28"><label>(2.1)</label><graphic position="anchor" xlink:href="//html.hanspub.org/file/3-1541745x13_hanspub.png"  xlink:type="simple"/></disp-formula><p>公式2.1中即为对图像进行高通滤波后得到的残差图像，其中 X ⌢ i , j 是根据图像中像素点 X i , j 的领域对 X i , j 的估计。</p><p>不同的高通滤波器可以对像素点的不同领域进行估计，所以Fridrich设计了多种多样的高通滤波去使对像素的评估模型更加全面和丰富，滤波器模型如图2所示。</p><p>在图2中 • 表示滤波器的中心，也就是待估计的像素点，其余的符号则为各式滤波器，相同符号表示相同的滤波器。</p><p>图2. 高通滤波器(文献 [<xref ref-type="bibr" rid="hanspub.35446-ref4">4</xref>] 中的Fig. 2)</p></sec><sec id="s4_2"><title>2.2. 提取共生矩阵生成特征</title><p>残差图像中一个像素点的幅值越大，则说明该像素点对应于领域像素的相关性较弱，由于残差图像中每个像素点的幅度各不相同，首先对图像进行量化及截断，希望能够将残差图像的范围限定在某一个区间，这样能够降低之后步骤的计算量。其量化及截断的步骤如下：</p><p>R i , j ← t r u n c T ( r o u n d ( R i , j Q ) ) , i = 1 , ⋯ , n 1 , j = 1 , ⋯ , n 2 r o u n d ( ⋅ ) (2.2)</p><p>式2.2中Q为量化因子，T为截断阈值， <inline-formula><inline-graphic xlink:href="//html.scirp.org/file/3-1541745x33_hanspub.png" xlink:type="simple"/></inline-formula> 表示截断， r o u n d ( ⋅ ) 表示取整。根据不同的量化因子及截断阈值，可以改变SRM的检测性能，本文中取Q = 1，T = 2。</p><p>共生矩阵是统计某一距离上的一类像素的数量。由量化截断后的残差图像提取共生矩阵，得到的共生矩阵即为SRM最终想要抽取的隐写分析特征。所提取共生矩阵阶数的大小会直接影响特征抽取的结果，阶数过高会使得特征的统计无意义；阶数如果过低，又会使得特征不够丰富，降低分析准确率。本文中提取残差图像的四阶共生矩阵作为隐写分析特征，且Q = 1, T = 2，在文献 [<xref ref-type="bibr" rid="hanspub.35446-ref4">4</xref>] 中被称作SRMQ1，即Q = 1，T = 2，d = 4。</p></sec></sec><sec id="s5"><title>3. 论加入图像纹理的空域富模型隐写分析方法</title><p>图像纹理 [<xref ref-type="bibr" rid="hanspub.35446-ref12">12</xref>] 是一种能够反映物体表面的变化的属性，图像纹理复杂的区域像素变化大、周期性小，纹理平滑区域则像素变化平缓，周期性大，如图3。纹理在性质上来说是一种难以描述的视觉属性，但现在多采用由1973年Haralick [<xref ref-type="bibr" rid="hanspub.35446-ref13">13</xref>] 等人提出的灰度共生矩阵来描述图像的纹理特征。灰度共生矩阵与共生矩阵的生成方法相同，是衡量图像空域中相隔某距离的两个像素之间的灰度关系，其中方向包括水平、竖直、对角线、逆对角线方向。最后再通过计算生成的灰度共生矩阵的特征参数，由此来描述图像的纹理信息。</p><p>图3. 复杂纹理图像(左)与平滑纹理图像(右)</p><p>Haralick等人定义了14个由灰度共生矩阵生成的特征参数来描述图像的纹理特征，而14个特征参数中有4个是非相关的，多被用于纹理特征的提取，本文中还加入另一个特征参数作为纹理特征，分别为能量、熵、对比度、相关性、均质性。通过取各个方向上灰度共生矩阵各个特征参数的均值及方差，就可以得到图像一个有较高分类精确度的10维特征。</p><p>如今自适应隐写多采用STC编码或损失函数来估计隐写对图像造成的改动，而在纹理复杂区域的改动往往对图像整体的影响较小，不易与被统计特征发现，这样损失函数最终确定的位置多位于纹理复杂的区域，所以自适应隐写的最终嵌入区域多处于纹理复杂区域。例如对图3中两幅图像进行S-UNIWARD方法以0.1嵌入率嵌入秘密信息，嵌入点如图4所示，其中黑色点为进行−1修改，白色点为进行+1修改。</p><p>图4. S-UNIWARD嵌入位置</p><p>由于SRM无法对图像的纹理信息进行辨识，遗漏了图像的纹理信息，而自适应隐写改动多位于纹理复杂区域。对此本文采用将图像进行2 &#215; 2分割，对每一块图像进行SRM判别。判别结果−1代表载体图像，+1代表含密图像，再将判别结果乘以相依块的10维纹理特征，最后按顺序拼接为，则可得到图像的40维纹理特征，最后再按照40维纹理特征进行分类。同理可将图像进行4 &#215; 4或更高数量的切割，以提高对局部纹理特征的辨识度。其具体隐写分析步骤如图5。</p><p>本文所使用的特征分类器使用由Fridrich等人提出的集成分类器(Ensemble Classifer) [<xref ref-type="bibr" rid="hanspub.35446-ref14">14</xref>] [<xref ref-type="bibr" rid="hanspub.35446-ref15">15</xref>]，此分类器对于大样本训练集训练速度快，分类效果好，能够明显缩短训练分类器的时间。集成分类器是以FLD</p><p>图5. 结合纹理复杂度的SRM隐写分析步骤</p><p>(Fisher Linear Discriminator)为基本分类器，通过有微弱差异的训练集对每个FID进行训练，最后将通过所有分类器的判决进行无加权投票，以投票数量为多数的结果作为最终结果。</p></sec><sec id="s6"><title>4. 实验与结果分析</title><sec id="s6_1"><title>4.1. 实验配置</title><p>本文的采用的图片源自不同手机型号拍摄的原始未经处理的JPEG格式的照片(图片源自http://www.cihw.org.cn/index.php/9/)，原始照片按最短边裁剪成正方形，然后统一缩放成1024 &#215; 1024大小，筛选出品质因子分布在90~95之间的图像。将图像库统一使用matlab转换为BMP图像格式，并生成两组图像相同、品质因数分别为75和95的图像库。隐写方法使用S-UNIWARD及WOW，类似文献 [<xref ref-type="bibr" rid="hanspub.35446-ref4">4</xref>]，检测嵌入率使用0.1~0.5及0.05。由于修改式隐写方法在嵌入率低于0.05时已较难被发现，且在嵌入率大于0.5时多种隐写分析方法均能检测出图像已被隐写，故不使用低于0.05和大于0.5的嵌入率。</p><p>对于不同品质因数下的不同嵌入率，分别使用相同的2000张图像作为训练集，1000张图像作为测试集，分别嵌入后进行得到载体图像和含密图像，测试模拟已知隐写环境分类器效果。</p></sec><sec id="s6_2"><title>4.2. 结果分析</title><p>通过测试对1000张图片进行分类后的错误率来对分类器性能进行评断，其错误率：</p><p>P = N F + N M N (4.1)</p><p>在式4.1中，<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/3-1541745x26_hanspub.png" xlink:type="simple"/></inline-formula>、<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/3-1541745x27_hanspub.png" xlink:type="simple"/></inline-formula>和 N 分别代表虚警样本数、漏警样本数、总样本数，这样就可以得到相应的分类器结果，从而判别分类器性能。</p><p>将通过纹理特征结合的SRM和原始SRM隐写分析性能进行对比，其中模拟已知隐写环境在S-UNIWARD隐写算法下，在载体图像品质因数QF为75及95的情况下错误率如图6及图7所示；其中模拟已知隐写环境在WOW隐写算法下，在载体图像品质因数QF为75及95的情况下错误率如图8及图9所示。</p><p>图6. QF = 75时对S-UNIWARD隐写分析错误率</p><p>图6中横轴为隐写嵌入率，纵轴为分类器进行分类后的错误率。可见本文结合图像纹理复杂度后的SRM隐写分析方法，在嵌入率为0.2、0.3时，对于采用S-UNIWARD为嵌入算法、载体图像品质因数QF = 75的图像对，检测错误率降低较为明显；而在0.05、0.1及0.5时降低不明显。</p><p>图7. QF = 95时对S-UNIWARD隐写分析错误率</p><p>类似于图7，可见本文算法在嵌入率为0.05和0.1时，相对于SRM错误率降低较少，其他嵌入率下错误率降低更为明显。且相比于选择载体图像品质因数QF = 75时，本文方法及SRM方法错误率均有所上升，且本文算法相对于SRM错误率的降低没有品质因数QF = 75时那么明显。所以品质因数高的图像更加能够抵抗隐写分析检测，本文的算法对于高品质因数下图像的隐写方法检测性能提升一般。</p><p>图8. QF = 75时对WOW隐写分析错误率</p><p>由图8可见，其隐写分析性能曲线与图6曲线类似，说明S-UNIWARD与WOW隐写算法的隐写性能较为相近。而本文结合图像纹理复杂度后的SRM隐写分析方法，对于在嵌入率适中时，性能提升优于在嵌入率较高或较低的情况。因此，使用本文方法对采用WOW进行隐写的图像进行检测时，类似于S-UNIWARD，在嵌入率适中时相对于SRM隐写分析方法性能提升更加明显。</p><p>图9. QF = 95时对WOW隐写分析错误率</p><p>由图9可见，在嵌入率大于0.1时，本文方法相对于SRM错误率有一定的降低，且在嵌入率适中时降低更加明显，与以S-UNIWARD作为隐写嵌入算法时的曲线类似。</p><p>可见在隐写嵌入率为0.2到0.4的时候，本文中的与纹理特征相结合的SRM隐写分析方法判别错误率，相较于SRM降低得更加明显。这说明本文提出的方法对于自适应隐写方法下隐写分析的检测性能有一定的提高，但是对于低嵌入率隐写或者图像高品质因数下的判别性能提升并不明显，所以本文方法适用于对中等嵌入率、图像品质因数不高的隐写图像进行隐写分析检测。</p></sec></sec><sec id="s7"><title>5. 总结与展望</title><p>本文从SRM隐写分析方法未考虑自适应隐写算法嵌入信息于图像纹理复杂区域的角度出发，提出了一种将图像纹理特征与SRM快速结合的图像隐写分析方法。先将图像进行分块判别，并将判别结果与块12维纹理特征结合，最后将纹理特征拼接，通过与判别结果结合后的纹理特征对图像进行分析。从实验结果中可以看出，在隐写嵌入率适中、图像品质因数不高时，此方法对针对于自适应隐写算法的检测错误率有一定的降低。</p><p>下一步，可以考虑如何将SRM特征与RGB通道等其他未考虑到的特征进行快速结合，提高隐写分析系统的性能，降低判别错误率。</p></sec><sec id="s8"><title>基金项目</title><p>本文受到国家自然科学基金(U1736121)资助。</p></sec><sec id="s9"><title>文章引用</title><p>刘子璇,吴建斌,伍 迁. 基于图像纹理的空域富模型隐写分析研究Research on Steganalysis of Spatial Rich Model Based on Image Texture[J]. 计算机科学与应用, 2020, 10(05): 832-840. https://doi.org/10.12677/CSA.2020.105086</p></sec><sec id="s10"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.35446-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Johnson, N.F. and Jajodia, S. (1998) Exploring Steganography: Seeingthe Unseen. IEEE Computer, 31, 26-34. 
&lt;br&gt;https://doi.org/10.1109/MC.1998.4655281</mixed-citation></ref><ref id="hanspub.35446-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Westfeld, A. (2001) High Capacity despite Better Steganalysis. Proceedings of 4th International Workshop on Information Hiding, No. 2137, 289-302. &lt;br&gt;https://doi.org/10.1007/3-540-45496-9_21</mixed-citation></ref><ref id="hanspub.35446-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Fridrich, J. and Pevny, T. (2007) Statistically Undetectable JPEG Steganography: Dead Ends Challenges, and Opportunities. In: Proceedings of 9th Workshop on Multimedia &amp; Security, 3-14. &lt;br&gt;https://doi.org/10.1145/1288869.1288872</mixed-citation></ref><ref id="hanspub.35446-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Fridrich, J. and Kodovsky, J. (2012) Rich Models for Ste-ganalysis of Digital Images. IEEE Transactions on Information Forensics and Security, 7, 868-882. &lt;br&gt;https://doi.org/10.1109/TIFS.2012.2190402</mixed-citation></ref><ref id="hanspub.35446-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Holub, V. and Fridrich, J. (2015) Low Complexity Features for JPEG Steganalysis Using Undecimated DCT. IEEE Transactions on Information Forensics and Security, 10, 219-228. &lt;br&gt;https://doi.org/10.1109/TIFS.2014.2364918</mixed-citation></ref><ref id="hanspub.35446-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Filler, T., Fridrich, J. and Judas, J. (2010) Minimizing Embedding Impact in Steganography Using Trellis-Coded Quantization. Proceedings of SPIE Electronic Imaging, Media Forensics and Security XII5, San Jose, CA, 18-20 January 2010, 1-14. &lt;br&gt;https://doi.org/10.1117/12.838002</mixed-citation></ref><ref id="hanspub.35446-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Holub, V. and Fridrich, J. (2013) Digital Image Steganography Using Universal Distortion. Proceedings of 1st ACM Workshop on In-formation Hiding and Multimedia Security, France, Montpellier, 59-68. 
&lt;br&gt;https://doi.org/10.1145/2482513.2482514</mixed-citation></ref><ref id="hanspub.35446-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Filler, T. and Fridrich, J. (2011) Gibbs Construction Insteganogra-phy. IEEE Transactions on Information Forensics and Security, 5, 705-720. &lt;br&gt;https://doi.org/10.1109/TIFS.2010.2077629</mixed-citation></ref><ref id="hanspub.35446-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Holub, V. and Fridrich, J. (2012) Designing Steganographic Distortion Using Directional Filters. Fourth IEEE International Workshop on Information Forensics and Security, Tene-rife, 234-239.  
&lt;br&gt;https://doi.org/10.1109/WIFS.2012.6412655</mixed-citation></ref><ref id="hanspub.35446-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Holub, V., Fridrich, J. and Denemark, T. (2014) Universal Dis-tortion Function for Steganography in an Arbitrary Domain. EURASIP Journal on Information Security, 2014, 1-13. &lt;br&gt;https://doi.org/10.1186/1687-417X-2014-1</mixed-citation></ref><ref id="hanspub.35446-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Chen, M., Sedighi, V., Boroumand, M. and Fridrich, J. (2017) JPEG-Phase-Aware Convolutional Neural Network for Steganalysis of JPEG Images. Proceedings of IH &amp; MMSec 17, Philadelphia, PA, 20-22 June 2017.  
&lt;br&gt;https://doi.org/10.1145/3082031.3083248</mixed-citation></ref><ref id="hanspub.35446-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">高程程. 基于灰度共生矩阵的纹理特征提取[J]. 计算机系统应用, 2010, 19(6): 195-198.</mixed-citation></ref><ref id="hanspub.35446-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Haralick, R.M. and Shanmugam, K. (1973) Texture Features for Image Classification. IEEE Transactions on Systems, Man, and Cybernetics, SMC-3, 610-621. &lt;br&gt;https://doi.org/10.1109/TSMC.1973.4309314</mixed-citation></ref><ref id="hanspub.35446-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">Kodovsky, J. and Fridrich, J. (2011) Steganalysis in High Di-mensions: Fusing Classifiers Built on Random Subspaces. Proceedings of SPIE, Electronic Imaging, Security and Fo-rensics of Multimedia XIII, San Francisco, CA, 23-26 January 2011, 1-13. &lt;br&gt;https://doi.org/10.1117/12.872279</mixed-citation></ref><ref id="hanspub.35446-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">Kodovsky, J., Fridrich, J. and Holub, V. (2012) Ensemble Classifier for Steganalysis of Digital Media. IEEE Transactions on Information Forensics and Security, 7, 432-444. &lt;br&gt;https://doi.org/10.1109/TIFS.2011.2175919</mixed-citation></ref></ref-list></back></article>