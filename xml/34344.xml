<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2020.102039</article-id><article-id pub-id-type="publisher-id">CSA-34344</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20200200000_57471926.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  结合改进引导滤波的GrabCut容器前景图像分割
  GrabCut Container Foreground Image Segmentation Combined with Improved Guided Filtering
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>张</surname><given-names>竞峰</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>柴</surname><given-names>文光</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>广东工业大学计算机学院，广东 广州</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>31</day><month>01</month><year>2020</year></pub-date><volume>10</volume><issue>02</issue><fpage>379</fpage><lpage>386</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   针对传统GrabCut算法用户交互后得到的目标容器分割结果存在的边缘凹陷、突刺问题，提出结合引导滤波算法与GrabCut函数的方法改善以上问题。该方法通过用户交互在彩色图像中用矩形框标记出存在容器的目标区域，通过GrabCut算法分割出目标容器，然后结合引导滤波算法，将分割后的结果二值化，作为引导滤波的引导图像掩膜，最后通过引导滤波器结合原图像和引导图像得到目标容器分割结果。实验测量了所提方法与其他对比方法的峰值信噪比(PSNR)、结构相似性(SSIM)及平均运行时间，同其他几种方法相比，实验结果表明，该方法对于GrabCut分割后的边缘凹陷、突刺问题优于对比方法，有明显改善。 Aiming at the problem of edge sags and spikes in the segmentation result of the target container obtained after user interaction with the traditional GrabCut algorithm, a method combining the guided filtering algorithm and the GrabCut function was proposed to improve the above problems. This method uses user interaction to mark the target area where the container exists in the color image with a rectangular frame. The target container is segmented by the GrabCut algorithm, and then the guided filtering algorithm is used to binarize the segmented result as a guided image mask for guided filtering Film, and finally the target container segmentation result is obtained by combining the original image and the guided image through a guided filter. The measured peak signal to noise ratio (PSNR), structural similarity (SSIM) and average running time of the proposed method compared with other comparison methods. Compared with several other methods, the experimental results show that this method is effective for GrabCut segmented edges. The problem of sags and spikes is better than the comparative method, and it is significantly improved. 
  
 
</p></abstract><kwd-group><kwd>GrabCut函数，图像分割，边缘细化，引导滤波, Grabcut Function</kwd><kwd> Image Segmentation</kwd><kwd> Edge Refinement</kwd><kwd> Guided Filtering</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>结合改进引导滤波的GrabCut容器前景图像 分割<sup> </sup></title><p>张竞峰，柴文光</p><p>广东工业大学计算机学院，广东 广州</p><p>收稿日期：2020年2月5日；录用日期：2020年2月20日；发布日期：2020年2月27日</p><disp-formula id="hanspub.34344-formula102"><graphic xlink:href="//html.hanspub.org/file/21-1541665x5_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>针对传统GrabCut算法用户交互后得到的目标容器分割结果存在的边缘凹陷、突刺问题，提出结合引导滤波算法与GrabCut函数的方法改善以上问题。该方法通过用户交互在彩色图像中用矩形框标记出存在容器的目标区域，通过GrabCut算法分割出目标容器，然后结合引导滤波算法，将分割后的结果二值化，作为引导滤波的引导图像掩膜，最后通过引导滤波器结合原图像和引导图像得到目标容器分割结果。实验测量了所提方法与其他对比方法的峰值信噪比(PSNR)、结构相似性(SSIM)及平均运行时间，同其他几种方法相比，实验结果表明，该方法对于GrabCut分割后的边缘凹陷、突刺问题优于对比方法，有明显改善。</p><p>关键词 :GrabCut函数，图像分割，边缘细化，引导滤波</p><disp-formula id="hanspub.34344-formula103"><graphic xlink:href="//html.hanspub.org/file/21-1541665x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2020 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/21-1541665x7_hanspub.png" /> <img src="//html.hanspub.org/file/21-1541665x8_hanspub.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>图像分割是计算机视觉领域的基础，所谓图像分割就是把图像分成若干个特定的、具有独特性质的区域并分割出感兴趣目标区域的技术和过程。目前有很多图像分割算法，常用的图像分割方法有基于图论的分割方法、基于区域的分割方法、基于阈值的分割方法、基于边缘的分割方法等。</p><p>其中图割是一种利用图像中纹理信息和边界反差信息的图像分割算法，2001年，Boykov等 [<xref ref-type="bibr" rid="hanspub.34344-ref1">1</xref>] 提出了GraphCut算法，该算法以灰度图像为主，用户交互标注出图像中的目标和背景区域，针对目标及背景区域建立灰度直方图模型，该算法最后通过一次最小估计完成能量最小化达到目标分割。2004年，Rother等 [<xref ref-type="bibr" rid="hanspub.34344-ref2">2</xref>] 提出了GrabCut算法，该算法是以GraphCut为基础通过用户交互，对目标及背景区域建立高斯混合模型，即预先用矩形框标记处背景区域。对高斯混合参数进行更新学习，用估计过程中可进化的迭代算法取代GraphCut算法中的一次最小估计来完成能量最小化从而达到目标分割。从GraphCut到GrabCut算法，图割算法受到越来越多的重视，在军事、遥感、气象等场景应用中需求不断增大。目前GrabCut算法的应用非常广泛，许多学者对其进行了改进。Chen等 [<xref ref-type="bibr" rid="hanspub.34344-ref3">3</xref>] 通过优化混合高斯模型，提高了GrabCut算法的性能。Wooi-Nee Tan等 [<xref ref-type="bibr" rid="hanspub.34344-ref4">4</xref>] 提出了一种基于blob分析的GrabCut分割算法，该算法应用于将已开放的花朵从图像中分割出来，结果证明该算法分割效果优于原始算法。Adri&#224; A等 [<xref ref-type="bibr" rid="hanspub.34344-ref5">5</xref>] 就GrabCut算法做了本质上的改进，结合多种方法对前景进行初始提取，将得到的前景初始估计作为GrabCut算法的输入，避免了交互的需要。王凯等 [<xref ref-type="bibr" rid="hanspub.34344-ref6">6</xref>] 通过结合GrabCut算法和颜色空间变换应用于超声相控阵图像中，对目标进行交互式图像分割，实验结果克服了背景噪声，保留了目标图像细节。Li Hong等 [<xref ref-type="bibr" rid="hanspub.34344-ref7">7</xref>] 提出了一种基于图割的立体匹配算法，将立体匹配问题描述为分段域中的能量最小化问题，快速逼近最优解，该算法在视差不连续和遮挡部分的效果有所提高。Shuo Deng等 [<xref ref-type="bibr" rid="hanspub.34344-ref8">8</xref>] 先对图像进行粗化预处理，得到不同比例的低分辨率图像，分别对其建立混合高斯模型进行分割，最终分割结果精度更高，时间消耗更低。周良芬等 [<xref ref-type="bibr" rid="hanspub.34344-ref9">9</xref>] 就GrabCut算法对于局部噪声敏感、耗时且提取边缘不理想等缺点，采用多尺度分水岭对梯度图像平滑去噪，优化分割能量函数，抑制了目标信息的损失。C. Guo等 [<xref ref-type="bibr" rid="hanspub.34344-ref10">10</xref>] 利用显著性信息初始化GrabCut算法的掩码，对GrabCut算法进行迭代，克服了背景噪声的干扰，保留了目标图像的细节，提高了算法精度。Hua S.等 [<xref ref-type="bibr" rid="hanspub.34344-ref11">11</xref>] 为了加快GrabCut算法中能量函数的收敛速度，提出了一种基于感兴趣区域的GrabCut彩色图像分割方法，同时提高了分割精度。Seetharani Murugaiyan Jaisakthi等 [<xref ref-type="bibr" rid="hanspub.34344-ref12">12</xref>] 将GrabCut算法结合K均值算法应用脑瘤图像分割。</p><p>本文将GrabCut算法应用于容器目标分割中，通过用户交互在彩色图像中用矩形框标记出存在容器的目标区域，通过GrabCut算法分割出目标容器，针对GrabCut算法分割出的目标容器边缘区域存在大量的凹陷、突刺问题，结合改进的引导滤波算法，将GrabCut算法预分割出的目标容器图像二值化，将二值化图像作为引导滤波算法的引导图像，结合原图像一起通过引导滤波器优化得到分割结果。</p></sec><sec id="s4"><title>2. GrabCut算法</title><p>如图1是GrabCut算法示意图，其主要思想是将待分割图像构建为一个包含两个端点的无向图，源点s、汇点t，即s-t图，源点s和汇点t分别表示图像中的目标和背景。GrabCut算法是对GraphCut算法的改进，GraphCut中的目标和背景的模型是灰度直方图，需要用户指定目标和背景的一些种子点并且其能量最小化分割是一次达到的，相较于GraphCut算法，GrabCut算法取代为RGB三通道的混合高斯模型GMM(Gaussian Mixture Model)，用户只需要提供背景区域的像素集并且GrabCut算法取代为一个交互的迭代过程，即不断进行分割估计和模型参数学习。GrabCut算法过程首先输入图像，用户交互标记矩形框，用来标记背景像素区域，矩形框内即为可能存在的目标对象，其次来对目标和背景进行建模，分别用一个含k个高斯分量的全协方差高斯混合模型GMM来对目标和背景进行建模，用来表示目标和背景像素的分布情况，由此引入了一个向量<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/21-1541665x9_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/21-1541665x10_hanspub.png" xlink:type="simple"/></inline-formula>，其中k<sub>n</sub>就表示第n个像素对应的高斯分量，该像素来自于目标或背景GMM中的某个高斯分量。GrabCut中的能量函数公式计算如下：</p><disp-formula id="hanspub.34344-formula104"><label>(1)</label><graphic position="anchor" xlink:href="//html.hanspub.org/file/21-1541665x11_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中，<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/21-1541665x12_hanspub.png" xlink:type="simple"/></inline-formula>为目标、背景标记，E为图像总能量，U是区域项，表示某个像素属于目标背景概率的负对数，即该像素被归类为目标或背景的惩罚。结合欧几里德距离计算出边界能量项V。</p><disp-formula id="hanspub.34344-formula105"><label>(2)</label><graphic position="anchor" xlink:href="//html.hanspub.org/file/21-1541665x13_hanspub.png"  xlink:type="simple"/></disp-formula><disp-formula id="hanspub.34344-formula106"><label>(3)</label><graphic position="anchor" xlink:href="//html.hanspub.org/file/21-1541665x14_hanspub.png"  xlink:type="simple"/></disp-formula><disp-formula id="hanspub.34344-formula107"><label>(4)</label><graphic position="anchor" xlink:href="//html.hanspub.org/file/21-1541665x15_hanspub.png"  xlink:type="simple"/></disp-formula><disp-formula id="hanspub.34344-formula108"><label>(5)</label><graphic position="anchor" xlink:href="//html.hanspub.org/file/21-1541665x16_hanspub.png"  xlink:type="simple"/></disp-formula><p>上述公式中，GMM的参数<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/21-1541665x17_hanspub.png" xlink:type="simple"/></inline-formula>有3个，即每个高斯分量的权重<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/21-1541665x18_hanspub.png" xlink:type="simple"/></inline-formula>、均值向量<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/21-1541665x19_hanspub.png" xlink:type="simple"/></inline-formula>和协方差矩阵<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/21-1541665x20_hanspub.png" xlink:type="simple"/></inline-formula>(RGB三通道，即3 &#215; 3矩阵)。上述的参数<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/21-1541665x21_hanspub.png" xlink:type="simple"/></inline-formula>由图像的对比度决定，通常<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/21-1541665x22_hanspub.png" xlink:type="simple"/></inline-formula>取50，<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/21-1541665x23_hanspub.png" xlink:type="simple"/></inline-formula>、<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/21-1541665x24_hanspub.png" xlink:type="simple"/></inline-formula>分别为图像区域的像素，<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/21-1541665x25_hanspub.png" xlink:type="simple"/></inline-formula>、<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/21-1541665x26_hanspub.png" xlink:type="simple"/></inline-formula>分别为像素<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/21-1541665x27_hanspub.png" xlink:type="simple"/></inline-formula>、<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/21-1541665x28_hanspub.png" xlink:type="simple"/></inline-formula>的属性。</p><p>GrabCut算法不断分割顶点与端点间的边、相邻顶点间的边，使每个像素仅与源点s或汇点t相连，此时图像的总能量可由公式(1)计算，示意图如图1(a)所示；当图像总能量达到最小时即实现目标分割，示意图如图1(b)所示。</p><p>下面是GrabCut算法示意图：</p><p>图1. GrabCut算法示意图</p><p>图2是GrabCut算法流程图。</p><p>图2. GrabCut算法示意图</p><p>GrabCut算法的实现步骤为：</p><p>Step1：输入图像，用户交互矩形框标记目标及背景区域。</p><p>Step2：分别对目标及背景区域构建高斯函数混合模型，即构建S-T图。</p><p>Step3：定义节点到源点和汇点间边的权值及节点间边的权值。</p><p>Step4：构建能量函数及求解能量函数。</p><p>Step5：重复Step4，更新GMM参数至收敛能量函数最小化，即分割目标图像。</p></sec><sec id="s5"><title>3. 改进的引导滤波器</title><sec id="s5_1"><title>3.1. 引导滤波器</title><p>引导滤波是一种图像滤波技术，通过一张引导图G，结合目标输入图像P进行滤波处理，输出图像与输入图像P大致相似，但纹理不同，纹理部分与引导图G相似。引导图可以是单独的图像或输入图像P，选取的引导图不同则输出图像存在差别。当引导图G是输入图像P时，该引导滤波器的输出效果与双边滤波器的输出效果类似，此时引导滤波即保持边缘特征，不同于双边滤波的是引导滤波保持了双边滤波的优势，既有效保持边缘，非迭代计算，又克服了双边滤波的缺点，即设计一种时间复杂度为<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/21-1541665x31_hanspub.png" xlink:type="simple"/></inline-formula>的快速滤波器，而且在主要边缘附近没有梯度的变形。引导滤波可以很容易设计一个与滤波半径无关的优化算法。其中串口半径为平滑半径，参数<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/21-1541665x32_hanspub.png" xlink:type="simple"/></inline-formula>为平滑项参数，其值越大平滑的越明显。</p><p>引导滤波算法原理：</p><disp-formula id="hanspub.34344-formula109"><label>(6)</label><graphic position="anchor" xlink:href="//html.hanspub.org/file/21-1541665x33_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中，i、k是像素索引，a、b是当窗口中心位于k时该线性函数的系数，I是输入像素的值，即q是进行计算后输出像素的值。如上面所述即当<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/21-1541665x34_hanspub.png" xlink:type="simple"/></inline-formula>时，引导图像为输入图像，引导滤波保持边缘特征。对公式(1)中两边取梯度可得：</p><disp-formula id="hanspub.34344-formula110"><label>(7)</label><graphic position="anchor" xlink:href="//html.hanspub.org/file/21-1541665x35_hanspub.png"  xlink:type="simple"/></disp-formula><p>当输入图像I有梯度时，输出图像q也有类似的梯度：</p><disp-formula id="hanspub.34344-formula111"><label>(8)</label><graphic position="anchor" xlink:href="//html.hanspub.org/file/21-1541665x36_hanspub.png"  xlink:type="simple"/></disp-formula><p>q为p去除噪声或纹理之后的图像，<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/21-1541665x37_hanspub.png" xlink:type="simple"/></inline-formula>表示噪声。</p><disp-formula id="hanspub.34344-formula112"><label>(9)</label><graphic position="anchor" xlink:href="//html.hanspub.org/file/21-1541665x38_hanspub.png"  xlink:type="simple"/></disp-formula><p><inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/21-1541665x39_hanspub.png" xlink:type="simple"/></inline-formula>、<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/21-1541665x40_hanspub.png" xlink:type="simple"/></inline-formula>为常数项系数，<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/21-1541665x41_hanspub.png" xlink:type="simple"/></inline-formula>为正则化参数，避免<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/21-1541665x42_hanspub.png" xlink:type="simple"/></inline-formula>过大，k为中心位置，<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/21-1541665x43_hanspub.png" xlink:type="simple"/></inline-formula>是所有包含像素的窗口。正则化参数的变化影响滤波效果。当<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/21-1541665x44_hanspub.png" xlink:type="simple"/></inline-formula>为0，即上述公式中最小解a为1，b为0，此时输出图像与原图像一样，不做滤波操作；当<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/21-1541665x45_hanspub.png" xlink:type="simple"/></inline-formula>，在像素强度变化小的区域，a趋近于0，b趋近于<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/21-1541665x46_hanspub.png" xlink:type="simple"/></inline-formula>；相反在像素强度变化大的区域，a近似为1，b近似为0，此时滤波效果较弱，有利于保持边缘特征，即随着<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/21-1541665x47_hanspub.png" xlink:type="simple"/></inline-formula>的增大，滤波效果越明显。</p><disp-formula id="hanspub.34344-formula113"><label>(10)</label><graphic position="anchor" xlink:href="//html.hanspub.org/file/21-1541665x48_hanspub.png"  xlink:type="simple"/></disp-formula><disp-formula id="hanspub.34344-formula114"><label>(11)</label><graphic position="anchor" xlink:href="//html.hanspub.org/file/21-1541665x49_hanspub.png"  xlink:type="simple"/></disp-formula><p><inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/21-1541665x50_hanspub.png" xlink:type="simple"/></inline-formula>是图像I在窗口<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/21-1541665x51_hanspub.png" xlink:type="simple"/></inline-formula>中的平均值，<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/21-1541665x52_hanspub.png" xlink:type="simple"/></inline-formula>是窗口<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/21-1541665x53_hanspub.png" xlink:type="simple"/></inline-formula>中的像素的数量。<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/21-1541665x54_hanspub.png" xlink:type="simple"/></inline-formula>是待滤波图像p在窗口<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/21-1541665x55_hanspub.png" xlink:type="simple"/></inline-formula>中的均值，<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/21-1541665x56_hanspub.png" xlink:type="simple"/></inline-formula>是I在窗口<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/21-1541665x57_hanspub.png" xlink:type="simple"/></inline-formula>中的方差。</p><disp-formula id="hanspub.34344-formula115"><label>(12)</label><graphic position="anchor" xlink:href="//html.hanspub.org/file/21-1541665x58_hanspub.png"  xlink:type="simple"/></disp-formula><p>由公式(7)建立每个像素点从I到q的映射。图3是引导滤波示意图。</p><p>图3. 引导滤波示意图</p></sec><sec id="s5_2"><title>3.2. 改进的引导滤波</title><p>通过实验对比，改进后的引导滤波在锐化边缘效果上更好。改进后的算法步骤如下：</p><p>利用GrabCut算法对图像进行分割，先进行用户交互矩形框标记目标、背景区域，用高斯混合模型分别对目标和背景进行建模，通过迭代方式计算得到初始分割结果；然后对分割结果进行二值化处理，二值化后的分割图像作为引导滤波的引导图像掩膜，最后通过引导滤波器结合原图像和引导图像优化GrabCut算法分割后的边缘凹陷突刺结果。</p></sec></sec><sec id="s6"><title>4. 结合引导滤波的GrabCut前景分割</title><p>图4是结合引导滤波和GrabCut算法的流程图：</p><p>图4. 结合引导滤波和GrabCut流程图</p><p>Step1：用户交互标记目标及背景区域。首先输入具有目标容器的图像，通过用户交互用矩形框标记出背景、目标区域，即矩形框外的像素区域为背景区域，矩形框内的区域为目标区域和部分需要剔除的背景区域。</p><p>Step2：GrabCut算法对目标容器区域进行分割。对目标及背景像素区域分别建立高斯混合模型，迭代更新求取高斯函数中的各参数，迭代到能量函数收敛完成能量函数最小化即分割出目标容器图像。</p><p>Step3：获得掩码图像，即引导滤波的引导图。将GrabCut算法分割出的目标容器图像进行二值化处理，二值化处理后的目标容器图像作为引导滤波器中的引导图。</p><p>Step4：通过引导滤波算法优化分割结果。将二值化后的分割图像作为引导图结合原图像作为引导滤波器的输入，通过引导滤波器得到优化后的目标容器图像分割结果，优化后的目标容器图像效果更好。</p></sec><sec id="s7"><title>5. 实验与分析</title><p>如图6(a)为具有前景瓷杯容器的图像，其RGB直方图如图5所示，需要通过用户交互对图像a中的目标容器用矩形框进行标记，如图6(b)所示，用蓝色矩形框标记出目标容器区域，即矩形框外的像素区域为背景区域，矩形框标记的区域如图6(c)所示，图像c中的像素区域存在目标容器，同时也存在需要剔除的背景区域。通过GrabCut算法过程中对目标和背景像素区域分别建立高斯混合模型，迭代更新其能量函数最小化即分割出目标容器图像，如图6(d)所示。</p><p>图5. RGB直方图</p><p>图6. 交互分割过程</p><p>通过GrabCut算法分割出的目标容器图像边缘存在凹陷、突刺问题，结合改进的引导滤波算法，将GrabCut算法预分割出的目标容器图像二值化，将二值化图像作为引导滤波算法的引导图像，结合原图像一起通过引导滤波器优化得到分割结果。图7为GrabCut算法结合不同的去噪算法实验结果。</p><p>图7. 结合不同去噪算法实验结果</p><p>为了证明所提算法的有效性，将GrabCut算法分别于本文算法、双边滤波算法、中值滤波算法、高斯滤波算法和均值偏移滤波算法结合的实验效果进行比较，比较结果如表1所示。以上几种方法在Intel(R)Core(TM)i5-3210M CPU@2.5 Hz处理器、4G内存、Windows7 64位操作系统和Pycharm2017的环境中运行。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Comparision of GrabCut with different noise reduction algorithm</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >算法</th><th align="center" valign="middle" >PSNR</th><th align="center" valign="middle" >MSE</th><th align="center" valign="middle" >SSIM</th><th align="center" valign="middle" >平均时间/s</th></tr></thead><tr><td align="center" valign="middle" >本文算法</td><td align="center" valign="middle" >25.4189</td><td align="center" valign="middle" >230.73044</td><td align="center" valign="middle" >0.9999997</td><td align="center" valign="middle" >0.0179</td></tr><tr><td align="center" valign="middle" >双边滤波</td><td align="center" valign="middle" >25.2267</td><td align="center" valign="middle" >240.247767</td><td align="center" valign="middle" >0.9999992</td><td align="center" valign="middle" >0.013005</td></tr><tr><td align="center" valign="middle" >中值滤波</td><td align="center" valign="middle" >24.4800</td><td align="center" valign="middle" >273.878701</td><td align="center" valign="middle" >0.9998748</td><td align="center" valign="middle" >0.0139</td></tr><tr><td align="center" valign="middle" >高斯滤波</td><td align="center" valign="middle" >24.6612</td><td align="center" valign="middle" >264.429429</td><td align="center" valign="middle" >0.9998964</td><td align="center" valign="middle" >0.0259</td></tr><tr><td align="center" valign="middle" >均值偏移滤波</td><td align="center" valign="middle" >25.3251</td><td align="center" valign="middle" >190.794717</td><td align="center" valign="middle" >0.9999872</td><td align="center" valign="middle" >0.373974</td></tr></tbody></table></table-wrap><p>表1. GrabCut结合不同的降噪算法比较</p><p>从表1中结合不同降噪算法比较结果可以看出：本文算法取得了最高的PSNR指标、均值偏移滤波算法次高。本文算法取得了最高的SSIM指标且平均时间较快，均值偏移滤波算法的SSIM指标稍小，其平均时间最慢。其他对比算法的PSNR、SSIM均小于本文算法，平均时间相近，本文算法在解决GrabCut算法目标分割后边缘凹陷、突刺问题上具有最优的特性，效果较其他方法效果更好。</p></sec><sec id="s8"><title>6. 结语</title><p>本文所提出的方法非常简单，基于GrabCut算法进行用户交互后得到的目标容器分割结果存在的边缘凹陷、突刺问题，结合引导滤波算法进行去噪、边缘细化，对比其他几种方法，其在PSNR、SSIM指标上均具有最优的特性，对于前景目标容器与单一背景区别相对明显的图片有着高效的处理速度和良好的处理效果，能够有效解决传统GrabCut算法用户交互后分割前景目标容器造成的边缘凹陷、突刺问题。但是对于前景目标和背景像素区域区分不大的图片，还需要优化GrabCut算法，影响后续操作准确性，本文算法及其他的对比算法PSNR指标都偏低，这也是未来需要改进的地方。</p></sec><sec id="s9"><title>基金项目</title><p>广东省重点领域研发计划项目(2019B010150002)。</p></sec><sec id="s10"><title>文章引用</title><p>张竞峰,柴文光. 结合改进引导滤波的GrabCut容器前景图像分割GrabCut Container Foreground Image Segmentation Combined with Improved Guided Filtering[J]. 计算机科学与应用, 2020, 10(02): 379-386. https://doi.org/10.12677/CSA.2020.102039</p></sec><sec id="s11"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.34344-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Boykov, Y.Y. and Jolly, M.-P. (2001) Interactive Graph Cuts for Optimal Boundary &amp; Region Segmentation of Objects in N-D Images. Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001, Vancouver, Canada, 7-14 July 2001, 105-112.&lt;br&gt;https://doi.org/10.1109/ICCV.2001.937505</mixed-citation></ref><ref id="hanspub.34344-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Rother, C. (2004) GrabCut: Interactive Foreground Extraction Using Iterated Graph Cuts. Proceedings of SIGGRAPH’04, 23.&lt;br&gt; https://doi.org/10.1145/1186562.1015720</mixed-citation></ref><ref id="hanspub.34344-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Chen, D., Chen, B., Mamic, G., Fookes, C. and Sridharan, S. (2008) Improved GrabCut Segmentation via GMM Optimization. 2008 Digital Image Computing: Techniques and Applications, Canberra, 1-3 December 2008, 39-45.  
https://doi.org/10.1109/DICTA.2008.68</mixed-citation></ref><ref id="hanspub.34344-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Tan, W.-N., Sunday, T. and Tan, Y.-F. (2013) Enhanced “GrabCut” Tool with Blob Analysis in Segmentation of Blooming Flower Images. 2013 10th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology, Krabi, Thailand, 15-17 May 2013, 1-4.  
https://doi.org/10.1109/ECTICon.2013.6559597</mixed-citation></ref><ref id="hanspub.34344-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Sangüesa, A.A., Jørgensen, N.K., Larsen, C.A., Nasrollahi, K. and Moeslund, T.B. (2017) Initiating GrabCut by Color Difference for Automatic Foreground Extraction of Passport Imagery. 2016 6th International Conference on Image Processing Theory, Tools and Applications, Oulu, Finland, 12-15 December 2016.  
https://doi.org/10.1109/IPTA.2016.7820964</mixed-citation></ref><ref id="hanspub.34344-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">王凯, 曹晓杰. 结合颜色空间变换与GrabCut的超声相控阵图像分割[J]. 智能计算机与应用, 2019, 9(4): 170-172+176.</mixed-citation></ref><ref id="hanspub.34344-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Li, H. and Chen, G. (2004) Segment-Based Stereo Matching Using Graph Cuts.</mixed-citation></ref><ref id="hanspub.34344-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Deng, S., Han, S.-D. and Liu, Y.-J. (2016) Image Segmentation Based on De-formed Multiresolution Graph Cuts. Proceedings of Eighth International Conference on Digital Image Processing. International Society for Optics and Photonics, 10033, Article ID: 1003319.&lt;br&gt;https://doi.org/10.1117/12.2244006</mixed-citation></ref><ref id="hanspub.34344-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">周良芬, 何建农. 基于GrabCut改进的图像分割算法[J]. 计算机应用, 2013, 33(1): 49-52.</mixed-citation></ref><ref id="hanspub.34344-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Guo, C., Li, Z., Qiao, X., Li, C. and Yue, J. (2015) Image Segmentation of Underwater Sea Cucumber Using GrabCut with Saliency Map. Transactions of the Chinese Society for Agricultural Machinery, 46, 147-152.</mixed-citation></ref><ref id="hanspub.34344-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Hua, S. and Shi, P. (2014) GrabCut Color Image Segmentation Based on Region of Interest. 2014 7th International Congress on Image and Signal Processing, Dalian, 14-16 October 2014, 392-396.&lt;br&gt;https://doi.org/10.1109/CISP.2014.7003812</mixed-citation></ref><ref id="hanspub.34344-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Jaisakthi, S.M., Mirunalini, P. and Aravindan, C. (2018) Automated Skin Lesion Segmentation of Dermoscopic Images using GrabCut and K-Means Algorithms. IET Computer Vision, 12, 1088-1095.  
https://doi.org/10.1049/iet-cvi.2018.5289</mixed-citation></ref></ref-list></back></article>