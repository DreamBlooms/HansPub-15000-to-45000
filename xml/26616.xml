<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2018.88137</article-id><article-id pub-id-type="publisher-id">CSA-26616</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20180800000_58221613.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于智能手机的三维模型重建方法研究
  Research on 3D Model Reconstruction Method Based on Smart Phone
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>曹</surname><given-names>航</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>邱</surname><given-names>志伟</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>辛</surname><given-names>威</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>付</surname><given-names>丹丹</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>淮海工学院，江苏 连云港</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>31</day><month>07</month><year>2018</year></pub-date><volume>08</volume><issue>08</issue><fpage>1270</fpage><lpage>1276</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   三维重建一直是计算机视觉中的重要的研究领域，这是突破现有数字计算机的信息处理能力，将其扩展为能处理多维信息的重要途径之一。针对三维模型重建成本高、操作繁琐、周期长等问题，提出了一种基于智能手机的三维模型重建方法。利用智能手机拍摄物体，通过计算相机内部参数和目标物体的三维信息，生成物体表面的密集点云数据，并根据点云数据建立三维模型。最终以三维激光扫描结果为基础对模型进行分析评价。实验结果表明，该方法可以快速建立高精度的三维模型，具有简单、高效的特点，可应用于各个领域。 3D reconstruction has always been an important research field in computer vision, which is one of the important ways to break through the information processing ability of the existing digital com-puter and extend it to multidimensional information. Aiming at the problems of high cost, cumber-some operation and long cycle of 3D model reconstruction, a 3D model reconstruction method based on smart phone is proposed. Using the intelligent mobile phone to shoot the object, the dense point cloud data on the surface of the object is generated by calculating the internal parameters of the camera and the three-dimensional information of the target object, and a three-dimensional model is established according to the point cloud data. The experimental results show that the method can quickly establish a high-precision 3D model, which is simple and efficient, and can be applied to various fields.
    
  
 
</p></abstract><kwd-group><kwd>智能手机，三维重建，点云数据, Intelligent Mobile Phone</kwd><kwd> Three-Dimensional Reconstruction</kwd><kwd> Point Cloud Data</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>基于智能手机的三维模型重建方法研究<sup> </sup></title><p>曹航<sup>*</sup>，邱志伟，辛威，付丹丹</p><p>淮海工学院，江苏 连云港</p><disp-formula id="hanspub.26616-formula13"><graphic xlink:href="//html.hanspub.org/file/12-1541090x5_hanspub.png"  xlink:type="simple"/></disp-formula><p>收稿日期：2018年8月5日；录用日期：2018年8月20日；发布日期：2018年8月28日</p><disp-formula id="hanspub.26616-formula14"><graphic xlink:href="//html.hanspub.org/file/12-1541090x6_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>三维重建一直是计算机视觉中的重要的研究领域，这是突破现有数字计算机的信息处理能力，将其扩展为能处理多维信息的重要途径之一。针对三维模型重建成本高、操作繁琐、周期长等问题，提出了一种基于智能手机的三维模型重建方法。利用智能手机拍摄物体，通过计算相机内部参数和目标物体的三维信息，生成物体表面的密集点云数据，并根据点云数据建立三维模型。最终以三维激光扫描结果为基础对模型进行分析评价。实验结果表明，该方法可以快速建立高精度的三维模型，具有简单、高效的特点，可应用于各个领域。</p><p>关键词 :智能手机，三维重建，点云数据</p><disp-formula id="hanspub.26616-formula15"><graphic xlink:href="//html.hanspub.org/file/12-1541090x7_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2018 by authors and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/12-1541090x8_hanspub.png" /> <img src="//html.hanspub.org/file/12-1541090x9_hanspub.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>如今随着科技的发展，越来越多的三维影像产品出现在人们的生活中。一般的三维模型重建方法是利用专用的设备如深度扫描仪等来获取三维数据，或者利用如3DSMAX，CAD以及MAMY等专业软件来构造三维模型。这样的方法大多都有着操作复杂，效率低，周期长，成本高等问题，无法适用于广泛的日常生活中。</p><p>而基于智能手机的三维模型重建是利用智能手机对同一物体在不同角度进行拍摄，通过一系列照片对物体进行三维模型重建 [<xref ref-type="bibr" rid="hanspub.26616-ref1">1</xref>][<xref ref-type="bibr" rid="hanspub.26616-ref2">2</xref>]。这种方法自动化程度高，实用性好，降低了建模成本与条件，适用于任何场景的重建。本文概括介绍了基于智能手机三维重建的各阶段及整体流程。</p></sec><sec id="s4"><title>2. 基于智能手机的三维模型重建方法</title><sec id="s4_1"><title>2.1. 相机标定</title><p>在对目标物拍摄之前，相机标定是必不可少的步骤之一。使用同一个相机对同一个黑白棋盘进行不同角度的拍摄，通过点的三维世界坐标和二维相机平面像素坐标来求解图像平面的单应性矩阵H，从而得到内部参数和外部参数 [<xref ref-type="bibr" rid="hanspub.26616-ref3">3</xref>]。</p><p>基本原理：</p><p>s [ u v 1 ] = K [ r 1 r 2 r 3 t ] [ X Y 0 1 ] = K [ r 1 r 2 t ] [ X Y 1 ]</p><p>H = [ h 1 h 2 h 3 ] = λ K [ r 1 r 2 t ]</p><p>根据旋转矩阵的性质，即 r 1 T r 2 = 0 和 | | r 1 | | = | | r 2 | | = 1 ，每幅图像可以获得以下两个对内参数矩阵的基本约束：</p><p>h 1 T k − T k − 1 h 2 = 0 h 1 T k − T k − 1 h 1 = h 2 T k − T k − 1 h 2</p><p>由于摄像机有5个未知内参数，所以当所摄取得的图像数目大于等于3时，就可以线性唯一求解出K得到内参矩阵。</p></sec><sec id="s4_2"><title>2.2. 特征点的提取和匹配</title><p>特征点的提取和匹配是利用两幅图像中的对应点来求取两个相机的相对关系。对于图像差别较大的情况，推荐使用SIFT特征，因为SIFT对旋转、尺度、透视都有较好的鲁棒性。如果差别不大，可以考虑其他更快速的特征，比如SURF、ORB等。</p><sec id="s4_2_1"><title>2.2.1. 基于SIFT算子的特征点的提取</title><p>SIFT算法是一种能够在尺度、亮度和视点变化的情况下提取稳定的特征点，并且生成具有良好匹配性特征点的方法 [<xref ref-type="bibr" rid="hanspub.26616-ref4">4</xref>]。提取过程分为四步：</p><p>1) 尺度空间极值检测</p><p>利用高斯核函数对图像进行尺度变换，获得图像在尺度空间下的多尺度序列表示。</p><p>L ( x , y , σ ) = G ( x , y , σ ) ⊗ I ( x , y )</p><p>其中为高斯核，随着尺度因子的改变，将会生成不同尺度下的图像，称为高斯尺度空间。之后构建DoG (Difference-of-Gaussians)空间，来检测尺度空间的局部极值。</p><p>2) 精确定位特征点</p><p>将候选特征点带入二次泰勒展开，从而修正特征点的位置达到子像素精度。这些特征点中很多都是不稳定的，需要除掉这些点。因此设定阈值，将小于的点剔除点，这样就增强了匹配的可靠性和稳定性。</p><p>3) 确定特征点方向</p><p>首先在尺度空间中计算像素梯度：</p><p>m ( x , y ) = ( ( L ( x + 1 ,   y ) − L ( x − 1 ,   y ) ) 2 + ( L ( x ,   y + 1 ) − L ( x ,   y − 1 ) ) 2 ) 1 2</p><p>θ ( x , y ) = tan − 1 ( L ( x ,   y + 1 ) − L ( x ,   y − 1 ) L ( x + 1 ,   y ) − L ( x − 1 ,   y ) )</p><p>以每个特征点为中心，采用梯度方向直方图的方法，在8 &#215; 8的领域中对梯度在36个离散方向上进行高斯加权，统计整个领域内的梯度方向。最后将梯度模型的极大值或者多个极大值作为该特征点的主方向或次方向。</p><p>4) 生成SIFT特征描述子</p><p>SIFT特征描述子是一个包含特征点领域信息的高维向量。它是将特征点领域内像素的0度方向旋转为该领域的主方向，以消除旋转变换的影响，然后在4 &#215; 4的区域内统计8个方向的梯度方向直方图。最后将SIFT特征描述子进行归一化处理，以消除光照变化的影响。</p></sec><sec id="s4_2_2"><title>2.2.2. 基于SIFT的特征匹配</title><p>SIFT匹配方法是在具体的点的匹配上采用欧式距离算法。对于匹配图像中的特征点，采用最近邻法搜索参考图像中的特征点，在参考图像中找到距离最近的和次近的两个特征点，如果最近距离和次近距离的比值小于设定的阈值，则接受这一对匹配点。在得到初始匹配结果时，会有一些误匹配，因此需要使用对极几何约束的方法来进行约束匹配，最后利用RANSAC模型剔除误匹配点 [<xref ref-type="bibr" rid="hanspub.26616-ref4">4</xref>][<xref ref-type="bibr" rid="hanspub.26616-ref5">5</xref>]。</p></sec></sec><sec id="s4_3"><title>2.3. 三维模型重建</title><sec id="s4_3_1"><title>2.3.1. 双目重建</title><p>对于空间任意一点M，同时用同一内参的摄像机和观测M点，并且确定在的像面上的m点和的像面上的点是空间同一点M的像点，那么M的三维位置是可以确定的，这就是三维立体视觉重建的基本原理如图1所示。</p><p>图1. 双目重建</p><p>在已知两个相机之间的变换矩阵，还有每一对匹配点的坐标，通过这些已知信息来还原匹配点在空间当中的坐标。根据公式：</p><p>s x 2 = K ( R X + T )</p><p>整理可得到一个关于空间坐标X的线性方程：</p><p>x ⌢ K [ R T ] [ X 1 ] = 0</p><p>求出X左边矩阵的零空间，再将最后一个元素归一化到1，即可求得X。由于只是两张照片的重建因此重建过程中会丢失许多三维数据信息，因此需要加入更多的图片来进行多目重建。</p></sec><sec id="s4_3_2"><title>2.3.2. 多目重建</title><p>通过双目重建后，我们可以得到一些特征点的空间坐标。之后加入第三张相片，与第二张相片进行匹配得到特征点，其中部分特征点同样属于相片一与相片二的特征点。这样我们在已知这些特征点的空间坐标和在第三张相片中像素坐标的情况下，通过solve PnP便可得到第三个相机在世界坐标系下的位置，即相机三到相机一的变换矩阵。</p><p>在得到相机三的变换矩阵后，通过triangulate Points方法将相三和相二之间的匹配点三角化，得到其空间坐标。同时将新得到的空间点和之前的三维点云融合。对之后的相片反复操作便可完成多目重建。</p></sec></sec></sec><sec id="s5"><title>3. 实验验证及分析</title><sec id="s5_1"><title>3.1. 数据准备</title><p>在进行三维模型重建之前需要对相机进行相机标定，本文使用的是张正友标定法来标定得到手机摄像头的内参矩阵 [<xref ref-type="bibr" rid="hanspub.26616-ref6">6</xref>][<xref ref-type="bibr" rid="hanspub.26616-ref7">7</xref>]。使用手机对黑白棋盘进行不同角度的拍摄用于相机标定的棋盘格，之后提取内角点进行标定得到标定误差及内参矩阵。</p><p>在对目标物进行拍摄时，应360˚全方位拍摄，同时保证每张相片拍摄时的拍摄角度和拍摄距离基本一致，还要注意相邻照片之间的交叠面积和摄像头分辨率。本文对校内孔子雕像如图2所示进行模型重建，拍摄照片为43张。</p><p>将所有相片导入，进行特征点的提取与匹配。由于手机拍摄所得相片差别较大，而基于SIFT算法特征点的提取与匹配对旋转、尺度、透视都有较好的鲁棒性。因此本文使用的是SIFT算法，得到一些稀疏的点云，称为稀疏重建，如图3所示。稀疏重建的结果只能看出物体的轮廓，因此在不影像物体的形状和点云质量的情况下需要对点云进行密集处理，称为密集重建。本文密集重建使用的是CMVS算法，得到的密集重建结果如图4所示。经过密集重建后得到的数据模型仍是由点云构成的。因此需要对密集重建结果进行表面纹理贴图处理。</p></sec><sec id="s5_2"><title>3.2. 三维重建结果</title><p>通过上述的数据准备与处理，得到最终的三维模型重建结果如图5所示，将此模型与实物以及三维激光扫描仪得到的扫描结果如图6所示进行对比分析。</p><p>图2. 孔子像</p><p>图3. 稀疏重建</p><p>图4. 密集重建</p><p>图5. 重建结果</p><p>图6. 激光扫描结果</p></sec><sec id="s5_3"><title>3.3. 结果分析</title><p>重建结果与实物和三维激光扫描仪扫描结果进行对比，模型形态无较大的几何畸变，雕像上的文字还原清晰，整体还原度较高，达到预计要求。但重建模型中的头部、肩部以及手臂内侧出现部分空缺，分析原因认为，由于雕像高度与拍摄角度的问题，存在一些拍摄死角导致以上部分未能得到足够多的点云数据，影响最终的建模结果。可以通过提高拍摄高度以及改变密集重建方法予以改进。同时该结果只能显示物体的形状和样貌，并不能得到物体的坐标、尺寸等属性信息，因此基于智能手机的三维模型重建技术仍有很大的发展空间。</p></sec></sec><sec id="s6"><title>4. 结语</title><p>本文以智能手机拍摄的孔子像相片为数据基础，通过相机标定、特征点的提取与匹配以及最终的模型重建等一系列步骤成功建立了雕像的三维模型，验证了该方法的可行性。该方法操作简便、自动化高、适用范围广，不仅减少了购买专业仪器的高额成本，还大大缩短了建模周期，为快速三维模型重建提供技术支持。基于智能手机的三维模型重建效果好，实用性强，可用于生活购物，现场勘测，文物保护以及工业生产等多个领域。</p></sec><sec id="s7"><title>基金项目</title><p>淮海工学院大学生创新创业项目，基于智能手机的三维模型重建方法研究(项目编号：Z201711641107002)。</p></sec><sec id="s8"><title>文章引用</title><p>曹 航,邱志伟,辛 威,付丹丹. 基于智能手机的三维模型重建方法研究 Research on 3D Model Reconstruction Method Based on Smart Phone[J]. 计算机科学与应用, 2018, 08(08): 1270-1276. https://doi.org/10.12677/CSA.2018.88137</p></sec><sec id="s9"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.26616-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">伍燕萍. 基于图像的三维重建[D]: [硕士学位论文]. 北京: 北京交通大学, 2009.</mixed-citation></ref><ref id="hanspub.26616-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">佘彦杰. 基于多幅图像序列的三维重建[D]: [硕士学位论文]. 长春: 吉林大学, 2006.</mixed-citation></ref><ref id="hanspub.26616-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">zkl99999. 张正友平面标定方法[EB/OL]. 
http://blog.csdn.net/zkl99999/article/details/48372203, 2015-09-11.</mixed-citation></ref><ref id="hanspub.26616-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">乔警卫, 胡少兴. 三维重建中特征点提取与匹配算法研究[J]. 系统仿真学报, 2008(s1): 400-403.</mixed-citation></ref><ref id="hanspub.26616-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">郭一洋, 宋伟东, 戴激光. 一种改进的多源遥感影像SIFT算法匹配策略[J]. 测绘工程, 2017, 26(1): 26-31.</mixed-citation></ref><ref id="hanspub.26616-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">sylvester0510. 张正友标定算法原理详解[EB/OL]. 
http://blog.csdn.net/u010128736/article/details/52860364, 2016-10-19.</mixed-citation></ref><ref id="hanspub.26616-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Abcijkxyz. 张正友相机标定Opencv实现以及标定流程&amp;标定结果评价&amp;图像矫正流程解析[EB/OL]. 
&lt;br&gt;https://my.oschina.net/abcijkxyz/blog/787659, 2016-11-14.</mixed-citation></ref></ref-list></back></article>