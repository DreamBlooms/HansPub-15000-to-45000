<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2020.1012242</article-id><article-id pub-id-type="publisher-id">CSA-39374</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20201200000_45026698.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  激光雷达数据协助下的高光谱图像三维残差网络分类
  3D Residual Network for Hyperspectral Image Classification Aided by LiDAR Data
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>王</surname><given-names>理</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>赵</surname><given-names>艮平</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>王</surname><given-names>卓薇</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>程</surname><given-names>良伦</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>廖</surname><given-names>建尚</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>广东工业大学计算机学院，广东 广州</addr-line></aff><aff id="aff3"><addr-line>广东交通职业技术学院轨道交通学院，广东 广州</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>09</day><month>12</month><year>2020</year></pub-date><volume>10</volume><issue>12</issue><fpage>2296</fpage><lpage>2305</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   高光谱成像(Hyperspectral Imaging, HSI)数据可以在狭窄和连续的波段中收集数据，即使在差异很小的情况下，也可以检测到不同类别的数据。然而，光谱变异性和阴影效应会限制任何HSI的分类精度。与HSI相比，激光雷达数据(LiDAR)是HSI的一个很好的补充，因为它提供了高度信息和来自不同物体的多次回波数据。在激光雷达数据的辅助下，通过HSI分类的预处理和深度残差网络分类，可以有效解决阴影效应光谱变异性的问题。除此之外，来源于点云数据的数字高程模型(Digital Elevation Models, DEM)也能够提高HSI分类性能。通过在MUUFL港湾高光谱和激光雷达机载数据集上进行实验的结果表明，采用两种DEM栅格层结合HSI的分类准确率为98.16%，而仅采用HSI数据集独立学习方法的分类准确率为96.3%。并且随着精度的提高，标准偏差从0.304降低到0.150。 Hyperspectral imaging (HSI) allows data to be collected in narrow and continuous wavebands, and even when the differences are small, different categories can be detected. However, spectral variability and shadow effects can limit the classification of any hyperspectral image. Compared with HSI, the LiDAR data is an excellent complement to HIS, because it provides both elevation information and multiple returns of echoes from different objects. A procedure including preprocessing and deep residual network classification is investigated for classification of HSI aided by the LiDAR data to solve the problem of identifying shaded objects and spectral variability. In addition, Digital Elevation Models (DEM) derived from point cloud data can also improve the performance of HSI classification. Experiments were performed on the MUUFL bay harbor hyperspectral and LiDAR airborne data sets. The results show that 98.16% classification accuracy was achieved when using two DEM raster layers combined with hyperspectral images, compared to 96.3% accuracy using independent learning methods derived from only the HSI data set. As the accuracy increased, the standard deviation decreased from 0.304 to 0.150. The former indicates that the effect of spectral variability is mitigated. 
  
 
</p></abstract><kwd-group><kwd>深度学习，高光谱图像，激光雷达，阴影效应，光谱变异, Deep Learning</kwd><kwd> Hyperspectral Image</kwd><kwd> LiDAR</kwd><kwd> Shadow Effect</kwd><kwd> Spectral Variability</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>摘要</title><p>高光谱成像(Hyperspectral Imaging, HSI)数据可以在狭窄和连续的波段中收集数据，即使在差异很小的情况下，也可以检测到不同类别的数据。然而，光谱变异性和阴影效应会限制任何HSI的分类精度。与HSI相比，激光雷达数据(LiDAR)是HSI的一个很好的补充，因为它提供了高度信息和来自不同物体的多次回波数据。在激光雷达数据的辅助下，通过HSI分类的预处理和深度残差网络分类，可以有效解决阴影效应光谱变异性的问题。除此之外，来源于点云数据的数字高程模型(Digital Elevation Models, DEM)也能够提高HSI分类性能。通过在MUUFL港湾高光谱和激光雷达机载数据集上进行实验的结果表明，采用两种DEM栅格层结合HSI的分类准确率为98.16%，而仅采用HSI数据集独立学习方法的分类准确率为96.3%。并且随着精度的提高，标准偏差从0.304降低到0.150。</p></sec><sec id="s2"><title>关键词</title><p>深度学习，高光谱图像，激光雷达，阴影效应，光谱变异</p></sec><sec id="s3"><title>3D Residual Network for Hyperspectral Image Classification Aided by LiDAR Data<sup> </sup></title><p>Li Wang<sup> 1</sup>, Genping Zhao<sup>1</sup>, Zhuowei Wang<sup>1</sup>, Lianglun Cheng<sup>1</sup>, Jianshang Liao<sup>2</sup></p><p><sup>1</sup>School of Computer Science, Guangdong University of Technology, Guangzhou Guangdong</p><p><sup>2</sup>School of Rail Transit, Guangdong Communication Polytechnic, Guangzhou Guangdong</p><p><img src="//html.hanspub.org/file/17-1541968x4_hanspub.png" /></p><p>Received: Nov. 26<sup>th</sup>, 2020; accepted: Dec. 18<sup>th</sup>, 2020; published: Dec. 25<sup>th</sup>, 2020</p><p><img src="//html.hanspub.org/file/17-1541968x5_hanspub.png" /></p></sec><sec id="s4"><title>ABSTRACT</title><p>Hyperspectral imaging (HSI) allows data to be collected in narrow and continuous wavebands, and even when the differences are small, different categories can be detected. However, spectral variability and shadow effects can limit the classification of any hyperspectral image. Compared with HSI, the LiDAR data is an excellent complement to HIS, because it provides both elevation information and multiple returns of echoes from different objects. A procedure including pre-processing and deep residual network classification is investigated for classification of HSI aided by the LiDAR data to solve the problem of identifying shaded objects and spectral variability. In addition, Digital Elevation Models (DEM) derived from point cloud data can also improve the performance of HSI classification. Experiments were performed on the MUUFL bay harbor hyperspectral and LiDAR airborne data sets. The results show that 98.16% classification accuracy was achieved when using two DEM raster layers combined with hyperspectral images, compared to 96.3% accuracy using independent learning methods derived from only the HSI data set. As the accuracy increased, the standard deviation decreased from 0.304 to 0.150. The former indicates that the effect of spectral variability is mitigated.</p><p>Keywords:Deep Learning, Hyperspectral Image, LiDAR, Shadow Effect, Spectral Variability</p><disp-formula id="hanspub.39374-formula11"><graphic xlink:href="//html.hanspub.org/file/17-1541968x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2020 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/17-1541968x7_hanspub.png" /> <img src="//html.hanspub.org/file/17-1541968x8_hanspub.png" /></p></sec><sec id="s5"><title>1. 引言</title><p>随着目前高光谱成像系统技术的发展，成像光谱仪采集到的数据越来越精细丰富。一方面HSI的空间分辨率和光谱分辨率越来越高，与普通的遥感图像如多光谱图像相比，HSI波段更多，光谱波段覆盖的范围更加广，蕴含的信息量更丰富，其形成的三维数据有效的结合了地物目标的空间信息和光谱信息，能够有效反映地物目标的信息，因此HSI被越来越广泛地应用在各个领域，如农业 [<xref ref-type="bibr" rid="hanspub.39374-ref1">1</xref>]、矿物鉴定 [<xref ref-type="bibr" rid="hanspub.39374-ref2">2</xref>]、景观分类 [<xref ref-type="bibr" rid="hanspub.39374-ref3">3</xref>] 等领域。然而，HSI的分类常常遇到光谱变异性问题，给地物 [<xref ref-type="bibr" rid="hanspub.39374-ref4">4</xref>] [<xref ref-type="bibr" rid="hanspub.39374-ref5">5</xref>] 的识别带来很大困难。有几种方法被提出来解决这个问题，如光谱解混 [<xref ref-type="bibr" rid="hanspub.39374-ref6">6</xref>] 和特征变换 [<xref ref-type="bibr" rid="hanspub.39374-ref7">7</xref>]。几何结构是 [<xref ref-type="bibr" rid="hanspub.39374-ref8">8</xref>] 目标识别的另一个重要因素。但实际上，HSI几乎无法检索高大物体(例如树木) [<xref ref-type="bibr" rid="hanspub.39374-ref9">9</xref>] 下方的光谱信息。虽然不同高度的邻域对象通常会产生阴影，从而使相邻像素 [<xref ref-type="bibr" rid="hanspub.39374-ref10">10</xref>] 的光谱特征变得模糊，但这种效果还因与给定物体相关的光谱可变性而变得更加复杂。此外，由于反射光谱主要来自地物表面，因此HSI检测垂直结构的能力受到限制。并且随着高光谱成像系统技术的进一步发展，HSI所含有的光谱信息会越来越多，越来越高维的高光谱数据也对高光谱遥感对地观测技术提出了更加复杂的要求。</p><p>激光成像探测和测距(LiDAR)数据可以提供精确的三维空间信息。激光成像技术能够实现地形高程信息的实时获取，尤其对阴影问题的求解具有重要的参考价值。与HSI相比，激光雷达获取的点云数据往往缺乏丰富的光谱信息。因此，LiDAR与高光谱遥感数据的融合可以有效地进行 [<xref ref-type="bibr" rid="hanspub.39374-ref11">11</xref>] 互补。激光雷达和HSI融合在森林监测 [<xref ref-type="bibr" rid="hanspub.39374-ref12">12</xref>] [<xref ref-type="bibr" rid="hanspub.39374-ref13">13</xref>] 和城市景观分类 [<xref ref-type="bibr" rid="hanspub.39374-ref11">11</xref>] 中得到了有效的研究。这种多源遥感数据融合不仅可以利用HSI的丰富的光谱信息，还协助解决了在HSI分类中由于利用高程信息，如点云数据生成的数字高程模型(DEM)所带来的光谱变化和阴影效应的问题。</p><p>充分利用丰富的光谱特征和空间特征是HSI和激光雷达数据融合的重要内容。好的分类通常需要有效的分类器进行特征提取或者特征挖掘来获得代表性特征。深度学习网络将特征提取和分类器训练过程嵌入到一起，在典型特征学习中被证明具有很大的潜力。许多论文已经证明了深度学习网络在高光谱遥感图像处理方面有很好的表现 [<xref ref-type="bibr" rid="hanspub.39374-ref14">14</xref>] [<xref ref-type="bibr" rid="hanspub.39374-ref15">15</xref>] [<xref ref-type="bibr" rid="hanspub.39374-ref16">16</xref>]。特别是卷积神经网络(CNN)及其扩展网络可以从HSI中学习光谱信息和空间信息 [<xref ref-type="bibr" rid="hanspub.39374-ref17">17</xref>] [<xref ref-type="bibr" rid="hanspub.39374-ref18">18</xref>] [<xref ref-type="bibr" rid="hanspub.39374-ref19">19</xref>]。深度学习网络可能会遇到退化问题。例如，当网络深度增加时，精度可能出现饱和，甚至降低 [<xref ref-type="bibr" rid="hanspub.39374-ref16">16</xref>]，这已经被证明既不是过拟合问题，也不是梯度消失或梯度爆炸问题。因此，何凯明在2015年提出了通过残差连接来解决退化问题。实验结果表明，深度残差网络(Deep residual network, ResNet)能够很好地解决网络退化问题。与CNN相比，光谱空间残差网络被证明能够带来更好的效果 [<xref ref-type="bibr" rid="hanspub.39374-ref20">20</xref>] (spatial-spatial residual network, SSRN)，它利用了光谱残差和空间残差两个模块，从光谱残差块和空间残差块中学习特征。由于它的残差连接，从高维光谱数据中学习多层网络特征可以很好地解决网络退化现象。因此，当有更多的激光雷达数据特征可以用于辅助HSI分类时，SSRN就能够从丰富的信息中学习到更多的高级特征。</p><p>综上所述，为了缓解HSI中阴影效应和光谱变异性问题的影响，本文利用3D-SSRN对基于HSI和激光雷达数据融合的分类进行了探索。为了降低光谱变异性的影响，本文对HSI的数据进行预处理，并在与激光雷达数据进行特征融合前进行降维。与常用的降维方法不同，本文使用了原型分析 [<xref ref-type="bibr" rid="hanspub.39374-ref21">21</xref>] 的特征估计模型对数据进行降维处理。</p></sec><sec id="s6"><title>2. 方法描述</title><p>为了解决HSI分类中的光谱变异性和阴影效应问题，本文利用激光雷达数据对HSI进行辅助分类。鉴于HSI的光谱波段众多，激光雷达数据回波数据多，本文使用了特征降维、不同特征融合、深度学习分类等方法。因此，下面将对这些方法按过程顺序进行介绍。</p><sec id="s6_1"><title>2.1. 对HSI进行基于原型分析的降维处理</title><p>针对高光谱图像数据中存在的数据冗余和光谱变异性问题，本文通过特征变换和特征选择来缓解。具体来说采用基于原型分析的特征挖掘模型(Archetypal Analysis, AA)对HSI数据进行特征选择 [<xref ref-type="bibr" rid="hanspub.39374-ref22">22</xref>]。AA算法目标是找到原始数据 X ∈ R M &#215; N 中最能描述原始数据组成部分的K个凸包 [<xref ref-type="bibr" rid="hanspub.39374-ref23">23</xref>] [<xref ref-type="bibr" rid="hanspub.39374-ref24">24</xref>]，凸包是包含数据 X 的最小凸集。AA的目标函数如公式1是为了得到最优的 C 和 S</p><p>arg min C , S ‖ X − X C S ‖ 2 s . t .   | c k | 1 = 1 ,   | s n | 1 = 1 ,   C ≥ 0 ,   S ≥ 0. (1)</p><p>在这个公式中，约束 | c k | 1 = 1 和约束 C ≥ 0 使特征矩阵 A = X C 为观测数据的加权和，同时约束 | s n | 1 = 1 ， S ≥ 0 要求用特征向量 X C ∈ R M &#215; K 的加权和逼近 X n 。其中，M为数据样本的数量，K为N个原始特征生成的新特征的数量。</p><p>特征矩阵 A = X C 代表特征转换的过程，具体来说，矩阵A中每个生成的新特征，都可以和矩阵C中的非负元素一一对应。因此，利用AA算法对高光谱数据进行特征变换后选择具有代表性的特征来实现降维。假设 X 为N个波段的高光谱数据，A中的K个原型特征为AA算法生成，则可以对目标函数(1)进行优化，得到最优矩阵C。生成不同数量的原型特征会保存不同百分比的信息。 可以通过分析AA算法得到的不同百分比的变化来评估K个原型特征保存了多少原始数据信息。如果当前模型保留的数据信息在可接受范围内，通过AA算法的多端元选择规则，根据索引集Ω从索引矩阵C中选取光谱，可以得到原始数据的目标波段，如公式2</p><p>Ω = { Ω k , k = 1 ,   2 ,   ⋯ ,   K } , Ω k = { i | c k ( i ) &gt; 0 ,   i = 1 ,   2 ,   ⋯ ,   N } . (2)</p></sec><sec id="s6_2"><title>2.2. HSI和激光雷达数据的预处理和特征融合</title><p>当图像中存在阴影效应时，HSI的光谱特征比较稀疏，对不同类别地物的表达能力不足，因此模型的识别分类效果有限。例如，HSI通常不能很好的对树的阴影部分和建筑物的阴影部分中的地物进行分类。此外，仅用HSI也很难将树与草、建筑物与道路的连接点分开。在这种情况下，激光雷达数据可以为反射率数据提供额外的仰角信息。因此，对HSI进行反射率特征和高程特征的融合是提高分类性能的关键。</p><p>一般情况下，激光雷达通过对同一地物目标进行多次扫描提供回波数据，回波数据提供了目标的垂直结构信息。充足的垂直结构信息被认为能够对HSI分类提供有效的帮助。在构成点云数据的多次回波数据中，第一次回波数据和最后一次回波数据对于生成目标垂直结构信息的数字高程模型具有重要作用。因此，本文利用第一次和最后一次回波产生的DEM光栅图像作为激光雷达数据的一部分特征，将其与降维后的HSI融合进行进一步识别。</p></sec><sec id="s6_3"><title>2.3. 利用三维残差网络进行分类</title><p>虽然卷积神经网络可以直接从HSI和激光雷达数据融合的三维数据中提取出光谱–空间特征，但是随着网络层数的增多，卷积神经网络模型的分类精度可能会降低。ResNet有助于解决这一问题，因此本文利用了融合了卷积神经网络和三维残差结构的三维卷积光谱空间残差网络SSRN [<xref ref-type="bibr" rid="hanspub.39374-ref20">20</xref>] 进行分类。整个三维剩余网络如图1所示。该框架采用了带有连续有监督光谱空间残差块的网络。光谱残差块和空间残差块从融合后的图像立方体中分别提取出可学习的光谱特征和空间特征，SSRN可以看作是卷积神经网络卷积层的扩展。与三维卷积神经网络相比，SSRN具有残差连接，网络结构也更深。一方面，可以通过残差连接来减少精度下降，提高分类精度。另一方面，两个连续的残差块分别学习了光谱特征和空间表示，通过它们可以提取出更多的可识别特征。</p><p>图1. 激光雷达数据协助下的高光谱图像三维残差网络分类流程图</p></sec></sec><sec id="s7"><title>3. 实验与分析</title><p>本文在MUUFL数据集 [<xref ref-type="bibr" rid="hanspub.39374-ref25">25</xref>] 上进行了实验，MUUFL数据集的数据采集地点是南密西西比海湾公园校园，高度为3500英尺，空间分辨率为1米，数据大小为220 &#215; 325像元，64个光谱波段，波长单元为2纳米，地物一共有12个类别，如表1所示。</p><p>同时，本文分析了影响训练过程时间和分类性能的多个因素，包括批量大小，空间尺寸大小，学习率。本论文还与SSRN模型进行了比较。为了验证本文激光雷达的有效性，本文测试了只包含光谱特征学习部分的数据、只包含空间特征学习部分的数据和只包含LiDAR特征学习部分的数据。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> The categories, quantities, and proportions of each labe</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >类别</th><th align="center" valign="middle" >数量</th><th align="center" valign="middle" >比例</th></tr></thead><tr><td align="center" valign="middle" >无标签地物</td><td align="center" valign="middle" >17,813</td><td align="center" valign="middle" >24.91</td></tr><tr><td align="center" valign="middle" >树木</td><td align="center" valign="middle" >23,246</td><td align="center" valign="middle" >32.51</td></tr><tr><td align="center" valign="middle" >草地</td><td align="center" valign="middle" >4270</td><td align="center" valign="middle" >5.97</td></tr><tr><td align="center" valign="middle" >混合地面</td><td align="center" valign="middle" >6882</td><td align="center" valign="middle" >9.63</td></tr><tr><td align="center" valign="middle" >泥沙</td><td align="center" valign="middle" >1826</td><td align="center" valign="middle" >2.55</td></tr><tr><td align="center" valign="middle" >道路</td><td align="center" valign="middle" >6687</td><td align="center" valign="middle" >9.35</td></tr><tr><td align="center" valign="middle" >水</td><td align="center" valign="middle" >466</td><td align="center" valign="middle" >0.65</td></tr><tr><td align="center" valign="middle" >建筑物</td><td align="center" valign="middle" >2233</td><td align="center" valign="middle" >3.12</td></tr><tr><td align="center" valign="middle" >建筑阴影</td><td align="center" valign="middle" >6240</td><td align="center" valign="middle" >8.73</td></tr><tr><td align="center" valign="middle" >人行道</td><td align="center" valign="middle" >1385</td><td align="center" valign="middle" >1.94</td></tr><tr><td align="center" valign="middle" >黄色路缘</td><td align="center" valign="middle" >183</td><td align="center" valign="middle" >0.26</td></tr><tr><td align="center" valign="middle" >布板</td><td align="center" valign="middle" >269</td><td align="center" valign="middle" >0.38</td></tr></tbody></table></table-wrap><p>表1. 各标签的类别、数量和比例</p><sec id="s7_1"><title>3.1. 参数设置</title><p>为了寻找最适合该模型的参数设置，我们分析对比了影响训练时间和分类性能的三个主要参数。这三个参数分别是训练数据的批量大小、卷积滤波器的空间尺寸大小和学习率。通过对不同的参数值进行测试，以找出效果最好的参数。在分析比较每个参数的过程中，保留具有最高分类性能的模型参数数值，并以此参数的数值为基础进行对下一个参数的分析。</p><p>训练数据的批量大小直接影响模型的优化程度和优化速度。因此，首先对批量大小对分类精度的影响进行分析总结，见表2。从实验结果可以看出，当批量大小由2增加到4时，分类性能出现显著增长，然后逐渐上升，在达到128时分类性能最好，当批量大小达到256的时候开始下降。当批量大小为128时，模型在MUUFL数据集上可以得到最好的分类精度。</p><p>学习率控制着每次迭代的特征学习进度，学习率设置不当会导致收敛速度变慢。实验中，本文的学</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> Classification accuracy with different batch size</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >批量大小</th><th align="center" valign="middle" >精度(%)</th></tr></thead><tr><td align="center" valign="middle" >2</td><td align="center" valign="middle" >78.27</td></tr><tr><td align="center" valign="middle" >4</td><td align="center" valign="middle" >95.01</td></tr><tr><td align="center" valign="middle" >8</td><td align="center" valign="middle" >96.17</td></tr><tr><td align="center" valign="middle" >16</td><td align="center" valign="middle" >96.80</td></tr><tr><td align="center" valign="middle" >32</td><td align="center" valign="middle" >97.04</td></tr><tr><td align="center" valign="middle" >64</td><td align="center" valign="middle" >97.10</td></tr><tr><td align="center" valign="middle" >128</td><td align="center" valign="middle" >97.34</td></tr><tr><td align="center" valign="middle" >256</td><td align="center" valign="middle" >96.95</td></tr></tbody></table></table-wrap><p>表2. 不同批量大小的分类精度</p><p>习率设置从0.01到0.000001来测试不同学习率对实验结果的影响，如表3所示。根据表中的结果，当学习率为0.0003时，模型在MUUFL数据集上会得到最好的分类精度。</p><table-wrap id="table3" ><label><xref ref-type="table" rid="table3">Table 3</xref></label><caption><title> Classification accuracy with different learning rate</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >学习率</th><th align="center" valign="middle" >精度(%)</th></tr></thead><tr><td align="center" valign="middle" >0.01</td><td align="center" valign="middle" >90.13</td></tr><tr><td align="center" valign="middle" >0.003</td><td align="center" valign="middle" >93.27</td></tr><tr><td align="center" valign="middle" >0.001</td><td align="center" valign="middle" >94.92</td></tr><tr><td align="center" valign="middle" >0.0003</td><td align="center" valign="middle" >97.43</td></tr><tr><td align="center" valign="middle" >0.0001</td><td align="center" valign="middle" >97.08</td></tr><tr><td align="center" valign="middle" >0.00003</td><td align="center" valign="middle" >97.04</td></tr><tr><td align="center" valign="middle" >0.00001</td><td align="center" valign="middle" >94.32</td></tr><tr><td align="center" valign="middle" >0.000003</td><td align="center" valign="middle" >90.92</td></tr><tr><td align="center" valign="middle" >0.000001</td><td align="center" valign="middle" >81.69</td></tr></tbody></table></table-wrap><p>表3. 不同学习率的分类精度</p><p>由于深度神经网络具有卷积结构，卷积核对其在特征学习过程中的空间信息学习能力起着重要作用。因此，卷积核的大小显著影响特征学习性能。在实验中，我们将卷积滤波器的大小从3 &#215; 3逐渐增加到11 &#215; 11来研究卷积核大小对特征学习性能的影响。表4给出了随卷积核大小变化而变化的分类精度。根据实验结果可以总结出，与7 &#215; 7相比，卷积核的过小和过大都会导致分类性能的变差。因此，在最终对MUUFL数据集进行分类实验时，我们将大小设为7 &#215; 7作为卷积滤波器大小参数值，图2为图像在批处理大小为128，学习率为0.0003，卷积滤波器大小为7&#215;7时的分类结果图。</p><table-wrap id="table4" ><label><xref ref-type="table" rid="table4">Table 4</xref></label><caption><title> Classification accuracy with different convolution filter size</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >卷积核大小</th><th align="center" valign="middle" >精度(%)</th></tr></thead><tr><td align="center" valign="middle" >3 &#215; 3</td><td align="center" valign="middle" >92.40</td></tr><tr><td align="center" valign="middle" >5 &#215; 5</td><td align="center" valign="middle" >96.47</td></tr><tr><td align="center" valign="middle" >7 &#215; 7</td><td align="center" valign="middle" >97.40</td></tr><tr><td align="center" valign="middle" >9 &#215; 9</td><td align="center" valign="middle" >96.83</td></tr><tr><td align="center" valign="middle" >11 &#215; 11</td><td align="center" valign="middle" >96.63</td></tr></tbody></table></table-wrap><p>表4. 不同卷积核大小的分类精度</p><p>图2. 分类结果图</p></sec><sec id="s7_2"><title>3.2. 数据降维</title><p>从HSI中得到的光谱特征和从激光雷达数据中得到的高程特征包含着不同的特征信息。预处理使得这些不同的特征信息能够被融合。首先使用AA [<xref ref-type="bibr" rid="hanspub.39374-ref21">21</xref>] 对原64维HSI进行波段选择从而降低数据的维度。分别保留不同数量的选择波段结果进行分类的性能如表5所示。可以看出，降维后数据的维数与分类准确率和训练时间成正比。但当数量达到40时，分类精度并没有得到明显提高。因此，根据实验的数据，本文选择了40个光谱波段，用于与激光雷达数据进行特征融合和分类。</p><table-wrap id="table5" ><label><xref ref-type="table" rid="table5">Table 5</xref></label><caption><title> Classification performance derived by using different dimension of spectral dat</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >维数</th><th align="center" valign="middle" >数据方差(%)</th><th align="center" valign="middle" >分类精度(%)</th><th align="center" valign="middle" >训练时间(s)</th></tr></thead><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" >6.94</td><td align="center" valign="middle" >94.70</td><td align="center" valign="middle" >5022</td></tr><tr><td align="center" valign="middle" >2</td><td align="center" valign="middle" >99.09</td><td align="center" valign="middle" >94.52</td><td align="center" valign="middle" >5044</td></tr><tr><td align="center" valign="middle" >3</td><td align="center" valign="middle" >99.66</td><td align="center" valign="middle" >94.57</td><td align="center" valign="middle" >6245</td></tr><tr><td align="center" valign="middle" >4</td><td align="center" valign="middle" >99.74</td><td align="center" valign="middle" >95.05</td><td align="center" valign="middle" >6267</td></tr><tr><td align="center" valign="middle" >5</td><td align="center" valign="middle" >99.79</td><td align="center" valign="middle" >95.51</td><td align="center" valign="middle" >7614</td></tr><tr><td align="center" valign="middle" >10</td><td align="center" valign="middle" >99.93</td><td align="center" valign="middle" >95.65</td><td align="center" valign="middle" >10,209</td></tr><tr><td align="center" valign="middle" >20</td><td align="center" valign="middle" >99.96</td><td align="center" valign="middle" >96.38</td><td align="center" valign="middle" >16,760</td></tr><tr><td align="center" valign="middle" >40</td><td align="center" valign="middle" >99.98</td><td align="center" valign="middle" >97.40</td><td align="center" valign="middle" >29,381</td></tr><tr><td align="center" valign="middle" >64</td><td align="center" valign="middle" >100</td><td align="center" valign="middle" >97.43</td><td align="center" valign="middle" >43,735</td></tr></tbody></table></table-wrap><p>表5. 利用不同维数的光谱数据得出的分类性能</p></sec><sec id="s7_3"><title>3.3. 特征融合</title><p>MUUFL数据集提供了激光雷达点云数据第一次和最后一次回波的光栅图像数据(如图3(a)，图4(b))。这两幅图像包含了地面的地物高程信息，通过不同的特征融合方式辅助光谱图像数据进行分类。除了将图3(a)第一次回波数据和图3(b)最后一次回波数据与40个光谱波段进行特征融合外，还对第一次回波和最后一次回波的高程信息差图像(如图3(c)所示)与40个光谱波段的特征融合进行了分类验证。如表6所示，任何激光雷达信息辅助HSI分类都有助于提高精度和降低标准差。其中，同时融合首次回波和末次回波能够获得最佳的分类精度。同时，单独的光谱数据和融合数据得到的分类图分别如图4(b)，图4(c)所示，图5为有HSI生成的RGB图像和最终得到的分类图。</p><p>图3. (a) 第一次回波图像；(b) 最后一次回波图像；(c) 第一次回波和最后一次回波的高程信息差图像</p><p>图4. 由高光谱数据(b)和高光谱融合激光雷达数据(c)得到的分类图</p><table-wrap id="table6" ><label><xref ref-type="table" rid="table6">Table 6</xref></label><caption><title> Classification accuracy under feature fusion of 40 spectral bands and different elevation feature from LiDAR dat</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >不同的高程信息</th><th align="center" valign="middle" >精度</th><th align="center" valign="middle" >标准差(%)</th></tr></thead><tr><td align="center" valign="middle" >无高程信息</td><td align="center" valign="middle" >97.40</td><td align="center" valign="middle" >0.30</td></tr><tr><td align="center" valign="middle" >融合第一次回波数据</td><td align="center" valign="middle" >97.86</td><td align="center" valign="middle" >0.15</td></tr><tr><td align="center" valign="middle" >融合最后一次回波数据</td><td align="center" valign="middle" >97.84</td><td align="center" valign="middle" >0.15</td></tr><tr><td align="center" valign="middle" >融合首次和末次回波数据</td><td align="center" valign="middle" >98.16</td><td align="center" valign="middle" >0.15</td></tr></tbody></table></table-wrap><p>表6. 40个光谱波段与不同高程特征融合的激光雷达数据分类精度</p><p>图5. (a) 显示由HSI生成的RGB图像；(b) 分类地图</p></sec></sec><sec id="s8"><title>4. 结语</title><p>本文通过三维残差网络探索了利用激光雷达数据辅助HSI进行分类。同时通过对HSI进行AA降维，缓解了在HSI分类中由于光谱变异性和阴影效应可能造成的误分类。在MUUFL高光谱和激光雷达数据集上进行了分类实验。</p><p>本文是首次使用AA模型进行光谱波段选择。从实验结果可以看出，利用AA模型进行降维可以使三维残差网络对HSI的分类更加有效和精确。在此过程中去除了冗余的数据和噪声。将激光雷达数据与高光谱数据在特征层次上进一步融合后，分类结果相比较于单独的HSI再次得到提高。这意味着，在识别高光谱图像中的地物时，激光雷达数据包含的高程信息与高光谱中包含的光谱信息是互补的。结果还显示，在提供多种回波数据的情况下，使用来自第一次回波数据和最后一次回波数据比只使用单独一层回波数据能够得到更好的分类效果。在整体分类精度提高的同时，标准差也从0.3降低到0.15。这意味着可能是由于激光雷达数据有助于缓解光谱变异性问题，减少了分类精度误差的波动。虽然HSI中的一些相同地物具有不同的光谱信息，但它们的高度信息往往是相同的。同样，对于具有相同光谱的不同物体，只要它们的高程信息不同，我们就可以通过激光雷达数据进行区分。</p><p>我们所有的实验都是使用有监督光谱空间残差网络SSRN进行的。事实上，它已被证明在 [<xref ref-type="bibr" rid="hanspub.39374-ref20">20</xref>] HSI分类中有着良好的性能。通过对HSI和激光雷达数据融合数据进行光谱空间特征学习的连续残差块，保证了该网络在处理多源遥感数据融合任务时具有更强的分类能力。</p></sec><sec id="s9"><title>基金项目</title><p>广东省信息物理融合重点实验室(2016B030301008)；国家自然科学基金(61701123)；国家高分地球观测主要项目(83-Y40G33-9001-18/20)；广东省农业科学与技术创新团队项目(2019KJ147)；广东省科技计划项目，水资源大数据项目(2016B010127005)；广东省自然科学基金项目(2018A030313195)；广州市科技计划项目(201804010262)。</p></sec><sec id="s10"><title>文章引用</title><p>王 理,赵艮平,王卓薇,程良伦,廖建尚. 激光雷达数据协助下的高光谱图像三维残差网络分类3D Residual Network for Hyperspectral Image Classification Aided by LiDAR Data[J]. 计算机科学与应用, 2020, 10(12): 2296-2305. https://doi.org/10.12677/CSA.2020.1012242</p></sec><sec id="s11"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.39374-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Lacar, F.M., Lewis, M.M. and Grierson, I.T. (2001) Use of Hyperspectral Reflectance for Discrimination between Grape Varieties. Scanning the Present and Resolving the Future. Proceedings. IEEE 2001 International Geoscience and Remote Sensing Symposium, Vol. 6, 2878-2880.</mixed-citation></ref><ref id="hanspub.39374-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Van Der Meer, F. (2004) Analysis of Spectral Absorption Features in Hyperspectral Imagery. International Journal of Applied Earth Observation and Geoinformation, 5, 55-68. &lt;br&gt;https://doi.org/10.1016/j.jag.2003.09.001</mixed-citation></ref><ref id="hanspub.39374-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Stuffler, T., Förster, K., Hofer, S., et al. (2009) Hyperspectral Imag-ing—An Advanced Instrument Concept for the EnMAP Mission (Environmental Mapping and Analysis Programme). Acta Astronautica, 65, 1107-1112.  
&lt;br&gt;https://doi.org/10.1016/j.actaastro.2009.03.042</mixed-citation></ref><ref id="hanspub.39374-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Samat, A., Li, J., Liu, S., et al. (2016) Improved Hyperspectral Image Classification by Active Learning Using Pre-Designed Mixed Pixels. Pattern Recognition, 51, 43-58. &lt;br&gt;https://doi.org/10.1016/j.patcog.2015.08.019</mixed-citation></ref><ref id="hanspub.39374-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Plaza, A., Martinez, P., Perez, R., et al. (2004) A New Approach to Mixed Pixel Classification of Hyperspectral Imagery Based on Extended Morphological Profiles. Pattern Recognition, 37, 1097-1116.  
&lt;br&gt;https://doi.org/10.1016/j.patcog.2004.01.006</mixed-citation></ref><ref id="hanspub.39374-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Keshava, N. and Mustard, J.F. (2002) Spectral Unmixing. IEEE Signal Processing Magazine, 19, 44-57.  
&lt;br&gt;https://doi.org/10.1109/79.974727</mixed-citation></ref><ref id="hanspub.39374-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Villa, A., Benediktsson, J.A., Chanussot, J., et al. (2011) Hyperspectral Image Classification with Independent Component Discriminant Analysis. IEEE Transactions on Geoscience and Re-mote Sensing, 49, 4865-4876.  
&lt;br&gt;https://doi.org/10.1109/TGRS.2011.2153861</mixed-citation></ref><ref id="hanspub.39374-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Chen, Y., Zhao, X. and Jia, X. (2015) Spectral-Spatial Classifi-cation of Hyperspectral Data Based on Deep Belief Network. IEEE Journal of Selected Topics in Applied Earth Observa-tions and Remote Sensing, 8, 2381-2392.  
&lt;br&gt;https://doi.org/10.1109/JSTARS.2015.2388577</mixed-citation></ref><ref id="hanspub.39374-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Matsuki, T., Yokoya, N. and Iwasaki, A. (2015) Hyperspec-tral Tree Species Classification of Japanese Complex Mixed Forest with the Aid of LiDAR Data. IEEE Journal of Se-lected Topics in Applied Earth Observations and Remote Sensing, 8, 2177-2187. &lt;br&gt;https://doi.org/10.1109/JSTARS.2015.2417859</mixed-citation></ref><ref id="hanspub.39374-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Friman, O., Tolt, G. and Ahlberg, J. (2011) Illumination and Shadow Compensation of Hyperspectral Images Using a Digital Surface Model and Non-Linear Least Squares Estima-tion. Image and Signal Processing for Remote Sensing XVII, Vol. 8180, 81800Q. &lt;br&gt;https://doi.org/10.1117/12.898084</mixed-citation></ref><ref id="hanspub.39374-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Debes, C., Merentitis, A., Heremans, R., et al. (2014) Hyperspectral and LiDAR Data Fusion: Outcome of the 2013 GRSS Data Fusion Contest. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 7, 2405-2418. &lt;br&gt;https://doi.org/10.1109/JSTARS.2014.2305441</mixed-citation></ref><ref id="hanspub.39374-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Sankey, T., Donager, J., McVay, J., et al. (2017) UAV Lidar and Hyperspectral Fusion for Forest Monitoring in the Southwestern USA. Remote Sensing of Environment, 195, 30-43. &lt;br&gt;https://doi.org/10.1016/j.rse.2017.04.007</mixed-citation></ref><ref id="hanspub.39374-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Dalponte, M., Bruzzone, L. and Gianelle, D. (2008) Fusion of Hy-perspectral and LIDAR Remote Sensing Data for Classification of Complex Forest Areas. IEEE Transactions on Geo-science and Remote Sensing, 46, 1416-1427.  
&lt;br&gt;https://doi.org/10.1109/TGRS.2008.916480</mixed-citation></ref><ref id="hanspub.39374-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">He, K. and Sun, J. (2015) Convolutional Neural Networks at Constrained Time Cost. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Boston, 7-12 June 2015, 5353-5360.  
&lt;br&gt;https://doi.org/10.1109/CVPR.2015.7299173</mixed-citation></ref><ref id="hanspub.39374-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">He, K., Zhang, X., Ren, S., et al. (2016) Deep Residual Learn-ing for Image Recognition. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Las Ve-gas, 27-30 June 2016, 770-778.  
&lt;br&gt;https://doi.org/10.1109/CVPR.2016.90</mixed-citation></ref><ref id="hanspub.39374-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">Zhao, C., Zhao, G. and Jia, X. (2016) Hyperspectral Image Unmixing Based on Fast Kernel Archetypal Analysis. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 10, 331-346.  
&lt;br&gt;https://doi.org/10.1109/JSTARS.2016.2606504</mixed-citation></ref><ref id="hanspub.39374-ref17"><label>17</label><mixed-citation publication-type="other" xlink:type="simple">Zhao, W. and Du, S. (2016) Spectral-Spatial Feature Extrac-tion for Hyperspectral Image Classification: A Dimension Reduction and Deep Learning Approach. IEEE Transactions on Geoscience and Remote Sensing, 54, 4544-4554.  
&lt;br&gt;https://doi.org/10.1109/TGRS.2016.2543748</mixed-citation></ref><ref id="hanspub.39374-ref18"><label>18</label><mixed-citation publication-type="other" xlink:type="simple">Li, W., Wu, G., Zhang, F., et al. (2016) Hyperspectral Image Classification Using Deep Pixel-Pair Features. IEEE Transactions on Geoscience and Remote Sensing, 55, 844-853. &lt;br&gt;https://doi.org/10.1109/TGRS.2016.2616355</mixed-citation></ref><ref id="hanspub.39374-ref19"><label>19</label><mixed-citation publication-type="other" xlink:type="simple">Chen, Y., Jiang, H., Li, C., et al. (2016) Deep Feature Extraction and Classification of Hyperspectral Images Based on Convolutional Neural Networks. IEEE Transactions on Geoscience and Remote Sensing, 54, 6232-6251.  
&lt;br&gt;https://doi.org/10.1109/TGRS.2016.2584107</mixed-citation></ref><ref id="hanspub.39374-ref20"><label>20</label><mixed-citation publication-type="other" xlink:type="simple">Zhong, Z., Li, J., Luo, Z., et al. (2017) Spectral-Spatial Residual Network for Hyperspectral Image Classification: A 3-D Deep Learning Framework. IEEE Transactions on Geoscience and Remote Sensing, 56, 847-858.  
&lt;br&gt;https://doi.org/10.1109/TGRS.2017.2755542</mixed-citation></ref><ref id="hanspub.39374-ref21"><label>21</label><mixed-citation publication-type="other" xlink:type="simple">Mørup, M. and Hansen, L.K. (2010) Archetypal Analysis for Machine Learning. 2010 IEEE International Workshop on Machine Learning for Signal Processing, Espoo, 21-24 Sep-tember 2020, 172-177.  
&lt;br&gt;https://doi.org/10.1109/MLSP.2010.5589222</mixed-citation></ref><ref id="hanspub.39374-ref22"><label>22</label><mixed-citation publication-type="other" xlink:type="simple">McCallum, D. and Avis, D. (1979) A Linear Algorithm for Finding the Convex Hull of a Simple Polygon. Information Processing Letters, 9, 201-206. &lt;br&gt;https://doi.org/10.1016/0020-0190(79)90069-3</mixed-citation></ref><ref id="hanspub.39374-ref23"><label>23</label><mixed-citation publication-type="other" xlink:type="simple">Dwyer, R.A. (1988) On the Convex Hull of Random Points in a Polytope. Journal of Applied Probability, 25, 688-699.  
&lt;br&gt;https://doi.org/10.2307/3214289</mixed-citation></ref><ref id="hanspub.39374-ref24"><label>24</label><mixed-citation publication-type="other" xlink:type="simple">Cutler, A. and Breiman, L. (1994) Archetypal Analysis. Technometrics, 36, 338-347.  
&lt;br&gt;https://doi.org/10.1080/00401706.1994.10485840</mixed-citation></ref><ref id="hanspub.39374-ref25"><label>25</label><mixed-citation publication-type="other" xlink:type="simple">Gader, P., Zare, A., Close, R., Aitken, J. and Tuell, G. (2013) MUUFL Gulfport Hyperspectral and LiDAR Airborne Data Set. University of Florida, Gainesville, Tech. Rep. REP-2013-570.</mixed-citation></ref></ref-list></back></article>