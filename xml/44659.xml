<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2021.118216</article-id><article-id pub-id-type="publisher-id">CSA-44659</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20210800000_67701311.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  应用于心脏病诊断的线性回归决策树模型
  Decision Tree Model Based on Linear Regression for Heart Disease Diagnosis
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>闵</surname><given-names>杰青</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>李</surname><given-names>昕洁</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>谭</surname><given-names>强</given-names></name><xref ref-type="aff" rid="aff4"><sup>4</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>赵</surname><given-names>娜</given-names></name><xref ref-type="aff" rid="aff4"><sup>4</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>李</surname><given-names>向娟</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>王</surname><given-names>剑</given-names></name><xref ref-type="aff" rid="aff5"><sup>5</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>曾</surname><given-names>敬勋</given-names></name><xref ref-type="aff" rid="aff6"><sup>6</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>刘</surname><given-names>学承</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff6"><addr-line>英国曼彻斯特大学计算机科学所，英国 曼彻斯特</addr-line></aff><aff id="aff2"><addr-line>昆明市儿童医院，云南 昆明</addr-line></aff><aff id="aff5"><addr-line>昆明理工大学信息工程与自动化学院，云南 昆明</addr-line></aff><aff id="aff3"><addr-line>新竹交通大学科技管理研究所，台湾 新竹</addr-line></aff><aff id="aff4"><addr-line>云南大学软件学院工程重点实验室，云南 昆明</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>02</day><month>08</month><year>2021</year></pub-date><volume>11</volume><issue>08</issue><fpage>2108</fpage><lpage>2116</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   心脏病是一种十分常见的高发性疾病，已经成为导致人类死亡的主要因素之一。提高心脏病的医疗诊断的准确性，并对其实行更早的干预与治疗是需要关注的问题。在本文中，我们在数据预处理和模型建立前期阶段采用的是python代码实现，最终发现患病比例与性别和年龄也有着一定的联系。然后采用了SPSS对其进行分析，发现R值为0.719，属于0.5~1之间的大效应的情况，因此，模型拟合效果良好。此外，方差分析的显著性值为0，处于0~0.05的范围之内，可以说明各个参数建立的线性关系回归模型具有极显著的统计学意义，即线性关系显著。模型建立的后期阶段采用以决策树为代表的多种预测模型，最终预测准确率如下：基于信息熵的决策树模型为85.6%，基于基尼指数的决策树模型为84.2%，基于基尼指数的决策树(预剪枝)模型为86.6%。我们发现：模型的准确率均在85%左右，其中基于基尼指数的决策树(预剪枝)模型准确率最高。 Heart disease is a very common high-incidence disease, which has become one of the main factors leading to human death. Improving the accuracy of medical diagnosis of heart disease and implementing earlier intervention and treatment are issues that need attention. In this article, we adopted python code in the early stage of data preprocessing and model establishment, and finally found that the disease ratio is also related to gender and age. Then SPSS was used to analyze it, and it was found that the R value was 0.719, which is a large effect between 0.5~1. Therefore, the model fitting effect is good. In addition, the significance value of the analysis of variance is 0, which is within the range of 0~0.05, which can indicate that the linear regression model established by each parameter has extremely significant statistical significance, that is, the linear relationship is significant. In the later stage of model establishment, a variety of prediction models represented by decision tree are used. The final prediction accuracy is as follows: the accuracy of the decision tree model based on information entropy is 85.6%, the accuracy of the decision tree model based on the Gini index is 84.2%, and the accuracy of the decision tree (prepruning) based on the Gini index is 86.6%. We found that the accuracy of the models is around 85%, and the decision tree (prepruning) model based on the Gini index has the highest accuracy. 
  
 
</p></abstract><kwd-group><kwd>变异数分析，线性回归，决策树，智慧医疗, Variance Analysis</kwd><kwd> Linear Regression</kwd><kwd> Decision Tree</kwd><kwd> Smart Healthcare</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>摘要</title><p>心脏病是一种十分常见的高发性疾病，已经成为导致人类死亡的主要因素之一。提高心脏病的医疗诊断的准确性，并对其实行更早的干预与治疗是需要关注的问题。在本文中，我们在数据预处理和模型建立前期阶段采用的是python代码实现，最终发现患病比例与性别和年龄也有着一定的联系。然后采用了SPSS对其进行分析，发现R值为0.719，属于0.5~1之间的大效应的情况，因此，模型拟合效果良好。此外，方差分析的显著性值为0，处于0~0.05的范围之内，可以说明各个参数建立的线性关系回归模型具有极显著的统计学意义，即线性关系显著。模型建立的后期阶段采用以决策树为代表的多种预测模型，最终预测准确率如下：基于信息熵的决策树模型为85.6%，基于基尼指数的决策树模型为84.2%，基于基尼指数的决策树(预剪枝)模型为86.6%。我们发现：模型的准确率均在85%左右，其中基于基尼指数的决策树(预剪枝)模型准确率最高。</p></sec><sec id="s2"><title>关键词</title><p>变异数分析，线性回归，决策树，智慧医疗</p></sec><sec id="s3"><title>Decision Tree Model Based on Linear Regression for Heart Disease Diagnosis<sup> </sup></title><p>Jieqing Min<sup>1*</sup>, Shin-Jye Lee<sup>2#</sup>, Qiang Tan<sup>3</sup>, Na Zhao<sup>3</sup>, Xiangjuan Li<sup>1</sup>, Jian Wang<sup>4</sup>, Ching-Hsun Tseng<sup>5</sup>, Hsueh-Cheng Liu<sup>2</sup></p><p><sup>1</sup>Children’s Hospital of Kunming, Kunming Yunnan</p><p><sup>2</sup>Institute of Science and Technology Management, National Yang Ming Chiao Tung University, Hsinchu Taiwan</p><p><sup>3</sup>School of Software, Key Laboratory in Software Engineering of Yunnan Province, Yunnan University, Kunming Yunnan</p><p><sup>4</sup>College of Information Engineering and Automation, Kunming University of Science and Technology, Kunming Yunnan</p><p><sup>5</sup>Institute of Computer Science, The University of Manchester, Manchester UK</p><p><img src="//html.hanspub.org/file/10-1542235x5_hanspub.png?20210823084258064" /></p><p>Received: Jul. 16<sup>th</sup>, 2021; accepted: Aug. 13<sup>th</sup>, 2021; published: Aug. 20<sup>th</sup>, 2021</p><p><img src="//html.hanspub.org/file/10-1542235x6_hanspub.png?20210823084258064" /></p></sec><sec id="s4"><title>ABSTRACT</title><p>Heart disease is a very common high-incidence disease, which has become one of the main factors leading to human death. Improving the accuracy of medical diagnosis of heart disease and implementing earlier intervention and treatment are issues that need attention. In this article, we adopted python code in the early stage of data preprocessing and model establishment, and finally found that the disease ratio is also related to gender and age. Then SPSS was used to analyze it, and it was found that the R value was 0.719, which is a large effect between 0.5~1. Therefore, the model fitting effect is good. In addition, the significance value of the analysis of variance is 0, which is within the range of 0~0.05, which can indicate that the linear regression model established by each parameter has extremely significant statistical significance, that is, the linear relationship is significant. In the later stage of model establishment, a variety of prediction models represented by decision tree are used. The final prediction accuracy is as follows: the accuracy of the decision tree model based on information entropy is 85.6%, the accuracy of the decision tree model based on the Gini index is 84.2%, and the accuracy of the decision tree (pre-pruning) based on the Gini index is 86.6%. We found that the accuracy of the models is around 85%, and the decision tree (pre-pruning) model based on the Gini index has the highest accuracy.</p><p>Keywords:Variance Analysis, Linear Regression, Decision Tree, Smart Healthcare</p><disp-formula id="hanspub.44659-formula3"><graphic xlink:href="//html.hanspub.org/file/10-1542235x7_hanspub.png?20210823084258064"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2021 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/10-1542235x8_hanspub.png?20210823084258064" /> <img src="//html.hanspub.org/file/10-1542235x9_hanspub.png?20210823084258064" /></p></sec><sec id="s5"><title>1. 引言</title><p>在传统的医疗诊断中，医生往往是根据自己积累的经验以及患者呈现和描述的症状来判断病人病情以及发病原因。然而，这很有可能会导致主观上的判断失误。机器学习主要是基于过去案例的经验进行学习，尤其是基于大数据的机器学习同传统医疗相比有着很大的优势。如果我们将机器学习的分类算法应用于疾病诊断中，那么可以很大程度上提高诊断的准确率，从而帮助人们做出更科学的诊断。</p><p>我们使用机器学习可以解决医疗过程中的很多问题，这对患者和医生都有好处。我们经常使用机器学习中的面向图像特征处理的深度神经网络和分类算法应用在医疗诊断领域中。提取医学影像特征、标准化临床数据和转化文本数据等问题都被人工智能有效解决了。</p><p>在传统计算机看来，医生的问诊记录、患者的日常护理记录、病理科的检验报告、放射科的CT报告等是没有任何意义，而对于人工智能却是有很大意义的。文献 [<xref ref-type="bibr" rid="hanspub.44659-ref1">1</xref>] 使用机器学习的方法诊断糖尿病视网膜病变；文献 [<xref ref-type="bibr" rid="hanspub.44659-ref2">2</xref>] 研究基于集成学习的乳腺癌分类；文献 [<xref ref-type="bibr" rid="hanspub.44659-ref3">3</xref>] 使用感知机算法诊断脊柱病。</p><p>本文使用基于线性回归分析的决策树模型，将其应用于心脏诊断，来帮助医生进行治疗。前期利用spss线性回归来分析数据中变量的关系，最后利用决策树算法来建立模型。但是因为决策树算法有不同的实现方式，因此本文在对比两种不同决策树(一个利用信息熵，一个利用基尼指数)结果后选择表现最优的方式作为最后建立模型的算法。</p></sec><sec id="s6"><title>2. 项目设计</title><sec id="s6_1"><title>2.1. 总体设计</title><p>总体结构设计如图1所示：</p><p>图1. 总体设计流程</p></sec><sec id="s6_2"><title>2.2. SPSS数据线性回归分析和结果</title><p>本文使用SPSS做线性回归分析 [<xref ref-type="bibr" rid="hanspub.44659-ref4">4</xref>]。</p><p>参数说明如表1所示：</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Parameter</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >序号</th><th align="center" valign="middle" >英文符号</th><th align="center" valign="middle" >参数</th></tr></thead><tr><td align="center" valign="middle" >0</td><td align="center" valign="middle" >age</td><td align="center" valign="middle" >年龄</td></tr><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" >sex</td><td align="center" valign="middle" >性别 1 = male，0 = female</td></tr><tr><td align="center" valign="middle" >2</td><td align="center" valign="middle" >cp</td><td align="center" valign="middle" >胸痛类型(4种)：值1：典型心绞痛，值2：非典型心绞痛，值3：非心绞痛，值4：无症状</td></tr><tr><td align="center" valign="middle" >3</td><td align="center" valign="middle" >trestbps</td><td align="center" valign="middle" >静息血压</td></tr><tr><td align="center" valign="middle" >4</td><td align="center" valign="middle" >chol</td><td align="center" valign="middle" >血清胆固醇</td></tr><tr><td align="center" valign="middle" >5</td><td align="center" valign="middle" >fbs</td><td align="center" valign="middle" >空腹血糖 &gt; 128 mg/dl，1 = true，0 = false</td></tr><tr><td align="center" valign="middle" >6</td><td align="center" valign="middle" >restecg</td><td align="center" valign="middle" >静息心电图(值1，2，3)</td></tr><tr><td align="center" valign="middle" >7</td><td align="center" valign="middle" >thalach</td><td align="center" valign="middle" >达到的最大心率</td></tr><tr><td align="center" valign="middle" >8</td><td align="center" valign="middle" >exang</td><td align="center" valign="middle" >运动诱发的心绞痛(1 = yes, 0 = no)</td></tr><tr><td align="center" valign="middle" >9</td><td align="center" valign="middle" >oldpeak</td><td align="center" valign="middle" >相对于休息的运动引起的ST值(ST值与心电图上的位置有关)</td></tr><tr><td align="center" valign="middle" >10</td><td align="center" valign="middle" >slope</td><td align="center" valign="middle" >运动高峰ST段的坡度(值1：uploping向上倾斜，值2：float持平，值3：downsloping向下倾斜)</td></tr><tr><td align="center" valign="middle" >11</td><td align="center" valign="middle" >ca</td><td align="center" valign="middle" >主要的血管数量(0~3)</td></tr><tr><td align="center" valign="middle" >12</td><td align="center" valign="middle" >thal</td><td align="center" valign="middle" >一种叫做地中海贫血的血液疾病(3 = 正常，6 = 固定缺陷，7 = 可逆转缺陷)</td></tr><tr><td align="center" valign="middle" >13</td><td align="center" valign="middle" >target</td><td align="center" valign="middle" >生病与否(0 = no, 1 = true)</td></tr></tbody></table></table-wrap><p>表1. 参数</p><p>判定系数 [<xref ref-type="bibr" rid="hanspub.44659-ref5">5</xref>] 一般需要大于60%才行，是判定线性方程拟合优度的重要指标。我们可以用判定系数来解释回归模型因变量变异的能力。我们将判定系数用R表示，其值越接近1越好。表2中第2列即为判定系数。我们得到的结果显示R = 0.719时模型的效果最好。</p><p>模型残差独立性 [<xref ref-type="bibr" rid="hanspub.44659-ref6">6</xref>] 检验：如果DW值被包含在无自相关性的值域之中(查询Durbin Watson table)，就认为残差是独立的。本例DW = 1.032，残差是独立的。</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> Linear regression analysis result</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >Model</th><th align="center" valign="middle" >R</th><th align="center" valign="middle" >R Square</th><th align="center" valign="middle" >Adjusted R Square</th><th align="center" valign="middle" >Std. Error of the Estimate</th><th align="center" valign="middle" >Durbin Waton</th></tr></thead><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" >0.719<sup>a</sup></td><td align="center" valign="middle" >0.518</td><td align="center" valign="middle" >0.496</td><td align="center" valign="middle" >0.35419</td><td align="center" valign="middle" >1.032</td></tr></tbody></table></table-wrap><p>表2. 线性回归分析结果<sup>b</sup></p><p>a. Predictors: (Constant), thal, restecg, fbs, thalach, chol, trestbps, ca, sex, cp, stope, exang, age, oldpeak. b. Dependent Variable: target.</p><p>我们得到的方差 [<xref ref-type="bibr" rid="hanspub.44659-ref7">7</xref>] 分析的显著性值 &lt; 0.01 &lt; 0.05。结果说明线性关系显著，即由自变量与因变量各个参数建立的线性关系回归模型具有显著的统计学意义。分析结果如表3~5所示：</p><table-wrap id="table3" ><label><xref ref-type="table" rid="table3">Table 3</xref></label><caption><title> ANOVA result</title></caption><table><tbody><thead><tr><th align="center" valign="middle"  colspan="2"  >Model</th><th align="center" valign="middle" >Sum of Square</th><th align="center" valign="middle" >df</th><th align="center" valign="middle" >Mean Square</th><th align="center" valign="middle" >F</th><th align="center" valign="middle" >Sig.</th></tr></thead><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" >Regression</td><td align="center" valign="middle" >38.893</td><td align="center" valign="middle" >13</td><td align="center" valign="middle" >2.992</td><td align="center" valign="middle" >23.848</td><td align="center" valign="middle" >0.000<sup>a</sup></td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Residual</td><td align="center" valign="middle" >36.255</td><td align="center" valign="middle" >289</td><td align="center" valign="middle" >0.125</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Total</td><td align="center" valign="middle" >75.149</td><td align="center" valign="middle" >102</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td></tr></tbody></table></table-wrap><p>表3. 方差分析结果<sup>b</sup></p><p>a. Predictors: (Constant), thal, restecg, fbs, thalach, chol, trestbps, ca, sex, cp, stope, exang, age, oldpeak. b. Dependent Variable: target.</p><table-wrap id="table4" ><label><xref ref-type="table" rid="table4">Table 4</xref></label><caption><title> Significance analysis results of each feature</title></caption><table><tbody><thead><tr><th align="center" valign="middle"  colspan="2"   rowspan="2"  >Model</th><th align="center" valign="middle"  colspan="2"  >Unstandardized Coefficients</th><th align="center" valign="middle" >Standardized Coefficients</th><th align="center" valign="middle"  rowspan="2"  >t</th><th align="center" valign="middle"  rowspan="2"  >Sig.</th></tr></thead><tr><td align="center" valign="middle" >B</td><td align="center" valign="middle" >Std. Error</td><td align="center" valign="middle" >Beta</td></tr><tr><td align="center" valign="middle"  rowspan="14"  >1</td><td align="center" valign="middle" >(Constant)</td><td align="center" valign="middle" >0.899</td><td align="center" valign="middle" >0.293</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >2.830</td><td align="center" valign="middle" >0.005</td></tr><tr><td align="center" valign="middle" >age</td><td align="center" valign="middle" >−0.001</td><td align="center" valign="middle" >0.003</td><td align="center" valign="middle" >−0.015</td><td align="center" valign="middle" >−0.304</td><td align="center" valign="middle" >0.761</td></tr><tr><td align="center" valign="middle" >sex</td><td align="center" valign="middle" >−0.196</td><td align="center" valign="middle" >0.047</td><td align="center" valign="middle" >−0.183</td><td align="center" valign="middle" >−4.157</td><td align="center" valign="middle" >0.000</td></tr><tr><td align="center" valign="middle" >cp</td><td align="center" valign="middle" >0.113</td><td align="center" valign="middle" >0.022</td><td align="center" valign="middle" >0.233</td><td align="center" valign="middle" >5.036</td><td align="center" valign="middle" >0.000</td></tr><tr><td align="center" valign="middle" >trestbps</td><td align="center" valign="middle" >−0.002</td><td align="center" valign="middle" >0.001</td><td align="center" valign="middle" >−0.070</td><td align="center" valign="middle" >−1.583</td><td align="center" valign="middle" >0.114</td></tr><tr><td align="center" valign="middle" >chol</td><td align="center" valign="middle" >0.000</td><td align="center" valign="middle" >0.000</td><td align="center" valign="middle" >−0.037</td><td align="center" valign="middle" >−0.838</td><td align="center" valign="middle" >0.403</td></tr><tr><td align="center" valign="middle" >fbs</td><td align="center" valign="middle" >0.017</td><td align="center" valign="middle" >0.060</td><td align="center" valign="middle" >0.012</td><td align="center" valign="middle" >0.291</td><td align="center" valign="middle" >0.771</td></tr><tr><td align="center" valign="middle" >restecg</td><td align="center" valign="middle" >0.050</td><td align="center" valign="middle" >0.040</td><td align="center" valign="middle" >0.053</td><td align="center" valign="middle" >1.249</td><td align="center" valign="middle" >0.213</td></tr><tr><td align="center" valign="middle" >thalach</td><td align="center" valign="middle" >0.003</td><td align="center" valign="middle" >0.001</td><td align="center" valign="middle" >0.139</td><td align="center" valign="middle" >2.671</td><td align="center" valign="middle" >0.008</td></tr><tr><td align="center" valign="middle" >exang</td><td align="center" valign="middle" >−0.144</td><td align="center" valign="middle" >0.051</td><td align="center" valign="middle" >−0.136</td><td align="center" valign="middle" >−2.804</td><td align="center" valign="middle" >0.005</td></tr><tr><td align="center" valign="middle" >oldpeak</td><td align="center" valign="middle" >−0.059</td><td align="center" valign="middle" >0.023</td><td align="center" valign="middle" >−0.137</td><td align="center" valign="middle" >−2.564</td><td align="center" valign="middle" >0.011</td></tr><tr><td align="center" valign="middle" >slope</td><td align="center" valign="middle" >0.079</td><td align="center" valign="middle" >0.042</td><td align="center" valign="middle" >0.098</td><td align="center" valign="middle" >1.863</td><td align="center" valign="middle" >0.063</td></tr><tr><td align="center" valign="middle" >ca</td><td align="center" valign="middle" >−0.101</td><td align="center" valign="middle" >0.022</td><td align="center" valign="middle" >−0.206</td><td align="center" valign="middle" >−4.603</td><td align="center" valign="middle" >0.000</td></tr><tr><td align="center" valign="middle" >thal</td><td align="center" valign="middle" >−0.119</td><td align="center" valign="middle" >0.036</td><td align="center" valign="middle" >−0.146</td><td align="center" valign="middle" >−3.339</td><td align="center" valign="middle" >0.001</td></tr></tbody></table></table-wrap><p>表4. 各个特征显著性分析结果<sup>a</sup></p><p>a. Dependent Variable: target.</p><table-wrap id="table5" ><label><xref ref-type="table" rid="table5">Table 5</xref></label><caption><title> Residual statistical results</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" >Minimum</th><th align="center" valign="middle" >Maximum</th><th align="center" valign="middle" >Mean</th><th align="center" valign="middle" >Std. Deviation</th><th align="center" valign="middle" >N</th></tr></thead><tr><td align="center" valign="middle" >Predicted Value</td><td align="center" valign="middle" >−0.3457</td><td align="center" valign="middle" >1.2750</td><td align="center" valign="middle" >0.5446</td><td align="center" valign="middle" >0.35887</td><td align="center" valign="middle" >303</td></tr><tr><td align="center" valign="middle" >Residual</td><td align="center" valign="middle" >−0.94748</td><td align="center" valign="middle" >0.93509</td><td align="center" valign="middle" >0.00000</td><td align="center" valign="middle" >0.34648</td><td align="center" valign="middle" >303</td></tr><tr><td align="center" valign="middle" >Std. Predicted Value</td><td align="center" valign="middle" >−2.481</td><td align="center" valign="middle" >2.035</td><td align="center" valign="middle" >0.000</td><td align="center" valign="middle" >1.000</td><td align="center" valign="middle" >303</td></tr><tr><td align="center" valign="middle" >Std. Residual</td><td align="center" valign="middle" >−2.675</td><td align="center" valign="middle" >2.640</td><td align="center" valign="middle" >0.000</td><td align="center" valign="middle" >0.978</td><td align="center" valign="middle" >303</td></tr></tbody></table></table-wrap><p>表5. 残差统计结果<sup>a</sup></p><p>a. Dependent Variable: target.</p><p>我们需要检验数据是否可以做回归分析。回归分析对数据的要求是十分严格的，所以有必要分析残差。</p><p>从图2来看，不完全对称的左右两侧；从图3来看，散点并没有全部靠近斜线。</p><p>综合而言，没有得到最好的残差正态性结果，但是在现实分析当中，理想状态的正态并不多见，接近或者近似就可以接受。</p></sec></sec><sec id="s7"><title>3. 决策树建模和结果</title><p>我们最后选择建立模型的算法是：基于信息熵 [<xref ref-type="bibr" rid="hanspub.44659-ref8">8</xref>] 和基尼指数 [<xref ref-type="bibr" rid="hanspub.44659-ref8">8</xref>] 的决策树 [<xref ref-type="bibr" rid="hanspub.44659-ref9">9</xref>] 算法。</p><p>决策树算法是一种不断逼近离散函数值的方法，是一种典型的分类算法。第一步先进行数据处理，利用归纳算法生成决策树和可读的规则，然后应用决策分析新数据。从本质上来说，通过一系列规则对数据进行分类的过程就叫做决策树算法。</p><p>上世纪60年代到70年代末，决策树方法产生了。J Ross Quinlan为了减少树的深度提出了ID3算法 [<xref ref-type="bibr" rid="hanspub.44659-ref10">10</xref>]，但是没有对叶子数目进行研究。C4.5算法 [<xref ref-type="bibr" rid="hanspub.44659-ref11">11</xref>] 是在ID3算法的基础上进行了改进的，大大改进了剪枝技术、预测变量的缺值处理、派生规则等方面，适合于分类问题和回归问题。</p><p>图2. 标准化残差直方图</p><p>图3. 标准化残差的P-P图</p><p>决策树算法发现数据中蕴涵的分类规则是通过构造决策树实现的，其核心内容是构造精度高且规模小的决策树。构造决策树可以分为两步：第一步，生成决策树：决策树由训练样本集生成。一般情况下，有历史的、达到某个综合水平的和用来进行数据分析处理的数据集作为训练样本的数据集。第二步，对决策树进行剪枝：这个过程实际上是对获得的决策树进行检验、校正和修饰。我们用测试数据集(与原来不同的样本数据集)中的数据测试决策树生成过程中产生的初步规则，剪除那些影响预衡准确性的无用分枝。</p>模型选择<p>结果中的信息有一下几点：</p><p>1) precision——查准率/准确率</p><p>2) recall——查全率/召回率</p><p>3) F1-score——基于查准率和查全率的调和平均</p><p>4) Support——样本标签(本文中的标签是0/1)出现的次数</p><p>5) Accuracy——模型准确率</p><p>6) macro average——宏平均值，即所有标签结果的平均值</p><p>7) weighted average——加权平均值，即所有标签结果的加权平均值</p><p>通过基于信息熵的决策树模型得到的结果如图4所示：</p><p>图4. 信息熵的决策树模型的结果</p><p>图5. 信息熵的决策树模型的ROC曲线</p><p>基于基尼指数的决策树的结果：</p><p>图6. 基尼指数的决策树模型的结果</p><p>图7. 基尼指数的决策树模型的ROC曲线</p><p>基于基尼指数的决策树(预剪枝)的结果：</p><p>图8. 基尼指数的预剪枝决策树模型的结果</p><p>图9. 基尼指数的预剪枝决策树模型的ROC曲线</p><p>通过对比准确率、召回率、ROC曲线图(如图5~9)可以看到，对于本文的数据，两种决策树的结果比较接近，但最终还是基于基尼指数的决策树的效果要略微好于基于信息熵的决策树。因此，本文选择建立模型的算法是基于基尼指数的决策树。</p></sec><sec id="s8"><title>5. 结语</title><p>本文使用基于线性回归分析的决策树模型应用在心脏疾病诊断。我们最后实现的方式是通过决策树算法，这是为了避免过拟合，也因为资料是关联式资料库的关系，经过特征筛选后，我们选择了决策树模型。此模型经过预剪枝后，稳定度提升，准确度与其他机器学习模型相比要稍微好一点。虽然最后的准确度仍然没有达到90%或者更高，但这些结果也可以说明机器学习在疾病诊断方面的可行性。</p><p>此外，本文所用的模型只有一个，要想进一步提高模型对策准确度，我们可以将它与另外的模型相结合(比如SPSS、朴素贝叶斯、BP神经网络等等)，应该会取得不错的效果。</p></sec><sec id="s9"><title>基金项目</title><p>昆明市卫生健康委员会卫生科研课题项目(2020-09-04-112)；云南省重点研发计划“基于智慧医疗平台的儿童疾病智能诊疗体系构建及应用示范”；中国博士后科学基金(2020M673312)；云南省博士后基金；云南大学“东陆中青年骨干教师”基金(C176220200)；云南省软件工程重点实验室开放基金资助项目(2020SE311)；云南省自然科学基金项目(202101AT070167)。</p></sec><sec id="s10"><title>文章引用</title><p>闵杰青,李昕洁,谭 强,赵 娜,李向娟,王 剑,曾敬勋,刘学承. 应用于心脏病诊断的线性回归决策树模型Decision Tree Model Based on Linear Regression for Heart Disease Diagnosis[J]. 计算机科学与应用, 2021, 11(08): 2108-2116. https://doi.org/10.12677/CSA.2021.118216</p></sec><sec id="s11"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.44659-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Cao, K. (2019) Artificial Intelligence on Diabetic Retinopathy Diagnosis: An Automatic Classification Method Based on Grey Level Co-Occurrence Matrix and Naive Bayesian Model. International Journal of Ophthalmology, 12, 1158-1162.</mixed-citation></ref><ref id="hanspub.44659-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">邓卓, 苏秉华, 张凯. 基于集成学习的乳腺癌分类研究[J]. 中国医疗设备, 2020, 35(12): 59-62.</mixed-citation></ref><ref id="hanspub.44659-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Yu, Y.X. (2019) The Application of Intelligent Medicine of Perceptron Algorithm in the Diagnosis of Spi-nal Disease. China New Telecommunications, 21, 229-231.</mixed-citation></ref><ref id="hanspub.44659-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">使用SPSS进行线性回归分析[EB/OL].  
&lt;br&gt;https://jingyan.baidu.com/article/b2c186c8055f49c46ef6ff0b.html, 2021-01-30.</mixed-citation></ref><ref id="hanspub.44659-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">R做线性回归[EB/OL]. &lt;br&gt;https://www.sohu.com/a/230584172_274950, 2021-01-30.</mixed-citation></ref><ref id="hanspub.44659-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">D-W检验[EB/OL]. &lt;br&gt;https://baike.baidu.com/item/D-W%E6%A3%80%E9%AA%8C/8030379?fr=aladdin, 2021-01-30.</mixed-citation></ref><ref id="hanspub.44659-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">方差[EB/OL]. &lt;br&gt;https://baike.baidu.com/item/%E6%96%B9%E5%B7%AE, 2021-01-30.</mixed-citation></ref><ref id="hanspub.44659-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">杜小芳, 陈毅红. Spark MLlib中决策树算法不同特征选择标准比较[J]. 太原师范学院学报(自然科学版), 2020, 19(4): 37-39+51.</mixed-citation></ref><ref id="hanspub.44659-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">张振, 田雪飞, 郜文辉, 何凤姣, 邓天好, 宋晓燕, 郑飘, 黄振. 基于决策树及贝叶斯网络建立原发性肝癌肝郁脾虚证诊断模型研究[J]. 中国中医药信息杂志, 2020, 27(9): 115-120.</mixed-citation></ref><ref id="hanspub.44659-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Ren Y.X., Wang, S.Y., Luo, Y.T. and Chen, S.Y. (2020) ID3 Algorithm-Based Research on College Students’ Mobile Game Preferences and Analysis of Cir-cumvention Paths. Academic Journal of Engineering and Technology Science, 3.</mixed-citation></ref><ref id="hanspub.44659-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Afrianto, E., Suseno, J.E. and Warsito, B. (2020) Decision Tree Method with C4.5 Algorithm for Students Classification Who Is Entitled to Receive Indonesian Smart Card (KIP). IOP Conference Series: Materials Science and Engineering, 879, Article ID: 012072.</mixed-citation></ref></ref-list></back></article>