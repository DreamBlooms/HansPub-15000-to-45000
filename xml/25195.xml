<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2018.85089</article-id><article-id pub-id-type="publisher-id">CSA-25195</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20180500000_68754076.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于融合的夜间去雾算法研究
  Research of Nighttime Image Dehazing by Fusion
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>吴</surname><given-names>钰芃</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib></contrib-group><aff id="aff1"><label>1</label><addr-line>null</addr-line></aff><aff id="aff2"><label>1</label><addr-line>合肥工业大学，安徽 合肥</addr-line></aff><author-notes><corresp id="cor1">* E-mail:</corresp></author-notes><pub-date pub-type="epub"><day>03</day><month>05</month><year>2018</year></pub-date><volume>08</volume><issue>05</issue><fpage>798</fpage><lpage>808</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   在雾、霾等天气条件下拍摄的户外图像，由于受到大气悬浮粒子的吸收和散射作用会产生对比度下降、颜色失真等退化现象。这些退化严重影响户外视觉系统的发挥。目前，针对光照不均匀场景(夜晚)的雾天图像复原研究较少。且夜晚雾天图像具有整体亮度低、光照不均匀、偏色和噪声大等特点，去雾难度大。本文从夜间雾天图像特点(光照不均匀、整体亮度低、细节模糊)出发，提出了基于融合的夜间雾天图像复原框架。针对光照不均匀和整体亮度低提出了新的亮度调整曲线，在保证提升亮度的同时避免曝光现象，生成光照图；针对细节模糊提出了在景深较浅的地方物体的颜色较为鲜艳，即饱和度较高，但是亮度较低。随着景深的增加，场景受雾的干扰导致亮度增加，但是饱和度变低。据此推导出新的传输图估计方法，生成细节增强图。在融合上述两张图片过程中使用三种权重图(亮度权重图、饱和度权重、显著度权重)，保证能够保留每幅图像上较好的部分，达到去雾的效果。 The outdoor images taken under the weather conditions such as fog and haze will result in degradation of contrast and color distortion. Due to the absorption and scattering of suspended particles, this degradation seriously affects the development of outdoor vision system. At present, there are few researches on image restoration for haze with uneven illumination. And the haze at night has the characteristics of low overall brightness, uneven illumination, color cast and noise. It’s difficult to dehaze. In this paper, a fusion based haze day image restoration framework is proposed based on the characteristics of haze day images (uneven illumination, low brightness, and blurred details). A new brightness adjustment curve is proposed for uneven illumination and low overall brightness. In order to ensure the enhancement of brightness and avoid exposure, the light map is generated. In detail, the light color of the object is relatively bright in the shallow depth of field; that is, the saturation is higher, but the brightness is low. With the increase of the depth of field, the fog in-creases, but the saturation decreases. Based on this, we derive a new transmission graph estimation method and generate detail maps. In the process of merging the above two images, three weights are used (the weight of the brightness, the weight of saturation, the weight of the saliency) to ensure that the better part of each image can be retained and the effect of fog removal can be achieved. 
 
</p></abstract><kwd-group><kwd>去雾，亮度调整图，细节图，权重图，图像融合, Dehazing</kwd><kwd> Brightness Adjustment Image</kwd><kwd> Detail Image</kwd><kwd> Weight Map</kwd><kwd> Image Fusion</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>基于融合的夜间去雾算法研究<sup> </sup></title><p>吴钰芃</p><p>合肥工业大学，安徽 合肥</p><p><img src="//html.hanspub.org/file/25-1541025x1_hanspub.png" /></p><p>收稿日期：2018年5月6日；录用日期：2018年5月23日；发布日期：2018年5月30日</p><disp-formula id="hanspub.25195-formula40"><graphic xlink:href="//html.hanspub.org/file/25-1541025x5_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>在雾、霾等天气条件下拍摄的户外图像，由于受到大气悬浮粒子的吸收和散射作用会产生对比度下降、颜色失真等退化现象。这些退化严重影响户外视觉系统的发挥。目前，针对光照不均匀场景(夜晚)的雾天图像复原研究较少。且夜晚雾天图像具有整体亮度低、光照不均匀、偏色和噪声大等特点，去雾难度大。本文从夜间雾天图像特点(光照不均匀、整体亮度低、细节模糊)出发，提出了基于融合的夜间雾天图像复原框架。针对光照不均匀和整体亮度低提出了新的亮度调整曲线，在保证提升亮度的同时避免曝光现象，生成光照图；针对细节模糊提出了在景深较浅的地方物体的颜色较为鲜艳，即饱和度较高，但是亮度较低。随着景深的增加，场景受雾的干扰导致亮度增加，但是饱和度变低。据此推导出新的传输图估计方法，生成细节增强图。在融合上述两张图片过程中使用三种权重图(亮度权重图、饱和度权重、显著度权重)，保证能够保留每幅图像上较好的部分，达到去雾的效果。</p><p>关键词 :去雾，亮度调整图，细节图，权重图，图像融合</p><disp-formula id="hanspub.25195-formula41"><graphic xlink:href="//html.hanspub.org/file/25-1541025x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2018 by author and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/25-1541025x7_hanspub.png" /> <img src="//html.hanspub.org/file/25-1541025x8_hanspub.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>计算机视觉系统有很多优点，可以直接、实时、全面检测观察对象，所以其应用越来越广泛。在一些恶劣天气条件下，室外的计算机视觉系统的作用会大打折扣。如在雾天条件下，计算机视觉系统受到大气中介质影响而导致成像细节降低。</p><p>近年来，一些研究者开始对夜间去雾进行研究。主要有以下成果。S. C. Pei等 [<xref ref-type="bibr" rid="hanspub.25195-ref1">1</xref>] 提出基于色彩转换和暗原色先验的算法。首先，利用色彩转换技术对输入图像进行预处理，将夜晚雾天图像的颜色特征转换成白天的清晰图像的颜色特征，然后，利用暗原色先验 [<xref ref-type="bibr" rid="hanspub.25195-ref2">2</xref>] 对转换后的图像进行复原。J. Zhang等 [<xref ref-type="bibr" rid="hanspub.25195-ref3">3</xref>] 提出一个新的夜间雾图退化模型，该模型首次考虑了夜间图像中的光照不均匀和颜色失真等问题。后利用Retinex [<xref ref-type="bibr" rid="hanspub.25195-ref4">4</xref>] 和暗原色先验等技术反解提出的模型得到去雾后的结果。Y. Li等 [<xref ref-type="bibr" rid="hanspub.25195-ref5">5</xref>] 关注夜间场景主动光源附近的光辉现象，认为光辉的产生的原因是场景中主动光源发出的光经过多次散射到达相机进行成像，并提出了一个新的夜间雾图退化模型，模型中添加大气点扩散函数来解释光辉的形成。复原时先，根据相对平滑约束的层次分离算法 [<xref ref-type="bibr" rid="hanspub.25195-ref6">6</xref>] 分离并去除光辉影响后利用暗原色去雾。Dubok Park等 [<xref ref-type="bibr" rid="hanspub.25195-ref7">7</xref>] 在针对夜间雾图多光源的问题上，提出了新的大气光估计和传输图估计方法，估计大气光时使用局部大气光和全局大气光选择策略，估计传输图根据清晰图像信息熵比雾天大的特征，构建目标函数通过是图像信息熵最大化求解该函数。</p><p>本文针对夜间雾天光照不均匀、细节模糊、颜色偏移等提出了基于融合的夜间雾天图像复原算法。针对颜色偏移问题，使用基于灰度世界理论的颜色恒常性来校正，针对光照不均匀，提新的光照调整方法，在提高图像中光照不足区域亮度的同时能防止亮区过曝。得到一张亮度合适但是细节模糊的图片(亮度图)。针对细节模糊问题，根据现有的夜间雾天图像退化模型，使用新的先验估计传输图得到一张细节清晰，亮度欠缺的图片(细节图)。之后提出不同的权重，融合到最终的去雾结果。</p></sec><sec id="s4"><title>2. 光学模型</title><p>文献 [<xref ref-type="bibr" rid="hanspub.25195-ref1">1</xref>] [<xref ref-type="bibr" rid="hanspub.25195-ref2">2</xref>] [<xref ref-type="bibr" rid="hanspub.25195-ref3">3</xref>] [<xref ref-type="bibr" rid="hanspub.25195-ref5">5</xref>] [<xref ref-type="bibr" rid="hanspub.25195-ref7">7</xref>] 提出的夜间雾图退化模型，是被广泛应用在计算机视觉领域，描述如下：</p><p>I i λ = L i R i λ t + A i λ ( 1 − t i ) (1)</p><p>i 和 λ 分别表示像素的位置和RGB通道。 L i 表示入射光强度， R i λ 为场景反射率， A i λ 为局部大气光， t = e − β d i 为传输图， β 表示大气衰减系数， d i 表场景与相机之间的距离。式(1)中第一项和第二项分别称为直接投射光和环境光。分描述目标与反射光的衰减过程和成像路径上周围杂散光的累积过程。在夜间条件下，由于光照不均匀，为消除不均匀光照的影响。假设在大气中介质分布是均匀的，改写式(1)的到式(2)</p><p>I ^ i λ = R i λ t i + A ^ λ ( 1 − t i ) (2)</p></sec><sec id="s5"><title>3. 去雾算法</title><sec id="s5_1"><title>3.1. 算法框架</title><p>图1给出了本文的算法流程图，流程主要包括三步骤：第一步：对图像进行光照和细节增强得到两个输入图像；第二步：分别计算两幅图像的权重图；第三步结合权重图和输入图像，得到最终的去雾结果。</p></sec><sec id="s5_2"><title>3.2. 输入图像生成</title><sec id="s5_2_1"><title>3.2.1. 亮度图生成</title><p>根据图(1)的流程对雾天图像进行白平衡预处理。夜晚图像整体亮度低，光照不均匀，针对这个问题。根据流程图生成的第一个输入是亮度较好的。已有的算法 [<xref ref-type="bibr" rid="hanspub.25195-ref3">3</xref>] 估计出光照图像Ｌ，之后使用伽马校正对光照图做统一处理。来消除光照不均匀的影响并提高亮度。统一的处理方式有时会造成较暗的地方亮度提升不明显，较亮的地方会造成曝光。</p><p>本文提出了新的光照调整函数，在提高光照不足区域的亮度的同时也要保证光照充足区域不过曝，公式(3)：</p><p>L ( x ) = x + s i g m a _ s ⋅ g ( x ) − s i g m a _ h ⋅ g ( 1 − x ) g ( x ) = x c 1 exp ( − c 2 x ) (3)</p><p>图1. 本文算法流程图</p><p>式中sigma_s的值越大调节曲线在光照不足区域越凸起，提高光照能力越强。同理sigma_h的值越大对光照充足区域抑制能力越强。 g ( x ) 和 g ( 1 − x ) 关于 x = 0.5 对称。</p></sec><sec id="s5_2_2"><title>3.2.2. 细节图生成</title><p>通过对夜间雾天图像进行分析，发现景深与图像饱和度和亮度之间关系。在景深较浅的地方物体的颜色较为鲜艳，即该处像素在某些颜色通道上值比较高，某些通道上比较低，即饱和度较高，但是亮度较低。随着景深的增加，场景受雾的干扰导致亮度增加，但是饱和度变低。根据上面的观察和上述给出的退化模型，估计出模型中变量。</p><p>I i λ = J i j t + A i λ ( 1 − t i ) ，在一个局部块 Ω ，根据上述观察，引入局部均值 M ( x , y ) 根据大气光散射模型用 V i ( x , y ) 代替 A i ( 1 − t ( x , y ) ) ，然后改写退化模型。</p><p>M I ( x , y ) = M J ( x , y ) t ( x ) + V ( x , y ) (4)</p><p>由式(4)可知 0 &lt; V ( x , y ) &lt; A ；<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/25-1541025x31_hanspub.png" xlink:type="simple"/></inline-formula>。大气散射光值随着场景深度的增加而增大。根据之前所描述的图像局部均值和饱和度的差也随着场景深度的增大而增大。所以使用图像局部均值和饱和度的差来估计大气散射光 V ( x , y ) ：</p><p>V ( x , y ) = max ( min ( ρ B ( x , y ) , M I ( x , y ) ) , 0 ) (5)</p><p>其中， B ( x , y ) = | M ( x , y ) − S ( x , y ) | 为图像局部亮度均值和饱和度的差值， ρ 为调整参数。 V ( x , y ) 的计算过程如下：</p><p>在以坐标 ( x , y ) 为中心的局部区域 Ω 内，先将该区域所有的点 ( x i , y j ) 转换成灰度值 K ( x i , y j ) ，之后选最小的作为局部均值(6)，之后对于该区域的所有点 ( x i , y j ) 计算局部区域的饱和度(7)</p><p>M &#175; ( x , y ) = min ( x , y ) ∈ Ω ( K ( x i , y j ) ) (6)</p><p>S ( x i , y j ) = max ( I l ( x i , y j ) ) − min ( I l ( x i , y j ) ) (7)</p><p>得到大气散射光之后，使用下式的到传输图。</p><p>t ( x , y ) = 1 − V ( x , y ) A Ω (8)</p><p>为了避免块效应，使用文献 [<xref ref-type="bibr" rid="hanspub.25195-ref8">8</xref>] ，的方法优化传输图。之后根据雾天图像退化模型，使用式(9)得到细节增强图像。</p><p>J ( x , y ) = I ( x , y ) − A Ω max ( t ( x , y ) , ε ) + A Ω (9)</p><p>图2为细节图生成的一些中间结果。</p></sec></sec><sec id="s5_3"><title>3.3. 权重图</title><p>在图像融合中，不同的融合算法中各个输入图像的权重计算方式对融合后的结果有很大的影响，所以图像融合中对权重的研究也是一个重要的研究方向。本文融合流程中使用权重图去计算每一个得到的输入图像，并确保在高对比度或者显著性的区域分配高的权重值。</p><p>亮度权重图，计算输入图像的每个像素点的可见度，并将较大值分配给具有良好可见度的区域，反之分配较小值。该权重图的计算过程根据RGB颜色空间信息。根据已知先验，在饱和高的区域有一个或</p><p>图2. 生成细节图中间结果</p><p>二个通道的值比较高。因此亮度权重图是从输入图像中计算每个像素点R，G，B三个通道与该点亮度L的差值。式(10)所示</p><p>W L k = 1 / 3 [ ( R k − L k ) 2 + ( G k − L k ) 2 + ( B k − L k ) 2 ] (10)</p><p>对于每个输入图像 I k ，其中k表示得到的第k个输入图像，L表示亮度值本文取RGB三通道的均值。亮度权重图中值较高的像素点我们假设他为最初的无雾像素点。另一方面，由于雾的存在造成的偏色和低对比度等问题所以在权重图中值较低(减少这些位置对输出图像的贡献)。对于得到的输入图像，光照权重图较黑的地方可以认为是有雾区域，光照权重图可以直观的将该区域标记出来。</p><p>亮度权重图的作用标记出多幅输入图像中无雾的区域，并使输入图像之间过度自然，但是会造成全局对比度降低和偏色问题。为了克服该问题，我们的融合框架中又设计了两种权重图饱和度权重(偏色问题)，显著权重图(全局对比度)。</p><p>饱和度权重图，为了控制输出图像饱和度的增加。该权重图的是根据一个事实，一般情况下人更喜欢饱和度高区域。因为颜色是图像质量的内在指标，所以使用颜色映射来增强颜色是常用的方法。</p><p>饱和度权重计算公式(11)，表示每个像素点，其饱和度S跟饱和度最大值之间的距离。</p><p>W C k = exp ( − ( S k ( x ) − S max k ) 2 2 σ 2 ) (11)</p><p>其中k表示第k个输入图像，标准差 σ = 0.3 ， S max 是一个常数，取决于所使用的颜色空间。本文选用的是HIS颜色空间，所以 S max = 1 。将较小的值分配给饱和度较低的像素点，而高饱和度的像素点值较大。该权重图能确保最终结果饱和度较好。</p><p>图像显著性是图像中重要的视觉特征，体现了人眼对图像的某些区域的重视程度。对于一幅图像来说，用户只对部分区域感兴趣，该区域称之为显著区域。显著区域的选择是非常主观的，由于个体任务和知识背景的不同，对于同一副图像，不同的用户可能会选择不同的区域作为显著区域。自从1998年Itti的工作以来，出现了很多量化图像显著性的方法，这些方法广泛应用于图像压缩、编码、图像边缘和区域加强、显著性目标分割和提取等。</p><p>显著权重图，本文使用的是Zhao J. Feng [<xref ref-type="bibr" rid="hanspub.25195-ref9">9</xref>] 等人提出的算法作为显著权重图的计算方法。根据心理学理论，人类视觉系统对图像中强度和色彩的变化敏感。利用HVS特性来设计反应输入图像在不同像素点区域视觉重要性的显著性权重。该显著性图通过不同像素带你之间的强度对比得到的。对于输入图像I中的像素点p位置的显著性值可以定义为式(12)</p><p>V ( p ) = ∑ ∀ q ∈ I G ( p , q ) (12)</p><p>显著性的值可以根据上式计算，类似颜色距离。用 I p 表示像素点p的强度值， G ( p , q ) 可以表达为相应像素点的差值：</p><p>G ( p , q ) = | I p − I q | (13)</p><p>根据式(13) V p 能按照式(14)的形式逐个像素点展开。</p><p>V ( p ) = | I p − I 1 | + | I p − I 2 | + ⋅ ⋅ ⋅ + | I p − I M | (14)</p><p>M为图像中像素点的个数，根据式(13)和式(14)，当像素点值相同时，它们的显著性值相同。以灰色图像为例，对于图像I中的强度 I p ，计算相对应的显著性值，式(15)。</p><p>V ( I p ) = ∑ j = 0 L − 1 N j G ( I p , j ) (15)</p><p>其中j代表强度， N j 表示图像中强度为j的像素点个数。L为灰度级，如果是8位的灰度图像，L的值为255。计算式(15)中所有的强度值，就能获得图像I原始显著图，之后对其进行归一化处理，使 V I ∈ ( 0 , 1 ) 。</p><p>通过实验，我们发现上述的三个权重对实验结果都有影响。但是第一种权重的影响最大，但是其效果还是没有使用三种权重的效果好。为了直观的表示这种影响，图3展示的是一次只用一种权重图所产生的结果。能够直观的看出使用三种权重图的情况下，融合效果比使用单一权重图效果好。图中，使用三种权重图时远处的吊桥能复原出来，而只使用显著度权重结果中没能复原出；在亮度上比仅使用饱和度权重的要好。在只使用一种权重的情况下，使用光照权重图的效果比其他两种要好，比如对小亭子的细节恢复。</p><p>最终的权重 W k 通过三种权重得到， W &#175; ( x ) = W k ( x ) / ∑ k W k ( x ) 这个操作我们成为归一化，其目的是在一个像素点x使其三种权重的值加在一起的值等于1。</p>融合<p>根据融合过程所处的不同阶级，图像融合可以在三个不同的层次上进行：像素级融合、特征级图像融合、决策级图像融合。本文输入像素级别图像融合在融合过程中，输入图像通过计算本文上述的权重图，以保存输入图像中最重要的特征，得到清晰的输出结果。对于输出图像F计算公式(16)</p><p>F ( x ) = ∑ W &#175; k ( x ) I k ( x ) (16)</p><p>其中 I k 为输入图像(k表示第k个)， W &#175; k 表示第k个归一化之后的权重图。</p><p>图3. 只用一种权重产生的结果</p></sec></sec><sec id="s6"><title>4. 实验结果与分析</title><p>本文使用的硬件平台处理器是Inter(R) Core(TM) i5-3210 2.5 GHz，内存大小8.00 GB，编程工具MATLAB 2014b.</p><sec id="s6_1"><title>4.1. 本文算法结果</title><p>本文实验证明本文算法的有效性，图片来源自网站Imgur和文献 [<xref ref-type="bibr" rid="hanspub.25195-ref3">3</xref>] 中收集的多幅图像。图4给出了实验结果，以及实验过程中的亮度图，细节图和三种权重图。</p></sec><sec id="s6_2"><title>4.2. 主观评价分析</title><p>为了验证本文算法的有效性，从图像分享网站Imgur上收集多幅图片进行试验，并选择五张图片进行比较。分别为：“Bridge”、“Street”、“Bus”、“Pavilion”和“Lane”对应图5的场景一到场景五。</p><p>本文试验结果与S. C. Pei [<xref ref-type="bibr" rid="hanspub.25195-ref2">2</xref>] 、J. Zhang [<xref ref-type="bibr" rid="hanspub.25195-ref3">3</xref>] 、Y. Li [<xref ref-type="bibr" rid="hanspub.25195-ref5">5</xref>] 和Zhao [<xref ref-type="bibr" rid="hanspub.25195-ref10">10</xref>] 的对比如图3所示。从结果中可以看出S. C. Pei的实验结果一定程度上提高了对比度，但是整体画面还是一种朦胧的感觉，且有严重的Halo现象在有光源的地方和场景的轮廓周围。因为该方法在进行颜色转换的时候是以一副白天清晰图像为标准进行转换的，目标图的选择会是否合适对复原的结果影响很大。J. Zhang的实验结果在整体亮度、对比度和细节方面有很大的提高，但是恢复的图像噪声很大，光源处也有严重的Halo现象。Y. Li [<xref ref-type="bibr" rid="hanspub.25195-ref5">5</xref>] 的实验结果在光源处及附件处复原效果不错，但是整体亮度低，掩盖了一些暗处的细节。Zhao [<xref ref-type="bibr" rid="hanspub.25195-ref10">10</xref>] 的实验结果在细节方面表现突出，但是也伴随着噪声放大的问题。本文的实验结果能做到亮度、对比度、细节的平衡同时噪声较小。特别是在远处的场景恢复的较好，比如“Pavilion”场景中亭子后面的树和吊桥都清晰的复原出来。场景一右侧路灯下的人也能清晰还原出来。因此，本文的算法能有效处理夜间雾图。</p><p>图4. 本文算法结果和中间过程</p><p>图5. 本文算法与其它算法的对比结果</p></sec><sec id="s6_3"><title>4.3. 客观评价分析</title><p>为了定量分析去雾结果的好坏，本文给出了集中评价指标的对比结果。图像的评价指标主要分为三种：全参考(FR)、半参考(RR)、无参考(NR)。由于自然条件下雾天图像没有对应的真实图像(Ground Truch)，因此这里使用的评价算法是无参考的质量评价算法。</p><p>1) NESS梯度结构相似度。ChunLing Yang等 [<xref ref-type="bibr" rid="hanspub.25195-ref11">11</xref>] 根据结构相似的思想结合人眼视觉系统的相关设计的。步骤如下：先为待评价图像制造参考图像。定义待评价图片I，参考图像使用 I r = L P F ( I ) ，即对待评价图像使用低通滤波得到参考图像。选择使用基于圆盘模型的均值滤波器和高斯模型的平滑滤波器都可以。为了更好的与成像系统匹配，建议使用 7 &#215; 7 高斯平滑滤波。但是在实际处理中使用同等大小的均值滤波器并不会使评价效果下降很大。之后提取带评价图像I和参考图像 I r 的梯度信息。利用人眼对水平方向和垂直方向的边缘最为敏感的特性，使用Sobel算子分别提取两幅图片的梯度图像 G 和 G r 。最后将图像<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/25-1541025x76_hanspub.png" xlink:type="simple"/></inline-formula>和 G r 划分成 8 &#215; 8 的小块，快间步长为4，即相邻重复率50%。计算每块的，方差越大表面梯度</p><p>信息越丰富，找出方差最大的N块，记为 { x i | i = 1 , 2 , 3 , ⋯ , N } ，对应的 G r 中的对应块记为 { y i | i = 1 , 2 , 3 , ⋯ , N } 。N的大小直接影响实验结果，同时也影响运行时间，本文使用64。之后使用式(17)计算NESS。</p><p>N R S S = 1 − 1 N ∑ i = 1 N S S I M ( x i , y i ) (17)</p><p>2) EAV点锐度。Ni. J等 [<xref ref-type="bibr" rid="hanspub.25195-ref12">12</xref>] 提出一种基于边缘锐度算法来评价图像清晰度。通过统计图像某一方向的灰度变化来评价。公式入下：</p><p>D ( f ) = ∑ a b ( d f / d x ) 2 | f ( b ) − f ( a ) | (18)</p><p>其中 d f / d x 为边缘法向的灰度变化率， f ( a ) − f ( b ) 为该方向的总体灰度变化。该算法只能对图像特定的边缘区域做统计，能否代表整幅图像的清晰度是有疑问的，而且计算前需要人工选定边缘区域，不便实现程序运行的自动化。Nan等对文献 [<xref ref-type="bibr" rid="hanspub.25195-ref12">12</xref>] 中对上述算法进行了改进。将针对边缘的梯度计算改为逐个像素域的梯度计算，以便能对整幅图像进行评价，前实现算法自动化。对像素的8个领域进行加权，根据人眼水平方向和垂直方向的边缘变化比较敏感。水平和垂直方向权重为1，其它4个方向权重为 1 / 2 。之后对计算的结果按照图像的大小进行标准化，以便于图像对比。改进后的公式(19)：</p><p>E A V = D ( f ) = ∑ x , y ∑ i = 1 8 | d f / d x | M &#215; N (19)</p><p>其中M和N为图像的行跟列。</p><p>3) 基于自然场景统计的无参考图像质量评价算法(NIQE)。A. Mittal等 [<xref ref-type="bibr" rid="hanspub.25195-ref13">13</xref>] 提出了基于自然场景统计的无参考图像质量评价算法，通过归一化的局部亮度系数提取多种可能反应图像质量的自然图像特征(文献 [<xref ref-type="bibr" rid="hanspub.25195-ref14">14</xref>] 中详细介绍了所提取的特征)，并使用多元高斯模型(MVG)来拟合这些特征。文章中指出未退化图像的归一化亮度系数是符合高斯分布的，而退化图像(不管退化类型)不满足这种分布。所以，对于输入的评价图像，其MVG模型越接近自然图像的MVG模型，其图像的质量越高。自然图像的MVG模型是通过统计图像库中大量的自然为退化图像得到的。公式如下所示：</p><p>D ( v 1 , v 2 , ∑ , ∑ ) = ( v 1 − v 2 ) T ( ∑ 1 + ∑ 2 2 ) − 1 ( v 1 − v 2 ) (20)</p><p>其中 v 1 ， v 2 和 ∑ 1 , ∑ 2 分别表示自然图和退化图像MVG模型中的均值向量和协方差矩阵。</p><p>表1给出了NESS算法的评价结果，表中的值代表评价图像梯度相似性的高低，值越高表示图像质量越好。因为在SSIM算法中两幅图像完全一样的情况下值为1。而NESS中带参考图像是评价图像通过低通滤波得到的，所以两幅图像的SSIM值越低说明评价图像的质量越好。对比发现本文的实验结果和Zhao的结果具有较高的清晰度。表2给出EVA算法的评价结果，表中的值表示图像的对比度高低。表3给出NIQE算法的评价结果，表中值代表评价图像和自然图像的MVG模型间的距离，所以值越小表示评价图像的质量越好，对比发现本文的算法一般具有较好的视觉质量。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Comparison with the NESS values of result</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" >Pei</th><th align="center" valign="middle" >Zhang</th><th align="center" valign="middle" >Li</th><th align="center" valign="middle" >Zhao</th><th align="center" valign="middle" >Our’s</th></tr></thead><tr><td align="center" valign="middle" >Bridge</td><td align="center" valign="middle" >0.7034</td><td align="center" valign="middle" >0.8234</td><td align="center" valign="middle" >0.8151</td><td align="center" valign="middle" >0.8255</td><td align="center" valign="middle" >0.8403</td></tr><tr><td align="center" valign="middle" >Street</td><td align="center" valign="middle" >0.6747</td><td align="center" valign="middle" >0.7345</td><td align="center" valign="middle" >0.7587</td><td align="center" valign="middle" >0.8084</td><td align="center" valign="middle" >0.8799</td></tr><tr><td align="center" valign="middle" >Bus</td><td align="center" valign="middle" >0.7448</td><td align="center" valign="middle" >0.7614</td><td align="center" valign="middle" >0.7953</td><td align="center" valign="middle" >0.8829</td><td align="center" valign="middle" >0.8593</td></tr><tr><td align="center" valign="middle" >Pavilion</td><td align="center" valign="middle" >0.6532</td><td align="center" valign="middle" >0.7807</td><td align="center" valign="middle" >0.8201</td><td align="center" valign="middle" >0.8917</td><td align="center" valign="middle" >0.8709</td></tr><tr><td align="center" valign="middle" >Lane</td><td align="center" valign="middle" >0.6712</td><td align="center" valign="middle" >0.7079</td><td align="center" valign="middle" >0.8382</td><td align="center" valign="middle" >0.8668</td><td align="center" valign="middle" >0.8812</td></tr></tbody></table></table-wrap><p>表1. 去雾结果的NESS值对比</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> Comparison with the EVA values of result</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" >Pei</th><th align="center" valign="middle" >Zhang</th><th align="center" valign="middle" >Li</th><th align="center" valign="middle" >Zhao</th><th align="center" valign="middle" >Our’s</th></tr></thead><tr><td align="center" valign="middle" >Bridge</td><td align="center" valign="middle" >72.95</td><td align="center" valign="middle" >81.34</td><td align="center" valign="middle" >82.29</td><td align="center" valign="middle" >82.55</td><td align="center" valign="middle" >84.03</td></tr><tr><td align="center" valign="middle" >Street</td><td align="center" valign="middle" >68.41</td><td align="center" valign="middle" >74.15</td><td align="center" valign="middle" >79.37</td><td align="center" valign="middle" >85.84</td><td align="center" valign="middle" >89.45</td></tr><tr><td align="center" valign="middle" >Bus</td><td align="center" valign="middle" >73.25</td><td align="center" valign="middle" >75.84</td><td align="center" valign="middle" >77.53</td><td align="center" valign="middle" >82.29</td><td align="center" valign="middle" >84.93</td></tr><tr><td align="center" valign="middle" >Pavilion</td><td align="center" valign="middle" >67.37</td><td align="center" valign="middle" >79.13</td><td align="center" valign="middle" >81.31</td><td align="center" valign="middle" >89.17</td><td align="center" valign="middle" >87.09</td></tr><tr><td align="center" valign="middle" >Lane</td><td align="center" valign="middle" >66.59</td><td align="center" valign="middle" >74.29</td><td align="center" valign="middle" >83.82</td><td align="center" valign="middle" >80.18</td><td align="center" valign="middle" >86.12</td></tr></tbody></table></table-wrap><p>表2. 去雾结果的EVA值对比</p><table-wrap id="table3" ><label><xref ref-type="table" rid="table3">Table 3</xref></label><caption><title> Comparison with the NIQE values of result</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" >Pei</th><th align="center" valign="middle" >Zhang</th><th align="center" valign="middle" >Li</th><th align="center" valign="middle" >Zhao</th><th align="center" valign="middle" >Our’s</th></tr></thead><tr><td align="center" valign="middle" >Bridge</td><td align="center" valign="middle" >4.7862</td><td align="center" valign="middle" >4.5234</td><td align="center" valign="middle" >4.2151</td><td align="center" valign="middle" >3.9525</td><td align="center" valign="middle" >3.9403</td></tr><tr><td align="center" valign="middle" >Street</td><td align="center" valign="middle" >5.7475</td><td align="center" valign="middle" >5.1345</td><td align="center" valign="middle" >5.0587</td><td align="center" valign="middle" >4.8084</td><td align="center" valign="middle" >4.5799</td></tr><tr><td align="center" valign="middle" >Bus</td><td align="center" valign="middle" >4.2491</td><td align="center" valign="middle" >3.7614</td><td align="center" valign="middle" >3.7953</td><td align="center" valign="middle" >3.1829</td><td align="center" valign="middle" >3.0532</td></tr><tr><td align="center" valign="middle" >Pavilion</td><td align="center" valign="middle" >3.6532</td><td align="center" valign="middle" >3.0817</td><td align="center" valign="middle" >2.8201</td><td align="center" valign="middle" >2.8917</td><td align="center" valign="middle" >2.9709</td></tr><tr><td align="center" valign="middle" >Lane</td><td align="center" valign="middle" >4.6712</td><td align="center" valign="middle" >4.2794</td><td align="center" valign="middle" >3.8582</td><td align="center" valign="middle" >3.4668</td><td align="center" valign="middle" >3.0812</td></tr></tbody></table></table-wrap><p>表3. 去雾结果的NIQE值对比</p></sec></sec><sec id="s7"><title>5. 总结</title><p>本文针对夜间雾天图像复原，从夜间雾天图像的图像特点出发提出了基于融合的夜间雾天图像复原框架。本文算法和已有的算法的不同体现在以下几点：第一，根据夜间图像亮度不均匀问题，改进已有的光照调整方法，在增强暗处的同时保证亮处不曝光：第二提出了新的传输图估计方法：第三，提出根据图像本身得到融合所需要权重图，使融合结果更加自然。在实验分析部分，从主观和客观两个方面说明了本文去雾算法的有效性。</p><p>但是，通过实验发现本文算法在生成亮度图时使用的参数是根据经验设计的，没有考虑到图像本身，参数没有鲁棒性。另外在光源处的处理效果不是很理想。会有一定的Halo现象。原因是夜间图像在光源处和暗处的属性差别非常大，本文使用的传输图估计方法可能会失效。我们将在以后的研究中针对这些问题进行。</p></sec><sec id="s8"><title>文章引用</title><p>吴钰芃. 基于融合的夜间去雾算法研究 Research of Nighttime Image Dehazing by Fusion[J]. 计算机科学与应用, 2018, 08(05): 798-808. https://doi.org/10.12677/CSA.2018.85089</p></sec><sec id="s9"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.25195-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Pei, S.C. and Lee, T.Y. (2012) Nighttime Haze Removal Using Color Transfer Pre-Processing and Dark Channel Prior. Proceedings of the IEEE International Conference on Image Processing, Orlando, 30 September-3 October 2012, 957-960.</mixed-citation></ref><ref id="hanspub.25195-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">He, K., Sun, J. and Tang, X. (2011) Single Image Haze Removal Using Dark Channel Prior. IEEE Transactions on Pattern Analysis and Machine Intelli-gence, 33, 2341-2353. &lt;br&gt;https://doi.org/10.1109/TPAMI.2010.168</mixed-citation></ref><ref id="hanspub.25195-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Zhang, J., Cao, Y. and Wang, Z. (2014) Nighttime Haze Removal Based on a New Imaging Model. Proceedings of the IEEE International Conference on Image Processing, Paris, 15-19 June 2014, 4557-4561.</mixed-citation></ref><ref id="hanspub.25195-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Land, E.H. and McCann, J.J. (1971) Lightness and Retinex Theory. Journal of the Optical Society of America, 61, 1-11. &lt;br&gt;https://doi.org/10.1364/JOSA.61.000001</mixed-citation></ref><ref id="hanspub.25195-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Li, Y., Tan, R.T. and Brown, M.S. (2015) Nighttime Haze Removal with Glow and Multiple Light Colors. Proceedings of the IEEE International Conference on Computer Vision, Santiago, 11-18 De-cember 2015, 226-234.</mixed-citation></ref><ref id="hanspub.25195-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Li, Y. and Brown, M. (2014) Single Image Layer Separation Using Relative Smoothness. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Columbus, 23-28 June 2014, 2752-2759.</mixed-citation></ref><ref id="hanspub.25195-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Park, D., Han, D.K. and Ko, H. (2016) Nighttime Image Dehazing with Local Atmospheric Light and Weighted Entropy. IEEE International Conference on Image Processing, 25-28 September 2016, 2261-2265.</mixed-citation></ref><ref id="hanspub.25195-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">He, K., Sun, J. and Tang, X. (2013) Guided Image Filtering. IEEE Transactions on Pattern Analysis &amp; Machine Intelligence, 35, 1397-1409. &lt;br&gt;https://doi.org/10.1109/TPAMI.2012.213</mixed-citation></ref><ref id="hanspub.25195-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Zhao, J., Feng, H., Xu, Z., et al. (2013) Detail Enhanced Multi-Source Fusion Using Visual Weight Map Extraction Based on Multi Scale Edge Preserving Decomposition. Optics Communications, 287, 45-52.</mixed-citation></ref><ref id="hanspub.25195-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">方帅, 赵育坤, 李心科, 等. 基于光照估计的夜间图像去雾[J]. 电子学报, 2016, 44(11): 2569-2575.</mixed-citation></ref><ref id="hanspub.25195-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Chen, G.H., Yang, C.L. and Xie, S.L. (2007) Gradient-Base Structural Similarity for Image Quality Assessment. IEEE International Conference on Image Processing, 2, 2.</mixed-citation></ref><ref id="hanspub.25195-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Ni, J. (2009) Image Sharpness Function Based on Edge Feature. Proceedings of SPIE, The International Society for Optical Engineering, 7513, 75131A-75131A-6.</mixed-citation></ref><ref id="hanspub.25195-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Mittal, A., Soundararajan, R. and Bovik, A.C. (2013) Making a Completely Blind Image Quality Analyzer. IEEE on Signal Processing Letters, 22, 209-212. &lt;br&gt;https://doi.org/10.1109/LSP.2012.2227726</mixed-citation></ref><ref id="hanspub.25195-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">Mittal, A., Moorthy, A.K. and Bovik, A.C. (2012) No-Reference Image Quality Assessment in the Spatial Domain. IEEE Transactions on Image Processing, 21, No. 12. &lt;br&gt;https://doi.org/10.1109/TIP.2012.2214050</mixed-citation></ref></ref-list></back></article>