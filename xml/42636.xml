<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">PM</journal-id><journal-title-group><journal-title>Pure  Mathematics</journal-title></journal-title-group><issn pub-type="epub">2160-7583</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/PM.2021.115104</article-id><article-id pub-id-type="publisher-id">PM-42636</article-id><article-categories><subj-group subj-group-type="heading"><subject>PM20210500000_93970260.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>数学与物理</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于多尺度残差网络与正则化约束的MR图像超分辨算法
  MR Image Super-Resolution Using Multi-Scale Residual Networks with Regularization Norm
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>蔡</surname><given-names>言</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib></contrib-group><aff id="aff1"><label>1</label><addr-line>null</addr-line></aff><aff id="aff2"><label>1</label><addr-line>上海大学理学院数学系，上海</addr-line></aff><pub-date pub-type="epub"><day>11</day><month>05</month><year>2021</year></pub-date><volume>11</volume><issue>05</issue><fpage>909</fpage><lpage>921</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
  
    核磁共振高分辨率的图像可以提供更加丰富的病理信息，起到辅助诊断的作用，超分辨重建是利用低分辨率图像通过算法重建出高分辨率图像的技术。本文研究了针对核磁共振图像的超分辨图像重建算法，该算法在超分辨卷积神经网络的基础上，在损失函数中添加全变分正则化项来降低生成图像的噪声，网络结构中增加多尺度残差模块，在后续网络层结构中补充更多图像的高频特征。通过在临床核磁共振数据集上实验，该算法相对于先前的网络在峰值信噪比和结构相似性两个指标上有显著提升。
    High-resolution images of MRI can provide richer pathological information to assist in diagnosis. Super-resolution reconstruction is a technique of using low-resolution images to reconstruct high-resolution images by algorithm. In this paper, the super-resolution image reconstruction al-gorithm for MRI images is studied, which is based on the super-resolution convolutional neural network and adds the total variation regularization to the loss function for smoothing processing. The multi-scale residual module is added to the network structure to supplement more high fre-quency characteristics of images in the subsequent network layer structure. By experimenting with clinical MR data sets, the algorithm improved significantly in peak signal-to-noise ratio and structural similarity compared to previous networks. 
  
 
</p></abstract><kwd-group><kwd>超分辨重建，卷积神经网络，多尺度残差，正则化, Super-Resolution Reconstruction</kwd><kwd> Convolutional Neural Network</kwd><kwd> Multi-Scale Residual Module</kwd><kwd> Regularization</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>摘要</title><p>核磁共振高分辨率的图像可以提供更加丰富的病理信息，起到辅助诊断的作用，超分辨重建是利用低分辨率图像通过算法重建出高分辨率图像的技术。本文研究了针对核磁共振图像的超分辨图像重建算法，该算法在超分辨卷积神经网络的基础上，在损失函数中添加全变分正则化项来降低生成图像的噪声，网络结构中增加多尺度残差模块，在后续网络层结构中补充更多图像的高频特征。通过在临床核磁共振数据集上实验，该算法相对于先前的网络在峰值信噪比和结构相似性两个指标上有显著提升。</p></sec><sec id="s2"><title>关键词</title><p>超分辨重建，卷积神经网络，多尺度残差，正则化</p></sec><sec id="s3"><title>MR Image Super-Resolution Using Multi-Scale Residual Networks with Regularization Norm<sup> </sup></title><p>Yan Cai</p><p>Department of Mathematics, School of Science, Shanghai University, Shanghai</p><p><img src="//html.hanspub.org/file/20-1251301x4_hanspub.png" /></p><p>Received: Apr. 17<sup>th</sup>, 2021; accepted: May 19<sup>th</sup>, 2021; published: May 26<sup>th</sup>, 2021</p><p><img src="//html.hanspub.org/file/20-1251301x5_hanspub.png" /></p></sec><sec id="s4"><title>ABSTRACT</title><p>High-resolution images of MRI can provide richer pathological information to assist in diagnosis. Super-resolution reconstruction is a technique of using low-resolution images to reconstruct high-resolution images by algorithm. In this paper, the super-resolution image reconstruction algorithm for MRI images is studied, which is based on the super-resolution convolutional neural network and adds the total variation regularization to the loss function for smoothing processing. The multi-scale residual module is added to the network structure to supplement more high frequency characteristics of images in the subsequent network layer structure. By experimenting with clinical MR data sets, the algorithm improved significantly in peak signal-to-noise ratio and structural similarity compared to previous networks.</p><p>Keywords:Super-Resolution Reconstruction, Convolutional Neural Network, Multi-Scale Residual Module, Regularization</p><disp-formula id="hanspub.42636-formula20"><graphic xlink:href="//html.hanspub.org/file/20-1251301x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2021 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/20-1251301x7_hanspub.png" /> <img src="//html.hanspub.org/file/20-1251301x8_hanspub.png" /></p></sec><sec id="s5"><title>1. 引言</title><p>磁共振成像(MRI)是临床实践中广泛使用的医学成像工具，通常用于一些疾病的诊断和治疗。空间分辨率是MR最重要的成像参数之一，清晰的磁共振成像图像可以提供丰富的结构细节信息，便于早期准确的诊断。但MR图像的分辨率受多种环境因素限制，想要更高的空间分辨率往往需要依靠减少SNR或者增加扫描时间的方式来实现 [<xref ref-type="bibr" rid="hanspub.42636-ref1">1</xref>]，由于诊所的成像系统、成像环境和人为因素不同，导致低分辨率和高噪声的磁共振图像的产生无法避免。</p><p>因此我们对图像进行超分辨率重建技术的研究，来提高医疗核磁共振图像的分辨率和质量。经典超分辨率算法可以分为三类：基于插值的方法 [<xref ref-type="bibr" rid="hanspub.42636-ref2">2</xref>]，基于重建的方法 [<xref ref-type="bibr" rid="hanspub.42636-ref3">3</xref>]，以及基于学习的方法 [<xref ref-type="bibr" rid="hanspub.42636-ref4">4</xref>]。</p><p>基于插值的方法主要包括线性插值与非线性插值，如最近邻插值(NN)，双线性插值(双线性)和双立方插值(双立方)。将插值像素插入到原始图像中，然后得到相应的放大图像。这种算法复杂度较低，但由于效果一般，所以适用性并不广泛。</p><p>基于重建的方法是利用信号和系统来解决成像问题的逆向过程，其中主要处理高频率信息，缺点是计算复杂性非常高。虽然这些传统的超分辨方法可以在一定程度上重建高分辨率图像，仍然存在一些问题需要进一步进行研究，如光滑边缘和纹理细节。</p><p>近年来，随着机器学习特别是深度学习的发展，在超分辨重建问题上体现出极大的价值。基于学习的理念，这种方法学习了低分辨率图像与高分辨率图像之间的映射关系，用来重建高分辨率图像。</p><p>深度学习已在超分辨领域获得显著的效果，从最初仅包含三个卷积层的超分辨率重建卷积神经网络(SRCNN) [<xref ref-type="bibr" rid="hanspub.42636-ref5">5</xref>]，其速度上有极大提升的加速图像超分辨率卷积神经网络(FSRCNN) [<xref ref-type="bibr" rid="hanspub.42636-ref6">6</xref>]。何凯明在2015年提出的深度残差神经网络(ResNet) [<xref ref-type="bibr" rid="hanspub.42636-ref7">7</xref>] 解决了之前网络结构比较深时无法训练的问题，性能也得到了提升，残差网络结构(residual network)被应用在了大量的工作中，超分辨领域提出了对应的深度残差超分辨率重建网络(SRResNet) [<xref ref-type="bibr" rid="hanspub.42636-ref8">8</xref>]。作为其衍生的深度全局残差学习网络(VDSR) [<xref ref-type="bibr" rid="hanspub.42636-ref9">9</xref>]，运用学习残差的结构，对结果进一步提升。</p><p>图像超级分辨深度递归卷积网络(DRCN) [<xref ref-type="bibr" rid="hanspub.42636-ref10">10</xref>] 第一次将之前已有的递归神经网络结构应用在超分辨率处理中，同时利用残差学习的思想，加深了网络结构(16个递归)，增强网络的感受野，从而达到提升性能的效果。深度递归残差图像超分辨网络(DRRN) [<xref ref-type="bibr" rid="hanspub.42636-ref11">11</xref>] 受到ResNet、VDSR和DRCN的启发，采用递归结构使得网络模块的参数共享，并且采用了更深的网络结构来获取性能的提升。密集卷积网络(DenseNet) [<xref ref-type="bibr" rid="hanspub.42636-ref12">12</xref>] 是CVPR2017的最佳获奖论文，DenseNet在密集模块(dense block)中将每一层的特征都输入给之后的所有层，使所有层的特征都串联起来，而不是像ResNet那样直接短路径添加，这样的结构给整个网络带来了减轻梯度消失问题、加强特征传播、支持特征复用、减少参数数量的优点。作为其衍生，超分辨领域提出了相应的密集卷积图像超分辨网络(SRDenseNet) [<xref ref-type="bibr" rid="hanspub.42636-ref13">13</xref>]，以及将残差模块(Residual block)和密集模块(Dense Block)相结合的残差密集深度网络(RDN) [<xref ref-type="bibr" rid="hanspub.42636-ref14">14</xref>]，还有引入了注意力机制的残差通道注意力网络(RCAN) [<xref ref-type="bibr" rid="hanspub.42636-ref15">15</xref>]。</p><p>一般的超分辨网络中鲜少运用到模型先验信息，超分辨网络也很少运用到多尺度信息。本文提出的算法有以下三点贡献：1) 在损失函数中添加全变分正则化项来降低生成图像的噪声；2) 网络结构中添加多尺度残差模块，在后续网络层结构中补充更多图像的高频特征；3) 本算法的结构相对于先前的网络在性能上有显著提升。</p></sec><sec id="s6"><title>2. 模型的建立</title><sec id="s6_1"><title>2.1. 图像超分辨重建网络框架</title><p>网络框架见图1整体网络框架，和传统的超分辨网络基础框架类似，它具有三个主要组成部分，分别为特征提取、非线性映射和图像重建。特征提取部分将输入的低分辨图像x提取出浅层特征，这些浅层特征接着传输进非线性映射部分，非线性映射部分由一系列模块构成，最后将收集到的层次特征输入图像重建部分，来生成整个模型的高分辨图像y。</p><p>图1. 整体网络框架</p><sec id="s6_1_1"><title>2.1.1. 特征提取</title><p>如图1所示，用x和y分别代变网络的输入和输出图像，使用两层卷积网络来提取浅层的特征，第一层卷积网络从输入的x提取出特征 F 1 。</p><p>这里采用参数化纠正线性单元PReLU作为每个卷积层后的激活函数，来代替常用的修正线性单元ReLU [<xref ref-type="bibr" rid="hanspub.42636-ref6">6</xref>] [<xref ref-type="bibr" rid="hanspub.42636-ref16">16</xref>] 激活函数，PReLU引入了一个可学习的参数，可以避免ReLU中零梯度造成后续特征不可被激活的情况。PRELU被定义为：</p><p>σ ( x i ) = max ( x i , 0 ) + a i min ( x i , 0 ) (1)</p><p>其中 x i 是第 i 层卷积层的输入，而 a i 是负部分的系数，当 a i = 0 时PReLU就退化为ReLU。</p><p>F 1 = σ ( H 1 ( x ) ) (2)</p><p>其中 H 1 ( ⋅ ) 表示特征提取部分中的第一层卷积操作，第一个卷积层有128个滤波器，使用 3 &#215; 3 的卷积核，步长为1，生成的特征图通道数为128， σ ( ⋅ ) 表示PReLU激活函数。</p><p>将输出的浅层特征 F 1 输入进第二层卷积层</p><p>F 2 = σ ( H 2 ( F 1 ) ) (3)</p><p>其中 H 2 ( ⋅ ) 表示特征提取部分中的第二层卷积操作，第二个卷积层有128个滤波器，使用 3 &#215; 3 的卷积核，步长为1，生成的特征图通道数为128， σ ( ⋅ ) 表示PReLU激活函数，其输出的特征为 F 2 。</p></sec><sec id="s6_1_2"><title>2.1.2. 非线性映射</title><p>非线性映射层是超分辨重建中的关键步骤，其映射的高维矢量代表了相应的高分辨率部分 [<xref ref-type="bibr" rid="hanspub.42636-ref6">6</xref>]。由多个组合的多尺度残差模块堆叠而成，来实施非线性映射。将 F 2 输入进第一个模块，同时引入局部残差学习的方法将 F 2 通过短连接的方式加到每一个模块后，从而改善信息流，提高网络表现能力，以此产生更好的性能。</p><p>F B 1 = H B 1 ( F 2 ) + F 2 (4)</p><p>其中 H B 1 ( ⋅ ) 代表第一个多尺度残差模块的复合函数操作，包括了一系列卷积和激活函数，输出的特征 F B 1 继续输入进后面的模块</p><p>F B n = H B n ( F B n − 1 ) + F 2 (5)</p><p>F B N = H B N ( F B N − 1 ) + F 2 = H B N ( H B N − 1 ( ⋯ ( H B 1 ( F 2 ) + F 2 ) ⋯ ) + F 2 ) + F 2 (6)</p><p>其中 n = ( 1 , ⋯ , N ) ， H B n ( ⋅ ) 表示第 n 个模块的复合函数操作， F B n − 1 和 F B n 分别表示第 n 个模块的输入和输出，当 n 取到 N 时，得到整个线性映射部分的输出 F B N 。</p></sec><sec id="s6_1_3"><title>2.1.3. 图像重建</title><p>在提取完局部与全局特征后，将 F B N 输入 3 &#215; 3 的卷积层进行图像重建，生成的特征图通道数设为1，步长设为1，使用PReLU作为激活函数，其输出为图像 F R</p><p>F R = σ ( H R ( F N ) ) (7)</p><p>其中 H R ( ⋅ ) 表示卷积操作， σ ( ⋅ ) 表示PReLU激活函数，其输出为图像 F R ，接着利用全局残差学习来获得特征图，整体网络的输入图像 x 通过残差学习短连接的方式对图像 F R 进行补充，输出高分辨图像 y</p><p>y = F R + x (8)</p></sec></sec><sec id="s6_2"><title>2.2. 多尺度残差模块</title><p>图2展示了非线性映射部分的多尺度残差模块的细节，普通的残差网络是将每个残差单元短连接来构建深度比较大的网络。在本模块中将输入图像进行多尺度的卷积操作后，利用残差方式短连接到输入图像，可以补充更多丰富的高频信息，来有效地进行局部残差学习。此外，这种多尺度短连接可以携带更多的高频信息进入到更深的网络。</p><p>图2. 多尺度残差模块结构图</p><p>模块的输入为 F B n − 1 ，将其进行两层 3 &#215; 3 卷积与PReLU激活</p><p>F B n − 1 , 1 = σ ( H B n − 1 , 1 ( F B n − 1 ) ) (9)</p><p>F B n − 1 , 2 = σ ( H B n − 1 , 2 ( F B n − 1 , 1 ) ) (10)</p><p>其中 H B n − 1 , 1 ( ⋅ ) 和 H B n − 1 , 2 ( ⋅ ) 表示卷积操作，卷积层滤波器个数均为128， σ ( ⋅ ) 表示PReLU激活函数。</p><p>使用 7 &#215; 7 的卷积核提取 F B n − 1 高频的图像信息用短连接的形式添加在 F B n − 1 , 1 上</p><p>F B n − 1 , α 1 = H B n − 1 , α 1 ( F B n − 1 ) (11)</p><p>F B n − 1 , M = F B n − 1 , 1 + F B n − 1 , α 1 (12)</p><p>其中 H B n − 1 , α 1 ( ⋅ ) 表示 7 &#215; 7 卷积操作，卷积层滤波器个数为128。</p><p>接着将 F B n − 1 , M 作为输入，继续进行两层 3 &#215; 3 卷积与PReLU激活</p><p>F B n − 1 , 3 = σ ( H B n − 1 , 3 ( F B n − 1 , M ) ) (13)</p><p>F B n − 1 , 4 = σ ( H B n − 1 , 4 ( F B n − 1 , 3 ) ) (14)</p><p>其中 H B n − 1 , 3 ( ⋅ ) 和 H B n − 1 , 4 ( ⋅ ) 表示卷积操作，卷积层滤波器个数均为128， σ ( ⋅ ) 表示PReLU激活函数。</p><p>使用 5 &#215; 5 的卷积核提取 F B n − 1 高频的图像信息用短连接的形式添加在 F B n − 1 , 4 上</p><p>F B n − 1 , α 2 = H B n − 1 , α 2 ( F B n − 1 ) (15)</p><p>F B n = F B n − 1 , 4 + F B n − 1 , α 2 (16)</p><p>其中 H B n − 1 , α 2 ( ⋅ ) 表示 5 &#215; 5 卷积操作，卷积层滤波器个数为128。</p></sec><sec id="s6_3"><title>2.3. 损失函数</title><p>在超分辨重建中，损失函数用于测量生成的高分辨SR图像与真实的高分辨HR图像之间的差异，并指导模型进行优化，正则化可以防止模型在训练中出现过拟合。</p><p>像素损失用来测量两个图像像素之间的差异，通常采用L1正则化和L2正则化。为了简化表示，将 I ^ 代表模型生成的高分辨SR图像，I代表原始作为目标的高分辨HR图像，这里采用L2正则化，即最小平方误差</p><p>L p i x e l _ l 2 ( I ^ , I ) = 1 h w c ∑ i , j , k ‖ I ^ i , j , k − I i , j , k ‖ 2 (17)</p><p>其中 h 、 w 、 c 分别是图像的长、宽和通道数。</p><p>为了抑制生成图像的噪声，我们将全变分正则化 [<xref ref-type="bibr" rid="hanspub.42636-ref16">16</xref>] 引入此超分辨重建算法中，它能去除图像噪声，有效地保留图像边缘信息，有助于优化重建后的图像。它被定义为相邻像素之间绝对差异的总和，并测量图像中的噪声量，对于模型生成的高分辨SR图像 I ^ ，全变分正则化函数定义为</p><p>L t v ( I ^ ) = 1 h w c ∑ i , j , k ( I ^ i , j + 1 , k − I ^ i , j , k ) 2 − ( I ^ i + 1 , j , k − I ^ i , j , k ) 2 (18)</p><p>模型的损失函数结合了L2正则化与全变分正则化</p><p>L = L p i x e l _ l 2 ( I ^ , I ) + φ L t v ( I ^ ) (19)</p><p>其中 φ 为参数。</p></sec></sec><sec id="s7"><title>3. 实验与结果</title><sec id="s7_1"><title>3.1. 数据集</title><p>为了评估本文所提出的图像超分辨重建网络算法的性能，使用三个真实的核磁共振(MR)图像数据库。第一个真实的核磁共振图像数据集是从iSeg-2017对于6个月的婴儿大脑核磁共振图像的分割任务中获得的(http://iseg2017.web.unc.edu/)。第二个真实的核磁共振图像数据集是从大脑分割测试网站下载的ALVIN数据集 [<xref ref-type="bibr" rid="hanspub.42636-ref17">17</xref>] (https://sites.google.com/site/brainseg/)。第三个临床数据集来自2015脑肿瘤图像分割基准BRATS数据集 [<xref ref-type="bibr" rid="hanspub.42636-ref18">18</xref>] (https://www.smir.ch/BRATS/Start2015)。所有数据集均采用轴向平面中常用的T1维度的核磁共振图像。</p></sec><sec id="s7_2"><title>3.2. 实验评价指标</title><p>在实验中，使用以下两个个指标来评估图像重建算法：1) 峰值信噪比(PSNR) [<xref ref-type="bibr" rid="hanspub.42636-ref19">19</xref>] 2) 结构相似性(SSIM) [<xref ref-type="bibr" rid="hanspub.42636-ref20">20</xref>]：</p><p>P S N R = 10 log 10 ( ( 2 n − 1 ) 2 M S E ) (20)</p><p>M S E = 1 H &#215; W ∑ i = 1 H ∑ j = 2 W ( X ( i , j ) − Y ( i , j ) ) 2 (21)</p><p>其中MSE表示当前图像X和参考图像Y的均方误差，n是每个像素的位数，如果每个像素都由8位二进制来表示，那么灰度图像的最大像素值为255。 X ( i , j ) 和 Y ( i , j ) 分别代表当前图像与参考图像的像素值，H和W代表图像的长和宽。PSNR是图像评价的客观标准，PSNR数值越高，图像的失真就越小。</p><p>S S I M ( X , Y ) = l ( X , Y ) ⋅ c ( X , Y ) ⋅ s ( X , Y ) (22)</p><p>其中 l ( X , Y ) 、 c ( X , Y ) 和 s ( X , Y ) 代表亮度、对比度和图像相似性，SSIM数值越高，代表生成图像与参考图像的相似度越高。</p></sec><sec id="s7_3"><title>3.3. 实验结果</title><p>将原核磁共振图像进行双三次插值Bicubic [<xref ref-type="bibr" rid="hanspub.42636-ref21">21</xref>] 再下采样，得到与原高分辨HR图像大小相同的低分辨率LR图像作为算法的输入，并将其切片成31 &#215; 31大小的图像，用于超分辨算法的训练，上述超分辨对比算法均在python2.7的pytorch框架上进行运算，实验的操作系统为Ubuntu16.04，CPU为Intel(R)E5-2620@2.1 GHz，GPU配置为TITAN X。本文提出的算法损失函数中的参数 φ 取值为0.1，多尺度残差模块的个数取为4，则网络深度为19。使用Adam算法来优化模型，迭代地更新神经网络的权重，其中权重衰减(weightdecay)设为0.0001，动量(momentum)设为0.9，一次训练所选取的样本数(BatchSize)为64。训练时每30个时期(epoch)进行学习率衰减，从初始值 10 − 3 降低至 10 − 5 。</p><p>为了验证我们的方法对大脑核磁共振图像数据集的影响，将此方法与其他超分辨图像重建方法进行比较，包括了超分辨率卷积神经网络(SRCNN)、加速图像超分辨率卷积神经网络(FSRCNN)、残差通道注意力网络(RCAN)、残差密集深度网络(RDN)、深度全局残差学习网络(VDSR)、深度递归残差图像超分辨网络(DRRN)。为了保持对照实验的公平性，将网络深度较大的RCAN、RDN与DRRN中各自的模块个数减小，使其网络深度与本算法类似进行对比实验。</p><sec id="s7_3_1"><title>3.3.1. iSeg-2017数据集</title><p>我们在iSeg-2017数据集上进行实验，此数据集为临床六个月的婴儿大脑核磁共振图像。我们随机地抽取15个T1维度的核磁共振3D图像，图像大小为 144 &#215; 192 &#215; 256 ，在每一个3D核磁共振图像中选取第131张到160张，也就是30张轴向平面图像用作训练。</p><p>图3展示了由不同的超分辨算法在婴儿大脑图像iSeg-2017数据集上生成的结果，本文提供的算法提供了更丰富的细节和显著的边缘，表1展示本算法获得了最佳峰值信噪比(PSNR) 36.92 dB和最佳结构相似度(SSIM) 0.9262。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Results of different algorithms on the iSeg-2017 T1 MR Image databas</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" >PSNR (dB)</th><th align="center" valign="middle" >SSIM</th></tr></thead><tr><td align="center" valign="middle" >SRCNN</td><td align="center" valign="middle" >34.78</td><td align="center" valign="middle" >0.8649</td></tr><tr><td align="center" valign="middle" >FSRCNN</td><td align="center" valign="middle" >35.10</td><td align="center" valign="middle" >0.9150</td></tr><tr><td align="center" valign="middle" >RCAN</td><td align="center" valign="middle" >33.56</td><td align="center" valign="middle" >0.8906</td></tr><tr><td align="center" valign="middle" >RDN</td><td align="center" valign="middle" >36.41</td><td align="center" valign="middle" >0.9225</td></tr><tr><td align="center" valign="middle" >VDSR</td><td align="center" valign="middle" >36.67</td><td align="center" valign="middle" >0.9250</td></tr><tr><td align="center" valign="middle" >DRRN</td><td align="center" valign="middle" >36.75</td><td align="center" valign="middle" >0.9249</td></tr><tr><td align="center" valign="middle" >Proposed</td><td align="center" valign="middle" >36.92</td><td align="center" valign="middle" >0.9262</td></tr></tbody></table></table-wrap><p>表1. iSeg-2017 T1 MR图像数据库上不同算法的结果</p><p>图3. iSeg-2017 MR T1数据示例图像上不同算法重建的高分辨率SR图像的结果</p></sec><sec id="s7_3_2"><title>3.3.2. ALVIN数据集</title><p>我们在ALVIN数据集上进行实验，此数据集为临床成人大脑核磁共振图像。我们随机地抽取15个T1维度的核磁共振3D图像，图像大小为 180 &#215; 256 &#215; 256 ，在每一个3D核磁共振图像中选取第131张到160张，也就是30张轴向平面图像用作训练。</p><p>图4展示了由不同的超分辨算法在在成人大脑图像ALVIN数据集上生成的结果，本文提供的算法提供了更丰富的细节，表2展示本算法获得了最佳峰值信噪比(PSNR) 38.42 dB和最佳结构相似度(SSIM) 0.9619。</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> Results of different algorithms on the ALVIN T1 MR Image databas</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" >PSNR (dB)</th><th align="center" valign="middle" >SSIM</th></tr></thead><tr><td align="center" valign="middle" >SRCNN</td><td align="center" valign="middle" >34.47</td><td align="center" valign="middle" >0.9028</td></tr><tr><td align="center" valign="middle" >FSRCNN</td><td align="center" valign="middle" >35.27</td><td align="center" valign="middle" >0.9268</td></tr><tr><td align="center" valign="middle" >RCAN</td><td align="center" valign="middle" >35.06</td><td align="center" valign="middle" >0.9311</td></tr><tr><td align="center" valign="middle" >RDN</td><td align="center" valign="middle" >36.62</td><td align="center" valign="middle" >0.9307</td></tr><tr><td align="center" valign="middle" >VDSR</td><td align="center" valign="middle" >37.74</td><td align="center" valign="middle" >0.9568</td></tr><tr><td align="center" valign="middle" >DRRN</td><td align="center" valign="middle" >38.11</td><td align="center" valign="middle" >0.9594</td></tr><tr><td align="center" valign="middle" >Proposed</td><td align="center" valign="middle" >38.42</td><td align="center" valign="middle" >0.9619</td></tr></tbody></table></table-wrap><p>表2. ALVIN T1 MR图像数据库上不同算法的结果</p><p>图4. ALVIN T1 MR数据示例图像上不同算法重建的高分辨率SR图像的结果</p></sec><sec id="s7_3_3"><title>3.3.3. BRATS数据集</title><p>我们在BRATS数据集上进行实验，此临床数据集为脑肿瘤图像。随机选择了20个T1对比增强型MRI图像与胶质母细胞瘤图像，图像大小为 240 &#215; 240 &#215; 155 ，在每个3D核磁共振图像中选取第65片到第99片，也就是35个轴向平面图像。由于该图像空白处过大，将轴向平面图像截取至 155 &#215; 177 用作后续训练。</p><p>图5展示了由不同的超分辨算法在成人大脑肿瘤图像BRATS数据集上生成的结果，本文提供的算法提供了更丰富的细节，表3展示本算法获得了最佳峰值信噪比(PSNR) 36.35 dB和最佳结构相似度(SSIM) 0.9579。</p></sec></sec><sec id="s7_4"><title>3.4. 实验结果分析</title><p>在这项工作中，我们提出了一种新的基于多尺度残差学习和正则化的超分辨算法，用于核磁共振图像的重建。基于三个真实MR图像数据集的结果显示，本文提出的算法优于其他超分辨算法。</p><p>全局残差学习用于学习图像细节信息，在基于卷积神经网络的超分辨算法中已经得到了广泛的应用，在算法的。但是由于图像细节信息在比较深的卷积神经网络中会因退化问题而丢失，所以其性能会受到一定的限制。局部残差学习结构可以在一定程度上克服这个问题，因为局部残差学习使用的短连接传输细节信息，以此补偿某些缺失的信息。我们结合了基于浅层网络模块的局部残差学习与传统的全局残差学习，来提高算法的图像重建性能。</p><p>我们在网络中的非线性映射部分使用局部残差学习模型，该部分由多个多尺度残差模块堆叠。在多尺度残差模块中，实施浅层卷积分支与深层卷积分支的多尺度要素总和的策略。如图2多尺度残差模块结构图所示，浅分支为深分支提供了叠加的更丰富的高频特性，而深分支则将细节信息传输到较远的残留方块。为了研究多尺度残差连接对网络的影响，我们删除 7 &#215; 7 与 5 &#215; 5 的卷积特征提取及短连接，在ALVIN数据集上进行相同环境下的训练，实验结果显示在表4中。</p><p>大部分深度学习超分辨重建网络损失函数仅使用一项，为L1正则化或L2正则化，本文引入全变分正则化项，它能去除图像噪声，有效地保留图像边缘信息，有助于优化重建图像。为了研究全变分正则化项对网络的影响，我们在损失函数中删除此正则化项，在ALVIN数据集上进行相同环境下的训练，实验结果显示在表4。</p><p>由表4可看出多尺度残差学习对算法的实验结果有比较大的提升，更多更丰富的高频信息得以保留并传输到网络的下一层继续训练，全变分正则化降低生成噪声，当正则化项参数选取得当的情况下对训练结果有一定的提升。</p><table-wrap id="table3" ><label><xref ref-type="table" rid="table3">Table 3</xref></label><caption><title> Results of different algorithms on the BRATS T1 MR Image databas</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" >PSNR (dB)</th><th align="center" valign="middle" >SSIM</th></tr></thead><tr><td align="center" valign="middle" >SRCNN</td><td align="center" valign="middle" >34.97</td><td align="center" valign="middle" >0.9392</td></tr><tr><td align="center" valign="middle" >FSRCNN</td><td align="center" valign="middle" >34.99</td><td align="center" valign="middle" >0.9454</td></tr><tr><td align="center" valign="middle" >RCAN</td><td align="center" valign="middle" >35.32</td><td align="center" valign="middle" >0.9511</td></tr><tr><td align="center" valign="middle" >RDN</td><td align="center" valign="middle" >35.39</td><td align="center" valign="middle" >0.9489</td></tr><tr><td align="center" valign="middle" >VDSR</td><td align="center" valign="middle" >35.66</td><td align="center" valign="middle" >0.9538</td></tr><tr><td align="center" valign="middle" >DRRN</td><td align="center" valign="middle" >36.06</td><td align="center" valign="middle" >0.9560</td></tr><tr><td align="center" valign="middle" >Proposed</td><td align="center" valign="middle" >36.35</td><td align="center" valign="middle" >0.9579</td></tr></tbody></table></table-wrap><p>表3. BRATS T1 MR图像数据库上不同算法的结果</p><p>图5. BRATS T1 MR数据示例图像上不同算法重建的高分辨率SR图像的结果</p><table-wrap id="table4" ><label><xref ref-type="table" rid="table4">Table 4</xref></label><caption><title> Model analysis of this method on the ALVIN image verification se</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >多尺度残差学习</th><th align="center" valign="middle" >全变分正则化</th><th align="center" valign="middle" >PSNR (dB)</th><th align="center" valign="middle" >SSIM</th></tr></thead><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" >38.06</td><td align="center" valign="middle" >0.9578</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" >38.34</td><td align="center" valign="middle" >0.9605</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" >38.42</td><td align="center" valign="middle" >0.9619</td></tr></tbody></table></table-wrap><p>表4. ALVIN图像验证集上对此方法的模型分析</p></sec></sec><sec id="s8"><title>4. 总结</title><p>本文我们提出了一种改进的深度学习超分辨网络，通过使用多尺度残差模块以及正则化项的创新，来提高算法在临床大脑核磁共振图像超分辨重建任务上的准确率。此算法可以有效地重建大脑核磁共振图像的细节信息，通过在三个临床MR图像数据库上的实验结果表明，在没有增大算法复杂程度的情况下，本文提出的算法性能优越，与目前先进的超分辨算法相比有显著的提升。</p></sec><sec id="s9"><title>基金项目</title><p>国家自然科学基金项(1197010603)。</p></sec><sec id="s10"><title>文章引用</title><p>蔡 言. 基于多尺度残差网络与正则化约束的MR图像超分辨算法MR Image Super-Resolution Using Multi-Scale Residual Networks with Regularization Norm[J]. 理论数学, 2021, 11(05): 909-921. https://doi.org/10.12677/PM.2021.115104</p></sec><sec id="s11"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.42636-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Reeth, E.V., Tham, I.W.K., Tan, C.H. and Poh, C.L. (2012) Super-Resolution in Magnetic Resonance Imaging: A Re-view. Concepts in Magnetic Resonance Part A, 40, 306-325. &lt;br&gt;https://doi.org/10.1002/cmr.a.21249</mixed-citation></ref><ref id="hanspub.42636-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Ji, C.T. (2014) An Edge-Oriented Interpolation Algorithm Based on Regularization. Journal of Electronic Information, 36, 293-297.</mixed-citation></ref><ref id="hanspub.42636-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Papyan, V. and Elad, M. (2016) Multi-Scale Patch-Based Image Restoration. IEEE Transactions on Image Processing, 25, 249-261. &lt;br&gt;https://doi.org/10.1109/TIP.2015.2499698</mixed-citation></ref><ref id="hanspub.42636-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Lu, X.Q., Huang, Z.H. and Yuan, Y. (2015) MR Image Super-Resolution via Manifold Regularized Sparse Learning. Neurocomputing, 162, 96-104. &lt;br&gt;https://www.sciencedirect.com/science/article/pii/S0925231215003896</mixed-citation></ref><ref id="hanspub.42636-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Dong, C., Chen, C.L., He, K. and Tang, X. (2014) Learning a Deep Convolutional Network for Image Super-Resolution. 2014 European Conference on Computer Vision (ECCV), Zurich, 6-12 September 2014, 184-199.  
&lt;br&gt;https://doi.org/10.1007/978-3-319-10593-2_13</mixed-citation></ref><ref id="hanspub.42636-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Dong, C., Loy, C.C. and Tang, X. (2016) Accelerating the Super-Resolution Convolutional Neural Network. 2016 European Conference on Computer Vision (ECCV), Amsterdam, 8-16 October, 391-407.  
&lt;br&gt;https://doi.org/10.1007/978-3-319-46475-6_25</mixed-citation></ref><ref id="hanspub.42636-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">He, K., Zhang, X., Ren, S. and Sun, J. (2016) Deep Residual Learning for Image Recognition. 2016 IEEE Conference on Computer Vision and Pattern Recognition, Las Vegas, 27-30 June 2016, 770-778.  
&lt;br&gt;https://doi.org/10.1109/CVPR.2016.90</mixed-citation></ref><ref id="hanspub.42636-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Ledig, C., Theis, L., Huszár, F., Caballero, J., Cunningham, A., Acosta, A., et al. (2017) Photorealistic Single Image Super-Resolution Using a Generative Adversarial Network. 2017 IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, 21-26 July 2017, 105-114. &lt;br&gt;https://doi.org/10.1109/CVPR.2017.19</mixed-citation></ref><ref id="hanspub.42636-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Kim, J., Lee, J.K. and Lee, K.M. (2016) Accurate Image Su-per-Resolution Using Very Deep Convolutional Networks. 2016 IEEE Conference on Computer Vision and Pattern Recognition, Las Vegas, 27-30 June 2016, 1646-1654.  
&lt;br&gt;https://doi.org/10.1109/CVPR.2016.182</mixed-citation></ref><ref id="hanspub.42636-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Kim, J., Lee, J.K. and Lee, K.M. (2016) Deeply-Recursive Convo-lutional Network for Image Super-Resolution. 2016 IEEE Conference on Computer Vision and Pattern Recognition, Las Vegas, 27-30 June 2016, 1637-1645.  
&lt;br&gt;https://doi.org/10.1109/CVPR.2016.181</mixed-citation></ref><ref id="hanspub.42636-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Tai, Y., Jian, Y. and Liu, X. (2017) Image Super-Resolution via Deep Recursive Residual Network. 2017 IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, 21-26 July 2017, 2790-2798.  
&lt;br&gt;https://doi.org/10.1109/CVPR.2017.298</mixed-citation></ref><ref id="hanspub.42636-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Huang, G., Liu, Z., Maaten, L.V.D. and Weinberger, K.Q. (2017) Densely Connected Convolutional Networks. 2017 IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, 21-26 July 2017, 2261-2269.  
&lt;br&gt;https://doi.org/10.1109/CVPR.2017.243</mixed-citation></ref><ref id="hanspub.42636-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Tong, T., Li, G., Liu, X. and Gao, Q. (2017) Image Su-per-Resolution Using Dense Skip Connections. 2017 IEEE International Conference on Computer Vision, Venice, 22-29 October 2017, 4809-4817.  
&lt;br&gt;https://doi.org/10.1109/ICCV.2017.514</mixed-citation></ref><ref id="hanspub.42636-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">Zhang, Y., Tian, Y., Kong, Y., Zhong, B. and Fu, Y. (2018) Residual Dense Network for Image Super-Resolution. 2018 IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, 18-23 June 2018, 2472-2481.  
&lt;br&gt;https://doi.org/10.1109/CVPR.2018.00262</mixed-citation></ref><ref id="hanspub.42636-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">Zhang, Y., Li, K., Wang, L., Zhong, B. and Fu, Y. (2018) Image Super-Resolution Using Very Deep Residual Channel Attention Networks. 2018 European Conference on Computer Vision, Munich, 8-14 September, 294-310.  
&lt;br&gt;https://doi.org/10.1007/978-3-030-01234-2_18</mixed-citation></ref><ref id="hanspub.42636-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">Zeiler, M.D. and Fergus, R. (2014) Visualizing and Under-standing Convolutional Networks. 2014 European Conference on Computer Vision, Zurich, 6-12 September 2014, 818-833. &lt;br&gt;https://doi.org/10.1007/978-3-319-10590-1_53</mixed-citation></ref><ref id="hanspub.42636-ref17"><label>17</label><mixed-citation publication-type="other" xlink:type="simple">Kempton, M.J., Underwood, T.S.A., Brunton, S., Stylios, F., Schmechtig, A., Ettinger, U., et al. (2011) A Comprehensive Testing Protocol for MRI Neuroanatomical Segmentation Techniques Evaluation of a Novel Lateral Ventricle Segmentation method. NeuroImage, 58, 1051-1059. &lt;br&gt;https://doi.org/10.1016/j.neuroimage.2011.06.080</mixed-citation></ref><ref id="hanspub.42636-ref18"><label>18</label><mixed-citation publication-type="other" xlink:type="simple">Menze, B.H., Jakab, A., Bauer, S., Kalpathy-Cramer, J., Farahani, K., Kirby, J., et al. (2015) The Multimodal Brain Tumor Image Segmentation Benchmark (BRATS). IEEE Transactions on Medical Imaging, 34, 1993-2024.  
&lt;br&gt;https://doi.org/10.1109/TMI.2014.2377694</mixed-citation></ref><ref id="hanspub.42636-ref19"><label>19</label><mixed-citation publication-type="other" xlink:type="simple">佟雨兵, 张其善, 祁云平. 基于PSNR与SSIM联合的图像质量评价模型[J]. 中国图象图形学报, 2006, 11(12): 1758-1763.</mixed-citation></ref><ref id="hanspub.42636-ref20"><label>20</label><mixed-citation publication-type="other" xlink:type="simple">Wang, Z., Bovik, A.C., Sheikh, H.R. and Simoncelli, E.P. (2004) Image Quality Assessment: From Error Visibility to Structural Similarity. IEEE Transactions on Image Processing, 13, 600-612. &lt;br&gt;https://doi.org/10.1109/TIP.2003.819861</mixed-citation></ref><ref id="hanspub.42636-ref21"><label>21</label><mixed-citation publication-type="other" xlink:type="simple">Keys, R. (1981) Cubic Con-volution Interpolation for Digital Image Processing. IEEE Transactions on Acoustics, Speech, and Signal Processing, 29, 1153-1160. &lt;br&gt;https://doi.org/10.1109/TASSP.1981.1163711</mixed-citation></ref></ref-list></back></article>