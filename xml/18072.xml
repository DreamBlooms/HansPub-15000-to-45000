<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">JISP</journal-id><journal-title-group><journal-title>Journal of Image and Signal Processing</journal-title></journal-title-group><issn pub-type="epub">2325-6753</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/JISP.2016.53014</article-id><article-id pub-id-type="publisher-id">JISP-18072</article-id><article-categories><subj-group subj-group-type="heading"><subject>JISP20160300000_58778154.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于RANSAC的PCA-SIFT立体匹配方法研究
  The Research of PCA-SIFT Stereo Matching Method Based on RANSAC
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>刘</surname><given-names>奥丽</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>王</surname><given-names>海晖</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>肖</surname><given-names>永强</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>王</surname><given-names>子维</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>章</surname><given-names>刘斌</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib></contrib-group><aff id="aff3"><addr-line>智能机器人湖北省重点实验室(武汉工程大学)，湖北 武汉</addr-line></aff><aff id="aff1"><addr-line>武汉工程大学计算机科学与工程学院，湖北 武汉</addr-line></aff><aff id="aff2"><addr-line>null</addr-line></aff><author-notes><corresp id="cor1">* E-mail:<email>1457769521@qq.com(刘奥)</email>;</corresp></author-notes><pub-date pub-type="epub"><day>12</day><month>07</month><year>2016</year></pub-date><volume>05</volume><issue>03</issue><fpage>105</fpage><lpage>111</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   针对传统的SIFT (Scale-Invariant Feature Transform)匹配算法数据量大，耗时长的问题，采用主成分不变特征变换PCA-SIFT (Principal Component Analysis, PCA)匹配算法。PCA-SIFT匹配算法将传统SIFT算法中的直方图法换做主元分析法，降低了传统SIFT特征描述符的维数，减少了数据量，提高了匹配效率。首先提取出两幅待匹配图像中的所有特征描述子，其次将提取出的特征描述子采用距离比阈值筛选出匹配点对，再采用RANSAC (Random Sample Consensus)法消除错配，最后得到精确的匹配结果。实验结果表明，PCA-SIFT + RANSAC算法较稳定、精确、快速。 Principal Component Analysis of Traditional Scale-Invariant Feature Transform (PCA-SIFT) is used instead of Traditional Scale-Invariant Feature Transform (SIFT) method which has a large amount of data, and needs long time. Principal Component Analysis of Traditional Scale-Invariant Feature Transform (PCA-SIFT) changed histogram method for main element analysis method, effectively reducing the dimension of the feature descriptor, decreasing data, improving the matching rate. Firstly we extract all the feature descriptors from the two matching images, and match them with the enulidean distance ratio, and then we use the Random Sample Consensus (RANSAC) algorithm to remove false matching. The experimental results show that the PCA-SIFT + RANSAC algorithm is more stable, more accurate and more rapid.
    
  
 
</p></abstract><kwd-group><kwd>立体匹配，SIFT，PCA-SIFT，RANSAC, Stereo Matching</kwd><kwd> SIFT</kwd><kwd> PCA-SIFT</kwd><kwd> RANSAC</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>基于RANSAC的PCA-SIFT立体匹配方法研究<sup> </sup></title><p>刘奥丽<sup>1</sup>，王海晖<sup>2</sup>，肖永强<sup>1</sup>，王子维<sup>1</sup>，章刘斌<sup>1</sup></p><p><sup>1</sup>武汉工程大学计算机科学与工程学院，湖北 武汉</p><p><sup>2</sup>智能机器人湖北省重点实验室(武汉工程大学)，湖北 武汉</p><disp-formula id="hanspub.18072-formula11"><graphic xlink:href="http://html.hanspub.org/file/4-2670079x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>收稿日期：2016年7月6日；录用日期：2016年7月24日；发布日期：2016年7月27日</p><disp-formula id="hanspub.18072-formula12"><graphic xlink:href="http://html.hanspub.org/file/4-2670079x7_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>针对传统的SIFT (Scale-Invariant Feature Transform)匹配算法数据量大，耗时长的问题，采用主成分不变特征变换PCA-SIFT (Principal Component Analysis, PCA)匹配算法。PCA-SIFT匹配算法将传统SIFT算法中的直方图法换做主元分析法，降低了传统SIFT特征描述符的维数，减少了数据量，提高了匹配效率。首先提取出两幅待匹配图像中的所有特征描述子，其次将提取出的特征描述子采用距离比阈值筛选出匹配点对，再采用RANSAC (Random Sample Consensus)法消除错配，最后得到精确的匹配结果。实验结果表明，PCA-SIFT + RANSAC算法较稳定、精确、快速。</p><p>关键词 :立体匹配，SIFT，PCA-SIFT，RANSAC</p><disp-formula id="hanspub.18072-formula13"><graphic xlink:href="http://html.hanspub.org/file/4-2670079x8_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s3"><title>1. 引言</title><p>双目立体视觉技术目前广泛应用于视频监视，人机交互，军事领域，医学等方面，随着科技的发展，双目立体视觉技术将会占有举足轻重的地位。双目立体视觉技术主要集中在相机标定和立体匹配部分，其中立体匹配是立体视觉最为关键的部分。基于其立体匹配的应用要求，一种同时具备准确性和高效性的图像匹配技术成为重要需求。在目前的立体匹配算法中，由于SIFT算法在特征点尺度，旋转和光照不变性方面明显优于其他特征描述子，因此得到广泛应用。但SIFT描述子的维度较高从而计算过于复杂，为了降低计算复杂度，提高匹配精度，有很多研究人员提出了各种基于SIFT的改进算法。Bay等人提出的快速鲁棒特征(Speeded Up Robust Features, SURF)算法 [<xref ref-type="bibr" rid="hanspub.18072-ref1">1</xref>] 类似于SIFT算法，特征点检测都是基于尺度空间，该算法采用Harr小波变换增加鲁棒性和Hessian矩阵来提高时间效率，同时以大大减少的特征点数目为代价；GLOH的方法 [<xref ref-type="bibr" rid="hanspub.18072-ref2">2</xref>] 采用环形扇区代替矩形区域构建梯度位置直方图描述算子，再使用PCA将272维描述符降为128维，该描述算子的独特性比SIFT要好，但是计算更复杂；Kc和Sukthankar [<xref ref-type="bibr" rid="hanspub.18072-ref3">3</xref>] 将主成分分析(PCA)方法运用至SIFT图像匹配中，采用主成分分析的方法对SIFT算子进行降维操作，其算法中特征点描述算子的维度可以降低到20维但是在执行快速匹配时的精度也不如SIFT [<xref ref-type="bibr" rid="hanspub.18072-ref4">4</xref>] 。</p><p>本文考虑到PCA-SIFT算法在速度上的优势和精度不高的缺点，结合由Fischler和Bones于1981年提出的RANSAC算法思想 [<xref ref-type="bibr" rid="hanspub.18072-ref5">5</xref>] ，综合利用二者的优势，提出了一种PCA-SIFT算法和RANSAC算法相结合的立体匹配方法。首先，采用PCA-SIFT算法提取图像中特征点，并对提取出的特征点进行预匹配，然后再利用RANSAC算法消除误差较大的误匹配。实验结果表明基于RANSAC的PCA-SIFT具有良好的匹配效果且速度和效果都优于SIFT算法。</p></sec><sec id="s4"><title>2. PCA-SIFT算法</title><p>PCA-SIFT算法是SIFT算法的改进算法，将传统SIFT算法中的直方图法换做主元分析法 [<xref ref-type="bibr" rid="hanspub.18072-ref6">6</xref>] ，降低了传统SIFT特征描述符的维数，减少了数据量，提高了匹配效率。PCA-SIFT算法需要如下几个步骤：1) 多尺度检测极值点；2) 计算关键点特征方向；3) 生成特征描述子。</p><sec id="s4_1"><title>2.1. 多尺度极值点检测</title><p>根据文献 [<xref ref-type="bibr" rid="hanspub.18072-ref7">7</xref>] ，尺度变换中把高斯卷积核当作唯一的变换核，并且也是作为唯一的线性核，一幅二维图像在不同尺度空间下的尺度可表示为：</p><disp-formula id="hanspub.18072-formula14"><label>(1)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/4-2670079x9_hanspub.png"  xlink:type="simple"/></disp-formula><disp-formula id="hanspub.18072-formula15"><label>(2)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/4-2670079x10_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x11_hanspub.png" xlink:type="simple"/></inline-formula>定义为原始图像<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x12_hanspub.png" xlink:type="simple"/></inline-formula>与一个可变尺度的2维高斯函数<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x13_hanspub.png" xlink:type="simple"/></inline-formula>卷积运算。<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x14_hanspub.png" xlink:type="simple"/></inline-formula>是尺度可变的高斯函数，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x15_hanspub.png" xlink:type="simple"/></inline-formula>是空间坐标。</p><p>特征点的检测要在尺度空间和平面空间中同时进行，这样才可以确保得到稳健性强的特征点。因此就引入了DoG算子，它是两个不同尺度高斯核的差分值 [<xref ref-type="bibr" rid="hanspub.18072-ref8">8</xref>] ，DoG算子的构成为：</p><disp-formula id="hanspub.18072-formula16"><label>(3)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/4-2670079x16_hanspub.png"  xlink:type="simple"/></disp-formula><p>构建一个大小为O组，并且每组有S层的高斯金字塔，在组内相邻的高斯图像差分得到高斯差分图像。在高斯差分图像中检测极值点，在每一幅高斯差分图像中的每一个像素点，和它所在图像的八领域像素比较，而且要和它所在图像的上一层和下一层的各九个邻近的像素点比较。为了获得稳定的特征点，将不稳定的点除去，不稳定的点包括低低对比度的点和边缘上的点。可以利用<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x17_hanspub.png" xlink:type="simple"/></inline-formula>去除低对比度的点。</p><disp-formula id="hanspub.18072-formula17"><label>(4)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/4-2670079x18_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x19_hanspub.png" xlink:type="simple"/></inline-formula>绝对值小于0.03的极值点都将被丢弃。利用如下公式</p><disp-formula id="hanspub.18072-formula18"><label>(5)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/4-2670079x20_hanspub.png"  xlink:type="simple"/></disp-formula><disp-formula id="hanspub.18072-formula19"><label>(6)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/4-2670079x21_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x22_hanspub.png" xlink:type="simple"/></inline-formula>是Hessian矩阵，除去边缘上的点。通过上述过程就得到稳定的特征点。</p></sec><sec id="s4_2"><title>2.2. 计算特征点方向</title><p>为了使关键特征具有旋转不变性，采用相对的概念为关键点赋一个方向，定义的关键点描述子是相对这个方向的。对于L上的每一个点<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x23_hanspub.png" xlink:type="simple"/></inline-formula>，计算梯度和方向：</p><disp-formula id="hanspub.18072-formula20"><label>(7)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/4-2670079x24_hanspub.png"  xlink:type="simple"/></disp-formula><disp-formula id="hanspub.18072-formula21"><label>(8)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/4-2670079x25_hanspub.png"  xlink:type="simple"/></disp-formula><p>以关键点为中心，划定一个区域，利用所在区域内的点的梯度形成一个直方图。直方图的横坐标是梯度方向，纵坐标是梯度大小，对于归到横坐标上的点，将其梯度大小相加，其和作为纵坐标。将直方图中纵坐标最大的一项的方向作为关键点的主方向，如果存在其他方向，纵坐标的大小大于主方向纵坐标大小的80%，将其作为关键点的副方向。</p></sec><sec id="s4_3"><title>2.3. 生成特征描述子</title><p>至此已经为关键点赋予了图像位置，方向以及尺度，这一步根据关键点周围的局部特征计算一个描述子。如图，以特征点为中心，选取一个<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x26_hanspub.png" xlink:type="simple"/></inline-formula>的区域，再将其平均分成4个<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x27_hanspub.png" xlink:type="simple"/></inline-formula>的小区域，计算每个小区域的梯度直方图，直方图包涵8个bin方向，这样就获得了一个<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x28_hanspub.png" xlink:type="simple"/></inline-formula>维的向量，也就生成了特征描述符向量(如图1 SIFT描述子的生成)。</p><p>图1. SIFT描述子的生成</p><p>用主元分析法对128维SIFT描述子降维的过程如下：首先将两幅待匹配图像中所有n个特征点描述子<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x30_hanspub.png" xlink:type="simple"/></inline-formula>作为样本，构成一个<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x31_hanspub.png" xlink:type="simple"/></inline-formula>矩阵C。然后计算矩阵C的均值向量<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x32_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x33_hanspub.png" xlink:type="simple"/></inline-formula>的协方差矩</p><p>阵<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x34_hanspub.png" xlink:type="simple"/></inline-formula>的<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x35_hanspub.png" xlink:type="simple"/></inline-formula>个特征值<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x36_hanspub.png" xlink:type="simple"/></inline-formula>和特征向量<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x37_hanspub.png" xlink:type="simple"/></inline-formula>。并将特征值按从大到小顺序排列，则有</p><p><inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x38_hanspub.png" xlink:type="simple"/></inline-formula>和对应的特征向量<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x39_hanspub.png" xlink:type="simple"/></inline-formula>。选选出对应最大K个特征值的特征向量作为主成分方向。本文选取K = 36，最后构造一个<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x40_hanspub.png" xlink:type="simple"/></inline-formula>的矩阵<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x41_hanspub.png" xlink:type="simple"/></inline-formula>。将原始128维描述子按照公式投影到这个K维子空间，得到描述子的主成分表示<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x42_hanspub.png" xlink:type="simple"/></inline-formula></p><disp-formula id="hanspub.18072-formula22"><label>(9)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/4-2670079x43_hanspub.png"  xlink:type="simple"/></disp-formula></sec></sec><sec id="s5"><title>3. RANSAC算法</title><p>RANSAC算法 [<xref ref-type="bibr" rid="hanspub.18072-ref9">9</xref>] 的基本假设是样本中包含正确数据也包含异常数据。而PCA-SIFT算法中的异常数据则是进行预匹配所产生的错误匹配或者误差较大的匹配。利用RANSAC算法消除误匹配，采用如下思想：</p><p>1) 考虑一个最小抽样集视为n的模型(n为初始化模型参数所需的最小样本数)和一个样本集<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x44_hanspub.png" xlink:type="simple"/></inline-formula>，集合<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x45_hanspub.png" xlink:type="simple"/></inline-formula>的样本数<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x46_hanspub.png" xlink:type="simple"/></inline-formula>，从<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x47_hanspub.png" xlink:type="simple"/></inline-formula>中随机抽取n个样本，构成<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x48_hanspub.png" xlink:type="simple"/></inline-formula>的子集<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x49_hanspub.png" xlink:type="simple"/></inline-formula>，用来初始化模型M。</p><p>2) 余集<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x50_hanspub.png" xlink:type="simple"/></inline-formula>中与模型M的误差小于某一设定阈值<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x51_hanspub.png" xlink:type="simple"/></inline-formula>的样本集合和集合<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x52_hanspub.png" xlink:type="simple"/></inline-formula>构成集合<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x53_hanspub.png" xlink:type="simple"/></inline-formula>。<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x54_hanspub.png" xlink:type="simple"/></inline-formula>是内集，它们构成<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x55_hanspub.png" xlink:type="simple"/></inline-formula>的一致集。</p><p>3) 若<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x56_hanspub.png" xlink:type="simple"/></inline-formula>，认为得到正确的模型参数，并利用集<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x57_hanspub.png" xlink:type="simple"/></inline-formula>(内点)，采用最小二乘等方法重新计算新的模型<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x58_hanspub.png" xlink:type="simple"/></inline-formula>。重新随机抽取新的<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2670079x59_hanspub.png" xlink:type="simple"/></inline-formula>，重复以上过程。</p><p>4) 在完成一定的抽样次数后，若未找到一致集，则算法失败，否则选取抽样后得到的最大一致集判断内外点，算法结束。</p></sec><sec id="s6"><title>4. PCA-SIFT的优化算法</title><p>本文PCA-SIFT算法提出了一种改进的图像立体匹配算法，具体步骤如下：</p><p>Step1构建高斯差分金字塔并检测极值点，经过稳定性筛选出关键点；</p><p>Step2利用关键点邻域像素的梯度方向分布特性为每个关键点指定方向参数，将坐标轴旋转为关键点的主方向；</p><p>Step3利用主元分析法生成32维特征描述子；</p><p>Step4按照最近邻比率算法对图像进行匹配，得到N对匹配点并以最近邻比率的大小进行排序；</p><p>Step5利用RANSAC算法进行变换矩阵参数的拟合，最后用得到的矩阵模型剔除错误匹配点。</p></sec><sec id="s7"><title>5. 实验结果</title><p>实验环境为CPU 2.20 GHz，内存8.00 GB，显存2.19 GHz，操作系统为Windows 10，仿真平台为Visual Studios 2010+Opencv2.4.10，所用的图像采集设备为Bumblebee双目视觉相机。使用了多幅图像进行实验，为了验证算法的有效性，将不同算法做实验比较，并对结果进行分析。在实验中对SIFT、PCA-SIFT、PCA-SIFT+RANSAC的性能进行了对比分析。实验结果图如图2~4所示。</p><p>根据表1，表2可以得知，PCA-SIFT在匹配时间上要优于SIFT算法，在图片中存在大量的匹配点，这个优点尤为突出；但是PCA-SIFT的误匹配要高于SIFT算法，采用RANSAC应用在PCA-SIFT算法上后，误匹配率降低，且低于SIFT算法，时间上还优于SIFT。综上诉述，PCA-SIFT + RANSAC算法在时间上和匹配效果上优于SIFT算法。</p><p>图2. SIFT匹配结果</p><p>图3. PCA-SIFT匹配结果图</p><p>图4. PCA-SIFT + RANSAC匹配结果图</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Experimental dat</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >算法</th><th align="center" valign="middle" >匹配点(对)</th><th align="center" valign="middle" >误匹配率(%)</th><th align="center" valign="middle" >时间(s)</th></tr></thead><tr><td align="center" valign="middle" >SIFT</td><td align="center" valign="middle" >67</td><td align="center" valign="middle" >5/67 = 7.4626</td><td align="center" valign="middle" >10.2785</td></tr><tr><td align="center" valign="middle" >PCA-SIFT</td><td align="center" valign="middle" >73</td><td align="center" valign="middle" >4/73 = 5.4794</td><td align="center" valign="middle" >6.9829</td></tr><tr><td align="center" valign="middle" >PCA-SIFT + RANSAC</td><td align="center" valign="middle" >68</td><td align="center" valign="middle" >2/68 = 2.9411</td><td align="center" valign="middle" >8.0190</td></tr></tbody></table></table-wrap><p>表1. 实验图数据</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> Multiple sets of experimental dat</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >实验</th><th align="center" valign="middle" ></th><th align="center" valign="middle" >SIFT</th><th align="center" valign="middle" >PCA-SIFT</th><th align="center" valign="middle" >PCA-SIFT + RANSAC</th></tr></thead><tr><td align="center" valign="middle"  rowspan="3"  >1</td><td align="center" valign="middle" >匹配点(对)</td><td align="center" valign="middle" >30</td><td align="center" valign="middle" >17</td><td align="center" valign="middle" >13</td></tr><tr><td align="center" valign="middle" >误匹配率(%)</td><td align="center" valign="middle" >3/30 = 10.0000</td><td align="center" valign="middle" >2/17 = 11.7647</td><td align="center" valign="middle" >1/13 = 7.6923</td></tr><tr><td align="center" valign="middle" >时间(s)</td><td align="center" valign="middle" >2.6192</td><td align="center" valign="middle" >1.3431</td><td align="center" valign="middle" >2.0307</td></tr><tr><td align="center" valign="middle"  rowspan="3"  >2</td><td align="center" valign="middle" >匹配点(对)</td><td align="center" valign="middle" >19</td><td align="center" valign="middle" >11</td><td align="center" valign="middle" >8</td></tr><tr><td align="center" valign="middle" >误匹配率(%)</td><td align="center" valign="middle" >2/19 = 10.5263</td><td align="center" valign="middle" >1/11 = 9.0909</td><td align="center" valign="middle" >0/8 = 0</td></tr><tr><td align="center" valign="middle" >时间(s)</td><td align="center" valign="middle" >11.0054</td><td align="center" valign="middle" >7.6972</td><td align="center" valign="middle" >8.5505</td></tr><tr><td align="center" valign="middle"  rowspan="3"  >3</td><td align="center" valign="middle" >匹配点(对)</td><td align="center" valign="middle" >31</td><td align="center" valign="middle" >32</td><td align="center" valign="middle" >28</td></tr><tr><td align="center" valign="middle" >误匹配率(%)</td><td align="center" valign="middle" >3/31 = 9.677</td><td align="center" valign="middle" >3/32 = 9.3750</td><td align="center" valign="middle" >1/28 = 3.5714</td></tr><tr><td align="center" valign="middle" >时间(s)</td><td align="center" valign="middle" >11.2439</td><td align="center" valign="middle" >6.2501</td><td align="center" valign="middle" >7.5552</td></tr></tbody></table></table-wrap><p>表2. 多组实验数据</p></sec><sec id="s8"><title>6. 结语</title><p>从上述理论分析和实验结果可以看出，基于RANSAC和PCA-SIFT算法的方法能够满足较高精度，同时使匹配的复杂度大大降低，算法在实时性和准确性方面得到了显著的提高。由上述算法的分析可以知：SIFT算法和PCA-SIFT算法具有相同的特征点坐标，方向，梯度，不同之处在于周围描述子不同，SIFT算法采用128维，而PCA-SIFT算法利用PCA降维达到32维，在后期匹配上，PCA-SIFT算法将会节省大量时间。利用RANSAC消除误匹配，又使PCA-SIFT算法在匹配效果上得到优化。采用基于RANSAC的PCA-SIFT的特征匹配，在保证匹配结果有效性和准确性的同时，极大提高了匹配效率和运算速度。</p></sec><sec id="s9"><title>文章引用</title><p>刘奥丽,王海晖,肖永强,王子维,章刘斌. 基于RANSAC的PCA-SIFT立体匹配方法研究The Research of PCA-SIFT Stereo Matching Method Based on RANSAC[J]. 图像与信号处理, 2016, 05(03): 105-111. http://dx.doi.org/10.12677/JISP.2016.53014</p></sec><sec id="s10"><title>参考文献 (References)</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.18072-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Bay, H., Ess, A., Tuytelaars, T., et al. (2008) Speeded-Up Robust Features (SURF). International Journal on Computer Vision and Image Understanding, 110, 346-359. http://dx.doi.org/10.1016/j.cviu.2007.09.014</mixed-citation></ref><ref id="hanspub.18072-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Mikolajczy, K. and Schmid, C. (2005) A Performance Evaluation of Local Descriptors. IEEE Transactions on Pattern Analysis and Machine Intelligence, 27, 1615-1630. http://dx.doi.org/10.1109/TPAMI.2005.188</mixed-citation></ref><ref id="hanspub.18072-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Ke, Y. and Sukthankar, R. (2004) PCA-SIFT: A More Distinctive Representation for Local Image Descriptors. Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition, Washington, 27 June-2 July, 506-513.</mixed-citation></ref><ref id="hanspub.18072-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Juan, L. and Gwun, O. (2009) A Comparison of SIFT, PCA-SIFT and SURF. International Journal of Image Processing, 3, 143-152.</mixed-citation></ref><ref id="hanspub.18072-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Fischler, M.A. and Bolles, R.C. (1981) Random Sample Consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartogramphy. Communications of the ACM, 24, 381-395.  
http://dx.doi.org/10.1145/358669.358692</mixed-citation></ref><ref id="hanspub.18072-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">马莉, 韩燮. 主成分分析法(PCA)在SIFT匹配算法中的应用[J]. 电视技术, 2012, 36(1): 129-132.</mixed-citation></ref><ref id="hanspub.18072-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Lowe, D.G. (2004) Distinctive Image Features from Scale-Invariant Keypoints. Journal of Computer Vision, 60, 91-110. http://dx.doi.org/10.1023/B:VISI.0000029664.99615.94</mixed-citation></ref><ref id="hanspub.18072-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Plum, J.P.W., Maintz, J.B.A. and Viergever, M.A. (2011) Mulual Information Matching in Multiresolution Contexts.  
http://www.docin.com/p-43905533.html</mixed-citation></ref><ref id="hanspub.18072-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">甄艳, 刘学军, 王美珍. 一种改进RANSAC的基础矩阵估计方法[J]. 测绘通报, 2014(4): 39-43.</mixed-citation></ref></ref-list></back></article>