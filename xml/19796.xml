<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">AIRR</journal-id><journal-title-group><journal-title>Artificial Intelligence and Robotics Research</journal-title></journal-title-group><issn pub-type="epub">2326-3415</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/AIRR.2017.61005</article-id><article-id pub-id-type="publisher-id">AIRR-19796</article-id><article-categories><subj-group subj-group-type="heading"><subject>AIRR20170100000_69111109.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject><subject> 工程技术</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于深度学习的高光谱图像分类方法
  A Classification Method for Hyperspectral Imagery Based on Deep Learning
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>袁</surname><given-names>林</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>胡</surname><given-names>少兴</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>张</surname><given-names>爱武</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>柴</surname><given-names>沙陀</given-names></name><xref ref-type="aff" rid="aff4"><sup>4</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>王</surname><given-names>兴</given-names></name><xref ref-type="aff" rid="aff4"><sup>4</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib></contrib-group><aff id="aff3"><addr-line>首都师范大学资源环境与旅游学院，北京</addr-line></aff><aff id="aff4"><addr-line>青海大学畜牧兽医院，青海 西宁</addr-line></aff><aff id="aff1"><addr-line>北京航空航天大学机械工程及自动化学院，北京</addr-line></aff><aff id="aff2"><addr-line>null</addr-line></aff><author-notes><corresp id="cor1">* E-mail:<email>yuanlinhyhy@163.com(袁林)</email>;</corresp></author-notes><pub-date pub-type="epub"><day>18</day><month>01</month><year>2017</year></pub-date><volume>06</volume><issue>01</issue><fpage>31</fpage><lpage>39</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   遥感高光谱成像能够获得丰富的地物光谱信息，这使得在传统的宽波段遥感中不可分辨的物质，在高光谱遥感中可以被分辨出来。高光谱图像具有“图谱合一”的特点，充分的利用高光谱图像中的光谱信息和空间信息是获得精确分类结果的前提。深度学习模型中的自编码神经网络能够实现高维数据的非线性降维，而卷积神经网络(Convolutional Neural Network, CNN)则能够自动的从图像中提取空间特征，基于此，本文提出了一种基于深度学习的Autoencoder-CNN高光谱图像分类方法。首先利用自编码神经网络对高光谱数据进行光谱维的降维，然后将卷积神经网络作为分类器，将待分类像元及其邻域像元一同作为卷积神经网络的输入，实现高光谱图像的空谱联合分类。 Remote sensing hyperspectral imaging can obtain abundant spectral information, which provides the possibility for the analysis of high precision terrain. The hyperspectral image has the characteristics of “map in one”, and the full use of spectral information and spatial information in hy- perspectral image is the premise of obtaining accurate classification results. Deep learning stack machine model in automatic encoding (Stack Auto-Encoder SAE) can effectively extract data in nonlinear information, and convolutional neural network (Convolutional Neural Network, CNN) can automatically extract features from the image. Based on this, this paper presents a classification method of hyperspectral images based on deep learning. Firstly, the spectral dimension of the hyperspectral data is reduced using automatic encoding machine, then convolutional neural network is used as the classifier, and the pixel and its neighborhood pixels are classified together as the input of the classifier, so as to realize the hyperspectral image classification with spectral space.
    
  
 
</p></abstract><kwd-group><kwd>高光谱，图像分类，深度学习，自编码神经网络，卷积神经网络, Hyperspectral</kwd><kwd> Image Classification</kwd><kwd> Depth Learning</kwd><kwd> Automatic Coding Machine</kwd><kwd> 
Convolutional Neural Network</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>基于深度学习的高光谱图像分类方法<sup> </sup></title><p>袁林<sup>1</sup>，胡少兴<sup>1</sup>，张爱武<sup>2</sup>，柴沙陀<sup>3</sup>，王兴<sup>3</sup></p><p><sup>1</sup>北京航空航天大学机械工程及自动化学院，北京</p><p><sup>2</sup>首都师范大学资源环境与旅游学院，北京</p><p><sup>3</sup>青海大学畜牧兽医院，青海 西宁</p><p>收稿日期：2017年2月3日；录用日期：2017年2月18日；发布日期：2017年2月24日</p><disp-formula id="hanspub.19796-formula102"><graphic xlink:href="http://html.hanspub.org/file/5-2610086x5_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>遥感高光谱成像能够获得丰富的地物光谱信息，这使得在传统的宽波段遥感中不可分辨的物质，在高光谱遥感中可以被分辨出来。高光谱图像具有“图谱合一”的特点，充分的利用高光谱图像中的光谱信息和空间信息是获得精确分类结果的前提。深度学习模型中的自编码神经网络能够实现高维数据的非线性降维，而卷积神经网络(Convolutional Neural Network, CNN)则能够自动的从图像中提取空间特征，基于此，本文提出了一种基于深度学习的Autoencoder-CNN高光谱图像分类方法。首先利用自编码神经网络对高光谱数据进行光谱维的降维，然后将卷积神经网络作为分类器，将待分类像元及其邻域像元一同作为卷积神经网络的输入，实现高光谱图像的空谱联合分类。</p><p>关键词 :高光谱，图像分类，深度学习，自编码神经网络，卷积神经网络</p><disp-formula id="hanspub.19796-formula103"><graphic xlink:href="http://html.hanspub.org/file/5-2610086x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2017 by authors and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="http://image.hanspub.org:8080\Html/htmlimages\1-2890033x\e70a10f1-7c93-45ea-9603-062237856e4b.png" /><img src="http://image.hanspub.org:8080\Html\htmlimages\1-2890033x\e898c85e-ffc4-45c9-b817-14224a4d6960.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>通过结合成像技术和光谱技术，高光谱遥感可以同时获得空间和光谱连续的数据。光谱数据在检测地球表面中是一种有效的工具，被广泛用于农业，矿物学，对地观测，物理学，天文学，化学成像和环境科学中 [<xref ref-type="bibr" rid="hanspub.19796-ref1">1</xref>] 。这些应用中的常用技术是对高光谱图像中每个像素进行分类。但是，高光谱图像的高数据维与不断提高的空间分辨率给传统的分类任务提出了新的挑战，提高高光谱图像的分类精度一直是遥感领域的研究热点。</p><p>限制高光谱图像分类精度的主要原因有两个：第一，与传统的图像分类问题 [<xref ref-type="bibr" rid="hanspub.19796-ref2">2</xref>] 相比，高光谱图像的分类问题具有数据空间维数高，训练样本难以获得的特点，即所谓的“维数灾难” [<xref ref-type="bibr" rid="hanspub.19796-ref3">3</xref>] ，这使得传统的在低维空间中表现良好的分类方法在高光谱图像分类问题上表现的不尽如人意。传统的解决维数灾难的方法是对高光谱数据进行降维处理后再分类 [<xref ref-type="bibr" rid="hanspub.19796-ref4">4</xref>] [<xref ref-type="bibr" rid="hanspub.19796-ref5">5</xref>] [<xref ref-type="bibr" rid="hanspub.19796-ref6">6</xref>] ，但传统的线性特征提取方法，如PCA、ICA，NFWE等，在降维的过程中舍弃了高光谱图像中光谱维上的细节信息，降维后的图像与多光谱无异，因而失去了“高光谱”的意义。第二，传统的方法把高光谱图像中的像元作为独立的光谱曲线进行分类，忽视了图像中的空间信息 [<xref ref-type="bibr" rid="hanspub.19796-ref6">6</xref>] 。为了利用图像中的空间信息，已有的文献从图像中提取纹理特征，结构特征，形态学特征等空间特征作为光谱特征的补充 [<xref ref-type="bibr" rid="hanspub.19796-ref6">6</xref>] [<xref ref-type="bibr" rid="hanspub.19796-ref7">7</xref>] [<xref ref-type="bibr" rid="hanspub.19796-ref8">8</xref>] 。但是各种的空间特征的抽取都需要人员的干预甚至设计，最终的分类效果与特征的好坏具备直接的关系，导致分类的准确率很大的依赖于人的经验，可能某一种空间特征在某一数据集上表现良好但是在其他数据集上结果却完全相反。</p><p>综上可知，高光谱图像分类问题在降维和空间特征提取两方面均有改进的空间，因此，本文提出了一种基于深度学习的高光谱图像分类方法，针对已有的分类方法中的缺陷，关注了深度学习中的两种常见模型——自动编码网络和卷积神经网络。自编码网络 [<xref ref-type="bibr" rid="hanspub.19796-ref9">9</xref>] 可以实现非监督的提取数据的特征，恰当设置非线性激活函数即可有效提取得到数据的非线性特征。卷积神经网络 [<xref ref-type="bibr" rid="hanspub.19796-ref10">10</xref>] [<xref ref-type="bibr" rid="hanspub.19796-ref11">11</xref>] 作为一种成功的视觉模型，已经在图像分类 [<xref ref-type="bibr" rid="hanspub.19796-ref2">2</xref>] ，人脸识别 [<xref ref-type="bibr" rid="hanspub.19796-ref12">12</xref>] ，目标检测 [<xref ref-type="bibr" rid="hanspub.19796-ref13">13</xref>] 等领域取得了巨大的成功，被证明能够自动从图像中有效的提取对分类结果有益的特征 [<xref ref-type="bibr" rid="hanspub.19796-ref14">14</xref>] ，避免了人工设计并抽取特征的过程。本文的分类算法流程图如图1所示。首先利用堆叠自动编码机对高光谱数据进行光谱维上的降维，然后将卷积神经网络作为分类器，将以待分类像元为中心的矩形内的高光谱数据立方体作为卷积神经网络的输入，进行空谱联合分类，获得最终的分类结果。</p></sec><sec id="s4"><title>2. 基于堆叠自编码网络的高光谱数据降维</title><p>自动编码网络由其基本单位——自动编码机堆叠而成。自动编码机是一个三层前馈神经网络，由输入层，隐藏层，重构层构成。自动编码机的编码及解码过程如公式 [<xref ref-type="bibr" rid="hanspub.19796-ref15">15</xref>] (1) (2)：</p><disp-formula id="hanspub.19796-formula104"><label>(1)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-2610086x9_hanspub.png"  xlink:type="simple"/></disp-formula><disp-formula id="hanspub.19796-formula105"><label>(2)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-2610086x10_hanspub.png"  xlink:type="simple"/></disp-formula><p>式中，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2610086x11_hanspub.png" xlink:type="simple"/></inline-formula>是原始数据的特征表达，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2610086x12_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2610086x13_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2610086x14_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2610086x15_hanspub.png" xlink:type="simple"/></inline-formula>分别为输入层到隐藏层，隐藏层到重构层的权重及偏移系数，一般取<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2610086x16_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2610086x17_hanspub.png" xlink:type="simple"/></inline-formula>为非线性映射函数，一般取为sigmoid函数，即：</p><disp-formula id="hanspub.19796-formula106"><label>(3)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-2610086x18_hanspub.png"  xlink:type="simple"/></disp-formula><p>通过调节<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2610086x19_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2610086x20_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2610086x21_hanspub.png" xlink:type="simple"/></inline-formula>使得输入<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2610086x22_hanspub.png" xlink:type="simple"/></inline-formula>和重构<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2610086x23_hanspub.png" xlink:type="simple"/></inline-formula>之间相似。一般采用交叉熵函数衡量<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2610086x24_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2610086x25_hanspub.png" xlink:type="simple"/></inline-formula>之间的距离，训练时采用分批训练，每一批的样本数为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2610086x26_hanspub.png" xlink:type="simple"/></inline-formula>，则损失函数为：</p><disp-formula id="hanspub.19796-formula107"><label>(4)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-2610086x27_hanspub.png"  xlink:type="simple"/></disp-formula><p>公式(4)中，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2610086x28_hanspub.png" xlink:type="simple"/></inline-formula>是每一批训练样本的个数，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2610086x29_hanspub.png" xlink:type="simple"/></inline-formula>是输入层与重构层的维数。</p><p>使用随机梯度下降训练网络参数，参数的更新规则为(<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2610086x30_hanspub.png" xlink:type="simple"/></inline-formula>代表学习率)：</p><disp-formula id="hanspub.19796-formula108"><label>(5)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-2610086x31_hanspub.png"  xlink:type="simple"/></disp-formula><disp-formula id="hanspub.19796-formula109"><label>(6)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-2610086x32_hanspub.png"  xlink:type="simple"/></disp-formula><disp-formula id="hanspub.19796-formula110"><label>(7)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-2610086x33_hanspub.png"  xlink:type="simple"/></disp-formula><p>图1. 本文分类流程</p><p>自动编码网络由若干个自动编码机层叠而成，上一层自动编码机隐藏层的输出作为下一层自动编码机的输出层的输入。其训练共分为三个阶段 [<xref ref-type="bibr" rid="hanspub.19796-ref15">15</xref>] ，共包括预训练，展开和微调3个步骤：</p><p>步骤1 预训练过程。逐层训练组成自动编码网络的多个自动编码机，下层自动编码机隐藏层单元输出作为其上层自动编码机的输入参与训练。</p><p>步骤2 展开过程。预训练完成后，下层AE输出单元与其上层AE合并为一层，将多个AE连接成一个自动编码深度网络。</p><p>步骤3 微调过程。展开的自动编码网络采用反向传播算法对预训练得到的初始权值进一步调整，进一步减少误差。</p></sec><sec id="s5"><title>3. 基于卷积神经网络的空谱联合分类</title><p>卷积神经网络由卷积层，池化层，全连接层和softmax分类层组成 [<xref ref-type="bibr" rid="hanspub.19796-ref15">15</xref>] 。一般地，在卷积层中对网络的输入或者前一个隐藏层的输出进行卷积操作生成特征图，卷积操作生成的每一张特征图都会与偏置项<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2610086x35_hanspub.png" xlink:type="simple"/></inline-formula>相加，随后非线性激活函数会作用在特征图中的每一个像素上。接下来，池化层会以非重叠的方式从每一个特征图中选取局部的主特征，也就是对特征图进行降维操作。整个过程可以用公式 [<xref ref-type="bibr" rid="hanspub.19796-ref16">16</xref>] 表示为：</p><disp-formula id="hanspub.19796-formula111"><label>(8)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-2610086x36_hanspub.png"  xlink:type="simple"/></disp-formula><p>式中，*代表卷积操作，pool代表最大化池操作。</p><p>数个卷积层和池化层交替重叠能够从输入中逐层的提取特征。之后，提取的特征在拉伸成为一个向量后送入全连接层。在全连接层，首先通过与权重矩阵<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2610086x37_hanspub.png" xlink:type="simple"/></inline-formula>相乘和偏置<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2610086x38_hanspub.png" xlink:type="simple"/></inline-formula>相加进行线性变换，然后将非线性函数作用在变换后的每一个分量上，有：</p><disp-formula id="hanspub.19796-formula112"><label>(9)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-2610086x39_hanspub.png"  xlink:type="simple"/></disp-formula><p>激活函数<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2610086x40_hanspub.png" xlink:type="simple"/></inline-formula>取公式(3)中的sigmoid函数。全连接层的输出被送至softmax层进行分类。卷积神经网络中的参数为权重矩阵<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2610086x41_hanspub.png" xlink:type="simple"/></inline-formula>以及偏置<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2610086x42_hanspub.png" xlink:type="simple"/></inline-formula>。网络通过反向传播算法进行训练，损失函数为：</p><disp-formula id="hanspub.19796-formula113"><label>(10)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-2610086x43_hanspub.png"  xlink:type="simple"/></disp-formula><p>通过使用随机梯度下降 [<xref ref-type="bibr" rid="hanspub.19796-ref11">11</xref>] 算法获得最优的参数值<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2610086x44_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2610086x45_hanspub.png" xlink:type="simple"/></inline-formula>。</p><p>为了对降维后的高光谱数据进行空谱联合的分类，本文设计了如图2所示的卷积神经网络结构。取以待分类像元为中心的矩形内的数据立方体作为卷积神经网络的输入，取矩形的大小为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2610086x46_hanspub.png" xlink:type="simple"/></inline-formula>，则网络输入的尺寸为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2610086x47_hanspub.png" xlink:type="simple"/></inline-formula>，其中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2610086x48_hanspub.png" xlink:type="simple"/></inline-formula>是高光谱图像降维后的光谱维度。与一般的图像分类方法，如人脸识别相比，本文分类任务的空间维度并不高，因此本文的卷积神经网络中不包含池化层的空间降维操作。卷积神经网络由三个卷积层，一个全连接层和一个softmax分类层组成。每个卷积层的卷积核大小为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2610086x49_hanspub.png" xlink:type="simple"/></inline-formula>，卷积核的个数为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2610086x50_hanspub.png" xlink:type="simple"/></inline-formula>，全连接层的输入维数均为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2610086x51_hanspub.png" xlink:type="simple"/></inline-formula>，输出维数为30，softmax分类层的输入个数为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2610086x52_hanspub.png" xlink:type="simple"/></inline-formula>，输出个数为高光谱图像中的地物种类数。</p></sec><sec id="s6"><title>4. 实验和分析</title><sec id="s6_1"><title>4.1. 实验数据集描述</title><p>本实验使用两组高光谱数据集检验本文算法的分类性能，分别是IndianPines数据集和University of Pavia数据集。前者为AVIRIS采集的农业区高光谱图像，图像大小为145像素 &#215; 145像素，共包含220个波段，去掉其中的20个水吸收严重的波段，得到包含200个波段的高光谱数据。后者为ROSIS采集</p><p>图2. 用于高光谱图像分类的卷积神经网络结构</p><p>的城区高光谱图像，图像大小为610像素 &#215; 340像素，共包含115个波段，去除其中水吸收严重的12个波段，将其余103个波段作为高光谱数据。Indian Pines数据以及University of Pavia数据的假彩色图及标记模板如图3(a)、图3(b)和图4(a)、图4(b)所示。</p></sec><sec id="s6_2"><title>4.2. 实验结果与讨论</title><sec id="s6_2_1"><title>4.2.1 . Indian Pines数据集</title><p>为了证实本文的算法确实有效，将本文的算法与以下分类算法进行对比：</p><p>1) PCA-SVM [<xref ref-type="bibr" rid="hanspub.19796-ref9">9</xref>] ：利用主成分分析对高光谱图像进行降维，然后采用SVM方法进行分类。</p><p>2) Autoencoder-SVM [<xref ref-type="bibr" rid="hanspub.19796-ref15">15</xref>] ：利用自编码网络对高光谱进行降维，然后使用SVM分类器进行分类，此结果用于证明Autoencoder在降维方面的优越性。</p><p>3) PCA-MOR-SVM [<xref ref-type="bibr" rid="hanspub.19796-ref9">9</xref>] ：利用主成分分析对高光谱数据进行降维，然后对前3个主成分提取形态学特征作为光谱特征的补充 [<xref ref-type="bibr" rid="hanspub.19796-ref1">1</xref>] ，接下来采用SVM分类器进行分类</p><p>4) PCA-CNN：利用主成分分析对高光谱数据降维，然后使用本文提出的卷积神经网络进行分类。</p><p>PCA和Autoencoder在降维方面各有优势，PCA能够用较少的维数表示原始数据中的大部分信息，而SAE则能够更好的保留数据的特征。本文的堆叠自动编码机的结构参照文献 [<xref ref-type="bibr" rid="hanspub.19796-ref14">14</xref>] 设置，经过堆栈自动编码机降维后的数据维数为40，自动编码机具有4层结构，每一层的节点数为200-40-40-40。在1)中同样取前40个主成分进行分类；在2)中利用SAE降维后的维数为40，并且使用SVM进行分类；在3)中</p><p>图3. Indian Pines数据集分类结果。(a) 假彩色图像；(b) 分类参考图；(c) PCA-SVM: 80.47%；(d) Autoencoder-SVM: 85.48%；(e) PCA-MOR-SVM: 91.13%；(f) PCA-CNN: 95.27%；(g) Autoencoder-CNN: 98.64%</p><p>图4. Indian Pines数据集分类结果。(a) 假彩色图像；(b) 分类参考图；(c) SVM: 80.01%；(d) Autoencoder-SVM: 94.14%；(e) PCA-MOR-SVM: 98.16%；(f) PCA-CNN: 98.56%；(g) Autoencoder-CNN: 99.26%</p><p>同样取前40个主成分进行分类，并且依据文献建立半径为2的圆形结构元素，对前3个主成分进行四次开闭运算，得到的形态学特征作为光谱特征的补充；在4)取PCA降维后的前40个主成分，并使用本文提出的CNN进行空谱联合分类。表1给出了图像详细的训练训练集的个数，测试集的个数以及分类数量。图3中为一次实验的结果图，图5是每一种地物的分类情况。从视觉角度看，仅利用光谱信息的分类对噪声比较敏感，分类结果中含有许多许多细小斑点，而综合利用光谱与空间信息的方法则能够获得比较完整的地物区域。</p></sec><sec id="s6_2_2"><title>4.2.2. University of Pavia数据集</title><p>为了进一步证明本文的算法确实有效，使用同样的方法对University of Pavia数据集进行分类。PCA降维方式同样保留前40个主成分，Autoencoder的结构为103-40-40-40，即使用深度为4的自动编码网络进行降维处理，降维后的光谱维度为40。Pavia大学数据集的类别数量以及训练和测试样本数量如表2所示，图4为分类的结果，图6为每一类地物分类的精度。从Pavia大学数据的分类结果可以得到与</p><p>图5. Indian Pines数据分类精度</p><p>图6. Pavia University数据分类精度</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Class labels and train-test distribution of samples for the Indian Pines dataset</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >No</th><th align="center" valign="middle" >Name</th><th align="center" valign="middle" >Train</th><th align="center" valign="middle" >Test</th></tr></thead><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" >Asphalt</td><td align="center" valign="middle" >10</td><td align="center" valign="middle" >36</td></tr><tr><td align="center" valign="middle" >2</td><td align="center" valign="middle" >Corn-notill</td><td align="center" valign="middle" >428</td><td align="center" valign="middle" >1000</td></tr><tr><td align="center" valign="middle" >3</td><td align="center" valign="middle" >Corn-minitill</td><td align="center" valign="middle" >200</td><td align="center" valign="middle" >630</td></tr><tr><td align="center" valign="middle" >4</td><td align="center" valign="middle" >Corn</td><td align="center" valign="middle" >47</td><td align="center" valign="middle" >197</td></tr><tr><td align="center" valign="middle" >5</td><td align="center" valign="middle" >Grass-pasture</td><td align="center" valign="middle" >150</td><td align="center" valign="middle" >333</td></tr><tr><td align="center" valign="middle" >6</td><td align="center" valign="middle" >Grass-tress</td><td align="center" valign="middle" >210</td><td align="center" valign="middle" >520</td></tr><tr><td align="center" valign="middle" >7</td><td align="center" valign="middle" >Grass-pasture-mowed</td><td align="center" valign="middle" >7</td><td align="center" valign="middle" >19</td></tr><tr><td align="center" valign="middle" >8</td><td align="center" valign="middle" >Hay-windrowed</td><td align="center" valign="middle" >119</td><td align="center" valign="middle" >360</td></tr><tr><td align="center" valign="middle" >9</td><td align="center" valign="middle" >Oats</td><td align="center" valign="middle" >6</td><td align="center" valign="middle" >14</td></tr><tr><td align="center" valign="middle" >10</td><td align="center" valign="middle" >Soybean-notill</td><td align="center" valign="middle" >300</td><td align="center" valign="middle" >672</td></tr><tr><td align="center" valign="middle" >11</td><td align="center" valign="middle" >Soybean-minitill</td><td align="center" valign="middle" >520</td><td align="center" valign="middle" >1935</td></tr><tr><td align="center" valign="middle" >12</td><td align="center" valign="middle" >Soybean-clean</td><td align="center" valign="middle" >100</td><td align="center" valign="middle" >493</td></tr><tr><td align="center" valign="middle" >13</td><td align="center" valign="middle" >Wheat</td><td align="center" valign="middle" >50</td><td align="center" valign="middle" >155</td></tr><tr><td align="center" valign="middle" >14</td><td align="center" valign="middle" >Woods</td><td align="center" valign="middle" >200</td><td align="center" valign="middle" >1065</td></tr><tr><td align="center" valign="middle" >15</td><td align="center" valign="middle" >Build-Grass-Tree-Drives</td><td align="center" valign="middle" >186</td><td align="center" valign="middle" >200</td></tr><tr><td align="center" valign="middle" >16</td><td align="center" valign="middle" >Stone-Steel-Towers</td><td align="center" valign="middle" >30</td><td align="center" valign="middle" >63</td></tr></tbody></table></table-wrap><p>表1. Indian Pines高光谱影像的类别和样本数</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> Class labels and train-test distribution of samples for the University of Pavi</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >No</th><th align="center" valign="middle" >Name</th><th align="center" valign="middle" >Train</th><th align="center" valign="middle" >Test</th></tr></thead><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" >Asphalt</td><td align="center" valign="middle" >2231</td><td align="center" valign="middle" >4400</td></tr><tr><td align="center" valign="middle" >2</td><td align="center" valign="middle" >Meadows</td><td align="center" valign="middle" >6993</td><td align="center" valign="middle" >12,493</td></tr><tr><td align="center" valign="middle" >3</td><td align="center" valign="middle" >Gravel</td><td align="center" valign="middle" >609</td><td align="center" valign="middle" >1440</td></tr><tr><td align="center" valign="middle" >4</td><td align="center" valign="middle" >Trees</td><td align="center" valign="middle" >1099</td><td align="center" valign="middle" >2064</td></tr><tr><td align="center" valign="middle" >5</td><td align="center" valign="middle" >Painted Metal Sheets</td><td align="center" valign="middle" >401</td><td align="center" valign="middle" >945</td></tr><tr><td align="center" valign="middle" >6</td><td align="center" valign="middle" >Bare Soil</td><td align="center" valign="middle" >1500</td><td align="center" valign="middle" >4029</td></tr><tr><td align="center" valign="middle" >7</td><td align="center" valign="middle" >Bitumen</td><td align="center" valign="middle" >300</td><td align="center" valign="middle" >1030</td></tr><tr><td align="center" valign="middle" >8</td><td align="center" valign="middle" >Self-Blocking Bricks</td><td align="center" valign="middle" >1000</td><td align="center" valign="middle" >2682</td></tr><tr><td align="center" valign="middle" >9</td><td align="center" valign="middle" >Shadows</td><td align="center" valign="middle" >300</td><td align="center" valign="middle" >647</td></tr></tbody></table></table-wrap><p>表2. Indian大学高光谱影像的类别和样本数</p><p>之前的类似结论，即：1) 非线性降维方式优于线性降维方式；2) 加入空间信息有利于分类精度的提升；3) 使用卷积神经网络能够自动的提取对分类有利的特征。</p></sec></sec></sec><sec id="s7"><title>5. 结论</title><p>本文从限制高光谱图像分类精度的两点出发，提出了基于深度学习的高光谱图像分类方法。在降维方面，针对PCA等线性降维方式不能提取光谱维上的非线性特征这一问题，使用了自编码网络提取光谱维度的非线性信息；另外，设计了一种卷积神经网络结构，能够自动的提取对分类有利的空间特征，并在分类时能同理利用光谱信息和空间信息；从而获得比传统分类方法更精确的分类结果。</p></sec><sec id="s8"><title>文章引用</title><p>袁 林,胡少兴,张爱武,柴沙陀,王 兴. 基于深度学习的高光谱图像分类方法 A Classification Method for Hyperspectral Imagery Based on Deep Learning[J]. 人工智能与机器人研究, 2017, 06(01): 31-39. http://dx.doi.org/10.12677/AIRR.2017.61005</p></sec><sec id="s9"><title>参考文献 (References)</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.19796-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Landgrebe, D. (2002) Hyperspectral Image Data Analysis. Signal Processing Magazine, 19, 17-28.  
https://doi.org/10.1109/79.974718</mixed-citation></ref><ref id="hanspub.19796-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Wange, A., Lu, J., Cai, J., Wang, G. and Charm, T.J. (2015) Unsupervised Joint Feature Learning and Encoding for RGB-D Scene Labeling. IEEE Transactions on Image Process, 24, 4459-4473.  
https://doi.org/10.1109/TIP.2015.2465133</mixed-citation></ref><ref id="hanspub.19796-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Huges, G. (1968) On the Mean Accuracy of Statistical Pattern Recognizers. IEEE Transactions on Information Theory, 14, 55-63. https://doi.org/10.1109/TIT.1968.1054102</mixed-citation></ref><ref id="hanspub.19796-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Kuo, B.-C. and Landgrebe, D.A. (2004) Nonparametric Weighted Feature Extraction for Classification for Classification. IEEE Transactions on Geoscience and Remote Sensing, 42, 1096-1105.  
https://doi.org/10.1109/TGRS.2004.825578</mixed-citation></ref><ref id="hanspub.19796-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Landgrebe, D.A. (2003) Signal Theory Methods in Multispectral Remote Sensing. Wiley, Hoboken.</mixed-citation></ref><ref id="hanspub.19796-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Liu, Y., Gu, Y. and Zhang, Y. (2006) Hyperspectral Feature Extraction Using Selective PCA Based on Genetic Algorithm with Subgroups. 1st International Conference on Innovative Computing, Information and Control, Beijing, 30 August-1 September 2006, 652-656.</mixed-citation></ref><ref id="hanspub.19796-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Zhao, Y., Zhang, L., Li, P. and Huang, B. (2007) Classification of High Spatial Resolution Imagery Using Improved Gaussian Markov Random-Field-Based Texture Features. IEEE Transactions on Geoscience and Remote Sensing, 45, 1458-1468. https://doi.org/10.1109/TGRS.2007.892602</mixed-citation></ref><ref id="hanspub.19796-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Xu, H., Li, P. and Shen, Y. (2008) The Application of Invariant Moments to High Resolution Remote Sensing Image Classification. Remote Sensing for Land &amp; Resources, 20, 9-13.</mixed-citation></ref><ref id="hanspub.19796-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Luo, B. and Zhang, L. (2014) Robust Autodual Morphological Profiles for the Classification of High-Resolution Satellite Images. IEEE Transactions on Geoscience and Remote Sensing, 52, 1451-1462.  
https://doi.org/10.1109/TGRS.2013.2251468</mixed-citation></ref><ref id="hanspub.19796-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Bengio, Y., Lamblin, P., Popovici, D., et al. (2007) Greedy Layer-Wise Training of Deep Networks. Advances in Neural Information Processing Systems, 19, 153.</mixed-citation></ref><ref id="hanspub.19796-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Fukushima, K. (1988) Neocognitron: A Hierarchical Neural Network Capable of Visual Pattern Recognition. Neural Networks, 1, 119-130. https://doi.org/10.1016/0893-6080(88)90014-7</mixed-citation></ref><ref id="hanspub.19796-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">LeCun, Y., Bottou, L., Bengio, Y. and Haffner, P. (1998) Gradient-Based Learning Applied to Document Recognition. Proceedings of the IEEE, 86, 2278-2323. https://doi.org/10.1109/5.726791</mixed-citation></ref><ref id="hanspub.19796-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Taigman, Y., Yang, M., Ranzato, M. and Wolf, L. (2014) DeepFace: Closing the Gap to Human-Level Performance in Face Verification. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Columbus, 23-28 June 2014, 1701-1708.</mixed-citation></ref><ref id="hanspub.19796-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">Sainath, T.N., Mohamed, A.-R., Kingsbury, B. and Ramabhadran, B. (2013) Deep Convolutional Neural Networks for LVCSR. Proceedings of the 38th IEEE International Conference on Acoustics, Speech, and Signal Processing, Vancouver, 26-31 May 2013, 8614-8618. https://doi.org/10.1109/icassp.2013.6639347</mixed-citation></ref><ref id="hanspub.19796-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">Chen, Y., Lin, Z., Zhao, X., Wang, G. and Gu, Y. (2014) Deep Learning-Based Classification of Hyperspectral Data. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 7, 2094-2107.  
https://doi.org/10.1109/JSTARS.2014.2329330</mixed-citation></ref><ref id="hanspub.19796-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">Lawrence, S., Giles, C.L., Tsoi, A.C. and Back, A.D. (1997) Face Recognition: A Convolutional Neural-Network Approach. IEEE Transactions on Neural Networks, 8, 98-113. https://doi.org/10.1109/72.554195</mixed-citation></ref></ref-list></back></article>