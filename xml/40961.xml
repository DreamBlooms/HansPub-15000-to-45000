<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">AAM</journal-id><journal-title-group><journal-title>Advances in Applied Mathematics</journal-title></journal-title-group><issn pub-type="epub">2324-7991</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/AAM.2021.103076</article-id><article-id pub-id-type="publisher-id">AAM-40961</article-id><article-categories><subj-group subj-group-type="heading"><subject>AAM20210300000_15601349.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>数学与物理</subject></subj-group></article-categories><title-group><article-title>
 
 
  计算机试验下Kriging模型选择的比较
  Comparison of Model Selection for Kriging Model in Computer Experiments
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>李</surname><given-names>涵</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>赵</surname><given-names>建昕</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>王</surname><given-names>晓</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>李</surname><given-names>新民</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib></contrib-group><aff id="aff3"><addr-line>海军潜艇学院基础部，山东 青岛</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><aff id="aff2"><addr-line>青岛大学数学与统计学院，山东 青岛</addr-line></aff><pub-date pub-type="epub"><day>10</day><month>03</month><year>2021</year></pub-date><volume>10</volume><issue>03</issue><fpage>694</fpage><lpage>700</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
  
    Kriging模型是计算机试验的一种常用模型，因具有良好的非线性拟合能力而被广泛使用。本文在一般Kriging模型相关研究的基础上，研究了Kriging模型的变量选择问题，并给出了Elastic Net变量选择方法。与Lasso和adaptive Lasso相比，数值模拟表明Elastic Net变量选择方法能够提高拟合模型的准确性和稳定性。
    Kriging model is a common model of computer experiment, which is widely used because of its good nonlinear fitting ability. Based on the research of Kriging model, this paper studies the variable selection of universal Kriging model, and gives the variable selection method of Elastic Net. Compared with Lasso and adaptive Lasso, numerical simulation shows that Elastic Net variable selection method can improve the accuracy and stability of the fitting model. 
  
 
</p></abstract><kwd-group><kwd>Kriging模型，模型选择，Elastic Net，Lasso, Kriging Model</kwd><kwd> Model Selection</kwd><kwd> Elastic Net</kwd><kwd> Lasso</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>摘要</title><p>Kriging模型是计算机试验的一种常用模型，因具有良好的非线性拟合能力而被广泛使用。本文在一般Kriging模型相关研究的基础上，研究了Kriging模型的变量选择问题，并给出了Elastic Net变量选择方法。与Lasso和adaptive Lasso相比，数值模拟表明Elastic Net变量选择方法能够提高拟合模型的准确性和稳定性。</p></sec><sec id="s2"><title>关键词</title><p>Kriging模型，模型选择，Elastic Net，Lasso</p></sec><sec id="s3"><title>Comparison of Model Selection for Kriging Model in Computer Experiments<sup> </sup></title><p>Han Li<sup>1</sup>, Jianxin Zhao<sup>2</sup>, Xiao Wang<sup>1</sup>, Xinmin Li<sup>1</sup></p><p><sup>1</sup>School of Mathematics and Statistics, Qingdao University, Qingdao Shandong</p><p><sup>2</sup>Basic Courses Department, Navy Submarine Academy, Qingdao Shandong</p><p><img src="//html.hanspub.org/file/7-2621496x4_hanspub.png" /></p><p>Received: Feb. 11<sup>th</sup>, 2021; accepted: Mar. 8<sup>th</sup>, 2021; published: Mar. 16<sup>th</sup>, 2021</p><p><img src="//html.hanspub.org/file/7-2621496x5_hanspub.png" /></p></sec><sec id="s4"><title>ABSTRACT</title><p>Kriging model is a common model of computer experiment, which is widely used because of its good nonlinear fitting ability. Based on the research of Kriging model, this paper studies the variable selection of universal Kriging model, and gives the variable selection method of Elastic Net. Compared with Lasso and adaptive Lasso, numerical simulation shows that Elastic Net variable selection method can improve the accuracy and stability of the fitting model.</p><p>Keywords:Kriging Model, Model Selection, Elastic Net, Lasso</p><disp-formula id="hanspub.40961-formula41"><graphic xlink:href="//html.hanspub.org/file/7-2621496x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2021 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/7-2621496x7_hanspub.png" /> <img src="//html.hanspub.org/file/7-2621496x8_hanspub.png" /></p></sec><sec id="s5"><title>1. 引言</title><p>随着科技的不断进步与发展，计算机试验作为物理实验的替代和辅助正在变得越来越流行。计算机试验的一个主要目标是构建一个廉价的元模型。Kriging模型最初是由南非的地质学家Krige在地质统计学中提出并发展的，Sacks等 [<xref ref-type="bibr" rid="hanspub.40961-ref1">1</xref>] 于1989年将Kriging模型引入到计算机试验中。从此，Kriging模型作为一种重要的元模型，在农业、工业、化学、生物等领域中有着广泛的应用。</p><p>Kriging模型包含平稳高斯过程和均值函数两部分。当均值函数只有一个常数时，称Ordinary Kriging模型；大部分的Kriging模型被假设均值函数部分已存在一些已知变量，这样的模型称为Universal Kriging模型(简称UK)。当模型中包含大量的输入变量时，识别那些(相对较少的)对响应有显著影响的变量是很重要的。Welch等人 [<xref ref-type="bibr" rid="hanspub.40961-ref2">2</xref>] 提出可以通过计算机试验进行变量选择，并且指出在保持均值函数不变的情况下，选择对高斯过程有显著影响的变量是非常有意义的。</p><p>计算机试验中常用的变量选择方法为贝叶斯方法和惩罚似然方法。对于贝叶斯变量选择，Linkletter等 [<xref ref-type="bibr" rid="hanspub.40961-ref3">3</xref>] 提出了高斯过程的贝叶斯选择方法；Huang等 [<xref ref-type="bibr" rid="hanspub.40961-ref4">4</xref>] 提出一种盲Kriging模型下对均值函数的变量进行随机搜索的贝叶斯选择方法。对于惩罚似然方法，Li等 [<xref ref-type="bibr" rid="hanspub.40961-ref5">5</xref>] 提出高斯过程的惩罚似然变量选择方法，Hung [<xref ref-type="bibr" rid="hanspub.40961-ref6">6</xref>] 提出了对均值函数进行Lasso和adaptive Lasso惩罚的似然方法，Zhang等 [<xref ref-type="bibr" rid="hanspub.40961-ref7">7</xref>] 提出了一种均值函数的新的惩罚方法，并从贝叶斯观点出发证明了该方法的有效性。</p><p>本文研究均值函数的惩罚似然变量选择方法，在Lasso和adaptive Lasso惩罚似然变量的基础上，提出Elastic Net (弹性网络)惩罚。本文的结构如下：第二部分介绍Kriging模型及其参数估计的算法；第三部分介绍了几种变量选择方法及其算法；第四部分通过数据模拟对Kriging模型的几种变量选择方法进行比较；第五部分实例分析，得出结论。</p></sec><sec id="s6"><title>2. Kriging模型简述</title><p>已知n个观察点，记为 X n = ( x 1 , x 2 , ⋯ , x n ) T ， Y = ( y 1 , y 2 , ⋯ , y n ) T ， y i = y ( x i ) 是点 x i 对应的输出，其中 y i ∈ R ， i = 1 , 2 , ⋯ , n 。d为设计变量x的维数。一般Kriging模型可写成如下形式：</p><p>y ( x ) = ∑ j = 1 d f j ( x ) β j + z ( x ) = f T ( x ) β + z ( x ) = m ( x ) + z ( x ) . (2.1)</p><p>其中 m ( x ) 是均值函数， f j ( x ) , j = 0 , 1 , ⋯ , d 是已知的基函数， f ( x ) = ( f 1 ( x ) , ⋯ , f d ( x ) ) T 是基向量，d表示回归函数中基函数的个数， β j 是未知系数， β = ( β 1 , ⋯ , β d ) T 是未知的回归系数向量， z ( x ) 是一个高斯随机过程且满足均值为0，即 E ( z ( x ) ) = 0 ，协方差函数为</p><p>cov ( z ( x i ) , z ( x j ) ) = σ 2 c ( ψ ; x i , x j ) ,   i , j = 1 , 2 , ⋯ , n . (2.2)</p><p>在许多计算机试验的文献中 [<xref ref-type="bibr" rid="hanspub.40961-ref8">8</xref>]，常用的相关函数为指数相关函数，Matern相关函数及高斯相关函数。本文仅考虑高斯相关函数</p><p>c ( ψ ; x i , x j ) = exp ( − ∑ i = 0 d | x i − x j | ψ i 2 ) . (2.3)</p><p>这里的 ψ 是自相关系数， ψ = ( ψ 1 , ⋯ , ψ d ) 。</p><p>Santner等 [<xref ref-type="bibr" rid="hanspub.40961-ref8">8</xref>] 表明最大似然估计优于交叉验证估计，所以本文使用最大似然估计来估计参数，对数似然函数为</p><p>l ( β , σ 2 , ψ ) = − n 2 lg ( 2 π ) − n 2 lg ( σ 2 ) − 1 2 lg | C ( ψ ) | − 1 2 σ 2 ( y − F β ) T C − 1 ( ψ ) ( y − F β ) (2.4)</p><p>这里的 F = ( f ( x 1 ) , ⋯ , f ( x n ) ) T 是 n &#215; d 的设计矩阵， C ( ψ ) 是高斯随机过程 z ( x ) 的相关矩阵，第ij个元素为 c ( x i , x j ) 。在(2.4)中， ( β , σ 2 , ψ ) 均未知。首先假设 ψ 已知，则 ( β , σ 2 ) 的估计可以通过最大化(2.4)得到：</p><p>β ^ = ( F T C − 1 ( ψ ) F ) − 1 F − 1 C − 1 ( ψ ) y ,(2.5)</p><p>σ ^ 2 = 1 n ( y − F β ) T C − 1 ( ψ ) ( y − F β ) .(2.6)</p><p>此时，(2.4)的最大值为：</p><p>l max = − n 2 ( 1 + lg ( 2 π ) ) − 1 2 ( n log σ ^ 2 + log | C ( ψ ) | ) . (2.7)</p><p>之后设定 ψ 未知，通过最大化(2.7)得到 ψ 的估计：</p><p>ψ ^ = arg min ψ { n log σ ^ 2 + log | C ( ψ ) | } .(2.8)</p><p>与其它模型相比，Kriging模型可以同时提供预测位置的预测值和预测误差，假定要预测 x ∗ 处的函数值， y ^ ( x ∗ ) 表示该点的一个预测值，那么 y ^ ( x ∗ ) 的最佳线性无偏估计(BLUP)为</p><p>y ^ ( x ∗ ) = f T ( x ∗ ) β ^ + c ( x ∗ , D ) C − 1 ( y − F β ^ ) .</p><p>其中， c ( x ∗ , D ) 是一个 1 &#215; n 的向量，第i个元素是 c ( x ∗ , x i ) 。</p></sec><sec id="s7"><title>3. Kriging模型的变量选择方法和算法</title><p>考虑Kriging模型的变量选择时，设候选基变量为 f ( x ) = ( 1 , f 1 ( x ) , ⋯ , f p ( x ) ) T ， β = ( β 0 , β 1 , ⋯ , β p ) T ， Z ( x ) 是均值为0，相关矩阵为 C ( ⋅ , ⋅ ) 的高斯过程。为了选出 F ( x ) 中的重要变量，参数 β 需要通过最大化惩罚下面的似然函数估计得到</p><p>Q ( β , σ 2 , ψ ) = l ( β , σ 2 , ψ ) − ∑ i = 1 t P λ ( | β i | ) .</p><p>这里的 l ( β , σ 2 , ψ ) 是(2.4)， P λ 是惩罚函数。</p><p>本节首先给出Hung [<xref ref-type="bibr" rid="hanspub.40961-ref6">6</xref>] 提出的Lasso方法和adaptive Lasso方法 [<xref ref-type="bibr" rid="hanspub.40961-ref9">9</xref>]，然后提出Elastic Net方法。</p><sec id="s7_1"><title>3.1. Lasso惩罚似然方法</title><p>为了估计惩罚Kriging模型中的参数，Hung [<xref ref-type="bibr" rid="hanspub.40961-ref6">6</xref>] 提出了重加权最小角度回归算法(IRLARS)，此算法比较容易实施，因此本文所使用的三种惩罚似然方法都要在此算法的框架下进行。</p><p>下面详述Lasso惩罚的IRLARS算法，而adaptive Lasso惩罚在Lasso惩罚算法的基础上稍加修改。Lasso惩罚的IRLARS算法如下：</p><p>算法1. Kriging模型Lasso惩罚的IRLARS算法</p><p>对于adaptive Lasso惩罚的变量选择方法 [<xref ref-type="bibr" rid="hanspub.40961-ref9">9</xref>]，是在Lasso的基础上，引入一个已知的权重向量 w j ，则adaptive Lasso惩罚下参数 β 的参数估计为：</p><p>β ^ a l ( n ) = arg min β ‖ y − ∑ j = 1 p x j β j ‖ 2 + λ n ∑ j = 1 p w ^ j | β j | . (3.1)</p><p>这里的 w ^ = 1 / | β ^ | γ ， γ &gt; 0 。在本文研究中， w ^ 中的 β ^ 使用最小二乘估计，即 β ^ = β ^ o l s ， γ = 1 。对应的算法只需对算法1中的Step 2稍加修改：</p><p>Step 2*：分解 C ( ψ ^ ( l ) ) − 1 / σ ^ ( l ) 2 = R ′ R ，得到 y * = R y ， X * = R X ， F * * = F * / ν = R F / ν ，利用交叉验证得到Lasso惩罚下的最优惩罚参数 λ ，求解Lasso问题，</p><p>β ^ ( l + 1 ) = arg min ‖ y * − F * β ‖ 2 + λ ∑ j = 1 p | β j | . (3.2)</p><p>迭代 β ^ j ( l + 1 ) = β ^ j * / ν j ，这里的 ν = | β ^ o l s | 。</p></sec><sec id="s7_2"><title>3.2. Elastic Net惩罚似然方法</title><p>对于Elastic Net惩罚的变量选择方法 [<xref ref-type="bibr" rid="hanspub.40961-ref10">10</xref>]，对于固定的非负 λ 1 ， λ 2 ，参数 β 的Elastic Net估计可通过下式求解，</p><p>β ^ E n e t = arg min β { ‖ Y ˜ − X ˜ T β ‖ 2 + λ 2 ‖ β ‖ 2 + λ 1 ‖ β ‖ 1 } . (3.3)</p><p>其中， ‖ β ‖ 2 = ∑ j = 1 p β i 2 ， ‖ β ‖ 1 = ∑ j = 1 p | β i | 。由此可见Elastic Net的罚函数是岭回归与Lasso的凸组合。本文研究中，最优惩罚参数 λ 依旧通过交叉验证得到， α = 0.7 。</p><p>由Elastic Net方法的定义可以看出，当(3.3)式中 λ 2 = 0 时，Elastic Net方法就变成了Lasso方法，因此Elastic Net方法结合岭回归与Lasso的优点，既能达到变量选择目的，又具有很好的群组效应。于是只需对算法1中的Step 2稍加修改：</p><p>Step 2**：分解 C ( ψ ^ ( l ) ) − 1 / σ ^ ( l ) 2 = R ′ R ，得到 y * = R y ， X * = R X ， F * * = F * / ν = R F / ν ，利用交叉验证得到Elastic Net惩罚下的最优惩罚参数 λ ，求解Elastic Net问题，</p><p>β ^ ( l + 1 ) = arg min ‖ y * − F * β ‖ 2 + λ 2 ‖ β ‖ 2 + λ 1 ‖ β ‖ 1 .</p></sec></sec><sec id="s8"><title>4. 数据模拟</title><p>本节对函数模型做UK模型拟合(UK)，对UK做Lasso惩罚(LUK)，对UK做adaptive Lasso惩罚(ALUK)，和对UK做Elastic Net惩罚(ENUK)，并对这些方法进行比较，最终从变量识别的准确性和预测精度这两方面进行评价。变量识别的准确性用以下三个指标：积极变量识别率的平均(AEIR)；消极变量识别率的平均(IEIR)；积极变量个数的平均(MEAN)。预测精度用以下两个指标来评估：均方根预测误差(RMSPE)的平均值MRMSPE及标准差(sd(RMSPE))。假设有 n 0 个预测点 x 1 * , ⋯ , x n 0 * ， y ^ ( x j * ) 是 x j * 的BLUP，则RMSPE的计算公式如下RMSPE：</p><p>RMSPE = 1 n 0 ∑ j = 1 n 0 ( y ( x j * ) − y ^ ( x j * ) ) 2</p><p>显然，AEIR越大越好，IEIR，RMSPE，sd(RMSPE)越小越好，MEAN越接近真模型越好。</p><sec id="s8_1"><title>4.1. 数据模拟1：已知函数</title><p>为了评估模型分别加入惩罚前后在预测精度及变量识别方面的性能，我们考虑一个已知线性函数模型 [<xref ref-type="bibr" rid="hanspub.40961-ref4">4</xref>]。这个已知函数模型被定义在12维(p = 12)的输入空间 [ 0 , 1 ] 12 上，其模型的前六个变量 x 1 , ⋯ , x 6 对计算机试验输出的影响逐渐变小，其余变量 x 7 , ⋯ , x 12 与输出无关(即零系数)。真模型为：</p><p>y ( x ) = 0.4 x 1 + 0.3 x 2 + 0.2 x 3 + 0.1 x 4 + 0.05 x 5 + 0.01 x 6 + ε . (4.1)</p><p>这里的 ε ~ N ( 0 , σ ε 2 ) ， σ ε = 0.05 。响应值y使用(4.1)独立产生，在Matlab上，通过拉丁超立方抽样生成维数p=12，样本量分别为N=50,80,100的样本D，候选变量C由所有的一阶主效应组成。用计算机随机生成的1000个样本点作为测试集G。基于500次的重复试验，模拟结果在表1中给出。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Data simulation results of function model (4.1</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >样本容量</th><th align="center" valign="middle" >方法</th><th align="center" valign="middle" >AEIR (%)</th><th align="center" valign="middle" >IEIR (%)</th><th align="center" valign="middle" >MEAN</th><th align="center" valign="middle" >MRMSPE</th><th align="center" valign="middle" >sd (RMSPE)</th></tr></thead><tr><td align="center" valign="middle"  rowspan="4"  >N = 50</td><td align="center" valign="middle" >UK</td><td align="center" valign="middle" >100</td><td align="center" valign="middle" >100</td><td align="center" valign="middle" >12.00</td><td align="center" valign="middle" >0.0658</td><td align="center" valign="middle" >0.0057</td></tr><tr><td align="center" valign="middle" >LUK</td><td align="center" valign="middle" >70.97</td><td align="center" valign="middle" >12.27</td><td align="center" valign="middle" >4.99</td><td align="center" valign="middle" >0.0636</td><td align="center" valign="middle" >0.0095</td></tr><tr><td align="center" valign="middle" >ALUK</td><td align="center" valign="middle" >70.13</td><td align="center" valign="middle" >12.13</td><td align="center" valign="middle" >4.94</td><td align="center" valign="middle" >0.0638</td><td align="center" valign="middle" >0.0098</td></tr><tr><td align="center" valign="middle" >ENUK</td><td align="center" valign="middle" >71.07</td><td align="center" valign="middle" >13.30</td><td align="center" valign="middle" >5.06</td><td align="center" valign="middle" >0.0638</td><td align="center" valign="middle" >0.0096</td></tr><tr><td align="center" valign="middle"  rowspan="4"  >N = 80</td><td align="center" valign="middle" >UK</td><td align="center" valign="middle" >100</td><td align="center" valign="middle" >100</td><td align="center" valign="middle" >12.00</td><td align="center" valign="middle" >0.0601</td><td align="center" valign="middle" >0.0039</td></tr><tr><td align="center" valign="middle" >LUK</td><td align="center" valign="middle" >80.27</td><td align="center" valign="middle" >11.60</td><td align="center" valign="middle" >5.51</td><td align="center" valign="middle" >0.0578</td><td align="center" valign="middle" >0.0060</td></tr><tr><td align="center" valign="middle" >ALUK</td><td align="center" valign="middle" >81.00</td><td align="center" valign="middle" >12.10</td><td align="center" valign="middle" >5.59</td><td align="center" valign="middle" >0.0576</td><td align="center" valign="middle" >0.0057</td></tr><tr><td align="center" valign="middle" >ENUK</td><td align="center" valign="middle" >81.40</td><td align="center" valign="middle" >13.00</td><td align="center" valign="middle" >5.66</td><td align="center" valign="middle" >0.0574</td><td align="center" valign="middle" >0.0055</td></tr><tr><td align="center" valign="middle"  rowspan="4"  >N = 100</td><td align="center" valign="middle" >UK</td><td align="center" valign="middle" >100</td><td align="center" valign="middle" >100</td><td align="center" valign="middle" >12.00</td><td align="center" valign="middle" >0.0580</td><td align="center" valign="middle" >0.0030</td></tr><tr><td align="center" valign="middle" >LUK</td><td align="center" valign="middle" >82.27</td><td align="center" valign="middle" >8.57</td><td align="center" valign="middle" >5.45</td><td align="center" valign="middle" >0.0563</td><td align="center" valign="middle" >0.0040</td></tr><tr><td align="center" valign="middle" >ALUK</td><td align="center" valign="middle" >82.20</td><td align="center" valign="middle" >8.90</td><td align="center" valign="middle" >5.47</td><td align="center" valign="middle" >0.0564</td><td align="center" valign="middle" >0.0040</td></tr><tr><td align="center" valign="middle" >ENUK</td><td align="center" valign="middle" >82.37</td><td align="center" valign="middle" >9.73</td><td align="center" valign="middle" >5.53</td><td align="center" valign="middle" >0.0563</td><td align="center" valign="middle" >0.0039</td></tr></tbody></table></table-wrap><p>表1. 函数模型(4.1)的数据模拟结果</p><p>通过表1数据可以发现，从MRMSPE上分析，UK模型都高于LUK，ALUK和ENUK模型，这说明对线性模型进行变量选择可以一定程度上提高模型的预测精度，但LUK，ALUK和ENUK模型的预测精度相差不大。从识别率方面分析，ENUK的积极变量识别率AEIR和识别个数MEAN均高于LUK和ALUK。但LUK的消极变量识别率IEIR低于LUK和ENUK。对于均值函数为多项式模型，模拟结果说明变量选择能够提高预测精度，并且ENUK方法的积极变量识别的准确性方面有明显优势，但消极变量识别率没有优势。</p></sec><sec id="s8_2"><title>4.2. 数据模拟2：钻孔函数</title><p>考虑钻孔函数 [<xref ref-type="bibr" rid="hanspub.40961-ref11">11</xref>] 如下：</p><p>y ( x ) = 2 π x 3 ( x 4 − x 6 ) { log ( x 2 x 1 ) ( 1 + 2 x 3 x 4 log ( x 2 / x 1 ) x 1 2 x 8 + x 3 x 5 ) } − 1 (4.2)</p><p>输入空间是一个矩形区间[0.05, 0.015] &#215; [100, 5000] &#215; [63,070, 115,600] &#215; [990, 1110] &#215; [63.1, 116] &#215; [700, 820] &#215; [1120, 1680] &#215; [9855, 12,045]，拟合模型形式为 y ^ ( x ) = m ( x ) + z ( x ) ，设定均值函数形式为 m ( x ) = β 0 + β 1 x 1 + ⋯ + β 8 x 8 。在Matlab上，通过拉丁超立方抽样生成n = 100，d = 8的样本D，计算机随机生成1000个样本点作为测试集G，计算均方根预测误差RMSPE。同样地，对(4.2)做UK, LUK, ALUK, ENUK几种方法的拟合。重复进行500次试验，并计算每种情况下的MRMSPE以及标准差sd (RMSPE)得到表2。</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> Data simulation results of the functional model (4.2</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >方法 指标</th><th align="center" valign="middle" >UK</th><th align="center" valign="middle" >LUK</th><th align="center" valign="middle" >ALUK</th><th align="center" valign="middle" >ENUK</th></tr></thead><tr><td align="center" valign="middle" >AEIR (%)</td><td align="center" valign="middle" >100.00</td><td align="center" valign="middle" >98.42</td><td align="center" valign="middle" >98.36</td><td align="center" valign="middle" >98.57</td></tr><tr><td align="center" valign="middle" >MEAN</td><td align="center" valign="middle" >8.00</td><td align="center" valign="middle" >7.87</td><td align="center" valign="middle" >7.87</td><td align="center" valign="middle" >7.89</td></tr><tr><td align="center" valign="middle" >MRMSPE</td><td align="center" valign="middle" >1.0963</td><td align="center" valign="middle" >0.0115</td><td align="center" valign="middle" >0.0113</td><td align="center" valign="middle" >0.0118</td></tr><tr><td align="center" valign="middle" >sd (RMSPE)</td><td align="center" valign="middle" >2.9280</td><td align="center" valign="middle" >0.0028</td><td align="center" valign="middle" >0.0027</td><td align="center" valign="middle" >0.0029</td></tr></tbody></table></table-wrap><p>表2. 函数模型(4.2)的数据模拟结果</p><p>从表2数据可以看出，从MRMSPE和sd (RMSPE)的数据分析，UK模型的MRMSPE和sd (RMSPE)远高于LUK, ALUK和ENUK模型，这说明对非线性模型进行变量选择也可以一定程度上提高模型的预测精度，但LUK, ALUK和ENUK模型的预测精度相差不大。从变量选择方面分析，ENUK的识别个数MEAN高于LUK和ALUK。对于均值函数为多项式模型，模拟结果表明变量选择能够提高预测精度，并且ENUK方法的变量识别有优势。这说明在真实模型为非线性模型的条件下，变量选择大大提高了参数估计的准确性与稳定性。</p></sec></sec><sec id="s9"><title>5. 实例分析：活塞拍击噪声</title><p>本节应用本文提出的对Kriging模型做变量选择的各种方法，对一个活塞拍击噪声的实例进行分析。活塞拍击是由活塞二次运动引起的一种不必要的发动噪声。通过计算机试验，改变六种因素来减少排挤噪声。这六种因素分别为活塞与缸套之间的间隙下x<sub>1</sub>，峰值压力的位置x<sub>2</sub>，活塞裙部长度x<sub>3</sub>，裙部型线x<sub>4</sub>，裙部椭圆轮廓x<sub>5</sub>，活塞销偏置x<sub>6</sub>。实例的相关数据集来源于Huang [<xref ref-type="bibr" rid="hanspub.40961-ref4">4</xref>]，数据包括100个观测值，6个输入变量，候选变量集C包括，所有的线性主效应，二次主效应，正交多项式编码下的两因素交叉效应 [<xref ref-type="bibr" rid="hanspub.40961-ref12">12</xref>]，因此C一共包含72个基变量。本研究进行5折交叉验证，每次将100个观测值随机选出80个数据作为训练集用于构建模型，剩下的20个作为预测集用于计算RMSPE，比较UK模型，OK模型，以及分别作Lasso，adaptive Lasso，Elastic Net惩罚前后的MRMSPE，sd (RMSPE)，MEAN。比较UK模型，以及分别做Lasso，adaptive Lasso，Elastic Net惩罚后得到的LUK，ALUK，ENUK的MRMSPE，sd(RMSPE)， MEAN。模拟结果如表3所示。</p><table-wrap id="table3" ><label><xref ref-type="table" rid="table3">Table 3</xref></label><caption><title> Data simulation results of a piston slap noise exampl</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >方法 指标</th><th align="center" valign="middle" >UK</th><th align="center" valign="middle" >LUK</th><th align="center" valign="middle" >ALUK</th><th align="center" valign="middle" >ENUK</th></tr></thead><tr><td align="center" valign="middle" >MEAN</td><td align="center" valign="middle" >72.00</td><td align="center" valign="middle" >14.00</td><td align="center" valign="middle" >14.20</td><td align="center" valign="middle" >15.80</td></tr><tr><td align="center" valign="middle" >MRMSPE</td><td align="center" valign="middle" >0.3187</td><td align="center" valign="middle" >0.1459</td><td align="center" valign="middle" >0.1637</td><td align="center" valign="middle" >0.1264</td></tr><tr><td align="center" valign="middle" >sd (RMSPE)</td><td align="center" valign="middle" >0.2470</td><td align="center" valign="middle" >0.0259</td><td align="center" valign="middle" >0.0491</td><td align="center" valign="middle" >0.0214</td></tr></tbody></table></table-wrap><p>表3. 活塞拍击噪声实例的数据模拟结果</p><p>从表3的数据可以看出，ENUK的MRMSPE和sd (RMSPE)远比UK, LUK和ALUK模型小；模型变量的个数远低于UK，而且ENUK模型的变量个数与LUK和ALUK相差不大。通过这个实例结果显示，使用ENUK方法可以有效简化模型的同时还可以降低均方预测误差。</p></sec><sec id="s10"><title>6. 结论</title><p>本文在一般Kriging模型相关研究的基础上，研究了Kriging模型的变量选择问题，并给出了Elastic Net变量选择方法。模拟结果和实例验证表明，Elastic Net变量选择方法与Lasso和adaptive Lasso相比，Elastic Net能够提高拟合模型的准确性和稳定性。</p></sec><sec id="s11"><title>文章引用</title><p>李 涵,赵建昕,王 晓,李新民. 计算机试验下Kriging模型选择的比较Comparison of Model Selection for Kriging Model in Computer Experiments[J]. 应用数学进展, 2021, 10(03): 694-700. https://doi.org/10.12677/AAM.2021.103076</p></sec><sec id="s12"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.40961-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Sacks, J., Welch, W.J., Mitchell, T.J. and Wynn, H.P. (1989) Design and Analysis of Computer Experiments. Statistical Science, 4, 409-423. &lt;br&gt;https://doi.org/10.1214/ss/1177012413</mixed-citation></ref><ref id="hanspub.40961-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Welch, W.J., Buck, R.J. and Sacks, J. (1992) Screening, Predicting, and Computer Experiments. Technometrics, 34, 15-25. &lt;br&gt;https://doi.org/10.2307/1269548</mixed-citation></ref><ref id="hanspub.40961-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Linkletter, C., Bingham, D. and Hengartner, N. (2006) Variable Selection for Gaussian Process Models in Computer Experiments. Technometrics, 48, 478-490. &lt;br&gt;https://doi.org/10.1198/004017006000000228</mixed-citation></ref><ref id="hanspub.40961-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Huang, H., Lin, D.K.J., Liu, M.Q. and Zhang, Q. (2019) Variable Selection for Kriging in Computer Experiments. Journal of Quality Technology, 52, 1-14. &lt;br&gt;https://doi.org/10.1080/00224065.2019.1569959</mixed-citation></ref><ref id="hanspub.40961-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Li, R. and Sudjianto, A. (2005) Analysis of Computer Experiments Using Penalized Likelihood in Gaussian Kriging Models. Tecnometrics, 47, 111-120. &lt;br&gt;https://doi.org/10.1198/004017004000000671</mixed-citation></ref><ref id="hanspub.40961-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Hung, Y. (2011) Penalized Blind Kriging in Computer Experiments. Statistica Sinica, 21, 1171-1190.  
&lt;br&gt;https://doi.org/10.5705/ss.2009.226</mixed-citation></ref><ref id="hanspub.40961-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Zhang, Y., Yao, W., Ye, S. and Chen, X. (2019) A Regularization Method for Constructing Trend Function in Kriging Model. Structural and Multidisciplinary Optimization, 59, 1221-1239. &lt;br&gt;https://doi.org/10.1007/s00158-018-2127-8</mixed-citation></ref><ref id="hanspub.40961-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Santner, T.J., Williams, B.J. and Notz, W.I. (2003) The Design and Analysis of Computer Experiments. Springer, New York. &lt;br&gt;https://doi.org/10.1007/978-1-4757-3799-8</mixed-citation></ref><ref id="hanspub.40961-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Zou, H. (2006) The Adaptive Lasso and Its Oracle Properties. Journal of the American Statistical Association, 101, 1418-1429. &lt;br&gt;https://doi.org/10.1198/016214506000000735</mixed-citation></ref><ref id="hanspub.40961-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Zou, H. and Hastie, T. (2005) Regularization and Variable Selection via the Elastic Net. Journal of the Royal Statistical Society, 67, 301-320. &lt;br&gt;https://doi.org/10.1111/j.1467-9868.2005.00503.x</mixed-citation></ref><ref id="hanspub.40961-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Worley, B.A. (1987) Deterministic Uncertainty Analysis. Oak Ridge National Lab, TN, USA.</mixed-citation></ref><ref id="hanspub.40961-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Altland, H.W. (2001) Experiments: Planning, Analysis, and Parameter Design Optimization. Technometrics, 43, 368-369.  
&lt;br&gt;https://doi.org/10.1198/004017001316975952</mixed-citation></ref></ref-list></back></article>