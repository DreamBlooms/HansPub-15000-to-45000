<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">GST</journal-id><journal-title-group><journal-title>Geomatics Science and Technology</journal-title></journal-title-group><issn pub-type="epub">2329-549X</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/GST.2018.63017</article-id><article-id pub-id-type="publisher-id">GST-25753</article-id><article-categories><subj-group subj-group-type="heading"><subject>GST20180300000_20367440.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>工程技术</subject></subj-group></article-categories><title-group><article-title>
 
 
  约束性神经网络及其在目标方向估计中的应用
  Constrained Neural Network and Its Application in Target Direction Estimation
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>刘</surname><given-names>进</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>刘</surname><given-names>淑敏</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>方</surname><given-names>高</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>武汉大学测绘遥感信息工程国家重点实验室，湖北 武汉</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><author-notes><corresp id="cor1">* E-mail:<email>291446679@qq.com(刘淑)</email>;</corresp></author-notes><pub-date pub-type="epub"><day>05</day><month>07</month><year>2018</year></pub-date><volume>06</volume><issue>03</issue><fpage>151</fpage><lpage>164</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
  目前，在计算机视觉领域，主流的卷积神经网络算法专注于目标的识别和定位，且大多数采用轴对齐包围盒定位目标，而为了对图像做更深刻的语义理解，更加精准地定位各类目标，需要获取目标的方向信息。因此，本文提出一种针对图像目标方向估计的方法，采用卷积神经网络对描述目标方向的两个方向角分量进行回归，规避一些现有方向估计方法直接对方向角回归而产生的缺点。由于方向分量之间存在平方和为1的函数约束，本文提出约束性神经网络的概念，进一步提出利用约束性神经网络解决这类带有输出约束问题的一般性方法，即在Loss层引入约束误差，参与反向传播，并将其具体运用于目标方向估计中。经实验，本文采用的基于约束性神经网络的目标方向估计方法，能够在保证原输出损失的下降速度和幅度的前提下，降低约束误差，提高估计精度。
   At present, the mainstream convolutional neural network (CNN) approaches focus on the recogni-tion and positioning of targets in the field of computer vision. Most locate the position of targets with axis-aligned bounding boxes. In order to make a deeper understanding of the images and obtain more accurate position of various targets, the direction information is needed. Therefore, a new method is proposed to estimate the target direction, which applies CNN to regress the two di-rectional components of the target direction angle that describes the direction, instead of directly regressing the direction angle like some existing approaches which shows some shortcomings. Considering the function constraint of the square sum of 1 between the directional components, this paper proposes a general method to solve this kind of problems with output constraints by using constrained neural network, which introduces constraint errors into the Loss layer and the back propagation process, and applies it in the target direction estimation. Experiments show that, the target direction estimation method maintains the descent rate and range of the original output loss and moreover, reduce the constraint error and improve the prediction accuracy. The significance lies in proposing a general method to solve a kind of problems with output constraints, which reduces constraint errors, and shows general applicability.
 
</p></abstract><kwd-group><kwd>卷积神经网络，输出约束，目标方向估计，方向分量, CNN</kwd><kwd> Output Constraints</kwd><kwd> Target Direction Estimation</kwd><kwd> Directional Components</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>约束性神经网络及其在目标方向估计中的应用<sup> </sup></title><p>刘进，刘淑敏<sup>*</sup>，方高</p><p>武汉大学测绘遥感信息工程国家重点实验室，湖北 武汉</p><disp-formula id="hanspub.25753-formula3"><graphic xlink:href="//html.hanspub.org/file/1-2840178x5_hanspub.png"  xlink:type="simple"/></disp-formula><p>收稿日期：2018年6月11日；录用日期：2018年6月28日；发布日期：2018年7月5日</p><disp-formula id="hanspub.25753-formula4"><graphic xlink:href="//html.hanspub.org/file/1-2840178x6_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>目前，在计算机视觉领域，主流的卷积神经网络算法专注于目标的识别和定位，且大多数采用轴对齐包围盒定位目标，而为了对图像做更深刻的语义理解，更加精准地定位各类目标，需要获取目标的方向信息。因此，本文提出一种针对图像目标方向估计的方法，采用卷积神经网络对描述目标方向的两个方向角分量进行回归，规避一些现有方向估计方法直接对方向角回归而产生的缺点。由于方向分量之间存在平方和为1的函数约束，本文提出约束性神经网络的概念，进一步提出利用约束性神经网络解决这类带有输出约束问题的一般性方法，即在Loss层引入约束误差，参与反向传播，并将其具体运用于目标方向估计中。经实验，本文采用的基于约束性神经网络的目标方向估计方法，能够在保证原输出损失的下降速度和幅度的前提下，降低约束误差，提高估计精度。</p><p>关键词 :卷积神经网络，输出约束，目标方向估计，方向分量</p><disp-formula id="hanspub.25753-formula5"><graphic xlink:href="//html.hanspub.org/file/1-2840178x7_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2018 by authors and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/1-2840178x8_hanspub.png" /> <img src="//html.hanspub.org/file/1-2840178x9_hanspub.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>近年来，神经网络发展迅速，尤其是卷积神经网络(Convolutional Neural Network, CNN) [<xref ref-type="bibr" rid="hanspub.25753-ref1">1</xref>] ，已经广泛应用于计算机视觉、语音识别、医学研究以及智能博弈等诸多领域，且仍在不断更新迭代。对于其中一个热点问题——图像目标检测，R-CNN [<xref ref-type="bibr" rid="hanspub.25753-ref2">2</xref>] 是将CNN方法引入进来的一个里程碑，随后衍生出系列研究Fast R-CNN [<xref ref-type="bibr" rid="hanspub.25753-ref3">3</xref>] 、Faster R-CNN [<xref ref-type="bibr" rid="hanspub.25753-ref4">4</xref>] 等，2016年YOLO [<xref ref-type="bibr" rid="hanspub.25753-ref5">5</xref>] 的提出，将目标的分类和位置检测作为一个整体回归问题进行求解，在识别速度上实现了重大突破，接着，SSD [<xref ref-type="bibr" rid="hanspub.25753-ref6">6</xref>] 、YOLO9000 [<xref ref-type="bibr" rid="hanspub.25753-ref7">7</xref>] 等进一步提高了目标检测的速度和精度。</p><p>然而人们并不仅仅满足于获取目标的类别和位置信息，还希望从图像中挖掘更多的信息，例如目标的方向信息，这样就可以对图像做出更深刻的语义理解，产生更多的应用，例如利用目标的方向信息对图像进行纠正，预测与目标特定方向相关联事件的发生概率，再如估计出动态目标的方向信息就能预测其意图等。另外，对于在原始图像上标记目标所在位置，上述方法均采用传统的轴对齐包围盒来标记目标，而针对任意角度倾斜的目标，特别是倾斜的细长条状物体，如船只、车辆、铅笔等，如果可以预测出目标的方向，更适合使用带有方向信息的倾斜包围盒进行定位，这样可以更加准确地包含目标，减少框内背景信息比例，增加包围盒的信息利用率，同时在目标密集区域也可大大减少多个包围盒之间的重叠率，更有效地区分不同目标个体，传统包围盒与倾斜包围盒的对比图如图1所示。</p><p>所以，对目标方向估计的研究很有价值。目前，针对目标方向估计也有不少研究，如文献 [<xref ref-type="bibr" rid="hanspub.25753-ref8">8</xref>] 提出R<sup>2</sup>CNN检测任意方向的文字目标，先粗预测文字的轴对齐包围盒，再通过不同尺度池化层提取的特征，精化轴对齐包围盒，再得到最小倾斜包围盒，非直接预测倾斜包围盒；文献 [<xref ref-type="bibr" rid="hanspub.25753-ref9">9</xref>] 采用有方向的SSD检测任意方向的车辆，直接将描述方向的方向角纳入到目标包围盒的属性数据中进行回归；文献 [<xref ref-type="bibr" rid="hanspub.25753-ref10">10</xref>] 则预先设定几组特定角度的旋转盒，预测时在各个位置基于这些预设的旋转盒及不同类型目标比例特征分子任务进行预测，且包围盒中也是添加一项方向角描述方向。但是，由于方向角度值 θ 在旋转一整周后，即从360˚</p><p>图1. 传统包围盒与倾斜包围盒的对比图</p><p>到0˚处角度的数值存在突变，而实际上360˚和0˚是指的同一方向，所以如果直接使用 θ 进行回归，网络在0˚和360˚处的预测值在数值上极有可能会存在很大误差。</p><p>本文采用目标方向 θ 的两个单位方向分量 ( x , y ) ( sin θ , cos θ ) ，作为卷积神经网络的输入数据和预测数据，因为 sin θ 和 cos θ 在 θ ∈ [ 0 ∘ , 360 ∘ ) 上具有单调性和连续性，不会出现上述突变问题。而由于方向分</p><p>量为单位矢量，即两个输出分量存在平方和为1的函数约束，这就会引入一个新问题，即如何确保神经网络输出的矢量是单位矢量。传统神经网络的主体思想是建立从输入到输出的数学模型，通过大量有标注的样本数据对模型进行训练，解算出其中未知的模型参数，最终得到完整的模型。而在诸多实际应用中，网络输出往往存在很多约束，例如需要满足某一值域范围，如图像目标框的长宽为正数，或是需要满足某种函数关系式，比如本文方向估计方法中的输出矢量分量平方和等于1，本文将这种具有输出约束的神经网络称作约束性神经网络，探讨使用约束性神经网络解决一类具有约束问题的一般性方法，将其具体应用于目标方向估计中。</p></sec><sec id="s4"><title>2. 约束性神经网络</title><p>传统神经网络的主体思想是，给定一个从输入X到输出Y的数学模型 Y = f ( W , X ) ，其中X是输入矢量，Y是输出矢量，W是参数矢量，通过给定大量样本数据集 ( x i , y i ) ，其中 i = 1 , 2 , ⋯ , n ，列出联合方程式，使用优化算法解算出模型参数W，最终建立从输入X到输出Y的完整数学模型。</p><p>然而，在不同的实际问题中，输入X与输出Y之间往往关系复杂，并非简单的线性关系可以表示，且输出Y多会有值域上的范围约束(本文中称作弱约束)，或多个输出分量之间存在函数约束(本文中称作强约束)，所以不论用多少样本都是有限的，无法完整和精确地描述模型，对于一个新样本 x i ∗ ，经过神经</p><p>网络前向传播输出的 y i ∗ = f ( W , x i ∗ ) ，不可能永远满足各项约束，这就提出一类新的问题——如何对现有</p><p>神经网络进行改进，使其不仅符合有限样本集的约束，而且满足各种实际问题的约束，进而使得一些以前不方便直接用神经网络解决的问题也能得到解决。因此本文的意义在于提出一种解决一类具有约束问题的一般性方法。</p><sec id="s4_1"><title>2.1. 弱约束</title><p>弱约束是指输出Y在值域上存在范围约束。例如，预测图像目标定位框的宽高，输出的值域范围是 [ 0 , + ∞ ) ；利用人脸图像预测年龄，输出的值域范围可以设为 [ 0 , 100 ] 等。</p><p>神经网络原始输出的值域范围是 ( − ∞ , + ∞ ) ，为了满足弱约束，一般性解决方案是采用输出转换函数 ϕ ( y ) ，将原始输出变换到要求的值域区间。输出转换函数 ϕ ( y ) 必须满足以下两个特性：</p><p>1) 单调，这样转换才具有唯一性；</p><p>2) 输出值域与问题期待值域范围一致。</p><p>在网络进行前向传播时，使用输出转换函数对原始输出进行转换，对误差进行反向传播时根据链式求导法则求出对应的偏导值，进行权值修正。</p><p>事实上，常用的几个激励函数可以作为输出转换函数使用，对于值域为 ( − ∞ , + ∞ ) 的原始输出，tanh函数可将其映射到 [ − 1 , 1 ] 区间上；sigmoid函数可将其映射到 [ 0 , 1 ] 区间上，而为避免梯度消失的问题，现在很少在中间层使用；ReLU函数可将正数保持不变，非正数全部映射成0，由于会丢失掉负数部分的信息，不宜作为输出转换函数。另外，也可根据实际问题，构造合适的输出转换函数，例如在预测图像目标定位框的宽高问题上，可在前向传播时，使用指数函数 ϕ ( y i ) = e y i 对神经网络输出值进行转换，将 y i ∈ ( − ∞ , + ∞ ) 映射到 ϕ ( y i ) ∈ ( 0 , + ∞ ) 上。</p></sec><sec id="s4_2"><title>2.2. 强约束</title><p>强约束是指根据问题需要，对输出矢量Y的内部某些分量有函数约束，以 φ ( y ) = 0 表示。对于不同问题，约束函数 φ ( y ) 的形式各不相同。</p><p>如果约束函数关系简单，比如只存在线性关系，也可通过输出转换函数实现。在经典的图像目标分类问题中，需要输出目标属于各个类别的概率，且概率总和为1，取其中概率最大者对应的类别作为该目标的预测类别，此问题中输出Y的各个分量需满足 ∑ i = 1 n y i = 1 ， y i ∈ [ 0 , 1 ] ，即输出约束函数 φ ( y ) = ∑ i = 1 n y i − 1 = 0 ， y i ∈ [ 0 , 1 ] ，由于</p><disp-formula id="hanspub.25753-formula6"><label>(1)</label><graphic position="anchor" xlink:href="//html.hanspub.org/file/1-2840178x42_hanspub.png"  xlink:type="simple"/></disp-formula><p>能很好地满足该约束要求，所以使用softmax函数作为转换输出函数，在神经网络最后加一个softmax层即可解决该分类问题。</p><p>但是，在很多复杂情况下，约束函数非线性，很难找到合适的输出转换函数，由此，本文提出一种解决这类问题的一般性方案。</p><p>当输出矢量Y的分量间有单个强约束函数关系 φ ( y ) = 0 时，那么在构建神经网络时，不仅需要将最终预测的 y ˜ i 分量与真值 y &#175; i 作比较求误差，以 D i f f y 表示，则</p><p>D i f f y = y ˜ i − y &#175; i (2)</p><p>还需要考虑 y ˜ i 分量之间的约束关系，增加一个约束误差计算，即计算 φ ( y ˜ ) 并与约束值真值0相减求误差，定义约束误差函数为 E r r o r φ ，则</p><p>E r r o r φ = φ ( y ˜ ) − 0 = φ ( y ˜ ) (3)</p><p>考虑约束误差的完整网络结构如图2所示。</p><p>在利用大量样本集进行网络训练的过程中，通过误差反向传播对各权值进行修正，反向传播采用经典的梯度下降法 [<xref ref-type="bibr" rid="hanspub.25753-ref11">11</xref>] ，计算式如下。</p><p>使用均方差定义输出损失函数 L o s s y ，则</p><p>L o s s y = 1 2 ∑ i = 1 n ( y ˜ i − y &#175; i ) 2 (4)</p><p>L o s s y 在反向传播时，对 y ˜ i 的偏导为</p><p>图2. 带有单个输出约束的神经网络结构图</p><p>∂ L o s s y ∂ y ˜ i = y ˜ i − y &#175; i (5)</p><p>约束误差的平方为</p><p>E r r o r φ 2 = ( φ ( y ˜ ) − 0 ) 2 = φ 2 ( y ˜ ) (6)</p><p>E r r o r φ 2 在反向传播时，对 y ˜ i 的偏导为</p><p>∂ E r r o r φ 2 ∂ y ˜ i = 2 φ ( y ˜ ) &#215; ∂ φ ( y ˜ ) ∂ y ˜ i (7)</p><p>记总体误差为 E sum ，则</p><p>E sum = λ ⋅ E r r o r φ 2 + L o s s y (8)</p><p>其中 λ 为约束误差的常数系数。</p><p>则 E sum 在反向传播时，对 y ˜ i 的偏导为</p><p>∂ E sum ∂ y ˜ i = λ ∂ E r r o r φ 2 ∂ y ˜ i + ∂ L o s s y ∂ y ˜ i (9)</p><p>代入公式(5)和(7)，则 E sum 对 y ˜ i 的偏导为</p><p>∂ E sum ∂ y ˜ i = 2 λ ⋅ φ ( y ˜ ) &#215; ∂ φ ( y ˜ ) ∂ y ˜ i + ( y ˜ i − y &#175; i ) (10)</p><p>权值修正根据导数的链式法则计算，例如，可通过下式更新权值 w ″ k i ，</p><p>∂ E sum ∂ w ″ k i = ∂ E sum ∂ y ˜ i &#215; ∂ y ˜ i ∂ w ″ k i (11)</p><p>w ″ k i + = w ″ k i − η ⋅ ∂ E sum ∂ w ″ k i (12)</p><p>其中 η 为神经网络的学习率。</p><p>其他部分与传统神经网络处理方法一致，由此对网络中所有权值进行更新迭代，得到模型最佳参数矢量W。</p><p>考虑约束误差的反向传播过程如图3所示。</p><p>如果输出分量 y i 之间具有N个输出约束 φ j ( y ) = 0 ，其中 j = 1 , 2 , ⋯ , N ，同理，在网络中对应增加N个约束误差计算，每个约束误差函数为 E r r o r φ i ，则</p><p>E r r o r φ j = φ j ( y ˜ ) − 0 = φ j ( y ˜ ) (13)</p><p>构建如图4所示的带有N个输出约束的神经网络。</p><p>此时，总体误差为</p><p>E sum = ∑ j = 1 N λ j ⋅ E r r o r φ j 2 + L o s s y (14)</p><p>其中 λ j 为各个约束误差的常数系数。</p><p>图3. 带有单个输出约束的神经网络反向传播示意图</p><p>图4. 带有N个输出约束的神经网络结构图</p><p>则 E sum 在反向传播时，对 y ˜ i 的偏导为</p><p>∂ E sum ∂ y ˜ i = ∑ j = 1 N λ j ∂ E r r o r φ j 2 ∂ y ˜ i + ∂ L o s s y ∂ y ˜ i = 2 ∑ j = 1 N λ j ⋅ φ j ( y ˜ ) &#215; ∂ φ j ( y ˜ ) ∂ y ˜ i + ( y ˜ i − y &#175; i ) (15)</p><p>同样通过链导原则进行权值修正和迭代更新，最终构建完整模型。</p><p>以上即为输出带有一个或多个强约束关系的神经网络的一般处理方案。约束性问题模型广泛存在，例如第二节将介绍的使用约束性神经网络预测目标方向分量，进而估计目标方向。</p></sec></sec><sec id="s5"><title>3. 目标方向估计</title><sec id="s5_1"><title>3.1. 网络输出设计</title><p>利用神经网络进行目标方向估计的主体思想是将目标方向作为卷积神经网络的一个输入对其进行训练，最终进行预测。首先，如图5所示，本文中定义的目标方向指，以朝上为标准方向，即0˚方向，顺</p><p>时针旋转 θ 角度为 θ 方向， θ ∈ [ 0 ∘ , 360 ∘ ) 。</p><p>但是，由于角度 θ 在旋转一整周后，即从360˚到0˚处角度的数值存在突变，而实际上360˚和0˚是指的同一方向，所以如果直接使用 θ 角度值进行回归，网络在0˚和360˚处的预测值在数值上极有可能会存在很大误差。所以本文采用目标方向 θ 的两个单位方向分量 ( x , y ) ( sin θ , cos θ ) ，作为卷积神经网络的输入数据和预测数据，因为 sin θ 和 cos θ 在 θ ∈ [ 0 ∘ , 360 ∘ ) 上具有单调性和连续性，不会出现上述问题，并且用预测出的一组方向分量，可以通过反三角函数公式并结合符号，唯一确认目标方向 θ ，实现目标方向估计。</p></sec><sec id="s5_2"><title>3.2. 方向分量间的强约束</title><p>令 ， y = cos θ 作为网络的输出，如图5所示，由于方向分量为单位矢量，即两个输出分量之间存在函数约束 x 2 + y 2 = 1 ，则目标方向估计神经网络就是输出带有单个强约束关系的神经网络，其强约束函数 φ 为</p><p>φ = x 2 + y 2 − 1 = 0 (16)</p></sec><sec id="s5_3"><title>3.3. 目标方向估计神经网络</title><p>为进行方向分量估计，现建立一个从输入图像I到输出方向分量 ( x , y ) 的卷积神经网络数学模型</p><p>图5. 目标方向角 θ 示意图</p><p>( x , y ) = f ( W , I ) ，其中W是参数矢量。通过给定大量样本图片 I i 和对应方向分量 ( x i , y i ) ，其中 i = 1 , 2 , ⋯ , n ，利用神经网络解算出模型参数W，最终建立从输入图像I到输出方向分量 ( x , y ) 的完整映射，实现对任一图像的方向估计。</p><p>本文神经网络结构参考Lenet-5经典模型 [<xref ref-type="bibr" rid="hanspub.25753-ref12">12</xref>] 的结构，在特征提取部分，同样使用两组卷积层和最大池化层最后通过一个全连接层提取图像的抽象特征；在特征映射部分，在保留图像目标识别功能的同时，网络中增加一条分支实现目标方向估计，即连接一个由两个神经元构成的全连接层，输出方向分量 ( x , y ) 。完整网络结构如图6所示。</p><p>目标识别部分的网络与Lenet-5一致，具体介绍方向估计部分的网络。由于两个输出分量 ( x , y ) 之间存在单个强约束 φ = x 2 + y 2 − 1 = 0 ，则按照本文第一节所述，考虑单个输出约束的网络结构如图7所示，其中网络的整个特征提取部分抽象为一个抽象特征层。</p><p>在图7中，不仅需要计算最终预测的估计值 ( x ˜ , y ˜ ) 与真值 ( x &#175; , y &#175; ) 之间的误差，以 D i f f θ 表示，则</p><p>D i f f θ = ( x ˜ − x &#175; ) + ( y ˜ − y &#175; ) (17)</p><p>还需要考虑输出 ( x ˜ , y ˜ ) 之间的约束关系 φ ，计算约束误差，约束误差函数为 E r r o r φ ，则</p><p>E r r o r φ = φ ˜ − 0 = x ˜ 2 + y ˜ 2 − 1 (18)</p><p>在利用大量标注有方向的图片样本集对网络进行训练的过程中，通过误差反向传播对各权值进行修正，过程示意图如图8所示。</p><p>权重更新计算推导如下。</p><p>图6. 基于Lenet-5的目标识别和方向估计网络结构图</p><p>图7. 考虑方向分量输出约束的神经网络结构图</p><p>图8. 考虑方向分量输出约束的神经网络反向传播示意图</p><p>Loss层中，使用均方差定义输出损失函数 L o s s θ ，则</p><p>L o s s θ = 1 2 ∑ [ ( x ˜ − x &#175; ) 2 + ( y ˜ − y &#175; ) 2 ] (19)</p><p>L o s s θ 在反向传播时，对 x ˜ 和 y ˜ 的偏导分别为</p><p>{ ∂ L o s s θ ∂ x ˜ = ( x ˜ − x &#175; ) ∂ L o s s θ ∂ y ˜ = ( y ˜ − y &#175; ) (20)</p><p>约束误差的平方为</p><p>E r r o r φ 2 = 1 4 ( φ − 0 ) 2 = 1 4 ( x ˜ 2 + y ˜ 2 − 1 ) 2 (21)</p><p>其中增加的系数 1 4 是为了平衡求偏导引入的系数。</p><p>则 E r r o r φ 2 在反向传播时，对 x ˜ 和 y ˜ 的偏导分别为</p><p>{ ∂ E r r o r φ 2 ∂ x ˜ = ( x ˜ 2 + y ˜ 2 − 1 ) ⋅ x ˜ ∂ E r r o r φ 2 ∂ y ˜ = ( x ˜ 2 + y ˜ 2 − 1 ) ⋅ y ˜ (22)</p><p>记总体误差为 E sum ，则</p><p>E sum = λ ⋅ E r r o r φ 2 + L o s s θ (23)</p><p>其中 λ 为约束误差的常数系数，实验中讨论 λ 的取值。</p><p>则 E sum 在反向传播时，对 x ˜ 和 y ˜ 的偏导分别为</p><p>{ ∂ E sum ∂ x ˜ = λ ∂ E r r o r φ 2 ∂ x ˜ + ∂ L o s s θ ∂ x ˜ ∂ E sum ∂ y ˜ = λ ∂ E r r o r φ 2 ∂ y ˜ + ∂ L o s s θ ∂ y ˜ (24)</p><p>代入公式(20)和(22)，则 E sum 对 x ˜ 和 y ˜ 的偏导为</p><p>{ ∂ E sum ∂ x ˜ = λ ⋅ ( x ˜ 2 + y ˜ 2 − 1 ) ⋅ x ˜ + ( x ˜ − x &#175; ) ∂ E sum ∂ y ˜ = λ ⋅ ( x ˜ 2 + y ˜ 2 − 1 ) ⋅ y ˜ + ( y ˜ − y &#175; ) (25)</p><p>权值修正根据导数的链式法则计算，例如，可通过下式更新权值 w k x 和 w k y ，</p><p>{ ∂ E sum ∂ w k x = ∂ E sum ∂ x ˜ &#215; ∂ x ˜ ∂ w k x ∂ E sum ∂ w k y = ∂ E sum ∂ y ˜ &#215; ∂ y ˜ ∂ w k y (26)</p><p>{ w k x + = w k x − η ⋅ ∂ E sum ∂ w k x w k y + = w k y − η ⋅ ∂ E sum ∂ w k y (27)</p><p>其中 η 为神经网络的学习率。</p><p>其他部分与传统神经网络处理方法一致，由此对网络中所有权值进行更新迭代，得到模型最佳参数矢量W。</p></sec><sec id="s5_4"><title>3.4. 方向角精度评定</title><p>神经网络预测出一组 ( cos θ ˜ , sin θ ˜ ) ，可以通过反三角函数公式 θ ˜ = arctan x ˜ y ˜ ，并结合 cos θ ˜ 和 sin θ ˜ 的符号，唯一确认目标方向预测值 θ ˜ 。若用 θ &#175; 表示真实值，那么方向角的估计误差 Δ θ 为</p><p>Δ θ = θ ˜ − θ &#175; (28)</p><p>而由于 θ 在360˚到0˚时数值有一个跳变，简单地利用该式计算可能会产生很大偏差。因为单个方向角的 l o s s 可以由公式(19)计算，将式中的方向分量分别用方向角的正弦和余弦展开，可以得到</p><p>l o s s = ( sin θ ˜ − sin θ &#175; ) 2 + ( cos θ ˜ − cos θ &#175; ) 2 2 = sin 2 θ ˜ + cos 2 θ ˜ + 1 2 − cos ( θ ˜ − θ &#175; ) (29)</p><p>cos ( Δ θ ) = sin 2 θ ˜ + cos 2 θ ˜ + 1 2 − l o s s (30)</p><p>所以，估计误差 Δ θ 可以由 l o s s 和方向分量估计值反算得到，即</p><p>| Δ θ | = arccos ( sin 2 θ ˜ + cos 2 θ ˜ + 1 2 − l o s s ) (31)</p><p>如果有N个样本测试，那么所有测试样本的方向估计均方误差E则为</p><p>E = ∑ i = 1 N Δ θ i 2 N = ∑ i = 1 N arccos 2 ( sin 2 θ ˜ i + cos 2 θ ˜ i + 1 2 − l o s s i ) N (32)</p><p>其中， i = 1 , 2 , ⋯ , N 。</p><p>这样，利用公式(31)和(32)计算得到的估计误差和均方误差不会因为角度值的跳变而出现突变。</p><p>公式(32)也反映了方向分量损失与方向估计精度的关系，当方向分量估计损失越小时，均方误差E越小，方向估计精度越高。</p><p>另外方向分量估计值的平方和也会影响估计误差，由于其存在 φ ˜ = sin 2 θ ˜ + cos 2 θ ˜ − 1 = 0 的约束，还需关注约束误差，约束误差由公式(18)和(21)计算得到，约束误差越小，方向估计精度越高。</p></sec></sec><sec id="s6"><title>4. 实验</title><sec id="s6_1"><title>4.1. 实验数据及运行环境</title><p>本文对高清航拍影像的飞机目标进行方向估计测试，原始数据来源于中科院大学高清航拍目标数据集UCAS-AOD [<xref ref-type="bibr" rid="hanspub.25753-ref13">13</xref>] 中的包含飞机目标的高清航拍影像，采用数据集中飞机目标位置标注数据裁剪出目标。整理后，最终使用893张影像内包含的6447架飞机作为训练集，104张影像内的1005架飞机作为测试集，比例约为6.4:1。部分实验样本示例图如图9所示。</p><p>目标方向为从飞机机尾指向机头的方向，编写方向标定程序对所有高清航拍影像中的飞机目标进行人工方向标注，首先画出从机尾到机头的直线，然后程序自动计算所画直线的方向角 θ 的两分量值，作为训练时的真值，存储在样本标定文本数据中。</p><p>本文全部程序采用C++语言，在Caffe框架下编写，Visual Studio 2013编译环境，硬件采用Intel i5-4210U处理器，1.7 GHz，8 G内存，单线程运行，无GPU加速。</p></sec><sec id="s6_2"><title>4.2. 实验步骤</title><sec id="s6_2_1"><title>4.2.1 . 训练</title><p>使用UCAS-AOD数据集中6447张飞机影像及相应的目标方向分量值作为学习数据，在Caffe框架下实现图6所示的网络结构，神经网络基础学习率 η = 0.01 ，分别采用不考虑输出约束的传统方法，即约束误差常数系数 λ = 0 ，和本文提出的考虑单个输出约束的方法，并考虑约束误差常数系数 λ 分别为0.5，1.0，1.5，对学习数据进行训练，迭代50,000次，得到训练模型，并绘制曲线观察每次迭代方向分量均方差Loss值和约束误差值的变化。</p><p>图9. 目标方向估计实验样本示例图</p></sec><sec id="s6_2_2"><title>4.2.2 . 测试</title><p>测试：使用UCAS-AOD中1005张飞机影像及相应的目标方向分量值作为测试数据，使用对应于训练网络的网络结构和训练得到的训练模型对测试数据进行方向估计，并采用方向角绘制程序将最终预测的方向显示展示出来。</p></sec></sec><sec id="s6_3"><title>4.3. 实验结果</title><p>训练过程中，当约束误差常数系数 λ 分别为0 (即不考虑约束误差的传统神经网络方法)、0.5、1.0及1.5时，目标方向分量的均方差损失和约束误差在前8000次迭代中的变化曲线如图10和图11所示。</p><p>图10. 目标方向分量均方差损失随迭代次数变化示意图</p><p>图11. 目标方向分量约束误差随迭代次数变化示意图</p><p>当约束误差常数系数不为0(红色曲线)时，即网络增加了约束误差的考量后，从图10中可以看出，目标方向分量的均方差损失值随迭代次数增加下降的速度和幅度与不考虑约束误差的传统方法几乎不变，维持在传统方法的水平；而从图11中可以明显看到，约束误差随迭代次数下降速度明显更快，且当约束误差趋于稳定时，约束性神经网络的方法得到的最终值比没有考虑约束的传统方法低近一倍。</p><p>因此，本文提出的方法，能提高约束误差下降的速度和幅度。而由公式(31)和(32)可以看出，减小约束误差，对减小方向估计误差是有作用的。因此，运用引入约束误差的约束化神经网络进行目标方向估计能够减小约束误差，提高方向估计精度。</p><p>关于约束误差常数系数 λ 的选择，在图10和图11中 λ 分别为0.5，1.0，1.5时，绿蓝黄三种曲线的走势相似，在此应用中，约束误差对整体预测的影响有一定限度，不过在实验发现，系数越大时网络越不容易收敛，所以建议在具体应用中，不宜使用较大的系数。</p><p>图12是使用约束误差常数系数 λ 为0.1的约束性神经网络，迭代50,000次的训练模型，对测试图片进行目标方向估计的部分结果图。</p></sec></sec><sec id="s7"><title>5. 结论与展望</title><p>本文提出了约束性神经网络的概念，进一步提出了在具体问题中网络输出分量间存在弱约束和强约束时的一般性处理方法，提供了考虑约束误差的新思路新方法，具有普适性和较高的应用价值。在图像目标方向估计的应用中，本文对描述目标方向的方向角的两个具有强约束关系的方向分量进行回归，故采用约束性神经网络，在Loss层引入约束误差，解决目标方向分量估计问题。实验表明，基于约束性神经网络的目标方向估计方法，能够在保证原输出损失的下降速度和幅度的前提下，减小约束误差，提高方向估计精度。</p><p>后续研究工作可以集中于采用结构更成熟的神经网络结构，实现利用目标的方向信息纠正图像、更加准确地定位任意角度倾斜的细长条状物体等一些具体应用，使用约束性神经网络解决更多具有输出约束的实际问题，如预测目标在三维空间内的方向等。</p></sec><sec id="s8"><title>致 谢</title><p>本文工作在刘进副教授的指导和方高硕士的帮助下完成，感谢中科院大学高清航拍目标数据集</p><p>图12. 测试图片目标方向估计的部分结果图</p><p>UCAS-AOD [<xref ref-type="bibr" rid="hanspub.25753-ref13">13</xref>] ，感谢国家自然科学基金项目“球面全方位目标测量及跟踪算法研究”(编号41271454)对本文工作的支持，特此致谢。</p></sec><sec id="s9"><title>基金项目</title><p>国家自然科学基金项目，编号41271454。</p></sec><sec id="s10"><title>文章引用</title><p>刘进,刘淑敏,方高. 约束性神经网络及其在目标方向估计中的应用 Constrained Neural Network and Its Application in Target Direction Estimation[J]. 测绘科学技术, 2018, 06(03): 151-164. https://doi.org/10.12677/GST.2018.63017</p></sec><sec id="s11"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.25753-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Krizhevsky, A., Sutskever, I. and Hinton, G.E. (2012) ImageNet Classification with Deep Convolutional Neural Networks. Advances in Neural Information Processing Systems, 1, 1097-1105.</mixed-citation></ref><ref id="hanspub.25753-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Girshick, R., Donahue, J., Darrell, T., et al. (2014) Rich Feature Hie-rarchies for Accurate Object Detection and Semantic Segmentation. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 580-587.</mixed-citation></ref><ref id="hanspub.25753-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Girshick, R. (2015) Fast r-cnn. arXiv Preprint arXiv:1504.08083.</mixed-citation></ref><ref id="hanspub.25753-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Ren, S., He, K., Girshick, R., et al. (2016) Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks. IEEE Transactions on Pattern Analysis and Machine Intelligence, 39, 1137-1149.</mixed-citation></ref><ref id="hanspub.25753-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Redmon, J., Divvala, S., Girshick, R., et al. (2016) You only Look Once: Unified, Real-Time Object Detection. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 779-788.</mixed-citation></ref><ref id="hanspub.25753-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Liu, W., Anguelov, D., Erhan, D., et al. (2016) SSD: Single Shot Multibox Detector. European Conference on Com-puter Vision, Springer, Berlin, 21-37.</mixed-citation></ref><ref id="hanspub.25753-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Redmon, J. and Farhadi, A. (2017) YOLO9000: Better, Faster, Stronger. arXiv Pre-print.</mixed-citation></ref><ref id="hanspub.25753-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Jiang, Y., Zhu, X., Wang, X., et al. (2017) R2CNN: Rotational Region CNN for Orientation Robust Scene Text Detection. arXiv Preprint arXiv:1706.09579.</mixed-citation></ref><ref id="hanspub.25753-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Tang, T., Zhou, S., Deng, Z., et al. (2017) Arbitrary-Oriented Vehicle Detection in Aerial Imagery with Single Convolutional Neural Networks. Remote Sensing, 9, 1170. &lt;br&gt;https://doi.org/10.3390/rs9111170</mixed-citation></ref><ref id="hanspub.25753-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Liu, L., Pan, Z. and Lei, B. (2017) Learning a Rotation Invariant Detector with Rotatable Bounding Box. arXiv Preprint ar-Xiv:1711.09405.</mixed-citation></ref><ref id="hanspub.25753-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Nasrabadi, N.M. (2007) Pattern Recognition and Machine Learning. Journal of Electronic Imaging, 16, 049901.  
&lt;br&gt;https://doi.org/10.1117/1.2819119</mixed-citation></ref><ref id="hanspub.25753-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">LeCun, Y. (2015) LeNet-5, Convolutional Neural Networks. http://yann.lecun.com/exdb/lenet</mixed-citation></ref><ref id="hanspub.25753-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Zhu, H., Chen, X., Dai, W., et al. (2015) Orientation Robust Object Detection in Aerial Images Using Deep Convolutional Neural Network. 2015 IEEE International Conference on Image Processing (ICIP), Quebec City, 27-30 September 2015, 3735-3739.</mixed-citation></ref></ref-list></back></article>