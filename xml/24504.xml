<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2018.84051</article-id><article-id pub-id-type="publisher-id">CSA-24504</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20180400000_81766211.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于LDP和PNN的掌纹识别算法
  Research of Palmprint Identification Algorithm Based on LDP and PNN
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>周</surname><given-names>萍萍</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>王</surname><given-names>晅</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>陕西师范大学，物理学与信息技术学院，陕西 西安</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>08</day><month>04</month><year>2018</year></pub-date><volume>08</volume><issue>04</issue><fpage>464</fpage><lpage>471</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   针对现有的掌纹识别算法对掌纹图像的旋转、尺度和亮度变化缺乏足够的鲁棒性，而且识别速度较慢的问题，本文通过LDP算子进行特征提取，将掌纹分成若干子区域后，然后通过连接这些子区域的LDP直方图生成掌纹特征向量，使得发生变化的同一类掌纹图像的相似性变大。为了能够提高识别精度且加快识别速度，通过概率神经网络(PNN)来进行分类。实验表明该算法对掌纹图像的旋转、尺度和亮度的变化有良好的鲁棒性，且提高识别率，识别速度较快。 To alleviate the limitations that the existing palmprint recognition methods are time-consuming, and their robustness to the variations of orientation, position and illumination is insufficient, this paper uses LDP operator to get feature extraction. The paimprint image is divided into sub-regions. Then connecting these sub-regions LDP histogram to generate palmprint feature vector, this can increase the similarity of the same type of palmprint image. In order to improve the recognition accuracy and accelerate the recognition speed, the classification is performed by Probabilistic Neural Networks (PNN). It is also shown that the proposed approach is robust to the variations of orientation, position and illumination and improves the recognition rate, and accelerates the recognition speed. 
  
 
</p></abstract><kwd-group><kwd>特征向量，LDP直方图，概率神经网络，掌纹识别, Feature Vector</kwd><kwd> LDP Histogram</kwd><kwd> Probabilistic Neural Networks (PNN)</kwd><kwd> Palmprint Recognition</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>基于LDP和PNN的掌纹识别算法<sup> </sup></title><p>周萍萍，王晅</p><p>陕西师范大学，物理学与信息技术学院，陕西 西安</p><p><img src="//html.hanspub.org/file/6-1540981x1_hanspub.png" /></p><p>收稿日期：2018年4月2日；录用日期：2018年4月18日；发布日期：2018年4月25日</p><disp-formula id="hanspub.24504-formula47"><graphic xlink:href="//html.hanspub.org/file/6-1540981x5_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>针对现有的掌纹识别算法对掌纹图像的旋转、尺度和亮度变化缺乏足够的鲁棒性，而且识别速度较慢的问题，本文通过LDP算子进行特征提取，将掌纹分成若干子区域后，然后通过连接这些子区域的LDP直方图生成掌纹特征向量，使得发生变化的同一类掌纹图像的相似性变大。为了能够提高识别精度且加快识别速度，通过概率神经网络(PNN)来进行分类。实验表明该算法对掌纹图像的旋转、尺度和亮度的变化有良好的鲁棒性，且提高识别率，识别速度较快。</p><p>关键词 :特征向量，LDP直方图，概率神经网络，掌纹识别</p><disp-formula id="hanspub.24504-formula48"><graphic xlink:href="//html.hanspub.org/file/6-1540981x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2018 by authors and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/6-1540981x7_hanspub.png" /> <img src="//html.hanspub.org/file/6-1540981x8_hanspub.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>几个世纪以来，身份鉴定始终是一个关键任务的必须要求，即一个对象只有这个正确的人拥有。因此通过一个项目或一个标记来确认身份这一过程始终得以发展，且这一过程日益完美和安全。现今有许多方法可用来进行身份识别，一个可靠的方法必须难以复制且准确性高，探索发现人类本身具有这些特征即生物识别特征，包括生理特征(虹膜、指纹、语音、脸部和掌纹等)和行为特征(如签名、步态、击键特征等) [<xref ref-type="bibr" rid="hanspub.24504-ref1">1</xref>] ，通过对这些高效和独特的特征进行图像处理和模式识别，从而进行可靠的分析和准确的描述，判断这些描述的相似性从而实现自动确认身份这一技术即生物识别技术。目前的生物识别技术有虹膜、脸部、语音、指纹、掌纹等人体特征的识别技术，有时甚至几种方法一起使用，然后交叉引用从而大大增加鉴别的精确度 [<xref ref-type="bibr" rid="hanspub.24504-ref2">2</xref>] 。掌纹识别由于其特征明显、稳定可靠、获取成本低和用户接受度好等特点而被广泛应用 [<xref ref-type="bibr" rid="hanspub.24504-ref3">3</xref>] 。</p><p>现有的掌纹识别方法大致可以分为三类，即基于结构的方法、基于子空间的方法和基于纹理的方法。按照应用层面分类，掌纹识别系统分为接触性和非接触型，接触型这类采集设备一般具有半封闭的外壳，内部设置光源，用户将手放在设备之上，在辅助定位装置的约束下完成采集。这类图像具有单一的背景，均匀的光照，同时避免了手部晃动，具有较高的识别精度，但用户接受度和实用性有待提高。非接触型提高用户接受度并且扩展了掌纹识别的应用领域。但由于移除了定位装置，掌纹图像会发生掌纹形变，包括线性形变与非线性形变。根据掌纹图像的采集方式分类，掌纹识别系统又可分为脱机式和联机式 [<xref ref-type="bibr" rid="hanspub.24504-ref3">3</xref>] ，脱机式大多用于高分辨率的掌纹图像，利用乳突纹和细节点进行识别，主要应用于刑侦、司法等领域。联机式用于低分辨率的掌纹图像，利用主线和褶皱信息进行识别，主要应用于民用和商业应用。</p><p>有关掌纹识别的早期著作主要集中于利用掌纹图像的结构特征，如主线、褶皱和细节点的方向位置信息。研究者们开发边缘探测器或使用现有的边缘检测方法来提取掌纹线 [<xref ref-type="bibr" rid="hanspub.24504-ref4">4</xref>] [<xref ref-type="bibr" rid="hanspub.24504-ref5">5</xref>] [<xref ref-type="bibr" rid="hanspub.24504-ref6">6</xref>] [<xref ref-type="bibr" rid="hanspub.24504-ref7">7</xref>] ，再用直接匹配或以其他格式表示匹配来进行识别。这类方法对脱机式的高分辨率图像产生了很好的识别率，但对于联机式的低分辨率图像，由于图像的边缘特征对图像的位置、方向、光照、噪声干扰等因素较为敏感，所以此类方法对这些因素的鲁棒性不高，而且这类方法的性能易受边缘检测算子的影响。</p><p>为了克服上述不足，基于子空间的方法是将掌纹图像看作是高维向量或矩阵 [<xref ref-type="bibr" rid="hanspub.24504-ref8">8</xref>] [<xref ref-type="bibr" rid="hanspub.24504-ref9">9</xref>] ，通过投影或变换，将其转换为低维向量或矩阵，并在此低维空间下对掌纹图像进行表示和匹配。目前较为广泛的方法主要包括ICA、PCA [<xref ref-type="bibr" rid="hanspub.24504-ref10">10</xref>] 、LDA [<xref ref-type="bibr" rid="hanspub.24504-ref11">11</xref>] ，子空间系数被认为是特征，但证明发现无论是高分辨率还是低分辨率图像，基于子空间的方法对取向、位置以及照明的变化较不敏感，因此在掌纹识别的应用中准确性不高。通常情况下该类方法对每个类别都需要多个训练样本，且训练样本的选取对识别结果影响较大。</p><p>基于纹理的方法扩展了掌纹识别的纹理分析方法，通过提取掌纹图像的主线或褶皱形成的特征进行识别。掌纹纹理的获得可以通过许多技术，如傅立叶变换 [<xref ref-type="bibr" rid="hanspub.24504-ref12">12</xref>] ，高斯滤波器，小波和Gabor小波等 [<xref ref-type="bibr" rid="hanspub.24504-ref13">13</xref>] [<xref ref-type="bibr" rid="hanspub.24504-ref14">14</xref>] [<xref ref-type="bibr" rid="hanspub.24504-ref15">15</xref>] 。此类方法适用于脱机式与联机式两种掌纹识别系统，其识别精度普遍高于基于子空间分解的方法，但是纹理特征本身在采集过程中就对位置方向的变化较为敏感，即使在同一设备上进行采集，由于每次采集都会有位置方向上的偏差，因此采集到的掌纹图像也会发生不同程度的变化。</p><p>局部二值模式(LBP)是纹理分类中一种简单有效的全局特征，LBP算子是一种有效的纹理描述算子，并且该算子具有很好的灰度和旋转不变性，因此在纹理描述中有关LBP算子的衍生体取得了巨大研究 [<xref ref-type="bibr" rid="hanspub.24504-ref16">16</xref>] 。LBP将局部区域内的相邻像素进行比较，计算简单且效率高，但灰度值很容易受随机噪声、非单调光照变化等的影响进而影响分类的准确性，针对噪声敏感这一缺点，Jabid等人提出对像素邻域8个方向上的边缘响应构造描述子，称为局部方向模式(LDP) [<xref ref-type="bibr" rid="hanspub.24504-ref17">17</xref>] 。LDP继承了LBP的优点，并利用了纹理的方向性，在一定程度上增强了抗随机噪声、光照变化的干扰能力，有效地克服了噪声带来的影响，对掌纹图像的旋转、尺度和亮度的变化有良好的鲁棒性，在掌纹识别中带来了很好的应用。</p></sec><sec id="s4"><title>2. 基于LDP的特征提取</title><sec id="s4_1"><title>2.1. LDP描述子</title><p>在3*3的局部区域上，通过计算8个不同方向上的边缘响应值，从而形成8位的二进制编码，即LDP编码。给定图像中的中心像素，通过Kirsch掩码 | M i | [<xref ref-type="bibr" rid="hanspub.24504-ref18">18</xref>] 计算8个方向的边缘响应值 | m i | ( i = 0 , 1 , ⋯ , 7 )，其中8个掩码为：</p><p>M 0 = [ − 3 − 3 5 − 3 0 5 − 3 − 3 5 ] , M 1 = [ − 3 5 5 − 3 0 5 − 3 − 3 − 3 ]</p><p>M 2 = [ 5 5 5 − 3 0 − 3 − 3 − 3 − 3 ] , <inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/6-1540981x15_hanspub.png" xlink:type="simple"/></inline-formula></p><p>M 4 = [ 5 − 3 − 3 5 0 − 3 5 − 3 − 3 ] , M 5 = [ − 3 − 3 − 3 5 0 − 3 5 5 − 3 ]</p><p>M 6 = [ − 3 − 3 − 3 − 3 0 − 3 5 5 5 ] , M 7 = [ − 3 − 3 − 3 − 3 0 5 − 3 5 5 ]</p><p>图像中的每个像素都用这8个掩码进行卷积，每个掩膜都对某个特定方向做出最大边缘响应，并对边缘响应取绝对值排序，最高的k个响应值 | m i | 被选中，相应的方向位被设置为1，剩余的(8 − k)位被设置为0。因此LDP编码被定义如下：</p><p>L D P k = ∑ i = 0 7 b i ( m i − m k ) 2 i (1)</p><p>其中， b i ( a ) = { 1 ,   a ≥ 0 0 ,   a &lt; 0</p><p>m k 是第k个最大边缘响应值。当k = 3时，相应的LDP算子的编码方式如图1所示。图2所示为掌</p><p>图1. LDP算子的编码方式</p><p>图2. 经LDP编码后的掌纹图像</p><p>纹图像经LDP编码后的纹理图像。</p></sec><sec id="s4_2"><title>2.2. 掌纹特征描述</title><p>相对于局部二值模式编码了局部区域的邻点之间的关系，局部方向模式考虑了更多的细节特征，它不仅编码了局部区域的邻点关系，还编码了局部区域上的空间关系，然而，由于特征的局部化特性，使它容易受到噪声的干扰而减弱其健壮性，缺乏对图像整体的粗粒度把握。因此分块的LDP被提出来弥补传统LDP的不足。本文对掌纹图像的感兴趣区域进行4 * 4的分块处理，对每一块的每个像素点进行LDP编码。最终按照从上到下、从左到右的顺序将各分块直方图联合起来组成一幅掌纹图像的特征。图3所示为特征直方图的联合过程。</p></sec></sec><sec id="s5"><title>3. PNN分类</title><p>1989年D.F. Specht 博士首先提出概率神经网络(PNN)，它是由径向基神经网络变化而来，是一种基于 Bayes 分类规则与 Parzen 窗的概率密度函数估计方法的一种并行算法 [<xref ref-type="bibr" rid="hanspub.24504-ref19">19</xref>] 。它是由输入层、模式层、求和层和输出层四个结构层构成，其结构图如下图4所示。</p><p>假设训练样本数量为n，记为 X = ( x 1 , x 2 , ⋯ , x n ) ，每一个输入样本 x i 的维数都是m维，将输入样本不需要任何改变的直接输入到输入层中，输入层中的输入节点数和神经元个数等于输入样本 x i 的维数m。模式层计算输入特征向量与训练集中各个样本的匹配程度，也就是相似度，一般该非线性算子取高斯函数：</p><p>M i j ( X ) = exp ( − ∑ i = 1 n ( ( X i − w i j ) 2 / ( X i + w i j ) ) σ ) (2)</p><p>图3. 特征直方图的联合过程</p><p>图4. 概率神经网络结构图</p><p>其中， x i 是指训练集中的第i个训练样本， w i j 是输入层的第i个神经元和模式层的第j个神经元的权重，σ是高斯核函数的平滑参数，取决于用户选择。求和层负责将各个样本类的模式层单元连接起来，即对向量M进行加权求和，这一层的神经元个数是样本的类别数目。</p><p>S i ( X ) = ∑ i = 1 N 1 w i j M i j ( X ) ,     i = 1 , 2 , ⋯ , n (3)</p><p>其中 ∑ i = 1 N 1 w i j = 1 ,   i = 1 , 2 , ⋯ , n 且 w i j ∈ [ 0 , 1 ]</p><p>输出层负责输出求和层中得分最高的那一类，得分最大的神经元输出为1，即为待识别的样本类别，其他神经元则输出为0。</p><p>相较于其它分类算法，PNN训练速度快，仅仅略大于读取数据的时间，无论分类问题多么复杂，只要有足够多的训练数据,就可以保证获得贝叶斯准则下的最优解，当增加或减少训练数据时，无需进行长时间的训练，且能够容忍个别错误样本。</p></sec><sec id="s6"><title>4. 实验结果和分析</title><p>本文采用的香港理工大学的标准掌纹数据库 [<xref ref-type="bibr" rid="hanspub.24504-ref20">20</xref>] ，包含了来自386个不同个体的7706张灰度图像，经过两次分批采集，第一次采集获取前十个样本，第二次采集获取其他十个样本，第一次采集和第二次采集之间的平均间隔为69天，且改变了光源并调整了CCD相机的焦点，因此第一次和第二次的采集可以被视为来自两个不同的掌纹获取设备。</p><p>实验的目的是为了检测此方法的分类准确性，以及验证所提出的方法对光照、位置和方向变化具有鲁棒性。对本文方法与基于PCA的方法、基于LDA的方法、Kong的方法 [<xref ref-type="bibr" rid="hanspub.24504-ref21">21</xref>] 和基于双树复小波变换 [<xref ref-type="bibr" rid="hanspub.24504-ref22">22</xref>] 的方法进行了比较。</p><p>实验1：本次试验的目的是测试所提出方法的分类准确性。将第一次采集样本的前五个样本视为训练样本，其他第一次采集的样本视为测试样本，分别用上面所提及的方法进行分类，分类比较结果见表1。实验证明，本文提出的方法具有较好的分类结果。</p><p>实验2：本次实验目的是为了验证所提出的方法对掌纹图像的取向、位置以及照度变化具有鲁棒性。将第一次采样样本的前五个样本作为测试样本，第二次采样样本的所有样本视为测试样本，分别对实验1所提及的方法进行分类，分类比较结果见表2。实验表明，所提出的方法对图像的取向，位置以及照度变化有较高的鲁棒性。</p><p>实验3：本实验的目的是测试所提出方法的计算成本。本次仿真实验环境为Intel&#174;CeleronCPU 1.99G Hz，1.99GB内存，Microsoft Windows XP操作系统。选用第一次采集样本进行试验，计算实验1中所提及方法的平均运行时间，实验结果见表3。实验证明，本文算法的运行时间较好，这是由于LDP进行特</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> The classification performance in different approaches (1</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >方法</th><th align="center" valign="middle" >正确识别率(%)</th></tr></thead><tr><td align="center" valign="middle" >本文方法</td><td align="center" valign="middle" >95.41</td></tr><tr><td align="center" valign="middle" >Kong的方法</td><td align="center" valign="middle" >92.88</td></tr><tr><td align="center" valign="middle" >基于PCA的方法</td><td align="center" valign="middle" >94.25</td></tr><tr><td align="center" valign="middle" >基于LDA的方法</td><td align="center" valign="middle" >92.05</td></tr><tr><td align="center" valign="middle" >基于双树复小波变化的方法</td><td align="center" valign="middle" >92.35</td></tr></tbody></table></table-wrap><p>表1. 不同算法的正确识别率(一)</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> The classification performance in different approaches (2</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >方法</th><th align="center" valign="middle" >正确识别率(%)</th></tr></thead><tr><td align="center" valign="middle" >本文方法</td><td align="center" valign="middle" >91.21</td></tr><tr><td align="center" valign="middle" >Kong的方法</td><td align="center" valign="middle" >88.67</td></tr><tr><td align="center" valign="middle" >基于PCA的方法</td><td align="center" valign="middle" >83.25</td></tr><tr><td align="center" valign="middle" >基于LDA的方法</td><td align="center" valign="middle" >84.05</td></tr><tr><td align="center" valign="middle" >基于双树复小波变化的方法</td><td align="center" valign="middle" >87.25</td></tr></tbody></table></table-wrap><p>表2. 不同算法的正确识别率(二)</p><table-wrap id="table3" ><label><xref ref-type="table" rid="table3">Table 3</xref></label><caption><title> The average running time(s) in different algorithm</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >方法</th><th align="center" valign="middle" >平均运行时间/s</th></tr></thead><tr><td align="center" valign="middle" >本文方法</td><td align="center" valign="middle" >0.8193</td></tr><tr><td align="center" valign="middle" >Kong的方法</td><td align="center" valign="middle" >1.4508</td></tr><tr><td align="center" valign="middle" >基于PCA的方法</td><td align="center" valign="middle" >0.7624</td></tr><tr><td align="center" valign="middle" >基于LDA的方法</td><td align="center" valign="middle" >1.4205</td></tr><tr><td align="center" valign="middle" >基于双树复小波变化的方法</td><td align="center" valign="middle" >0.8210</td></tr></tbody></table></table-wrap><p>表3. 不同算法的平均运行时间</p><p>征提取时需要计算8个方向的边缘相应且要进行绝对值排序，因此特征提取的过程比较耗时，针对此问题，还有待于进一步改进。</p></sec><sec id="s7"><title>5. 结论</title><p>本文提出了一种基于LDP和PNN的掌纹识别算法。将原始掌纹图像通过一系列的预处理之后，提取出图像的感兴趣区域，本文采用LDP算子进行掌纹特征提取，并将提取出的特征用直方图的形式进行描述，最后用PNN进行匹配识别。实验结果表明所提出的方法与其他算法相比在识别的准确性上能够产生更好的性能，对于掌纹图像的方向、位置和照度变化具有较高的鲁棒性。</p></sec><sec id="s8"><title>文章引用</title><p>周萍萍,王 晅. 基于LDP和PNN的掌纹识别算法 Research of Palmprint Identification Algorithm Based on LDP and PNN[J]. 计算机科学与应用, 2018, 08(04): 464-471. https://doi.org/10.12677/CSA.2018.84051</p></sec><sec id="s9"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.24504-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Jain, A.K., Flynn, P. and Ross, A. (2007) Handbook of Biometrics. Springer, New York, 1-22.</mixed-citation></ref><ref id="hanspub.24504-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Yue, F., Zuo, W.-M. and Zhang, D.P. (2010) Survey of Palmprint Ecognition Algorithm. Acta Automatica Sinica, 36, 353- 365. &lt;br&gt;https://doi.org/10.3724/SP.J.1004.2010.00353</mixed-citation></ref><ref id="hanspub.24504-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Kong, A., Zhang, D. and Kamel, M. (2009) A Survey of Palmprint Recogni-tion. Pattern Recognition, 42, 1408-1418. 
&lt;br&gt;https://doi.org/10.1016/j.patcog.2009.01.018</mixed-citation></ref><ref id="hanspub.24504-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Huang, D.S., Jia, W. and Zhang, D. (2008) Palmprint Verification Based on Principal Lines. Pattern Recognition, 41, 1316-1328. &lt;br&gt;https://doi.org/10.1016/j.patcog.2007.08.016</mixed-citation></ref><ref id="hanspub.24504-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Leung, M.K.S., Fong, A.C.M. and Hui, S.C. (2007) Palmprint Verification for Controlling Access to Shared Computing Resources. IEEE Pervasive Compu-ting, 6, 40-47. &lt;br&gt;https://doi.org/10.1109/MPRV.2007.78</mixed-citation></ref><ref id="hanspub.24504-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Rafael Diaz, M., Travieso, C.M., Alonso, J.B. and Ferrer, M.A. (2004) Biometric System Based in the Feature of Hand Palm. Proceedings of 38th Annual International Carnahan Conference on Se-curity Technology, Albuquerque, 136-139.</mixed-citation></ref><ref id="hanspub.24504-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Wu, X.Q., Wang, K. and Zhang, D. (2002) Line Feature Extraction and Matching in Palmprint. Proceedings of the Second International Conference on Image and Graphics, Hefei, 31 July 2002, 583-590.  
&lt;br&gt;https://doi.org/10.1117/12.477200</mixed-citation></ref><ref id="hanspub.24504-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Wu, X.Q., Zhang, D. and Wang, K. (2003) Fisherpalms Based Palmprint Recognition. Pattern Recognition Letters, 24, 2829-2838. &lt;br&gt;https://doi.org/10.1016/S0167-8655(03)00141-7</mixed-citation></ref><ref id="hanspub.24504-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Lu, G., Zhang, D. and Wang, K. (2003) Palmprint Recognition Using Eigenpalms Features. Pattern Recognition Letters, 24, 1463-1467.</mixed-citation></ref><ref id="hanspub.24504-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Connie, T., Jin, A.T.B., Ong, M.G.K. and Ling, D.N.C. (2005) An Automated Palmprint Recognition System. Image and Vision Computing, 23, 501-515. &lt;br&gt;https://doi.org/10.1016/j.imavis.2005.01.002</mixed-citation></ref><ref id="hanspub.24504-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Du, F., Yu, P., Li, H., et al. (2011) Palmprint Recognition Using Gabor Fea-ture-Based Bidirectional 2DLDA. Communications in Computer &amp; Information Science, 159.</mixed-citation></ref><ref id="hanspub.24504-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Li, W., Zhang, D. and Xu, Z. (2002) Palmprint Identification by Fourier Transform. International Journal of Pattern Recognition and Artificial Intelligence, 16, 417-432. &lt;br&gt;https://doi.org/10.1142/S0218001402001757</mixed-citation></ref><ref id="hanspub.24504-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Arivazhagan, S., Ganesan, L. and Priyal, S.P. (2006) Texture Classification Using Gabor Wavelets Based Rotation Invariant Features. Pattern Recognition Letters, 27, 1976-1982. &lt;br&gt;https://doi.org/10.1016/j.patrec.2006.05.008</mixed-citation></ref><ref id="hanspub.24504-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">Li, W., You, J. and Zhang, D. (2005) Texture-Based Palmprint Retrieval Using a Layered Search Scheme for Personal Identification. IEEE Transactions on Multimedia, 7, 891-898. &lt;br&gt;https://doi.org/10.1109/TMM.2005.854380</mixed-citation></ref><ref id="hanspub.24504-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">Wu, X.Q., Wang, K. and Zhang, D. (2006) Palmprint Texture Analysis Using Derivative of Gaussian Filters. Proceedings of 2006 International Conference on Computational Intelligence and Security, Guangzhou, 3-6 November 2006, 751-754. &lt;br&gt;https://doi.org/10.1109/ICCIAS.2006.294235</mixed-citation></ref><ref id="hanspub.24504-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">刘伟锋, 李树娟, 王延江. 人脸表情的LBP特征分析[J]. 计算机工程与应用, 2011, 47(2): 149-152.</mixed-citation></ref><ref id="hanspub.24504-ref17"><label>17</label><mixed-citation publication-type="other" xlink:type="simple">Jabid, T., Kabir, M.H. and Oksam, C. (2010) Local Directional Pattern (LDP) for Face Recognition. 2010 Digest of Technical Papers International Conference on Consumer Electronics (ICCE), Las Vegas, NV, 9-13 January 2010, 329-330. &lt;br&gt;https://doi.org/10.1109/ICCE.2010.5418801</mixed-citation></ref><ref id="hanspub.24504-ref18"><label>18</label><mixed-citation publication-type="other" xlink:type="simple">Jabid, T. and Kabir, M.H. (2010) Local Di-rectional Pattern (LDP)—A Robust Image Descriptor for Object Recognition. 7th IEEE International Conference on Advanced Video and Signal Based Surveillance, Boston, MA, 29 August-1 September 2010, 482-487.</mixed-citation></ref><ref id="hanspub.24504-ref19"><label>19</label><mixed-citation publication-type="other" xlink:type="simple">Specht, D.F. (1990) Probabilistic Neural Network. Neural Network, 3, 109-118.  
&lt;br&gt;https://doi.org/10.1016/0893-6080(90)90049-Q</mixed-citation></ref><ref id="hanspub.24504-ref20"><label>20</label><mixed-citation publication-type="other" xlink:type="simple">Zhang, D., Kong, W.K., You, J. and Wong, M. (2003) Online Palmprint Identification. IEEE Transactions on Pattern Analysis and Machine Intelligence, 25, 1041-1049. &lt;br&gt;https://doi.org/10.1109/TPAMI.2003.1227981</mixed-citation></ref><ref id="hanspub.24504-ref21"><label>21</label><mixed-citation publication-type="other" xlink:type="simple">Connie, T., Teoh, A., Goh, M. and Ngo, D. (2004) Palmprint Recognition with PCA and ICA. Proceedings of Image and Vision Computing, New Zealand, 227-232.</mixed-citation></ref><ref id="hanspub.24504-ref22"><label>22</label><mixed-citation publication-type="other" xlink:type="simple">Lu, G., Zhang, D. and Wang, K. (2003) Palmprint Recognition Using Eigenpalms Features. Pattern Recognition Letters, 24, 1463-1467. &lt;br&gt;https://doi.org/10.1016/S0167-8655(02)00386-0</mixed-citation></ref></ref-list></back></article>