<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">SEA</journal-id><journal-title-group><journal-title>Software Engineering and Applications</journal-title></journal-title-group><issn pub-type="epub">2325-2286</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/SEA.2015.43010</article-id><article-id pub-id-type="publisher-id">SEA-15594</article-id><article-categories><subj-group subj-group-type="heading"><subject>SEA20150300000_13676271.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>工程技术</subject></subj-group></article-categories><title-group><article-title>
 
 
  Markov逻辑网研究综述
  Survey of Markov Logic Networks
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>徐</surname><given-names>元子</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>张</surname><given-names>迎新</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>刘</surname><given-names>登第</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff3"><addr-line>中国人民解放军71375部队，山东 潍坊 </addr-line></aff><aff id="aff2"><addr-line>空军指挥学院，北京 </addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>09</day><month>06</month><year>2015</year></pub-date><volume>04</volume><issue>03</issue><fpage>73</fpage><lpage>80</lpage><history><date date-type="received"><day>Nov.</day>	<month>4th,</month>	<year>2013</year></date><date date-type="rev-recd"><day>Nov.</day>	<month>11th,</month>	<year>2013</year>	</date><date date-type="accepted"><day>Nov.</day>	<month>18th,</month>	<year>2013</year></date></history><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   Markov逻辑网是将Markov网络与一阶谓词逻辑相结合的统计关系学习模型。Markov逻辑网在实体识别、数据融合、信息抽取等领域都有重要研究价值，具有广泛的应用。本文较为全面的介绍了Markov逻辑网的理论模型、推理、参数学习、与其他算法的比较，最后探讨Markov逻辑网未来的研究方向。&lt;br/&gt;Markov logic networks (MLNs) is a kind of statistical relational learning model which combines Markov network and first-order logic together. MLNs has the significant research value and in many areas it has widely applications, such as entity recognition, data integration and information extrac-tion. In this paper, we introduced the theoretical model of Markov logic networks, inference and pa-rametric learning of it and compared it with other. In the end, we discussed future works of MLNs.
    
  
 
</p></abstract><kwd-group><kwd>Markov逻辑网，一阶谓词逻辑，统计关系学习，推理，参数学习, Markov Logic Network</kwd><kwd> First-Order Logic</kwd><kwd> Statistical Relational Learning</kwd><kwd> Inference</kwd><kwd> Parametric Learning Algorithms</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>Markov逻辑网研究综述<sup> </sup></title><p>徐元子<sup>1</sup>，张迎新<sup>2</sup>，刘登第<sup>1</sup></p><p><sup>1</sup>空军指挥学院，北京</p><p><sup>2</sup>中国人民解放军71375部队，山东 潍坊</p><p>Email: xu_yuanzi@163.com</p><p>收稿日期：2015年6月10日；录用日期：2015年6月27日；发布日期：2015年6月30日</p><disp-formula id="hanspub.15594-formula6118"><graphic xlink:href="http://html.hanspub.org/file/7-2690151x5_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>Markov逻辑网是将Markov网络与一阶谓词逻辑相结合的统计关系学习模型。Markov逻辑网在实体识别、数据融合、信息抽取等领域都有重要研究价值，具有广泛的应用。本文较为全面的介绍了Markov逻辑网的理论模型、推理、参数学习、与其他算法的比较，最后探讨Markov逻辑网未来的研究方向。</p><p>关键词 :Markov逻辑网，一阶谓词逻辑，统计关系学习，推理，参数学习</p><disp-formula id="hanspub.15594-formula6119"><graphic xlink:href="http://html.hanspub.org/file/7-2690151x6_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s3"><title>1. 引言</title><p>面对海量的网络信息，如何处理信息的复杂性和不确定性问题是人工智能、数据集成的难点之一。为解决这类问题近年来提出了统计关系学习[<xref ref-type="bibr" rid="hanspub.15594-ref1">1</xref>] (statistical relational learning, SRL)和概率图模型[<xref ref-type="bibr" rid="hanspub.15594-ref2">2</xref>] (probabilistic graphical model, PGM)。统计关系学习是通过逻辑表示、概率推理、机器学习和数据挖掘等方法获取关系数据中的似然模型。概率图模型将概率统计信息与数据的结构信息相结合，主要涵盖了贝叶斯网络(Bayesian networks, BNs) [<xref ref-type="bibr" rid="hanspub.15594-ref3">3</xref>] 、隐马尔科夫模型(hidden Markov model, HMM) [<xref ref-type="bibr" rid="hanspub.15594-ref4">4</xref>] 、神经网络(neural network, NN) [<xref ref-type="bibr" rid="hanspub.15594-ref5">5</xref>] 等方法。人们迫切需要一种模型将逻辑表示方法和概率方法结合起来。</p><p>2004年美国华盛顿大学的Domingos和Richardson首次提出了马尔可夫逻辑网[<xref ref-type="bibr" rid="hanspub.15594-ref6">6</xref>] (Markov logic networks, MLNs)，MLNs可以将统计关系学习和概率图进行较好的结合，比纯逻辑方法和纯概率方法能更好的解决问题。Markov逻辑网是一种统计关系学习框架，具有强大的描述能力、逻辑推理能力和处理不确定性的能力。从处理不确定性问题看，Markov逻辑网为一阶谓词附加权值，容忍知识库中存在不完整和互相矛盾的知识，具有较好的处理不确定性问题的能力；从概率统计方面看，Markov逻辑网为描述Markov网络提供了简洁有效的方法。Markov逻辑网已成为人工智能、数据集成、机器学习等领域的研究热点，具有广阔的应用前景。</p><p>本文介绍Markov逻辑网，在介绍模型定义的基础上简要介绍Markov逻辑网的推理、参数学习、与其他统计关系学习算法的比较，Markov逻辑网的主要应用和未来研究方向。</p></sec><sec id="s4"><title>2. Markov逻辑网</title><sec id="s4_1"><title>2.1. Markov逻辑网的基本概念</title><p>Markov逻辑网是一种将Markov网络与一阶谓词逻辑相结合的统计关系学习模型[<xref ref-type="bibr" rid="hanspub.15594-ref7">7</xref>] ，为Markov网络提供一种简洁的描述语言，为一阶逻辑增加了不确定性处理能力。</p><p>Markov网络也称为Markov随机场(Markov random field，简称MRF)，是一个变量集合<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2690151x7_hanspub.png" xlink:type="simple"/></inline-formula>的联合分布模型。Markov网络由无向图G和定义于G上的一组势函数Ф<sub>m</sub>组成，G中每个节点代表一个随机变量，G中每个团对应一个非负势函数Ф<sub>i</sub>，代表团的一个状态。</p><p>一阶谓词逻辑是建立在一阶语言基础上的逻辑体系[<xref ref-type="bibr" rid="hanspub.15594-ref8">8</xref>] 。一阶语言由常量、变量、函数和谓词四种类型符号组成，若干一阶谓词逻辑组成一阶谓词知识库[<xref ref-type="bibr" rid="hanspub.15594-ref9">9</xref>] 。常量指定义域里一个简单的对象；变量指定义域里若干对象；函数表示一组对象到一个对象的映射；谓词指定义域中若干对象之间的关系，如FatherOf()，以及对象的属性，如Accurate()。一阶逻辑可以看做在可能世界的集合上建立的硬性规则，一系列硬性规则组成一阶逻辑知识库。如果一个世界违反了知识库中某一条规则，这个世界存在概率就为0。</p><p>Markov逻辑网的基本思想是放松一阶谓词逻辑的硬性规则，给每个规则附加权重。如果一个世界违反了其中一条规则，这个世界存在的可能性将降低，但仍有可能存在。一个世界违反的规则越少，这个世界存在的可能性就越大。一个规则的权重越大，越接近于一阶谓词逻辑。</p><p>Markov逻辑网的定义：Markov逻辑网L是一组二元项<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2690151x8_hanspub.png" xlink:type="simple"/></inline-formula>，其中F<sub>i</sub>表示一阶逻辑规则，w<sub>i</sub>是一个实数。<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2690151x9_hanspub.png" xlink:type="simple"/></inline-formula>与有限常量集<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2690151x10_hanspub.png" xlink:type="simple"/></inline-formula>一起定义了一个以闭谓词为节点，闭谓词关系为边的Markov网M<sub>L,C</sub>，其中：</p><p>1) L中任意闭谓词都对应M<sub>L,C</sub>中的一个二元节点．若此闭谓词为真，则对应的二元节点取值为1，否则为0。</p><p>2) L中任意闭公式都对应M<sub>L,C</sub>中的一个特征值，若闭公式为真，则对应的特征值为l，否则为0。特征值权重为二元项中该规则F<sub>i</sub>对应的权重w<sub>i</sub>。</p><p>由定义可知，Markov逻辑网M<sub>L,C</sub>可以看作是一个构建Markov网络的模板，给定相同的Markov逻辑网M<sub>L,C</sub>和不同的有限量集合C，可以产生不同的Markov网络。这些Markov网络有一些相似点，比如有相同的团的数目，同一规则所有可能常量取值有相同权重。根据这种方式产生的Markov网络称为闭Markov网，一个闭Markov网中所蕴含的可能世界x的概率分布如下:</p><disp-formula id="hanspub.15594-formula6120"><label>(1)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/7-2690151x11_hanspub.png"  xlink:type="simple"/></disp-formula><p>公式(1)中，Z为归一化常数，n<sub>i</sub>(x)为F<sub>i</sub>在x中所有取值为真的基本规则数量，x<sub>{i}</sub>是F<sub>i</sub>中为真的原子，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2690151x12_hanspub.png" xlink:type="simple"/></inline-formula>，w<sub>i</sub>为第i个公式F<sub>i</sub>的权重。如果一个规则包含多个从句，这些从句将平分该规则的权重。</p></sec><sec id="s4_2"><title>2.2. Markov逻辑网实例</title><p>从公式(1)中可以看出，对应同一公式的所有闭公式有相同权重。设知识库包含公式F<sub>1</sub>和F<sub>2</sub>，权重分别为1.2和2.0，一个简单的Markov逻辑网实例见表1。</p><p>表1中，x和y分别表示个体变项，D<sub>r</sub>(x), H<sub>y</sub>(x)和F<sub>r</sub>(x, y)分别表示x酗酒与否，x患高血压与否，x与y是否是朋友的谓词；规则F<sub>1</sub>表示酗酒导致高血压，F<sub>2</sub>表示如果x与y是朋友，则他们可能都酗酒，可能都不酗酒。公式F<sub>2</sub>中两个从句平分权重为1.0。当给定个体常项集合<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2690151x13_hanspub.png" xlink:type="simple"/></inline-formula>时，生成的闭Markov网络如图1所示。</p><p>从图1中看出，闭Markov网络中有6个团，团的权重如表2所示。</p><p>图1. 一个闭Markov网</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> A simple Markov logic network exampl</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >命题</th><th align="center" valign="middle" >一阶逻辑规则</th><th align="center" valign="middle" >权重</th></tr></thead><tr><td align="center" valign="middle" >酗酒导致高血压</td><td align="center" valign="middle" >F<sub>1</sub>：<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2690151x15_hanspub.png" xlink:type="simple"/></inline-formula></td><td align="center" valign="middle" >1.2</td></tr><tr><td align="center" valign="middle" >如果两人是朋友，他们可能都酗酒，可能都不酗酒</td><td align="center" valign="middle" >F<sub>2</sub>：<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2690151x16_hanspub.png" xlink:type="simple"/></inline-formula></td><td align="center" valign="middle" >1.0 1.0</td></tr></tbody></table></table-wrap><p>表1. 一个简单的Markov逻辑网实例</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> A closed Markov network and its weigh</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >团</th><th align="center" valign="middle" >权重</th></tr></thead><tr><td align="center" valign="middle" ><inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2690151x17_hanspub.png" xlink:type="simple"/></inline-formula> <inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2690151x18_hanspub.png" xlink:type="simple"/></inline-formula></td><td align="center" valign="middle" >1.2 1.2</td></tr><tr><td align="center" valign="middle" ><inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2690151x19_hanspub.png" xlink:type="simple"/></inline-formula> <inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2690151x20_hanspub.png" xlink:type="simple"/></inline-formula> <inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2690151x21_hanspub.png" xlink:type="simple"/></inline-formula> <inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2690151x22_hanspub.png" xlink:type="simple"/></inline-formula></td><td align="center" valign="middle" >1.0 1.0 1.0 1.0</td></tr></tbody></table></table-wrap><p>表2. 闭Markov网及其权重</p></sec></sec><sec id="s5"><title>3. Markov逻辑网的推理</title><p>Markov逻辑网的推理主要在生成的闭Markov网上进行，可以进行边缘概率，条件概率和最大可能性推理。</p><sec id="s5_1"><title>3.1. 边缘概率和条件概率</title><p>边缘概率的推理问题可以表示为：给定Markov逻辑网和常量集，求某个规则取值为真的概率。条件概率是在边缘概率中给定了若干其他规则的取值情况，求某个规则取值为真的概率。</p><p>根据条件概率和Markov逻辑网定义可知，给定Markov逻辑网L、常量集C以及给定规则F<sub>1</sub>取真时，规则F<sub>2</sub>取真的概率为：</p><disp-formula id="hanspub.15594-formula6121"><label>(2)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/7-2690151x23_hanspub.png"  xlink:type="simple"/></disp-formula><p>公式中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2690151x24_hanspub.png" xlink:type="simple"/></inline-formula>是所有使F<sub>1</sub>取值为真的世界存在的概率之和。公式中随着闭原子个数的增加，计算量将指数级上升。有效的方法是运用MCMC(Markov Chain Monte Carlo)算法[<xref ref-type="bibr" rid="hanspub.15594-ref10">10</xref>] [<xref ref-type="bibr" rid="hanspub.15594-ref11">11</xref>] 和的基于整数线性规划的CPI (Cutting Plane Inference)算法[<xref ref-type="bibr" rid="hanspub.15594-ref12">12</xref>] 来近似推理。文献[<xref ref-type="bibr" rid="hanspub.15594-ref13">13</xref>] 提出了切片抽样的MCMC算法MC-SAT，算法严格遵从MCMC所需要的遍历原则和细节平衡原则，在原有的MCMC算法中引入一个辅助参数，捕捉变量之间某些确定性关系，用模拟退火步骤对切片进行采样。文献[<xref ref-type="bibr" rid="hanspub.15594-ref14">14</xref>] 证明，MC-SAT算法得到的概率非常准确。</p></sec><sec id="s5_2"><title>3.2. 最大可能性</title><p>最大可能性问题是概率图模型推理的重要内容，其基本过程表述为：给定证据变量集x，求变量集y最可能处于的状态<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2690151x25_hanspub.png" xlink:type="simple"/></inline-formula>。在Markov逻辑网中转化问题为求<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2690151x26_hanspub.png" xlink:type="simple"/></inline-formula>，其中w<sub>i</sub>表示从句i的权重，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2690151x27_hanspub.png" xlink:type="simple"/></inline-formula>表示从句i的闭从句的真值数量[<xref ref-type="bibr" rid="hanspub.15594-ref15">15</xref>] 。计算最大可能性问题可转换为最大化带权的可满足性问题，即寻找一组变量的赋值，使得所有被满足的从句权重之和最大。Richardson为解决这个问题提出了MaxWalkSAT算法[<xref ref-type="bibr" rid="hanspub.15594-ref16">16</xref>] ，算法首先对所有变量随机赋值，然后在所有未满足的从句中随机选取一个从句，改变从句中一个变量x的值。变量x的选取可以根据概率随机选取，可以根据是否选取后所有已满足的从句权重之和达到最大进行选取。MaxWalkSAT算法有一个缺点是内存的需求量会随着从句数量增加呈指数级上升，文献[<xref ref-type="bibr" rid="hanspub.15594-ref17">17</xref>] 提出的LazySAT算法弥补了这个缺陷。LazySAT算法是一种“需要时再激活”的“惰性”思想，利用一阶知识库的稀疏性，隐性决定了大多数闭从句的取值都为真。算法对内存的需求量只由搜索进行当中那些潜在的未满足的闭原子和闭从句决定。LazySAT算法提高了推理速度，但没有提高推理的精度，文献[<xref ref-type="bibr" rid="hanspub.15594-ref18">18</xref>] 进一步提高推理速度。</p></sec></sec><sec id="s6"><title>4. Markov逻辑网的参数学习</title><p>Markov逻辑网的学习分为结构学习和参数学习。参数学习是指在Markov逻辑网结构确定的前提下，进一步学习和优化模型的参数。参数学习即学习公式(1)中的权重w<sub>i</sub>。参数学习可以采用最大似然方法，一个规则F<sub>i</sub>的权重w<sub>i</sub>的对数似然函数梯度可表示为：</p><disp-formula id="hanspub.15594-formula6122"><label>(3)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/7-2690151x28_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2690151x29_hanspub.png" xlink:type="simple"/></inline-formula>为世界x中规则F<sub>i</sub>的真值个数，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2690151x30_hanspub.png" xlink:type="simple"/></inline-formula>是在所有可能世界<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2690151x31_hanspub.png" xlink:type="simple"/></inline-formula>中求和，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2690151x32_hanspub.png" xlink:type="simple"/></inline-formula>的计算建立在当前的规则权重向量集<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2690151x33_hanspub.png" xlink:type="simple"/></inline-formula>上。直接计算规则F<sub>i</sub>的真值个数的数学期望并不可行，目前主要方法是使用伪最大似然估计[<xref ref-type="bibr" rid="hanspub.15594-ref6">6</xref>] 和区别式训练[<xref ref-type="bibr" rid="hanspub.15594-ref19">19</xref>] 。</p><sec id="s6_1"><title>4.1. 伪最大似然估计</title><p>伪最大似然估计是对Markov逻辑网的伪似然概率分布，公式如下：</p><disp-formula id="hanspub.15594-formula6123"><label>(4)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/7-2690151x34_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中x<sub>l</sub>表示l个闭原子的真值，MB<sub>x</sub>(X<sub>l</sub>)表示X<sub>l</sub>的Markov边界，伪最大似然估计可以学习Markov逻辑网参数，但伪似然参数会导致非邻接变量之间的推理结果不理想。区别式训练参数方法可以解决该问题。</p></sec><sec id="s6_2"><title>4.2. 区别式训练</title><p>区别式训练假设谓词分为两个集合: 证据谓词集合X(谓词已知真值)，查询谓词集合Y(谓词未知真值)，通过对条件概率求最大似然来学习权值w<sub>i</sub>，公式如下：</p><disp-formula id="hanspub.15594-formula6124"><label>(5)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/7-2690151x35_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中F<sub>y</sub>是公式集合，该集合的每个公式至少包含1个闭查询谓词。<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/7-2690151x36_hanspub.png" xlink:type="simple"/></inline-formula>是知识库中第i个公式的真闭公式个数。</p></sec></sec><sec id="s7"><title>5. 统计关系学习算法比较</title><p>目前统计关系学习(SRL)方法主要有基于Bayesian网的SRL方法、基于隐Markov模型的SRL方法、基于随机文法的SRL方法和Markov逻辑网。MLNs与基于Bayesian 网的似然逻辑程序模型(Probabilistic Logic Program, PLPs) [<xref ref-type="bibr" rid="hanspub.15594-ref20">20</xref>] 相比，具有能够在对象实体和关系不断变化中自动调整其网络结构，能够通过自动更新Markov网来调整规则的权重，能够对同一实体对象动态识别的优点。MLNs与隐Markov模型(HMM)相比，虽然HMM可以有效解决动态序列化问题，但处理数据时要遵循数据块之间是独立的前提[<xref ref-type="bibr" rid="hanspub.15594-ref15">15</xref>] ，而MLNs没有这种限制。MLNs与基于随机文法的SRL方法相比，如与随机逻辑程序(stochastic logic program, SLP) [<xref ref-type="bibr" rid="hanspub.15594-ref21">21</xref>] 和统计建模程序设计(programming in statistical modeling, PRISM) [<xref ref-type="bibr" rid="hanspub.15594-ref22">22</xref>] 方法，MLNs推理和学习方法比较灵活，在处理质量较差的数据时MLNs受到的影响较小，而SLP和PRISM算法会受到较大影响。</p></sec><sec id="s8"><title>6. Markov逻辑网的主要应用</title><p>Markov逻辑网(MLNs)作为统计关系学习的统一框架，受到国内外人工智能、数据挖掘、机器学习等领域[<xref ref-type="bibr" rid="hanspub.15594-ref23">23</xref>] [<xref ref-type="bibr" rid="hanspub.15594-ref24">24</xref>] 研究的广泛关注，Domingos研究团队不断完善Markov逻辑网的理论体系，并提供了一个学习和发展该理论体系的平台Alchemy[<xref ref-type="bibr" rid="hanspub.15594-ref25">25</xref>] 。MLNs作为统计关系学习的统一框架，在实体识别[<xref ref-type="bibr" rid="hanspub.15594-ref26">26</xref>] -[<xref ref-type="bibr" rid="hanspub.15594-ref28">28</xref>] 、信息抽取[<xref ref-type="bibr" rid="hanspub.15594-ref29">29</xref>] -[<xref ref-type="bibr" rid="hanspub.15594-ref33">33</xref>] 、社会网络[<xref ref-type="bibr" rid="hanspub.15594-ref34">34</xref>] 、语义网络[<xref ref-type="bibr" rid="hanspub.15594-ref35">35</xref>] 、自然语言理解[<xref ref-type="bibr" rid="hanspub.15594-ref36">36</xref>] -[<xref ref-type="bibr" rid="hanspub.15594-ref39">39</xref>] 、数据挖掘[<xref ref-type="bibr" rid="hanspub.15594-ref40">40</xref>] [<xref ref-type="bibr" rid="hanspub.15594-ref41">41</xref>] 、生物信息[<xref ref-type="bibr" rid="hanspub.15594-ref42">42</xref>] [<xref ref-type="bibr" rid="hanspub.15594-ref43">43</xref>] 等方面都有大量应用。</p><p>国际上，文献[<xref ref-type="bibr" rid="hanspub.15594-ref26">26</xref>] 将Markov 逻辑网与多个实体识别方法无缝结合，有效解决实体识别问题。文献[<xref ref-type="bibr" rid="hanspub.15594-ref33">33</xref>] 利用Markov逻辑网采用StatSnowball方法进行Web实体关系的抽取。Gayathri等人[<xref ref-type="bibr" rid="hanspub.15594-ref43">43</xref>] 使用MLNs进行层次行为识别。Cheng等人[<xref ref-type="bibr" rid="hanspub.15594-ref44">44</xref>] 将Markov逻辑网运用于主题发现。Chahuara等人[<xref ref-type="bibr" rid="hanspub.15594-ref45">45</xref>] 利用Markov逻辑网来处理不确定性推理问题。在国内，胡宜敏等人[<xref ref-type="bibr" rid="hanspub.15594-ref28">28</xref>] 提出将Markov逻辑网和基于本体与Web搜索的属性抽取算法相结合的命名实体解析方法。刘永彬等人[<xref ref-type="bibr" rid="hanspub.15594-ref32">32</xref>] 提出使用基于MLNs的联合推理模型处理开放式信息抽取。李燕[<xref ref-type="bibr" rid="hanspub.15594-ref40">40</xref>] 构建Markov转移矩阵，针对过程挖掘算法的局限性设计多步过程挖掘算法。重庆大学张玉芳副教授的研究团队使用Markov逻辑网进行文本分类[<xref ref-type="bibr" rid="hanspub.15594-ref46">46</xref>] [<xref ref-type="bibr" rid="hanspub.15594-ref47">47</xref>] ，重复数据删除[<xref ref-type="bibr" rid="hanspub.15594-ref48">48</xref>] ，取得较好效果。中国科学院的吴蕾等人将多个主题模型和MLNs相结合，提出了一种融合概率图模型[<xref ref-type="bibr" rid="hanspub.15594-ref49">49</xref>] ，解决异构信息网络中存在多种数据目标类型和多种数据连接关系的问题；将隐马尔科夫网络与条件随机场相结合，提出基于深度学习框架的隐藏主题变量图模型[<xref ref-type="bibr" rid="hanspub.15594-ref50">50</xref>] ，有效挖掘主题信息。张永新等人[<xref ref-type="bibr" rid="hanspub.15594-ref51">51</xref>] 提出使用MLNs处理数据融合中的冲突问题，将冲突分为强冲突和弱冲突，制定不同规则使用MLNs推理真值，解决数据冲突。</p></sec><sec id="s9"><title>7. 未来研究方向</title><p>统计关系学习模型Markov逻辑网的研究在起步阶段，模型需要完善，推理和学习算法仍需拓展。Markov逻辑网将来可以从以下几方面深入研究：1)增强算法学习能力，使其可以从不完备数据中学习；提高学习算法的效率，提高真闭公式个数计算速度。2)从一阶逻辑和 Markov 网两个方面完善 Markov逻辑网理论。3)扩展模型的应用范围，例如与主题模型等其他模型融合，与自然语言处理、信息抽取、数据融合、生物信息等领域充分结合，更好的解决实际问题。</p></sec><sec id="s10"><title>文章引用</title><p>徐元子,张迎新,刘登第, (2015) Markov逻辑网研究综述 Survey of Markov Logic Networks. 软件工程与应用,03,73-80. doi: 10.12677/SEA.2015.43010</p></sec><sec id="s11"><title>参考文献 (References)</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.15594-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Liu, D.Y., Yu, P., Gao, Y., Qi, H. and Sun, S.Y. (2008) Research progress in statistical relational learning. Journal of Computer Research and Development, 45, 2110-2119.</mixed-citation></ref><ref id="hanspub.15594-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Koller, D. and Friedman, N. (2009) Probabilistic graphical models: Principles and techniques. The MIT Press, Cambridge.</mixed-citation></ref><ref id="hanspub.15594-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Jensen, F.V. and Nielsen, T.D. (2007) Bayesian Networks and Decision Graphs. 2nd Edition, Springer-Verlag, New York.</mixed-citation></ref><ref id="hanspub.15594-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Rabiner, L.R. (1989) A tutorial on hidden Markov models and selected applications in speech recognition. Proceedings of the IEEE, 77, 257-286.</mixed-citation></ref><ref id="hanspub.15594-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Arbib, M.A. (2003) The Handbook of Brain Theory and Neural Networks. MIT Press, Bos-ton.</mixed-citation></ref><ref id="hanspub.15594-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Richardson, M. and Domingos, P. (2004) Markov Logic Networks. Department of Computer Science and Engineering, University of Washington, Seattle.</mixed-citation></ref><ref id="hanspub.15594-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Wong, T.-L. (2014) Learning Markov logic networks with limited number of labeled training examples. International Journal of Knowledge-Based and Intelligent Engineering Systems, 2, 91-98.</mixed-citation></ref><ref id="hanspub.15594-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">耿素云, 屈婉玲 (1998) 离散数学. 高等教育出版社, 北京.</mixed-citation></ref><ref id="hanspub.15594-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Genesereth, M.R. and NiIsson, N.J. (1987) Logical foundations of artificial intelligence. Morgan Kaufmann, San Mateo.</mixed-citation></ref><ref id="hanspub.15594-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Gilks, W.R., Richardson, S. and Spiegelhalter, D.J. (1996) Markov chain Monte Carlo in practice. Chapman and Hall, London.</mixed-citation></ref><ref id="hanspub.15594-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Liu, Z.Y., Chen, D., Wurm, K.M. and von Wichert, G. (2015) Table-top scene analysis using knowledge-supervised MCMC. Robotics and Computer-Integrated Manufacturing, 33, 110-123.</mixed-citation></ref><ref id="hanspub.15594-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Riedel, S. (2008) Improving the accuracy and efficiency of map inference for Markov logic. Proceedings of the Annual Conference on Uncertainty in Artificial Intelligence, Helsinki, 9-12 July 2008, 468-475.</mixed-citation></ref><ref id="hanspub.15594-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Poon, H. and Domingos, P. (2006) Sound and efficient inference with probabilistic and deterministic dependencies. Proceedings of the 2lst National Conference on Artificial Intelligence (AAAI 2006), Boston, 16-20 July 2006, 458-463.</mixed-citation></ref><ref id="hanspub.15594-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">Liu, D.C. and Nocedal, J. (1989) On the limited memory BFGS method for large scale optimization. Mathematical Programming, 45, 503-528.</mixed-citation></ref><ref id="hanspub.15594-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">徐从富, 郝春亮, 苏保君, 楼俊杰 (2011) 马尔科夫逻辑网研究. 软件学报, 8, 1699-1713.</mixed-citation></ref><ref id="hanspub.15594-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">Richardson, M. and Domingos, P. (2006) Markov logic networks. Machine Learning, 62, 107-136.</mixed-citation></ref><ref id="hanspub.15594-ref17"><label>17</label><mixed-citation publication-type="other" xlink:type="simple">Singla, P. and Domingos, P. (2006) Memory efficient inference in relational domains. Proceedings of the 21st National Conference on Artificial Intelligence (AAAI 2006), Boston, 16-20 July 2006, 488-493.</mixed-citation></ref><ref id="hanspub.15594-ref18"><label>18</label><mixed-citation publication-type="other" xlink:type="simple">Gogate, V., Webb, W.A. and Domingos, P. (2010) Learning efficient Markov networks. Proceedings of the 24th Annual Conference on Neural Information Processing Systems (NIPS-2010), Vancouver, 6-9 December 2010, 748-756.</mixed-citation></ref><ref id="hanspub.15594-ref19"><label>19</label><mixed-citation publication-type="other" xlink:type="simple">Singla, P. and Domingos, P. (2005) Discriminative training of Markov logic networks. Proceedings of the 20th National Conference on Artificial Intelligence (AAAI 2005), Pittsburgh, 9-13 July 2005, 868-873.</mixed-citation></ref><ref id="hanspub.15594-ref20"><label>20</label><mixed-citation publication-type="other" xlink:type="simple">Ngo, L. and Haddawy, P. (1997) Answering queries from context-sensitive probabilistic knowledge bases. Theoretical Computer Science, 171, 147-177.</mixed-citation></ref><ref id="hanspub.15594-ref21"><label>21</label><mixed-citation publication-type="other" xlink:type="simple">Muggleton, S. (1996) Stochastic logic programs. Proceedings of the 5th International Workshop on Inductive Logic Programming, IOS Press, Amsterdam, 1996, 254-264.</mixed-citation></ref><ref id="hanspub.15594-ref22"><label>22</label><mixed-citation publication-type="other" xlink:type="simple">Sato, T. and Kamcya, Y. (1997) PRJSM: A language for symbolic-statistical modeling. Proceedings of the 15th International Joint Conference on Artificial Intelligence, Nagoya, 23-29 August 1997, 1330-1339.</mixed-citation></ref><ref id="hanspub.15594-ref23"><label>23</label><mixed-citation publication-type="other" xlink:type="simple">孙舒杨, 刘大有, 孙成敏, 黄冠利 (2007) 统计关系学习模型Markov 逻辑网综述. 计算机应用研究, 2, 1-3.</mixed-citation></ref><ref id="hanspub.15594-ref24"><label>24</label><mixed-citation publication-type="other" xlink:type="simple">Domingos, P. and Lowd, D. (2009) Markov logic: An interface layer for artificial intelligence. Morgan and Claypool, San Rafael.</mixed-citation></ref><ref id="hanspub.15594-ref25"><label>25</label><mixed-citation publication-type="other" xlink:type="simple">Kok, S., Singla, P. and Richardson, M. (2005) The alchemy system for statistical relational AI: User manual. Department of Computer Science and Engineering, VSi University of Washington, Seattle.</mixed-citation></ref><ref id="hanspub.15594-ref26"><label>26</label><mixed-citation publication-type="other" xlink:type="simple">Singla, P. and Domingos, P. (2006) Entity resolution with Markov logic. Proceedings of the 6th IEEE Industrial Conference on Data Mining (ICDM), Hong Kong, 18-22 December 2006, 572-582.</mixed-citation></ref><ref id="hanspub.15594-ref27"><label>27</label><mixed-citation publication-type="other" xlink:type="simple">Paolo, F., Francesco, G., Marco, L. and Simone, M. (2014) Markov logic networks for optical chemical structure recognition. Journal of Chemical Information and Modeling, 8, 2380-2390.</mixed-citation></ref><ref id="hanspub.15594-ref28"><label>28</label><mixed-citation publication-type="other" xlink:type="simple">胡宜敏, 宋良图, 陈鹏, 魏圆圆, 宋雅茹 (2013) 一种基于Markov逻辑网的中文地理名称实体解析方法. 模式识别与人工智能, 1, 114-122.</mixed-citation></ref><ref id="hanspub.15594-ref29"><label>29</label><mixed-citation publication-type="other" xlink:type="simple">Yang, J.M., Cai, Y., Wang, Y., Zhu, J., Zhang, L. and Ma, W.Y. (2009) Incorporating site-level knowledge to extract structured data from web forums. Proceedings of the 18th International Conference on World Wide Web (WWW), Madrid, Spain, 20-24 April 2009, 181-190.</mixed-citation></ref><ref id="hanspub.15594-ref30"><label>30</label><mixed-citation publication-type="other" xlink:type="simple">谭永兴, 罗军勇, 尹美娟 (2012) Markov逻辑网及其在信息抽取中的应用, 计算机工程, 18, 162-165.</mixed-citation></ref><ref id="hanspub.15594-ref31"><label>31</label><mixed-citation publication-type="other" xlink:type="simple">刘小军, 邢永康, 袁文群, 武南南 (2013) 马尔可夫逻辑网在信息抽取中的应用. 世界科技研究与发展, 4, 465- 468.</mixed-citation></ref><ref id="hanspub.15594-ref32"><label>32</label><mixed-citation publication-type="other" xlink:type="simple">刘永彬, 杨炳儒, 李广源, 刘英华 (2012) 基于马尔可夫逻辑网的联合推理开放信息抽取. 计算机科学, 9, 202- 205.</mixed-citation></ref><ref id="hanspub.15594-ref33"><label>33</label><mixed-citation publication-type="other" xlink:type="simple">Zhu, J., Nie, Z.P., Liu, X.J., Zhang, B. and Wen, J.-R. (2009) StatSnowball: A statistical approach to extracting entity relationships. Proceedings of the 18th ACM International World Wide Web Conference, Madrid, 20-24 April 2009, 101-110.</mixed-citation></ref><ref id="hanspub.15594-ref34"><label>34</label><mixed-citation publication-type="other" xlink:type="simple">Singla, P., Kautz, H., Luo, J.B. and Gallagher, A. (2008) Discovery of social relationships in consumer photo collections using Markov logic. Proceedings of the CVPR Workshop on Semantic Learning and Applications in Multimedia, Anchorage, 24-26 June 2008, 1-7.</mixed-citation></ref><ref id="hanspub.15594-ref35"><label>35</label><mixed-citation publication-type="other" xlink:type="simple">Poon, H. and Domingos, P. (2009) Unsupervised semantic parsing. Proceedings of the 2009 International Conference on Empirical Methods in Natural Language Processing (EMNLP), Singapore, 6-7 August 2009, 1-10.</mixed-citation></ref><ref id="hanspub.15594-ref36"><label>36</label><mixed-citation publication-type="other" xlink:type="simple">杨博, 蔡东风, 赵奇猛, 杨华 (2014) 融合WordNet的无监督语义分析研究. 小型微型计算机系统, 2, 368-373.</mixed-citation></ref><ref id="hanspub.15594-ref37"><label>37</label><mixed-citation publication-type="other" xlink:type="simple">杨立公, 汤世平, 朱俭 (2013) 基于马尔科夫逻辑网的句子情感分析方法. 北京理工大学学报, 6, 600-604.</mixed-citation></ref><ref id="hanspub.15594-ref38"><label>38</label><mixed-citation publication-type="other" xlink:type="simple">McNeill, F., Halpin, H., Klein, E. and Bundy, A. (2006) Merging stories with shallow semantics. Proceedings of the Workshop on Knowledge and Reasoning for Language Processing (KRAQ 2006), Trento, 3-7 April 2006, 37-42.</mixed-citation></ref><ref id="hanspub.15594-ref39"><label>39</label><mixed-citation publication-type="other" xlink:type="simple">Wong, T.L., Chow, K.O., Wang, F.L. and Tsang, P.M. (2010) Improving Markov logic network learning using unlabeled data. Proceedings of the 2010 International Conference on Machine Learning and Cybernetics (ICMLC), Qingdao, 11-14 July 2010, 236-240.</mixed-citation></ref><ref id="hanspub.15594-ref40"><label>40</label><mixed-citation publication-type="other" xlink:type="simple">李燕 (2013) 基于马尔可夫转移矩阵的多步过程挖掘方法. 信息系统工程, 2, 37-40.</mixed-citation></ref><ref id="hanspub.15594-ref41"><label>41</label><mixed-citation publication-type="other" xlink:type="simple">王星, 方滨兴, 张宏莉, 何慧, 赵蕾 (2013) 关系分类的学习界限研究. 软件学报, 11, 2508-2521.</mixed-citation></ref><ref id="hanspub.15594-ref42"><label>42</label><mixed-citation publication-type="other" xlink:type="simple">Davis, J. and Domingos, P. (2009) Deep transfer via second-order Markov logic. Proceedings of the 20th International Conference on Machine Learning (ICML), Montreal, 14-18 June 2009, 217-224.</mixed-citation></ref><ref id="hanspub.15594-ref43"><label>43</label><mixed-citation publication-type="other" xlink:type="simple">Gayathri, K.S., Elias, S. and Ravindran, B. (2015) Hierarchical activity recognition for dementia care using Markov logic network. Personal and Ubiquitous Computing, 19, 271-285.</mixed-citation></ref><ref id="hanspub.15594-ref44"><label>44</label><mixed-citation publication-type="other" xlink:type="simple">Cheng, V. and Li, C.H. (2007) Topic detection via participation using Markov logic network. Proceedings of the Third International IEEE Conference on Signal-Image Technologies and Internet-Based System (SITIS), Shanghai, 16-18 December 2007, 85-91.</mixed-citation></ref><ref id="hanspub.15594-ref45"><label>45</label><mixed-citation publication-type="other" xlink:type="simple">Chahuara, P., Portet, F. and Vacher, M. (2013) Making context aware decision from uncertain information in a smart home: A Markov logic network approach. Proceedings of the 4th International Joint Conference, Dublin, 3-5 December 2013, 78-93.</mixed-citation></ref><ref id="hanspub.15594-ref46"><label>46</label><mixed-citation publication-type="other" xlink:type="simple">张玉芳, 黄涛, 艾冬梅, 熊忠阳 (2009) Markov逻辑网及其在文本分类中的应用. 计算机应用, 10, 2729-2732.</mixed-citation></ref><ref id="hanspub.15594-ref47"><label>47</label><mixed-citation publication-type="other" xlink:type="simple">张玉芳, 孔润, 田源, 熊忠阳 (2011) 基于Markov逻辑网的超文本分类. 南京大学学报(自然科学版), 5, 571-577.</mixed-citation></ref><ref id="hanspub.15594-ref48"><label>48</label><mixed-citation publication-type="other" xlink:type="simple">张玉芳, 黄涛, 艾冬梅, 熊忠阳, 唐容君 (2010) Markov逻辑网在重复数据删除中的应用. 重庆大学学报, 8, 36- 41.</mixed-citation></ref><ref id="hanspub.15594-ref49"><label>49</label><mixed-citation publication-type="other" xlink:type="simple">吴蕾, 张文生, 王珏 (2014) 异构信息网络数据上的融合概率图模型. 计算机科学与探索, 6, 712-718.</mixed-citation></ref><ref id="hanspub.15594-ref50"><label>50</label><mixed-citation publication-type="other" xlink:type="simple">吴蕾, 张文生, 王珏 (2015) 基于深度学习框架的隐藏主题变量图模型. 计算机研究与发展, 1, 191-199.</mixed-citation></ref><ref id="hanspub.15594-ref51"><label>51</label><mixed-citation publication-type="other" xlink:type="simple">张永新, 李庆忠, 彭朝晖 (2012) 基于Markov逻辑网的两阶段数据冲突解决方法. 计算机学报, 1, 101-111.</mixed-citation></ref></ref-list></back></article>