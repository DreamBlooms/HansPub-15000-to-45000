<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">AAM</journal-id><journal-title-group><journal-title>Advances in Applied Mathematics</journal-title></journal-title-group><issn pub-type="epub">2324-7991</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/AAM.2019.88169</article-id><article-id pub-id-type="publisher-id">AAM-31804</article-id><article-categories><subj-group subj-group-type="heading"><subject>AAM20190800000_12884059.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>数学与物理</subject></subj-group></article-categories><title-group><article-title>
 
 
  神经网络实现函数逼近的影响因素分析
  Analysis of the Effect of BP Neural Network on Function Approximation
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>佘</surname><given-names>嘉博</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>谭</surname><given-names>艳祥</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>长沙理工大学数学与统计学院，湖南 长沙</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>07</day><month>08</month><year>2019</year></pub-date><volume>08</volume><issue>08</issue><fpage>1453</fpage><lpage>1456</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
  
    基于向后传播算法的多层网络又称BP网络，因其易于实现，是目前应用最广的一种神经网络。本文主要研究基于MATLAB的BP网络在函数逼近的应用，分析其函数逼近效果的影响因素。经本文研究表明，人工神经网络随隐层层数增加，函数逼近误差减小，随隐层单元数增加，函数逼近误差减小，误差减小速率逐渐减慢。随训练精度减小，函数逼近误差减小，减小速率逐渐减慢，同时收敛步数增加。
    The multi-layer network based on backward propagation algorithm is also called BP network. Be-cause it is easy to implement, it is the most widely used neural network. This paper mainly studies the application of BP network based on MATLAB in function approximation, and analyzes the in-fluencing factors of its function approximation effect. The research results show that the artificial neural network increases with the number of hidden layers, and the function approximation error decreases. As the number of hidden layer elements increases, the function approximation error decreases, and the error reduction rate gradually decreases. As the training accuracy decreases, the function approximation error decreases, the decrease rate gradually decreases, and the number of convergence steps increases. 
  
 
</p></abstract><kwd-group><kwd>BP神经网络，函数逼近，MATLAB, BP Neural Network</kwd><kwd> Function Approximation</kwd><kwd> MATLAB</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>神经网络实现函数逼近的影响因素分析<sup> </sup></title><p>佘嘉博，谭艳祥</p><p>长沙理工大学数学与统计学院，湖南 长沙</p><p><img src="//html.hanspub.org/file/17-2621025x1_hanspub.png" /></p><p>收稿日期：2019年7月31日；录用日期：2019年8月15日；发布日期：2019年8月22日</p><disp-formula id="hanspub.31804-formula29"><graphic xlink:href="//html.hanspub.org/file/17-2621025x5_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>基于向后传播算法的多层网络又称BP网络，因其易于实现，是目前应用最广的一种神经网络。本文主要研究基于MATLAB的BP网络在函数逼近的应用，分析其函数逼近效果的影响因素。经本文研究表明，人工神经网络随隐层层数增加，函数逼近误差减小，随隐层单元数增加，函数逼近误差减小，误差减小速率逐渐减慢。随训练精度减小，函数逼近误差减小，减小速率逐渐减慢，同时收敛步数增加。</p><p>关键词 :BP神经网络，函数逼近，MATLAB</p><disp-formula id="hanspub.31804-formula30"><graphic xlink:href="//html.hanspub.org/file/17-2621025x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2019 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/17-2621025x7_hanspub.png" /> <img src="//html.hanspub.org/file/17-2621025x8_hanspub.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>人工神经网络是在现代神经科学的发展基础之上提出的一个研究方向，目的在于反映人脑的结构和功能特性的一种独特的数学模型。在上世纪80年代，人工神经网络取得了重大突破，相关理论已经发展成为了交叉学科，它在模糊控制、自动化等方面得到广泛的应用，推出了四十余种相关的神经网络模型。</p></sec><sec id="s4"><title>2. 神经网络结构</title><p>人工神经元与生物神经元相类似，是基本的信号处理单元。它接受其他神经元的输出并作为其输入，并且产生一个输出，输入到另一个神经元，具体结构如图1 [<xref ref-type="bibr" rid="hanspub.31804-ref1">1</xref>] 。</p><p>图1. 人工神经网络基本单元的神经元模型</p><p>人工神经网络基本要素：</p><p>1) 一组连接，连接的强度由连接上的值来表示。</p><p>2) 一个求和单元，用于求各输入信号的线性组合。</p><p>3) 一个非线性激活函数，将神经元的输出的幅度限制于特定范围内。</p></sec><sec id="s5"><title>3. 函数逼近影响因素</title><p>1) 隐层层数。在训练精度为0.0005，训练次数为5000，隐层单元数均取5个，训练函数取trainlm，传递函数为tansig/purelin情况下，依次设置1、2、3层隐层，同时传递函数取tansig，以此研究隐层层数对函数逼近的效果的影响 [<xref ref-type="bibr" rid="hanspub.31804-ref2">2</xref>] 。</p><p>2) 隐层单元数。在训练精度为0.0005，训练次数为5000，训练函数取trainlm，传递函数为tansig/purelin情况下，隐层层数为1情况下，依次设置1、2、3、4、5、6、7、8个隐层单元数，以此研究隐层单元数对函数逼近的效果的影响情况。</p><p>3) 训练精度。在训练次数为5000时，隐层单元数取5个，训练函数取 trainlm，传递函数为tansig/purelin，隐层层数为1情况下，依次设置0.5、0.05、0.005、0.0005、0.00005的训练精度，研究训练精度对函数逼近效果的影响。</p><p>4) 训练次数。在训练精度为0.0005时，隐层单元数取5个，训练函数取trainlm，传递函数为tansig/purelin，隐层层数为1情况下，依次设置100、500、1000次训练次数，研究训练次数对函数逼近效果的影响。</p></sec><sec id="s6"><title>4. 结果分析</title><p>分析隐层层数时涉及传递函数、隐层单元数的变化，由于本实验仅考虑隐层层数对函数逼近效果的影响，因此取各隐层单元数均为5，同时传递函数均选取为tansig。</p><p>训练精度为0.0005，训练次数为5000时，隐层单元数取5个，训练函数取trainlm，传递函数为tansig/purelin情况下，依次设置1、2、3层隐层，实验结果如表1。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Data table of the effect of hidden layer number on function approximatio</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >设置隐层层数</th><th align="center" valign="middle" >隐层单元数</th><th align="center" valign="middle" >传递函数</th><th align="center" valign="middle" >收敛时间(s)</th><th align="center" valign="middle" >收敛步数</th><th align="center" valign="middle" >逼近误差</th></tr></thead><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" >5</td><td align="center" valign="middle" >tansig</td><td align="center" valign="middle" >12</td><td align="center" valign="middle" >839</td><td align="center" valign="middle" >4.2943</td></tr><tr><td align="center" valign="middle" >2</td><td align="center" valign="middle" >5</td><td align="center" valign="middle" >tansig</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >29</td><td align="center" valign="middle" >1.4988</td></tr><tr><td align="center" valign="middle" >3</td><td align="center" valign="middle" >5</td><td align="center" valign="middle" >tansig</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >51</td><td align="center" valign="middle" >1.4073</td></tr></tbody></table></table-wrap><p>表1. 隐层层数对函数逼近效果影响的数据表</p><p>在训练精度为0.0005，训练次数为5000，训练函数取trainlm，传递函数为tansig/purelin情况下，隐层层数为1情况下，依次设置1、2、3、4、5、6、7、8个隐层单元数，实验结果如表2。</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> Data table of the influence of the number of hidden layer units on the function approximation effec</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >隐层单元数</th><th align="center" valign="middle" >收敛时间(s)</th><th align="center" valign="middle" >收敛步数</th><th align="center" valign="middle" >逼近误差</th></tr></thead><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >9</td><td align="center" valign="middle" >72.4918</td></tr><tr><td align="center" valign="middle" >2</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >38</td><td align="center" valign="middle" >64.6115</td></tr><tr><td align="center" valign="middle" >3</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >60</td><td align="center" valign="middle" >5.7436</td></tr><tr><td align="center" valign="middle" >4</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >95</td><td align="center" valign="middle" >4.2943</td></tr><tr><td align="center" valign="middle" >5</td><td align="center" valign="middle" >5</td><td align="center" valign="middle" >367</td><td align="center" valign="middle" >2.3099</td></tr><tr><td align="center" valign="middle" >6</td><td align="center" valign="middle" >6</td><td align="center" valign="middle" >392</td><td align="center" valign="middle" >1.5782</td></tr><tr><td align="center" valign="middle" >7</td><td align="center" valign="middle" >4</td><td align="center" valign="middle" >275</td><td align="center" valign="middle" >1.5551</td></tr><tr><td align="center" valign="middle" >8</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >13</td><td align="center" valign="middle" >1.2776</td></tr></tbody></table></table-wrap><p>表2. 隐层单元数对函数逼近效果影响的数据表</p><p>在训练次数为5000时，隐层单元数取5个，训练函数取trainlm，传递函数为tansig/purelin，隐层层数为1情况下，依次设置0.5、0.05、0.005、0.0005、0.00005 的训练精度，实验结果如表3。</p><table-wrap id="table3" ><label><xref ref-type="table" rid="table3">Table 3</xref></label><caption><title> Data table of the effect of training accuracy on function approximatio</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >训练精度</th><th align="center" valign="middle" >收敛时间(s)</th><th align="center" valign="middle" >收敛步数</th><th align="center" valign="middle" >逼近误差</th></tr></thead><tr><td align="center" valign="middle" >0.5</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >36.9967</td></tr><tr><td align="center" valign="middle" >0.05</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >5</td><td align="center" valign="middle" >14.4202</td></tr><tr><td align="center" valign="middle" >0.005</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >6</td><td align="center" valign="middle" >4.5751</td></tr><tr><td align="center" valign="middle" >0.0005</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >31</td><td align="center" valign="middle" >1.5599</td></tr><tr><td align="center" valign="middle" >0.00005</td><td align="center" valign="middle" >80</td><td align="center" valign="middle" >5000</td><td align="center" valign="middle" >1.0056</td></tr></tbody></table></table-wrap><p>表3. 训练精度对函数逼近效果影响的数据表</p><p>训练精度为0.0005时，隐层单元数取5个，训练函数取trainlm，传递函数为tansig/purelin，隐层层数为1情况下，依次设置100、500、1000次训练次数，实验结果如表4。</p><table-wrap id="table4" ><label><xref ref-type="table" rid="table4">Table 4</xref></label><caption><title> Data table of the effect of training times on function approximatio</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >训练次数</th><th align="center" valign="middle" >收敛时间(s)</th><th align="center" valign="middle" >收敛步数</th><th align="center" valign="middle" >逼近误差</th></tr></thead><tr><td align="center" valign="middle" >100</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >100</td><td align="center" valign="middle" >4.0978</td></tr><tr><td align="center" valign="middle" >500</td><td align="center" valign="middle" >8</td><td align="center" valign="middle" >500</td><td align="center" valign="middle" >2.1129</td></tr><tr><td align="center" valign="middle" >1000</td><td align="center" valign="middle" >17</td><td align="center" valign="middle" >1000</td><td align="center" valign="middle" >1.3092</td></tr></tbody></table></table-wrap><p>表4. 训练次数对函数逼近效果影响的数据表</p></sec><sec id="s7"><title>5. 结论</title><p>经本文研究表明，人工神经网络随隐层层数增加，函数逼近误差减小，随隐层单元数增加，函数逼近误差减小，误差减小速率逐渐减慢。随训练精度减小，函数逼近误差减小，减小速率逐渐减慢，同时收敛步数增加。在收敛步数等于训练次数时，随训练次数增加，函数逼近误差减小。</p></sec><sec id="s8"><title>文章引用</title><p>佘嘉博,谭艳祥. 神经网络实现函数逼近的影响因素分析Analysis of the Effect of BP Neural Network on Function Approximation[J]. 应用数学进展, 2019, 08(08): 1453-1456. https://doi.org/10.12677/AAM.2019.88169</p></sec><sec id="s9"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.31804-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">王丽萍. 基于BP神经网络的工具箱实现函数逼近[J]. 湖南农机, 2011, 38(9): 29-31.</mixed-citation></ref><ref id="hanspub.31804-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">曹旭帆, 叶舟, 万俊, 等. 基于BP神经网络的函数逼近实验及MATLAB实现[J]. 实验室研究与探索, 2008, 27(5): 34-38.</mixed-citation></ref></ref-list></back></article>