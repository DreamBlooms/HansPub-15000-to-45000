<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">AAM</journal-id><journal-title-group><journal-title>Advances in Applied Mathematics</journal-title></journal-title-group><issn pub-type="epub">2324-7991</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/AAM.2020.912260</article-id><article-id pub-id-type="publisher-id">AAM-39446</article-id><article-categories><subj-group subj-group-type="heading"><subject>AAM20201200000_45279051.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>数学与物理</subject></subj-group></article-categories><title-group><article-title>
 
 
  有限差分与人工神经网络方法求解偏微分方程解对比及定性分析
  Comparison and Qualitative Analysis of Solutions of Partial Differential Equations by Finite Difference Method and Artificial Neural Network Method
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>殷</surname><given-names>图源</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>魏</surname><given-names>大盛</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>王</surname><given-names>海辉</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>北京航空航天大学能源动力工程学院，北京</addr-line></aff><aff id="aff3"><addr-line>北京航空航天大学数学学院，北京</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>07</day><month>12</month><year>2020</year></pub-date><volume>09</volume><issue>12</issue><fpage>2228</fpage><lpage>2235</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
  
    本文对人工神经网络方法(ANN)求解偏微分方程进行了研究，选择特定偏微分方程将求解结果与经典有限差分方法(FDM)进行了比对，最后得出在样本与训练次数选择恰当时，ANN方法可以得出相对较精确的数值解，但需要选取恰当权重与激活函数，并对现有激活函数提出了修正。具体通过Lagaris发表文献以复算计结果并进行了分析与探讨，更详细地揭示计算求解注意事项，最后结论得出权重训练次数后每次迭代梯度愈小与解析解越接近，而激活函数改变对计算结果影响较小。此外对双曲二维Burgers方程进行了稳态求解在100次训练过程后，但对非稳态及耗散损失还需后续进一步探讨研究。
    In this paper, the artificial neural network (ANN) method for solving partial differential equations is studied. The specific equation is selected and the solution accuracy is compared with the classical finite element FDM method. Finally, when the sample and training times are selected properly, the ANN method can get relatively high numerical solution, but it needs to select the appropriate weight and activation function, and modify the existing activation function. The specific implementation is to analyze and discuss the numerical solution of partial differential equation by using ANN through the early lagaris published literature recalculation calculation, and reveal more detailed calculation and solution precautions. Finally, it is concluded that the smaller the iteration gradient after weight training times is, the closer it is to the finite element result, and the change of activation function has little influence on the calculation result. In addition, the two-dimensional hyperbolic Burgers equation is solved in steady state, but the unsteady state and dissipation need further study. 
  
 
</p></abstract><kwd-group><kwd>人工神经网络算法，偏微分方程数值解，数值求解精度，激活函数，权函数, Artificial Neural Network Algorithm</kwd><kwd> Numerical Solution of Differential Equation</kwd><kwd> Numerical Solution Accuracy</kwd><kwd> Activation Function</kwd><kwd> Finite Element Numerical Solution</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>摘要</title><p>本文对人工神经网络方法(ANN)求解偏微分方程进行了研究，选择特定偏微分方程将求解结果与经典有限差分方法(FDM)进行了比对，最后得出在样本与训练次数选择恰当时，ANN方法可以得出相对较精确的数值解，但需要选取恰当权重与激活函数，并对现有激活函数提出了修正。具体通过Lagaris发表文献以复算计结果并进行了分析与探讨，更详细地揭示计算求解注意事项，最后结论得出权重训练次数后每次迭代梯度愈小与解析解越接近，而激活函数改变对计算结果影响较小。此外对双曲二维Burgers方程进行了稳态求解在100次训练过程后，但对非稳态及耗散损失还需后续进一步探讨研究。</p></sec><sec id="s2"><title>关键词</title><p>人工神经网络算法，偏微分方程数值解，数值求解精度，激活函数，权函数</p></sec><sec id="s3"><title>Comparison and Qualitative Analysis of Solutions of Partial Differential Equations by Finite Difference Method and Artificial Neural Network Method</title><p>Tuyuan Yin<sup>1</sup>, Dasheng Wei<sup>1</sup>, Haihui Wang<sup>2*</sup></p><p><sup>1</sup>School of Energy and Power Engineering, Beihang University, Beijing</p><p><sup>2</sup>School of Mathematics, Beihang University, Beijing</p><p><img src="//html.hanspub.org/file/16-2621401x4_hanspub.png" /></p><p>Received: Nov. 21<sup>st</sup>, 2020; accepted: Dec. 20<sup>th</sup>, 2020; published: Dec. 28<sup>th</sup>, 2020</p><p><img src="//html.hanspub.org/file/16-2621401x6_hanspub.png" /></p></sec><sec id="s4"><title>ABSTRACT</title><p>In this paper, the artificial neural network (ANN) method for solving partial differential equations is studied. The specific equation is selected and the solution accuracy is compared with the classical finite element FDM method. Finally, when the sample and training times are selected properly, the ANN method can get relatively high numerical solution, but it needs to select the appropriate weight and activation function, and modify the existing activation function. The specific implementation is to analyze and discuss the numerical solution of partial differential equation by using ANN through the early lagaris published literature recalculation calculation, and reveal more detailed calculation and solution precautions. Finally, it is concluded that the smaller the iteration gradient after weight training times is, the closer it is to the finite element result, and the change of activation function has little influence on the calculation result. In addition, the two-dimensional hyperbolic Burgers equation is solved in steady state, but the unsteady state and dissipation need further study.</p><p>Keywords:Artificial Neural Network Algorithm, Numerical Solution of Differential Equation, Numerical Solution Accuracy, Activation Function, Finite Element Numerical Solution</p><disp-formula id="hanspub.39446-formula14"><graphic xlink:href="//html.hanspub.org/file/16-2621401x7_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2020 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/16-2621401x8_hanspub.png" /> <img src="//html.hanspub.org/file/16-2621401x9_hanspub.png" /></p></sec><sec id="s5"><title>1. 引言</title><p>目前偏微分方程数值求解通常采用有限节点差分FDM方法，其可以保持较高精度，但随着智能算法如神经网络、遗传等不断发展，在偏微分方程有所应用 [<xref ref-type="bibr" rid="hanspub.39446-ref1">1</xref>]。如Lagaris, Isaac E早期首次将ANN应用在偏微分方程，但由于年份较远，细节论证讨论相对不清晰 [<xref ref-type="bibr" rid="hanspub.39446-ref2">2</xref>]。杨云磊对常微分方程进行了数值求解，但仅讨论了常微分方程(ODE)，并且为强制边界 [<xref ref-type="bibr" rid="hanspub.39446-ref3">3</xref>]，康奈尔大学MALLS也将常微分方程进行了数值求解，并讨论了收敛机理 [<xref ref-type="bibr" rid="hanspub.39446-ref4">4</xref>]，但上述仅讨论ODE，未提及偏微分方程求解计算与权重函数迭代增量收敛性故不具备较深参考性。因此为完善ANN计算应用，本文对Lagaris早期发表的文献进行复算与更详尽说明，并对双曲方程做了求解应用，更好地明晰了求解过程，但对非稳态及耗散与CFD格式精度关联还需后续进一步探讨研究。</p></sec><sec id="s6"><title>2. 分析</title><p>目前FDM对求解PDE方法较为成熟，对一般偏微分方程通常采用有点差分法，通过节点加密并迭代求得数值解。而ANN采用改变过程变量权重，并经过训练以达到数值解，具体流程见图1(a)~(d)，这里不再系统阐述。</p></sec><sec id="s7"><title>3. 具体案例求解</title><p>例1 求解非其次泊松方程(文献 [<xref ref-type="bibr" rid="hanspub.39446-ref2">2</xref>] problem7)以计算求解：</p><p>∇ 2 Ψ ( x , y ) + Ψ ( x , y ) ∂ ∂ y Ψ ( x , y ) = sin ( π x ) ( 2 − π 2 y 2 + 2 y 3 sin ( π x ) )</p><p>x , y ∈ [ 0 , 1 ]</p><p>Ψ ( 0 , y ) = 0 , Ψ ( 1 , y ) = 0</p><p>Ψ ( x , 0 ) = 0 , ( ∂ / ∂ y ) Ψ ( x , 1 ) = 2 sin ( π x )</p><p>Ψ a ( x , y ) = y 2 sin ( π x )</p><p>其中FDM方法采用五点差分方法Gauss迭代与神经网络结果见图2(b)，其中训练次数T = 1，T = 10，T = 50三种，其中激活函数采用 1 1 + e − a x ，其中 a = 1 。</p><p>图1. (a) FDM方法求解流程；(b) ANN方法求解流程；(c) ANN流程；(d) ANN方法加权过程</p><p>图2. (a) FDM方法求解数值结果；(b) ANN方法求解结果(T = 1)；(c) ANN方法求解结果(T = 10)；(d) ANN方法求解结果(T = 50)；(e) ANN方法求解与解析解求解误差(T = 10，ANN方法求解值偏小)；(f) ANN方法求解与解析解求解误差(T = 50)</p><p>具体测试参数设置见表1，从表1得出，影响计算关键精度主要在于权重w， Δ w ˙ i 为每次权重变化率即( w i − w i − 1 )，当权重变化量。最右侧表示：最大权重增量梯度，以表征权重变化梯度，并且介于(0-1)区间。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Description of ANN method parameter setting and solution result</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >序号</th><th align="center" valign="middle" >类别</th><th align="center" valign="middle" >参数说明</th><th align="center" valign="middle" >节点数/求解时间</th><th align="center" valign="middle" >求解误差</th><th align="center" valign="middle" >max ( Δ w i )</th></tr></thead><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" >FDM</td><td align="center" valign="middle" >−</td><td align="center" valign="middle" >0.05 s</td><td align="center" valign="middle" >0.001</td><td align="center" valign="middle" >−</td></tr><tr><td align="center" valign="middle" >2</td><td align="center" valign="middle" >ANN(T = 1)</td><td align="center" valign="middle"  rowspan="3"  >初始值 w 1 = 1 , w i ≠ 1 = 0 w i p i + b &gt; 0 , Δ w ˙ i ≤ ε t 0 &lt; ε t &lt; 1 ，递减</td><td align="center" valign="middle" >0.03 s</td><td align="center" valign="middle" >0.2~0.3</td><td align="center" valign="middle" >0.87</td></tr><tr><td align="center" valign="middle" >3</td><td align="center" valign="middle" >ANN(T = 10)</td><td align="center" valign="middle" >0.5 s</td><td align="center" valign="middle" >0.01~0.1</td><td align="center" valign="middle" >0.23</td></tr><tr><td align="center" valign="middle" >4</td><td align="center" valign="middle" >ANN(T = 50)</td><td align="center" valign="middle" >4 s</td><td align="center" valign="middle" >0.001~0.005</td><td align="center" valign="middle" >0.02</td></tr><tr><td align="center" valign="middle" >5</td><td align="center" valign="middle" >ANN(T = 50)</td><td align="center" valign="middle" >a = 0.80 − 1.2, Δa = 0.05，修正激活函数</td><td align="center" valign="middle" >4 s</td><td align="center" valign="middle" >0.001~0.005 (结果无明显变化)</td><td align="center" valign="middle" >0.02</td></tr></tbody></table></table-wrap><p>表1. ANN方法参数设置与求解结果说明</p><p>例2 选定文献problem5。</p><p>∇ 2 Ψ ( x , y ) = e − x ( x − 2 + y 3 + 6 y )</p><p>x , y ∈ [ 0 , 1 ] ， Ψ ( 0 , y ) = y 3 ， Ψ ( 1 , y ) = ( 1 + y 3 ) e − 1 ， Ψ ( x , 0 ) = x e − x ， Ψ ( x , 1 ) = e − x ( x + 1 )</p><p>Ψ a ( x , y ) = e − x ( x + y 3 )</p><p>求解过程与例1相同，结果见图3。</p><p>图3. (a) 解析解结果；(b) FDM数值解结果；(c) ANN方法求解结果(T = 10)；(d) ANN方法求解结果(T = 50)；(e) ANN方法求解与解析解求解误差(T = 10)；(f) ANN方法求解与解析解求解误差(T = 50)</p><p>表2 problem5例求解参数设置与结果说明。</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> Solution parameter setting and solution result descriptio</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >序号</th><th align="center" valign="middle" >类别</th><th align="center" valign="middle" >参数说明</th><th align="center" valign="middle" >节点数/求解时间</th><th align="center" valign="middle" >求解误差</th><th align="center" valign="middle" >max ( Δ w i )</th></tr></thead><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" >FDM</td><td align="center" valign="middle" >−</td><td align="center" valign="middle" >0.03 s</td><td align="center" valign="middle" >1e−3</td><td align="center" valign="middle" >−</td></tr><tr><td align="center" valign="middle" >2</td><td align="center" valign="middle" >ANN(T = 1)</td><td align="center" valign="middle"  rowspan="3"  >初始值 w 1 = 1 , w i ≠ 1 = 0 w i p i + b &gt; 0 , Δ w ˙ i ≤ ε t 0 &lt; ε t &lt; 1 ，递减</td><td align="center" valign="middle" >0.03 s</td><td align="center" valign="middle" >0.2~0.3</td><td align="center" valign="middle" >0.87</td></tr><tr><td align="center" valign="middle" >3</td><td align="center" valign="middle" >ANN(T = 10)</td><td align="center" valign="middle" >0.5 s</td><td align="center" valign="middle" >0.05~0.2</td><td align="center" valign="middle" >0.23</td></tr><tr><td align="center" valign="middle" >4</td><td align="center" valign="middle" >ANN(T = 50)</td><td align="center" valign="middle" >3 s</td><td align="center" valign="middle" >0.001~0.005</td><td align="center" valign="middle" >0.02</td></tr><tr><td align="center" valign="middle" >5</td><td align="center" valign="middle" >ANN(T = 50)</td><td align="center" valign="middle" >a = 0.80 − 1.2, Δa = 0.05，修正激活函数</td><td align="center" valign="middle" >3 s</td><td align="center" valign="middle" >0.001~0.005 (结果无明显变化)</td><td align="center" valign="middle" >0.02</td></tr><tr><td align="center" valign="middle" >6</td><td align="center" valign="middle" >ANN(T = 100)</td><td align="center" valign="middle" >同上</td><td align="center" valign="middle" >6 s</td><td align="center" valign="middle" >0.001~0.005</td><td align="center" valign="middle" >0.02</td></tr></tbody></table></table-wrap><p>表2. 求解参数设置与求解结果说明</p><p>例3 求解稳态二维Burgers双曲方程根据文献 [<xref ref-type="bibr" rid="hanspub.39446-ref5">5</xref>]。</p><p>u ∂ u ∂ x + v ∂ v ∂ y = μ ∂ 2 u ∂ x 2 + μ ∂ 2 v ∂ y 2 ，边界 u ( 0 ) = u ( 2 π ) , v ( 0 ) = v ( 2 π )</p><p>其解析解为： ϕ = exp ( − ( x − 4 t ) 2 4 μ ( t + 1 ) ) + exp ( − ( x − 4 t − 2 π ) 2 4 μ ( t + 1 ) ) + exp ( − ( y − 4 t ) 2 4 μ ( t + 1 ) ) + exp ( − ( y − 4 t − 2 π ) 2 4 μ ( t + 1 ) )</p><p>由于是稳态求解，另时间t=0，需要说明由于边界与文献边界不同，因此公式需要修正。</p><p>结果如下： Ψ t ( x , y ) = A ( x , y ) + x ( 2 π − x ) y ( 2 π − y ) N ( x , y , p → )</p><p>A ( x , y ) = ( 2 π − x ) f 0 ( y ) + x f 1 ( y ) + ( 2 π − y ) { g 0 ( x ) − [ ( 2 π − x ) g 0 ( 0 ) + x g 0 ( 1 ) ] }     + y { g 1 ( x ) − [ ( 2 π − x ) g 1 ( 0 ) + x g 1 ( 1 ) ] }</p><p>化简后：</p><p>同时，为了简化问题取t = 0初始时刻，以求解稳态方程。</p><p>图4. (a) 解析解图像；(b) ANN方法求解结果(T = 10)；(c) ANN方法求解结果(T = 100)；(d) ANN方法求解与解析解残差(T = 100)</p><p>Burgers双曲方程参数设置与求解结果见表3。</p><table-wrap id="table3" ><label><xref ref-type="table" rid="table3">Table 3</xref></label><caption><title> Parameter setting of the solution method and description of the solution result</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >序号</th><th align="center" valign="middle" >类别</th><th align="center" valign="middle" >参数说明</th><th align="center" valign="middle" >节点数/求解时间</th><th align="center" valign="middle" >求解误差</th><th align="center" valign="middle" >max ( Δ w i )</th></tr></thead><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" >ANN(T = 1)</td><td align="center" valign="middle"  rowspan="3"  >初始值 w 1 = 1 , w i ≠ 1 = 0 Math_61# 0 &lt; ε t &lt; 1 ，递减</td><td align="center" valign="middle" >0.03 s</td><td align="center" valign="middle" >0.3~0.6</td><td align="center" valign="middle" >0.9</td></tr><tr><td align="center" valign="middle" >2</td><td align="center" valign="middle" >ANN(T = 50)</td><td align="center" valign="middle" >0.5 s</td><td align="center" valign="middle" >0.05~0.2</td><td align="center" valign="middle" >0.23</td></tr><tr><td align="center" valign="middle" >3</td><td align="center" valign="middle" >ANN(T = 100)</td><td align="center" valign="middle" >3 s</td><td align="center" valign="middle" >0.01~0.08</td><td align="center" valign="middle" >0.05</td></tr></tbody></table></table-wrap><p>表3. 求解方法参数设置与求解结果说明</p><p>通过计算可知，ANN同样适用与双曲方程但求解精度有所下降，这与双曲方程不稳定性有关(库朗数CFL &lt; 1)。但由于本案例处理稳态问题，因此得出ANN对稳态双曲同样适用，但处理非稳态问题还需再探讨。图4(c)结果偏小是由于ANN训练结果从下界逼近真实解析解。</p></sec><sec id="s8"><title>4. 讨论</title><p>根据上述计算结果可知，对ANN求解偏微分方程精确，需要对权重函数进行约束，即 f = ( ∑ w i ∗ p i + b ) ,     w i ∗ p i + b ≥ 0 ， 0 &lt; | Δ w i | ≤ ε t ， Δ ε t 递减， Δ w i 求解采用最速下降法。</p><p>ANN方法可求解出精度较高的数值解。具体流程及求解时间见图5，对于求解步骤见表4。</p><p>图5. (a) ANN求解流程；(b) 权函数求解过程修正；(c) 训练次数与求解时间关系；(d) 求解时间比较</p><table-wrap id="table4" ><label><xref ref-type="table" rid="table4">Table 4</xref></label><caption><title> ANN solving step</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >步骤</th><th align="center" valign="middle" >类别</th><th align="center" valign="middle" >说明</th></tr></thead><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" >确定偏微分方程类型，边界</td><td align="center" valign="middle" >∇ 2 Ψ = f ( x , y ) Ψ ( x , y ) = C</td></tr><tr><td align="center" valign="middle" >2</td><td align="center" valign="middle" >修正试函数</td><td align="center" valign="middle" >根据边界以修正，但对于双曲尽量选择较小时刻，避免震荡耗散。</td></tr><tr><td align="center" valign="middle" >3</td><td align="center" valign="middle" >设置初始权重w<sub>i</sub><sub>，</sub>b<sub>i</sub><sub>满足</sub><sub> w i ∗ p i + b &gt; 0 </sub> (1)</td><td align="center" valign="middle" >满足式(1)即可，但由于解无解因此需要增加 | Δ w i | 约束</td></tr><tr><td align="center" valign="middle" >4</td><td align="center" valign="middle" >如果 | Δ w i | &lt; ε t Goto w(n)+Δw<sub>i</sub>/2; (2)否则停止训练</td><td align="center" valign="middle" >约束以对权重变化量进行修正，采用最速下降法并修正，防止训练结果发散。</td></tr><tr><td align="center" valign="middle" >5</td><td align="center" valign="middle" >输出训练后数值解并与解析解或FDM比对</td><td align="center" valign="middle" ></td></tr></tbody></table></table-wrap><p>表4. ANN求解步骤</p></sec><sec id="s9"><title>5. 结语</title><p>本文目前论述了人工神经网络ANN与经典有限元FDM求解偏微分方程的区别，得出了以下结论：</p><p>1) 采用高斯经典FDM在处理偏微分方程问题时，求解时间较短，但本文只对椭圆型以双曲稳态方程进行了验证，因此FDM方法与ANN方法求解偏微分方程优势较大需要后续更深入研究。</p><p>2) ANN方法求解精度取决于权重w设定，变化 Δ w i 愈小求解愈精确，其激活函数修正对计算结果影响较小。</p><p>3) 偏微分方程求解精度需要对权重变化率 Δ w i 设定约束条件。</p><p>4) 通常求解到 max Δ w i 小于0.1时，求出数值解与解析解误差相对较小。</p><p>5) 对二维双曲Burgers方程进行了稳态求解，但对非稳态时变效应及耗散问题还需后续进一步探讨研究。</p></sec><sec id="s10"><title>致谢</title><p>在此对本文提出修改意见的专家表示感谢，以及对魏大盛和王海辉两位老师对本文的指导提出由衷地感谢！</p></sec><sec id="s11"><title>文章引用</title><p>殷图源,魏大盛,王海辉. 有限差分与人工神经网络方法求解偏微分方程解对比及定性分析Comparison and Qualitative Analysis of Solutions of Partial Differential Equations by Finite Difference Method and Artificial Neural Network Method[J]. 应用数学进展, 2020, 09(12): 2228-2235. https://doi.org/10.12677/AAM.2020.912260</p></sec><sec id="s12"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.39446-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">侯媛彬. 神经网络[M]. 西安: 西安电子科技大学出版社, 2007.</mixed-citation></ref><ref id="hanspub.39446-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Lagarisie, L. (1998) Artificial Neural Networks for Solving Ordinary and Partial Differential Equations. IEEE Transactions on Neural Networks, 9, 987-1000. &lt;br&gt;https://doi.org/10.1109/72.712178</mixed-citation></ref><ref id="hanspub.39446-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">杨云磊, 张天乐, 侯木舟, 等. 一类微分方程两点边值问题的神经网络方法应用研究[J]. 徐州工程学院学报(自然科学版), 2018, 33(128): 63-69.</mixed-citation></ref><ref id="hanspub.39446-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Chakravertys, M. (2016) Application of Legendre Neural Network for Solving Ordinary Differentiate Equations. Applied Computing, 43, 347-356. &lt;br&gt;https://doi.org/10.1016/j.asoc.2015.10.069</mixed-citation></ref><ref id="hanspub.39446-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">李荣华. 偏微分方程数值解[M]. 北京: 高等教育出版社, 2007.</mixed-citation></ref></ref-list></back></article>