<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2018.83044</article-id><article-id pub-id-type="publisher-id">CSA-24304</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20180300000_83072812.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于分层PCA技术的显著性目标检测算法
  Saliency Detection Based on Hierarchical PCA Technology
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>王</surname><given-names>烨蕾</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>李</surname><given-names>玲</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>辛</surname><given-names>云宏</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff3"><addr-line>西安航空学院机械工程学院，陕西 西安</addr-line></aff><aff id="aff2"><addr-line>陕西师范大学物理学与信息技术学院，陕西 西安</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>19</day><month>3</month><year>2018</year></pub-date><volume>08</volume><issue>03</issue><fpage>398</fpage><lpage>409</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   针对当前显著性目标检测方法存在的背景噪声较大、准确度较低以及计算量大等问题，提出了一种基于分层PCA技术的显著性目标检测算法。该方法首先将原始RGB图像转换为灰度图像，并通过比特面分层技术将原始灰度图像分为8层，每层图像包含与该层图像特征相匹配的显著目标信息；接着，以原图的色彩结构为参考图像，通过灰度级–彩色变换方法为分层后的灰度图像重新赋值，分层图像不仅体现了原有的结构特征而且有效地保留了原始图像的彩色特征；然后，对分层图像进行PCA分析，得到每层图像在主成分方向上的结构差异特征以及色彩差异特征；之后，将两种特征进行融合，产生精度高、鲁棒性好的分层显著图，进而利用中心先验方法将显著目标放置近似中心处从而突出目标区域，得到更加精确的显著图。最后，对分层显著图进行信息熵判决，并由此得到一幅背景信息最少而显著信息突出的最优显著图。在MSRA、ASD、ESSCD等数据集中随机选取300张图像进行了测试并与ITTI (IT)、GBVS (GB)、SR、LC、HS、CHS等几种经典方法进行了比较，实验结果表明所提出方法能够有效的将显著目标与背景相分离，检测效果更接近人工标定的结果，与对照方法相比在准确率(PRE)、召回率(REC)和F-measure等性能参数方面具有明显优势。同时加快了运算速度，提高了检测精确度。 Many traditional methods of saliency detection have the disadvantages of intensive background noise, low accuracy and high calculation cost. Therefore, this paper proposes a novel saliency detection algorithm based on hierarchical PCA method. Firstly, according to prominently distinct detail, the original image is divided into eight layers. Each layer contains correlated target information of the image layer shared the same feature. Then, the method of grayscale image colorizing is used to transplant color characteristics from source image to hierarchical grayscale image, which purpose is to make the layered image not only reflect the pattern characteristics but also retain the original color feature. After that, PCA technology is used to detect layered images to obtain distinct object’s pattern distinctness and color distinctness in the principal component direction. Next, two features are integrated to get the saliency map with high robustness, and to further refine our results, the known priors are incorporated on image organization, which can place the subject of the photo-graph near the center of the image. Finally, entropy calculation is used to determine the optimal image from the layered saliency map; the optimal map has the least background information and the most prominently salient target. 300 pictures of the MSRA, ASD and ESSCD databases are randomly selected to test and compare with several classical methods. The layered PCA technology can effectively separate the significant object from the background. The detection results of the proposed method are closer to the manual calibration, while taking advantages of performance parameter include accuracy rate, recall rate and F-measure value. At the same time, it accelerates the calculation speed and improves the detection accuracy.
    
  
 
</p></abstract><kwd-group><kwd>分层PCA，显著性检测，结构特征，色彩特征, Hierarchical PCA</kwd><kwd> Saliency Detection</kwd><kwd> Pattern Feature</kwd><kwd> Color Feature</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>基于分层PCA技术的显著性目标检测算法<sup> </sup></title><p>王烨蕾<sup>1</sup>，李玲<sup>2</sup>，辛云宏<sup>1</sup></p><p><sup>1</sup>陕西师范大学物理学与信息技术学院，陕西 西安</p><p><sup>2</sup>西安航空学院机械工程学院，陕西 西安</p><p><img src="//html.hanspub.org/file/17-1540951x1_hanspub.png" /></p><p>收稿日期：2018年3月10日；录用日期：2018年3月22日；发布日期：2018年3月30日</p><disp-formula id="hanspub.24304-formula16"><graphic xlink:href="//html.hanspub.org/file/17-1540951x5_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>针对当前显著性目标检测方法存在的背景噪声较大、准确度较低以及计算量大等问题，提出了一种基于分层PCA技术的显著性目标检测算法。该方法首先将原始RGB图像转换为灰度图像，并通过比特面分层技术将原始灰度图像分为8层，每层图像包含与该层图像特征相匹配的显著目标信息；接着，以原图的色彩结构为参考图像，通过灰度级–彩色变换方法为分层后的灰度图像重新赋值，分层图像不仅体现了原有的结构特征而且有效地保留了原始图像的彩色特征；然后，对分层图像进行PCA分析，得到每层图像在主成分方向上的结构差异特征以及色彩差异特征；之后，将两种特征进行融合，产生精度高、鲁棒性好的分层显著图，进而利用中心先验方法将显著目标放置近似中心处从而突出目标区域，得到更加精确的显著图。最后，对分层显著图进行信息熵判决，并由此得到一幅背景信息最少而显著信息突出的最优显著图。在MSRA、ASD、ESSCD等数据集中随机选取300张图像进行了测试并与ITTI (IT)、GBVS (GB)、SR、LC、HS、CHS等几种经典方法进行了比较，实验结果表明所提出方法能够有效的将显著目标与背景相分离，检测效果更接近人工标定的结果，与对照方法相比在准确率(PRE)、召回率(REC)和F-measure等性能参数方面具有明显优势。同时加快了运算速度，提高了检测精确度。</p><p>关键词 :分层PCA，显著性检测，结构特征，色彩特征</p><disp-formula id="hanspub.24304-formula17"><graphic xlink:href="//html.hanspub.org/file/17-1540951x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2018 by authors and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/17-1540951x7_hanspub.png" /> <img src="//html.hanspub.org/file/17-1540951x8_hanspub.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>本人眼的视觉注意机制使人类能够在复杂场景中实时定位图像中位置相对重要的信息，并以此来判定处理不同目标的优先级序列，这样可有效地缩小视觉处理的范围，进而极大地节约计算资源。因此，对人类的视觉注意机制进行研究并将其应用于计算机视觉和图像处理等领域具有非常重大的意义。如今，基于人类视觉注意机制的显著性区域检测技术得到了国内外研究学者的广泛关注，该方法已经成为计算机视觉领域中非常重要的研究课题，并成功地应用于图像裁剪，目标跟踪与识别以及缩略图生成等多个方面。</p><p>计算机视觉研究人员模拟视觉注意机制的初期往往采用自下而上的过程，这类模型被称为自下而上的显著性模型。如：Itti等人 [<xref ref-type="bibr" rid="hanspub.24304-ref1">1</xref>] 模拟人脑视皮层神经细胞对颜色、亮度和方向特征的融合机制，并使用“中心–周边”原理建立了视觉显著性模型，有效地检测出了对比度明显的显著性区域。此模型计算过程简单，但对目标区域的检测不够准确。Yang C等人 [<xref ref-type="bibr" rid="hanspub.24304-ref2">2</xref>] 基于图论模型对Itti模型加以改进，提出了GBVS (Saliency detection via graph-based)算法模型。其计算方法与Itti模型相似，图像颜色、亮度与方向等底层特征的提取方法相同。GBVS模型通过马尔可夫随机场计算特征显著图，能够从全局的角度较好地进行图像显著性检测，但其缺点是效率较低，无法辨识目标轮廓。侯晓迪等人 [<xref ref-type="bibr" rid="hanspub.24304-ref3">3</xref>] 提出了一种SR (Spectral Residual)算法，该方法认为从图像的幅度谱中减去先验知识的幅度谱，剩下的就是显著部分的幅度谱，再通过频域空间变换就可得到目标显著图。此算法运算速度虽快，但精确度难以保证。Shen等人 [<xref ref-type="bibr" rid="hanspub.24304-ref4">4</xref>] [<xref ref-type="bibr" rid="hanspub.24304-ref5">5</xref>] 提出的LR (Low Rank)算法将高层先验统一到低秩的框架中，能够提取较多的显著特征，但其计算量较大，得到的显著图均匀性较差。总的来说，自下而上的显著性方法大都比较基础，运算速度较快，算法实现简单，但得到的显著性检测结果往往通过密集的亮点来表示显著性部分，因此无法显现出显著性物体的清晰轮廓。</p><p>另外一种显著性检测方法为自上而下的模型。主要根据具体任务通过对自下而上的检测结果进行形状、大小、特征数、阈值等调整而实现的 [<xref ref-type="bibr" rid="hanspub.24304-ref6">6</xref>] 。例如：Achanta等人 [<xref ref-type="bibr" rid="hanspub.24304-ref7">7</xref>] 提出的FT (Frequency tuned)算法就是将经过高斯低通滤波图像中的每个像素值和整幅图像的平均像素值之间的欧式距离作为该点的显著值，形成了一种基于全局对比的显著区域检测方法。Cheng等人 [<xref ref-type="bibr" rid="hanspub.24304-ref8">8</xref>] 提出的RC (Region Contrast)算法则通过计算每个划分区域的显著性值，构建了基于局部对比度的显著性图。Dalal等人 [<xref ref-type="bibr" rid="hanspub.24304-ref9">9</xref>] 提出了一种基于梯度直方图特征的人体检测方法。该方法使用梯度方向直方图信息来表达人体特征，并提取人体的外形信息和运动信息，进而组成了丰富的特征集。这几种自上向下的模型 [<xref ref-type="bibr" rid="hanspub.24304-ref7">7</xref>] [<xref ref-type="bibr" rid="hanspub.24304-ref8">8</xref>] [<xref ref-type="bibr" rid="hanspub.24304-ref9">9</xref>] 均是通过图像的局部对比度特征进行显著特性分析，此类模型由于要提取多种特征，因此运算速度较慢，并且容易受到光照环境等客观因素的影响，使得目标检测的准确率大大降低。</p><p>近年来，许多研究者将机器学习等类方法应用于显著性检测方面并取得了较大进展。如杜玉龙等人 [<xref ref-type="bibr" rid="hanspub.24304-ref10">10</xref>] [<xref ref-type="bibr" rid="hanspub.24304-ref11">11</xref>] 根据人眼视觉原理，构建深度卷积神经网络模型(CNN)并结合超像素聚类方法获取图像区域特征，通过对特征进行学习实现了有效的显著性区域检测。Ying Tang等人 [<xref ref-type="bibr" rid="hanspub.24304-ref12">12</xref>] 是利用机器学习和稀疏编码的高效性和鲁棒性进行显著性检测的。此类方法鲁棒性高，但运算速度慢。为此，Bing Yang等人 [<xref ref-type="bibr" rid="hanspub.24304-ref13">13</xref>] [<xref ref-type="bibr" rid="hanspub.24304-ref14">14</xref>] 将主成分分析法(PCA)运用到显著性检测中，该方法保留了机器学习的高效性，但是，当图像背景信息量较大时，难以有效的提取出仅代表显著目标的主成分信息，从而导致检测结果含有较大的背景噪声。</p><p>在显著性检测任务中，由于图像的复杂性，对于单一级别的检测方法得到的显著图是不明确的。为了减少图像复杂度的影响，Che等人 [<xref ref-type="bibr" rid="hanspub.24304-ref15">15</xref>] 提出了HS (Hierarchical Saliency)算法。该方法通过对图像分层并计算分层显著图，有效地抑制了背景噪声对目标检测的干扰。李波等人 [<xref ref-type="bibr" rid="hanspub.24304-ref15">15</xref>] [<xref ref-type="bibr" rid="hanspub.24304-ref17">17</xref>] [<xref ref-type="bibr" rid="hanspub.24304-ref18">18</xref>] 也利用了分层图像以及融合各层特征的方式对物体进行检测，都取得了比较好的检测效果。</p><p>基于上述分析，为了减弱冗余信息对检测结果的影响以及保留机器学习的高效性，本文提出了一种基于分层PCA技术的显著性目标检测算法，利用分层PCA技术将图像分成背景信息缺失程度不同的多层图像，使得每层图像都包含与其结构特征相匹配的显著目标信息，有效地突出了显著目标并减少了背景噪声，使得在提取主成分信息的过程中减少计算量并减弱背景信息对检测过程的干扰，有利于将目标与背景相分离，保留机器学习的高效性，增加算法的鲁棒性。</p></sec><sec id="s4"><title>2. 算法描述</title><p>分层PCA显著性目标检测算法流程如图1所示。其基本处理过程为：首先，对原始图像进行分层，利用不同比特层包含的数据重构一幅图像，从而突出显著目标的信息。接着，为了融合多种特征，将原图的色彩结构转移到分层后的灰度图像中，使得每层图像都具有与原图像相对应的色彩结构。第三，运用PCA (principal component analysis)算法提取出各自的结构特征及颜色特征。第四，将两种差异特征相融合得到多幅显著图；最后，通过信息熵选择出最优结果。</p><sec id="s4_1"><title>2.1. 比特面图像分层原理</title><p>一幅8比特灰度图像，可以认为是8个1比特的平面组成，每个平面都包含与其相匹配的显著信息。</p><p>图1. 算法流程图</p><p>其中4个高阶比特平面，特别是最后两个比特平面，包含了显著目标的大多数信息。而低阶比特平面则在图像上贡献了更精细的灰度细节，这就意味着可以使用显著信息更多的比特层来构建原图，突出显著目标在整幅图像中所占的比重。因此，可以用不同的比特层信息来表示分层后的图像。其算法步骤为：</p><p>1) 将原图像转换为灰度图像并作为第一层图像。</p><p>2) 将第一层图像的最低有效比特层置零，得到一幅包含了七个比特层的图像作为第二层图像输出，接着对第二层图像的最低有效比特层置零作为第三层图像输出，以此类推，直到图像仅保留一个比特层。</p><p>3) 将得到的比特层数不同的二进制数据转换成十进制像素值，从而获得与比特层数相匹配的多层图像。</p><p>选择利用去除二进制某一比特层的方法实现图像分层，目的是产生多层以显著目标为主要信息的图像，减少背景信息的干扰。其操作结果如图2所示。</p><p>从图2可以看出，不同的比特平面层包含的图像信息大不相同，第八幅图像明显减少了显著物体所包含的信息，使得图像中的显著目标区域缺失。而其他图像由于缺失的比特层不同也在一定程度上减少了背景信息，突出了显著目标所包含的信息。</p></sec><sec id="s4_2"><title>2.2. 彩色转换</title><p>基于比特面的图像分层是在灰度图像的基础上进行的，为了使分层图像保持原有的色彩特征，将原图像的色彩结构作为模具对分层后的灰度图像进行色彩转移。</p><p>在转换过程中，经常采用的技术是灰度级-彩色变换，意思就是对黑白图像上的每一个像素点，取得该点的灰度值并送入三个通道经过实施不同的变换，产生相应的R、G、B的亮度值，即所求彩色图像对应像素点的彩色值，这样不仅能够保留原图像中显著目标与背景的模式差异，也将两者的颜色进行了区分，增强了显著目标的对比度，使得检测更加方便可行。</p><p>图2. 图像分层结果</p><p>本文采取了文献 [<xref ref-type="bibr" rid="hanspub.24304-ref19">19</xref>] 的方法，实现步骤为：</p><p>1) 将原图像作为参考图像I<sub>o</sub> (original image)，分层后的图像作为待处理图像I<sub>g</sub> (gray image)，将I<sub>g</sub>扩展到三通道，并将扩展后的图像与I<sub>o</sub>分别转化到YC<sub>b</sub>C<sub>r</sub>空间(其中Y是指亮度分量，C<sub>b</sub>指蓝色色度分量，而C<sub>r</sub>指红色色度分量)。</p><p>2) 对I<sub>o</sub>构成的图像矩阵的每一列求最大值和最小值，假设图像的分辨率为n &#180; m，用 P ( i , j ) n ( 1 &lt; i &lt; n , 1 &lt; j &lt; m ) 来表示第m列的像素点，则矩阵中每一列的最大值和最小值我们可以表示为：</p><p>P max m = max ( P 1 , 1 m , P 1 , 2 m , ⋯ , P 1 , n m )</p><p>P min m = min ( P 1 , 1 m , P 1 , 2 m , ⋯ , P 1 , n m )</p><p>紧接着计算出两幅图像的最大值 I o max ， I g max 和最小值 I o min ， I g min 。</p><p>3) 对两幅图像进行归一化处理以得到重构的彩色图像模具 [<xref ref-type="bibr" rid="hanspub.24304-ref14">14</xref>] ：</p><p>M a r k 1 = I g − I g min I g max − I g min , (1)</p><p>M a r k 2 = I o − I o min I o max − I o min , (2)</p><p>4) 进行色彩映射转移，将Mark2中的像素值转移到对应的Mark1中的像素点上，使分层后的灰度图像具有与原图像相同的色彩结构。转换结果如图3所示。</p></sec></sec><sec id="s5"><title>3. 利用分层PCA生成显著图</title><p>不要主成分分析(PCA)是多元统计分析中用来分析数据的一种方法，它是用一种较少数量的特征对样本进行描述以达到降低特征空间维数的方法。本文所提出的算法是针对分层的显著目标包含的像素附近区域独特的结构和颜色特征作为主元成分参考，重构一幅融合两种特征的显著图。由于分层的结果，使得每层图像的集成模式和颜色模式均不同于其他图像，由上一小节内容可知，分层的图像中总是存在一</p><p>图3. 色彩转换效果图</p><p>层背景信息减少而突出显著目标的图像，因此，通过计算每层图像的显著性，进而找出最接近真值的结果输出。实验结果图4所示，其中(a)~(h)分别代表其上方所对应的分层图像的显著图。算法的具体计算过程如下所述。</p><sec id="s5_1"><title>3.1. 提取结构特征</title><p>除为了提高结构特征计算的效率，本文提出了一种基于主成分分析(principal component analysis, PCA) 的结构特征计算方法 [<xref ref-type="bibr" rid="hanspub.24304-ref20">20</xref>] 。</p><p>首先对彩色分层图像进行主成分分析，然后将每层图像分成大小为9 &#215; 9的图像块，N表示分割后图像块的总个数。对于单层图像来讲，每一个以像素点i为中心的图像块用 p i 表示，则平均图像块 p a 可定义为 [<xref ref-type="bibr" rid="hanspub.24304-ref20">20</xref>] ：</p><p>p a = 1 N ∑ i = 1 N     p i (3)</p><p>接下来，我们沿着主成分方向计算出每一个图像块 p i 与平均图像块 p a 之间的距离 d ( p i , p a ) ；并以此距离的大小来判定一个图像块是否具有显著的结构特征，每个图像块的位置坐标用其中心像素点 p i ( i x , i y ) 表示，平均图像块的位置用 p a ( a x , a y ) 表示。则 d ( p i , p a ) 定义式如下 [<xref ref-type="bibr" rid="hanspub.24304-ref20">20</xref>] ：</p><p>d ( p i , p a ) = 1 N &#215; ∑ i = 1 N     p i &#215; ( i x − a x ) 2 + ( i y − a y ) 2 S ( i , a ) 2 (4)</p><p>其中， S ( i , a ) 2 是两个图像块之间的方差。</p><p>判决规则： d ( p i , p a ) 较大时，图像块具有显著特性，反之为普通图像块。从数学含义上讲，结构特征的提取归结为在PCA坐标系统中计算 p i 的L<sub>1</sub>范数，因此，进一步定义结构特征 P ( p i ) 为 [<xref ref-type="bibr" rid="hanspub.24304-ref20">20</xref>] ：</p><p>P ( p i ) = ‖ p ′ i ‖ 1 (5)</p><p>图4. 分层图像显著图</p><p>式中： p ′ i 为 p i 在PCA坐标系下的坐标。 ‖   ⋅   ‖ 1 表示L<sub>1</sub>范数的运算符号。</p></sec><sec id="s5_2"><title>3.2. 提取颜色特征</title><p>尽可能使用国际尽管结构特征的提取可以找出图像中最独特的图块，但并不是适用于所有图像。如图5所示：图中各个球体的结构特征相同，但颜色不同，这种情况下则认为颜色特征更特殊的为显著区域，因此颜色特征的提取必不可少。</p><p>这里，采用两个步骤来检测颜色差异的图像块。第一步：采用简单的线性迭代聚类超像素分割法将每层图片分隔成若干个图像块，然后再确定哪个图像块具有独特的颜色特征。第二步，把YCbCr颜色空间中该图像块与其他图像块的距离之和定义为该图像块的颜色差异。这里，用 r i 表示第i个图像块在色彩空间中的位置， r j 表示第j个图像块的位置。从数学含义上讲，对图像块 r i 提取颜色特征是在PCA坐标系统中计算它的L<sub>2</sub>范数。因此，我们把 r i 的颜色特征 C ( r i ) 定义为 [<xref ref-type="bibr" rid="hanspub.24304-ref20">20</xref>] ：</p><p>C ( r i ) = ∑ j = 1 M ‖ r i − r j ‖ 2 (6)</p><p>上式中， r i − r j 表示两个图块之间的距离。 ‖   ⋅   ‖ 1 表示L<sub>2</sub>范数的运算符号。M表示超像素分割后的图块总数。</p></sec><sec id="s5_3"><title>3.3. 结构特征与颜色特征的显著性融合</title><p>对单一的图像结构特征或者颜色特征都无法有效地表征显著目标的所有信息。为了得到准确的显著目标，我们将各层图像的结构特征和颜色特征相结合来检测不同层图像的显著区域。这里，我们采用的融和特征规则通过式(7)得到：</p><p>D ( p i ) = P ( p i ) ⋅ C ( p i ) (7)</p><p>之后，通过归一化将融合特征限制到[0,1]范围内。</p><p>由于视觉上显著像素往往是集群形式，它们一般对应于真实场景中的物体，为了进一步修正显著模型，人们通常采用中心先验的方法将目标区域放在近似中心处。基于中心先验的算法 [<xref ref-type="bibr" rid="hanspub.24304-ref21">21</xref>] 通常以目标位于图像中心作为假设条件，通过用一个峰值位于中心的高斯函数定义中心先验权重，根据权重分布不同从而有层次地突出位于图像中心的目标显著值。这里，用不同阈值下的像素集表示不同的目标区域，阈值均匀分布在[0,1]区间(均匀的取10个阈值)。因此，中心先验计算过程如下；</p><p>1) 用融和特征映射D(p<sub>i</sub>)检测不同层的像素集,计算每个阈值结果的重心。</p><p>2) 每个重心放置一个δ设为10,000的高斯分布，计算各个阈值相应的高斯权重。</p><p>3) 在各层图像中心处增加一个权重为5的高斯分布，提高中心位置的权重。</p><p>用高斯权重映射 G ( p i ) 表示所有高斯分布的加权和，根据权重分配的差异给予不同的显著优先级。</p><p>图5. 色彩特征提取</p><p>因此，可以进一步定义显著性映射，将融合特征映射和高斯权重映射相结合，得到突出中心目标的融合显著图 S ( p i ) ，即：</p><p>S ( p i ) = D ( p i ) ⋅ G ( p i ) (8)</p></sec><sec id="s5_4"><title>3.4. 最优结果判决</title><p>经过特征融合可以得到检测结果不同的多幅显著图，运用一种判决方法，使得输出的图像噪声最小，信息量最多。</p><p>在信息论当中，熵是一个比较基础的概念，它代表了在随机事件当中的平均信息量。信息熵往往暗含着图像信号中前景与背景噪声的分布情况。一般情况下，若是一幅图像显著区域越明显，那么它在整幅图像的表现上就越突出，同时重复出现的背景区域也就抑制的较多。因此，显著区域在直方图上也就聚集在某一特定区域值里面，同时提供了较小的信息熵。基于这一事实，通常的规则为：最小的信息熵对应最佳的显著图。对于一幅图像信号X来说，其信息熵定义为：</p><p>E n s ( X ) = − ∑ i = 1 m   ∑ j = 1 n     p ( X i , j ) log p ( X i , j ) (9)</p><p>在式中， X i , j ( i = 1 , 2 , ⋯ , m ; j = 1 , 2 , ⋯ , n ) 表示的是图像X在第i行第j列的像素灰度值， p ( X i , j ) 意味着在图像X中， X i , j 发生的概率，Ens代表的是图像信息熵。</p><p>那么最佳尺度的显著图 k o p t 可以表示为：</p><p>k o p t = argmin k ( E n s ( S k ) ) ,     k = 1 , ⋯ , K (10)</p><p>对分层PCA处理后的多层显著图计算信息熵，结果如下表所示：</p><p>表1中数据为图6所示各个图像的信息熵。利用上述信息熵判定规则对8层图像进行判决，选择信息熵最小的图像作为最优结果输出，由此得到背景信息最少的显著图也就是最终结果图。</p></sec></sec><sec id="s6"><title>4. 实验结果及分析</title><p>分别在MSRA-1000、ASD-1000、ESSCD-1000等数据集上对上面所提出的分层PCA显著性目标检测算法进行了测试，并与几种经典ITTI (IT)、GBVS (GB)、SR、LC、HS等进行了比较。所产生的结果分别由文献 [<xref ref-type="bibr" rid="hanspub.24304-ref1">1</xref>] 、 [<xref ref-type="bibr" rid="hanspub.24304-ref2">2</xref>] 、 [<xref ref-type="bibr" rid="hanspub.24304-ref3">3</xref>] 、 [<xref ref-type="bibr" rid="hanspub.24304-ref15">15</xref>] [<xref ref-type="bibr" rid="hanspub.24304-ref22">22</xref>] 、作者主页所提供的原码或可执行软件在各个数据集上测试生成。CHS [<xref ref-type="bibr" rid="hanspub.24304-ref23">23</xref>] 采用文献 [<xref ref-type="bibr" rid="hanspub.24304-ref23">23</xref>] 作者主页提供的在ECCSD数据集上生成的原始数据。视觉对比结果如图7所示。此外，为了客观的评价检测结果，我们用准确率(PRE)、召回率(REC)和F-measure (FME)等性能参数各种算法进行了评估。准确率、召回率和F-measure定义式如公式(11)~(13)所示：</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Entropy of hierarchical image informatio</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" >第1层</th><th align="center" valign="middle" >第2层</th><th align="center" valign="middle" >第3层</th><th align="center" valign="middle" >第4层</th><th align="center" valign="middle" >第5层</th><th align="center" valign="middle" >第6层</th><th align="center" valign="middle" >第7层</th><th align="center" valign="middle" >第8层</th></tr></thead><tr><td align="center" valign="middle" >图7—B1</td><td align="center" valign="middle" >6.3323</td><td align="center" valign="middle" >6.3976</td><td align="center" valign="middle" >6.3342</td><td align="center" valign="middle" >6.3592</td><td align="center" valign="middle" >6.3084</td><td align="center" valign="middle" >6.3650</td><td align="center" valign="middle" >5.7816</td><td align="center" valign="middle" >6.0554</td></tr><tr><td align="center" valign="middle" >图7—B2</td><td align="center" valign="middle" >7.2114</td><td align="center" valign="middle" >6.7306</td><td align="center" valign="middle" >7.0384</td><td align="center" valign="middle" >7.0239</td><td align="center" valign="middle" >6.9984</td><td align="center" valign="middle" >7.0126</td><td align="center" valign="middle" >7.1003</td><td align="center" valign="middle" >7.0316</td></tr><tr><td align="center" valign="middle" >图7—B3</td><td align="center" valign="middle" >5.7816</td><td align="center" valign="middle" >5.8034</td><td align="center" valign="middle" >5.7501</td><td align="center" valign="middle" >5.6330</td><td align="center" valign="middle" >5.5693</td><td align="center" valign="middle" >5.6912</td><td align="center" valign="middle" >5.7864</td><td align="center" valign="middle" >5.7906</td></tr></tbody></table></table-wrap><p>表1. 分层图像信息熵</p><p>图6. 分层PCA显著图</p><p>图7. 算法结果对比图</p><p>PRE = TP TP + FP (11)</p><p>REC = TP TP + FN (12)</p><p>FME = 2 &#215; PRE &#215; REC PRE + REC (13)</p><p>其中，TP表示检测出的显著目标的像素个数，TN表示将背景正确划分为背景类的像素个数，FP表示提取出错误背景的像素个数，FN表示将显著目标错误划分为背景类的像素个数。</p><p>图8所示为在3个公共数据集上，不同显著性检测算法的PR 曲线，图9为图8所示各个算法结果的F-measure对比直方图。可以看出，由于数据集ESSCD图像识别率较高，HS，LC算法的准确率超过90%，但F-measure值较低。在较为复杂的MSAR数据集上,各个算法在一定程度上降低了召回率，并且IT、GB、LC等算法的F-measure值明显降低。在较为简单的ASD数据集上，GB算法的召回率较高，</p><p>图8. 不同数据集P-R曲线</p><p>图9. F-measure值对比直方图</p><p>HS算法在准确率与F-measure值上有一定的优势。总体上，本文算法在不同数据集上的准确率均超过90%，并且平均F-measure值高于其他算法，检测效果稳定，鲁棒性较好。</p></sec><sec id="s7"><title>5. 结论</title><p>本文提出了一种基于分层PCA技术的显著性目标检测算法。实验结果表明，所提出算法能够减少背景噪声干扰，有效的将背景与目标分离，在检测精度、召回率以及F-measure参数等方面具有一定优势，同时保留了机器学习方法在提升显著性检测效果方面的优良特性。因此，分层PCA显著性检测技术是一种有效的复杂背景下的目标检测方法。分层PCA算法无法同时对图像中的所有信息进行分析，当图像背景中的物体与目标对象拥有同等级的亮度及分辨率时，难以提取出完整的目标信息。因此，本文下一步的工作目标是针对这一问题进行研究，进一步提高整幅图像的信息利用率以得到更精确的显著目标信息。</p></sec><sec id="s8"><title>文章引用</title><p>王烨蕾,李 玲,辛云宏. 基于分层PCA技术的显著性目标检测算法 Saliency Detection Based on Hierarchical PCA Technology[J]. 计算机科学与应用, 2018, 08(03): 398-409. https://doi.org/10.12677/CSA.2018.83044</p></sec><sec id="s9"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.24304-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Itti, L., Koch, C. and Niebur, E. (1998) A Model of Saliency-Based Visual Attention for Rapid Scene Analysis. IEEE Transactions on Pattern Analysis and Machine Intelligence, 20, 1254-1259. &lt;br&gt;https://doi.org/10.1109/34.730558</mixed-citation></ref><ref id="hanspub.24304-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Yang, C., Zhang, L.H., Lu, H.C., et al. (2013) Saliency Detection via Graph-Based Manifold Ranking. IEEE Conference on Computer Vision and Pattern Recognition, 23-28 June 2013, Portland, OR, 3166-3173.  
&lt;br&gt;https://doi.org/10.1109/CVPR.2013.407</mixed-citation></ref><ref id="hanspub.24304-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Hou, X.D. and Zhang, L.Q. (2007) Saliency Detection: A Spectral Residual Approach. IEEE Conference on Computer Vision and Pattern Recognition, 17-22 June 2007, Minneapolis, MN, 1-8. &lt;br&gt;https://doi.org/10.1109/CVPR.2007.383267</mixed-citation></ref><ref id="hanspub.24304-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Shen, X.H. and Wu, Y. (2012) A Unified Approach to Sa-lient Object Detection via Low Rank Matrix Recovery. IEEE Conference on Computer Vision and Pattern Recognition, 16-21 June 2012, Providence, RI, 853-860.  
&lt;br&gt;https://doi.org/10.1109/CVPR.2012.6247758</mixed-citation></ref><ref id="hanspub.24304-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Li, C., Chen, Z., Li, S., Wang, Y.G., et al. (2017) Video Sali-ency Detection via Spatial-Temporal Fusion and Low-Rank Coherency Diffusion. IEEE Transactions on Image Pro-cessing, 26, 3156-3170.  
&lt;br&gt;https://doi.org/10.1109/TIP.2017.2670143</mixed-citation></ref><ref id="hanspub.24304-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">张旭东, 吕言言, 缪永伟, 郝鹏翼, 陈佳舟. 结合区域协方差分析的图像显著性检测[J]. 中国图象图形学报, 2016, 21(5): 605-615.</mixed-citation></ref><ref id="hanspub.24304-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Achanta, R., Hemami, S., Estrada, F., et al. (2009) Frequency-Tuned Salient Region Detection. IEEE Conference on Computer Vision and Pattern Recognition, 20-25 June 2009, Miami, FL, 1597-1604.  
&lt;br&gt;https://doi.org/10.1109/CVPR.2009.5206596</mixed-citation></ref><ref id="hanspub.24304-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Cheng, M.M., Mitra, N.J., Huang, X., et al. (2015) Global Contrast Based Salient Region Detection. IEEE Transactions on Pattern Analysis and Machine Intelligence, 37, 569-582. &lt;br&gt;https://doi.org/10.1109/TPAMI.2014.2345401</mixed-citation></ref><ref id="hanspub.24304-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Dalal, N. and Triggs, B. (2005) Histograms of Oriented Gra-dients for Human Detection. Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 20-25 June 2005, San Diego, CA, 886-893. &lt;br&gt;https://doi.org/10.1109/CVPR.2005.177</mixed-citation></ref><ref id="hanspub.24304-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">杜玉龙, 李建增, 张岩. 基于深度交叉CNN和免交互GrabCut的显著性检测[J]. 电子工程与应用, 2017, 53(3): 32-40.</mixed-citation></ref><ref id="hanspub.24304-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">李岳云, 许悦雷, 马时平, 史鹤欢. 深度卷积神经网络的显著性检测[J]. 中国图象图形学报, 2016, 21(1): 53-59.</mixed-citation></ref><ref id="hanspub.24304-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Tang, Y., Zhu, L. and Wu, J. (2017) Salient Object Detection on Multiscale Learning and Sparse Coding. Control Conference (CCC), 26-28 July 2017, Dalian, 11047-11052.</mixed-citation></ref><ref id="hanspub.24304-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">马小龙, 谢旭东, 林健文. 基于鲁棒主成分分析和多个色彩通道的显著性检测[J]. 清华大学学报, 2014(8): 1122-1126.</mixed-citation></ref><ref id="hanspub.24304-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">Yang, B., Zhang, X.Y., Chen, L., et al. (2016) Principal Component Analysis-Based Visual Saliency Detection. IEEE Transactions on Broadcasting, 62, 842-854.</mixed-citation></ref><ref id="hanspub.24304-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">Che, Z.H., Zhai, G.T. and Min, X.K. (2015) A Hierarchical Saliency Detection Approach for Bokeh Im-ages. 17th International Workshop on Multimedia Signal Processing, Xiamen, 19-21 October 2015, 1-6.</mixed-citation></ref><ref id="hanspub.24304-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">祝军, 赵杰煜, 董振宇, 等. 融合显著信息的层次特征学习图像分类[J]. 计算机研究与发展, 2014, 51(9): 1919-1928.</mixed-citation></ref><ref id="hanspub.24304-ref17"><label>17</label><mixed-citation publication-type="other" xlink:type="simple">李波, 金连宝, 曹俊杰, 冷成财, 卢春园, 苏志勋. 分层信息融合的物体级显著性检测[J]. 中国图象图形学报, 2016, 21(5): 595-604.</mixed-citation></ref><ref id="hanspub.24304-ref18"><label>18</label><mixed-citation publication-type="other" xlink:type="simple">罗会兰, 万成涛, 孔繁胜. 基于KL散度及多尺度融合的显著性区域检测算法[J]. 电子与信息学报, 2016, 38(7): 1594-1601.</mixed-citation></ref><ref id="hanspub.24304-ref19"><label>19</label><mixed-citation publication-type="other" xlink:type="simple">Zhang, Y., Zhao, T.H., Mo, Z.P., et al. (2013) A Method of Illumination Effect Transfer between Images using Color Transfer and Gradient Fusion. Signal and Infor-mation Processing Association Annual Summit and Conference, Kaohsiung, 29 October-1 November 2013, 1-6.</mixed-citation></ref><ref id="hanspub.24304-ref20"><label>20</label><mixed-citation publication-type="other" xlink:type="simple">王姮, 王曼, 张华, 刘桂华. 基于PCA模式和颜色特征的钢轨表面缺陷视觉显著性检测[J]. 自动化仪表, 2017, 38(1): 73-76.</mixed-citation></ref><ref id="hanspub.24304-ref21"><label>21</label><mixed-citation publication-type="other" xlink:type="simple">周帅骏, 任福继, 堵俊杨. 融合背景先验与中心先验的显著性目标检测[J]. 中国图象图形学报, 2017, 22(5): 584-595.</mixed-citation></ref><ref id="hanspub.24304-ref22"><label>22</label><mixed-citation publication-type="other" xlink:type="simple">Fang, Y.M., Zhang, C., Li, J., et al. (2017) Visual Attention Modeling for Stereoscopic Video: A Benchmark and Computational Model. IEEE Transactions on Image Processing, 26, 4684-4696.  
&lt;br&gt;https://doi.org/10.1109/TIP.2017.2721112</mixed-citation></ref><ref id="hanspub.24304-ref23"><label>23</label><mixed-citation publication-type="other" xlink:type="simple">Zhang, L.H., Yang, C., Lu, L.C., et al. (2017) Ranking Saliency. IEEE Transactions on Pattern Analysis and Machine Intelligence, 39, 1892-1904. &lt;br&gt;https://doi.org/10.1109/TPAMI.2016.2609426</mixed-citation></ref></ref-list></back></article>