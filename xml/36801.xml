<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">SA</journal-id><journal-title-group><journal-title>Statistics and Application</journal-title></journal-title-group><issn pub-type="epub">2325-2251</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/SA.2020.94056</article-id><article-id pub-id-type="publisher-id">SA-36801</article-id><article-categories><subj-group subj-group-type="heading"><subject>SA20200400000_81932205.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>数学与物理</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于文本挖掘的纪录片传播影响因素分析
  Analysis of Influencing Factors of Documentary Communication Based on Text Mining
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>黄</surname><given-names>梓玉</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>孟</surname><given-names>捷</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>云南大学数学与统计学院，云南 昆明</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>29</day><month>07</month><year>2020</year></pub-date><volume>09</volume><issue>04</issue><fpage>525</fpage><lpage>532</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
  
    为了解影响纪录片传播的因素，将爬虫得到数据资源清洗后，经描述统计获得基础影响因素作为分类变量，使用Python得到较精准的中文分词结果，编写Gibbs算法建立LDA模型来进行分析得到不同纪录片适合的困惑度和主题数以及语义网络、词云图等结果。通过分析文本的结果得知人们的价值观与纪录片的传播可展现双向的影响作用，纪录片的拍摄会根据时代的主流与需求进行拍摄，而时代的主流与需求也是人们的价值观最直接的展现；再者，人们通过观看纪录片来了解当下的世界展现给人们的面目，同样这也是一种对人们思维的引领方向，影响较大的为人们的现实需求、纪录片的承载形式以及纪录片的真实性。
    After cleaning the basic influence factors as classification variables obtained from the descriptive statistics, in order to understand the factors affecting the spread of the documentary, the crawled data resources get more accuracy of Chinese word segmentation results using Python. Writing Gibbs algorithm analysis LDA model is set up to get a different degree of confusion and theme of the documentary for number and semantic network, such as word cloud image results. Through the analysis of the text, it is found that people’s values and the dissemination of documentaries can show a two-way influence. Documentary filming will be based on the mainstream and demand of The Times, which is also the most direct display of people’s values. In addition, people can under-stand what the current world shows to people by watching documentaries, which is also a guiding direction for people’s thinking and has a great influence on people’s practical needs, the carrying form of documentaries and the authenticity of documentaries. 
  
 
</p></abstract><kwd-group><kwd>动态网页爬虫，中文分词，Gibbs算法，LDA模型，语义分析, Dynamic Web Crawler</kwd><kwd> Chinese Word Segmentation</kwd><kwd> Gibbs Algorithm</kwd><kwd> The LDA Model</kwd><kwd> Semantic Analysis</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>基于文本挖掘的纪录片传播影响因素分析<sup> </sup></title><p>黄梓玉，孟捷<sup>*</sup></p><p>云南大学数学与统计学院，云南 昆明</p><p>收稿日期：2020年7月9日；录用日期：2020年7月23日；发布日期：2020年7月30日</p><disp-formula id="hanspub.36801-formula61"><graphic xlink:href="//html.hanspub.org/file/4-2580633x6_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>为了解影响纪录片传播的因素，将爬虫得到数据资源清洗后，经描述统计获得基础影响因素作为分类变量，使用Python得到较精准的中文分词结果，编写Gibbs算法建立LDA模型来进行分析得到不同纪录片适合的困惑度和主题数以及语义网络、词云图等结果。通过分析文本的结果得知人们的价值观与纪录片的传播可展现双向的影响作用，纪录片的拍摄会根据时代的主流与需求进行拍摄，而时代的主流与需求也是人们的价值观最直接的展现；再者，人们通过观看纪录片来了解当下的世界展现给人们的面目，同样这也是一种对人们思维的引领方向，影响较大的为人们的现实需求、纪录片的承载形式以及纪录片的真实性。</p><p>关键词 :动态网页爬虫，中文分词，Gibbs算法，LDA模型，语义分析</p><disp-formula id="hanspub.36801-formula62"><graphic xlink:href="//html.hanspub.org/file/4-2580633x7_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2020 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/4-2580633x8_hanspub.png" /> <img src="//html.hanspub.org/file/4-2580633x9_hanspub.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>纪录片是记录真实生活后通过特定加工形式及表现手法而体现的生活写照。纪录片市场也逐渐成熟，更多优秀的纪录片从国内走向国际，观影方式也与纪录片进行融合也展现了多元化，此次数据来源为腾讯视频纪录片片库，对片库中的纪录片进行影响因素研究。</p><p>回顾我国纪录片的而发展历程，中日合拍的纪录片《丝绸之路》较早的展现了此历程的开始，为电视与电影开创了极具影响作用的传播引领作用。国内纪录片极具多样化标准，在其中，题材的多元化选择视角、实际的故事引导性、拍摄手法多样性与真实事件的展现都可体现纪录片在人民群众中的广泛传播。基于中国目前所处于的国际地位的上升，逐渐形成走向国际市场进行竞争从而提升自身的影响程度。何莹莹通过对增加电视纪录片故事性的方法和手段研究来剖析电视纪录片故事化叙事方法 [<xref ref-type="bibr" rid="hanspub.36801-ref1">1</xref>]。孟庆龙通过对国外纪录片发展史上不同制作模式的“故事化”叙事方法考察，寻找“故事化”叙事方法演变的轨迹 [<xref ref-type="bibr" rid="hanspub.36801-ref2">2</xref>]。王鹏飞通过对题材的取舍研究来分析题材独特性与普遍性的内在统一 [<xref ref-type="bibr" rid="hanspub.36801-ref3">3</xref>]。国外纪录片的发展状况较国内而言要早一些，他们提出了纪录片的记录性与纪实性。万燕蓉用各种方法从消费者角度探讨纪录片需求 [<xref ref-type="bibr" rid="hanspub.36801-ref4">4</xref>]。张芳以受众心理学、纪实美学为基础结合案例调查法等多种科学研究方法对纪录片创作进行分析 [<xref ref-type="bibr" rid="hanspub.36801-ref5">5</xref>]。李琰从翻译中的归化和异化策略角度研究纪录片中字幕翻译引起的多种问题 [<xref ref-type="bibr" rid="hanspub.36801-ref6">6</xref>]。以上的分析大多源自文献资料的总结分析整理所得，而对纪录片中评论内容做相关性的研究。因此本文将评论内容语义集建立文本挖掘模型来及逆行相关文本类研究。</p></sec><sec id="s4"><title>2. 数据处理</title><sec id="s4_1"><title>2.1. 数据来源</title><p>在本文中，利用网络爬虫，获取纪录片的相关信息，如片名、播放量、上映时间、评分、标签、简介、短评总数和短评详情等。首先提取全部纪录片的URL标签，再根据已获得的各纪录片URL对纪录片详情进行分析提取，使用selenium库中的webdriver进行驱动浏览器，模拟用户正常上网行为，通过这样来获取异步加载后的评论信息。根据影片的id号通过抓包的方式获得短评内容及下一页开头评论id号，以此循环至全部抓取完毕或达到满足分析使用的标准。获得详细数据如下表(表1)所示。将获得到的影片详细信息进行数据清洗及筛选工作，获得用于分析的最终数据。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Sample content for the documentary has been downloade</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >片名</th><th align="center" valign="middle" >播放量</th><th align="center" valign="middle" >上映时间</th><th align="center" valign="middle" >评分</th><th align="center" valign="middle" >标签</th><th align="center" valign="middle" >短评总数</th><th align="center" valign="middle" >短评详情</th></tr></thead><tr><td align="center" valign="middle" >宵夜江湖美食纯享</td><td align="center" valign="middle" >884.7万</td><td align="center" valign="middle" >2019 8.20发布</td><td align="center" valign="middle" >7.6</td><td align="center" valign="middle" >内地 2019 美食</td><td align="center" valign="middle" >5</td><td align="center" valign="middle" >1.真要命的视频，放在嘴里的感觉和幸福有关 2.我去，人家用竹子轩，他们用铁，吃了致癌 3.烤串位置在哪儿呢想去 4.不能合到一起放嘛。 5.羊肉串吗？？？？？？</td></tr></tbody></table></table-wrap><p>表1. 纪录片已下载内容示例</p><p>由上表可以看出，下载得到的纪录片相关信息较为完整，查看所有的纪录片文本可以发现下载的数据完整性较高，其中包括在播的纪录片以及已下架的纪录片，选择将数据进行清洗，获得可进行分析的文本。</p></sec><sec id="s4_2"><title>2.2. 数据清洗与基础分类</title><p>通过爬虫获得的纪录片数据需进行简单清洗，清洗的原因主要在于部分纪录片存在下架的情况、纪录片涉及政治因素或是纪录片带有强烈的多方因素影响，在多种情形的作用下，就会有纪录片内容缺失、评论被屏蔽或者开启评论筛选的多种选择，此类情况的评论内容受到版权限制，无法收集得到。故选择将没有评论内容的数据进行剔除处理以调整具备评论内容的数据的平衡。再通过Excel进行繁简体转换、空白格替换等方式得到最为基础的清洗数据。</p></sec></sec><sec id="s5"><title>3. 主题挖掘</title><p>不要使用空格、制表符设置段落缩进，不要通过连续的回车符(换行符)调整段间距。</p><sec id="s5_1"><title>3.1. 文本分词</title><p>除了一些众所周知的英文缩写，如IP、CPU、FDA，所有的英文缩写在文中第一次出现时都应该给出其全称。文章标题中尽量避免使用生僻的英文缩写。</p><sec id="s5_1_1"><title>3.1.1. 停止词建立</title><p>停止词在分词的使用中，具备重要作用，通过建立停止词库，去除无效的词汇，可方便结果实施，若不去除无意义词，则会使关键性情感词的比例下降，所得出的结论就不具备代表性。得到停止词的方法大部分为三种，一种是网络资源进行查找，可以较快的获得停止词库，是比较简便的方法；第二种是自己编写，对于不同的文本数据，对应的无意义词也是不同的，那么在这种情况下，自己编写的停止词就更有针对性，能够更有效率的获得准确度高的分词结果；第三种一般为编程软件自带的停止词库，可调用，同时也可以通过导出来格式来方便下次使用。例如R语言中：write.table (stopwordsCN(x), ‘filename’)，就可以实现将R语言中内置的停止词写成文件格式导出，但这种方式获得的停止词只有519个，远远不适用于普遍使用。就一般使用而言，基本的停止词量是在1400左右，那么这种情况就需要在已有的停止词的基础上，进行补充来确保此次所使用的停止词库的完整性。</p></sec><sec id="s5_1_2"><title>3.1.2. 中文分词</title><p>本文通过Python来进行分词，在进行分析时，同时需要导入各种库的使用，进行中文分词功能时，使用最多的就是jieba语库，主要通过pandas、xlwt这两个库来驱动实施，Python实现的分词并没有分离开表情符号等文字，而是最大程度的保留了原始文本以确保分词的完整性，在通过自定义函数去掉停止词、除去其中包含的数字和字母，最终得到的结果分别存入csv以及txt两种格式备用，查看分词内容时，若出现其余无效字符，可以手动增加停止词文件的内容，并再次剔除，反复进行，最终可得到一份较为适合的分词结果，经过多次分词结果的比对，选择先通过Python中jieba语库进行语义分词，再导入ROST CM6中进行情感分析以及聊天分析，获得多种分词结果。进行查看后，发现所保留的内容有效成分高达98%，更优于匹配率97%，那么此份数据便成为进行文本模型构建的依据。</p></sec></sec><sec id="s5_2"><title>3.2. LDA模型概况</title><sec id="s5_2_1"><title>3.2.1. LDA简述</title><p>LDA的全称是隐含狄利克雷分布(Latent Dirichlet Allocation)，一种文档主题生成模型。在机器学习中，即为线性判别，其主要功能为降维与分类 [<xref ref-type="bibr" rid="hanspub.36801-ref7">7</xref>]。若是进行文本主题类的则需要进行具备三层贝叶斯结构的文档主题模型，其内容由词、主题以及文档组成。</p><p>LDA是基于贝叶斯模型的，而贝叶斯模型最为主要的三个关键地方就是先验分布、似然估计以及后验分布。贝叶斯推断的含义在于先预估数据的先验概率，再将其置于实验，判断实验结果对先验概率的影响是加强或是削减 [<xref ref-type="bibr" rid="hanspub.36801-ref8">8</xref>]。那么在最初的朴素贝叶斯的思想中，根据条件独立公式获得条件概率公式，并</p><p>以此推得贝叶斯公式： P ( Y k | X ) = P ( X | Y k ) P ( Y k ) ∑ k P ( X | Y = Y k ) P ( Y k ) 。引申获得三层的贝叶斯模型，在这其中，实</p><p>现文档到主题服从多项式分布，主题到词服从多项式分布。</p><p>在贝叶斯的推断中，狄利克雷分布作为多项分布的共轭先验得到较多的应用，可运用到LDA模型中。在二维的分布中，可使用二项分布和Beta分布进行表达，类推可以获得在三维情形中，可以用三维的Beta分布来表达先验后验分布、三项的多项分布来表示具备似然情况的数据。</p><p>在三维的多项分布中可以写成： multi ( x 1 , x 2 , x 3 | n , p 1 , p 2 , p 3 ) = n ! x 1 ! x 2 ! x 3 ! p 1 x 1 p 2 x 2 p 3 x 3</p><p>同时，通过二维的Beta分布可类推获得三维的Dirichlet分布，形式如下：</p><p>Dirichlet ( p 1 , p 2 , p 3 | α 1 , α 2 , α 3 ) = Γ ( α 1 + α 2 + α 3 ) Γ ( α 1 ) Γ ( α 2 ) Γ ( α 3 ) ( p 1 ) α 1 − 1 ( p 2 ) α 2 − 1 ( p 3 ) α 3 − 1</p><p>通过类推，可以获得K维Dirichlet分布表达式： Dirichlet ( p → | α → ) = Γ ( ∑ k = 1 K α k ) ∏ k = 1 K Γ ( α k ) ∏ k = 1 K p k α k − 1 ；</p><p>并通过两者共轭得到与二项分布相同的结论： Dirichlet ( p → | α → ) + Multi ( x → ) = Dirichlet ( p → | α → + x → ) 。</p></sec><sec id="s5_2_2"><title>3.2.2. 主题模型</title><p>LDA主题模型的建立同样是通过先验概率+似然=后验概率的基础公式可以得到。通过已知内容进行潜在狄利克雷分布的主题挖掘 [<xref ref-type="bibr" rid="hanspub.36801-ref9">9</xref>]。形似类似于上一小节中所提到的模型表示，通过流程图(如图1)展示的为一个文档模型的基础分布，D表示文档，数量较多，此处表示文档集合； α → 表示分布的比例参数，是维数为K维的向量，K为主题数量； θ d = Dirichlet ( α → ) 为每个文档中主题所占的比例； Z d , n = multi ( θ d ) 表</p><p>示每一主题的比例赋值； W d , n = multi ( β Z d , n ) 表示文档中观察到的词； β k 表示主题其中的值，同时服从狄利克雷分布，多主题的主题也能够表示为 β K , n 。</p><p>图1. 主题流程图</p><p>假设在一类文档中，文档主题数有N个，文档主题数N就符合狄利克雷分布，也可形成了由 α → → θ d → Z d , n 组成的狄利克雷分布多项共轭可推得 θ d 得后验分布为： Dirichlet ( θ d | α → + n d → ) ， n d → 为在第d个文档中所包含的词数，则就是文档主题的后验分布。同样道理，由主题数为K的主题元素形成的 β k , n → W d , n → 可形成狄利克雷多项共轭推得 β k , n 的后验分布为： Dirichlet ( β k | β k , n → + n k → ) ， n k → 为第k个主题中的次数，则产生了主题词分布的后验分布。通过推导所获得的公式，可形成初步的LDA思想，为后续的实施方法做更完全的准备。求解LDA主题分布的方法一般有两种，一种为Gibbs采样，另一种为变分推断EM算法，在本文中，则采取Gibbs采样的方法。</p></sec></sec><sec id="s5_3"><title>3.3. 主题数选取与困惑度</title><p>该如何选择主题数在LDA中一直是比较关键的问题，主题数目选的过于少的话，就会导致各个主题的信息过于简洁从而损失更多关键词；若主题数足够多过于全面的话，就会产生信息量的冗余，那么在信息的选择上难免会有相似的词产生冲突。这两种情况，无论是哪一种，在情感词分析的范畴中都会导致信息量的不平衡。那么该如何确定主题数量方法也是与计算量的直接体现，所以就选择的方法来讲，第一种方法是通过分类来做到肉眼的识别，这是比较直接的方法，但是该怎样分类以及怎么做到比较全面是一个比较困难的事情，若词汇量过于庞大，采取这种方法得到的主题就会很艰难，同时也可能会产生较大误差；第二种方法是按照一些特定的指标，例如Perplexity或者MPI—score这两种指标值，用处较多的是Perplexity这种方法，主要的查看方式就是根据主题数与困惑度的折线图进行查看，重点在于图中的拐点，这就需要进行代码编程；或者按照公式也可计算出困惑度。</p><sec id="s5_3_1"><title>3.3.1. 困惑度概念</title><p>困惑度的基础公式为： P ( W ˜ | M ) = ∏ m = 1 M p ( W → m ˜ ˜ | M ) − 1 N = exp   − ∑ m = 1 M log p ( W → m ˜ ˜ | M ) ∑ m = 1 M N m ；</p><p>困惑度是用来度量一个概率分布或者一个概率模型拟合优劣的评判指标，在之后的计算当中，也产生了针对不同情形的困惑度公式。</p><p>1) 概率分布的困惑度</p><p>在定义相关概率分布的困惑度时，常用的公式为： 2 H ( p ) = 2 − ∑ x p ( x ) log 2 p ( x ) 。</p><p>其中，H(p)是概率分布p的熵，x是样本点。 p ( x ) = n N 。在某些特定的分布情况下，主题数与困惑度的</p><p>倒数存在一定的关联；在普遍意义下，困惑度是信息熵的指数。</p><p>2) 概率模型的困惑度</p><p>分布可以构建模型，模型可以将分布可视化，那么用概率模型 q ( x ) 来估计真实概率分布 p ( x ) 的参数，并得到具体的模型诸值，这时需要的困惑度公式可以写作：</p><p>b − 1 N ∑ i = 1 N log b q ( x i ) ,     H ( p ^ , q ) = − ∑ x p ^ ( x ) log 2 q (x)</p><p>在一般情况下，b的取值为2， H ( p ^ , q ) 称为交叉熵， p ( x ) = n N 。</p><p>3) 分词困惑度</p><p>分词的情况主要用于在分词后的句子位置的概率分布，大概可视作词语在句子上的特定位置出现的概率。其中可能包括多元模型会增加计算量，或涉及语法模型。</p></sec><sec id="s5_3_2"><title>3.3.2. 困惑度与主题</title><p>通过Python来实现困惑度–主题数的分布图。主要是基于信息理论来求的某一主题对应熵的能量 [<xref ref-type="bibr" rid="hanspub.36801-ref10">10</xref>] [<xref ref-type="bibr" rid="hanspub.36801-ref11">11</xref>]。以一个主题为基准计算其困惑度，再逐一递增直到找到困惑度较合适时相对应的主题数。可使用公式：</p><p>Perplexity ( A ) = exp { − ∑ d = 1 M lg P ( W d ) ∑ d = 1 M N d } 。</p><p>通过python进行实现，可以得到相应的主题和困惑度相关图，由于纪录片种类繁多，类型齐全，经过筛选，再经过重新合并在经过筛选，最终得出真人秀、时尚与科学证实这三种类型的纪录片在众多类型中更受欢迎。</p></sec></sec><sec id="s5_4"><title>3.4. 结果分析</title><p>根据得到的特征词分布，结合其中的比例分配，可以看出积极网络用语的比例为65%，其中消极情绪的35%，而消极情绪的大部分都与时尚类别相关，相关词语多以“看不懂”为主。具体主题–特征词分类下表(表2)所示。</p><table-wrap-group id="2"><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> Theme-Feature word</title></caption><table-wrap id="2_1"><table><tbody><thead><tr><th align="center" valign="middle" >Topic</th><th align="center" valign="middle" >主题词</th><th align="center" valign="middle" >特征词</th></tr></thead><tr><td align="center" valign="middle" >topic1</td><td align="center" valign="middle" >恐怖电影</td><td align="center" valign="middle" >僵尸、真的、\u2006、电影、喜欢、蛇、行尸走肉、美剧、发生、好看</td></tr><tr><td align="center" valign="middle" >topic2</td><td align="center" valign="middle" >多种类型</td><td align="center" valign="middle" >真的、僵尸、电影、美剧、喜欢、科学、好奇、\u2006、节目、宇宙</td></tr><tr><td align="center" valign="middle" >topic3</td><td align="center" valign="middle" >演技</td><td align="center" valign="middle" >干、假、挖出、湿、泥土、演技、东西、太、感觉、厉害</td></tr><tr><td align="center" valign="middle" >topic4</td><td align="center" valign="middle" >自然求生</td><td align="center" valign="middle" >鱼、鲨鱼、求生、吐、想、好看、大自然、喜欢、太、生活</td></tr><tr><td align="center" valign="middle" >topic5</td><td align="center" valign="middle" >节目效果</td><td align="center" valign="middle" >完、改、蓝色、想、效果、节目、粗糙、银色、老板、干活</td></tr><tr><td align="center" valign="middle" >topic6</td><td align="center" valign="middle" >芭蕾节目</td><td align="center" valign="middle" >袖珍、🐼、节目、说、芭蕾、🐶、挑选、想、片子、😳</td></tr><tr><td align="center" valign="middle" >topic7</td><td align="center" valign="middle" >刺激好看</td><td align="center" valign="middle" >更新、鱼、喜欢、刺激、好看、想、紧、做人、真的、吃</td></tr><tr><td align="center" valign="middle" >topic8</td><td align="center" valign="middle" >魔术假</td><td align="center" valign="middle" >魔术、假、真的、哈哈哈、想、说、逼、厉害、太、神奇</td></tr><tr><td align="center" valign="middle" >topic9</td><td align="center" valign="middle" >减肥养生</td><td align="center" valign="middle" >减肥、运动、想、吃、报名、针灸、广告、太、节目、节食</td></tr></tbody></table></table-wrap><table-wrap id="2_2"><table><tbody><thead><tr><th align="center" valign="middle" >topic10</th><th align="center" valign="middle" >节目假</th><th align="center" valign="middle" >假、节目、不错、两个、真实性、怀疑、疑点、金属、逗比、😊</th></tr></thead><tr><td align="center" valign="middle" >topic11</td><td align="center" valign="middle" >鞋子</td><td align="center" valign="middle" >\u2006、收藏、&amp;#、鞋、沙发、鞋子、更新、挖掘机、呜呜、国家</td></tr><tr><td align="center" valign="middle" >topic12</td><td align="center" valign="middle" >钓鱼</td><td align="center" valign="middle" >喜欢、金枪鱼、鱼、钓、日本、好样、鱼钩、一条、钓鱼、资源</td></tr><tr><td align="center" valign="middle" >topic13</td><td align="center" valign="middle" >魔术假</td><td align="center" valign="middle" >魔术、假、说、玻璃、真的、逼、鞋子、克里斯、太、🐼</td></tr><tr><td align="center" valign="middle" >topic14</td><td align="center" valign="middle" >青春靓丽</td><td align="center" valign="middle" >穿、真的、青春、当年、选美、想、衣服、容颜、美貌、美丽</td></tr><tr><td align="center" valign="middle" >topic15</td><td align="center" valign="middle" >希望好看</td><td align="center" valign="middle" >哈哈哈、哈、喜欢、克里斯、感觉、好看、第三季、纪录片、希望、挺</td></tr><tr><td align="center" valign="middle" >topic16</td><td align="center" valign="middle" >探索科学</td><td align="center" valign="middle" >宇宙、节目、科学、知识、世界、袖珍、喜欢、探索、东西、洞</td></tr><tr><td align="center" valign="middle" >topic17</td><td align="center" valign="middle" >出乎意料好看</td><td align="center" valign="middle" >出乎意料、挺、好看、一双、买、上档次、人生、骗到、一丝、节目</td></tr><tr><td align="center" valign="middle" >topic18</td><td align="center" valign="middle" >青年喜欢玩</td><td align="center" valign="middle" >害羞、青年、图、终究、玩儿、帅帅帅、记录、喜欢、玩、生活</td></tr><tr><td align="center" valign="middle" >topic19</td><td align="center" valign="middle" >高跟鞋</td><td align="center" valign="middle" >乘客、高跟鞋、穿、☹、首歌、️、喜欢、手机、铃声、好看</td></tr><tr><td align="center" valign="middle" >topic20</td><td align="center" valign="middle" >巴铁兄弟</td><td align="center" valign="middle" >傻、兄弟、巴铁、丢人、脑残、说、东西、一点、欺骗、性格</td></tr><tr><td align="center" valign="middle" >topic21</td><td align="center" valign="middle" >出乎意料好看</td><td align="center" valign="middle" >出乎意料、好看、特别、节目、骗到、☹、一丝、一双、上档次、买</td></tr><tr><td align="center" valign="middle" >topic22</td><td align="center" valign="middle" >穿高跟鞋</td><td align="center" valign="middle" >穿、️、☹、高跟鞋、好看、假、买、这鞋、点、女人</td></tr><tr><td align="center" valign="middle" >topic23</td><td align="center" valign="middle" >确定穿高跟鞋</td><td align="center" valign="middle" >穿、☹、️、高跟鞋、好看、漂亮、美女、真的、女人、肯定</td></tr><tr><td align="center" valign="middle" >topic24</td><td align="center" valign="middle" >文明标准</td><td align="center" valign="middle" >文明、标准、人有、伤风、宣传、底线、敗俗、丑陋、有悖、道德</td></tr></tbody></table></table-wrap></table-wrap-group><p>表2. 主题–特征词</p><p>此语义网络图(图2)中的所展示的占据较多的为减肥、运动一系列有助于健康的词语；而比例第二高的“恐怖”一类具备真实色彩的极限纪录片为主，可以说明当下人们对自身知识的局限性以及对未知事物的好奇。</p><p>图2. 网络语义图</p><p>根据词频所绘制的词云图(图3)，可以明显看出大部分人对于通过纪录片来记录生活中的美好呈乐观状态。回溯评论内容较具备代表性的纪录片可以发现，能流传时间较长的纪录片一般都是类似于中国历史以及人物传记类具备较强民族特点以及时代意义的影片。</p><p>图3. 真人秀词云图</p></sec></sec><sec id="s6"><title>4. 结论</title><p>本文通过建立LDA模型来进行分析得到影响纪录片传播的因素，通过Gibbs算法推进LDA模型的实现，并通过困惑度的选择获得较为适合的主题数量，并进行主题分析。通过主题分析可知当下较为受欢迎的纪录片类型是具备科学性、真实性以及可以实现经久不衰特点的这一类影片，此类纪录片不仅与当下的时代形态相关，更与纪录片所包含的历史背景和所输出的价值观相关，是否能做到抓住人们的眼球并分泌多巴胺促进大脑皮层活跃也是影响纪录片能否收到广泛关注的关键因素。而网民对纪录片的态度超过一半呈积极赞同的态度，三分之一数量呈中性态度，而剩余不足10%的人表现出较强烈的不满情绪，这说明人们的价值观与纪录片的传播可展现双向的影响作用。总体来看，纪录片的影响因素受群众的价值观影响较大，同时也与传播展现形式有着密不可分的关系。</p></sec><sec id="s7"><title>文章引用</title><p>黄梓玉,孟 捷. 基于文本挖掘的纪录片传播影响因素分析Analysis of Influencing Factors of Documentary Communication Based on Text Mining[J]. 统计学与应用, 2020, 09(04): 525-532. https://doi.org/10.12677/SA.2020.94056</p></sec><sec id="s8"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.36801-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">何莹莹. 电视纪录片故事化叙事研究[D]: [硕士学位论文]. 济南: 山东师范大学, 2015.</mixed-citation></ref><ref id="hanspub.36801-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">孟庆龙. 纪录片“故事化”叙事手法渊源及演进研究[D]: [硕士学位论文]. 扬州: 扬州大学, 2013.</mixed-citation></ref><ref id="hanspub.36801-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">王鹏飞. 纪录片题材选择研究[D]: [硕士学位论文]. 南京: 南京航空航天大学, 2013.</mixed-citation></ref><ref id="hanspub.36801-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">万燕蓉. 受众视角下的中国纪录片发展研究[D]: [硕士学位论文]. 济南: 山东大学, 2018.</mixed-citation></ref><ref id="hanspub.36801-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">张芳. 现实题材纪录片创作研究[D]: [硕士学位论文]. 济南: 山东师范大学, 2017.</mixed-citation></ref><ref id="hanspub.36801-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">李琰. 从归化和异化角度探讨华语纪录片字幕翻译[D]: [硕士学位论文]. 北京: 首都经济贸易大学, 2017.</mixed-citation></ref><ref id="hanspub.36801-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">董悦, 王梦. 基于情感分析与LDA模型的网络舆情案例研究[J]. 价值工程, 2019, 38(34): 169-172.</mixed-citation></ref><ref id="hanspub.36801-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">张磊. 基于C-LDA的微博推荐算法[D]: [硕士学位论文]. 乌鲁木齐: 新疆大学, 2016.</mixed-citation></ref><ref id="hanspub.36801-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Masood, M.A., Abbasi, R.A., Maqbool, O., et al. (2017) MFS-LDA: A Multi-Feature Space Tag Recommendation Model for Cold Start Problem. Program: Automated Library and Information Systems, 51, 218-234. 
&lt;br&gt;https://doi.org/10.1108/PROG-01-2017-0002</mixed-citation></ref><ref id="hanspub.36801-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">刘亚姝, 王志海, 侯跃然, 等. 一种基于概率主题模型的恶意代码特征提取方法[J]. 计算机研究与发展, 2019, 56(11): 2339-2348.</mixed-citation></ref><ref id="hanspub.36801-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">薛佳奇, 杨凡. 基于交叉熵与困惑度的LDA-SVM主题研究[J]. 智能计算机与应用, 2019, 9(4): 45-50.</mixed-citation></ref></ref-list></back></article>