<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">AAM</journal-id><journal-title-group><journal-title>Advances in Applied Mathematics</journal-title></journal-title-group><issn pub-type="epub">2324-7991</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/AAM.2017.65080</article-id><article-id pub-id-type="publisher-id">AAM-21685</article-id><article-categories><subj-group subj-group-type="heading"><subject>AAM20170500000_52769449.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>数学与物理</subject></subj-group></article-categories><title-group><article-title>
 
 
  利用支持向量机和人工神经网络填补缺失数据
  The Use of Support Vector Machines and Artificial Neural Networks to Fill Missing Data
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>张</surname><given-names>楠</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>程</surname><given-names>理</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>王</surname><given-names>鹏</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>null</addr-line></aff><aff id="aff1"><addr-line>北京林业大学理学院，北京</addr-line></aff><author-notes><corresp id="cor1">* E-mail:<email>771568416@qq.com(张楠)</email>;</corresp></author-notes><pub-date pub-type="epub"><day>02</day><month>08</month><year>2017</year></pub-date><volume>06</volume><issue>05</issue><fpage>677</fpage><lpage>684</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
  本文从R内置数据集iris中按需要选取样本数据建立学习样本，模拟生物样本属性值缺失和类别缺失两种缺失数据的情况，以MATLAB为工具，利用支持向量机和人工神经网络对缺失值进行填补。对于生物样本数据中存在属性值缺失的情况，可以分别采用支持向量机和人工神经网络进行回归填补，并对BP神经网络和RBF神经网络的适用性进行了对比；对于生物样本数据中存在样本类别缺失的情况，采用支持向量机分类填补。结果显示，用神经网络预测填补缺失的属性值时，RBF网络对隐层神经元数目选取的自适应性使之比BP网络更为稳定；相比人工神经网络，支持向量机对有限的样本更为适用，并且不依赖设计者经验，泛化能力强。
   In this paper, we use the built-in data set iris to select the sample data according to the need to es-tablish the learning samples, simulate the missing values of the biological sample attributes and the missing two types of missing data. Using MATLAB as the tool, we use the support vector machine and the artificial neural network to carry out the missing values to fill. For the case of missing attribute values in the biological sample data, the support vector machine and the artificial neural network can be used for the regression filling, and the applicability of the BP neural network and the RBF neural network can be compared. For the sample of the biological sample, missing situation, using support vector machine classification to fill. The results show that the adaptability of the number of hidden neurons in the RBF network is more stable than that of the BP network when the neural network is used to predict the missing attribute values. Compared with the artificial neural network, the support vector machine for the application, do not rely on the designer experience and has generalization ability.
 
</p></abstract><kwd-group><kwd>生物样本，填补缺失数据，支持向量机，人工神经网络, Biological Sample</kwd><kwd> Filling Missing Data</kwd><kwd> Support Vector Machine</kwd><kwd> Artificial Neural Network</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>利用支持向量机和人工神经网络填补缺失数据<sup> </sup></title><p>张楠，程理，王鹏<sup>*</sup></p><p>北京林业大学理学院，北京</p><disp-formula id="hanspub.21685-formula41"><graphic xlink:href="http://html.hanspub.org/file/4-2620460x5_hanspub.png"  xlink:type="simple"/></disp-formula><p>收稿日期：2017年7月21日；录用日期：2017年8月8日；发布日期：2017年8月14日</p><disp-formula id="hanspub.21685-formula42"><graphic xlink:href="http://html.hanspub.org/file/4-2620460x6_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>本文从R内置数据集iris中按需要选取样本数据建立学习样本，模拟生物样本属性值缺失和类别缺失两种缺失数据的情况，以MATLAB为工具，利用支持向量机和人工神经网络对缺失值进行填补。对于生物样本数据中存在属性值缺失的情况，可以分别采用支持向量机和人工神经网络进行回归填补，并对BP神经网络和RBF神经网络的适用性进行了对比；对于生物样本数据中存在样本类别缺失的情况，采用支持向量机分类填补。结果显示，用神经网络预测填补缺失的属性值时，RBF网络对隐层神经元数目选取的自适应性使之比BP网络更为稳定；相比人工神经网络，支持向量机对有限的样本更为适用，并且不依赖设计者经验，泛化能力强。</p><p>关键词 :生物样本，填补缺失数据，支持向量机，人工神经网络</p><disp-formula id="hanspub.21685-formula43"><graphic xlink:href="http://html.hanspub.org/file/4-2620460x7_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2017 by authors and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="http://image.hanspub.org:8080\Html/htmlimages\1-2890033x\e70a10f1-7c93-45ea-9603-062237856e4b.png" /><img src="http://image.hanspub.org:8080\Html\htmlimages\1-2890033x\e898c85e-ffc4-45c9-b817-14224a4d6960.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>一个简单的生命，也包含庞大的数据信息，数据构成十分复杂。随着生物科技的蓬勃发展，与生物有关的统计研究逐步展开，生物学数据的处理与分析成为一个重要的研究领域。有时我们获得的生物学样本数据不完整，导致研究工作困难重重。如何填补缺失的数据，也就成为了一个亟待解决的问题。</p><p>在生物样本数据中，通常情况下缺失的数据无非两种：属性值和分类值。如果缺失了属性值，可以进行回归填补；如果缺失了类别值，可以进行分类填补。这些都可以用支持向量机实现。就支持向量机而言，分类问题和回归问题都是根据训练样本找到一个实值函数g(x)：回归问题就是给定一个新的模式，根据训练样本确定一个实值函数g(x)，使用y = g(x)推断任一输入x所对应的输出y (实数)；分类问题就是给定一个新的模式，根据训练样本找到一个实值函数g(x)，使用y = sign(g(x))推断任一输入x所对应的类别(如：+1，−1) [<xref ref-type="bibr" rid="hanspub.21685-ref1">1</xref>] 。文献 [<xref ref-type="bibr" rid="hanspub.21685-ref2">2</xref>] 使用RBF神经网络对上证指数进行预测，类似地，填补缺失的属性值也可以用人工神经网络回归预测进行处理。本文从R内置数据集iris中按需要选取样本数据建立学习样本，模拟生物样本属性值缺失和类别缺失两种缺失数据的情况，以MATLAB为工具，采取支持向量机和人工神经网络的模型，以无缺失值的样本预测有缺失值的样本中的缺失值，从而进行填补。属性值缺失值用支持向量机或人工神经网络进行回归填补，样本类别缺失值用支持向量机分类填补。神经网络推导出的各种算法很难在样本数据有限时取得理想的应用效果，需要设计者有效利用自己的经验。与神经网络相比，支持向量机能够基于有限的样本信息求解，同时避免了神经网络实现中的经验成分。</p></sec><sec id="s4"><title>2. 填补缺失的样本属性值</title><sec id="s4_1"><title>2.1. 支持向量机回归填补</title><p>支持向量机SVM (Support Vector Machines)是由Vanpik领导的AT&amp;TBell实验室研究小组在1963年提出的一种新的分类技术，在解决小样本、非线性、高维模式识别问题中表现出许多特有的优势，并且可以推广应用到函数拟合等问题中去 [<xref ref-type="bibr" rid="hanspub.21685-ref3">3</xref>] 。</p><p>我们从R语言内置的iris数据集中的setosa类别选取20个样本组成一个新的数据集，作为网络学习样本，并删去第二十个样本的最后一个属性值(Petal.Width)，模拟数据缺失的情况，如表1。其实，无论缺失的是什么位置的数据，只要将没有缺失数据的行列集合到一起，作为训练集，用来预测数据不完全样本的缺失属性的值。选取1到19个样本的Sepal.Length、Sepal.Width、Petal.Length、Petal.Width为自变量，2到20个样本的Petal.Width为因变量。</p><p>SVM的实现使用MATLAB的libsvm工具箱，实现数据归一化预处理，寻找回归的最佳参数，参数选择结果图(等高线图)如图1。用找到的最佳参数对SVM进行训练，再对原始数据进行回归预测，得回归预测数据与原始数据对比图，如图2。SVM回归预测的均方误差MSE = 0.0312355，相关系数R = 67.5382%，缺失值填补为0.2969。</p></sec><sec id="s4_2"><title>2.2. 人工神经网络回归填补</title><p>人工神经网络(Artificial Neutral Network, ANN)是由神经元相互连接，通过模拟人脑神经处理信息的方式，进行信息并行处理和非线性转换的复杂网络系统，在控制与优化、预测与管理、模式识别与图像处理、通信等方面得到了十分广泛的应用 [<xref ref-type="bibr" rid="hanspub.21685-ref4">4</xref>] 。前向反馈(Back Programming, BP)网络和径向基(Radical Basis Function, RBF)网络是目前应用最广泛的两种网络。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> A set of biological samples with missing attribute value</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" >Sepal.Length</th><th align="center" valign="middle" >Sepal.Width</th><th align="center" valign="middle" >Petal.Length</th><th align="center" valign="middle" >Petal.Width</th></tr></thead><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" >5.1</td><td align="center" valign="middle" >3.5</td><td align="center" valign="middle" >1.4</td><td align="center" valign="middle" >0.2</td></tr><tr><td align="center" valign="middle" >2</td><td align="center" valign="middle" >4.9</td><td align="center" valign="middle" >3</td><td align="center" valign="middle" >1.4</td><td align="center" valign="middle" >0.2</td></tr><tr><td align="center" valign="middle" >3</td><td align="center" valign="middle" >4.7</td><td align="center" valign="middle" >3.2</td><td align="center" valign="middle" >1.3</td><td align="center" valign="middle" >0.2</td></tr><tr><td align="center" valign="middle" >4</td><td align="center" valign="middle" >4.6</td><td align="center" valign="middle" >3.1</td><td align="center" valign="middle" >1.5</td><td align="center" valign="middle" >0.2</td></tr><tr><td align="center" valign="middle" >5</td><td align="center" valign="middle" >5</td><td align="center" valign="middle" >3.6</td><td align="center" valign="middle" >1.4</td><td align="center" valign="middle" >0.2</td></tr><tr><td align="center" valign="middle" >6</td><td align="center" valign="middle" >5.4</td><td align="center" valign="middle" >3.9</td><td align="center" valign="middle" >1.7</td><td align="center" valign="middle" >0.4</td></tr><tr><td align="center" valign="middle" >7</td><td align="center" valign="middle" >4.6</td><td align="center" valign="middle" >3.4</td><td align="center" valign="middle" >1.4</td><td align="center" valign="middle" >0.3</td></tr><tr><td align="center" valign="middle" >8</td><td align="center" valign="middle" >5</td><td align="center" valign="middle" >3.4</td><td align="center" valign="middle" >1.5</td><td align="center" valign="middle" >0.2</td></tr><tr><td align="center" valign="middle" >9</td><td align="center" valign="middle" >4.4</td><td align="center" valign="middle" >2.9</td><td align="center" valign="middle" >1.4</td><td align="center" valign="middle" >0.2</td></tr><tr><td align="center" valign="middle" >10</td><td align="center" valign="middle" >4.9</td><td align="center" valign="middle" >3.1</td><td align="center" valign="middle" >1.5</td><td align="center" valign="middle" >0.1</td></tr><tr><td align="center" valign="middle" >11</td><td align="center" valign="middle" >5.4</td><td align="center" valign="middle" >3.7</td><td align="center" valign="middle" >1.5</td><td align="center" valign="middle" >0.2</td></tr><tr><td align="center" valign="middle" >12</td><td align="center" valign="middle" >4.8</td><td align="center" valign="middle" >3.4</td><td align="center" valign="middle" >1.6</td><td align="center" valign="middle" >0.2</td></tr><tr><td align="center" valign="middle" >13</td><td align="center" valign="middle" >4.8</td><td align="center" valign="middle" >3</td><td align="center" valign="middle" >1.4</td><td align="center" valign="middle" >0.1</td></tr><tr><td align="center" valign="middle" >14</td><td align="center" valign="middle" >4.3</td><td align="center" valign="middle" >3</td><td align="center" valign="middle" >1.1</td><td align="center" valign="middle" >0.1</td></tr><tr><td align="center" valign="middle" >15</td><td align="center" valign="middle" >5.8</td><td align="center" valign="middle" >4</td><td align="center" valign="middle" >1.2</td><td align="center" valign="middle" >0.2</td></tr><tr><td align="center" valign="middle" >16</td><td align="center" valign="middle" >5.7</td><td align="center" valign="middle" >4.4</td><td align="center" valign="middle" >1.5</td><td align="center" valign="middle" >0.4</td></tr><tr><td align="center" valign="middle" >17</td><td align="center" valign="middle" >5.4</td><td align="center" valign="middle" >3.9</td><td align="center" valign="middle" >1.3</td><td align="center" valign="middle" >0.4</td></tr><tr><td align="center" valign="middle" >18</td><td align="center" valign="middle" >5.1</td><td align="center" valign="middle" >3.5</td><td align="center" valign="middle" >1.4</td><td align="center" valign="middle" >0.3</td></tr><tr><td align="center" valign="middle" >19</td><td align="center" valign="middle" >5.7</td><td align="center" valign="middle" >3.8</td><td align="center" valign="middle" >1.7</td><td align="center" valign="middle" >0.3</td></tr><tr><td align="center" valign="middle" >20</td><td align="center" valign="middle" >5.1</td><td align="center" valign="middle" >3.8</td><td align="center" valign="middle" >1.5</td><td align="center" valign="middle" ></td></tr></tbody></table></table-wrap><p>表1. 有缺失属性值的生物样本集</p><p>注：20号样本缺失的Petal.Width真实值为0.3。</p><p>图1. 参数选择结果图(等高线图)</p><p>图2. 回归预测数据与原始数据对比图</p><sec id="s4_2_1"><title>2.2.1. BP神经网络填补</title><p>BP神经网络是一种具有三层或者三层以上神经元的神经网络，包括输入层、中间层(隐含层)和输出层，上下层之间全连接，而同一层的神经元之间无连接，两个神经元之间的连接强度为网络的权值。BP算法称为“误差反向传播算法”，通过误差逆向传播修正的反复进行，逐步修正各连接权值，核心是“负梯度下降”理论，误差调整方向沿着误差下降最快的方向进行 [<xref ref-type="bibr" rid="hanspub.21685-ref5">5</xref>] 。</p><p>使用表1数据为网络学习样本。在本例中将前三个属性作为输入，Petal.Width作为输出，构成3个输入1个输出的网络，将前19个无缺样本数据作为训练样本集，后1个有缺样本作为预测检验样本。</p><p>对样本的输入、输出数据进行规格化处理：<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2620460x12_hanspub.png" xlink:type="simple"/></inline-formula>，其中，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2620460x13_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2620460x14_hanspub.png" xlink:type="simple"/></inline-formula>分别为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2620460x15_hanspub.png" xlink:type="simple"/></inline-formula>的最大值和</p><p>最小值，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2620460x16_hanspub.png" xlink:type="simple"/></inline-formula>为规格化后的变量。MATLAB中提供了对数据进行规格化处理的函数[tn,pn] = mapminmax(t)，相应的逆处理函数t = mapminmax(‘reverse’,tn,ps)，执行的算法是<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2620460x17_hanspub.png" xlink:type="simple"/></inline-formula> [<xref ref-type="bibr" rid="hanspub.21685-ref6">6</xref>] 。</p><p>BP网络用于函数逼近时，权值的调节采用的是负梯度下降法，这种调节权值的方法存在收敛速度慢和局部极小等缺点。</p><p>BP网络的学习过程常发生振动，每一次运行的结果可能会相差很大。如果将隐含神经元个数取为3，查看某一次运行结果的回归结果图(图3)和误差直方图(图4)，可以得知，此时数据拟合的不好，误差也相当大。</p><p>对于隐含层的神经元个数的确定，至今尚未找到一个很好的解析式，只能根据经验确定或自行设计一些估计方法 [<xref ref-type="bibr" rid="hanspub.21685-ref7">7</xref>] 。在初始化神经网络时，为了使计算结果相对稳定，往往需要进行多次实验，从而找到使结果最稳定的隐含层神经元个数。</p></sec><sec id="s4_2_2"><title>2.2.2. RBF神经网络填补</title><p>RBF神经网络是模拟视网膜的感受功能产生的：距离感受视野中心越近的视神经元越兴奋；视神经元的激活区域呈径向对称。将视网膜感受原理映射到RBF神经网络，可对隐含层神经元进行建模：</p><p><inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2620460x18_hanspub.png" xlink:type="simple"/></inline-formula>。其中，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2620460x19_hanspub.png" xlink:type="simple"/></inline-formula>为输入样本；<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2620460x20_hanspub.png" xlink:type="simple"/></inline-formula>为感受视野中心(中心点)，决定了径向基函数围绕中心点</p><p>图3. 回归结果图</p><p>图4. 误差直方图</p><p>的宽度；<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2620460x23_hanspub.png" xlink:type="simple"/></inline-formula>为宽度；<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2620460x24_hanspub.png" xlink:type="simple"/></inline-formula>为径向基函数，也称激励函数、传递函数或激活函数；<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2620460x25_hanspub.png" xlink:type="simple"/></inline-formula>是距离函数，表示网络样本值与数据中心(中心点)之间的距离；<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2620460x26_hanspub.png" xlink:type="simple"/></inline-formula>为网络输出。隐含层神经元径向基函数通常选用</p><p>Gaussian函数，则上述神经元相应模型转化成：<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2620460x27_hanspub.png" xlink:type="simple"/></inline-formula> [<xref ref-type="bibr" rid="hanspub.21685-ref4">4</xref>] 。</p><p>RBF网络也有三层，隐含层激活函数是高斯函数，第一层(输入神经元)和第三层(输出神经元)一般采用线性激励函数；依据链式偏微分法则，可得网络数据中心、宽度和权值的调整量 [<xref ref-type="bibr" rid="hanspub.21685-ref8">8</xref>] 。利用MATLAB提供的神经网络工具箱 [<xref ref-type="bibr" rid="hanspub.21685-ref9">9</xref>] 实现人工神经网络的功能十分方便。RBF与BP的不同点在于，中间隐含层神经元的个数，BP网络需要根据经验取定，RBF网络会在训练过程中自适应地取定。依然使用表1数据作为网络学习样本，RBF网络预测第20个样本的缺失属性值(Petal.Width)为0.2489，相对误差为17.02%。可见，RBF网络模型的预测结果优于BP网络模型的预测结果。</p></sec></sec></sec><sec id="s5"><title>3. 填补缺失的样本类别</title><p>选取iris数据集中setosa、versicolor的样本各10个，组成一个新的数据集。删去新数据集中10号和20号样本的类别，模拟类别值缺失的情况，如表2。令setosa、versicolor为“1”类、“2”类，那么缺失的10号和20号样本的类别真实值分别为“1”和“2”。</p><p>用<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2620460x28_hanspub.png" xlink:type="simple"/></inline-formula>分别表示20个样本，第i个样本的第j个属性取值为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2620460x29_hanspub.png" xlink:type="simple"/></inline-formula>。类别已知的18个样本点的</p><p>均值向量<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2620460x30_hanspub.png" xlink:type="simple"/></inline-formula>，标准差向量<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2620460x31_hanspub.png" xlink:type="simple"/></inline-formula>。对所有样本点数据进行标准化处理：<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2620460x32_hanspub.png" xlink:type="simple"/></inline-formula>。对应地，称<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2620460x33_hanspub.png" xlink:type="simple"/></inline-formula>为标准化指标向量。记<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2620460x34_hanspub.png" xlink:type="simple"/></inline-formula>。记标准化后的18个类别已知的样本点数据行向量为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2620460x35_hanspub.png" xlink:type="simple"/></inline-formula>。利用线性内核函数的支持向量机模型进行分类，求得支持向量：<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2620460x36_hanspub.png" xlink:type="simple"/></inline-formula>，线性分类函数：<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2620460x37_hanspub.png" xlink:type="simple"/></inline-formula>，其中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2620460x38_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2620460x39_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2620460x40_hanspub.png" xlink:type="simple"/></inline-formula>。当<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2620460x41_hanspub.png" xlink:type="simple"/></inline-formula>时，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2620460x42_hanspub.png" xlink:type="simple"/></inline-formula>属于“1”类；当<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2620460x43_hanspub.png" xlink:type="simple"/></inline-formula>时，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/4-2620460x44_hanspub.png" xlink:type="simple"/></inline-formula>属</p><p>于“2”类 [<xref ref-type="bibr" rid="hanspub.21685-ref6">6</xref>] 。</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> A set of biological samples with missing category value</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" >Sepal.Length</th><th align="center" valign="middle" >Sepal.Width</th><th align="center" valign="middle" >Petal.Length</th><th align="center" valign="middle" >Petal.Width</th><th align="center" valign="middle" ></th></tr></thead><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" >5.1</td><td align="center" valign="middle" >3.5</td><td align="center" valign="middle" >1.4</td><td align="center" valign="middle" >0.2</td><td align="center" valign="middle" >setosa</td></tr><tr><td align="center" valign="middle" >2</td><td align="center" valign="middle" >4.9</td><td align="center" valign="middle" >3</td><td align="center" valign="middle" >1.4</td><td align="center" valign="middle" >0.2</td><td align="center" valign="middle" >setosa</td></tr><tr><td align="center" valign="middle" >3</td><td align="center" valign="middle" >4.7</td><td align="center" valign="middle" >3.2</td><td align="center" valign="middle" >1.3</td><td align="center" valign="middle" >0.2</td><td align="center" valign="middle" >setosa</td></tr><tr><td align="center" valign="middle" >4</td><td align="center" valign="middle" >4.6</td><td align="center" valign="middle" >3.1</td><td align="center" valign="middle" >1.5</td><td align="center" valign="middle" >0.2</td><td align="center" valign="middle" >setosa</td></tr><tr><td align="center" valign="middle" >5</td><td align="center" valign="middle" >5</td><td align="center" valign="middle" >3.6</td><td align="center" valign="middle" >1.4</td><td align="center" valign="middle" >0.2</td><td align="center" valign="middle" >setosa</td></tr><tr><td align="center" valign="middle" >6</td><td align="center" valign="middle" >5.4</td><td align="center" valign="middle" >3.9</td><td align="center" valign="middle" >1.7</td><td align="center" valign="middle" >0.4</td><td align="center" valign="middle" >setosa</td></tr><tr><td align="center" valign="middle" >7</td><td align="center" valign="middle" >4.6</td><td align="center" valign="middle" >3.4</td><td align="center" valign="middle" >1.4</td><td align="center" valign="middle" >0.3</td><td align="center" valign="middle" >setosa</td></tr><tr><td align="center" valign="middle" >8</td><td align="center" valign="middle" >5</td><td align="center" valign="middle" >3.4</td><td align="center" valign="middle" >1.5</td><td align="center" valign="middle" >0.2</td><td align="center" valign="middle" >setosa</td></tr><tr><td align="center" valign="middle" >9</td><td align="center" valign="middle" >4.4</td><td align="center" valign="middle" >2.9</td><td align="center" valign="middle" >1.4</td><td align="center" valign="middle" >0.2</td><td align="center" valign="middle" >setosa</td></tr><tr><td align="center" valign="middle" >10</td><td align="center" valign="middle" >4.9</td><td align="center" valign="middle" >3.1</td><td align="center" valign="middle" >1.5</td><td align="center" valign="middle" >0.1</td><td align="center" valign="middle" ></td></tr><tr><td align="center" valign="middle" >61</td><td align="center" valign="middle" >7</td><td align="center" valign="middle" >3.2</td><td align="center" valign="middle" >4.7</td><td align="center" valign="middle" >1.4</td><td align="center" valign="middle" >versicolor</td></tr><tr><td align="center" valign="middle" >62</td><td align="center" valign="middle" >6.4</td><td align="center" valign="middle" >3.2</td><td align="center" valign="middle" >4.5</td><td align="center" valign="middle" >1.5</td><td align="center" valign="middle" >versicolor</td></tr><tr><td align="center" valign="middle" >63</td><td align="center" valign="middle" >6.9</td><td align="center" valign="middle" >3.1</td><td align="center" valign="middle" >4.9</td><td align="center" valign="middle" >1.5</td><td align="center" valign="middle" >versicolor</td></tr><tr><td align="center" valign="middle" >64</td><td align="center" valign="middle" >5.5</td><td align="center" valign="middle" >2.3</td><td align="center" valign="middle" >4</td><td align="center" valign="middle" >1.3</td><td align="center" valign="middle" >versicolor</td></tr><tr><td align="center" valign="middle" >65</td><td align="center" valign="middle" >6.5</td><td align="center" valign="middle" >2.8</td><td align="center" valign="middle" >4.6</td><td align="center" valign="middle" >1.5</td><td align="center" valign="middle" >versicolor</td></tr><tr><td align="center" valign="middle" >66</td><td align="center" valign="middle" >5.7</td><td align="center" valign="middle" >2.8</td><td align="center" valign="middle" >4.5</td><td align="center" valign="middle" >1.3</td><td align="center" valign="middle" >versicolor</td></tr><tr><td align="center" valign="middle" >67</td><td align="center" valign="middle" >6.3</td><td align="center" valign="middle" >3.3</td><td align="center" valign="middle" >4.7</td><td align="center" valign="middle" >1.6</td><td align="center" valign="middle" >versicolor</td></tr><tr><td align="center" valign="middle" >68</td><td align="center" valign="middle" >4.9</td><td align="center" valign="middle" >2.4</td><td align="center" valign="middle" >3.3</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >versicolor</td></tr><tr><td align="center" valign="middle" >69</td><td align="center" valign="middle" >6.6</td><td align="center" valign="middle" >2.9</td><td align="center" valign="middle" >4.6</td><td align="center" valign="middle" >1.3</td><td align="center" valign="middle" >versicolor</td></tr><tr><td align="center" valign="middle" >70</td><td align="center" valign="middle" >5.2</td><td align="center" valign="middle" >2.7</td><td align="center" valign="middle" >3.9</td><td align="center" valign="middle" >1.4</td><td align="center" valign="middle" ></td></tr></tbody></table></table-wrap><p>表2. 有缺失类别值的生物样本集</p><p>注：10号、70号样本缺失的类别真实值分别为setosa、versicolor。</p><p>用判别函数判别，得到缺失的第十个、第二十个样本类别分别为“1”、“2”，与真实值一致。所有已知样本点回代分类函数皆正确，误判率为0。</p></sec><sec id="s6"><title>4. 缺失数据填补效果比较与分析</title><p>因为神经网络基于传统统计学，研究样本无穷大时的渐进理论 [<xref ref-type="bibr" rid="hanspub.21685-ref10">10</xref>] ，故以此推导出的各种算法很难在样本数据有限时取得理想的应用效果。同时，因为神经网络是基于经验的风险最小化，不能保证网络的泛化能力 [<xref ref-type="bibr" rid="hanspub.21685-ref11">11</xref>] ，故需要设计者有效利用自己的经验，网络系统的优劣是因人而异的。</p><p>与神经网络相比，支持向量机以统计学理论为基础，主要针对小样本情况 [<xref ref-type="bibr" rid="hanspub.21685-ref12">12</xref>] ，能够基于有限的样本信息求解。同时，支持向量机基于结构风险最小化原则，有严格的理论和数学基础 [<xref ref-type="bibr" rid="hanspub.21685-ref13">13</xref>] ，可以避免神经网络实现中的经验成分。</p></sec><sec id="s7"><title>致谢</title><p>大学生创新创业项目(X201610022132)对全基因组关联分析中数据缺失研究。</p></sec><sec id="s8"><title>文章引用</title><p>张楠,程理,王鹏. 利用支持向量机和人工神经网络填补缺失数据 The Use of Support Vector Machines and Artificial Neural Networks to Fill Missing Data[J]. 应用数学进展, 2017, 06(05): 677-684. http://dx.doi.org/10.12677/AAM.2017.65080</p></sec><sec id="s9"><title>参考文献 (References)</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.21685-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">陈爱军. 最小二乘支持向量机及其在工业过程建模中的应用[D]: [博士学位论文]. 杭州: 浙江大学, 2006.</mixed-citation></ref><ref id="hanspub.21685-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">MATLAB中文论坛. MATLAB神经网络30个案例分析[M]. 北京: 北京航空航天大学出版社, 2010: 133-140.</mixed-citation></ref><ref id="hanspub.21685-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">王洪波. 单分类支持向量机的学习方法研究[D]: [博士学位论文]. 杭州: 浙江大学, 2012.</mixed-citation></ref><ref id="hanspub.21685-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">束洪春, 邬乾晋, 张广斌, 孙士云, 刘可真. 基于神经网络的单端行波故障测距方法[J]. 中国电机工程学报, 2011, 31(4): 85-92.</mixed-citation></ref><ref id="hanspub.21685-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">卓金武. MATLAB在数学建模中的应用[M]. 第2版. 北京: 北京航空航天大学出版社, 2014: 99-125.</mixed-citation></ref><ref id="hanspub.21685-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">司守奎, 孙兆亮. 数学建模算法与应用[M]. 第2版. 北京: 国防工业出版社, 2015: 350-356, 761-776.</mixed-citation></ref><ref id="hanspub.21685-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">周永权. 前向多层代数神经网络隐层神经元数目估计方法[J]. 广西民族大学学报(自然科学版), 2000, 6(3): 190- 192.</mixed-citation></ref><ref id="hanspub.21685-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">卢金娜. 基于优化算法的径向基神经网络模型的改进及应用[D]: [博士学位论文]. 太原: 中北大学, 2015.</mixed-citation></ref><ref id="hanspub.21685-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">徐国志, 李茂元. 基于Matlab神经网络工具箱进行港口集装箱运量预测[J]. 港工技术, 2003(4): 15-17.</mixed-citation></ref><ref id="hanspub.21685-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">张昕. 基于SVM方法的医学图像分类研究[D]: [硕士学位论文]. 杭州: 浙江大学, 2006.</mixed-citation></ref><ref id="hanspub.21685-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">李巍. 基于宏观经济指标和人工智能方法的上证综合指数预测[D]: [硕士学位论文]. 成都: 西南财经大学, 2012.</mixed-citation></ref><ref id="hanspub.21685-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">平源. 基于支持向量机的聚类及文本分类研究[D]: [博士学位论文]. 北京: 北京邮电大学, 2012.</mixed-citation></ref><ref id="hanspub.21685-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">刘斌. 支持向量机及其在信号处理中的应用[D]: [硕士学位论文]. 大庆: 大庆石油学院, 2006.</mixed-citation></ref></ref-list></back></article>