<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2020.1011222</article-id><article-id pub-id-type="publisher-id">CSA-38863</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20201100000_88934781.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于1D卷积与特征融合的深度学习轴承诊断算法研究
  Research on Deep Learning Bearing Diagnosis Algorithm Based on 1D Convolution and Feature Fusion
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>余</surname><given-names>波</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>王</surname><given-names>朝宇</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>付</surname><given-names>志超</given-names></name><xref ref-type="aff" rid="aff4"><sup>4</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>凌</surname><given-names>静</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>陈</surname><given-names>军江</given-names></name><xref ref-type="aff" rid="aff4"><sup>4</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff3"><addr-line>重庆交通大学城市轨道车辆系统集成与控制重点实验室，重庆</addr-line></aff><aff id="aff4"><addr-line>重庆市勘测院，重庆</addr-line></aff><aff id="aff2"><addr-line>重庆交通大学机电与车辆工程学院，重庆</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>09</day><month>11</month><year>2020</year></pub-date><volume>10</volume><issue>11</issue><fpage>2105</fpage><lpage>2121</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   轴承损伤严重影响设备正常运行，减小设备寿命。对轴承损伤的有效识别可以帮助设备进行维护。为此，本文创造性地提出了一种基于1D卷积与特征融合的互扰神经网络(Interference neural net-work, IFNN)深度学习模型来实现轴承诊断。该模型由7层大尺寸卷积核单元、传统特征计算单元、融合单元和Softmax分类器组成。为了检验所提出方法的有效性，采用10倍交叉验证、4个数值指标和ROC曲线面积来评估分类结果。实验结果表明，本文提出的IFNN模型准确率为96.09%，精度为96.48%，召回率为96.10%，F1-score为96.08%，ROC值为1。通过与随机森林、支持向量机等模型的对比，IFNN模型的性能明显优于其他模型。因此，所提出的IFNN模型能有效地完成轴承损伤诊断任务。 Bearing damage seriously affects the normal operation of the equipment and reduces the life of the equipment. Effective identification of bearing damage can help equipment maintenance. For this reason, this paper creatively proposes a deep learning model of Interference Neural Network (IFNN) based on 1D convolution and feature fusion to realize bearing diagnosis. The model consists of 7-layer large-size convolution kernel unit, traditional feature calculation unit, fusion unit and Soft-max classifier. In order to test the effectiveness of the proposed method, 10-fold cross-validation, 4 numerical indicators and ROC curve area are used to evaluate the classification results. The experimental results show that the accuracy rate of the IFNN model proposed in this paper is 96.09%, the precision is 96.48%, the recall rate is 96.10%, the F1-score is 96.08%, and the ROC value is 1. Through comparison with models such as random forest and support vector machine, the performance of the IFNN model is significantly better than other models. Therefore, the proposed IFNN model can effectively complete the task of bearing damage diagnosis. 
  
 
</p></abstract><kwd-group><kwd>轴承诊断，1D卷积，特征融合，互扰神经网络, Bearing Diagnosis</kwd><kwd> 1D Convolution</kwd><kwd> Feature Fusion</kwd><kwd> Interference Neural Network</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>摘要</title><p>轴承损伤严重影响设备正常运行，减小设备寿命。对轴承损伤的有效识别可以帮助设备进行维护。为此，本文创造性地提出了一种基于1D卷积与特征融合的互扰神经网络(Interference neural network, IFNN)深度学习模型来实现轴承诊断。该模型由7层大尺寸卷积核单元、传统特征计算单元、融合单元和Softmax分类器组成。为了检验所提出方法的有效性，采用10倍交叉验证、4个数值指标和ROC曲线面积来评估分类结果。实验结果表明，本文提出的IFNN模型准确率为96.09%，精度为96.48%，召回率为96.10%，F1-score为96.08%，ROC值为1。通过与随机森林、支持向量机等模型的对比，IFNN模型的性能明显优于其他模型。因此，所提出的IFNN模型能有效地完成轴承损伤诊断任务。</p></sec><sec id="s2"><title>关键词</title><p>轴承诊断，1D卷积，特征融合，互扰神经网络</p></sec><sec id="s3"><title>Research on Deep Learning Bearing Diagnosis Algorithm Based on 1D Convolution and Feature Fusion<sup> </sup></title><p>Bo Yu<sup>1</sup>, Chaoyu Wang<sup>2</sup>, Zhicao Fu<sup>3</sup>, Jing Ling<sup>2</sup>, Junjiang Chen<sup>3</sup></p><p><sup>1</sup>Electromechanical and Vehicle Engineering, Chongqing Jiaotong University, Chongqing</p><p><sup>2</sup>Key Laboratory of Urban Rail Vehicle System Integration and Control, Chongqing Jiaotong University, Chongqing</p><p><sup>3</sup>Chongqing Survey Institute, Chongqing</p><p>Received: Nov. 4<sup>th</sup>, 2020; accepted: Nov. 19<sup>th</sup>, 2020; published: Nov. 26<sup>th</sup>, 2020</p><p><img src="//html.hanspub.org/file/20-1541898x5_hanspub.png" /></p></sec><sec id="s4"><title>ABSTRACT</title><p>Bearing damage seriously affects the normal operation of the equipment and reduces the life of the equipment. Effective identification of bearing damage can help equipment maintenance. For this reason, this paper creatively proposes a deep learning model of Interference Neural Network (IFNN) based on 1D convolution and feature fusion to realize bearing diagnosis. The model consists of 7-layer large-size convolution kernel unit, traditional feature calculation unit, fusion unit and Softmax classifier. In order to test the effectiveness of the proposed method, 10-fold cross-validation, 4 numerical indicators and ROC curve area are used to evaluate the classification results. The experimental results show that the accuracy rate of the IFNN model proposed in this paper is 96.09%, the precision is 96.48%, the recall rate is 96.10%, the F1-score is 96.08%, and the ROC value is 1. Through comparison with models such as random forest and support vector machine, the performance of the IFNN model is significantly better than other models. Therefore, the proposed IFNN model can effectively complete the task of bearing damage diagnosis.</p><p>Keywords:Bearing Diagnosis, 1D Convolution, Feature Fusion, Interference Neural Network</p><disp-formula id="hanspub.38863-formula22"><graphic xlink:href="//html.hanspub.org/file/20-1541898x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2020 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/20-1541898x7_hanspub.png" /> <img src="//html.hanspub.org/file/20-1541898x8_hanspub.png" /></p></sec><sec id="s5"><title>1. 引言</title><p>轴承在现在大型机械中，尤其是大型机械的传动系统中，扮演着其他构件无法替代的角色，其工作状态直接影响并决定着整个机器的性能安全。那么有效判断轴承是否能够正常工作，对于现代工业发展就显得尤为重要。</p><p>目前，大量的机器学习模型与传统提取特征结合的方法应用于轴承智能诊断中，并取得了一些不错的成绩。李辉 [<xref ref-type="bibr" rid="hanspub.38863-ref1">1</xref>] 等提出基于EMD和Teager能量算子的模型，成功运用于齿轮箱轴承的故障诊断。田晶 [<xref ref-type="bibr" rid="hanspub.38863-ref2">2</xref>] 等提出了一种深度梯度提升模型(DeepGBM)，其故障诊断准确率达到87%，并具有良好的泛化能力。张文额 [<xref ref-type="bibr" rid="hanspub.38863-ref3">3</xref>] 等利用层次化分块正交匹配算法(HBW-OOMP)的高稀疏性和运算速度快等优点，提出了一种基于K-奇异值分解(K-SVD)字典和HBW-OOMP算法的故障轴承诊断方法。刘文朋 [<xref ref-type="bibr" rid="hanspub.38863-ref4">4</xref>] 等通过一种多点峭度谱(Mkurt spectrum)和MCKD相结合的方法进行滚动轴承故障诊断，有效地实现滚动轴承的故障诊断。欧璐 [<xref ref-type="bibr" rid="hanspub.38863-ref5">5</xref>] 等采用图傅里叶变换(Graph Fourier transformation, GFT)进行特征提取和K-均值聚类进行滚动轴承故障诊断。与此同时，He Cheng [<xref ref-type="bibr" rid="hanspub.38863-ref6">6</xref>] 等结合极端点对称模式分解(ESMD)复合多尺度加权置换熵(CMWPE)和基于多重自适应约束策略(MACGSA)优化最小二乘支持向量机(LSSVM)的重力搜索算法，提出了一种MACGSA-LSSVM滚动轴承故障诊断方法，该方法具有更高的诊断准确性。Mohamad T. Ha [<xref ref-type="bibr" rid="hanspub.38863-ref7">7</xref>] 等提取动态系统非线性动力学行为作为特征，开发了一种称为相空间拓扑(PST)技术用于轴承诊断。Liu Chenyu [<xref ref-type="bibr" rid="hanspub.38863-ref8">8</xref>] 等提出了一种新型的半监督支持向量数据描述(SVDD)与负样本(NSVDD)故障检测方法，并取得一定成果。Wang Gang [<xref ref-type="bibr" rid="hanspub.38863-ref9">9</xref>] 等通过一种新型的具有证据推理规则的诊断聚合方法用于轴承故障诊断，实验结果表明该方法有一定的有效性。尽管传统的方法在轴承故障诊断领域取得了很大成就，但是需要进行特征提取器的设计，这对专业知识有一定的要求。因此需要使用更先进的技术对故障信号进行特征提取，来代替自适应的手动提取和选择特征。</p><p>近年来，随着深度学习方法的快速发展，为轴承诊断提供了新的解决方案和框架。杜小磊等 [<xref ref-type="bibr" rid="hanspub.38863-ref10">10</xref>] 提出了一种基于同步挤压S变换(synchrosqueezed S transform, SSST)和深度曲线波卷积神经网络(deep curvelet convolutional neural network, DCCNN)的轴承故障诊断方法。庄雨璇等 [<xref ref-type="bibr" rid="hanspub.38863-ref11">11</xref>] 提出一种基于长短时记忆网络的端到端故障诊断模型e2e-LSTM，实验结果表明该模型能够以端到端模式一次性地诊断多种轴承故障。吴小龙等 [<xref ref-type="bibr" rid="hanspub.38863-ref12">12</xref>] 通过无监督学习的去噪自动编码器(Denoising Auto-encoder, DAE)进行特征提取，与传统模型相比，该方法在轴承故障诊断领域有更优越的正确率与稳定性。涂小卫等 [<xref ref-type="bibr" rid="hanspub.38863-ref13">13</xref>] 提出了一种FFT + DBN + 参数寻优的牵引系统电机轴承诊断方法，有效提高故障识别准确度，为电机轴承故障诊断提供了解决方案。杜小磊等 [<xref ref-type="bibr" rid="hanspub.38863-ref14">14</xref>] 提出一种基于改进深层小波自编码器的轴承智能故障诊断方法。该方法能有效地对轴承进行多种故障类型和多种故障程度的识别。Shang，Z.W等 [<xref ref-type="bibr" rid="hanspub.38863-ref15">15</xref>] 提出了一种基于快速动态时间扭曲(fast DTW)和自适应高斯–伯努利深度信念网络(AGBDBN)的故障诊断方法并取得了良好的诊断效果。Li Xiang等 [<xref ref-type="bibr" rid="hanspub.38863-ref16">16</xref>] 提出了一种基于深度学习的机械故障诊断的领域适应方法，引入对抗性训练进行边缘域融合，并探索无监督并行数据实现不同机器健康状况下的条件分布对齐。Chen Xiaohan等 [<xref ref-type="bibr" rid="hanspub.38863-ref17">17</xref>] 提出了一种自动特征学习神经网络，根据学习到的特征，并利用长短期记忆来识别故障类型。Wang Yu等 [<xref ref-type="bibr" rid="hanspub.38863-ref18">18</xref>] 提出了一种基于宽卷积和多尺度卷积的新型胶囊网络(WMSCCN)对轴承进行故障诊断。Xue Yan [<xref ref-type="bibr" rid="hanspub.38863-ref19">19</xref>] 提出了一种基于深度卷积神经网络(DCNN)和支持向量机(SVM)的故障诊断方法。Guo Chaozhong等 [<xref ref-type="bibr" rid="hanspub.38863-ref20">20</xref>] 提出了一种基于深度信念网络(DBN)的超参数优化的滚动轴承智能故障诊断方法。对于深度学习方法而言，这些方法虽然都可以在轴承诊断上进行高性能的表现，但是由于深度卷积网络在深度上还有其最后的全连接层上的参数数据庞大，这对工业检测的设备计算性能和储存性能都有一定的要求。</p><p>本文提出了一种传统特征提取与深度学习特征融合的IFNN深度学习模型。该方法通过深度学习特征对传统特征进行修正，以得到更加鲁棒性的特征，而且该方法继承了深度学习自学习特征的优点，同时由于对传统特征进行了修正，避免了全连接层的产生。进而使得模型的参数降低了一半，从而进一步提高了运行训练时间。</p></sec><sec id="s6"><title>2. IFNN模型原理</title><sec id="s6_1"><title>2.1. 小波变换</title><p>小波变换作为处理非平稳信号的方法，它通过变化的“时间–频率”窗口去提取时序信号中的局部信息，从而对信号的局部信息进行表征。这种局部分析方法为信号在低频上的不突出和高频上的过多干扰提供了有效的降噪措施。其小波变换表达式如下</p><p>D W ( 2 − j , 2 − j k ) = 1 2 j ∫ − ∞ + ∞ f ( t ) y ( t − 2 j k 2 j ) d t (1)</p><p>其小波逆变换为：</p><p>f ( t ) = A ∑ j = − ∞ + ∞ ∑ k = − ∞ + ∞ D W ( 2 j , 2 j k ) ψ ( 2 j , 2 j k ) ( x ) (2)</p><p>在式(1-2)中， f ( t ) 是原始信号， ψ ( t ) 是小波母函数， 2 − j 是伸缩因子， 2 − j k 是平移因子，A一个与号无关的常数。</p></sec><sec id="s6_2"><title>2.2. 1D卷积神经网络</title><p>卷积神经网络是由若干滤波器组成的多级神经网络。过滤器的设计用于从输入中提取特征，输入包含两种层：卷积层和池化层。下面将分别描述每种类型的层的作用。</p><p>卷积层将输入的局部区域与滤波器的多个内核进行卷积，然后由激活单元产生输出特征。滤波器使用不同的内核来提取输入局部区域的不同局部特征。一个滤波器包含了不同的内核，而内核的多少表式该滤波器的大小。我们用 K i l ， b i l 分别表示层l中第i个滤波器内核的权值和偏置，用 x l ( j ) 表示层l中的第j个局部区域。因此，卷积过程可描述如下：</p><p>y i l + 1 ( j ) = K i l * x l ( j ) + b i l (3)</p><p>这里*表示局部区域与滤波器内核的权值的卷积运算， y i l + 1 ( j ) 表示第l + 1层第i个内核的第j个神经元的输入。</p><p>在卷积运算后，激活函数是必不可少的。它使神经网络能够获得输入信号的非线性表达，提高了表示能力，使学习到的特征更加具有可分性。近年来，整流线性单元(Relu)被广泛用作激活单元，以加快CNN的收敛速度。当使用反向传播学习方法调整参数时，relu使浅层的权重更容易训练。RELU的公式如下：</p><p>a i ( l + 1 ) ( j ) = f ( y i ( l + 1 ) ( j ) ) = max { 0 , y i ( l + 1 ) ( j ) } (4)</p><p>其中 y i l + 1 ( j ) 是卷积运算的输出值， a i l + 1 ( j ) 是 y i l + 1 ( j ) 的激活值。</p><p>在卷积神经网络结构中，通常在卷积层之后添加池化层。它作为一种下采样操作，用于减少了卷积神经网络的特征空间大小和参数。最常用的池化层是最大池化层，其对输入特征执行局部最大操作，以减少参数并获得信号的表征。最大池转换描述如下：</p><p>p i l + 1 ( j ) = max ( j − 1 ) W + 1 ≤ t ≤ j W { q i l ( t ) } (5)</p><p>其中 q i l ( t ) 表示l层第i个卷积内核的t神经元的值， t ∈ [ ( j − 1 ) W , j W ] ，W为池化内核的宽度， p i l + 1 ( j ) 表示池化操作后的神经元的值。</p></sec><sec id="s6_3"><title>2.3. IFNN模型的提出</title><p>CNN强大的自提取特征的能力。已经很好地应用于轴承诊断领域，但是其特点都是采用的小的卷积核，虽然小的卷积核能很优秀的学习到局部特征，但是却容易丢失关联信息。 例如信号是非平稳性信号，这就使得需要传递的信息未能被完全学习，从而导致模型训练造成的低精度。此外，小内核容易受到外部环境中常见的低频噪声的影响。因此，为了使内核拥有足够大的接收场以捕获低频信号的有用信息，也能接受高频振动的有用信息。我们将单小内核卷积神经网络进行改进，通过大内核的形式将高低频信息全部得到有效提取，同时利用传统方法将轴承信号的时频域特征进行提取，使得两类不同性质的特征进行相互作用，从而将其泛化能力和性能进一步提高。我们提出了的模型的一个输入为该卷积核以大卷积核阶梯减小的CNN模型。这样能使得模型结构加深，学习到的特征更具表达性。另一个输入轴承信号的传统特征，然后将这两类不同特征进行融合操作，并在其后添加全连接层，其功能是通过全连接降低输出参数，达到降维目的。同时由于DNN也拥有优化特征的能力。这样的结合使得模型的性能有了进一步的提高。</p><p>互扰神经网络(Interference neural network)。即本文提出了一种自适应的IFNN模型。每个部分的详细信息将在下面的部分中描述。</p><sec id="s6_3_1"><title>2.3.1. IFNN模型</title><p>如图1所示，CNN的输入是轴承诊断信号。第一个卷积层从被截获的原始信号中提取特征，而不进行任何其他转换。不同之处在于，本文采用大的内核去提取相关特征信息。通过自学习的方式剔除噪音信息。</p><p>它包括特征提取阶段和分类阶段。特征提取阶段不同之处在于，它具有两个不同的输入端，其中一个输入端拥有7层CNN的基本结构，但是它通过大的卷积核进行特征提取操作。而另一个输入端拥有3层DNN的基本结构。其通过全连接的方式将传统特征进行加工。然后得到的两个维度的特征进行融合，这样做的目的是为了使信息交融。通过这种方法使得所得到的特征相互干扰，从而形成一种相互促进的机制，进一步使得学习到的特征具有更深层的表达。</p><p>其分类阶段由一个全连接层，并利用Softmax函数对3个神经元进行逻辑变换，使之符合不同条件下的概率分布。而softmax函数的形式为：</p><p>t ( z j ) = e z j ∑ k = 1 n e z k (6)</p><p>其中 z j 表示第j个输出逻辑神经元的值。</p><p>图1. 提出的IFNN模型结构</p></sec><sec id="s6_3_2"><title>2.3.2. IFNN的训练</title><p>IFNN模型的结构是为输入信号为一维序列数据而设计的，有关IFNN结构的详细信息将在第三节中给出。传统的二维CNN和一维CNN的主要结构差异在于是处理数据的维度，而一维CNN使用一维内核和一维特征映射。另外，在反传播过程中，与二维卷积(卷积2D)和横向旋转(旋转180)不同的是，是通过一维卷积和逆卷积进行反向传播的。在这一部分中，我们将详细阐述利用反向传播算法对IFNN进行训练的过程。</p><p>我们的IFNN模型的损失函数是Softmax输出的概率分布与目标类的概率分布之间的交叉熵。用 y ( i ) 表示第i个逻辑神经元的目标概率， y &#175; ( i ) 表示第i个逻辑神经元的预测概率。从而该损失函数的表达式为：</p><p>J ( w , b ) = L ( y &#175; ( i ) , y ( i ) ) = − 1 m ∑ i = 1 m ( y ( i ) log ( y &#175; ( i ) ) ) + ( 1 − y ( i ) ) log ( 1 − y &#175; ( i ) ) (7)</p><p>完全连接的层与BP中的层完全相同。具体来说，设 χ ( l ) 是交叉熵损失J在l + 1层对l层产生的误差。其中 ( W , b ) 是对应于l到l + 1层的权值和偏置。最后L层的损失误差表达式为：</p><p>χ ( l ) = ( ( W ( l ) ) T χ ( l + 1 ) ) f ′ ( z ( l ) ) (8)</p><p>并通过梯度下降算法对参数迭代更新，公式如下：</p><p>W i j ( l ) = W i j ( l ) − α ∂ J ∂ W i j ( l ) (9)</p><p>b i ( l ) = b i ( l ) − α ∂ J ∂ b i ( l ) (10)</p><p>其中 α 为学习率。</p><p>而对于池化层来说，由于其没有参数，所有不需要进行权值更新，因此只需要对其输入求导。其表达式为：</p><p>∂ g ∂ x i = { 1 ,         if   x i = max ( x ) 0 ,                 其 他 (11)</p><p>g ′ n = ∂ g ∂ x ( n − 1 ) m + 1 : n m (12)</p><p>其中 g ′ n 表示第n个池化操作。</p><p>χ ( n − 1 ) m + 1 : n m x = χ n ( y ) g ′ n = ∂ J ∂ y n ∂ y n ∂ x ( n − 1 ) m + 1 : n m = ∂ J ∂ x ( n − 1 ) m + 1 : n m (13)</p><p>最后，对于计算滤波器的梯度，我们将使用卷积运算，并反转误差矩阵，因此表达式为：</p><p>χ ( l − 1 ) = ( ∂ a l ∂ a l − 1 ) T χ l = χ l rot 180 ( W l ) ∗ f ( a l − 1 ) (14)</p><p>其中rot180表示将卷积内核反转180度。</p></sec></sec></sec><sec id="s7"><title>3. 实验数据与信号时域分析</title><sec id="s7_1"><title>3.1. 数据描述</title><p>该实验数据来自于KAT数据中心中的基于振动和电动机电流信号的状态监测(CM)实验轴承数据集。该数据集是通过高采样率(40 Hz)采集的。该数据是根据Creative Commons Attribution-Non Commercial 4.0国际许可证授权的。可用于非商业学术研究。该数据包含了轴承健康、加速损坏或者人为损坏。表1中是分别选取的5组健康轴承数据集和有实际损害的数据集，并用其中4组通过5折交叉验证的方式进行训练和验证。且其中1组用于测试。其中任何一组包含80个信号样本，该实验将每个信号样本通过2048个样本点切片。最后获取训练与验证样本119,454个，测试样本29834个。</p></sec><sec id="s7_2"><title>3.2. 信号的时域波形</title><p>三种不同损坏状态的轴承信号时域波形如图2所示。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Experimental dat</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" >健康(类1)</th><th align="center" valign="middle" >加速损坏(类2)</th><th align="center" valign="middle" >人为损坏(类2)</th></tr></thead><tr><td align="center" valign="middle"  rowspan="4"  >训练与验证</td><td align="center" valign="middle" >K001</td><td align="center" valign="middle" >KI14</td><td align="center" valign="middle" >KA05</td></tr><tr><td align="center" valign="middle" >K002</td><td align="center" valign="middle" >KI16</td><td align="center" valign="middle" >KA06</td></tr><tr><td align="center" valign="middle" >K003</td><td align="center" valign="middle" >KI17</td><td align="center" valign="middle" >KA07</td></tr><tr><td align="center" valign="middle" >K004</td><td align="center" valign="middle" >KI18</td><td align="center" valign="middle" >KA08</td></tr><tr><td align="center" valign="middle" >测试</td><td align="center" valign="middle" >K005</td><td align="center" valign="middle" >KI21</td><td align="center" valign="middle" >KA09</td></tr></tbody></table></table-wrap><p>表1. 实验数据</p><p>图2. 不同状态轴承信号的时域波形。(a) 健康轴承；(b) 加速损坏轴承；(c) 人为损坏轴承</p><p>不同状态的轴承信号时域波形有一定的区别，但是这些区别表现出的无规则性，相同状态下可分性小。因此为了实现其损坏状态的诊断识别，研究基于深度学习模型的自适应特征优化和识别方法。</p></sec></sec><sec id="s8"><title>4. 实例验证</title><p>首先将数据进行样本划分，通过小波变换和时域信息提取等算法计算每个样本的低级特征，然后将获得的低级特征与对应的原始样本划分成训练集、验证集和测试集，最后将获得的训练集输入到IFNN模型进行训练，通过训练使模型达到最优，最后用测试集评估IFNN的性能，为了对比所提方法的优越性，使用与1DCNN相同结构深度学习模型和多隐层神经网络作为对比分析。具体实验流程图如图3所示。</p><sec id="s8_1"><title>4.1. 特征提取</title><p>特征提取包括从原始切片信号中提取时间、频率和时频域特征。从机械部件如故障轴承中获取的信号通常是非平稳的，这意味着信号的频率分量随时间的变化而变化。因此，提取时频特征是必要的。在本工作中，小波包分解(WPD)用于提取时频特征。原始信号分解至5级。求1到5级的详细系数和近似系数并从中计算小波能量。利用快速傅里叶变换(FFT)和功率谱密度(PSD)提取频域特征。从每个信号共提取44个特征。然后该特征集和对应的切片信号输入到IFNN模型中进行特征提取。为了分析IFNN网络对特征的判别能力，分别将原始切片信号、提取特征和通过IFNN模型获得的特征用t-SNE技术进行可视化比较。文献 [<xref ref-type="bibr" rid="hanspub.38863-ref15">15</xref>] 详细的介绍了t-SNE理论。可视化结果如图4所示，图4(a)为原始切片信号经过t-SNE后的散点图，从图中可以看出，3种类型的散点状态相互之间有交叉和重叠，呈现出了没有规则的聚集状态，这说明原始特征集类与类之间的特征存在冗余，导致总体呈现出了较差的聚集状态。图4(b)为特征提取的特征经过t-SNE后的散点图，从图中可以看出，3种类型在类与类之间呈现出了有一定规则的聚集状态，整体上观察，类之间的距离还是特别相近，但是有相互分离的趋势，这也是该特征在IFNN模型中对1DCNN模块具有促进作用的原因。图4(c)为IFNN模型学习所得的特征经过t-SNE后的散点图。该图表明类内间距明显变小，类间距明显增大，此外，类与类之间存在的交叉和重叠只在分类边界存在，总之，呈现出了较好的可分性。这些说明IFNN模型对原始特征的学习能力较强，在保留原始特征的内在结构的同时，并消除原始特征之间的冗余，对原始特征进行抽象的提取，使原始特征得到优化，从而使高级特征对轴承的分级和诊断变得更有效。</p><p>图3. 实验流程框图</p><p>图4. 特征可视化分析。(a) 原始信号特征散点图；(b) 特征提取的特征散点图；(c) IFNN优化特征散点图</p></sec><sec id="s8_2"><title>4.2. 模型参数</title><p>IFNN模型架构由一个卷积特征提取单元和一个完全连接的特征优化单元组成，最后是一个分类层。结合本实验的实际需要，确定的模型结构如图1所示。模型的结构参数将在下面详细描述。</p><p>对于一个卷积特征提取单元，由7层卷积神经网络基本单元组成。对于完全连接的特征优化单元，由3层隐藏层的全连接网络组成。然后将两个单元的输出特征进行融合操作。最后连接完全连接的分类单元。具体参数见表2。同时，每层后添加的Dropout操作，其参数为0.2。以提高模型泛化能力。同时其中选用的SGD优化器，学习率0.01。</p><table-wrap-group id="2"><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> Parameter settings of IFNN mode</title></caption><table-wrap id="2_1"><table><tbody><thead><tr><th align="center" valign="middle" >层数</th><th align="center" valign="middle" >层类型</th><th align="center" valign="middle" >卷积核数目</th><th align="center" valign="middle" >核大小/步长</th><th align="center" valign="middle" >激活函数</th><th align="center" valign="middle" >填充方式</th><th align="center" valign="middle" >输出</th></tr></thead><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" >卷积层1</td><td align="center" valign="middle" >32</td><td align="center" valign="middle" >128'1/2'1</td><td align="center" valign="middle" >relu</td><td align="center" valign="middle" >same</td><td align="center" valign="middle" >[None, 2048, 32]</td></tr><tr><td align="center" valign="middle" >2</td><td align="center" valign="middle" >池化层1</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >2'1/2'1</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" >[None, 1024, 32]</td></tr><tr><td align="center" valign="middle" >3</td><td align="center" valign="middle" >卷积层2</td><td align="center" valign="middle" >64</td><td align="center" valign="middle" >128'1/1'1</td><td align="center" valign="middle" >relu</td><td align="center" valign="middle" >same</td><td align="center" valign="middle" >[None, 1024, 64]</td></tr><tr><td align="center" valign="middle" >4</td><td align="center" valign="middle" >池化层2</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >2'1/2'1</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" >[None, 512, 64]</td></tr></tbody></table></table-wrap><table-wrap id="2_2"><table><tbody><thead><tr><th align="center" valign="middle" >5</th><th align="center" valign="middle" >卷积层3</th><th align="center" valign="middle" >32</th><th align="center" valign="middle" >64'1/1'1</th><th align="center" valign="middle" >relu</th><th align="center" valign="middle" >same</th><th align="center" valign="middle" >[None, 512, 32]</th></tr></thead><tr><td align="center" valign="middle" >6</td><td align="center" valign="middle" >池化层3</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >2'1/2'1</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" >[None, 256, 32]</td></tr><tr><td align="center" valign="middle" >7</td><td align="center" valign="middle" >卷积层4</td><td align="center" valign="middle" >64</td><td align="center" valign="middle" >64'1/1'1</td><td align="center" valign="middle" >relu</td><td align="center" valign="middle" >same</td><td align="center" valign="middle" >[None, 256, 64]</td></tr><tr><td align="center" valign="middle" >8</td><td align="center" valign="middle" >池化层4</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >2'1/2'1</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" >[None, 128, 64]</td></tr><tr><td align="center" valign="middle" >9</td><td align="center" valign="middle" >卷积层5</td><td align="center" valign="middle" >32</td><td align="center" valign="middle" >32'1/1'1</td><td align="center" valign="middle" >relu</td><td align="center" valign="middle" >same</td><td align="center" valign="middle" >[None, 128, 32]</td></tr><tr><td align="center" valign="middle" >10</td><td align="center" valign="middle" >池化层5</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >2'1/2'1</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" >[None, 64, 32]</td></tr><tr><td align="center" valign="middle" >11</td><td align="center" valign="middle" >卷积层6</td><td align="center" valign="middle" >64</td><td align="center" valign="middle" >16'1/1'1</td><td align="center" valign="middle" >relu</td><td align="center" valign="middle" >same</td><td align="center" valign="middle" >[None, 64, 64]</td></tr><tr><td align="center" valign="middle" >12</td><td align="center" valign="middle" >池化层6</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >2'1/2'1</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" >[None, 32, 64]</td></tr><tr><td align="center" valign="middle" >13</td><td align="center" valign="middle" >卷积层7</td><td align="center" valign="middle" >128</td><td align="center" valign="middle" >16'1/16'1</td><td align="center" valign="middle" >relu</td><td align="center" valign="middle" >same</td><td align="center" valign="middle" >[None, 32, 128]</td></tr><tr><td align="center" valign="middle" >14</td><td align="center" valign="middle" >池化层7</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >2'1/2'1</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" >[None, 16, 128]</td></tr><tr><td align="center" valign="middle" >15</td><td align="center" valign="middle" >全连接层1</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" >relu</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >[None, 128]</td></tr><tr><td align="center" valign="middle" >16</td><td align="center" valign="middle" >全连接层2</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" >relu</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >[None, 512]</td></tr><tr><td align="center" valign="middle" >17</td><td align="center" valign="middle" >全连接层3</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" >relu</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >[None, 128]</td></tr><tr><td align="center" valign="middle" >18</td><td align="center" valign="middle" >融合层</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" >[None, 16]</td></tr><tr><td align="center" valign="middle" >19</td><td align="center" valign="middle" >分类层</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" >Softmax</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >[None, 3]</td></tr></tbody></table></table-wrap></table-wrap-group><p>表2. IFNN模型的参数设置</p></sec><sec id="s8_3"><title>4.3. 实验结果分析</title><p>目前由于深度学习没有的参数调节没有确定的方法，往往需要反复试验，通过实验结果微调参数，从而使得模型达到最佳。本实验一：通过调节不同的batch_size大小进行模型实验。从而查看最优的batch_size学习效果。实验二：采用IFNN模型的1DCNN深度学习模型模块和多隐层神经网络模块作为对比实验分析。</p><p>实验一中分别设置了batch_size为[32, 64, 128, 256, 512, 1024]，并使用SGD优化器，其学习率为0.01，同时采用了五折交叉验证。图5、图6分别表示在对应batch_size下的准确率和交叉熵损失值得变化情况。从图中可以看出，不同的batch_size所达到的效果并不相同，其中batch_size为128、256时曲线更加容易收敛，扰动比较小。64、512都能最终收敛，但是在收敛过程中存在不同大小的扰动情况。而32、1024存在过拟合现象。同时对测试集参数进行计算，结果如表3所示。</p><p>图5. 不同batch_size下准确率的变化情况</p><p>通过表3和前面结果分析可得虽然batch_size为125、256是收敛速度快且收敛平稳，但是在测试集中却出现过拟合现象。因此其并不是最优选择。虽然512存在收敛扰动，但是其在测试集中表现的优异性，证明了它是最合理的选择。因此最后选择512作为模型的batch_size参数。图7表示诊断结果图。从结果分析，人为损坏存在20%左右的误诊。其他诊断具有好的性能。</p><p>图6. 不同batch_size下交叉熵损失的变化情况</p><table-wrap id="table3" ><label><xref ref-type="table" rid="table3">Table 3</xref></label><caption><title> Accuracy of IFNN model in different batch_siz</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >Batch</th><th align="center" valign="middle" >平均准确率(%)</th><th align="center" valign="middle" >最高准确率(%)</th><th align="center" valign="middle" >最低准确率(%)</th></tr></thead><tr><td align="center" valign="middle" >32</td><td align="center" valign="middle" >86.904</td><td align="center" valign="middle" >94.93</td><td align="center" valign="middle" >77.16</td></tr><tr><td align="center" valign="middle" >64</td><td align="center" valign="middle" >90.152</td><td align="center" valign="middle" >91.88</td><td align="center" valign="middle" >86.82</td></tr><tr><td align="center" valign="middle" >128</td><td align="center" valign="middle" >89.132</td><td align="center" valign="middle" >93.41</td><td align="center" valign="middle" >83.38</td></tr><tr><td align="center" valign="middle" >256</td><td align="center" valign="middle" >88.332</td><td align="center" valign="middle" >92.77</td><td align="center" valign="middle" >78.56</td></tr><tr><td align="center" valign="middle" >512</td><td align="center" valign="middle" >91.916</td><td align="center" valign="middle" >93.42</td><td align="center" valign="middle" >89.23</td></tr><tr><td align="center" valign="middle" >1024</td><td align="center" valign="middle" >83.738</td><td align="center" valign="middle" >96.10</td><td align="center" valign="middle" >67.80</td></tr></tbody></table></table-wrap><p>表3. IFNN模型在不同batch_size的准确率</p><p>在实验二中采用不加融合的方式进行实验对比。分别采用卷积网络实验和使用多层全连接网络实验。其中卷积神经网络采用模型的卷积模块部分。结果如图8(a)所示，其中多层全连接采用模型的全连接部分。结果如图8(b)所示。从图8(a)能够看出，在健康状态下有没有样本被预测错误，加速损坏状态下有0.04%的样本被预测为健康，0.69%的样本被预测为人为损坏。人为损坏状态下有37.91%的样本被预测为加速损坏；从图8(a)能够看出，在健康状态下有0.48%的样本被加速损坏，加速损坏状态下有6.67%的样本被预测为人为损坏。人为损坏状态下有0.19%的样本被预测为健康，39.88%的样本被预测为加速损坏。通过对比图7和图8能够看出，IFNN在健康和加速损坏状态下具有较好的诊断能力，虽然在人为情况下的诊断能力只有80%左右，但是相对于其对比模型，其能力大幅提高。</p><p>为了进一步验证模型的有效性，采用传统机器学习算法支持向量机、朴素贝叶斯、随机森林、最近邻算法和逻辑回归进行对比实验。该实验选取稀疏自编码器进行特征提取，并将稀疏自编码器所得的特征与44维时频域特征进行整合。组成最终特征集，然后通过传统的机器学习算法进行分类。该实验结果通过5折交叉验证所得。实验结果如图9所示。从结果可以看出在随机算法与IFNN模型在训练集与验证集上的表现相差在1%左右，但是IFNN模型在测试集上的表现高随机森林算法7%。而与其余模型对比可得，IFNN模型表现性能远高于支持向量机、k最近邻、朴素贝叶斯和逻辑回归算法。这充分说明，IFNN模型在轴承损坏诊断中比对比模型更加有效。</p><p>为了验证所提方法的性能，分别对前文所用模型在测试集上的准确率、精确率、召回率和f1-score进行计算，实验结果如表4所示。从结果不难看出，本文所提出的模型在各个指标都远高于其他模型</p><p>图7. IFNN的诊断结果混淆矩阵图</p><p>图8. 对比实验的诊断结果混淆矩阵图。(a) DNN诊断结果混淆矩阵图；(b) 1DCNN诊断结果混淆矩阵图</p><p>图9. 机器学习模型与IFNN模型在不同数据集上的准确率</p><table-wrap id="table4" ><label><xref ref-type="table" rid="table4">Table 4</xref></label><caption><title> Comparison results of various indicators of different model</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >模型</th><th align="center" valign="middle" >准确率(%)</th><th align="center" valign="middle" >精确率(%)</th><th align="center" valign="middle" >召回率(%)</th><th align="center" valign="middle" >f1-score (%)</th><th align="center" valign="middle" >模型参数大小</th><th align="center" valign="middle" >训练时间</th></tr></thead><tr><td align="center" valign="middle" >IFNN</td><td align="center" valign="middle" >96.09</td><td align="center" valign="middle" >96.48</td><td align="center" valign="middle" >96.10</td><td align="center" valign="middle" >96.08</td><td align="center" valign="middle" >0.6 M</td><td align="center" valign="middle" >12 s</td></tr><tr><td align="center" valign="middle" >DNN</td><td align="center" valign="middle" >84.25</td><td align="center" valign="middle" >86.53</td><td align="center" valign="middle" >84.26</td><td align="center" valign="middle" >83.83</td><td align="center" valign="middle" >2 M</td><td align="center" valign="middle" >47 s</td></tr><tr><td align="center" valign="middle" >IDCNN</td><td align="center" valign="middle" >87.11</td><td align="center" valign="middle" >90.40</td><td align="center" valign="middle" >87.12</td><td align="center" valign="middle" >86.65</td><td align="center" valign="middle" >7 M</td><td align="center" valign="middle" >243 s</td></tr><tr><td align="center" valign="middle" >随机森林算法</td><td align="center" valign="middle" >85.78</td><td align="center" valign="middle" >88.47</td><td align="center" valign="middle" >85.79</td><td align="center" valign="middle" >85.33</td><td align="center" valign="middle" >-</td><td align="center" valign="middle" >-</td></tr><tr><td align="center" valign="middle" >支持向量机</td><td align="center" valign="middle" >72.93</td><td align="center" valign="middle" >78.33</td><td align="center" valign="middle" >72.95</td><td align="center" valign="middle" >69.43</td><td align="center" valign="middle" >-</td><td align="center" valign="middle" >-</td></tr><tr><td align="center" valign="middle" >K最近邻</td><td align="center" valign="middle" >80.26</td><td align="center" valign="middle" >84.44</td><td align="center" valign="middle" >80.27</td><td align="center" valign="middle" >78.84</td><td align="center" valign="middle" >-</td><td align="center" valign="middle" >-</td></tr><tr><td align="center" valign="middle" >逻辑回归</td><td align="center" valign="middle" >58.83</td><td align="center" valign="middle" >56.87</td><td align="center" valign="middle" >58.85</td><td align="center" valign="middle" >56.69</td><td align="center" valign="middle" >-</td><td align="center" valign="middle" >-</td></tr><tr><td align="center" valign="middle" >朴素贝叶斯</td><td align="center" valign="middle" >70.54</td><td align="center" valign="middle" >74.15</td><td align="center" valign="middle" >70.57</td><td align="center" valign="middle" >66.56</td><td align="center" valign="middle" >-</td><td align="center" valign="middle" >-</td></tr></tbody></table></table-wrap><p>表4. 不同模型各个指标的对比结果</p><p>的结果。同时本文所提模型在参数大小与每个epoch的训练时长都小于其他深度学习模型(由于传统机器学习方法没有用GPU加速，因此不予比较)。</p><p>除了上述性能指标外，还引入了接收器工作特性(ROC)曲线，并应用于多分类性能的可视化。ROC图描述了灵敏度(SEN)和特异性(SPE)之间的相对权衡。ROC图下的面积越大，分类性能越好。通过图10(a)~(h)图像中roc区域面积值比较，IFNN在不同的类别上，都达到了1，微观平均roc曲线和宏观平均roc曲线下的面积均大于其他模型。由此可以得出该模型的结果具有稳定性。可以用于轴承故障诊断。</p><p>图10. 不同模型的ROC曲线图</p></sec></sec><sec id="s9"><title>5. 结论</title><p>本文提出一个基于传统特征与卷积神经网络特征融合的方法。该方法通过卷积网络对原始传统特征进行修正学习，自我地进行特征优化学习，进一步学习到优良的特征表达。实验结果表明，相比于本文所提到的其他方法，进行轴承的故障诊断，IFNN模型对轴承故障状态有更好的鉴别能力和稳定性。</p></sec><sec id="s10"><title>基金项目</title><p>重庆市研究生科研创新项目(No. 2020S0037)。</p></sec><sec id="s11"><title>文章引用</title><p>余 波,王朝宇,付志超,凌 静,陈军江. 基于1D卷积与特征融合的深度学习轴承诊断算法研究 Research on Deep Learning Bearing Diagnosis Algorithm Based on 1D Convolution and Feature Fusion[J]. 计算机科学与应用, 2020, 10(11): 2105-2121. https://doi.org/10.12677/CSA.2020.1011222</p></sec><sec id="s12"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.38863-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">李辉, 郑海起, 杨绍普. 基于EMD和Teager能量算子的轴承故障诊断研究[J]. 振动与冲击, 2008(10): 22-24+29+195.</mixed-citation></ref><ref id="hanspub.38863-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">田晶, 李有儒, 艾延廷. 一种基于Deep-GBM的航空发动机中介轴承故障诊断方法[J]. 航空动力学报, 2019, 34(4): 756-763.</mixed-citation></ref><ref id="hanspub.38863-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">张文颢, 李永健, 张卫华. 基于K-奇异值分解和层次化分块正交匹配算法的滚动轴承故障诊断[J]. 中国机械工程, 2019, 30(4): 406-412.</mixed-citation></ref><ref id="hanspub.38863-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">刘文朋, 廖英英, 杨绍普, 刘永强, 顾晓辉. 一种基于多点峭度谱和最大相关峭度解卷积的滚动轴承故障诊断方法[J]. 振动与冲击, 2019, 38(2): 151-156+168.</mixed-citation></ref><ref id="hanspub.38863-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">欧璐, 于德介. 路图傅里叶变换及其在滚动轴承故障诊断中的应用[J]. 机械工程学报, 2015, 51(23): 76-83.</mixed-citation></ref><ref id="hanspub.38863-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">He, C., Wu, T., Liu, C.C. and Chen, T. (2020) A Novel Method of Composite Multiscale Weighted Permutation Entropy and Machine Learning for Fault Complex System Fault Diagnosis. Measurement, 158, Article ID: 107748.  
&lt;br&gt;https://doi.org/10.1016/j.measurement.2020.107748</mixed-citation></ref><ref id="hanspub.38863-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Mohamad, T.H., Nazari, F. and Nataraj, C. (2020) A Re-view of Phase Space Topology Methods for Vibration-Based Fault Diagnostics in Nonlinear Systems. Journal of Vibra-tion Engineering &amp; Technologies, 8, 393-401.  
&lt;br&gt;https://doi.org/10.1007/s42417-019-00157-6</mixed-citation></ref><ref id="hanspub.38863-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Liu, C.Y. and Gryllias, K. (2020) A Semi-Supervised Support Vector Data Description-Based Fault Detection Method for Rolling Element Bearings Based on Cyclic Spectral Analysis. Mechanical Systems and Signal Processing, 140, Article ID: 106682. &lt;br&gt;https://doi.org/10.1016/j.ymssp.2020.106682</mixed-citation></ref><ref id="hanspub.38863-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Wang, G., Zhang, F., Cheng, B.Y. and Fang, F. (2020) DAMER: A Novel Diagnosis Aggregation Method with Evidential Reasoning Rule for Bearing Fault Diagnosis. Journal of Intelligent Manufacturing.</mixed-citation></ref><ref id="hanspub.38863-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">杜小磊, 陈志刚, 张楠, 等. 基于同步挤压S变换和深度学习的轴承故障诊断[J]. 组合机床与自动化加工技术, 2019, 543(5): 95-98+102.</mixed-citation></ref><ref id="hanspub.38863-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">庄雨璇, 李奇, 杨冰如, 等. 基于LSTM的轴承故障诊断端到端方法[J]. 噪声与振动控制, 2019, 39(6): 187-193.</mixed-citation></ref><ref id="hanspub.38863-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">吴小龙, 雷文平, 陈宏, 等. 具有多核结构的稀疏化DNN在轴承诊断中的应用[J]. 机械设计与制造, 2020(2): 248-251, 255.</mixed-citation></ref><ref id="hanspub.38863-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">涂小卫, 张士强, 王明. 基于深度置信网络的牵引电机轴承故障诊断方法[J]. 城市轨道交通研究, 2020, 23(1): 174-178, 195.</mixed-citation></ref><ref id="hanspub.38863-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">杜小磊, 陈志刚, 许旭, 等. 改进深层小波自编码器的轴承故障诊断方法[J]. 计算机工程与应用, 2020, 56(5): 263-269.</mixed-citation></ref><ref id="hanspub.38863-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">Shang, Z.W., Liu, X., Li, W.X., et al. (2020) A Rolling Bearing Fault Diagnosis Method Based on Fast DTW and an AGBDBN. Insight, 62, 457-463. &lt;br&gt;https://doi.org/10.1784/insi.2020.62.8.457</mixed-citation></ref><ref id="hanspub.38863-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">Li, X., Zhang, W., Xu, N.X., et al. (2020) Deep Learning-Based Machinery Fault Diagnostics with Domain Adaptation across Sensors at Different Places. IEEE Transactions on Industrial Electronics, 67, 6785-6794.  
&lt;br&gt;https://doi.org/10.1109/TIE.2019.2935987</mixed-citation></ref><ref id="hanspub.38863-ref17"><label>17</label><mixed-citation publication-type="other" xlink:type="simple">Chen, X.H., Zhang, B.K. and Gao, D. (2020) Bearing Fault Diag-nosis Base on Multi-Scale CNN and LSTM Model. Journal of Intelligent Manufacturing.</mixed-citation></ref><ref id="hanspub.38863-ref18"><label>18</label><mixed-citation publication-type="other" xlink:type="simple">Wang, Y., Ning, D.J. and Feng, S.L. (2020) A Novel Capsule Network Based on Wide Convolution and Multi-Scale Convolution for Fault Diagnosis. Applied Sciences—Basel, 10, 16. &lt;br&gt;https://doi.org/10.3390/app10103659</mixed-citation></ref><ref id="hanspub.38863-ref19"><label>19</label><mixed-citation publication-type="other" xlink:type="simple">Xue, Y., Dou, D.Y. and Yang, J.G. (2020) Multi-Fault Diagnosis of Rotating Machinery Based on Deep Convolution Neural Network and Sup-port Vector Machine. Measurement, 156, 7.  
&lt;br&gt;https://doi.org/10.1016/j.measurement.2020.107571</mixed-citation></ref><ref id="hanspub.38863-ref20"><label>20</label><mixed-citation publication-type="other" xlink:type="simple">Guo, C.Z., Li, L., Hu, Y.Y., et al. (2020) A Deep Learn-ing Based Fault Diagnosis Method with Hyperparameter Optimization by Using Parallel Computing. IEEE Access, 8, 131248-131256.  
&lt;br&gt;https://doi.org/10.1109/ACCESS.2020.3009644</mixed-citation></ref></ref-list></back></article>