<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2019.96133</article-id><article-id pub-id-type="publisher-id">CSA-31044</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20190600000_50627089.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于卷积神经网络室内火焰烟雾识别
  Indoor Flame Smoke Identification Based on Convolutional Neural Network
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>白</surname><given-names>岩</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>徐</surname><given-names>泽堃</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>黄</surname><given-names>森</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>于</surname><given-names>显驰</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>李</surname><given-names>覃</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>赵</surname><given-names>伟</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>东北林业大学，黑龙江 哈尔滨</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>18</day><month>06</month><year>2019</year></pub-date><volume>09</volume><issue>06</issue><fpage>1183</fpage><lpage>1191</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   人们在生活中面临的最大问题是室内火灾问题。近年来，基于图像模式识别的火灾探测技术引起了众多研究者的关注，并得到了迅速的发展。技术以计算机技术为核心，结合图像处理技术和模式识别技术，可以对火灾火焰和烟雾特征实现有效的检测和识别，在人流聚集的市场、企业事业单位的办公区域和生产车间区域火灾报警可以发挥出重要的作用。本文分析了烟雾和火焰模式识别的难点，使用运动学检测方法、特征提取、卷积神经网络等方法解决了传统方法对室内烟雾和火焰识别不准确的缺点。结果表明，该识别方案的准确率可以达到93%。 The biggest problem people face in life is the problem of indoor fire. In recent years, fire detection technology based on image pattern recognition has attracted the attention of many researchers and developed rapidly. With computer technology as the core, combined with image processing technology and pattern recognition technology, it can effectively detect and identify fire flame and smoke characteristics, gather people in the market, and play an important role in fire alarm in office areas and production workshops of enterprises and institutions. This paper analyzes the difficulties of smoke and flame pattern recognition, and uses kinematics detection method, feature ex-traction, convolutional neural network and other methods to solve the shortcomings of the traditional method of indoor smoke and flame recognition which is not accurate. The result shows that the accuracy of the scheme can reach 93%. 
  
 
</p></abstract><kwd-group><kwd>烟雾特征，计算机视觉，神经网络, Characteristics of Smoke</kwd><kwd> Computer Vision</kwd><kwd> The Neural Network</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>基于卷积神经网络室内火焰烟雾识别<sup> </sup></title><p>白岩，徐泽堃，黄森，于显驰，李覃，赵伟<sup>*</sup></p><p>东北林业大学，黑龙江 哈尔滨</p><disp-formula id="hanspub.31044-formula83"><graphic xlink:href="//html.hanspub.org/file/17-1541451x5_hanspub.png"  xlink:type="simple"/></disp-formula><p>收稿日期：2019年6月8日；录用日期：2019年6月21日；发布日期：2019年6月28日</p><disp-formula id="hanspub.31044-formula84"><graphic xlink:href="//html.hanspub.org/file/17-1541451x6_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>人们在生活中面临的最大问题是室内火灾问题。近年来，基于图像模式识别的火灾探测技术引起了众多研究者的关注，并得到了迅速的发展。技术以计算机技术为核心，结合图像处理技术和模式识别技术，可以对火灾火焰和烟雾特征实现有效的检测和识别，在人流聚集的市场、企业事业单位的办公区域和生产车间区域火灾报警可以发挥出重要的作用。本文分析了烟雾和火焰模式识别的难点，使用运动学检测方法、特征提取、卷积神经网络等方法解决了传统方法对室内烟雾和火焰识别不准确的缺点。结果表明，该识别方案的准确率可以达到93%。</p><p>关键词 :烟雾特征，计算机视觉，神经网络</p><disp-formula id="hanspub.31044-formula85"><graphic xlink:href="//html.hanspub.org/file/17-1541451x7_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2019 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/17-1541451x8_hanspub.png" /> <img src="//html.hanspub.org/file/17-1541451x9_hanspub.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>火灾的发生一直是人们日常生活中最难预防的灾害之一 [<xref ref-type="bibr" rid="hanspub.31044-ref1">1</xref>] 。今天，随着世界经济的发展，城市面积逐渐扩大，出现了许多大型的空间建筑，如大公司、商场、住宅楼等，建筑内部结构复杂多样。通常这些建筑物人流较多，无论是建筑材料还是建筑放置的物品，越易燃，就越容易引起火灾的发生。近10年来，共发生火灾3.1万起，造成474人死亡，直接财产损失15.6亿元。中国高层建筑火灾数据分析显示，在过去10年里，中国发生了3.1万起火灾。数据显示，8层以上24米以上高层建筑34.7万幢，100米以上超高层建筑6000多栋，居世界首位。随着社会的逐步发展，人们一直在总结消防救援经验，试图将火灾的经济损失降到最低。杜绝火灾的发生是不现实的，但如果我们可以找到正确的方式，可以检测火灾的发生，通过自动报警，让人们快速找到火源，用最短的时间将它熄灭，可以极大地减少火灾损失，因此，火焰和烟雾的识别是人们继续研究的重要内容。随着计算机技术和电子技术的发展，“智慧城市”已成为城市建设的主题，智能监控系统已应用于各种场景环境。与传统的火灾探测器相比，模式识别技术能够以更大的监测距离和更广的应用范围探测火灾情况，为人们及时准确地探测火灾提供了一种新的方法。</p></sec><sec id="s4"><title>2. 火灾与烟雾识别过程</title><sec id="s4_1"><title>2.1. 运动目标检测</title><p>现在常用的运动目标检测方法主要可以分为三种：光流法、帧间差分法、背景减除法。摄像机采集的视频序列具有连续性的特点 [<xref ref-type="bibr" rid="hanspub.31044-ref2">2</xref>] 。因为如果场景内没有运动目标，则连续帧的变化很微弱，存在运动目标，则连续的帧和帧之间会有明显地变化，所以我们采用的是帧间差分法。帧间差分法(Temporal Difference)就是借鉴了上述思想。由于场景中的目标在运动，目标的影像在不同图像帧中的位置不同。该类算法对时间上连续的两帧或三帧图像进行差分运算，不同帧对应的像素点相减，判断灰度差的绝对值，当绝对值超过一定阈值时，即可判断为运动目标，从而实现目标的检测功能。运动目标监测流程图如下图1所示。</p><p>图1. 运动目标监测流程图</p><p>帧差法的特点是实现简单，运算速度快，对于动态环境自适应性是很强的，对光线的变化不是十分的敏感。但是在运动体内易产生空洞．特别是目标运动速度较快时，影响目标区域准确提取。</p></sec><sec id="s4_2"><title>2.2. 神经网络选取</title><p>在图像识别问题中，输入层的每一个神经元可能代表一个像素的灰度值。但这种神经网络用于图像识别有几个问题，一是没有考虑图像的空间结构，识别性能会受到限制；二是每相邻两层的神经元都是全相连，参数太多，训练速度受到限制 [<xref ref-type="bibr" rid="hanspub.31044-ref3">3</xref>] 。</p><p>而卷积神经网络就可以解决这些问题。卷积神经网络使用了针对图像识别的特殊结构，可以快速训练。因为速度快，使得采用多层神经网络变得容易，而多层结构在识别准确率上又很大优势。卷积神经网络如下图2所示。</p><p>图2. 卷积神经网络图</p><p>做烟雾和火焰我们分别采用两种神经网络，做烟雾识别我们采用的是mobilenet网络，做火焰识别我们采用的是使用tensorflow自己搭建的神经网络结构，这样可以使火焰和烟雾得到更好的识别效果 [<xref ref-type="bibr" rid="hanspub.31044-ref4">4</xref>] 。</p><p>Mobilenet是一种基于深度可分离卷积的模型，深度可分离卷积是一种将标准卷积分解成深度卷积以及一个1 &#215; 1的卷积即逐点卷积。对于MobileNet而言，深度卷积针对每个单个输入通道应用单个滤波器进行滤波，然后逐点卷积应用1 &#215; 1的卷积操作来结合所有深度卷积得到的输出。而标准卷积一步即对所有的输入进行结合得到新的一系列输出。深度可分离卷积将其分成了两步，针对每个单独层进行滤波然后下一步即结合。这种分解能够有效的大量减少计算量以及模型的大小。</p><p>我们为了提高识别的精度，我们使用的是mobilenet-ssd。SSD是为了实现实时目标检测而设计的。Faster R&#173;CNN使用一个区域建议网络region proposal network (RPN)产生可能包含物体的建议区域(一般训练时2000，测试时600)，并且利用这些建议区域进行微调对物体进行分类和定位。Faster RCNN整个处理过程大约是每秒7帧，这远远不能满足实时性。SSD通过取消RPN来加速处理过程。为了弥补精度上的损失。</p><p>SSD采取了一些改进方法如：</p><p>1) 提取了不同尺度的特征图来做检测，大尺度特征图(较靠前的特征图)可以用来检测小物体，而小尺度特征图(较靠后的特征图)用来检测大物体。这些改进方法允许SSD使用较低分辨率的图像就可以达到Faster R&#173;CNN的精度，而且处理速度更快。从下图可以看出，SSD达到了实时处理的速度并且精度还强于Faster R&#173;CNN。(精度的评价指标是m AP&#173;预测平均精度)。</p><p>2) 采用了不同尺度和长宽比的先验框(Prior boxes, Default boxes，在Faster R&#173;CNN中叫做锚(Anchors)。</p><p>3) 采用CNN来直接进行检测，而不是像Faster RCNN Yolo那样在全连接层之后做检测，实现了全卷积。</p><p>4) 将空洞卷积应用于目标检测。</p><p>识别火焰我们使用自己搭建的神经网络，网络的结构是→卷积–池化–卷积–池化–卷积–池化–全连接层–全连接层–全连接层，神经网络的深度对于神经网络的识别率是很关键的，神经网络深度过深的网络识别的效果不一定会很好，但是深度太浅的神经网络识别的结果一定是不好的。在搭建的神经网络的过程中使用的tflearn，这是一个和tensorflow息息相关的一个第三方包，用来弥补tensorflow搭建网络过于复杂的问题</p></sec><sec id="s4_3"><title>2.3. 火焰特征提取</title><p>从火焰和烟雾的纹理特征和几何特征入手，实现对火焰和烟雾的准确识别 [<xref ref-type="bibr" rid="hanspub.31044-ref5">5</xref>] 。</p><p>火焰模型和运动检测一般采用几何特征分析。采用火焰颜色模型或运动检测提取的图像区域作为输入。几何特征包括轮廓粗糙度、面积增长率和圆形度</p><p>1) 轮廓粗糙度</p><p>轮廓粗糙度是指物体轮廓的周长与其凸壳的周长之比。由于火焰的不规则性，在大多数情况下，图像中火焰的轮廓是凹的，其轮廓周长大于凸壳的轮廓周长。因此，可以设置阈值，当轮廓粗糙度大于一定阈值时，认为该区域可能是火焰区域。火焰轮廓区域特征图如下图3所示。</p><p>图3. 火焰区域特征图</p><p>2) 圆形度</p><p>圆是同一周长下面积最大的几何图形。如果物体的形状离圆越近，C<sub>k</sub>越大；否则，形状越复杂，C<sub>k</sub>越小。C<sub>k</sub>的值在0和1之间。同样，由于火焰形状不规则，可以设置阈值C (如1/2.56)</p><p>C k = 4 π A k P k 2 ,   k = 1 , 2 , ⋯ , n (1)</p><p>其中A<sub>k</sub>表示区域的面积，P<sub>k</sub>表示区域的周长，C<sub>k</sub>表示区域的圆形度。</p><p>3) 面积增长率</p><p>在火灾的初始阶段，火焰在图像中的面积不断增大。在燃烧过程中，火焰形状的变化也会带来一定程度的面积变化，而一般物体的面积不会经常变化。因此，还可以设置阈值来确定某个区域是否可能是火焰区域。</p><p>G i = a r e a ( R i ) t − a r e a ( R i ) t 0 t − t 0 (2)</p><p>area(R<sub>t</sub>)<sub>t</sub>即为区域R<sub>i</sub>在时间点t的面积值，则G<sub>i</sub>为从t<sub>0</sub>到t时间段内R<sub>i</sub>区域的面积变化率。</p><p>在火灾的初始阶段，火焰在图像中的面积不断增大。在燃烧过程中，火焰形状的变化也会带来一定程度的面积变化，而一般物体的面积不会经常变化。因此，还可以设置阈值来确定某个区域是否可能是火焰区域。</p><p>几何特征要求火焰在图像中有一个清晰的轮廓。图像中火焰轮廓越清晰，上述计算的特征值就越有价值。图像中的噪声轮廓也会影响上述特征。此时，使用硬边界形式进行判断并不理想，可以考虑基于机器学习的决策方法。</p><p>纹理特征通常在颜色和运动分析之后进行分析。感兴趣的感兴趣区域的纹理特征本质上是其像素值的空间变化的统计特征</p><p>一阶统计：一阶统计特征表示每个像素值本身的属性，不考虑像素与相邻像素之间的关系。利用区域灰度直方图计算一阶统计特征。常见的一阶统计特征包括均值、方差、倾斜度等。</p><p>二阶统计：二阶统计特征表示像素与相邻像素之间的空间关系，采用灰度共生矩阵计算。灰度直方图是图像上单个像素的某一灰度的统计结果，而灰度共生矩阵是图像上保持一定距离的两个像素的某一灰度的统计结果。常见的二阶统计特征包括熵和对比度。火焰特征提取图如下图4所示。</p><p>图4. 火焰特征提取图</p></sec><sec id="s4_4"><title>2.4.神经网络特征训练过程</title><p>对于烟雾识别的训练过程就是先对图片的加载，分为训练数据集和测试数据集，测试数据集和训练数据集都有标签，用于和识别的结果进行对比，然后进行反馈传递，改变神经网络的参数，一遍遍的修改神经元的参数，最后达到一个很低的loss以及很高的accuracy [<xref ref-type="bibr" rid="hanspub.31044-ref6">6</xref>] 。这里使用的keras搭建的网络，输出的数据先是经过mobilenet，然后是model_mobilenet.predict(x).reshape((7 * 7 * 1024))，得到一些预测的数据，然后再经过自己搭建的神经网络，最后得到自己搭建神经网络的预测结果，反向传递修改的只是自己搭建神经网络的参数 [<xref ref-type="bibr" rid="hanspub.31044-ref7">7</xref>] 。monilenet卷积神经网络工作过程如图5所示，一个标准的卷积1(a)被分解成深度卷积1(b)以及1 &#215; 1的逐点卷积1(c)。</p><p>图5. 卷积神经网络工作过程</p><p>Mobilenet神经网络架构，如下表1所示。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Mobileenet neural network architectur</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >Type/Stride</th><th align="center" valign="middle" >Filter Shape</th><th align="center" valign="middle" >Input Size</th></tr></thead><tr><td align="center" valign="middle" >Conv/s2</td><td align="center" valign="middle" >3*3*3*32</td><td align="center" valign="middle" >224*224*3</td></tr><tr><td align="center" valign="middle" >Conv dw/s1</td><td align="center" valign="middle" >3*3*32 dw</td><td align="center" valign="middle" >112*112*32</td></tr><tr><td align="center" valign="middle" >Conv/s1</td><td align="center" valign="middle" >1*1*32*64</td><td align="center" valign="middle" >112*112*32</td></tr><tr><td align="center" valign="middle" >Conv dw/s2</td><td align="center" valign="middle" >3*3*64 dw</td><td align="center" valign="middle" >112*112*64</td></tr><tr><td align="center" valign="middle" >Conv/s1</td><td align="center" valign="middle" >1*1*64*128</td><td align="center" valign="middle" >56*56*64</td></tr><tr><td align="center" valign="middle" >Conv dw/s1</td><td align="center" valign="middle" >3*3*128 dw</td><td align="center" valign="middle" >56*56*128</td></tr><tr><td align="center" valign="middle" >Conv/s1</td><td align="center" valign="middle" >1*1*128*128</td><td align="center" valign="middle" >56*56*128</td></tr><tr><td align="center" valign="middle" >Conv dw/s2</td><td align="center" valign="middle" >3*3*128 dw</td><td align="center" valign="middle" >56*56*128</td></tr><tr><td align="center" valign="middle" >Conv/s1</td><td align="center" valign="middle" >1*1*128*256</td><td align="center" valign="middle" >28*28*128</td></tr><tr><td align="center" valign="middle" >Conv dw/s1</td><td align="center" valign="middle" >3*3*256 dw</td><td align="center" valign="middle" >28*28*256</td></tr><tr><td align="center" valign="middle" >Conv/s1</td><td align="center" valign="middle" >1*1*256*256</td><td align="center" valign="middle" >28*28*256</td></tr><tr><td align="center" valign="middle" >Conv dw/s2</td><td align="center" valign="middle" >3*3*256 dw</td><td align="center" valign="middle" >28*28*256</td></tr><tr><td align="center" valign="middle" >Conv/s1</td><td align="center" valign="middle" >1*1*256*512</td><td align="center" valign="middle" >14*14*256</td></tr><tr><td align="center" valign="middle" >5&#215;Conv dw/s1 5&#215;Conv/s1</td><td align="center" valign="middle" >3*3*512 dw 1*1*512*512</td><td align="center" valign="middle" >14*14*512 14*14*512</td></tr><tr><td align="center" valign="middle" >Conv dw/s2</td><td align="center" valign="middle" >3*3*512 dw</td><td align="center" valign="middle" >14*14*512</td></tr><tr><td align="center" valign="middle" >Conv/s1</td><td align="center" valign="middle" >1*1*512*1024</td><td align="center" valign="middle" >7*7*512</td></tr><tr><td align="center" valign="middle" >Conv dw/s2</td><td align="center" valign="middle" >3*3*1024 dw</td><td align="center" valign="middle" >7*7*1024</td></tr><tr><td align="center" valign="middle" >Conv/s1</td><td align="center" valign="middle" >1*1*1024*1024</td><td align="center" valign="middle" >7*7*1024</td></tr><tr><td align="center" valign="middle" >Avg Pool/s1</td><td align="center" valign="middle" >Pool 7*7</td><td align="center" valign="middle" >7*7*1024</td></tr><tr><td align="center" valign="middle" >FC/s1</td><td align="center" valign="middle" >1024*1000</td><td align="center" valign="middle" >7*7*1024</td></tr><tr><td align="center" valign="middle" >Softmax/s1</td><td align="center" valign="middle" >Classifier</td><td align="center" valign="middle" >7*7*1024</td></tr></tbody></table></table-wrap><p>表1. Mobileenet神经网络架构</p><p>除全连接层外，所有层后面都接着BN、Relu，如下图6所示，全连接层接Softmax用于分类。MobileNet共有28层 [<xref ref-type="bibr" rid="hanspub.31044-ref8">8</xref>] 。</p><p>图6. 层间连接图</p><p>实际运算速度不仅与乘–加(Mult-Adds)操作的次数有关，还与矩阵的稀疏度有关，非结构化稀疏矩阵的运算速度通常低于稠密矩阵的运算速度 [<xref ref-type="bibr" rid="hanspub.31044-ref9">9</xref>] 。矩阵运算时需要使用im2col将矩阵转化为列向量进行计算，im2col的示意图如下图7所示。</p><p>图7. Im2col的示意图</p><p>但是MobileNet中使用的1 &#215; 1，1 &#215; 1的卷积不需要im2col操作，可以节省大量时间，MobileNet花费95%的时间在1 &#215; 1，1 &#215; 1的卷积上，1 &#215; 1，1 &#215; 1的卷积上包含了75%的参数，剩下的参数大都在全连接层上，具体参数见下表2。</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> Other parameter</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >Type</th><th align="center" valign="middle" >Mult-Adds</th><th align="center" valign="middle" >Parameters</th></tr></thead><tr><td align="center" valign="middle" >Conv 1*1</td><td align="center" valign="middle" >94.86%</td><td align="center" valign="middle" >74.59%</td></tr><tr><td align="center" valign="middle" >ConvDW 3*3</td><td align="center" valign="middle" >3.06%</td><td align="center" valign="middle" >1.06%</td></tr><tr><td align="center" valign="middle" >Conv 3*3</td><td align="center" valign="middle" >1.19%</td><td align="center" valign="middle" >0.02%</td></tr><tr><td align="center" valign="middle" >FullyConnected</td><td align="center" valign="middle" >0.18%</td><td align="center" valign="middle" >04.33%</td></tr></tbody></table></table-wrap><p>表2. 其他参数</p><p>MobileNet使用的优化方法为asynchronous gradient descent，与Inception-V3相同，因为是小网络，不用担心过拟合，所以只使用少量/不用正则与数据增强 [<xref ref-type="bibr" rid="hanspub.31044-ref10">10</xref>] 。</p></sec></sec><sec id="s5"><title>3. 实验结果与分析</title><p>本文使用的实验数据集来自于火焰烟气开放数据集和网络采集。实验数据集分为训练集和测试集，图像数据均来自不同的场景，有利于模型的训练和推广 [<xref ref-type="bibr" rid="hanspub.31044-ref11">11</xref>] 。可以看出，本文使用的数据集属于小数据集，因此本文采用Image Net大数据集作为迁移学习的数据集。图像网分类数据集包含1000个类别的图像数据。大量丰富的数据为基于深度迁移学习的模型构建提供了有力的支持。</p><p>基于mobilenet的图像处理的特点是无论从图片细节显示或其他高级图像的抽象特点如边缘、纹理等特征，这些都是可以详细地反映在卷积过滤之后，这主要是因为mobilenet训练拥有的大量数据，使训练mobilenet网络学习样本的抽象特性得到了更详细和准确的方法。一般情况下，将图像网络数据集中训练好的mobilenet模型使用到火焰烟雾识别问题中，能够较好地提取了图像的抽象特征，从而提高了模型的泛化能力。</p><p>本文中使用的方法有火焰和烟雾识别约93%的速度，但它缺乏学习能力的微烟数据集。这主要是因为前者有很大的依赖性对于数据，需要极其大量数据学习。火焰与烟雾识别结果如下图8所示。</p><p>图8. 火焰与烟雾识别结果</p></sec><sec id="s6"><title>4. 结论</title><p>本文针对室内火灾安全需求和现火焰烟雾识别的不足，将神经网络引入火焰烟雾识别的设计。本文采用神经网络中mobiletnet网络的结构，提出了可高效识别室内火焰烟雾的方法，省去了用户对家庭火灾安全的烦恼，识别成功率达到了93%。未来我们会将视线注视到火焰烟雾识别其他场景相结合，并进一步研究运动学检测方法，神经网络的其他模型与算法，深度学习分类方法等技术，让更多的用户体验到人工智能所带来的便利，使用户的生活安全提高一个层次。因此，本系统设计具有很高的研究意义和实用价值。</p></sec><sec id="s7"><title>基金项目</title><p>“中央高校基本科研业务费专项资金资助” (Supported by the Fundamental Research Funds for the Central Universities) 2572019BF03。</p></sec><sec id="s8"><title>文章引用</title><p>白 岩,徐泽堃,黄森,于显驰,李 覃,赵 伟. 基于卷积神经网络室内火焰烟雾识别Indoor Flame Smoke Identification Based on Convolutional Neural Network[J]. 计算机科学与应用, 2019, 09(06): 1183-1191. https://doi.org/10.12677/CSA.2019.96133</p></sec><sec id="s9"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.31044-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">孙继平, 孙雁宇, 范伟强. 基于可见光和红外图像的矿井外因火灾识别方法[J]. 工矿自动化, 2019, 4(5): 1-6.</mixed-citation></ref><ref id="hanspub.31044-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">冯丽琦, 赵亚琴, 孙一超, 龚云荷. 一种基于多尺度局部纹理特征和CART决策树的野外火灾火焰图像识别算法[J]. 计算机应用与软件, 2019(5): 194-198.</mixed-citation></ref><ref id="hanspub.31044-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">汪乐章, 林娴, 唐伊文, 张国平. 基于树莓派与计算机视觉的家庭火灾报警系统的设计与研究[J]. 电子测量技术, 2019, 42(8): 83-87.</mixed-citation></ref><ref id="hanspub.31044-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">刘剑慧. 智能识别在隧道火警上的应用[J]. 电子技术与软件工程, 2019(7): 144.</mixed-citation></ref><ref id="hanspub.31044-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">刘小虎, 欧阳继能, 卜乐平. 基于改进梯度边缘特征的早期火焰识别方法[J]. 消防科学与技术, 2019, 38(2): 250-252.</mixed-citation></ref><ref id="hanspub.31044-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">黎传琛, 白勇, 陈益民. 基于迁移学习的火焰图像识别技术研究[J]. 高技术通讯, 2019, 29(3): 274-282</mixed-citation></ref><ref id="hanspub.31044-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">刘建浩, 娄春, 冯涛, 王龙飞, 兰勇. 基于辐射图像处理的玻璃窑炉火焰特征监测研究[J]. 工业炉, 2019, 41(1): 15-18.</mixed-citation></ref><ref id="hanspub.31044-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Jones, V.C., Kennedy, R.D., Welding, K., Gielen, A.C. and Frattaroli, S. (2019) The Prevalence of Fire and CO Safety Amenities in Airbnb Venues That Permit Smoking—Findings from 17 Countries. Preventive Medicine, 123, 8-11.  
https://doi.org/10.1016/j.ypmed.2019.02.021</mixed-citation></ref><ref id="hanspub.31044-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Ronchi, E., Corbetta, A., Galea, E.R., Kinateder, M., Kuligowski, E., McGrath, D., Pel, A., Shiban, Y., Thompson, P. and Toschi, F. (2019) New Approaches to Evacuation Modeling for Fire Safety Engineering Applications. Fire Safety Journal, 106, 197-209. &lt;br&gt;https://doi.org/10.1016/j.firesaf.2019.05.002</mixed-citation></ref><ref id="hanspub.31044-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Van Coile, R., Jomaas, G. and Bisby, L. (2019) Defining ALARP for Fire Safety Engineering Design via the Life Quality Index. Fire Safety Journal, 107, 1-14. &lt;br&gt;https://doi.org/10.1016/j.firesaf.2019.04.015</mixed-citation></ref><ref id="hanspub.31044-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">朱永红, 杨建. 基于深度学习对陶瓷梭式窑火焰图像识别[J]. 西部皮革, 2018, 40(22): 152-153.</mixed-citation></ref></ref-list></back></article>