<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2018.88132</article-id><article-id pub-id-type="publisher-id">CSA-26595</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20180800000_41852047.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于遗传算法和正则化极限学习机的PM2.5浓度预测研究
  PM
  <sub>2.5</sub> Prediction Based on Genetic Algorithm and Regularized Extreme Learning Machine
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>翁</surname><given-names>福添</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>张</surname><given-names>天乐</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>侯</surname><given-names>木舟</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>罗</surname><given-names>建书</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff3"><addr-line>国防科技大学，理学院，湖南 长沙</addr-line></aff><aff id="aff2"><addr-line>中南大学，数学与统计学院，湖南 长沙</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>31</day><month>07</month><year>2018</year></pub-date><volume>08</volume><issue>08</issue><fpage>1207</fpage><lpage>1216</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   环境质量与人们的健康息息相关，一直是研究的热点。本文选取长沙市2017年NO<sub>2</sub>、PM<sub>10</sub>等大气数据对PM<sub>2.5</sub>日均值进行预测，采用BIC准则进行特征选择。在传统的超限学习机(ELM)的基础上，引入正则化项以控制模型的复杂度，并用遗传算法(GA)对模型的输入层权重矩阵和隐含层阈值矩阵进行优化，建立遗传算法和正则化极限学习机(GA-RE-ELM)的PM<sub>2.5</sub>预测模型。实验表明，该模型相比BP神经网络、超限学习机有更好的精度，均方误差分别降低了35.09%、25.49%，平均绝对误差分别降低了40.86%、30.80%，平均绝对百分误差分别降低了45.49%、31.65%，为PM<sub>2.5</sub>浓度的预测提供一种新的方法。 Environmental quality is closely related to people’s health and has always been a research hotspot. In this paper, the daily average values of PM<sub>2.5</sub> are predicted by atmospheric data such as NO<sub>2</sub> and PM<sub>10</sub> in Changsha City in 2017, and the BIC criterion is used for feature selection. On the basis of the traditional over-limit learning machine (ELM), the regularization term is introduced to control the complexity of the model, and the input layer weight matrix and the hidden layer threshold matrix of the model are optimized by genetic algorithm (GA) to establish the genetic algorithm. Then the PM<sub>2.5</sub> prediction model of the regularized limit learning machine (GA-RE-ELM) is built, the experiment shows that the model achieves more state of the art performance than the BP neural network and the over-limit learning machine, the mean square error is reduced by 35.09% and 25.49%, the average absolute error is reduced by 40.86% and 30.80%, and the average absolute percentage error is reduced by 45.49% and 31.65%. Meanwhile, it provides a new method for predicting PM<sub>2.5</sub> concentration.
    
  
 
</p></abstract><kwd-group><kwd>遗传算法，正则化极限学习机，PM2.5浓度预测, Genetic Algorithm</kwd><kwd> Regularized ELM</kwd><kwd> PM<sub>2.5</sub> Concentration Prediction</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>基于遗传算法和正则化极限学习机的 PM<sub>2.5</sub>浓度预测研究<sup> </sup></title><p>翁福添<sup>1</sup>，张天乐<sup>1</sup>，侯木舟<sup>1*</sup>，罗建书<sup>2</sup></p><p><sup>1</sup>中南大学，数学与统计学院，湖南 长沙</p><p><sup>2</sup>国防科技大学，理学院，湖南 长沙</p><disp-formula id="hanspub.26595-formula78"><graphic xlink:href="//html.hanspub.org/file/7-1541114x5_hanspub.png"  xlink:type="simple"/></disp-formula><p>收稿日期：2018年8月5日；录用日期：2018年8月20日；发布日期：2018年8月27日</p><disp-formula id="hanspub.26595-formula79"><graphic xlink:href="//html.hanspub.org/file/7-1541114x6_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>环境质量与人们的健康息息相关，一直是研究的热点。本文选取长沙市2017年NO<sub>2</sub>、PM<sub>10</sub>等大气数据对PM<sub>2.5</sub>日均值进行预测，采用BIC准则进行特征选择。在传统的超限学习机(ELM)的基础上，引入正则化项以控制模型的复杂度，并用遗传算法(GA)对模型的输入层权重矩阵和隐含层阈值矩阵进行优化，建立遗传算法和正则化极限学习机(GA-RE-ELM)的PM<sub>2.5</sub>预测模型。实验表明，该模型相比BP神经网络、超限学习机有更好的精度，均方误差分别降低了35.09%、25.49%，平均绝对误差分别降低了40.86%、30.80%，平均绝对百分误差分别降低了45.49%、31.65%，为PM<sub>2.5</sub>浓度的预测提供一种新的方法。</p><p>关键词 :遗传算法，正则化极限学习机，PM<sub>2.5</sub>浓度预测</p><disp-formula id="hanspub.26595-formula80"><graphic xlink:href="//html.hanspub.org/file/7-1541114x7_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2018 by authors and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/7-1541114x8_hanspub.png" /> <img src="//html.hanspub.org/file/7-1541114x9_hanspub.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>空气质量的好坏和人们的健康息息相关，PM<sub>2.5</sub>作为衡量空气质量的重要标准，逐渐引起人们的重视，进而成为众多学者研究的热点 [<xref ref-type="bibr" rid="hanspub.26595-ref1">1</xref>] 。从国内外近几年的研究状况来看 [<xref ref-type="bibr" rid="hanspub.26595-ref2">2</xref>] ，应用数值方法来预测PM<sub>2.5</sub>浓度通常需要较详细的排放源时空分布资料和高分辨率的气象模式，但该方法的发展在我国的大部分城市并不成熟 [<xref ref-type="bibr" rid="hanspub.26595-ref3">3</xref>] 。而回归分析 [<xref ref-type="bibr" rid="hanspub.26595-ref4">4</xref>] 、时间序列 [<xref ref-type="bibr" rid="hanspub.26595-ref5">5</xref>] 、贝叶斯网络 [<xref ref-type="bibr" rid="hanspub.26595-ref6">6</xref>] 等广泛应用的空气质量统计预测方法，其预测精度并不能令人满意 [<xref ref-type="bibr" rid="hanspub.26595-ref7">7</xref>] 。随着计算机技术和理论的发展，基于智能原理的人工神经网络、支持向量机模型在PM<sub>2.5</sub>浓度的预测中取得了不错的效果 [<xref ref-type="bibr" rid="hanspub.26595-ref8">8</xref>] 。然而，传统的神经网络容易过拟合，隐藏层神经元个数难以确定、寻找结构参数复杂，而且在输入数据较多且具有多重共线性时 [<xref ref-type="bibr" rid="hanspub.26595-ref2">2</xref>] ，神经网络模型的训练效率会降低，从而影响空气质量预测的精度。陈绍炜 [<xref ref-type="bibr" rid="hanspub.26595-ref9">9</xref>] ，易少强 [<xref ref-type="bibr" rid="hanspub.26595-ref10">10</xref>] ，张卫辉 [<xref ref-type="bibr" rid="hanspub.26595-ref11">11</xref>] 等分别提出了各种与极限学习机(ELM)结合的预测模型，在工程问题上取得了一定的效果 [<xref ref-type="bibr" rid="hanspub.26595-ref12">12</xref>] ，但这些方法都有可能陷入局部最优。</p><p>本文运用BIC信息准则选择与PM<sub>2.5</sub>浓度相关的指标，并结合遗传算法和正则化项，提出了一种基于超限学习机的PM<sub>2.5</sub>预测模型(GA-RELM)。该预测模型融合了遗传算法全局寻优和正则化项能控制ELM模型复杂度，能有效地提高PM<sub>2.5</sub>浓度预测的精度，并分析与其有关的指标，为加强环境污染的防控提供有力的参考。</p></sec><sec id="s4"><title>2. 研究方法</title><sec id="s4_1"><title>2.1. BP神经网络</title><p>误差反向传播算法(BP)解决的了神经网络隐含层连接权值的问题，进而解放了BP神经网络的应用，它是至今为止最经典且最成功的学习算法之一。在实际任务中使用神经网络时，大多是用BP算法进行训练 [<xref ref-type="bibr" rid="hanspub.26595-ref13">13</xref>] 。1989年Robert Hecht-Nielsen提出了万能逼近定理：具有输出层和至少一层具有激活函数的隐藏层，只要给予足够数量的隐藏层神经元 [<xref ref-type="bibr" rid="hanspub.26595-ref14">14</xref>] ，那么它可以任意精度地毕竟一个闭区间内的连续函数 [<xref ref-type="bibr" rid="hanspub.26595-ref15">15</xref>] 。</p></sec><sec id="s4_2"><title>2.2. 传统的极限学习机</title><p>单隐藏层神经网络是十分常用的网络结构，广泛地运用于各种分类、预测问题上。但其梯度下降学习算法效率较低且容易造成过拟合。黄广斌 [<xref ref-type="bibr" rid="hanspub.26595-ref16">16</xref>] [<xref ref-type="bibr" rid="hanspub.26595-ref17">17</xref>] 等人提出超限学习机模型，通过对隐层神经元阈值和输入层、隐藏层的连接权重的随机赋值，通过Moore-Penrose广义逆求解出输出权重，最终得到唯一的最优解 [<xref ref-type="bibr" rid="hanspub.26595-ref18">18</xref>] 。</p></sec><sec id="s4_3"><title>2.3. 遗传算法和正则化极限学习机算法</title><p>通过增加正则化项以惩罚系数 β ，进而得到更好的泛化性能 [<xref ref-type="bibr" rid="hanspub.26595-ref16">16</xref>] [<xref ref-type="bibr" rid="hanspub.26595-ref17">17</xref>] 。则超限学习机的目标函数为：</p><p>min β ∈ R L &#215; m 1 2 ‖ β ‖ 2 + C 2 ∑ i = 1 N ‖ e i ‖ 2 s .t     h ( x i ) β = t i T − e i T , i = 1 , ⋯ , N (1)</p><p>其中,第一项为正则化项，可控制预测模型的复杂程度。将约束条件带入其目标函数中，我们即得到下面的等价的无约束优化问题：</p><p>min β ∈ R L &#215; m L E L M = 1 2 ‖ β ‖ 2 + C 2 ‖ T − H β ‖ 2 (2)</p><p>可将上面的问题称为岭回归或者正则化最小二乘法，通过将 L E L M 对 β 求导并令其等于零，我们可以得到：</p><p>L E L M = β * − C H T ( T − H β * ) = 0 (3)</p><p>对训练集的数量(N)和隐层神经数量(L)的不同，我们可以得到 β 的两种不同近似解：</p><p>β = { H T ( I C + H T H ) − 1 T         if   N ≤ L ( I C + H T H ) − 1 H T T         if   N &gt; L (4)</p><p>其中，I是纬度为L的单位矩阵。</p><p>遗传算法 [<xref ref-type="bibr" rid="hanspub.26595-ref19">19</xref>] (Genetic Algorithm, GA)是一种基于概率转换的计算方法，是全局搜索的运算模型。它可以将PM<sub>2.5</sub>浓度预测模型的解看成种群，再通过各种遗传学上的操作，让问题解的精度越来越来。</p><p>因此，本文提出了一种结合遗传算法和正则化项的超限学习机(GA-RELM)的PM<sub>2.5</sub>浓度预测模型，该算法增加了正则化项，用于控制空气质量预测模型的复杂性。并通过遗传算法全局搜索寻优的能力，计算正则化极限学习机(RE-ELM)学习模型最优的隐藏层阈值和输入层、隐藏层的连接权值，进而提高PM<sub>2.5</sub>浓度预测模型的泛化能力。该学习模型融合了遗传算法和正则化项的优点，对传统ELM随机产生输入层权值矩阵和隐含层阈值矩阵所造成网络预测出的PM<sub>2.5</sub>浓度值变化较大的问题，是有效的解决方法，在控制学习模型复杂性的同时，还能增加其泛化性能。</p><p>在该学习模型中，将RE-ELM训练样本的输入层、隐藏层的连接权值和隐含层神经元的阈值，看成遗传算法生物中染色体的基因；染色体的适应度即RE-ELM训练样本的均方误差，如此便可以把学习模型中最优的连接权值、阈值的求解问题转化为以降低染色体适应度为目的，选择最佳的染色体问题。总之，结合了遗传算法和正则化项的超限学习机的学习模型，融合了遗传算法的全局搜索最优的能力和RE-ELM的强大学习及泛化性能。</p><p>本文将实验样本(PM<sub>2.5</sub>浓度及其各种影响因素)划分为训练集和验证集两个部分，同时为了减少因为样本数据数量级的差距导致的误差，本文对PM<sub>2.5</sub>浓度预测模型的相关数据做了归一化处理。 [<xref ref-type="bibr" rid="hanspub.26595-ref20">20</xref>] 首先初始化种群，每个染色体中都包含输入层、隐藏层之间的连接权值和隐藏层的阈值；接着采用遗传算法寻找RE-ELM学习模型最佳的初始权值和阈值，本文使用训练集预测误差的均方误差作为个体适应度函数；最后，用GA计算得到的最佳权值和阈值对正则化超限学习机模型的初始连接权值和阈值进行复制，同时设定隐藏层神经元的数量，至此建立了GA-RELM空气质量预测模型；最后利用测试集样本对GA-RELM模型进行测试及效果评价。</p></sec></sec><sec id="s5"><title>3. 基于遗传算法和正则化极限学习机的PM<sub>2.5</sub>浓度预测</title><p>本文采用GA-RELM学习模型对长沙市2017年的PM<sub>2.5</sub>浓度进行预测，算法的具体过程如图1。</p><sec id="s5_1"><title>3.1. 数据来源</title><p>长沙市是我国长江中游地区最重要的城市之一，长沙冬天寒冷且干燥，夏天炎热少雨，汽车、工业排放量较大，只是空气质量不佳。从图2的原始PM<sub>2.5</sub>浓度的数据可以看出，浓度呈现非线性的特征。</p><p>本文选取长沙市2017年空气质量数据来预测PM<sub>2.5</sub>浓度。其中所使用的空气质量数据(包括SO<sub>2</sub>、NO<sub>2</sub>、PM<sub>10</sub>、CO、O<sub>3</sub>)来自长沙市环境监测站，资料取2017-01-01至2017-12-31共365天的日均值数据。所采用的实时气象数据有最高气温(T<sub>max</sub>)、最低气温(T<sub>min</sub>)、平均气温(T<sub>avg</sub>)，均来自长沙市气象局。并选取后40天的样本数据作为测试集，其余的样本数据作为模型的训练样本。</p><p>图1. 基于GA-RELM的预测框架</p><p>图2. 长沙市2017年PM<sub>2.5</sub>浓度原始数据</p></sec><sec id="s5_2"><title>3.2. 预测精度评价指标</title><p>1)平均绝对误差</p><p>M A E = 1 N ∑ i = 1 N | R p r e d − R o b s | (5)</p><p>2)相对百分误差绝对值的平均值</p><p>M A P E = 1 N ∑ i = 1 N | R p r e d − R o b s R o b s | (6)</p><p>3)均方根误差</p><p>R M S E = 1 N ∑ i N ( R p r e d − R o b s ) 2 (7)</p><p>式中， R o b s 、 R p r e d 分别为真实值和预测值,N为测试集样本数。</p></sec><sec id="s5_3"><title>3.3. 算法过程</title><sec id="s5_3_1"><title>3.3.1. BIC准则进行PM<sub>2.5</sub>浓度相关特征的提取</title><p>在预测问题上，模型变量的选择是至关重要的，对预测模型的精度有很大的影响。本文采用贝叶斯贝叶斯信息准则(BIC)对PM<sub>2.5</sub>浓度预测模型进行变量选择，BIC准则的基本思想是假设候选模型中存在均匀分布，接着在学习模型上找到后验分布，最后选择具有最大后验概率的模型，因此我们认为最小化BIC值的变量子集是最优的 [<xref ref-type="bibr" rid="hanspub.26595-ref21">21</xref>] 。</p><p>BIC = − 2 ln g ( θ ^ k | y ) + k log n (8)</p><p>表1显示了不同模型大小的最佳预测子集的输出，本文选择了关于PM<sub>2.5</sub>浓度的8个变量(前一日的SO<sub>2</sub>、NO<sub>2</sub>、PM<sub>10</sub>、CO、O<sub>3</sub>、T<sub>max</sub>、T<sub>min</sub>、T<sub>avg</sub>)，因此输出最优的8个变量模型。从表2可以看出，第5</p><p>个模型的BIC值最低，所以我们选择与该模型对应的变量子集作为后续学习模型的变量，它们分别为前一日的NO<sub>2</sub>、PM<sub>10</sub>、CO、Tmax和Tavg，以第二天的PM<sub>2.5</sub>浓度日均值作为输出。</p></sec><sec id="s5_3_2"><title>3.3.2. 模型参数的设置</title><p>通过上述分析，我们最终选取2017-01-01至2017-11-21的325组数据作为训练样本，2017-11-21至2017-12-30的40组数据作为测试集。并以长沙市前一日的NO<sub>2</sub>、PM<sub>10</sub>、CO、T<sub>max</sub>和T<sub>avg</sub>值作为预测模型的输入，第二天的PM<sub>2.5</sub>浓度值作为输出。</p><p>在以下的实验中，将预测模型的输入数据都归一化到[0, 1]之间，隐藏层的激活函数均使用Sigmoid。而GA-RELM的PM<sub>2.5</sub>浓度预测模型的参数，经过多次测试调整，推荐值见表3。</p><p>在单隐层前馈神经网络模型中，隐藏层神经元的数目大小十分关键，超限学习机作为单隐层前馈神经网络模型之一也是如此。神经元数目过多容易造成模型的过拟合，而数目太少会出现欠拟合的情况，都将降低PM<sub>2.5</sub>浓度的预测效果。因此，本文通过不断试验和改变网络的隐层节点数目，寻找较优的节点</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Subsets of optimal predictor variables for different model size</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >model</th><th align="center" valign="middle" >SO<sub>2 </sub></th><th align="center" valign="middle" >NO<sub>2 </sub></th><th align="center" valign="middle" >PM<sub>10</sub></th><th align="center" valign="middle" >CO</th><th align="center" valign="middle" >O<sub>3 </sub></th><th align="center" valign="middle" >T<sub>max </sub></th><th align="center" valign="middle" >T<sub>min </sub></th><th align="center" valign="middle" >T<sub>avg </sub></th></tr></thead><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" >*</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td></tr><tr><td align="center" valign="middle" >2</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" >*</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" >*</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td></tr><tr><td align="center" valign="middle" >3</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" >*</td><td align="center" valign="middle" >*</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >*</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td></tr><tr><td align="center" valign="middle" >4</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" >*</td><td align="center" valign="middle" >*</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >*</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td></tr><tr><td align="center" valign="middle" >5</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >*</td><td align="center" valign="middle" >*</td><td align="center" valign="middle" >*</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >*</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >*</td></tr><tr><td align="center" valign="middle" >6</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >*</td><td align="center" valign="middle" >*</td><td align="center" valign="middle" >*</td><td align="center" valign="middle" >*</td><td align="center" valign="middle" >*</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >*</td></tr><tr><td align="center" valign="middle" >7</td><td align="center" valign="middle" >*</td><td align="center" valign="middle" >*</td><td align="center" valign="middle" >*</td><td align="center" valign="middle" >*</td><td align="center" valign="middle" >*</td><td align="center" valign="middle" >*</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >*</td></tr><tr><td align="center" valign="middle" >8</td><td align="center" valign="middle" >*</td><td align="center" valign="middle" >*</td><td align="center" valign="middle" >*</td><td align="center" valign="middle" >*</td><td align="center" valign="middle" >*</td><td align="center" valign="middle" >*</td><td align="center" valign="middle" >*</td><td align="center" valign="middle" >*</td></tr></tbody></table></table-wrap><p>表1. 不同模型大小的最佳预测变量子集</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> BIC values for different variable subset</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >Model</th><th align="center" valign="middle" >1</th><th align="center" valign="middle" >2</th><th align="center" valign="middle" >3</th><th align="center" valign="middle" >4</th></tr></thead><tr><td align="center" valign="middle" >BIC</td><td align="center" valign="middle" >−7180.312</td><td align="center" valign="middle" >−7579.4</td><td align="center" valign="middle" >−7676.008</td><td align="center" valign="middle" >−7683.124</td></tr><tr><td align="center" valign="middle" >Model</td><td align="center" valign="middle" >5</td><td align="center" valign="middle" >6</td><td align="center" valign="middle" >7</td><td align="center" valign="middle" >8</td></tr><tr><td align="center" valign="middle" >BIC</td><td align="center" valign="middle" >−7683.16</td><td align="center" valign="middle" >−7679.58</td><td align="center" valign="middle" >−7673.14</td><td align="center" valign="middle" >−7666.192</td></tr></tbody></table></table-wrap><p>表2. 不同变量子集模型的BIC值</p><table-wrap id="table3" ><label><xref ref-type="table" rid="table3">Table 3</xref></label><caption><title> GA-RE-ELM parameters setting tabl</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >序号</th><th align="center" valign="middle" >参数</th><th align="center" valign="middle" >值</th></tr></thead><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" >种群大小</td><td align="center" valign="middle" >30</td></tr><tr><td align="center" valign="middle" >2</td><td align="center" valign="middle" >最大迭代数</td><td align="center" valign="middle" >150</td></tr><tr><td align="center" valign="middle" >3</td><td align="center" valign="middle" >交叉概率</td><td align="center" valign="middle" >0.75</td></tr><tr><td align="center" valign="middle" >4</td><td align="center" valign="middle" >变异概率</td><td align="center" valign="middle" >0.01</td></tr><tr><td align="center" valign="middle" >5</td><td align="center" valign="middle" >目标函数</td><td align="center" valign="middle" >训练集均方误差</td></tr><tr><td align="center" valign="middle" >6</td><td align="center" valign="middle" >终止条件</td><td align="center" valign="middle" >最大迭代数</td></tr></tbody></table></table-wrap><p>表3. GA-RE-ELM参数表</p><p>数。选取ELM网络隐含层节点数范围为[1,200]，计算相应测试集样本均方误差的大小，其结果如图3所示。</p><p>从图3表明，网络隐层神经元数量的增加，会导致测试样本的均方误差在整体上呈现出先降低后升高的趋势，符合前文的分析。为了更精确地选出较优的隐层节点数，本文选取图3中均方误差较低的几个点，对不同的隐层神经元数量的模型进行100次试验，并记录下测试样本均方误差的均值，如表4所示。</p><p>由表4可得，隐藏层神经元数量为43时，学习模型在测试集上的均方误差是最低的。为了便于评价模型的优劣，本文令BP神经网络、ELM神经网络、GA-RELM模型中的隐藏层神经网络数目均为43。</p></sec><sec id="s5_3_3"><title>3.3.3. 实验结果与分析</title><p>把表3的值作为GA-RELM预测模型的参数，对长沙市PM<sub>2.5</sub>浓度进行预测。通过图4 GA优化的进化过程，可以看出GA-RE-ELM预测模型经过150次的计算能得到一个最佳的适应度的稳定迭代值。</p><p>为了更好地验证所提出模型的预测效果，本文分别运用BP神经网络、传统的ELM模型对长沙市PM<sub>2.5</sub>的浓度进行预测，训练样本和测试样本的划分一致。从图5三种预测模型预测结果的绝对误差曲线可以看出，GA-RELM预测模型的绝对误差曲线相对其它两个模型最为平稳，且大部分预测值的绝对误差在10 ug/m<sup>3</sup>之内，在可接受的范围之内。从图6的各个模型的PM<sub>2.5</sub>浓度预测曲线可以看出，GA-RELM的预测效果是最佳的，ELM预测模型次之。</p><p>表5列明了这三种预测模型在训练样本和测试样本上的预测结果，由表中数据分析可知：GA-RELM模型在长沙市PM<sub>2.5</sub>浓度的预测中取得了最优的效果。不管是训练集还是测试集，GA-RELM均取得了最</p><p>图3. 网络的隐层节点数试验过程</p><table-wrap id="table4" ><label><xref ref-type="table" rid="table4">Table 4</xref></label><caption><title> Comparison of repeated test result</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >节点数</th><th align="center" valign="middle" >28</th><th align="center" valign="middle" >31</th><th align="center" valign="middle" >32</th><th align="center" valign="middle" >36</th><th align="center" valign="middle" >37</th><th align="center" valign="middle" >43</th><th align="center" valign="middle" >50</th><th align="center" valign="middle" >62</th><th align="center" valign="middle" >95</th></tr></thead><tr><td align="center" valign="middle" >均方误差</td><td align="center" valign="middle" >21.714</td><td align="center" valign="middle" >21.569</td><td align="center" valign="middle" >21.464</td><td align="center" valign="middle" >21.283</td><td align="center" valign="middle" >21.492</td><td align="center" valign="middle" >21.139</td><td align="center" valign="middle" >21.142</td><td align="center" valign="middle" >21.893</td><td align="center" valign="middle" >25.011</td></tr></tbody></table></table-wrap><p>表4. 多次重复实验结果比较</p><p>好的预测精度，且具有很强的泛化能力。在测试集上，GA-RELM的均方误差BP神经网络和ELM分别降低了35.09%、25.49%，平均绝对误差分别降低了40.86%、30.80%，平均绝对百分误差分别降低了45.49%、31.65%。</p></sec></sec></sec><sec id="s6"><title>4. 结论</title><p>PM<sub>2.5</sub>浓度预测的准确可以为有效地治理空气污染发挥重要的作用。但是，PM<sub>2.5</sub>成因复杂、其浓</p><p>图4. 遗传算法优化的进化过程</p><p>图5. 三种模型预测结果的绝对误差</p><p>图6. 三种模型对测试集样本的预测结果与测试集真实值对比</p><table-wrap id="table5" ><label><xref ref-type="table" rid="table5">Table 5</xref></label><caption><title> Comparisons of prediction consequences for the different model</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" ></th><th align="center" valign="middle" >BP</th><th align="center" valign="middle" >ELM</th><th align="center" valign="middle" >GA-RELM</th></tr></thead><tr><td align="center" valign="middle"  rowspan="2"  >RMSE</td><td align="center" valign="middle" >Tra</td><td align="center" valign="middle" >21.67</td><td align="center" valign="middle" >9.5537</td><td align="center" valign="middle" >7.98</td></tr><tr><td align="center" valign="middle" >Test</td><td align="center" valign="middle" >23.720</td><td align="center" valign="middle" >20.6615</td><td align="center" valign="middle" >15.3955</td></tr><tr><td align="center" valign="middle"  rowspan="2"  >MAPE</td><td align="center" valign="middle" >Tra</td><td align="center" valign="middle" >0.2031</td><td align="center" valign="middle" >0.1404</td><td align="center" valign="middle" >0.102</td></tr><tr><td align="center" valign="middle" >Test</td><td align="center" valign="middle" >0.2330</td><td align="center" valign="middle" >0.1842</td><td align="center" valign="middle" >0.1270</td></tr><tr><td align="center" valign="middle"  rowspan="2"  >MAE</td><td align="center" valign="middle" >Tra</td><td align="center" valign="middle" >17.38</td><td align="center" valign="middle" >5.9118</td><td align="center" valign="middle" >9.83</td></tr><tr><td align="center" valign="middle" >Test</td><td align="center" valign="middle" >19.3487</td><td align="center" valign="middle" >16.5346</td><td align="center" valign="middle" >11.4426</td></tr></tbody></table></table-wrap><p>表5. 不同模型预测的预测结果对比</p><p>Note: Tra means Traing.</p><p>度数据呈现非线性和不规律等特点增大了准确预测PM<sub>2.5</sub>浓度的难度。所以，有效地预测PM<sub>2.5</sub>浓度的模型方法是十分有必要研究的。正如前言所说，运用数值方法来预测PM<sub>2.5</sub>目前在我国的大部分地区并不成熟 [<xref ref-type="bibr" rid="hanspub.26595-ref2">2</xref>] [<xref ref-type="bibr" rid="hanspub.26595-ref3">3</xref>] ，而回归分析 [<xref ref-type="bibr" rid="hanspub.26595-ref4">4</xref>] 、时间序列 [<xref ref-type="bibr" rid="hanspub.26595-ref5">5</xref>] 的预测精度往往不能让人满意。运用基于智能原理的神经网络等方法将成为一个趋势，而传统的神经网络存在过拟合、结构参数寻找复杂等不足，针对这些不足，ELM应运而生 [<xref ref-type="bibr" rid="hanspub.26595-ref12">12</xref>] 。</p><p>然而，传统的超限学习机(ELM)模型由于随机产生输入连接权值和隐层神经元的阈值，会造成预测结果不稳定，本文运用BIC信息准则选择与PM<sub>2.5</sub>浓度相关的指标，并将遗传算法、正则化与极限学习机相结合，提出了一种GA-RE-ELM模型，将其应用于长沙市PM<sub>2.5</sub>浓度的预测中。在该算法中，正则化项能控制学习模型的复杂度，遗传算法能对预测模型的输入层权值和隐含层阈值矩阵进行优化，从而降低了其随机性对结果的影响，能得到更好的预测效果，丰富了PM<sub>2.5</sub>浓度的预测方法，具有很好的实际运用价值。</p></sec><sec id="s7"><title>基金项目</title><p>本研究由国家自然科学基金资助，资助项目61375063，61773404，11301549和11271378，部分资金由中南大学研究生创新基金会(2018zzts322)资助。</p></sec><sec id="s8"><title>文章引用</title><p>翁福添,张天乐,侯木舟,罗建书. 基于遗传算法和正则化极限学习机的PM2.5浓度预测研究PM<sub>2.5</sub> Prediction Based on Genetic Algorithm and Regularized Extreme Learning Machine[J]. 计算机科学与应用, 2018, 08(08): 1207-1216. https://doi.org/10.12677/CSA.2018.88132</p></sec><sec id="s9"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.26595-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">谢心庆, 郑薇. 国内外PM2.5研究进展综述[J]. 电力科技与环保, 2015, 31(4): 17-20.</mixed-citation></ref><ref id="hanspub.26595-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">喻其炳, 李勇, 白云, 等. 基于聚类分析与偏最小二乘法的支持向量机PM_(2.5)预测[J]. 环境科学与技术, 2017(6): 157-164.</mixed-citation></ref><ref id="hanspub.26595-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">苏航, 银燕, 朱彬, 等. 中国环渤海地区SO2和NO2干沉降数值模拟及影响因子分析[J]. 中国环境科学, 2012, 32(11): 1921-1932.</mixed-citation></ref><ref id="hanspub.26595-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Sahanavin, N., Prueksasit, T., Tantrakarnapa, K. 使用路径分析和线性回归确定的高交通区域PM10和PM2.5之间的关系[J]. 环境科学杂志, 2017.</mixed-citation></ref><ref id="hanspub.26595-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Tong, L., Lau, A.K.H., Kai, S., et al. 基于区域数值模拟的香港空气质量时间序列预测[J]. 地球物理研究大气学报, 2018, 123(3).</mixed-citation></ref><ref id="hanspub.26595-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">朱亚杰, 李琦, 侯俊雄, 等. 运用贝叶斯方法的PM_(2.5)浓度时空建模与预测[J]. 测绘科学, 2016, 41(2): 44-48.</mixed-citation></ref><ref id="hanspub.26595-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">李勇, 白云, 李川. 基于小波分析与 BP神经网络的 PM10浓度预测模型[J]. 环境监测管理与技术, 2016, 28(5): 24-28.</mixed-citation></ref><ref id="hanspub.26595-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">王鹏，张秦, 等. 基于ARIMA和SVM的PM 2.5混合Garch模型，浓度预测[J]. 大气污染研究, 2017, 8(5).</mixed-citation></ref><ref id="hanspub.26595-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">陈绍炜, 柳光峰, 冶帅, 等. 基于蝙蝠算法优化ELM的模拟电路故障诊断研究[J]. 电子测量技术, 2015, 38(2): 138-141.</mixed-citation></ref><ref id="hanspub.26595-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">易少强, 何世平, 王杰. 粒子群算法在约束型垫高阻尼结构动力学优化中的应用[J]. 中国舰船研究, 2018(1): 31-37.</mixed-citation></ref><ref id="hanspub.26595-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">张卫辉, 黄南天, 杨金成, 等. 基于广义S变换和DE-ELM的电能质量扰动信号分类[J]. 电测与仪表, 2016, 53(20): 50-55.</mixed-citation></ref><ref id="hanspub.26595-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">梅益, 孙全龙, 喻丽华, 等. 基于GA-ELM的铝合金压铸件晶粒尺寸预测[J]. 金属学报, 2017, 53(9): 1125-1132.</mixed-citation></ref><ref id="hanspub.26595-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Pineda, F.J. (1987) Generalization of Back-Propagation to Recurrent Neural Networks. Physical Review Letters, 59, 2229-2232. &lt;br&gt;https://doi.org/10.1103/PhysRevLett.59.2229</mixed-citation></ref><ref id="hanspub.26595-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">邢高生. 基于系统工程文档的领域知识库构建[D]: [硕士学位论文]. 北京: 北京交通大学, 2017.</mixed-citation></ref><ref id="hanspub.26595-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">Hecht-Nielsen, R. (1989) Theory of the Backpropagation Neural Network. In: Neural Networks for Per-ception, Vol. 2, Harcourt Brace &amp; Co., 593-605.</mixed-citation></ref><ref id="hanspub.26595-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">Huang, G.B., Zhu, Q.Y. and Siew, C.K. (2006) Extreme Learning Machine: Theory and Applications. Neurocomputing, 70, 489-501. &lt;br&gt;https://doi.org/10.1016/j.neucom.2005.12.126</mixed-citation></ref><ref id="hanspub.26595-ref17"><label>17</label><mixed-citation publication-type="other" xlink:type="simple">Huang, G.B.,Zhu, Q.Y. and Siew, C.K. (2006) Real-Time Learning Capability of Neural Networks. IEEE Transactions on Neural Networks, 17, 863-878. &lt;br&gt;https://doi.org/10.1109/TNN.2006.875974</mixed-citation></ref><ref id="hanspub.26595-ref18"><label>18</label><mixed-citation publication-type="other" xlink:type="simple">Huang, G.B., Ding, X. and Zhou, H. (2010) Optimization Method Based Ex-treme Learning Machine for Classification. Elsevier Science Publishers B.V., Amsterdam.</mixed-citation></ref><ref id="hanspub.26595-ref19"><label>19</label><mixed-citation publication-type="other" xlink:type="simple">郑鹏, 张琳娜, 赵凤霞. 形状误差评定的拟合操作研究[J]. 计量与测试技术, 2008, 35(12): 1-3.</mixed-citation></ref><ref id="hanspub.26595-ref20"><label>20</label><mixed-citation publication-type="other" xlink:type="simple">王新全, 孙培廷, 邹永久, 等. 基于 GA-BP模型的船舶柴油机排气温度趋势预测[J]. 大连海事大学学报, 2015, 41(3): 73-76.</mixed-citation></ref><ref id="hanspub.26595-ref21"><label>21</label><mixed-citation publication-type="other" xlink:type="simple">Burnham, K.P. (2004) Understanding AIC and BIC in Model Selection. Sociological Methods &amp; Research, 33.</mixed-citation></ref></ref-list></back></article>