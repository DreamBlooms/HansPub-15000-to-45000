<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2020.109173</article-id><article-id pub-id-type="publisher-id">CSA-37816</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20200900000_27433581.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  一种基于自适应搜索策略的改进萤火虫算法
  An Improved Firefly Algorithm Based on Adaptive Search Strategies
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>于</surname><given-names>干</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>金</surname><given-names>丹丹</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>阜阳师范大学信息工程学院，安徽 阜阳</addr-line></aff><aff id="aff3"><addr-line>阜阳师范大学计算机与信息工程学院，安徽 阜阳</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>02</day><month>09</month><year>2020</year></pub-date><volume>10</volume><issue>09</issue><fpage>1639</fpage><lpage>1645</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   萤火虫算法(FA)是一种基于群智能的优化技术，它在很多优化问题上表现出较好的性能。然而，它求解复杂优化问题时存在一些问题，如收敛速度慢，精度低。针对这些问题，本文提出了一种新的萤火虫算法(取名AFA)，该方法使用了三种混合策略，以获得好的优化性能。它首先使用一种自适应的参数方法来动态改变步长参数，然后应用一种改进的搜索策略来消除吸引力，于是，AFA不再包含光吸收系数和初始吸引力这2个参数；再使用反向学习来提高解的精度。仿真结果表明，本文提出的AFA算法优化结果优于MFA及PAFA算法。 Firefly algorithm (FA) is a recently proposed optimisation technique, based on swarm intelligence, which has shown good optimisation performance. However, FA suffers from slow convergence and low accuracy of solutions. To improve this case, this paper presents a new firefly algorithm (AFA) by using three hybrid strategies to obtain a good optimisation performance. First, an adaptive parameter method is used to dynamically changing the step factor. Second, AFA uses a modified search strategy and eliminates the concept of attractiveness. So, HFA does not include two parameters, ab-sorption coefficient and initial attractiveness. Third, a concept of opposition-based learning is used for improving the accuracy of the global best solution. Experiments on some benchmark problems show that AFA is superior to mimetic FA (MFA) and probabilistic attraction-based FA (PAFA). 
  
 
</p></abstract><kwd-group><kwd>萤火虫算法，自适应搜索策略，反向学习，优化, Firefly Algorithm</kwd><kwd> Adaptive Search Strategies</kwd><kwd> Opposition-Based Learning</kwd><kwd> Optimisation</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>摘要</title><p>萤火虫算法(FA)是一种基于群智能的优化技术，它在很多优化问题上表现出较好的性能。然而，它求解复杂优化问题时存在一些问题，如收敛速度慢，精度低。针对这些问题，本文提出了一种新的萤火虫算法(取名AFA)，该方法使用了三种混合策略，以获得好的优化性能。它首先使用一种自适应的参数方法来动态改变步长参数，然后应用一种改进的搜索策略来消除吸引力，于是，AFA不再包含光吸收系数和初始吸引力这2个参数；再使用反向学习来提高解的精度。仿真结果表明，本文提出的AFA算法优化结果优于MFA及PAFA算法。</p></sec><sec id="s2"><title>关键词</title><p>萤火虫算法，自适应搜索策略，反向学习，优化</p></sec><sec id="s3"><title>An Improved Firefly Algorithm Based on Adaptive Search Strategies</title><p>Gan Yu<sup>1</sup>, Dandan Jin<sup>2</sup></p><p><sup>1</sup>College of Information Engineering, Fuyang Normal University, Fuyang Anhui</p><p><sup>2</sup>School of Computer and Information Engineering, Fuyang Normal University, Fuyang Anhui</p><p><img src="//html.hanspub.org/file/12-1541751x4_hanspub.png" /></p><p>Received: Sep. 7<sup>th</sup>, 2020; accepted: Sep. 18<sup>th</sup>, 2020; published: Sep. 25<sup>th</sup>, 2020</p><p><img src="//html.hanspub.org/file/12-1541751x5_hanspub.png" /></p></sec><sec id="s4"><title>ABSTRACT</title><p>Firefly algorithm (FA) is a recently proposed optimisation technique, based on swarm intelligence, which has shown good optimisation performance. However, FA suffers from slow convergence and low accuracy of solutions. To improve this case, this paper presents a new firefly algorithm (AFA) by using three hybrid strategies to obtain a good optimisation performance. First, an adaptive parameter method is used to dynamically changing the step factor. Second, AFA uses a modified search strategy and eliminates the concept of attractiveness. So, HFA does not include two parameters, absorption coefficient and initial attractiveness. Third, a concept of opposition-based learning is used for improving the accuracy of the global best solution. Experiments on some benchmark problems show that AFA is superior to mimetic FA (MFA) and probabilistic attraction-based FA (PAFA).</p><p>Keywords:Firefly Algorithm, Adaptive Search Strategies, Opposition-Based Learning, Optimisation</p><disp-formula id="hanspub.37816-formula6"><graphic xlink:href="//html.hanspub.org/file/12-1541751x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2020 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/12-1541751x7_hanspub.png" /> <img src="//html.hanspub.org/file/12-1541751x8_hanspub.png" /></p></sec><sec id="s5"><title>1. 标准萤火虫算法</title><p>萤火虫算法是由剑桥大学的Yang教授提出的一种群智能算法，它模拟了萤火虫的闪烁求偶行为。类似于粒子群算法，萤火虫算法也是一种基于群体的随机搜索算法。群体中的每个个体(萤火虫)是对应问题的一个候选解。萤火虫算法的搜索依靠个体之间的吸引而产生移动来完成，适应值较好(较亮)的萤火虫具有较大的吸引力，使得适应值较差(较暗)的萤火虫向其移动。</p><p>个体(萤火虫)之间的吸引力定义为：</p><p>β ( r i j ) = β β 0 e − γ r i j 2 (1)</p><p>其中r<sub>ij</sub>表示萤火虫之间的距离，它定义为：</p><p>r i j = ‖ X i − X j ‖ = ∑ d = 1 D ( x i d − x j d ) 2 (2)</p><p>对于两个不同的萤火虫X<sub>i</sub>和X<sub>j</sub>，适应值较差(较暗)的萤火虫将向较好的萤火虫移动。假设X<sub>j</sub>优于X<sub>i</sub>，则X<sub>i</sub>向X<sub>j</sub>移动，移动方式表示为：</p><p>x i d ( t + 1 ) = x i d ( t ) + β 0 e − γ r i j 2 ( x j d ( t ) − x i d ( t ) ) + α ε i d ( t ) (3)</p><p>标准FA中的参数都事先设定的，FA的搜索能力受到其控制参数(如步长因子)的影响，会导致算法收敛早熟；标准FA因参数设置不当而导致算法无法收敛或收敛速度过慢。为了解决这两类问题，使算法具有较好的优化性能，需要对标准FA进行改进。</p></sec><sec id="s6"><title>2. 改进算法的实现</title><p>萤火虫算法 [<xref ref-type="bibr" rid="hanspub.37816-ref1">1</xref>] [<xref ref-type="bibr" rid="hanspub.37816-ref2">2</xref>] 是基于以下三个理想化的特征提出的：(1) 萤火虫不分性别，即萤火虫之间的相互吸引只考虑个体发光的亮度；(2) 吸引力与发光亮度成正比，与个体之间的距离成反比；(3) 萤火虫的亮度由待优化的目标函数值决定，即 I i = f ( x i ) 。FA的关键思想是亮度小的萤火虫被亮度大的萤火虫吸引而向其移动，并更新自身的位置。萤火虫的发光亮度取决于自身所处位置的目标值，亮度越高所表示的目标值越好，吸引其他萤火虫的能力也越强。若相邻的个体亮度相同，萤火虫则随机移动。</p><p>在标准的FA中，每个萤火虫都能被人群中其他明亮的萤火虫所吸引，这种吸引力机制称为完全吸引模式 [<xref ref-type="bibr" rid="hanspub.37816-ref3">3</xref>] [<xref ref-type="bibr" rid="hanspub.37816-ref4">4</xref>]，在该模型下，标准FA具有双环操作，因此，计算时间复杂度很高，同时FA的搜索能力受到其控制参数(如步长因子)的影响 [<xref ref-type="bibr" rid="hanspub.37816-ref5">5</xref>]。为了解决这个问题，本文提出了一种自适应的参数策略来动态调整步长因子，来消除吸引力。</p><p>1) 自适应搜索策略</p><p>一些文献指出，FA的搜索能力受到其控制参数(如步长因子)的影响。为了克服这个问题，本文使用了一种自适应的参数策略来动态调整步长因子α的值。</p><p>α ( t + 1 ) = ( 1 9000 ) 1 / t α ( t ) (4)</p><p>其中，t指进化的代数。</p><p>基于Rao等人提出的Jaya算法，本文针对萤火虫的移动方式进行了下面改进：</p><p>x i d ( t + 1 ) = x i d ( t ) + r 1 d ( x j d ( t ) − | x i d ( t ) | ) − r 2 d ( x w d ( t ) − | x i d ( t ) | ) (5)</p><p>其中，r<sub>1d</sub>和r<sub>2d</sub>是2个[0,1]之间的随机数，X<sub>w</sub>是当前种群中的最差解。与原有的萤火虫移动公式相比，上述改进公式消除了吸引力的概念。因此，我们新提出的算法不再包含初始吸引力和光吸收系数两个参数。</p><p>2) 反向学习过程</p><p>为了加快算法的收敛，本文使用了反向学习策略(Opposition-Based Learning OBL)。对于当前种群中的最好解X<sub>best</sub>，本文利用OBL产生一个反向解 X b e s t * 。</p><p>X b e s t * ( t ) = a &#175; + b &#175; − X b e s t ( t ) (6)</p><p>其中， [ a &#175; , b &#175; ] 表示当前种群的搜索区间。如果新产生的反向解 X b e s t * 优于X<sub>best</sub>，则使用 X b e s t * 替换X<sub>best</sub>。一些研究表明 [<xref ref-type="bibr" rid="hanspub.37816-ref6">6</xref>] [<xref ref-type="bibr" rid="hanspub.37816-ref7">7</xref>]，反向学习策略OBL有较高的概率找到的反向解比当前解更好。</p><p>3) 算法实现过程</p><p>Begin</p><p>Initialise the population;</p><p>while the stopping condition is satisfied do</p><p>Update the step factor according to equation (4);</p><p>for i = 1 to N do</p><p>for j = 1 to N do</p><p>if f(Xj) &lt; f(Xi) then</p><p>Conduct the movement according to equation (5);</p><p>Compute the fitness value of Xi;</p><p>end if</p><p>end for</p><p>Conduct the X<sub>best</sub><sup>*</sup> according to equation (6);</p><p>ifX<sub>best</sub><sup>*</sup> be better than X<sub>best</sub></p><p>X<sub>best</sub> = X<sub>best</sub><sup>* </sup></p><p>end if</p><p>end for</p><p>end while</p><p>End</p></sec><sec id="s7"><title>3. 使用基准函数来测试AFA算法的性能</title><sec id="s7_1"><title>3.1. 测试函数</title><p>为了验证AFA算法性能，本文使用了7个基准函数进行测试 [<xref ref-type="bibr" rid="hanspub.37816-ref8">8</xref>] [<xref ref-type="bibr" rid="hanspub.37816-ref9">9</xref>] [<xref ref-type="bibr" rid="hanspub.37816-ref10">10</xref>] [<xref ref-type="bibr" rid="hanspub.37816-ref11">11</xref>]，所有测试函数均为最小值优化函数且全局最优解均为零。</p><p>测试函数1：</p><p>F 1 ( X ) = ∑ i = 1 D x i 2 ,     x i ∈ [ − 100 , 100 ] (7)</p><p>测试函数2：</p><p>F 2 ( X ) = ∑ i = 1 D | x i | + ∏ i = 1 D x i ,     x i ∈ [ − 10 , 10 ] (8)</p><p>测试函数3：</p><p>F 3 ( X ) = ∑ i = 1 D ( ∑ j = 1 i x j ) 2 ,     x i ∈ [ − 100 , 100 ] (9)</p><p>测试函数4：</p><p>F 4 ( X ) = max i ( | x i | , 1 ≤ i ≤ D ) ,     x i ∈ [ − 100 , 100 ] (10)</p><p>测试函数5：</p><p>F 5 ( X ) = ∑ i = 1 D − 1 ( 100 ( x i − x i 2 ) 2 + ( x i − 1 ) 2 ) ,     x i ∈ [ − 30 , 30 ] (11)</p><p>测试函数6：</p><p>F 6 ( X ) = ∑ i = 1 D i x i 4 + r a n d ( 0 , 1 ) ,     x i ∈ [ − 1.28 , 1.28 ] (12)</p><p>测试函数7：</p><p>F 7 ( X ) = 418.9829 ⋅ D − ∑ i = 1 D − 1 ( x i sin ( | x i | ) ) ,     x i ∈ [ − 500 , 500 ] (13)</p></sec><sec id="s7_2"><title>3.2. 测试结果分析</title><p>测试实验中上述7个函数维度D分别设置为为10和30，并将AFA的计算结果与MFA和PAFA进行比较，结果显示，本文提出的HFA优于其它两种改进的FA算法。所有算法的终止条件均设置为适应值函数最大个数(MaxFEs)。维度D = 10时，MaxFEs设置为1.0e+04；维度D = 30时，MaxFEs设置为5.0e+04。对于两种不同的维度值，算法的其他参数α，β<sub>0</sub>，γ分别设置为0.2，1.0，及1/Γ2。</p><p>表1展现了当维度D = 10时，经过30代的演化计算三种算法所得到的最优函数值。从结果来看AFA函数结果除函数F7外均优于MFA。求解函数F7问题时，算法MFA和PAFA的优化结果优于AFA算法的结果。与MFA算法类似的是，AFA算法求解F1至F6函数所表现出的其他性能(收敛速度、不易陷入局部寻优等)亦优于PAFA算法，如对于所有的测试函数求解过程中，当AFA算法已找到最优函数值时，算法MFA和PAFA仍陷入局部寻优过程。正如文章开始提到的“标准FA的搜索能力受到其控制参数(如步长因子)的影响，会导致算法收敛早熟”，通过自适应策略，本文提出的AFA算法不易陷入局部寻优的过程。</p><p>表2展现了当维度D = 30时，经过30代的演化计算三种算法所得到的最优函数值。如表所示，AFA求解F1，F2，F3，F5，F6，F7函数展现了较好的算法性能。MFA在求解F4函数时优于AFA。相对于PAFA，求解F1，F2，F5，F6函数时MFA能够找到更加精确地解。求解F3，F4，F7函数时PAFA性能优于AFA。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Computational results of each algorithm for D = 1</title></caption><table><tbody><thead><tr><th align="center" valign="middle"  rowspan="2"  >测试函数</th><th align="center" valign="middle" >MFA</th><th align="center" valign="middle" >PAFA</th><th align="center" valign="middle" >AFA</th></tr></thead><tr><td align="center" valign="middle" >最优解</td><td align="center" valign="middle" >最优解</td><td align="center" valign="middle" >最优解</td></tr><tr><td align="center" valign="middle" >F1</td><td align="center" valign="middle" >2.08e+02</td><td align="center" valign="middle" >2.59e+01</td><td align="center" valign="middle" >6.19e−05</td></tr><tr><td align="center" valign="middle" >F2</td><td align="center" valign="middle" >2.83e+00</td><td align="center" valign="middle" >8.46e−01</td><td align="center" valign="middle" >2.68e−03</td></tr><tr><td align="center" valign="middle" >F3</td><td align="center" valign="middle" >4.26e+02</td><td align="center" valign="middle" >1.56e+01</td><td align="center" valign="middle" >4.52e−01</td></tr><tr><td align="center" valign="middle" >F4</td><td align="center" valign="middle" >8.65e+00</td><td align="center" valign="middle" >1.21e+00</td><td align="center" valign="middle" >1.32e−01</td></tr><tr><td align="center" valign="middle" >F5</td><td align="center" valign="middle" >2.04e−02</td><td align="center" valign="middle" >6.49e−03</td><td align="center" valign="middle" >4.16e−03</td></tr><tr><td align="center" valign="middle" >F6</td><td align="center" valign="middle" >1.87e+03</td><td align="center" valign="middle" >1.42e+03</td><td align="center" valign="middle" >1.08e+03</td></tr><tr><td align="center" valign="middle" >F7</td><td align="center" valign="middle" >3.01e+01</td><td align="center" valign="middle" >1.84e+01</td><td align="center" valign="middle" >3.12e+01</td></tr></tbody></table></table-wrap><p>表1. 维度D = 10各算法寻优结果</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> Computational results of each algorithm for D = 3</title></caption><table><tbody><thead><tr><th align="center" valign="middle"  rowspan="2"  >测试函数</th><th align="center" valign="middle" >MFA</th><th align="center" valign="middle" >PAFA</th><th align="center" valign="middle" >AFA</th></tr></thead><tr><td align="center" valign="middle" >最优解</td><td align="center" valign="middle" >最优解</td><td align="center" valign="middle" >最优解</td></tr><tr><td align="center" valign="middle" >F1</td><td align="center" valign="middle" >5.34e+02</td><td align="center" valign="middle" >8.82e−04</td><td align="center" valign="middle" >1.68e−09</td></tr><tr><td align="center" valign="middle" >F2</td><td align="center" valign="middle" >1.01e+01</td><td align="center" valign="middle" >1.42e−02</td><td align="center" valign="middle" >1.12e−05</td></tr><tr><td align="center" valign="middle" >F3</td><td align="center" valign="middle" >2.15e+03</td><td align="center" valign="middle" >8.08e−03</td><td align="center" valign="middle" >3.12e−01</td></tr><tr><td align="center" valign="middle" >F4</td><td align="center" valign="middle" >8.65e+00</td><td align="center" valign="middle" >1.29e−02</td><td align="center" valign="middle" >1.32e+01</td></tr><tr><td align="center" valign="middle" >F5</td><td align="center" valign="middle" >6.96e−02</td><td align="center" valign="middle" >1.62e−02</td><td align="center" valign="middle" >1.28e−02</td></tr><tr><td align="center" valign="middle" >F6</td><td align="center" valign="middle" >6.53e+03</td><td align="center" valign="middle" >6.12e+03</td><td align="center" valign="middle" >5.98e+03</td></tr><tr><td align="center" valign="middle" >F7</td><td align="center" valign="middle" >1.83e+02</td><td align="center" valign="middle" >2.78e+01</td><td align="center" valign="middle" >3.26e+01</td></tr></tbody></table></table-wrap><p>表2. 维度D = 30各算法寻优结果</p><p>图1展示的是当维度D = 10，算法AFA、MFA和PAFA求解函数F1，F2时的算法收敛过程。</p><p>图1. D = 10，AFA、MFA及PAFA的收敛过程，(a) 功能F1，(b) 功能F2</p><p>图2展示的是当维度D = 30，算法AFA、MFA和PAFA求解函数F1，F2时的算法收敛过程。</p><p>图2. D = 30，AFA、MFA及PAFA的收敛过程，(a) 功能F1，(b) 功能F2</p><p>从收敛曲线来看，本文提出AFA的收敛速度也比MFA和PAFA快。通过标准反向学习过程，AFA解决了“FA因参数设置不当而导致算法无法收敛或收敛速度过慢”问题。</p><p>测试实验中，MaxFEs的值设置的较小。当维度从10增加到30时，MaxFEs的值从1.0e+04增加到5.0e+04，算法MFA和PAFA的实验结果值得到了改进，但如果将MaxFEs设置为一个更大的值时，AFA可能会有更好的表现。通过实验可以得出，MaxFEs的值对AFA的算法性能影响很大。</p></sec></sec><sec id="s8"><title>4. 结束语</title><p>本文提出了一种新的数值优化算法AFA，该算法基于标准的萤火虫算法FA，采用三种改进的措施，包括自适应的参数方法来动态改变步长参数，应用一种改进的搜索策略来消除吸引力；再使用反向学习来提高解的精度。为了验证AFA的算法性能，文章测试了7个标准的数值优化函数，并分别测试了所测7个函数不同维度值。实验结果表明，AFA算法在求解大部分函数时所表现出来的性能都优于算法MFA和PAFA。</p><p>然而，通过函数收敛图可以发现，AFA在整个优化过程中，该算法的收敛速度并没有明显优于MFA和PAFA算法，如何解决这一问题，使AFA算法性能更好，这将是作者今后的研究工作之一。</p></sec><sec id="s9"><title>基金项目</title><p>本文受到安徽省省级示范实验实训中心项目(2018sxzx38)；2018教育部智融兴教课题(2018A01010)；教育部2019年协同育人项目(201901258002)；安徽省教育厅高校优秀拔尖人才资助项目(gxyqZD2020054)等项目资助。</p></sec><sec id="s10"><title>文章引用</title><p>于 干,金丹丹. 一种基于自适应搜索策略的改进萤火虫算法An Improved Firefly Algorithm Based on Adaptive Search Strategies[J]. 计算机科学与应用, 2020, 10(09): 1639-1645. https://doi.org/10.12677/CSA.2020.109173</p></sec><sec id="s11"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.37816-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Wang, H., Wang, W.J., Sun, H. and Rahnamayan, S. (2016) Firefly Algorithm with Random Attraction. International Journal of Bio-Inspired Computation, 8, 33-41. &lt;br&gt;https://doi.org/10.1504/IJBIC.2016.074630</mixed-citation></ref><ref id="hanspub.37816-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Rao, R. (2016) Jaya: A Simple and New Optimization Algorithm for solving Constrained and Unconstrained Optimization Problems. International Journal of Industrial Engineering Computations, 7, 19-34.  
&lt;br&gt;https://doi.org/10.5267/j.ijiec.2015.8.004</mixed-citation></ref><ref id="hanspub.37816-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Cai, X.J., Gao, X.Z. and Xue, Y. (2016) Improved Bat Algorithm with Optimal Forage Strategy and Random Disturbance Strategy. International Journal of Bio-Inspired Computation, 8, 205-214.  
&lt;br&gt;https://doi.org/10.1504/IJBIC.2016.078666</mixed-citation></ref><ref id="hanspub.37816-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Wang, H., Sun, H., Li, C.H., Rahnamayan, S. and Pan, J.S. (2013) Diversity Enhanced Particle Swarm Optimization with Neighborhood Search. Information Sciences, 223, 119-135. &lt;br&gt;https://doi.org/10.1016/j.ins.2012.10.012</mixed-citation></ref><ref id="hanspub.37816-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Fister Jr., I., Yang, X.S., Fister, I. and Brest, J. (2012) Memetic Firefly Algorithm for Combinatorial Optimization. Bioinspired Optimization Methods and Their Applications, 103, 1-14.</mixed-citation></ref><ref id="hanspub.37816-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Yu, G. (2016) An improved Firefly Algorithm Based on Probabilistic Attraction. International Journal of Computing Science and Mathematics, 7, 530-536. &lt;br&gt;https://doi.org/10.1504/IJCSM.2016.081701</mixed-citation></ref><ref id="hanspub.37816-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Yu, G. and Feng, Y.Y. (2018) Improving Firefly Algorithm Using Hybrid Strategies. International Journal of Computing Science and Mathematics, 9, 163-170. &lt;br&gt;https://doi.org/10.1504/IJCSM.2018.091749</mixed-citation></ref><ref id="hanspub.37816-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Zhang, M.Q., Wang, H., Cui, Z.H. and Chen, J.J. (2018) Hybrid Multi-Objective Cuckoo Search with Dynamical Local Search. Memetic Computing, 10, 199-208. &lt;br&gt;https://doi.org/10.1007/s12293-017-0237-2</mixed-citation></ref><ref id="hanspub.37816-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Wang, F., Zhang, H., Li, K., Lin, Z., Yang, J. and Shen, X.-L. (2018) A Hybrid Particle Swarm Optimization Algorithm Using Adaptive Learning Strategy. Information Sciences, 436-437, 162-177.  
&lt;br&gt;https://doi.org/10.1016/j.ins.2018.01.027</mixed-citation></ref><ref id="hanspub.37816-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Wang, F., Zhang, H., Li, Y., Zhao, Y. and Rao, Q. (2018) External Archive Matching Strategy for MOEA/D. Soft Computing, 22, 7833-7846. &lt;br&gt;https://doi.org/10.1007/s00500-018-3499-9</mixed-citation></ref><ref id="hanspub.37816-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Cui, Z., Zhangm J., Wang, Y., et al. (2019) A Pigeon-Inspired Optimization Algorithm for Many-Objective Optimization Problems. Science China Information Sciences, 62, Article No. 70212. &lt;br&gt;https://doi.org/10.1007/s11432-018-9729-5</mixed-citation></ref></ref-list></back></article>