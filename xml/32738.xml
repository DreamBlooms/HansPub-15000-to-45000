<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">FIN</journal-id><journal-title-group><journal-title>Finance</journal-title></journal-title-group><issn pub-type="epub">2161-0967</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/FIN.2019.96065</article-id><article-id pub-id-type="publisher-id">FIN-32738</article-id><article-categories><subj-group subj-group-type="heading"><subject>FIN20190600000_35387928.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>经济与管理</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于集成学习的房租预测研究
  Research of Prediction on House Rent Based on Intergration Learning
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>马</surname><given-names>涛</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>刘</surname><given-names>宁宁</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib></contrib-group><aff id="aff1"><addr-line>对外经济贸易大学，北京</addr-line></aff><aff id="aff2"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>25</day><month>10</month><year>2019</year></pub-date><volume>09</volume><issue>06</issue><fpage>586</fpage><lpage>594</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   住房租赁市场的快速发展使得人们对房屋租赁信息的需求不断增加，对房屋租金关注持续变高。租房市场供给两端一直存在着信息不对称的问题，房租是由诸多方面因素共同决定的，而现有的基于单一算法的房租预测模型，其预测精度往往受模型性能好坏、噪声、以及过度拟合风险等因素影响。本文基于堆叠集成策略，融合Random Forest Regressor、Extra Trees Regressor、LightGBM三个基模型，建立了集成学习的房租预测模型。研究结果表明，本方法预测精度明显优于任一单一预测模型，提高了预测的准确性和稳定性，证实了该模型在房租预测上的有效性。 The rapid development of the housing rental market has led to an increasing demand for housing rental information. There is always a problem of information asymmetry at both ends of the rental market. The rent is determined by many factors together. Accuracy of a single prediction model is unstable and is often affected by factors such as model performance, noise, and over-fitting risk. This study aims to develop and evaluate models of rental market dynamics using stacking integra-tion strategy on data from the DC competition community. We use the three basic models of Ran-dom Force Regressor, Extra Trees Regressor and LightGBM and establish a rent prediction model for integrated learning. The experimental results show that the prediction accuracy of this method is obviously better than any single prediction model, which improves the accuracy and stability of the prediction, and confirms the validity of the model in rent prediction.
    
    
   
  
 
</p></abstract><kwd-group><kwd>集成学习，房租预测，随机森林，极端随机森林, Integrated Learning</kwd><kwd> Rent Forecast</kwd><kwd> Random Forest</kwd><kwd> Extra-Trees</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>基于集成学习的房租预测研究<sup> </sup></title><p>马涛，刘宁宁</p><p>对外经济贸易大学，北京</p><p><img src="//html.hanspub.org/file/4-1140449x1_hanspub.png" /></p><p>收稿日期：2019年10月8日；录用日期：2019年10月23日；发布日期：2019年10月30日</p><disp-formula id="hanspub.32738-formula73"><graphic xlink:href="//html.hanspub.org/file/4-1140449x5_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>住房租赁市场的快速发展使得人们对房屋租赁信息的需求不断增加，对房屋租金关注持续变高。租房市场供给两端一直存在着信息不对称的问题，房租是由诸多方面因素共同决定的，而现有的基于单一算法的房租预测模型，其预测精度往往受模型性能好坏、噪声、以及过度拟合风险等因素影响。本文基于堆叠集成策略，融合Random Forest Regressor、Extra Trees Regressor、LightGBM三个基模型，建立了集成学习的房租预测模型。研究结果表明，本方法预测精度明显优于任一单一预测模型，提高了预测的准确性和稳定性，证实了该模型在房租预测上的有效性。</p><p>关键词 :集成学习，房租预测，随机森林，极端随机森林</p><disp-formula id="hanspub.32738-formula74"><graphic xlink:href="//html.hanspub.org/file/4-1140449x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2019 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/4-1140449x7_hanspub.png" /> <img src="//html.hanspub.org/file/4-1140449x8_hanspub.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>据国家统计局数据，2018年我国房屋租赁市场规模已达2.5万亿元。随着住房市场发展进入快车道，预计2025年房屋租赁总收入将接近3万亿元，租赁人口达2.3亿。对于租房这个相对传统的行业来说，信息严重不对称一直存在。一方面，房东不了解租房的市场真实价格，只能忍痛空置高租金的房屋；另一方面，租客也找不到满足自己需求的高性价比房屋，这造成了租房资源的极大浪费 [<xref ref-type="bibr" rid="hanspub.32738-ref1">1</xref>] 。在当今大数据时代背景下，机器学习理论不断创新和发展，互联网、大数据、人工智能和实体经济融合更加深入，运用互联网技术和信息化手段去解决现实生活中的问题是完全可行的。</p><p>本文基于最新的机器学习算法，采用模型融合的集成策略，利用出租房屋的一些特征数据，对其租金进行预测，使房东和租客之间的供需匹配更为精确，降低租房的时间成本，有一定的学术意义和时间价值，同时也为解决房屋租赁市场的信息不对称问题提供了一种新的思路和方法。</p></sec><sec id="s4"><title>2. 相关研究</title><p>近年来，随着房屋租赁市场的蓬勃发展以及租房人口的迅速增长，住房租金的波动越来越受到人们的关注，而房租由装修情况、位置地段、户型格局、交通便利程度、市场供需等多方面因素综合决定。因此，如何进行合理有效的预测已成为房租研究领域的热点问题。</p><p>目前，学者们对于房租预测问题的研究多集中于租金影响因素、定价和工序等定性方面的研究。例如，郑文娟以“因素观”视角来研究我国城市住房价格与住房租金问题，采用全国35个大中城市的面板数据，实证研究了我国城市住房价格与住房租金各自的关键影响因素，以及住房价格与住房租金之间关系在短期上与长期上的具体表现 [<xref ref-type="bibr" rid="hanspub.32738-ref2">2</xref>] 。陈思翀和陈英楠基于资产定价的视角，通过将标准的动态戈登增长模型和传统的住房使用成本模型相结合，建立了一个关于住房市场租金收益率的动态住房使用成本模型，并将该模型应用于京沪广深四大城市的季度数据，使用方差分解方法来考察国内住房市场动态波动的影响因素及其相对重要性 [<xref ref-type="bibr" rid="hanspub.32738-ref3">3</xref>] 。相较于以实证分析为主的定性研究，利用机器学习模型，以大样本数据集作为驱动的对于房租预测的定量研究则相对较少。Jinze Li基于脱敏后的实际租赁市场的数据，利用月租标签的历史数据建立基于机器学习的LightGBM (Light Gradient Boosting)模型，并对房屋月租金进行了较为准确的预测，为城市租赁市场提供客观的度量 [<xref ref-type="bibr" rid="hanspub.32738-ref4">4</xref>] 。Y. Ma和Z. Zhang主要研究了共享仓库租金的定价模型，为了理解定价机制，作者从分类广告网站上收集构建了一个北京地区的仓库数据集，基于该数据集，应用机器学习技术将仓库价格与其相关特征关联，并对比了线性回归、回归树、随机森林和梯度增强四个模型，通过相关系数比较，发现随机森林模型表现最佳 [<xref ref-type="bibr" rid="hanspub.32738-ref5">5</xref>] 。</p><p>当前对于房租预测领域的定量研究相对较少，我们参考了一些住房价格和商品价格的预测研究。J.J. Wang和S.G. Hu设计一种基于memristors、具有反向传播算法的多变量回归模型。用该ANN模型训练和预测了美国波士顿城镇的房价，得到了较为精确的预测结果 [<xref ref-type="bibr" rid="hanspub.32738-ref6">6</xref>] 。Jingyi Mu将支持向量机(SVM)、最小二乘支持向量机(LSSVM)算法应用于房地产价值预测，对房屋价值进行预测。选择波士顿郊区房屋数据集样本，对住宅价值进行了预测。首先建立了几种机器学习方法的模型并分析数据，然后结合测试数据的相应特性来预测房屋价值 [<xref ref-type="bibr" rid="hanspub.32738-ref7">7</xref>] 。李春生、李霄野等人优化调整了BP神经网络的初始权值和阈值，分别对传统BP神经网络和改进后的GA-BP神经网络建立了房价预测模型。实验结果表明，经过遗产算法改进的BP神经网络较传统BP神经网络具有预测精度高、收敛速度快的优点，同时避免了陷入局部最优的缺陷 [<xref ref-type="bibr" rid="hanspub.32738-ref8">8</xref>] 。Kanwal Noor和Sadaqat Jan提出了一种基于监督机器学习技术的车辆价格预测系统。该研究使用线性回归作为预测方法，预测精度达98%。在多元线性回归中将车辆价格作为因变量，自变量包括车辆模型、制造城市、型号、颜色、里程、合金轮辋和动力转向等 [<xref ref-type="bibr" rid="hanspub.32738-ref9">9</xref>] 。</p><p>综上所述，借鉴学者们在房租、房价及商品价格预测领域的研究。我们发现相较于理论基础完善的定性研究，借助于机器学习工具进行的定量研究相对较少，且研究大多只采用单一模型，无法克服各模型固有的局限性，使得预测结果可能不够准确完备。在机器学习算法不断发展更新的背景下，相较于单个模型，结合多个模型算法的集成策略在房租预测领域的应用具备先天优势，将会进一步的提高模型的预测精度和稳定性。</p></sec><sec id="s5"><title>3. 研究思路和方法</title><sec id="s5_1"><title>3.1. 问题分析</title><p>房屋租金预测本质上是回归预测问题，本文采用模型融合的集成策略，在对原数据集进行数据清洗和特征工程的基础上，先对单个模型进行学习和选择，然后运用Stacking进行模型融合，并对测试集进行预测，结果评价指标为均方根误差(RMSE)。研究具体步骤见图1所示：</p><p>图1. 问题解决思路</p></sec><sec id="s5_2"><title>3.2. 模型比较</title><p>随机森林、极端随机森林、LightGBM是三种常用的价格回归预测模型。随机森林本质上一种Bagging算法，它以分类树为基本单元，通过二分数据进行分类或回归，相比与决策树，随机森林在不增加计算复杂度的前提下提高了预测精度。极端随机树(Extra-Trees)算法与随机森林算法十分相似，都是由决策树构成的。LightGBM是由微软亚洲软件开发院开源公布的一种快速的，分布式的，高性能的基于决策树算法的梯度提升框架。相比与XGBoost，LightGBM在不降低准确率的前提下，速度提升了10倍左右，占用内存下降了3倍左右，各模型优势比较见表1所示。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Model compariso</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >随机森林</th><th align="center" valign="middle" >在数据集上表现良好，不容易陷入过拟合；</th></tr></thead><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >具有良好的抗噪声能力；</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >能够处理高纬度的数据。对数据集的适应能力强。</td></tr><tr><td align="center" valign="middle" >极端随机森林</td><td align="center" valign="middle" >完全随机得到分叉值。从而实现对决策树进行分叉；</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >使用所有样本训练，在某种程度上效果优于随机森林。</td></tr><tr><td align="center" valign="middle" >LightGBM</td><td align="center" valign="middle" >训练效率快、可以处理大规模数据；</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >支持并行优化学习；</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >内存使用率较低。</td></tr></tbody></table></table-wrap><p>表1. 模型对比</p></sec><sec id="s5_3"><title>3.3. 集成学习策略</title><p>模型融合的基本思想就是通过对多个单模型融合以提升整体性能。常用的模型融合方法有Voting、Averging、Bagging、Boosting等。本文采用Stacking作为模型融合策略，具体流程如下图2所示。</p><p>Stacking是一种非线性的融合决策,是一种从原数据集中自动抽取有效特征的表示学习。一般来说Stacking就是训练一个多层的学习器结构，第一层称为学习层，用n个不同的分类器，将得到的预测结果合并为新的特征集，并作为下一层分类器的输入，通过第二层的输出训练器得到最终预测结果。为了防止过度拟合问题，Stacking在第一层模型训练时采用K折交叉检验的方式，第二层输出训练器一般选用逻辑回归模型。</p><p>图2. Stacking策略</p></sec></sec><sec id="s6"><title>4. 数据</title><p>本文数据集来自DC竞赛社区住房月租金预测大赛所提供的某地3个月的房屋租赁价格以及房屋的基本信息。该数据集共有196539条数据，19个特征变量，15个为数值型变量，4个为分类型变量。所有特征如下表2所示，房租：</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> Feature descriptio</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >字段名</th><th align="center" valign="middle" >说明</th><th align="center" valign="middle" >字段名</th><th align="center" valign="middle" >说明</th></tr></thead><tr><td align="center" valign="middle" >时间</td><td align="center" valign="middle" >房屋信息采集时间</td><td align="center" valign="middle" >小区名</td><td align="center" valign="middle" >房屋所在小区(脱敏)</td></tr><tr><td align="center" valign="middle" >小区房屋出租数量</td><td align="center" valign="middle" >小区房屋出租数量(脱敏，保留大小关系)</td><td align="center" valign="middle" >楼层</td><td align="center" valign="middle" >楼层高中低(脱敏)</td></tr><tr><td align="center" valign="middle" >总楼层</td><td align="center" valign="middle" >房屋所在建筑的总楼层数(脱敏)</td><td align="center" valign="middle" >房屋面积</td><td align="center" valign="middle" >房屋面积(脱敏)</td></tr><tr><td align="center" valign="middle" >房屋朝向</td><td align="center" valign="middle" >房屋朝向</td><td align="center" valign="middle" >居住状态</td><td align="center" valign="middle" >是否已经出租或居住中(脱敏)</td></tr><tr><td align="center" valign="middle" >卧室数量</td><td align="center" valign="middle" >卧室数量</td><td align="center" valign="middle" >客厅数量</td><td align="center" valign="middle" >客厅数量</td></tr><tr><td align="center" valign="middle" >卫的数量</td><td align="center" valign="middle" >卫的数量</td><td align="center" valign="middle" >租出方式</td><td align="center" valign="middle" >表示是否出租</td></tr><tr><td align="center" valign="middle" >区</td><td align="center" valign="middle" >房屋所在区级行政单位(脱敏)</td><td align="center" valign="middle" >位置</td><td align="center" valign="middle" >小区所在商圈(脱敏)</td></tr><tr><td align="center" valign="middle" >地铁线路</td><td align="center" valign="middle" >第几条线路(脱敏)</td><td align="center" valign="middle" >地铁站点</td><td align="center" valign="middle" >房屋临近站点(脱敏)</td></tr><tr><td align="center" valign="middle" >距离</td><td align="center" valign="middle" >房屋距地铁站距离(脱敏)</td><td align="center" valign="middle" >装修情况</td><td align="center" valign="middle" >房屋装修档次(脱敏)</td></tr></tbody></table></table-wrap><p>表2. 特征描述</p><sec id="s6_1"><title>4.1. 数据预处理</title><p>通过对原始数据集进行分析发现，数据不仅包括房屋面积、楼层、客厅数量等数值型数据，还包括租出方式、房屋朝向等非数值型数据；同时该数据集中也存在异常值、缺失值、以及不一致数据。为了使数据集符合建模要求，需要进行必要的数据清理和转换。</p><p>首先对缺失值进行统计分析，其中装修情况、居住状态、出租方式字段缺失率较高，考虑实际情况，以上三个特征都是分类变量，因此将其缺失值作为一种特征处理。对于地铁站点、距离、地铁线路三个特征的缺失值，用相同小区名的数据代替，若该小区所有房屋都缺失这三个字段，就将其作为特征处理，表示该房屋附近没有地铁。小区房屋出租数量字段用相同小区、邻近楼层和邻近时间的值进行填充。位置和区的缺失值用所有数据的中位数代替。接下来对异常值进行处理，经过统计分析发现房屋面积字段存在明显异常值，对于房屋面积超出0.146的数据进行删除。最后数据集中房屋朝向特征用中文表述，为了匹配模型对其进行数据转换，用数值型数据代替中文。</p></sec><sec id="s6_2"><title>4.2. 特征工程</title><p>接下来对清洗好的数据集进行特征处理。由图3可知房屋面积、卧室数量、厅的数量、卫的数量与月租金相关性较高，这也符合现实中的情况，如两室一厅和三室一厅的房屋在租金上是有很大差别的。因此在特征构造时，主要考虑以上特征之间的关系。在构造特征时，对卧室面积、卫生间面积和厅面积占整个房屋面积比例进行了量化处理，按照现实房屋中的一般占比确定系数，原数据集中楼层用0，1，2表示，对其进行归一化和量化处理，然后与总楼层相乘便可得到具体楼层。所有新构造特征如下表3所示：</p><p>图3. 特征相关性分析</p><table-wrap id="table3" ><label><xref ref-type="table" rid="table3">Table 3</xref></label><caption><title> Characteristic constructio</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >构造特征</th><th align="center" valign="middle" >描述</th></tr></thead><tr><td align="center" valign="middle" >卧室均面积</td><td align="center" valign="middle" >房屋面积 &#215; 0.3/卧室数量</td></tr><tr><td align="center" valign="middle" >卫的均面积</td><td align="center" valign="middle" >房屋面积 &#215; 0.07/卫的数量</td></tr><tr><td align="center" valign="middle" >卧室总面积</td><td align="center" valign="middle" >卧室均面积 &#215; 卧室数量</td></tr><tr><td align="center" valign="middle" >除卧室外剩余面积</td><td align="center" valign="middle" >房屋面积 − 卧室总面积</td></tr><tr><td align="center" valign="middle" >客厅均面积</td><td align="center" valign="middle" >房屋面积 &#215; 0.26/厅的数量</td></tr><tr><td align="center" valign="middle" >客厅总面积</td><td align="center" valign="middle" >客厅均面积 &#215; 客厅数量</td></tr><tr><td align="center" valign="middle" >卧室和厅</td><td align="center" valign="middle" >卧室数量 + 厅的数量</td></tr><tr><td align="center" valign="middle" >具体楼层</td><td align="center" valign="middle" >总楼层 &#215; 100 &#215; 楼层系数</td></tr></tbody></table></table-wrap><p>表3. 特征构造</p></sec></sec><sec id="s7"><title>5. 模型的建立</title><sec id="s7_1"><title>5.1. 单一模型训练</title><p>本文选用Stacking集成策略进行模型融合，为了构建初级学习器，需要选择若干个基模型。首先，将经过数据处理的数据集划分为训练集和测试集，其中训练集占80%，测试集占20%。在回归模型的选择上，本文初始考虑Lasso、Catbost、Random Forest Regressor、Extra Trees Regressor、Lightgbm等5个模型。为了鉴别模型的优劣，我们定义了均方根误差(RMSE)和模型拟合优度(SCORE)作为交叉验证的评估指标，经过初步筛选，本文选择了Random Forest Regressor、Extra Trees Regressor、Lightgbm三个模型，并利用Grid Search CV (网格搜索)对模型参数进行调整，以达到效果最优，调参后各模型得分和模型最优参数如下表4、表5、表6、表7所示。</p><table-wrap id="table4" ><label><xref ref-type="table" rid="table4">Table 4</xref></label><caption><title> RF Optimal parameter</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >参数名称</th><th align="center" valign="middle" >参数含义</th><th align="center" valign="middle" >取值</th></tr></thead><tr><td align="center" valign="middle" >max_features</td><td align="center" valign="middle" >单个决策树使用的最大特征数量</td><td align="center" valign="middle" >10</td></tr><tr><td align="center" valign="middle" >n_estimators</td><td align="center" valign="middle" >子树的数量</td><td align="center" valign="middle" >10</td></tr></tbody></table></table-wrap><p>表4. RF最优参数</p><table-wrap id="table5" ><label><xref ref-type="table" rid="table5">Table 5</xref></label><caption><title> ET Optimal parameter</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >参数名称</th><th align="center" valign="middle" >参数含义</th><th align="center" valign="middle" >取值</th></tr></thead><tr><td align="center" valign="middle" >max_features</td><td align="center" valign="middle" >单个决策树使用的最大特征数量</td><td align="center" valign="middle" >6</td></tr><tr><td align="center" valign="middle" >n_estimators</td><td align="center" valign="middle" >子树的数量</td><td align="center" valign="middle" >30</td></tr></tbody></table></table-wrap><p>表5. ET最优参数</p><table-wrap id="table6" ><label><xref ref-type="table" rid="table6">Table 6</xref></label><caption><title> Lgb Optimal parameter</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >参数名称</th><th align="center" valign="middle" >参数含义</th><th align="center" valign="middle" >取值</th></tr></thead><tr><td align="center" valign="middle" >num_leaves</td><td align="center" valign="middle" >数模型复杂度</td><td align="center" valign="middle" >900</td></tr><tr><td align="center" valign="middle" >learning_rate</td><td align="center" valign="middle" >学习率</td><td align="center" valign="middle" >0.1</td></tr><tr><td align="center" valign="middle" >n_estimators</td><td align="center" valign="middle" >子树的数量</td><td align="center" valign="middle" >3141</td></tr><tr><td align="center" valign="middle" >bagging_fraction</td><td align="center" valign="middle" >在不进行重采样的情况下随机选择部分数据</td><td align="center" valign="middle" >0.7</td></tr><tr><td align="center" valign="middle" >feature_fraction</td><td align="center" valign="middle" >随机选择部分特征</td><td align="center" valign="middle" >0.6</td></tr><tr><td align="center" valign="middle" >min_data_in_leaf</td><td align="center" valign="middle" >一个叶子上数据的最小数量</td><td align="center" valign="middle" >18</td></tr><tr><td align="center" valign="middle" >min_sum_hessian_in_leaf</td><td align="center" valign="middle" >一个叶子上的最小 hessian</td><td align="center" valign="middle" >0.001</td></tr></tbody></table></table-wrap><p>表6. Lgb最优参数</p><table-wrap id="table7" ><label><xref ref-type="table" rid="table7">Table 7</xref></label><caption><title> Scores of each mode</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >模型名称</th><th align="center" valign="middle" >mean</th><th align="center" valign="middle" >score</th></tr></thead><tr><td align="center" valign="middle" >RandomForestRegressor</td><td align="center" valign="middle" >1.48</td><td align="center" valign="middle" >0.94</td></tr><tr><td align="center" valign="middle" >ExtraTreesRegressor</td><td align="center" valign="middle" >1.36</td><td align="center" valign="middle" >0.95</td></tr><tr><td align="center" valign="middle" >Lightgbm</td><td align="center" valign="middle" >1.35</td><td align="center" valign="middle" >0.95</td></tr><tr><td align="center" valign="middle" >Catbost</td><td align="center" valign="middle" >1.40</td><td align="center" valign="middle" >0.88</td></tr></tbody></table></table-wrap><p>表7. 各模型得分</p></sec><sec id="s7_2"><title>5.2. 集成学习</title><p>上一节中已经选定了三个基模型作为初级学习器，在此基础上对模型进行Stacking集成。本文选择Lasso模型作为次级学习器，并采用5-折交叉检验的方法对基模型进行训练。这个训练过程主要分两层：将原始训练集分为5折，记为fold1~fold5，依次取其中的四折数据来训练模型一，对测试集进行预测，并对剩余的一折数据进行预测，预测值即作为基模型对一折数据生成的原特征，将五组原特征拼接起来，得到该模型对整个原始训练集生成的原特征，而对测试集的预测结果，取其五次预测的平均值。同样地，对其它基模型也采用相同方法生成元特征，从而构成用于第二层模型训练的完整原特征集。通过初级学习器的训练，得到了3份train数据和3份test数据，然后用Lasso模型进行进一步融合，得到最终预测值。</p><p>将单个模型和Stacking集成策略模型做损失函数对比，可以看出集成策略在RF、ET、LGB模型的基础上进一步的提高了预测精度，均方误差比最优子模型降低了1.5%左右，实验结果表明，基于集成学习的房租预测模型对于提高房租的预测效果是有效的，结果对比如下表8所示。</p><table-wrap id="table8" ><label><xref ref-type="table" rid="table8">Table 8</xref></label><caption><title> Mean square error and mean absolute error of each mode</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >模型名称</th><th align="center" valign="middle" >mean</th><th align="center" valign="middle" >MAE</th></tr></thead><tr><td align="center" valign="middle" >RandomForestRegressor</td><td align="center" valign="middle" >1.48</td><td align="center" valign="middle" >0.85</td></tr><tr><td align="center" valign="middle" >ExtraTreesRegressor</td><td align="center" valign="middle" >1.36</td><td align="center" valign="middle" >0.78</td></tr><tr><td align="center" valign="middle" >Lightgbm</td><td align="center" valign="middle" >1.35</td><td align="center" valign="middle" >0.79</td></tr><tr><td align="center" valign="middle" >StackingCVRegressor</td><td align="center" valign="middle" >1.33</td><td align="center" valign="middle" >0.79</td></tr></tbody></table></table-wrap><p>表8. 各模型均方误差和平均绝对误差</p></sec></sec><sec id="s8"><title>6. 总结与展望</title><p>本研究构建了一种基于Stacking集成策略的两层模型，使用DC竞赛社区住房月租金预测大赛提供的数据集。以筛选和调参之后的Random Forest Regressor、Extra Trees Regressor、Lightgbm模型为基模型，并选用Lasso作为次级学习器中的融合模型，运用训练集中的数据训练模型，并对测试集的月租金进行预测。实验结果表明Stacking集成模型结果要优于任一单个模型，其采用交叉验证的方法构造，稳健性强，并且融合多个模型判断结果，进行次级训练，预测精度高。</p><p>同时本研究也存在进一步探讨的空间。在数据集的选择上，可以参考一些住房租赁网站提供的数据，使用不同的数据集训练模型，以检验模型的泛化性。在特征的构造上，可以结合中国住房租赁市场的实际情况，构造更为合理、有效的特征。在模型的选择上，由于房屋租赁价格与位置、地段等因素相关，因此在基模型的选择上可以考虑加入深度学习网络，利用租房分布的地理位置地图进行模型训练，以提升基模型的多样性，进一步提高集成模型预测的精度。</p></sec><sec id="s9"><title>致谢</title><p>感谢我的导师刘宁宁老师，在整个论文写作过程中给予我的大力帮助。刘老师的悉心指导贯穿了论文写作的方方面面，在他的指导下我认识到了自己很多不足，并在这一过程中取得进步。</p></sec><sec id="s10"><title>基金项目</title><p>这项工作得到了国家青年科学基金资助(批准号：61806056)，北京市社会科学青年基金资助(批准号：17YYC015)，中央高校基本科研业务专项资金资助(批准号：CXTD10-05)。</p></sec><sec id="s11"><title>文章引用</title><p>马 涛,刘宁宁. 基于集成学习的房租预测研究Research of Prediction on House Rent Based on Intergration Learning[J]. 金融, 2019, 09(06): 586-594. https://doi.org/10.12677/FIN.2019.96065</p></sec><sec id="s12"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.32738-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">中国软件行业协会培训中心. 2018年全国大学生计算机技能应用大赛[EB/OL]. http://www.cnccac.com/, 2018-8-20.</mixed-citation></ref><ref id="hanspub.32738-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">郑文娟. 中国城市住房价格与住房租金的影响因素及相互关系研究[D]: [博士学位论文]. 浙江: 浙江大学, 2011.</mixed-citation></ref><ref id="hanspub.32738-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">陈思翀, 陈英楠. 中国住房市场波动的影响因素研究——基于租金收益率的方差分解[J]. 金融研究, 2019, 464(2): 140-157.</mixed-citation></ref><ref id="hanspub.32738-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Li, J.Z. (2018) Monthly Housing Rent Forecast Based on LightGBM (Light Gradient Boosting) Model. In-ternational Journal of Intelligent Information and Management Science, 7, 6.</mixed-citation></ref><ref id="hanspub.32738-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Ma, Y., Zhang, Z., Ihler, A. and Pan, B. (2018) Estimating Warehouse Rental Price Using Machine Learning Techniques. International Journal of Computers Com-munications &amp; Control, 13, 235-250  
&lt;br&gt;https://doi.org/10.15837/ijccc.2018.2.3034</mixed-citation></ref><ref id="hanspub.32738-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Wang, J.J., Hu, S.G., Zhan, X.T., et al. (2018) Predicting House Price with a Memristor-Based Artificial Neural Network. IEEE Access, 6, 6. &lt;br&gt;https://doi.org/10.1109/ACCESS.2018.2814065</mixed-citation></ref><ref id="hanspub.32738-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Mu, J., Wu, F. and Zhang, A. (2014) Housing Value Forecasting Based on Machine Learning Methods. Abstract and Applied Analysis, 2014, Article ID: 648047. &lt;br&gt;https://doi.org/10.1155/2014/648047</mixed-citation></ref><ref id="hanspub.32738-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">李春生, 李霄野, 张可佳. 基于遗传算法改进的BP神经网络房价预测分析[J]. 计算机技术与发展, 2018, 28(8): 144-147.</mixed-citation></ref><ref id="hanspub.32738-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Noor, K. and Jan, S. (2017) Vehicle Price Prediction System Using Machine Learning Techniques. International Journal of Computer Applications, 167, 27-31. &lt;br&gt;https://doi.org/10.5120/ijca2017914373</mixed-citation></ref></ref-list></back></article>