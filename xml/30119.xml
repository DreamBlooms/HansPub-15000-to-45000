<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2019.95094</article-id><article-id pub-id-type="publisher-id">CSA-30119</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20190500000_18014344.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  卷积神经网络在植被识别中的应用研究
  Application of Convolutional Neural Network in Vegetation Recognition
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>黎</surname><given-names>普涛</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>鞠</surname><given-names>训光</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>张</surname><given-names>德升</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>丁</surname><given-names>宾</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>王</surname><given-names>琢</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>徐州工程学院，江苏 徐州</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>08</day><month>05</month><year>2019</year></pub-date><volume>09</volume><issue>05</issue><fpage>841</fpage><lpage>848</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   大多数植物图片识别的方法，都是聚焦与植物图片的某一特征进行识别，例如叶径，叶长，花，果实，叶片。使用其植物某个器官进行识别，这样得出的结果并不可靠，因为实际自然界有非常多的植物有着极其相似的特征。本文通过选取整个植物图片作为训练样本，即提取植物的所有特征，基于卷积神经网络(Convolutional Neural Networks, CNN)中的AlexNet模型，利用GPU并行计算能力加快模型训练和图片识别速度。通过对潘安湖的5类植物数据集进行训练，训练得到正确精度为87.5%的模型，并且将此训练精度与最近邻(K-NearestNeighbor, KNN)和BP神经网络(Back Propagation, BP)两种分类算法训练得到的训练精度作比较，验证了模型的高可用性。以此模型为基础，应用Python开发了一款基于潘安湖湿地公园植物的植物APP识别软件。 Most plant image recognition methods focus on one feature of plant image, such as leaf diameter, leaf length, flower, fruit and leaf. Using one of its plant organs to identify, the result is not reliable, because there are many plants in nature with very similar characteristics. In this paper, the whole plant image is selected as training sample that is to extract all plant features. Based on AlexNet model of Convolutional Neural Networks (CNN), the parallel computing ability of GPU is used to speed up model training and image recognition. Through training the data sets of five kinds of plants in Pan’an Lake, the correct accuracy of the model is 87.5%. The training accuracy is com-pared with that of KNN nearest neighbor and BP neural network, which verifies the high availability of the model. Based on this model, a plant identification software named APP was developed by Python, which is based on the plant of Pan’an Lake Wetland Park. 
  
 
</p></abstract><kwd-group><kwd>深度学习，卷积神经网络，潘安湖湿地公园, Deep Learning</kwd><kwd> Convolutional Neural Network</kwd><kwd> Pan’an Lake Wetland Park</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>卷积神经网络在植被识别中的应用研究<sup> </sup></title><p>黎普涛，鞠训光<sup>*</sup>，张德升，丁宾，王琢</p><p>徐州工程学院，江苏 徐州</p><disp-formula id="hanspub.30119-formula45"><graphic xlink:href="//html.hanspub.org/file/2-1541377x5_hanspub.png"  xlink:type="simple"/></disp-formula><p>收稿日期：2019年4月24日；录用日期：2019年5月2日；发布日期：2019年5月9日</p><disp-formula id="hanspub.30119-formula46"><graphic xlink:href="//html.hanspub.org/file/2-1541377x6_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>大多数植物图片识别的方法，都是聚焦与植物图片的某一特征进行识别，例如叶径，叶长，花，果实，叶片。使用其植物某个器官进行识别，这样得出的结果并不可靠，因为实际自然界有非常多的植物有着极其相似的特征。本文通过选取整个植物图片作为训练样本，即提取植物的所有特征，基于卷积神经网络(Convolutional Neural Networks, CNN)中的AlexNet模型，利用GPU并行计算能力加快模型训练和图片识别速度。通过对潘安湖的5类植物数据集进行训练，训练得到正确精度为87.5%的模型，并且将此训练精度与最近邻(K-NearestNeighbor, KNN)和BP神经网络(Back Propagation, BP)两种分类算法训练得到的训练精度作比较，验证了模型的高可用性。以此模型为基础，应用Python开发了一款基于潘安湖湿地公园植物的植物APP识别软件。</p><p>关键词 :深度学习，卷积神经网络，潘安湖湿地公园</p><disp-formula id="hanspub.30119-formula47"><graphic xlink:href="//html.hanspub.org/file/2-1541377x7_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2019 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/2-1541377x8_hanspub.png" /> <img src="//html.hanspub.org/file/2-1541377x9_hanspub.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>植物是人类日常生活当中不可缺少的一部分。就刚需而言，它提供人类生活所必需的氧气、食物和药材，以及对空气的净化能力；而植物的观赏性和部分稀缺植物的珍贵则形成了人类对植物的弹需。无论是刚需或者是弹需，植物的作用不言而喻。如何普及人们对世界上已有植物的了解以及对现存海量植物的管理和保护，就是目前人们需要考虑的问题。潘安湖湿地公园地处于江苏徐州市，草本植物丰富。据调查，目前已发现植物97科227属353种 [<xref ref-type="bibr" rid="hanspub.30119-ref1">1</xref>] 。</p><p>在植物识别方面，前人也有一些实践。但是，多种植物识别，一般传统意义上的机器学习算法很难支持，并且在识别效率和速度上也很难满足要求。第一款植物识别app由Leafsnap小组 [<xref ref-type="bibr" rid="hanspub.30119-ref2">2</xref>] 研发成功，但其局限性很明显，只是满足其在植物的叶片上的识别。黄婕等 [<xref ref-type="bibr" rid="hanspub.30119-ref3">3</xref>] 提出了尺度不变特征变换(SIFF)的带预处理的算法，此算法针对展示在摄像头之下的植物叶片，可以进行植物叶片的自动分类，达到了识别53中植物叶片的效果。秦风 [<xref ref-type="bibr" rid="hanspub.30119-ref4">4</xref>] 等人提出了基于CNN和SVM算法的图像分析，测试集准确率达到87.48%。目前来说，这些植物识别准确率上差异明显，可识别的植物种类也少。</p><p>目前比较成熟的深度卷积网络模型有很多，最出名的包括AlexNet [<xref ref-type="bibr" rid="hanspub.30119-ref5">5</xref>] ，VGGNet [<xref ref-type="bibr" rid="hanspub.30119-ref6">6</xref>] ，GoogleNet [<xref ref-type="bibr" rid="hanspub.30119-ref7">7</xref>] ，ResNet [<xref ref-type="bibr" rid="hanspub.30119-ref8">8</xref>] ，这些网络模型在每年的IamgeNet图像分类竞赛中都有着出色的表现。并且在实际应用中，准确度、内存占用、参数、操作时间、操作次数、推理时间、功耗都体现出了优秀的成绩 [<xref ref-type="bibr" rid="hanspub.30119-ref9">9</xref>] 。本文采用深度学习中卷积神经网络(Convolutional Neural Networks)的AlexNet模型对潘安湖植物进行植物特征提取和分类建模，与KNN最近邻分类和BP神经网络两种分类算法进行实验结果对比，验证实验可行性。</p></sec><sec id="s4"><title>2. 相关理论</title><sec id="s4_1"><title>2.1. 卷积神经网络CNN</title><p>卷积神经网络(CNN)，是人工神经网络其中的一种。相较于全连接神经网络的输入层、输出层和隐藏层每一层的所有神经元与相邻的所有神经元全部连接相比，卷积神经网络的权重共享的网络结构，降低了模型的复杂度，减少了权值的数量。同时，卷积神经网络可以直接将图片作为输入对象，自动提取图片特征。卷积神经网络主要由卷积层、池化层和全连接层三个部分组成。</p><p>卷积层(Conv Layer)的输出张量(图像大小)计算公式：</p><p>Putsize = floor ( Insize + 2 * padding-pool_size ) / stride + 1 (1)</p><p>Putsize——卷积后的图片张量；Insize——输入张量大小；padding——填充数；pool_size——卷积核尺寸大小；stride——采样核移动步长。</p><p>池化层(MaxPool Layer)的输出张量(图像大小)计算公式：</p><disp-formula id="hanspub.30119-formula48"><label>(2)</label><graphic position="anchor" xlink:href="//html.hanspub.org/file/2-1541377x11_hanspub.png"  xlink:type="simple"/></disp-formula><p>Oousize——池化后的图片张量；Insize——输入张量大小；Csize——池化层尺寸；stride——采样核移动步长。</p><p>全连接层(Full Connected Layer)的输出张量(图像大小)：全连接层输出向量长度等于神经元的数量。</p></sec><sec id="s4_2"><title>2.2. AlexNet模型</title><p>总共有八层网络。前5层是卷积层(convolution)，后3层是全连接层(full-connected)。</p><p>Conv1为96个大小为11 &#215; 11 &#215; 3，步长为4个像素的的核对224 &#215; 224 &#215; 3的输入图像进行滤波；conv2为256个大小为5 &#215; 5 &#215; 48的核对第一个卷积层的输出进行滤波；conv3为384个大小为3 &#215; 3 &#215; 256的核连接到第二个卷积层的输出；conv4和conv5分别为384个大小为3 &#215; 3 &#215; 198的核及256个大小为3 &#215; 3 &#215; 192的核。每个全连接层各有4096个神经元。</p><p>其中最后的一个全连接层output是具有100个输出的Softmax。在第一层conv1和conv2后是morm1和norm2层，每一个conv层以及全连接层后紧跟的是激活函数(ReLu)。池化(Maxpooling)操作紧跟在norm1和norm2和conv5之后。随机失活(Dropout)操作在最后两个全连接层。AlexNet网络结构如图1。</p><p>图1.AlexNet网络结构</p></sec></sec><sec id="s5"><title>3. 基于CNN潘安湖植物识别流程</title><sec id="s5_1"><title>3.1. 实验对象</title><p>本文使用的植物图像数据集是在潘安湖湿地公园实地采集到植物图片，数据集所包含的植物种类和数量如表1所示。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Plant image data se</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >数据集</th><th align="center" valign="middle" >含有植物种类</th><th align="center" valign="middle" >植物图片数量</th></tr></thead><tr><td align="center" valign="middle" >潘安湖植物数据集</td><td align="center" valign="middle" >5</td><td align="center" valign="middle" >3670</td></tr></tbody></table></table-wrap><p>表1. 植物图像数据集</p><p>数据集训练测试采用二八分，即实验过程中随机选取每种类别的植物图片的前80%样本为训练数据集，剩下的20%样本则构成测试数据集。</p></sec><sec id="s5_2"><title>3.2. 实验环境</title><p>本系统采用的CPU显卡为GTX1050Ti，显存4GB。在Deepin 15.7版本环境下配置Tensorflow，opencv服务，构成以tensorflow为核心的GPU加速卷积神经网络框架。</p></sec><sec id="s5_3"><title>3.3. 实验步骤</title><p>1) 数据集处理：植物的五个类别每个类别约有680张图片，将每个类别对应图片按照二八百分比分成训练集和测试集。</p><p>2) 数据预处理：植物图片大小不一，所以通过python语言的图片处理代码将所有图片像素resize，使得每张图片的大小一样。实验采取三种不同输入的图片张量，分别为32 &#215; 32 &#215; 3，64 &#215; 64 &#215; 3，80 &#215; 80 &#215; 3。其中，图片通道数为3。</p><p>3) 确立网络流程，建立网络结构：本实验采用AlexNet网络结构，其中4个卷积层，三个全连接层。模型结构如图2。</p><p>图2. 模型结构</p><p>网络训练流程图如图3。</p><p>图3. 网络训练流程图</p><p>4) 定义损失函数、激励函数以及学习率和正则化</p><p>5) 模型尺寸分析：因为卷积层部分采用了全部补0，所以训练经过卷积层时长和宽不变，深度加深；而池化层全部没有补0，所以训练过程池化层长和宽均减少，深度不变。模型图片大参数变化过程如表2。</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> The change process of model picture parameter</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >Input_size</th><th align="center" valign="middle" >filter</th><th align="center" valign="middle" >kernel_size</th><th align="center" valign="middle" >Pading</th><th align="center" valign="middle" >Pool_size</th><th align="center" valign="middle" >strides</th><th align="center" valign="middle" >Output_size</th></tr></thead><tr><td align="center" valign="middle" >32 &#215; 32 &#215; 3</td><td align="center" valign="middle" >32 -&gt; 64 -&gt; 128 -&gt; 128</td><td align="center" valign="middle" >5 &#215; 5 -&gt; 5 &#215; 5 -&gt; 3 &#215; 3 -&gt; 3 &#215; 3</td><td align="center" valign="middle" >Same</td><td align="center" valign="middle" >3 &#215; 3</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >2 &#215; 2 &#215; 128</td></tr><tr><td align="center" valign="middle" >64 &#215; 64 &#215; 3</td><td align="center" valign="middle" >32 -&gt; 64 -&gt; 128 -&gt; 128</td><td align="center" valign="middle" >5 &#215; 5 -&gt; 5 &#215; 5 -&gt; 3 &#215; 3 -&gt; 3 &#215; 3</td><td align="center" valign="middle" >Same</td><td align="center" valign="middle" >3 &#215; 3</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >4 &#215; 4 &#215; 128</td></tr><tr><td align="center" valign="middle" >80 &#215; 80 &#215; 3</td><td align="center" valign="middle" >32 -&gt; 64 -&gt; 128 -&gt; 128</td><td align="center" valign="middle" >5 &#215; 5 -&gt; 5 &#215; 5 -&gt; 3 &#215; 3 -&gt; 3 &#215; 3</td><td align="center" valign="middle" >same</td><td align="center" valign="middle" >3 &#215; 3</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >5 &#215; 5 &#215; 128</td></tr></tbody></table></table-wrap><p>表2. 模型图片参数变化过程</p><p>图片尺寸具体变化过程如表3。</p><table-wrap id="table3" ><label><xref ref-type="table" rid="table3">Table 3</xref></label><caption><title> Specific Change Process of Picture Siz</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >输入大小</th><th align="center" valign="middle" >尺寸变化</th></tr></thead><tr><td align="center" valign="middle" >32 &#215; 32 &#215; 3</td><td align="center" valign="middle" >32 &#215; 32 &#215; 3 -&gt; 32 &#215; 32 &#215; 32 -&gt; 16 &#215; 16 &#215; 32 -&gt; 16 &#215; 16 &#215; 64 -&gt; 8 &#215; 8 &#215; 64 -&gt; 8 &#215; 8 &#215; 128 -&gt; 4 &#215; 4 &#215; 128 -&gt; 2 &#215; 2 &#215; 128</td></tr><tr><td align="center" valign="middle" >64 &#215; 64 &#215; 3</td><td align="center" valign="middle" >64 &#215; 64 &#215; 3 -&gt; 64 &#215; 64 &#215; 32 -&gt; 32 &#215; 32 &#215; 32 -&gt; 32 &#215; 32 &#215; 64 -&gt; 16 &#215; 16 &#215; 64 -&gt; 16 &#215; 16 &#215; 128 -&gt; 8 &#215; 8 &#215; 128 -&gt; 4 &#215; 4 &#215; 128</td></tr><tr><td align="center" valign="middle" >80 &#215; 80 &#215; 3</td><td align="center" valign="middle" >80 &#215; 80 &#215; 3 -&gt; 80 &#215; 80 &#215; 32 -&gt; 40 &#215; 40 &#215; 32 -&gt; 40 &#215; 40 &#215; 64 -&gt; 20 &#215; 20 &#215; 64 -&gt; 20 &#215; 20 &#215; 128 -&gt; 10 &#215; 10 &#215; 128 -&gt; 5 &#215; 5 &#215; 128</td></tr></tbody></table></table-wrap><p>表3. 图片尺寸具体变化过程</p><p>6) 存储模型并调用</p><p>在得到训练模型之后，将测试集的图片用于模型测试，检验模型可用性。测试流程如图4。</p><p>图4. 测试流程</p></sec></sec><sec id="s6"><title>4. 实验结果及分析</title><sec id="s6_1"><title>4.1. 实验过程模拟</title><p>可视化工具TensorBoard可以将TensorFlow程序运行过程中输出的日志文件可视化，其中训练模型张量变化过程如图5所示。</p><p>图5. 基于tensorboard训练模型</p></sec><sec id="s6_2"><title>4.2. 各输入图片张量对比</title><p>其中横坐标为训练集(测试集)图片数量/每次迭代输入的图片数量，一共迭代50次；纵坐标为正确率。三种不同像素输入张量所得到训练与测试的拟合程度如图6所示。</p><p>图6. 像素拟合程度汇总</p></sec><sec id="s6_3"><title>4.3. 训练模型测试</title><p>数据集：训练数据总共有五类植物，其中雏菊(daisy)有633张图片，蒲公英(dandelion)有898张图片，红玫瑰(rose)有641张图片，向日葵(sunflower)有699张图片，郁金香(tulip)有799张图片。分别收集每类植物图片100张，用于模型正确率实测，测试结果如表4。</p><table-wrap id="table4" ><label><xref ref-type="table" rid="table4">Table 4</xref></label><caption><title> Measurement of model correctness rat</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >Classification</th><th align="center" valign="middle" >Daisy</th><th align="center" valign="middle" >Dandelion</th><th align="center" valign="middle" >Rose</th><th align="center" valign="middle" >Sunflower</th><th align="center" valign="middle" >Tulip</th></tr></thead><tr><td align="center" valign="middle" >Accuracy</td><td align="center" valign="middle" >88%</td><td align="center" valign="middle" >89%</td><td align="center" valign="middle" >95%</td><td align="center" valign="middle" >85%</td><td align="center" valign="middle" >78%</td></tr></tbody></table></table-wrap><p>表4. 模型正确率实测</p><p>为了进一步验证本文采用的AlexNet模型识别的识别率，分别用BP神经网络 [<xref ref-type="bibr" rid="hanspub.30119-ref10">10</xref>] 和KNN最近邻分类 [<xref ref-type="bibr" rid="hanspub.30119-ref11">11</xref>] 这两种分类算法进行对比。验证方法与上面五类植物图片正确率验证一致，均用分类的方法分别对五种植物识别，得到综合识别率。对于识别速率的评价，使用了K交叉验证。该结果表明，本文采用的模型以及识别方法具有更高的识别率，其实验对比如表5所示。</p><table-wrap id="table5" ><label><xref ref-type="table" rid="table5">Table 5</xref></label><caption><title> Comparison of custom experiments with different classifier</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >分类算法</th><th align="center" valign="middle" >识别率</th></tr></thead><tr><td align="center" valign="middle" >KNN最近邻</td><td align="center" valign="middle" >0.8409</td></tr><tr><td align="center" valign="middle" >BP神经网络</td><td align="center" valign="middle" >0.8581</td></tr><tr><td align="center" valign="middle" >CNN</td><td align="center" valign="middle" >0.8748</td></tr></tbody></table></table-wrap><p>表5. 不同分类器的自定义实验对比</p></sec><sec id="s6_4"><title>4.4. 软件开发测试</title><p>通过将模型植入到Android项目中，开发app。app识别潘安湖图片效果如图7所示。</p><p>图7. 植物识别APP软件</p></sec><sec id="s6_5"><title>4.5. 实验分析</title><p>此实验采用。由图5由图6可知，当输入张量为32 &#215; 32和64 &#215; 64时，训练集得到训练正确率和测试集得到的测试正确率呈稳步上升的趋势，两者在约各自迭代图片数据到三分之二时，正确率几乎重合，随着迭代的进行，正确率被拉开，最终各自稳定在99%和63%左右。图7输入张量为80 &#215; 80时，训练所得到的正确率不可思议的达到了100%，而测试正确率仅为65%，显然训练过拟合造成了训练的正确率稳定在了1。同时，训练正确率和测试正确率的曲线重合率也反映出了收敛的过程。而最好的结果应该是训练正确率和测试正确率数据越接近，得到正确率越高。通过对三种不同的输入张量训练所得到的正确率进行对比，当图片张量为64 &#215; 64时，所得到的训练、测试正确率数据最接近，且上升趋势稳定，因此，64 &#215; 64像素处理应该是此实验最佳的方案，得到了87%的识别正确率。同时，在与KNN最近邻和BP神经网络两种分类算法分别对数据集图片进行实验比较，可知，在采用64 &#215; 64像素处理的情况下，植物图片的识别率在三种图片分类算法上，卷积神经网络算法在植物图像识别上，有着更加优秀的表现。</p></sec></sec><sec id="s7"><title>5. 结论</title><p>本文在介绍了卷积神经网络之后，化理论为实操。通过实验，基于卷积神经网络将潘安湖湿地公园的部分植物用于实验数据，在通过不同参数的反复调整与训练，得到的识别模型的正确率基本稳定，最后将识别模型用于app中。本文目前只是采集了五种不同植物，并且图片数量有限，后期得到了更多的样本，再调整下网络结构，得到的正确率将会大大提高。</p></sec><sec id="s8"><title>基金项目</title><p>徐州市科技计划项目(KC16SS094)、徐州市科技计划项目(KC17078)。</p></sec><sec id="s9"><title>文章引用</title><p>黎普涛,鞠训光,张德升,丁 宾,王 琢. 卷积神经网络在植被识别中的应用研究Application of Convolutional Neural Network in Vegetation Recognition[J]. 计算机科学与应用, 2019, 09(05): 841-848. https://doi.org/10.12677/CSA.2019.95094</p></sec><sec id="s10"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.30119-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">杨瑞卿, 王千千, 徐德兰. 徐州潘安湖湿地公园植物多样性调查与分析[J]. 西北林学院学报, 2018, 33(3): 285-289.</mixed-citation></ref><ref id="hanspub.30119-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">尤肖虎, 潘志文, 高西奇, 等. 5G移动通信发展趋势与若干关键技术[J]. 中国科学: 信息科学, 2014, 44(5): 551-563</mixed-citation></ref><ref id="hanspub.30119-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">黄婕, 李浩锐, 黄皓琪, 胡小珍, 刘馨欣, 高凤连, 叶志鹏. 基于尺度不变特征变换算法的植物自动识别系统[J].计算机应用, 2016, 36(z2): 203-205.</mixed-citation></ref><ref id="hanspub.30119-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">秦丰, 刘东霞, 孙炳达, 阮柳, 马占鸿, 王海光. 基于深度学习和支持向量机的4种苜蓿叶部病害图像识别[J]. 中国农业大学学报, 2017, 22(7): 123-133.</mixed-citation></ref><ref id="hanspub.30119-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Krizhevsky, A., Sutskever, I. and Hinton, G. (2012) ImageNet Classification with Deep Convolutional Neural Networks. Advances in Neural Information Processing Systems, 25.</mixed-citation></ref><ref id="hanspub.30119-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Simonyan, K. and Zisserman, A. (2014) Very Deep Convolutional Networks for Large-Scale Image Recognition. Computer Science, arXiv: 1409.1556.</mixed-citation></ref><ref id="hanspub.30119-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Szegedy, C., Liu, N.-W., Jia, N.-Y., et al. (2015) Going Deeper with Convolutions. 2015 IEEE Con-ference on Computer Vision and Pattern Recognition (CVPR). Boston, MA, 2015, 1-9. &lt;br&gt;https://doi.org/10.1109/CVPR.2015.7298594</mixed-citation></ref><ref id="hanspub.30119-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Targ, S., Almeida, D. and Lyman, K. (2016) Resnet in Resnet: Generalizing Residual Architectures. Computer Science, arXiv: 1603.08029.</mixed-citation></ref><ref id="hanspub.30119-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Canziani, A., Paszke, A. and Culur-ciello, E. (2016) An Analysis of Deep Neural Network Models for Practical Applications. Computer Science, arXiv: 1605.07678.</mixed-citation></ref><ref id="hanspub.30119-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">黄杰贤, 刘燕, 杨冬涛. 基于BP神经网络的柚子分类研究[J]. 湖北农业科学, 2018, 57(24): 112-115.</mixed-citation></ref><ref id="hanspub.30119-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">刘应东, 牛惠民. 基于k-最近邻图的小样本KNN分类算法[J]. 计算机工程, 2011, 37(9): 198-200.</mixed-citation></ref></ref-list></back></article>