<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2021.117200</article-id><article-id pub-id-type="publisher-id">CSA-44148</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20210700000_12670330.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  生成对抗网络在医学图像计算上的进展与展望
  Review and Prospects for Generative Adversarial Networks on Medical Image Computation
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>游</surname><given-names>森榕</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>胡</surname><given-names>圣烨</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>申</surname><given-names>妍燕</given-names></name><xref ref-type="aff" rid="aff4"><sup>4</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>王</surname><given-names>书强</given-names></name><xref ref-type="aff" rid="aff4"><sup>4</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff4"><addr-line>中国科学院深圳先进技术研究院，广东 深圳</addr-line></aff><aff id="aff3"><addr-line>中国科学院深圳先进技术研究院，广东 深圳;中国科学院大学，北京</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><aff id="aff2"><addr-line>中国科学院深圳先进技术研究院，广东 深圳；中国科学院大学，北京</addr-line></aff><pub-date pub-type="epub"><day>08</day><month>07</month><year>2021</year></pub-date><volume>11</volume><issue>07</issue><fpage>1949</fpage><lpage>1961</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   生成对抗网络中生成器和判别器进行博弈的对抗训练方法在计算机视觉任务中引起了大量关注。生成器的参数更新不是直接来自真实数据样本，而是依据判别器的真伪和类别判别，从而具有生成媲美真实图像的能力。此外，生成对抗网络的对抗训练方式具有半监督/无监督训练特性，非常适合应用于医学图像计算领域，用以解决医学图像数据量少、质量低的缺陷。本文从不同角度对基于生成对抗网络的医学图像计算(医学图像合成、超分辨率重建和辅助诊断)的研究进展进行了回顾，并从模型设计、性能表现等方面对相关工作进行了概述和分析。最后，对生成对抗网络在该领域面临的挑战及潜在应用进行了展望。 In generator adversarial networks (GANs), the adversarial training mechanism between the generator and discriminator has attracted lots of attention in computer vision community. The update of the parameters in generator depends on the decision of the discriminator rather than the ground truth images, so the generator is able to synthesize more plausible images. In addition, the adversarial training mechanism makes GANs suitable for the semi-supervised/unsupervised training. This characteristic has been proven useful to address the problem that the medical images are limited and the quality is poor in the field of medical image computation. This paper reviews the researches of medical image computation (medical image synthesis, super-resolution and computer aided diagnosis) based on generative adversarial networks from different perspectives, and analyzes the related works from the aspects of model architecture and performance. Finally, the challenges and potential applications of generative adversarial networks in this field are presented. 
  
 
</p></abstract><kwd-group><kwd>生成对抗网络，医学图像计算，深度学习, Generative Adversarial Networks</kwd><kwd> Medical Image Computation</kwd><kwd> Deep Learning</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>摘要</title><p>生成对抗网络中生成器和判别器进行博弈的对抗训练方法在计算机视觉任务中引起了大量关注。生成器的参数更新不是直接来自真实数据样本，而是依据判别器的真伪和类别判别，从而具有生成媲美真实图像的能力。此外，生成对抗网络的对抗训练方式具有半监督/无监督训练特性，非常适合应用于医学图像计算领域，用以解决医学图像数据量少、质量低的缺陷。本文从不同角度对基于生成对抗网络的医学图像计算(医学图像合成、超分辨率重建和辅助诊断)的研究进展进行了回顾，并从模型设计、性能表现等方面对相关工作进行了概述和分析。最后，对生成对抗网络在该领域面临的挑战及潜在应用进行了展望。</p></sec><sec id="s2"><title>关键词</title><p>生成对抗网络，医学图像计算，深度学习</p></sec><sec id="s3"><title>Review and Prospects for Generative Adversarial Networks on Medical Image Computation<sup> </sup></title><p>Senrong You<sup>1,2</sup>, Shenye Hu<sup>1,2</sup>, Yanyan Shen<sup>1</sup>, Shuqiang Wang<sup>1*</sup></p><p><sup>1</sup>Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen Guangdong</p><p><sup>2</sup>University of Chinese Academy of Sciences, Beijing</p><p><img src="//html.hanspub.org/file/12-1542240x5_hanspub.png?20210727085450214" /></p><p>Received: Jun. 20<sup>th</sup>, 2021; accepted: Jul. 16<sup>th</sup>, 2021; published: Jul. 26<sup>th</sup>, 2021</p><p><img src="//html.hanspub.org/file/12-1542240x6_hanspub.png?20210727085450214" /></p></sec><sec id="s4"><title>ABSTRACT</title><p>In generator adversarial networks (GANs), the adversarial training mechanism between the generator and discriminator has attracted lots of attention in computer vision community. The update of the parameters in generator depends on the decision of the discriminator rather than the ground truth images, so the generator is able to synthesize more plausible images. In addition, the adversarial training mechanism makes GANs suitable for the semi-supervised/unsupervised training. This characteristic has been proven useful to address the problem that the medical images are limited and the quality is poor in the field of medical image computation. This paper reviews the researches of medical image computation (medical image synthesis, super-resolution and computer aided diagnosis) based on generative adversarial networks from different perspectives, and analyzes the related works from the aspects of model architecture and performance. Finally, the challenges and potential applications of generative adversarial networks in this field are presented.</p><p>Keywords:Generative Adversarial Networks, Medical Image Computation, Deep Learning</p><disp-formula id="hanspub.44148-formula5"><graphic xlink:href="//html.hanspub.org/file/12-1542240x7_hanspub.png?20210727085450214"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2021 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/12-1542240x8_hanspub.png?20210727085450214" /> <img src="//html.hanspub.org/file/12-1542240x9_hanspub.png?20210727085450214" /></p></sec><sec id="s5"><title>1. 引言</title><p>医学图像可以提供人体内部相关信息的视觉展示，从而被广泛应用于疾病诊断、治疗方案规划、术中导航、术后检测等多个医疗环节之中。它具有多种成像模态，比如计算机断层扫描(computed tomography, CT)、磁共振成像(magnetic resonance imaging, MRI)、正电子发射断层扫描(positron emission computed tomography, PET)等。各种模态的医学图像提供了关于人体内部不同的结构和功能信息，极大地推动了医学学科的进步和提升了疾病诊断的水平。但与自然图像相比，医学图像的数据量更少、要求的分辨率更高、获取成本也更加昂贵，这促使医学图像计算(如合成、超分辨率和辅助诊断等)工作吸引了国内外众多研究者的关注，并逐渐成为了当下的研究热点之一。尽管在过去已有许多工作对该领域进行了探索，然而，基于配准的方法 [<xref ref-type="bibr" rid="hanspub.44148-ref1">1</xref>] 高度依赖配准精度，并且它们的表征能力非常有限；而传统的机器学习方法 [<xref ref-type="bibr" rid="hanspub.44148-ref2">2</xref>] 需要医学专家手工制作图像特征，并且这些特征是专属于某一具体应用的，无法通用。这些缺陷大大限制了相关模型在该领域的应用，所获得的合成或超分辨率图像质量也不尽如人意。深度学习和卷积神经网络(convolutional neural network, CNN) [<xref ref-type="bibr" rid="hanspub.44148-ref3">3</xref>] 的兴起为图像计算工作带来了全新思路，它能从数据分布中自动地学习最佳特征 [<xref ref-type="bibr" rid="hanspub.44148-ref4">4</xref>]，因而非医学专业的研究者也能有效地利用深度模型开展医学图像合成和超分辨率研究工作。尽管研究者们利用CNN取得了一系列突破 [<xref ref-type="bibr" rid="hanspub.44148-ref5">5</xref>]，但其往往存在“平均效应”，所获取的输出图像往往较模糊。具有对抗训练机制、可以完美学习到训练样本分布的生成对抗网络的出现，进一步掀起了医学图像计算中医学图像合成、超分辨率和辅助诊断领域的研究热潮。</p></sec><sec id="s6"><title>2. 生成对抗网络简介</title><p>生成对抗网络(generative adversarial networks, GAN)由Goodfellow等人 [<xref ref-type="bibr" rid="hanspub.44148-ref6">6</xref>] 受到博弈论的启发，于2014年提出。它的本质是一种生成模型，旨在学习一个从简单潜在分布到真实数据分布的非线性映射，而无需显式地建模复杂且难以表达的概率密度函数。GAN由两个神经网络组成：生成器G与判别器D，其中G和D互相博弈，相比于基于变分方法 [<xref ref-type="bibr" rid="hanspub.44148-ref7">7</xref>] [<xref ref-type="bibr" rid="hanspub.44148-ref8">8</xref>] [<xref ref-type="bibr" rid="hanspub.44148-ref9">9</xref>] 的变分自编码器(variational auto-encoder, VAE) [<xref ref-type="bibr" rid="hanspub.44148-ref10">10</xref>]，GAN能更好地生成高频细节。生成器和判别器可根据实际需要，灵活地选用各种深度网络结构，并在相应的参数空间中进行更新。生成器的输入一般是从先验分布中采样的潜层向量，这里的先验分布通常会选择高斯分布或均匀分布。潜层向量经过生成器的非线性映射，得到生成样本，生成器的目标就是使生成样本与真实样本相似。判别器的输入则是真实样本或是生成样本，其输出是一个0到1之间的概率值。它的目标是通过将较高(1)和较低的概率值(0)分别分配给真实样本和生成样本，来尽可能正确地区分二者。图1展示了一个生成对抗网络的基本结构。</p><p>图1. 基本的生成对抗网络框架</p><p>生成对抗网络最独特的地方在于它的对抗训练机制。它的训练优化过程可以被概括为一个极小–极大博弈过程，生成器期望生成样本能够“骗过”判别器，即期望当生成样本作为判别器输入时，判别器的输出概率值为1；而判别器则期望完全区分开生成样本与真实样本，对真实样本输入时输出值为1，对生成样本输入时输出值为0。整个训练过程实际上就是生成器与判别器的零和博弈，二者在互相对抗的情况下不断迭代优化，最终达到纳什均衡。具体来说，在训练过程中生成器根据判别器的梯度信息不断更新其网络权重，保持生成的样本沿真实数据流形方向移动，使生成样本与真实样本愈发接近。随着训练次数的增加，判别器会愈发难以分辨出输入的真实样本和生成样本。当经过充分训练后，判别器对于任意输入样本输出的概率值都是0.5，代表整个网络达到纳什均衡，此时可以认为生成器已经学会了如何生成真实数据分布。在实际训练的过程中，一般采用交替优化的训练方法：首先固定生成器G的参数，更新判别器D的参数，使得D的判别准确率最大化；随后再固定判别器D的参数，更新生成器G的参数，使得D的判别准确率最小化 [<xref ref-type="bibr" rid="hanspub.44148-ref11">11</xref>]。</p><p>在GAN中，一般用x代表从真实数据分布p<sub>data</sub>抽取的真实样本，用z代表从先验噪声分布p<sub>z</sub>中采样得到的潜层向量，用p<sub>g</sub>代表生成器的生成数据分布。潜层向量z作为输入传递给生成器G，然后G生成图像 G ( z ) ，对抗训练的目的是使判别器D无法区分生成样本和真实样本，相当于使p<sub>g</sub>与p<sub>data</sub>尽可能靠近。此外，D同时尝试避免自己被G欺骗。生成对抗网络的损失函数可以由公式(1)表示：</p><p>min G max D V ( G , D ) = E x ~ p d a t a [ log D ( x ) ] + E z ~ p z [ log ( 1 − D ( G ( z ) ) ) ]</p><p>其中 V ( G , D ) 代表二分类交叉熵损失函数。</p><p>近年来，生成对抗网络已经成为了最流行的深度生成模型，在图像生成 [<xref ref-type="bibr" rid="hanspub.44148-ref12">12</xref>]、视频生成 [<xref ref-type="bibr" rid="hanspub.44148-ref13">13</xref>]、域自适应 [<xref ref-type="bibr" rid="hanspub.44148-ref14">14</xref>]、自然语言处理 [<xref ref-type="bibr" rid="hanspub.44148-ref15">15</xref>]、强化学习 [<xref ref-type="bibr" rid="hanspub.44148-ref16">16</xref>] 等方面有广泛的应用。各种基于GAN的改进模型也不断涌现，比如著名的深度卷积生成对抗网络(deep convolutional generative adversarial networks, DCGAN) [<xref ref-type="bibr" rid="hanspub.44148-ref17">17</xref>]、训练更加稳定的Wasserstein GAN [<xref ref-type="bibr" rid="hanspub.44148-ref18">18</xref>]、分别用于配对图像合成和非配对图像合成的Pix2Pix GAN [<xref ref-type="bibr" rid="hanspub.44148-ref19">19</xref>] 和CycleGAN [<xref ref-type="bibr" rid="hanspub.44148-ref20">20</xref>]，以及可以合成逼真的高分辨率图像的渐进式生成对抗网络 [<xref ref-type="bibr" rid="hanspub.44148-ref12">12</xref>]。但它们的原始应用场景多为自然图像，相比于数据量丰富、分辨率较高的自然图像而言，由于成像成本、隐私保护、硬件设施限制等，医学图像往往数据量有限、分辨率较低。生成对抗网络在图像合成、超分辨率和辅助诊断上的巨大潜力，为解决这一在医学图像分析中最大的挑战提供了崭新的思路和方法。</p></sec><sec id="s7"><title>3. 基于生成对抗网络的医学图像计算研究进展</title><sec id="s7_1"><title>3.1. 从潜层向量中合成医学图像</title><p>从潜层向量中合成医学图像又称医学图像的无条件合成，潜层向量一般从高斯分布或是均匀分布中采样而来，为了确保合成图像可以用于后续的医学图像分析任务，研究者们通常会对合成每一种模态图像都单独训练一个生成器。Frid-Adar [<xref ref-type="bibr" rid="hanspub.44148-ref21">21</xref>] 等使用三个DCGAN分别生成了三类肝损伤(囊肿，转移酶和血管瘤)的CT图像。由于训练数据集样本有限，该研究使用了增强数据来训练生成对抗网络。在肝脏病变分类的实验中，该研究发现当合成样本与真实的训练数据结合使用时，分类结果的敏感性和特异性得到了同时提高，证明生成图像可用于病变数据增强，以改善疾病分类任务的性能。</p><p>Bermudez等 [<xref ref-type="bibr" rid="hanspub.44148-ref22">22</xref>] 使用生成对抗网络来研究正常大脑的隐性流形，并生成新的高质量磁共振(magnetic resonance, MR)图像。为了验证生成图像的质量，作者先将生成图像与训练集进行互相关验证，证明合成图像并非是真实图像经过简单的图像处理手段得来的。其次，由两名神经放射科的医生评估真实图像和生成图像，生成图像的质量得分与真实图像的质量得分基本重叠。这项工作进一步证明了生成对抗网络合成逼真的医学图像数据的能力。</p><p>恶性及良性肺结节的区分在临床诊断上仍是一个较困难的挑战，放射科医生往往需要借助计算机辅助诊断系统来寻找与恶性和良性结节相对应的鉴别成像特征。为了进一步学习在肺结节上最有区别的特征，Chuquicusma等 [<xref ref-type="bibr" rid="hanspub.44148-ref23">23</xref>] 利用DCGAN来逼真地生成肺结节样本。在对两名放射科医生进行的视觉图灵测试中，医生也很难将合成的肺癌结节图像与真实图像区分开，从而验证了所生成图像的质量。该研究随后还提出了合成图像的三种用途：1) 通过挖掘具有高度区分性的成像特征来改善疾病的诊断决策；2) 培训放射科医生；以及3) 作为数据增强方法以训练需要大量数据的深度网络。</p><p>与许多利用机器学习进行医学图像分析的任务一样，皮肤图像分析长期遭受缺乏标签数据和数据类不均衡的困扰，并且对皮肤病变分割或分类的模型更依赖于高分辨率的图像数据。Baur等人 [<xref ref-type="bibr" rid="hanspub.44148-ref24">24</xref>] 成功地利用渐进式生成对抗网络从潜层向量中合成了具有高分辨率的逼真皮肤病变图像。定性和定量的实验表明这种渐进式结构相比常用的DCGAN等结构在合成高分辨率医学图像上的优势，并且即使是专业的皮肤科医生也很难将合成图像与真实的皮肤病变图像区分开。</p><p>由于生成对抗网络存在模式崩溃、训练不稳定的困难，以往的工作局限于二维切片的生成，很少尝试从潜层向量中直接合成三维医学图像。Kwon等 [<xref ref-type="bibr" rid="hanspub.44148-ref25">25</xref>] 提出了一个三维生成对抗网络模型，该模型成功地从潜层向量中产生了全新的三维脑部MR图像。该研究将α-GAN [<xref ref-type="bibr" rid="hanspub.44148-ref26">26</xref>] 的结构应用于三维医学图像生成，通过在现有的生成器和判别器之上引入附加的自动编码器和编码判别器网络来解决模式崩溃和生成图像模糊的问题。还利用带梯度惩罚的Wasserstein GAN [<xref ref-type="bibr" rid="hanspub.44148-ref18">18</xref>] 损失函数来防止训练不稳定。为了证明模型的通用性，该研究分别在脑肿瘤和脑卒中的数据集上训练了多个模型，并证明了提出模型可以生成多类型(如正常或病变)和多模态(如T1、T2或FLAIR)的逼真三维脑部MR图像。由于该模型仅需要少量的训练数据，因此有望广泛应用于医学图像分析任务，特别是对罕见疾病的诊断任务。</p><p>考虑到大多数现有合成方法仅考虑全局上下文信息，而忽略了前景的结构细节，例如血管，骨骼等，在这些细节中可能包含了病变标志物。为此，Zhang等 [<xref ref-type="bibr" rid="hanspub.44148-ref27">27</xref>] 提出了一种带有Sketching-Rendering架构的无条件生成对抗网络，以引入先验约束来指导医学图像的生成。在该研究提出的模型中，Sketching模块用于从随机噪声中生成高质量的结构草图，然后Rendering模块提出一种颜色渲染映射应用到生成的结构草图中，类似于添加背景外观。实验结果表明，所提出的模型在合成各种不同模态的医学图像上都达到了最好的结果，包括视网膜眼底图像，X光图像，CT图像和MR图像。此外，该研究还表明，通过将合成图像用作医学图像分割上的数据增强，可以使分割性能得到改善。</p></sec><sec id="s7_2"><title>3.2. 跨模态合成医学图像</title><p>医学图像在各种临床应用中起着至关重要的作用。然而，由于多种考虑，例如成本和辐射剂量，某些模态图像的获取可能受到限制。跨模态医学图像合成是一种通过已有模态数据合成所需模态数据的方法，由于它不需要实际成本就能获取所需模态图像，引起了人们的广泛关注 [<xref ref-type="bibr" rid="hanspub.44148-ref28">28</xref>] [<xref ref-type="bibr" rid="hanspub.44148-ref29">29</xref>] [<xref ref-type="bibr" rid="hanspub.44148-ref30">30</xref>]。Nie等 [<xref ref-type="bibr" rid="hanspub.44148-ref31">31</xref>] 提出了生成器为全卷积网络(fully convolutional network, FCN)的生成对抗网络架构，实现了从MR图像生成CT图像和从3T-MR图像生成7T-MR图像两种任务。具体来说，该研究先训练了一个FCN以在给定源域图像的情况下生成目标域图像，并使用对抗训练策略来更好地建模从源域到目标域的非线性映射并生成更逼真的目标图像。该研究将基于图像梯度差的损失函数融入网络训练中，可以避免生成模糊的目标图像；并进一步应用了自动上下文模型细化生成结果。在三个不同的数据集上的实验结果表明，该研究提出的方法是准确而可靠的，可以从源域图像中准确合成相应的目标域图像。</p><p>对于多发性硬化症而言，PET是一种可靠的生物标记物，可用于测量多发性硬化症患者体内髓磷脂含量的变化。然而，PET成像昂贵且具有侵入性。尽管MR是一种非侵入性的且成本更低的技术，但迄今为止，现有的MR图像尚不能提供髓磷脂含量变化的直接标志物。为此，Wei等 [<xref ref-type="bibr" rid="hanspub.44148-ref32">32</xref>] 提出了一种三维Sketcher-Refiner GAN用于脑部MR到PET的合成。该方法设置了两个生成过程来提升合成图像的质量，并使GANs训练过程更加稳定。具体来说，该研究先利用Sketcher模块生成初步的解剖和生理信息，再通过Refiner模块进行细化并生成可反映人脑组织中髓磷脂含量的图像。此外，该研究还设计了一种自适应对抗损失，使得Refiner模块更加关注多发性硬化症病变和髓磷脂含量的预测。评估结果表明，该方法有可能成为针对多发性硬化症患者临床管理的有效工具。</p><p>此外，多模态的神经图像，例如MR和PET可以提供互补的疾病信息，因而广泛用于脑部疾病的诊断，例如阿尔茨海默症等。然而在实际的临床场景中，某种模态的数据缺失往往是不可避免的，比如在ADNI [<xref ref-type="bibr" rid="hanspub.44148-ref33">33</xref>] 数据集中，就有大量受试者缺乏PET模态的数据。解决这一问题的简单策略是直接将缺少PET数据的受试者移出训练集，但这将大大减少训练可靠诊断模型的受试者数量。由于从同一受试者获得的不同模态图像之间往往存在潜在的相关性，Pan等 [<xref ref-type="bibr" rid="hanspub.44148-ref34">34</xref>] 提出了针对阿尔茨海默症的合成和分类两阶段深度学习框架。在第一阶段，通过使用CycleGAN根据现有的MR数据估算相应的缺失PET数据。在第二阶段，借助原始的MR数据和合成的PET数据，开发了用于阿尔茨海默症诊断和轻度认知障碍转换预测的深层多实例神经网络。在ADNI数据集上的实验结果表明，该研究合成的PET图像是合理的，而且在阿尔茨海默症的诊断方面也优于最新方法。更进一步地，为了避免合成模型会同等地处理三维图像中的所有体素，从而忽略了多模态图像中传达的疾病图像特定信息的问题，Pan等 [<xref ref-type="bibr" rid="hanspub.44148-ref35">35</xref>] 提出了一个使用不完整的多模态神经影像数据进行图像合成和疾病诊断的联合深度学习框架。该框架包括用于图像合成的特征一致性生成对抗网络和用于诊断的疾病图像特定分类网络，诊断网络在其特征图中编码疾病图像的特异性以协助生成网络的训练，而生成网络估算缺失的图像以提高诊断网络的诊断性能。实验结果表明该框架能将生成和分类两个任务互相促进，从MR图像中合成更高质量的PET图像，并且利用合成图像进行多模态融合分类，提升了疾病诊断效果。</p><p>不同模态的MR可以从不同的角度表明肿瘤引起的组织变化，因此获取多种模态的MR图像有益于脑肿瘤的分割。考虑到获取多模态图像的成本，Yu等 [<xref ref-type="bibr" rid="hanspub.44148-ref36">36</xref>] 设计了一种三维条件生成对抗网络，从脑肿瘤的T1-MR图像合成脑肿瘤的FLAIR-MR图像，并通过一种凸组合优化策略来进一步增强合成图像的细节。将合成图像用作多模态数据融合后，可以有效地提升在脑肿瘤分割任务上的表现。在另一方面，由于病理影像数据通常较少，医学影像数据集往往呈现类不均衡的情况，这为训练相应的深度学习诊断模型带来了重大挑战。Shin等 [<xref ref-type="bibr" rid="hanspub.44148-ref37">37</xref>] 利用生成对抗网络从基于脑肿瘤或脑解剖结构的分割掩膜合成带有脑肿瘤的异常脑部MR图像。该研究展示了医学图像合成提供的两个独特优势：首先，通过利用合成图像作为肿瘤分割的数据增强方法提升了分割性能；其次，当在合成数据上训练模型与在真实受试者数据上训练模型时，肿瘤分割结果具有可比性，这证明了生成对抗网络作为匿名化工具的价值。该研究为解决深度学习在医学影像处理中面临的类不均衡问题和病理数据不共享问题提供了可能的解决方案。</p><p>尽管CycleGAN在不具有配对数据的医学图像合成中取得了显著成果，但是由于输入图像和合成图像之间缺少直接约束，因此CycleGAN无法保证两图像之间的结构一致性，而这种结构一致性在多模态医学图像中是极为重要的。为了克服这个问题，Yang等 [<xref ref-type="bibr" rid="hanspub.44148-ref38">38</xref>] 提出了一种具有结构约束的CycleGAN，实现了不含有配对数据的脑部MR到CT的合成。该研究基于模态独立的邻域描述符定义了一种结构一致性损失，并附加到对抗损失上，以约束输入图像与合成图像之间存在结构一致性。此外，该研究提出了一种基于位置的选择策略来选择训练图像，而不同于以往常用的完全随机的数据选择方案。定性和定量的实验结果表明，该方法在医学图像合成上的效果比常规的CycleGAN更好。更进一步地，尽管CycleGAN及其改进框架已成功应用于脑部的不配对CT和MR图像，但由于骨盆区域存在关节和肌肉，骨盆区域图像的强度变化要比脑部图像更强。Hiasa等 [<xref ref-type="bibr" rid="hanspub.44148-ref39">39</xref>] 通过添加梯度一致性损失来进一步扩展CycleGAN方法，用于骨盆区域的CT图像到MR图像的跨模态合成，以克服较大的图像结构变化与提高边界处的合成表现。为了评估图像合成结果，该研究对训练数据的数量和梯度一致性损失对图像合成表现的影响进行了研究，并通过合成图像的分割精度证明了所提出方法的适用性。</p><p>医学图像的自动分割在临床研究中具有广泛的应用。Zhang等 [<xref ref-type="bibr" rid="hanspub.44148-ref40">40</xref>] 也提出了一种基于CycleGAN的跨模态综合框架来实现心血管MR图像到CT图像的三维合成，并通过将合成图像用于数据增强来改善分割结果。该研究的巧妙之处在于联合学习跨域转换的生成网络和性能更优的分割网络，生成网络用于增强训练样本有限的模态数据，而分割网络除了以在线学习的方式使用合成数据提高分割表现之外，还通过计算一种新颖的形状一致性损失，以保证输入MR图像和合成CT图像具有一致的解剖结构，解决在跨模态合成中经常存在几何失真的问题，提升生成网络的合成图像质量。二者以一种端到端的训练方式从一个联合优化目标中受益。实验结果表明，将合成数据用作线下的数据增强的表现不如该研究提出的端到端在线数据增强方法。分割和合成两种任务彼此有益，并且将它们结合起来处理比单独处理具有更好的表现。此外，CT图像能显示和分割出清晰的骨结构，因此在颅颌面部的诊断和手术计划中起着至关重要的作用。但是，CT成像会对被扫描的对象造成辐射风险，而MR则不存在这个问题。Zhao等 [<xref ref-type="bibr" rid="hanspub.44148-ref41">41</xref>] 提出了一种具有深度监督判别器的级联生成对抗网络，先从MR中生成高质量的CT图像，再基于原始的MR图像和生成的CT图像来自动分割骨结构。与传统的判别器不同，深度监督判别器在不同的特征图层次上将生成的CT图像与真实的CT图像区分开。此外，该研究还加入了抽象感知损失，以提升合成数据在分割任务上的表现。实验结果表明，该方法生成的CT图像具有更清晰的结构细节，并且可以更准确地分割出骨结构。</p></sec><sec id="s7_3"><title>3.3. 医学图像超分重建</title><p>在临床上，高分辨率的医学图像有助于医生对患者病情的分析和诊断更加精准。然而，受限于硬件设施、示踪剂剂量或成像时间等因素，医学图像的信噪比通常较低，获取高分辨率的医学图像相对困难。随着生成对抗网络在图像生成领域的广泛应用，研究人员也对其在医学图像超分辨率上的应用进行大量研究 [<xref ref-type="bibr" rid="hanspub.44148-ref42">42</xref>]。</p><p>Mahapatra等 [<xref ref-type="bibr" rid="hanspub.44148-ref43">43</xref>] 提出利用渐进式生成对抗网络 [<xref ref-type="bibr" rid="hanspub.44148-ref7">7</xref>] 来实现多阶段渐进式地提升医学图像分辨率。该模型使用了两个相同结构的渐进式生成对抗网络同时学习从低分辨率眼底图像到高分辨率眼底图像的生成，并引入三元损失计算两个生成对抗网络损失，使得模型能利用前一阶段的输出作为基准逐步提高图像质量。该模型除了在图像定量评价指标上优于对比模型，在利用获得的高分辨率眼底图像和心脏图像分别进行血管分割和微动脉瘤监测实验上也有着更高的精确度。该研究利用分割和检测的准确度来评价模型性能的方式是对超分辨率图像质量客观和主观评价指标的有效补充。</p><p>Zhao等 [<xref ref-type="bibr" rid="hanspub.44148-ref44">44</xref>] 提出了结合拉普拉斯金字塔 [<xref ref-type="bibr" rid="hanspub.44148-ref45">45</xref>] 的生成对抗网络模型，生成视觉效果更好的高分辨率心血管超声图像以辅助诊断和治疗。该方法利用拉普拉斯金字塔结构在不同的尺度分析重建的超分辨率图像的高频细节特征，通过最小方差损失消除梯度消失效应，并引入密集残差块作为网络的基本单元以加深网络的深度。通过以上措施，使模型具有更强的超分辨率性能，避免产生局部伪影，并且在峰值信噪比和结构相似度指标上都具有更好的得分。该方法将拉普拉斯金字塔和生成对抗网络结合起来，更加注重于图像的高频细节，有效地提高了超分辨率质量。</p><p>为了使生成的超分辨率医学图像保留更多有用的图像细节，同时避免生成高频部分的错误信息，Bing等 [<xref ref-type="bibr" rid="hanspub.44148-ref46">46</xref>] 提出一种基于生成对抗网络的医学图像超分辨率改进模型。通过对Squeeze and Excitation (SE)块 [<xref ref-type="bibr" rid="hanspub.44148-ref47">47</xref>] 中的激活函数进行修改，使其能更高效地利用隐藏层信息和避免中间层的数值过小。该研究将改进的SE块集成到简化的EDSR [<xref ref-type="bibr" rid="hanspub.44148-ref48">48</xref>] 网络中构建基于生成对抗网络的超分辨率改进模型，并通过融合相关损失进一步增强改进模型对图像低维特征的约束。在眼底数据集上的大量实验表明，该研究提出的方法比SRGAN [<xref ref-type="bibr" rid="hanspub.44148-ref49">49</xref>]，EDSR [<xref ref-type="bibr" rid="hanspub.44148-ref48">48</xref>]，VDSR [<xref ref-type="bibr" rid="hanspub.44148-ref50">50</xref>] 和D-DBPN [<xref ref-type="bibr" rid="hanspub.44148-ref51">51</xref>] 等经典方法具有更好的超分辨率性能。</p><p>You等 [<xref ref-type="bibr" rid="hanspub.44148-ref52">52</xref>] 以CycleGAN为基本框架，结合深度卷积网络和残差网络，提出了一个从有噪声的低分辨率CT图像生成高质量的高分辨率CT图像的生成对抗网络模型。通过输入配对CT图像，网络的正向循环根据低分辨率图像生成高分辨率图像，反向循环则利用高分辨率图像生成低分辨率图像。为了增强低分辨率CT和高分辨率CT间的跨域循环一致性，该方法引入了循环一致性约束。此外，模型中引入联合约束以利用先验信息提高模型去除噪声以及保留高分辨率CT图像的解剖学结构的能力。通过在胫骨和腹部CT数据集上的实验，证明了该模型在CT图像超分辨率上具有优秀的性能。</p><p>为了解决临床实际上配对的低分辨率和高分辨率PET图像缺乏，而超分辨率模型训练需要大量配对图像的矛盾，Song等 [<xref ref-type="bibr" rid="hanspub.44148-ref53">53</xref>] 提出了一种基于对偶生成对抗网络的自监督医学图像超分辨率方法。该模型通过引入VDSR [<xref ref-type="bibr" rid="hanspub.44148-ref50">50</xref>] 方法的高维特征作为辅助信息，有效地增强了模型的超分辨率性能。并通过自监督方式减少了对配对的PET图像的需求，更加符合实际临床场景，然而该模型需要高分辨率的MR图像作为辅助信息，这会对实际应用造成一定的阻碍。</p><p>为了进一步解决超分辨率生成对抗网络训练不稳定的问题，Zhu等 [<xref ref-type="bibr" rid="hanspub.44148-ref54">54</xref>] 提出一种基于多尺度生成对抗网络的病灶聚焦超分辨率模型，实现更加稳定和高效的训练并且生成感知上更加真实的超分辨率医学图像。具体而言，该研究首先利用预训练的病灶聚焦模型将病变区域分割出来，随后利用多尺度的生成对抗网络将分割出来的区域进行超分辨率。该研究提出的方法不仅可以实现病变区域的超分辨率，而且不会引入人造伪影。通过和其他超分辨率模型的比较，该模型在融合领域专家先验知识的评价意见得分中取得了最高评分。</p><p>为了辅助医生查看医学病理图像，Huang等 [<xref ref-type="bibr" rid="hanspub.44148-ref55">55</xref>] 提出一种基于生成对抗网络的医学图像超分辨率方法。考虑到病理图像通常具有较大的无组织区域，该研究中先通过预处理手段获取组织区域，然后再通过生成对抗网络生成超分辨率的组织病理图像。该模型应用了小批量的相对判别器对生成图像和真实图像进行相对判别，促进模型学习更多的先验知识，提高超分辨率图像的质量。同时添加了额外的损失函数，使得在图像中病理组织变化较大的情况下模型也能具有较好的稳定性。最后，该研究提出了一种特征相似性 [<xref ref-type="bibr" rid="hanspub.44148-ref56">56</xref>] 指标，能更好地评价超分辨率图像的特征重建效果。相关实验表明该模型在重建图像的颜色和细胞间的细节纹理上具有较大优势。</p><p>上述方法大多利用单一模型实现医学图像超分辨率，目前有学者对利用集成学习技术综合多个超分辨率模型实现医学图像超分辨率生成进行了研究。比如Lyu等 [<xref ref-type="bibr" rid="hanspub.44148-ref57">57</xref>] 提出了一个深度集成学习框架进行MR图像的超分。具体而言，该研究首先在同一数据集上应用了五个常用的超分辨率模型，生成了五个具有先验互补性的放大MR数据集。接着通过一个生成对抗网络对放大后的五个MR数据集进行超分，生成超分辨率的MR图像。最后再利用另一个生成对抗网络对生成的超分辨率图像进行进一步细化合成，获得最终的超分辨率MR图像。相比于单个超分模型，该方法能有效融合多个方法的优点，在抑制伪影和保留图像细节上更具优势。该研究提出的通过集成学习技术对多个超分辨率模型进行集成的想法，非常具有进一步研究的价值。</p></sec><sec id="s7_4"><title>3.4. 医学图像辅助诊断</title><p>在临床上，医学图像是医师对患者病情进行评估和诊断的重要依据，医师往往需要花费大量时间对病人的病理图像进行细致地观察和分析，白白耗费了宝贵的医疗资源。同时，医师对医学图像的分析存在主观差异，容易造成偏差。因此研究基于医学影像的辅助诊断技术具有重要意义，有利于提高医师对医学图像分析的效率和对患者病情诊断的精确度，有利于缓解医疗资源紧张的局面。</p><p>随着机器学习尤其是深度学习在医学图像计算上研究的深入，医学图像辅助诊断技术得到快速发展，如利用弥散张量图像(diffusion tensor image, DTI)进行脊髓型颈椎病(cervical spondylotic myelopathy, CSM)病变程度预测和诊断 [<xref ref-type="bibr" rid="hanspub.44148-ref58">58</xref>] [<xref ref-type="bibr" rid="hanspub.44148-ref59">59</xref>]；利用尺骨桡骨的X光片进行骨龄成熟度预测 [<xref ref-type="bibr" rid="hanspub.44148-ref60">60</xref>] [<xref ref-type="bibr" rid="hanspub.44148-ref61">61</xref>]；利用脑补磁共振(magnetic resonance, MR)图像进行阿尔茨海默症(Alzheimer’s disease, AD)的预测和诊断 [<xref ref-type="bibr" rid="hanspub.44148-ref62">62</xref>] [<xref ref-type="bibr" rid="hanspub.44148-ref63">63</xref>] [<xref ref-type="bibr" rid="hanspub.44148-ref64">64</xref>] [<xref ref-type="bibr" rid="hanspub.44148-ref65">65</xref>] [<xref ref-type="bibr" rid="hanspub.44148-ref66">66</xref>]。由于生成对抗网络博弈对抗学习的方式具有半监督/无监督训练的特性，基于生成对抗网络的医学图像辅助诊断技术也受到广泛关注。</p><p>Yu等 [<xref ref-type="bibr" rid="hanspub.44148-ref67">67</xref>] 提出了一种基于张量化和二阶池化的三元生成对抗网络模型(TGAN)利用MR图像的三维信息进行阿尔茨海默症的分类辅助诊断。该模型通过Tensor-train张量分解方法优化三元生成对抗网络的结构，有利于保留MR图像的三维脑部解剖结构信息。同时，通过引入二阶池化，能够充分利用整体MR图像的二阶信息，在自注意力机制的作用下提取与病变相关的更有判别性的特征，从而提高阿尔兹海默症的辅助诊断准确率。实验结果表明，基于张量化和二阶池化的三元生成对抗网络模型在NC (正常对照组) vs. AD (阿尔茨海默症组)上的辅助诊断率最优达到95.92%。</p><p>Lei等 [<xref ref-type="bibr" rid="hanspub.44148-ref68">68</xref>] 提出了一种用于皮肤镜损伤区域分割的皮肤病辅助诊断生成对抗网络模型(DAGAN)。该模型中生成器模块由一个基于跳跃连接和密集空洞卷积的U-Net网络(UNet-SCDC)构成，有利于生成保留了细粒度信息的深度表示。判别器模块由两个子判别器构成，其中一个子判别器使用传统的对抗损失专注于判别分割区域与基本对照区域在边缘上的差异，另一个子模块使用条件判别损失检测原始图像中目标对象的上下文环境。通过在2017和2018的International Skin Imaging Collaboration (ISIC)皮肤损伤挑战赛公共数据集上进行验证，DAGAN对损伤区域分割的准确率达到了93.5%。</p><p>Wang等 [<xref ref-type="bibr" rid="hanspub.44148-ref69">69</xref>] 提出半监督机制的多通道生成对抗网络(MGAN)用于糖尿病视网膜病变诊断。MGAN先利用多通道机制提取眼底图像中不同的糖尿病视网膜病变特征，再进行病变特征的结合表示，有效地对分散的病变特征进行提取。此外，MGAN设计了半监督的学习机制，减少了模型训练中对标注数据的依赖，有利于无压缩地识别出视网膜中的损伤特征。在公共数据集Messidor上的实验结果表明，MGAN对糖尿病视网膜病变的诊断准确率达到了84.23%，比其他模型的最高准确率提高了4.06%。</p></sec></sec><sec id="s8"><title>4. 基于生成对抗网络的医学图像计算展望</title><p>将生成对抗网络应用于医学图像合成、超分辨率和辅助诊断等医学图像计算领域仍然需要解决一些挑战。在上述介绍的工作中，大多数工作仍采用计算机视觉领域的自然图像计算指标作为评估合成或超分辨率医学图像质量的度量标准，比如平均绝对值误差(mean absolute error, MAE)，峰值信噪比(peak signal to noise ratio, PSNR)或结构相似性(structural similarity index, SSIM)等。但是这些指标未必能准确评估医学图像的质量。缓解此问题的一种方法是将生成图像数据应用于后续的医学分析任务，例如分类或分割等，以验证生成图像质量，这已在上述介绍的工作中被大量采用。另一种方法是招募医学成像领域的专家进行视觉图灵测试，但是这种方法所需的时间成本和经济成本都很高，不具有通用性。尽管已有部分研究 [<xref ref-type="bibr" rid="hanspub.44148-ref70">70</xref>] [<xref ref-type="bibr" rid="hanspub.44148-ref71">71</xref>] [<xref ref-type="bibr" rid="hanspub.44148-ref72">72</xref>] 致力于探索与人类观察者的主观测量更接近的评估指标，但这些指标对医学图像质量评估的有效性仍待研究。寻找更具医学意义的图像质量评估指标，更有效地评估合成或超分辨率医学图像的质量，是未来的重要研究方向之一。</p><p>除去本文介绍的应用工作之外，生成对抗网络在医学图像计算上仍有极大的应用潜力。例如，从带有由于运动或其他因素造成的某些伪影的MR图像合成清晰的MR图像，这可以避免患者接受重复的检查。同样地，可以通过图像合成的方式去除带有石膏的患者的骨骼X射线图像的伪影，这可以帮助放射科医生更有效地评估骨愈合的进展。在另一方面，生成对抗网络在文本至图像的合成之间取得了重要进展，我们期望病历到图像的转换能在医学图像领域有所应用，这能进一步提升合成图像的质量，并且有可能解决合成图像中细微的病变区域丢失的问题。此外，现有的医学图像跨模态合成工作大多集中于单模态图像到单模态图像的合成，考虑到多个模态所反映的信息更全面，从多模态图像合成单模态图像，或是从多模态图像合成多模态图像会是跨模态工作的发展趋势之一，这会进一步增强合成图像的可靠性。最近部分关于生成对抗网络的工作 [<xref ref-type="bibr" rid="hanspub.44148-ref73">73</xref>] [<xref ref-type="bibr" rid="hanspub.44148-ref74">74</xref>] 还展示了通过自适应归一化层控制合成图像高级属性和语义布局的能力。在未来也许我们可以通过这种方式按当下的需求定制医学图像，或对现有医学图像进行局部化的修改，这或许能为疾病预测以及药物功效试验提供帮助。</p><p>最后，尽管生成对抗网络在医学图像计算上的研究工作如同雨后春笋般不断冒出，但目前尚无有影响力的临床应用。解决生成对抗网络的可解释性和可靠性的问题，是基于生成对抗网络的医学图像计算落地应用的关键因素。该领域的研究仍处于起步阶段，仍有巨大的研究空白尚待填补。</p></sec><sec id="s9"><title>5. 总结</title><p>本文首先简单梳理了生成对抗网络的网络结构和对抗训练理论，随后从潜层向量合成医学图像、跨模态合成医学图像、医学图像超分重建和医学图像辅助诊断四个方面，对近年来生成对抗网络在医学图像合成、超分重建以及辅助诊断上的研究现状进行了分析，介绍了许多具有代表性和影响力的工作。最后，展望了生成对抗网络在该领域亟待解决的挑战和发展前景，为该领域后续发展提供了思路与启示。</p></sec><sec id="s10"><title>基金项目</title><p>本文工作受以下项目资助：国家自然科学基金资助项目(No. 61872351)，广东省国际科技合作计划项目(No. 2019A050510030)，广东省杰出青年基金(No. 2021B1515020019)，深圳市优秀科技创新人才培养项目(RCYX20200714114641211)和深圳科创委基础研究重点项目(JCYJ20200109115641762)。</p></sec><sec id="s11"><title>文章引用</title><p>游森榕,胡圣烨,申妍燕,王书强. 生成对抗网络在医学图像计算上的进展与展望Review and Prospects for Generative Adversarial Networks on Medical Image Computation[J]. 计算机科学与应用, 2021, 11(07): 1949-1961. https://doi.org/10.12677/CSA.2021.117200</p></sec><sec id="s12"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.44148-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Burgos, N., Cardoso, M.J., Thielemans, K., et al. (2014) Attenuation Correction Synthesis for Hybrid PET-MR Scanners: Application to Brain Studies. IEEE transactions on medical imaging, 33, 2332-2341. 
&lt;br&gt;https://doi.org/10.1109/TMI.2014.2340135</mixed-citation></ref><ref id="hanspub.44148-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Jog, A., Carass, A. and Prince, J.L. (2014) Improving Magnetic Resonance Resolution with Supervised Learning. 2014 IEEE 11th International Symposium on Biomedical Imaging (ISBI), Beijing, 29 April-2 May 2014, 987-990. 
&lt;br&gt;https://doi.org/10.1109/ISBI.2014.6868038</mixed-citation></ref><ref id="hanspub.44148-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Krizhevsky, A., Sutskever, I. and Hinton, G.E. (2012) Imagenet Classification with Deep Convolutional Neural Networks. Advances in Neural Information Processing Systems, Nevada, 3-6 December 2012, 1097-1105.</mixed-citation></ref><ref id="hanspub.44148-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Zeng, D., Wang, S., Shen, Y., et al. (2017) A GA-Based Feature Selection and Parameter Optimization for Support Tucker Machine. Procedia Computer Science, 111, 17-23. &lt;br&gt;https://doi.org/10.1016/j.procs.2017.06.004</mixed-citation></ref><ref id="hanspub.44148-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Li, R., Zhang, W., Suk, H.I., et al. (2014) Deep Learning Based Imaging Data Completion for Improved Brain Disease Diagnosis. International Conference on Medical Image Compu-ting and Computer-Assisted Intervention, Boston, 14-18 September 2014, 305-312. &lt;br&gt;https://doi.org/10.1007/978-3-319-10443-0_39</mixed-citation></ref><ref id="hanspub.44148-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Goodfellow, I., Pouget-Abadie, J., Mirza, M., et al. (2014) Generative Adversarial Nets. Advances in Neural Information Processing Systems, Montreal, 8-13 December 2014, 2672-2680.</mixed-citation></ref><ref id="hanspub.44148-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Mo, L.F. and Wang, S.Q. (2009) A Variational Approach to Nonlinear Two-Point Boundary Value Problems. Nonlinear Analysis: Theory, Methods &amp; Applications, 71, e834-e838. &lt;br&gt;https://doi.org/10.1016/j.na.2008.12.006</mixed-citation></ref><ref id="hanspub.44148-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Wang, S.Q. (2009) A Variational Approach to Nonlinear Two-Point Boundary Value Problems. Computers &amp; Mathematics with Applications, 58, 2452-2455. &lt;br&gt;https://doi.org/10.1016/j.camwa.2009.03.050</mixed-citation></ref><ref id="hanspub.44148-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Wang, S.Q. and He, J.H. (2008) Variational Iteration Method for a Nonlinear Reaction-Diffusion Process. International Journal of Chemical Reactor Engineering, 6, A37. &lt;br&gt;https://doi.org/10.2202/1542-6580.1630</mixed-citation></ref><ref id="hanspub.44148-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Kingma, D.P. and Welling, M. (2013) Auto-Encoding Variational Bayes. arXiv Preprint, arXiv:1312.6114.</mixed-citation></ref><ref id="hanspub.44148-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">王坤峰, 苟超, 段艳杰, 等. 生成式对抗网络GAN的研究进展与展望[J]. 自动化学报, 2017, 43(3): 321-332.</mixed-citation></ref><ref id="hanspub.44148-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Karras, T., Aila, T., Laine, S., et al. (2017) Progressive Growing of Gans for Improved Quality, Stability, and Variation. arXiv Preprint, arXiv:1710.10196.</mixed-citation></ref><ref id="hanspub.44148-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Spampinato, C., Palazzo, S., D’Oro, P., et al. (2019) Adversarial Framework for Unsupervised Learning of Motion Dynamics in Videos. Internation-al Journal of Computer Vision, 128, 1378-1397.</mixed-citation></ref><ref id="hanspub.44148-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">Kim, T., Cha, M., Kim, H., et al. (2017) Learning to Discover Cross-Domain Relations with Generative Adversarial Networks. Proceedings of the 34th International Conference on Machine Learning, 70, 1857-1865.</mixed-citation></ref><ref id="hanspub.44148-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">Zhang, Y., Gan, Z. and Carin, L. (2016) Generating Text via Adversarial Training. NIPS Workshop on Adversarial Training, 21, 21-32.</mixed-citation></ref><ref id="hanspub.44148-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">Yu, L., Zhang, W., Wang, J., et al. (2017) Seqgan: Sequence Generative Adversarial Nets with Policy Gradient. Thirty-First AAAI Conference on Artificial Intelligence, 31, 2852-2858.</mixed-citation></ref><ref id="hanspub.44148-ref17"><label>17</label><mixed-citation publication-type="other" xlink:type="simple">Radford, A., Metz, L. and Chintala, S. (2015) Unsupervised Representation Learning with Deep Con-volutional Generative Adversarial Networks. arXiv Preprint, arXiv:1511.06434.</mixed-citation></ref><ref id="hanspub.44148-ref18"><label>18</label><mixed-citation publication-type="other" xlink:type="simple">Arjovsky, M., Chintala, S. and Bottou, L. (2017) Wasserstein Gan. arXiv Preprint, arXiv:1701.07875.</mixed-citation></ref><ref id="hanspub.44148-ref19"><label>19</label><mixed-citation publication-type="other" xlink:type="simple">Isola, P., Zhu, J.Y., Zhou, T., et al. (2017) Image-to-Image Translation with Conditional Adversarial Networks. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, 21-26 July 2017, 1125-1134. &lt;br&gt;https://doi.org/10.1109/CVPR.2017.632</mixed-citation></ref><ref id="hanspub.44148-ref20"><label>20</label><mixed-citation publication-type="other" xlink:type="simple">Zhu, J.Y., Park, T., Isola, P., et al. (2017) Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks. Proceedings of the IEEE International Conference on Com-puter Vision, Venice, 22-29 October 2017, 2223-2232. &lt;br&gt;https://doi.org/10.1109/ICCV.2017.244</mixed-citation></ref><ref id="hanspub.44148-ref21"><label>21</label><mixed-citation publication-type="other" xlink:type="simple">Frid-Adar, M., Diamant, I., Klang, E., et al. (2018) GAN-Based Synthetic Medical Image Augmentation for Increased CNN Perfor-mance in Liver Lesion Classification. Neurocomputing, 321, 321-331.  
&lt;br&gt;https://doi.org/10.1016/j.neucom.2018.09.013</mixed-citation></ref><ref id="hanspub.44148-ref22"><label>22</label><mixed-citation publication-type="other" xlink:type="simple">Bermudez, C., Plassard, A.J., Davis, L.T., et al. (2018) Learn-ing Implicit Brain MRI Manifolds with Deep Learning. Medical Imaging 2018: Image Processing, Houston. &lt;br&gt;https://doi.org/10.1117/12.2293515</mixed-citation></ref><ref id="hanspub.44148-ref23"><label>23</label><mixed-citation publication-type="other" xlink:type="simple">Chuquicusma, M.J.M., Hussein, S., Burt, J., et al. (2018) How to Fool Radiologists with Generative Adversarial Networks? A Visual Turing Test for Lung Cancer Diagnosis. 2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018), Washington, 4-7 April 2018, 240-244. &lt;br&gt;https://doi.org/10.1109/ISBI.2018.8363564</mixed-citation></ref><ref id="hanspub.44148-ref24"><label>24</label><mixed-citation publication-type="other" xlink:type="simple">Baur, C., Albarqouni, S. and Navab, N. (2018) Generating Highly Realistic Images of Skin Lesions with GANs. OR 2.0 Context-Aware Operating Theaters, Computer Assisted Robotic Endoscopy, Clinical Image-Based Procedures, and Skin Image Analysis. Springer, Cham, 260-267. &lt;br&gt;https://doi.org/10.1007/978-3-030-01201-4_28</mixed-citation></ref><ref id="hanspub.44148-ref25"><label>25</label><mixed-citation publication-type="other" xlink:type="simple">Kwon, G., Han, C. and Kim, D. (2019) Generation of 3D Brain MRI Using Auto-Encoding Generative Adversarial Networks. International Conference on Medical Image Com-puting and Computer-Assisted Intervention, Shenzhen, 13-17 October 2019, 118-126. &lt;br&gt;https://doi.org/10.1007/978-3-030-32248-9_14</mixed-citation></ref><ref id="hanspub.44148-ref26"><label>26</label><mixed-citation publication-type="other" xlink:type="simple">Rosca, M., Lakshminarayanan, B., Warde-Farley, D., et al. (2017) Variational Approaches for Auto-Encoding Generative Adversarial Networks. arXiv Preprint, arXiv:1706.04987.</mixed-citation></ref><ref id="hanspub.44148-ref27"><label>27</label><mixed-citation publication-type="other" xlink:type="simple">Zhang, T., Fu, H., Zhao, Y., et al. (2019) SkrGAN: Sketching-Rendering Unconditional Gen-erative Adversarial Networks for Medical Image Synthesis. International Conference on Medical Image Computing and Computer-Assisted Intervention, Shenzhen, 13-17 October 2019, 777-785. &lt;br&gt;https://doi.org/10.1007/978-3-030-32251-9_85</mixed-citation></ref><ref id="hanspub.44148-ref28"><label>28</label><mixed-citation publication-type="other" xlink:type="simple">Hu, S., Shen, Y., Wang, S., et al. (2020) Brain MR to PET Synthesis via Bidirectional Generative Adversarial Network. International Conference on Medical Image Computing and Computer-Assisted Intervention, Lima, 4-8 October 2020, 698-707. &lt;br&gt;https://doi.org/10.1007/978-3-030-59713-9_67</mixed-citation></ref><ref id="hanspub.44148-ref29"><label>29</label><mixed-citation publication-type="other" xlink:type="simple">Hu, S., Yu, W., Chen, Z., et al. (2020) Medical Image Recon-struction Using Generative Adversarial Network for Alzheimer Disease Assessment with Class-Imbalance Problem. 2020 IEEE 6th International Conference on Computer and Communications (ICCC), Chengdu, 11-14 December 2020, 1323-1327.  
&lt;br&gt;https://doi.org/10.1109/ICCC51575.2020.9344912</mixed-citation></ref><ref id="hanspub.44148-ref30"><label>30</label><mixed-citation publication-type="other" xlink:type="simple">Hu, S., Yuan, J. and Wang, S. (2019) Cross-Modality Synthesis from MRI to PET Using Adversarial U-Net with Different Normalization. 2019 International Conference on Medical Imaging Physics and Engineering (ICMIPE), Shenzhen, 22-24 November 2019, 1-5. &lt;br&gt;https://doi.org/10.1109/ICMIPE47306.2019.9098219</mixed-citation></ref><ref id="hanspub.44148-ref31"><label>31</label><mixed-citation publication-type="other" xlink:type="simple">Nie, D., Trullo, R., Lian, J., et al. (2018) Medical Image Synthesis with Deep Convolutional Adversarial Networks. IEEE Transactions on Biomedical Engineering, 65, 2720-2730. &lt;br&gt;https://doi.org/10.1109/TBME.2018.2814538</mixed-citation></ref><ref id="hanspub.44148-ref32"><label>32</label><mixed-citation publication-type="other" xlink:type="simple">Wei, W., Poirion, E., Bodini, B., et al. (2018) Learning Myelin Content in Multiple Sclerosis from Multimodal MRI through Adversarial Training. International Con-ference on Medical Image Computing and Computer-Assisted Intervention, Granada, 16-20 September 2018, 514-522. &lt;br&gt;https://doi.org/10.1007/978-3-030-00931-1_59</mixed-citation></ref><ref id="hanspub.44148-ref33"><label>33</label><mixed-citation publication-type="other" xlink:type="simple">Jack, Jr.C.R., Bernstein, M.A., Fox, N.C., et al. (2008) The Alzheimer’s Disease Neuroimaging Initiative (ADNI): MRI Methods. Journal of Magnetic Resonance Imaging: An Offi-cial Journal of the International Society for Magnetic Resonance in Medicine, 27, 685-691.</mixed-citation></ref><ref id="hanspub.44148-ref34"><label>34</label><mixed-citation publication-type="other" xlink:type="simple">Pan, Y., Liu, M., Lian, C., et al. (2018) Synthesizing Missing PET from MRI with Cycle-Consistent Generative Adversarial Networks for Alz-heimer’s Disease Diagnosis. International Conference on Medical Image Computing and Computer-Assisted Interven-tion, Granada, 16-20 September 2018, 455-463.  
&lt;br&gt;https://doi.org/10.1007/978-3-030-00931-1_52</mixed-citation></ref><ref id="hanspub.44148-ref35"><label>35</label><mixed-citation publication-type="other" xlink:type="simple">Pan, Y., Liu, M., Lian, C., et al. (2019) Disease-Image Spe-cific Generative Adversarial Network for Brain Disease Diagnosis with Incomplete Multi-Modal Neuroimages. Interna-tional Conference on Medical Image Computing and Computer-Assisted Intervention, Shenzhen, 13-17 October 2019, 137-145.  
&lt;br&gt;https://doi.org/10.1007/978-3-030-32248-9_16</mixed-citation></ref><ref id="hanspub.44148-ref36"><label>36</label><mixed-citation publication-type="other" xlink:type="simple">Yu, B., Zhou, L., Wang, L., et al. (2018) 3D cGAN Based Cross-Modality MR Image Synthesis for Brain Tumor Segmentation. 2018 IEEE 15th International Symposium on Bio-medical Imaging (ISBI 2018) Washington, 4-7 April 2018, 626-630. &lt;br&gt;https://doi.org/10.1109/ISBI.2018.8363653</mixed-citation></ref><ref id="hanspub.44148-ref37"><label>37</label><mixed-citation publication-type="other" xlink:type="simple">Shin, H.C., Tenenholtz, N.A., Rogers, J.K., et al. (2018) Medical Image Synthesis for Data Augmentation and Anonymization Using Generative Adversarial Networks. International Workshop on Simulation and Synthesis in Medical Imaging, Granada, 16 September 2018, 1-11. &lt;br&gt;https://doi.org/10.1007/978-3-030-00536-8_1</mixed-citation></ref><ref id="hanspub.44148-ref38"><label>38</label><mixed-citation publication-type="other" xlink:type="simple">Yang, H., Sun, J., Carass, A., et al. (2018) Unpaired Brain MR-to-CT Synthesis Using a Structure-Constrained CycleGAN. In: Stoyanov, D., et al., Eds., Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support, Springer, Cham, 174-182. &lt;br&gt;https://doi.org/10.1007/978-3-030-00889-5_20</mixed-citation></ref><ref id="hanspub.44148-ref39"><label>39</label><mixed-citation publication-type="other" xlink:type="simple">Hiasa, Y., Otake, Y., Takao, M., et al. (2018) Cross-Modality Image Synthesis from Unpaired Data Using CycleGAN. In: Gooya, A., Goksel, O., Oguz, I., Burgos, N., Eds., Simula-tion and Synthesis in Medical Imaging, Springer, Cham, 31-41. &lt;br&gt;https://doi.org/10.1007/978-3-030-00536-8_4</mixed-citation></ref><ref id="hanspub.44148-ref40"><label>40</label><mixed-citation publication-type="other" xlink:type="simple">Zhang, Z., Yang, L. and Zheng, Y. (2018) Translating and Segmenting Multimodal Medical Volumes with cycle-And Shape-Consistency Generative Adversarial Network. Pro-ceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, 18-23 June 2018, 9242-9251. &lt;br&gt;https://doi.org/10.1109/CVPR.2018.00963</mixed-citation></ref><ref id="hanspub.44148-ref41"><label>41</label><mixed-citation publication-type="other" xlink:type="simple">Zhao, M., Wang, L., Chen, J., et al. (2018) Cranio-maxillofacial Bony Structures Segmentation from Mri with Deep-Supervision Adversarial Learning. International Con-ference on Medical Image Computing and Computer-Assisted Intervention, Granada, 16-20 September 2018, 720-727. &lt;br&gt;https://doi.org/10.1007/978-3-030-00937-3_82</mixed-citation></ref><ref id="hanspub.44148-ref42"><label>42</label><mixed-citation publication-type="other" xlink:type="simple">You, S., Liu, Y., Lei, B., et al. (2020) Fine Perceptive GANs for Brain MR Image Super-Resolution in Wavelet Domain. arXiv Preprint, arXiv:2011.04145,.</mixed-citation></ref><ref id="hanspub.44148-ref43"><label>43</label><mixed-citation publication-type="other" xlink:type="simple">Mahapatra, D., Bozorgtabar, B. and Garnavi, R. (2019) Image Super-Resolution Using Progressive Generative Adversarial Networks for Medical Image Analysis. Computerized Medical Imaging and Graphics, 71, 30-39. 
&lt;br&gt;https://doi.org/10.1016/j.compmedimag.2018.10.005</mixed-citation></ref><ref id="hanspub.44148-ref44"><label>44</label><mixed-citation publication-type="other" xlink:type="simple">Zhao, M., Liu, X., Liu, H., et al. (2020) Su-per-Resolution of Cardiac Magnetic Resonance Images Using Laplacian Pyramid based on Generative Adversarial Net-works. Computerized Medical Imaging and Graphics, 80, Article ID: 101698. &lt;br&gt;https://doi.org/10.1016/j.compmedimag.2020.101698</mixed-citation></ref><ref id="hanspub.44148-ref45"><label>45</label><mixed-citation publication-type="other" xlink:type="simple">Burt, P. and Adelson, E. (1983) The Laplacian Pyramid as a Compact IMAGE code. IEEE Transactions on Communications, 31, 532-540. &lt;br&gt;https://doi.org/10.1109/TCOM.1983.1095851</mixed-citation></ref><ref id="hanspub.44148-ref46"><label>46</label><mixed-citation publication-type="other" xlink:type="simple">Bing, X., Zhang, W., Zheng, L., et al. (2019) Medical Image Super Resolution Using Improved Generative Adversarial Networks. IEEE Access, 7, 145030-145038. &lt;br&gt;https://doi.org/10.1109/ACCESS.2019.2944862</mixed-citation></ref><ref id="hanspub.44148-ref47"><label>47</label><mixed-citation publication-type="other" xlink:type="simple">Hu, J., Shen, L. and Sun, G. (2018) Squeeze-and-Excitation Networks. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, 18-23 June 2018, 7132-7141. 
&lt;br&gt;https://doi.org/10.1109/CVPR.2018.00745</mixed-citation></ref><ref id="hanspub.44148-ref48"><label>48</label><mixed-citation publication-type="other" xlink:type="simple">Lim, B., Son, S., Kim, H., et al. (2017) Enhanced Deep Residual Networks for Single Image Super-Resolution. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, Honolulu, 21-26 July 2017, 136-144. &lt;br&gt;https://doi.org/10.1109/CVPRW.2017.151</mixed-citation></ref><ref id="hanspub.44148-ref49"><label>49</label><mixed-citation publication-type="other" xlink:type="simple">Ledig, C., Theis, L., Huszár, F., et al. (2017) Photo-Realistic Sin-gle Image Super-Resolution Using a Generative Adversarial Network. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, 21-26 July 2017, 4681-4690. &lt;br&gt;https://doi.org/10.1109/CVPR.2017.19</mixed-citation></ref><ref id="hanspub.44148-ref50"><label>50</label><mixed-citation publication-type="other" xlink:type="simple">Kim, J., Kwon Lee, J. and Mu Lee, K. (2016) Accurate Image Su-per-Resolution Using Very Deep Convolutional Networks. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Las Vegas, 27-30 June 2016, 1646-1654. &lt;br&gt;https://doi.org/10.1109/CVPR.2016.182</mixed-citation></ref><ref id="hanspub.44148-ref51"><label>51</label><mixed-citation publication-type="other" xlink:type="simple">Haris, M., Shakhnarovich, G. and Ukita, N. (2018) Deep Back-Projection Networks for Super-Resolution. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, 18-23 June 2018, 1664-1673. 
&lt;br&gt;https://doi.org/10.1109/CVPR.2018.00179</mixed-citation></ref><ref id="hanspub.44148-ref52"><label>52</label><mixed-citation publication-type="other" xlink:type="simple">You, C., Li, G., Zhang, Y., et al. (2019) CT Super-Resolution GAN Constrained by the Identical, Residual, and Cycle Learning Ensemble (GAN-CIRCLE). IEEE Transactions on Medical Imaging, 39, 188-203. 
&lt;br&gt;https://doi.org/10.1109/TMI.2019.2922960</mixed-citation></ref><ref id="hanspub.44148-ref53"><label>53</label><mixed-citation publication-type="other" xlink:type="simple">Song, T.A., Chowdhury, S.R., Yang, F., et al. (2020) PET Image Super-Resolution Using Generative Adversarial Networks. Neural Networks, 125, 83-91. &lt;br&gt;https://doi.org/10.1016/j.neunet.2020.01.029</mixed-citation></ref><ref id="hanspub.44148-ref54"><label>54</label><mixed-citation publication-type="other" xlink:type="simple">Zhu, J., Yang, G. and Lio, P. (2019) How Can We Make Gan Perform Better in Single Medical Image Super-Resolution? A Lesion Focused Multi-Scale Approach. 2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019), Venice, 8-11 April 2019, 1669-1673. &lt;br&gt;https://doi.org/10.1109/ISBI.2019.8759517</mixed-citation></ref><ref id="hanspub.44148-ref55"><label>55</label><mixed-citation publication-type="other" xlink:type="simple">Huang, X., Zhang, Q., Wang, G., et al. (2019) Medical Image Super-Resolution Based on the Generative Adversarial Network. Chinese Intelligent Systems Conference, Haikou, 26-27 October 2019, 243-253.  
&lt;br&gt;https://doi.org/10.1007/978-981-32-9686-2_29</mixed-citation></ref><ref id="hanspub.44148-ref56"><label>56</label><mixed-citation publication-type="other" xlink:type="simple">Morrone, M.C. and Owens, R.A. (1987) Feature Detection from Local Energy. Pattern Recognition Letters, 6, 303-313. &lt;br&gt;https://doi.org/10.1016/0167-8655(87)90013-4</mixed-citation></ref><ref id="hanspub.44148-ref57"><label>57</label><mixed-citation publication-type="other" xlink:type="simple">Lyu, Q., Shan, H. and Wang, G. (2020) MRI Su-per-Resolution with Ensemble Learning and Complementary Priors. IEEE Transactions on Computational Imaging, 6, 615-624. &lt;br&gt;https://doi.org/10.1109/TCI.2020.2964201</mixed-citation></ref><ref id="hanspub.44148-ref58"><label>58</label><mixed-citation publication-type="other" xlink:type="simple">Wang, S.Q., Li, X., Cui, J.L., et al. (2015) Prediction of Myelopathic Level in Cervical Spondylotic Myelopathy Using Diffusion Tensor Imaging. Journal of Magnetic Reso-nance Imaging, 41, 1682-1688.  
&lt;br&gt;https://doi.org/10.1002/jmri.24709</mixed-citation></ref><ref id="hanspub.44148-ref59"><label>59</label><mixed-citation publication-type="other" xlink:type="simple">Wang, S., Hu, Y., Shen, Y., et al. (2018) Classification of Diffusion Ten-sor Metrics for the Diagnosis of a Myelopathic Cord Using Machine Learning. International Journal of Neural Systems, 28, Article ID: 1750036. 
&lt;br&gt;https://doi.org/10.1142/S0129065717500368</mixed-citation></ref><ref id="hanspub.44148-ref60"><label>60</label><mixed-citation publication-type="other" xlink:type="simple">Wang, S., Shen, Y., Shi, C., et al. (2018) Skeletal Maturity Recognition Using a Fully Automated System with Convolutional Neural Networks. IEEE Access, 6, 29979-29993. &lt;br&gt;https://doi.org/10.1109/ACCESS.2018.2843392</mixed-citation></ref><ref id="hanspub.44148-ref61"><label>61</label><mixed-citation publication-type="other" xlink:type="simple">Wang, S., Wang, X., Shen, Y., et al. (2020) An Ensem-ble-Based Densely-Connected Deep Learning System for Assessment of Skeletal Maturity. IEEE Transactions on Sys-tems, Man, and Cybernetics: Systems, 1-12. 
&lt;br&gt;https://doi.org/10.1109/TSMC.2020.2997852</mixed-citation></ref><ref id="hanspub.44148-ref62"><label>62</label><mixed-citation publication-type="other" xlink:type="simple">Wang, S., Shen, Y., Chen ,W., et al. (2017) Automatic Recog-nition of Mild Cognitive Impairment from Mri Images Using Expedited Convolutional Neural Networks. International Conference on Artificial Neural Networks, Alghero, 11-14 September 2017, 373-380. &lt;br&gt;https://doi.org/10.1007/978-3-319-68600-4_43</mixed-citation></ref><ref id="hanspub.44148-ref63"><label>63</label><mixed-citation publication-type="other" xlink:type="simple">Wang, S., Wang, H., Shen, Y., et al. (2018) Automatic Recognition of Mild Cognitive Impairment and Alzheimers Disease Using Ensemble Based 3D Densely Connected Convolutional Networks. 2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA), Orlando, 17-20 December 2018, 517-523.  
&lt;br&gt;https://doi.org/10.1109/ICMLA.2018.00083</mixed-citation></ref><ref id="hanspub.44148-ref64"><label>64</label><mixed-citation publication-type="other" xlink:type="simple">Lei, B., Yang, M., Yang, P., et al. (2020) Deep and Joint Learn-ing of Longitudinal Data for Alzheimer’s Disease Prediction. Pattern Recognition, 102, Article ID: 107247. &lt;br&gt;https://doi.org/10.1016/j.patcog.2020.107247</mixed-citation></ref><ref id="hanspub.44148-ref65"><label>65</label><mixed-citation publication-type="other" xlink:type="simple">Wang, S., Wang, H., Cheung, A.C., et al. (2020) Ensemble of 3D Densely Connected Convolutional Network for Diagnosis of Mild Cognitive Impairment and Alzheimer’s Disease. Deep Learning Applications, 1098, 53-73. 
&lt;br&gt;https://doi.org/10.1007/978-981-15-1816-4_4</mixed-citation></ref><ref id="hanspub.44148-ref66"><label>66</label><mixed-citation publication-type="other" xlink:type="simple">Yu, S., Wang, S., Xiao, X., et al. (2020) Multi-Scale Enhanced Graph Convolutional Network for Early Mild Cognitive Impairment Detection. International Conference on Medical Image Computing and Computer-Assisted Intervention, Lima, 4-8 October 2020, 228-237. &lt;br&gt;https://doi.org/10.1007/978-3-030-59728-3_23</mixed-citation></ref><ref id="hanspub.44148-ref67"><label>67</label><mixed-citation publication-type="other" xlink:type="simple">Yu, W., Lei, B., Ng, M.K., et al. (2021) Tensorizing GAN with High-Order Pooling for Alzheimer’s Disease Assessment. IEEE Transactions on Neural Networks and Learning Systems, 1-15.  
&lt;br&gt;https://doi.org/10.1109/TNNLS.2021.3063516</mixed-citation></ref><ref id="hanspub.44148-ref68"><label>68</label><mixed-citation publication-type="other" xlink:type="simple">Lei, B., Xia, Z., Jiang, F., et al. (2020) Skin Lesion Segmenta-tion via Generative Adversarial Networks with Dual Discriminators. Medical Image Analysis, 64, Article ID: 101716. &lt;br&gt;https://doi.org/10.1016/j.media.2020.101716</mixed-citation></ref><ref id="hanspub.44148-ref69"><label>69</label><mixed-citation publication-type="other" xlink:type="simple">Wang, S., Wang, X., Hu, Y., et al. (2020) Diabetic Retinopathy Diagnosis Using Multichannel Generative Adversarial Network with Semisupervision. IEEE Transactions on Automa-tion Science and Engineering, 18, 574-585. 
&lt;br&gt;https://doi.org/10.1109/TASE.2020.2981637</mixed-citation></ref><ref id="hanspub.44148-ref70"><label>70</label><mixed-citation publication-type="other" xlink:type="simple">Zhang, R., Isola, P., Efros, A.A., et al. (2018) The Unreasonable Effectiveness of Deep Features as a Perceptual Metric. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, 18-23 June 2018, 586-595. &lt;br&gt;https://doi.org/10.1109/CVPR.2018.00068</mixed-citation></ref><ref id="hanspub.44148-ref71"><label>71</label><mixed-citation publication-type="other" xlink:type="simple">Odena, A., Olah, C. and Shlens, J. (2017) Conditional Image Synthesis with Auxiliary Classifier Gans. Proceedings of the 34th International Conference on Machine Learning, 70, 2642-2651.</mixed-citation></ref><ref id="hanspub.44148-ref72"><label>72</label><mixed-citation publication-type="other" xlink:type="simple">Heusel, M., Ramsauer, H., Unterthiner, T., et al. (2017) Gans Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium. Advances in Neural Information Processing Systems, Long Beach, 4-9 De-cember 2017, 6626-6637.</mixed-citation></ref><ref id="hanspub.44148-ref73"><label>73</label><mixed-citation publication-type="other" xlink:type="simple">Karras, T., Laine, S. and Aila, T. (2019) A Style-Based Generator Architecture for Gen-erative Adversarial Networks. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Long Beach, 15-20 June 2019, 4401-4410. &lt;br&gt;https://doi.org/10.1109/CVPR.2019.00453</mixed-citation></ref><ref id="hanspub.44148-ref74"><label>74</label><mixed-citation publication-type="other" xlink:type="simple">Park, T., Liu, M.Y., Wang, T.C., et al. (2019) Semantic Image Synthesis with Spatially-Adaptive Normalization. Proceedings of the IEEE Confer-ence on Computer Vision and Pattern Recognition, Long Beach, 15-20 June 2019, 2337-2346. &lt;br&gt;https://doi.org/10.1109/CVPR.2019.00244</mixed-citation></ref></ref-list></back></article>