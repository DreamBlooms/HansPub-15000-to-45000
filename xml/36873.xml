<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">SA</journal-id><journal-title-group><journal-title>Statistics and Application</journal-title></journal-title-group><issn pub-type="epub">2325-2251</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/SA.2020.94059</article-id><article-id pub-id-type="publisher-id">SA-36873</article-id><article-categories><subj-group subj-group-type="heading"><subject>SA20200400000_59468714.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>数学与物理</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于AIC, BIC, CV准则的模型选择
  Model Selection Based on AIC, BIC, CV Criteria
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>王</surname><given-names>俊艳</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib></contrib-group><aff id="aff1"><label>1</label><addr-line>null</addr-line></aff><aff id="aff2"><label>1</label><addr-line>云南财经大学，统计与数学学院，云南 昆明</addr-line></aff><pub-date pub-type="epub"><day>29</day><month>07</month><year>2020</year></pub-date><volume>09</volume><issue>04</issue><fpage>546</fpage><lpage>565</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
  
    众所周知，一个好的模型不仅要具有优良的拟合度，而且还要具有简洁的形式，那么究竟怎样平衡模型的精确度与复杂度呢，这就需要进行模型选择了。而AIC, BIC及CV恰好能平衡模型这种关系，恰好解决了当下模型选择的难题。本文依据AIC, BIC及CV准则来进行模型选择，对WAGE2数据进行建模。首先对12个变量通过简单统计量及其统计作图得到数据的一些分布特征及其相关关系。接着用AIC, BIC及CV来进行统计建模，选出最优模型，并用最小二乘法求得拟合方程，然后进行经济学意义的解释。最后为了让模型的选择更具有说服力，重复1000次实验选出最优模型，与之前的模型进行比较，得到一致最优的模型。
    As we all know, a good model must not only have a good fit, but also have a concise form, so how to balance the accuracy and complexity of the model requires model selection. And AIC, BIC and CV can just balance the relationship of the model, which just solves the problem of current model selection. This article chooses models based on AIC, BIC and CV criteria, and models WAGE2 data. Firstly, some distribution characteristics and correlations of the data are obtained through simple statistics and statistical mapping for the 12 variables. Then, we use AIC, BIC and CV to conduct statistical modeling, select the optimal model, and use least squares method to find the fitting equation, and then explain the economic significance. Finally, in order to make the selection of the model more convincing, the optimal model was selected by repeating 1000 experiments, and compared with the previous model to obtain a consistent optimal model. 
  
 
</p></abstract><kwd-group><kwd>模型选择，精确度，复杂度，AIC，BIC，CV，最小二乘法, Model Selection</kwd><kwd> Accuracy</kwd><kwd> Complexity</kwd><kwd> AIC</kwd><kwd> BIC</kwd><kwd> CV</kwd><kwd> Least Square Method</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>基于AIC, BIC, CV准则的模型选择</title><p>王俊艳</p><p>云南财经大学，统计与数学学院，云南 昆明</p><p>收稿日期：2020年7月13日；录用日期：2020年7月27日；发布日期：2020年8月4日</p><disp-formula id="hanspub.36873-formula51"><graphic xlink:href="//html.hanspub.org/file/7-2580639x5_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>众所周知，一个好的模型不仅要具有优良的拟合度，而且还要具有简洁的形式，那么究竟怎样平衡模型的精确度与复杂度呢，这就需要进行模型选择了。而AIC, BIC及CV恰好能平衡模型这种关系，恰好解决了当下模型选择的难题。本文依据AIC, BIC及CV准则来进行模型选择，对WAGE2数据进行建模。首先对12个变量通过简单统计量及其统计作图得到数据的一些分布特征及其相关关系。接着用AIC, BIC及CV来进行统计建模，选出最优模型，并用最小二乘法求得拟合方程，然后进行经济学意义的解释。最后为了让模型的选择更具有说服力，重复1000次实验选出最优模型，与之前的模型进行比较，得到一致最优的模型。</p><p>关键词 :模型选择，精确度，复杂度，AIC，BIC，CV，最小二乘法</p><disp-formula id="hanspub.36873-formula52"><graphic xlink:href="//html.hanspub.org/file/7-2580639x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2020 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/7-2580639x7_hanspub.png" /> <img src="//html.hanspub.org/file/7-2580639x8_hanspub.png" /></p></sec><sec id="s3"><title>1. 绪论</title><sec id="s3_1"><title>1.1. 研究背景及意义</title><p>随着社会科学的发展，模型选择是很多研究学者讨论的一个重要话题，究竟应该怎样评判一个模型的好坏呢，它的拟合优度及其参数选择怎样才更合理呢，这是一个值得研究与探索的问题。</p><p>模型选择一定伴随着参数估计的问题，有很多学者采用极大似然函数作为目标函数，这也是评判拟合优度的一个标准。为了提高模型的精度，我们可以选用较多的训练样本，但是，一般情况下，模型精度的提高伴随着另一个问题就是模型的复杂度变大了，为此，就可能出现另外一种结果，出现过度拟合的情况，因此，对于模型的选择是一个迫切需要研究的课题，要怎样在模型的精确度与复杂度之间平衡呢？AIC, BIC [<xref ref-type="bibr" rid="hanspub.36873-ref1">1</xref>] 及其CV [<xref ref-type="bibr" rid="hanspub.36873-ref3">3</xref>] 在这方面就很好的平衡了这两者之间的关系，而本文就依托这三个模型选择的准则来选择最优模型。</p></sec><sec id="s3_2"><title>1.2. 文献综述</title><p>关于模型识别国内外有很多学者做了相关研究，特别是关于AIC, BIC准则的模型识别。</p><p>YUHONG YANG [<xref ref-type="bibr" rid="hanspub.36873-ref1">1</xref>] 在AIC和BIC的优势可以共享吗？模型辨识与回归估计的关系这篇文章中提出在模型选择中，BIC在选择真模型时是一致的，AIC在估计回归函数时是最优的极大极小率。最近的一个发展方向是自适应模型选择，与AIC和BIC相比，惩罚项是数据相关的。在自适应模型选择的支持下，已经取得了一些理论和实证结果，但目前还不清楚它是否能真正共享AIC和BIC模型的结合或平均的强度，已引起越来越多的关注，这是克服模型选择不确定性的一种方法，贝叶斯模型平均值是否是估计模型的最佳方法？最小极大意义上的回归函数？我们发现，这些问题的答案基本上是否定的：对于任何一个模型选择准则都是一致的，它必须表现出次优的行为来估计覆盖率极小极大值项下的回归函数；而贝叶斯模型平均不能成为回归估计的极小极大值。Cheryl J. Flynn [<xref ref-type="bibr" rid="hanspub.36873-ref2">2</xref>] 在规范化参数选择的效率——误判模式的惩罚似然估计这篇文章中提出，在经典回归中，当最大候选模型的维数与样本量之间存在较大的相关性时，AIC往往会选择过于复杂的模型，仿真研究表明，AIC在使用惩罚回归时，会有一些缺点。因此，提出了使用经典校正AIC(AICC)作为替代方案，并证明它保持了所需的渐近性质。Jun Shao [<xref ref-type="bibr" rid="hanspub.36873-ref3">3</xref>] 在交叉验证发的线性模型的选择这篇文章中提出可以通过使用遗漏n交叉验证，可以纠正遗漏1交叉验证的一致性，并且给出了使用遗漏交叉验证方法的动机、理由和一些实用性的讨论，并给出了仿真研究的结果。</p></sec><sec id="s3_3"><title>1.3. 研究问题概述</title><p>本文主要的研究问题有5个：</p><p>1)：对给出的12个变量进行描述性的统计分析；</p><p>2)：依托全部数据用AIC, BIC, CV准则从12个模型中选出最优模型；</p><p>3)：对最优模型用最小二乘法进行拟合，求得参数，获得模型的方程。</p><p>4)：对所获得的最优方程进行经济学意义的解释。</p><p>5)：重复进行1000次实验，把数据分为训练集与测试集，用AIC, BIC, CV来进行模型选择，选出最优模型。</p></sec><sec id="s3_4"><title>1.4. 研究思路和行文框架</title><p>本文的研究思路是先对对数据进行描述性统计分析，然后再利用AIC, BIC及CV准则来进行模型选择。</p><p>本文具体的行文安排如下：第一章绪论部分，从模型选择的研究意义出发说明研究本文的必要性，然后分析了模型选择的研究现状，并给出本文的研究思路及行文框架。第二章主要是相关知识准备，主要包括AIC, BIC及CV的简介原理及其实现步骤。第三章是对数据进行描述性的统计分析。第四章主要依托第二章的相关知识用AIC, BIC及CV这三个准则进行模型选择。先用这三个准则进行模型选择，接着再用最小二乘法对最优模型进行拟合，求得参数，获得最优方程，并且对最优方程进行经济学解释。最后，为了让结果更具有说服力，重复进行1000次实验，来选出最优模型。第五章为研究结论，主要是针对本文所做的分析做一个总结。</p></sec></sec><sec id="s4"><title>2. 相关知识准备</title><sec id="s4_1"><title>2.1. AIC, BIC, CV的简介与原理</title><p>1) AIC的简介及原理</p><p>AIC是赤池信息准则的简称，是日本的一个统计学家赤池宏次提出的，它的用途是衡量统计模型拟合度是否优良，对多个模型做出选择判别。不仅如此，它在估计模型的复杂度方面也有很大的用途。AIC准则主要在熵的基础上建立的，一般情况下，认为AIC越小，所对应的模型拟合度越好，模型越精确。 [<xref ref-type="bibr" rid="hanspub.36873-ref4">4</xref>]</p><p>AIC的一般表达式为：</p><p>AIC = ( 2 k − 2 L ) / n (1)</p><p>k表示的是模型中参数的个数，L表示的是对数似然函数，n是样本量。</p><p>我们要想选取AIC最小的那个模型，需要做到两点：</p><p>一是要提高极大似然函数的拟合度，即提高模型的拟合度。</p><p>二是：要降低过度拟合的可能性，这就需要加入惩罚项，使模型的参数尽可能少。</p><p>显然，AIC准则在合理控制了参数的同时也使得似然函数尽可能大，模型的拟合度尽可能高。</p><p>特别注意的是AIC的使用条件一定是在误差项服从正太分布的情况下。</p><p>2) BIC的简介及原理</p><p>BIC是贝叶斯信息准则的简称，是Schwarz提出的，它与AIC准则相似，也是用于模型选择。当增加参数k的数量时，就增加了模型的复杂度，似然函数也会增大，与AIC相似，也易导致过度拟合的现象。针对此现象，AIC, BIC的处理方式相似，都引入了与参数相关的惩罚项，但是BIC的惩罚项会更大一点相对AIC而言，因此，考虑了样本量，样本量较大时，就有效的解决了由于模型精度过高导致的复杂度也较高的问题。</p><p>BIC的一般表达式为：</p><p>BIC = k ln ( n ) − 2 ln ( L ) (2)</p><p>k表示的是模型中参数的个数，L表示的是对数似然函数，n是样本量， k ln ( n ) 表示惩罚项。</p><p>3) CV的简介及原理</p><p>CV是交叉验证法的简称，它也是一种分类的统计分析方法，它的基本思想是对原始的数据集分组为两部分，训练集与验证集。先对训练集进行训练，然后再用验证集对训练的模型进行测试，进一步进行分类评价。</p><p>最常见的CV方法主要有2种：</p><p>a) 一种是将原始数据进行分组，将其中的一组数据作为验证，其余的K-1组作为训练集，这样就可以得到k个模型，一般情况k大于2，分类结果还是相对有效的。</p><p>b) 另外一种方法与第一种方法的不同是将每个样本都做一次验证集，剩下的全部样本作为训练集，假设有n个样本，则共有n个模型。最终可以取分类准确率的平均数来作为分类的性能指标。几乎用上了所有样本作为训练集，最接近原始的样本，几乎没有信息损失，结果更为可靠，这种方法更受欢迎。</p><p>本文的CV方法采用的就是第二种方法。</p></sec><sec id="s4_2"><title>2.2. AIC, BIC, CV的实现步骤</title><p>1) AIC, BIC模型的实现步骤</p><p>a) 计算总体的概率密度。假设 y i , i = 1 , ⋯ , n ，是来自总体<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/7-2580639x13_hanspub.png" xlink:type="simple"/></inline-formula>的样本。</p><p>y i = X i β + ε i (3)</p><p>其中 y i ~ N ( X ′ i , σ 2 ) ， ε i ~ i i d N ( 0 , σ 2 )</p><p>若 y i 的密度函数为</p><p>f ( y i | β , σ 2 ) = 1 2 π σ 2 exp ( − ( y i − X ′ i β ) 2 2 σ 2 ) (4)</p><p>则似然函数为</p><p>L = f ( y | β , σ 2 ) = ∏ 1 n f ( y i | β , σ 2 ) = ∏ i = 1 n { 1 2 π σ 2 exp ( − ( y i − X ′ i β ) 2 2 σ 2 ) } (5)</p><p>b) 计算对数似然函数。对数似然函数为</p><p>ln L = − n 2 ln ( 2 π ) − n 2 ln ( σ 2 ) − { ∑ i = 1 n ( y i − X ′ i β ) 2 2 σ 2 } (6)</p><p>c) 求出参数 σ 2 的极大似然估计</p><p>σ ^ 2 = ∑ i = 1 n ( y i − X ′ i β ) 2 n (7)</p><p>d) 计算 β 的最小二乘估计</p><p>在正太分布的情况， β 的极大似然估计与最小二乘估计无大的区别。在本文中用的是最小二乘估计。</p><p>β ^ = ( X ′ X ) − 1 X ′ y (8)</p><p>e) 计算AIC与BIC。将计算得到的参数估计值代入计算AIC, BIC</p><p>A I C = − 2 L ( β ^ , σ ^ 2 | Y ) + 2 ( p + 1 ) (9)</p><p>B I C = − 2 L ( β ^ , σ ^ 2 | Y ) + ( p + 1 ) ln ( n ) (10)</p><p>其中p表示的是参数的数目，n表示的是总的样本量。</p><p>2) CV模型的实现步骤</p><p>设总的数据的样本书目为n， y i 为因变量， x i 为自变量，用CV来选择模型。</p><p>第一步：删除 ( x 1 , y 1 ) ，用 ( x 2 , y 2 ) , ⋯ , ( x n , y n ) 作为训练集，用最小二乘法来做参数估计。</p><p>β ^ [ − 1 ] = ( X ′ X ) − 1 X ′ y (11)</p><p>其中 β ^ [ − 1 ] 表示已经去除了第一个样本的参数估计值。预测误差为 ( y 1 − x ′ 1 β ^ [ − 1 ] ) 2 。</p><p>第二步：删除<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/7-2580639x36_hanspub.png" xlink:type="simple"/></inline-formula>，用 ( x 1 , y 1 ) , ( x 3 , y 3 ) , ⋯ , ( x n , y n ) 作为训练集，用最小二乘法来做参数估计。</p><p>β ^ [ − 2 ] = ( X ′ X ) − 1 X ′ y (12)</p><p>其中 β ^ [ − 2 ] 表示已经去除了第二个样本的参数估计值。</p><p>预测误差为 ( y 2 − x ′ 2 β ^ [ − 2 ] ) 2 。</p><p>第三步往后，依次删除一个样本，用这个删除的样本作为测试集，用剩下的样本来做参数估计，并求得预测误差。</p><p>最后一步：删除 ( x n , y n ) ，用 ( x 1 , y 1 ) , ⋯ , ( x n − 1 , y n − 1 ) 作为训练集，用最小二乘法来做参数估计。</p><p>β ^ [ − n ] = ( X ′ X ) − 1 X ′ y (13)</p><p>其中 β ^ [ − 2 ] 表示已经去除了第二个样本的参数估计值。</p><p>预测误差为 ( y n − x ′ n β ^ [ − n ] ) 2</p><p>总共进行了n次，则有n个预测误差。</p><p>计算累加的误差之和。</p><p>CV = ∑ 1 n ( y i − x ′ i β ^ [ − i ] ) 2 (14)</p><p>则CV就是当前模型的误差。</p><p>如果有k个模型，只需要比较这k个CV值，选择最小CV值对应的模型就是最优的模型。</p></sec></sec><sec id="s5"><title>3. 对数据的描述性统计分析</title><sec id="s6_0_1"><title>3.1. 数据准备</title><p>本文的数据来源于WAGE2，共有935个样本，12个变量，本文主要对这12个变量进行数据分析，变量说明如下表1。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Description of variables in wage</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >y</th><th align="center" valign="middle" >x1</th><th align="center" valign="middle" >x2</th><th align="center" valign="middle" >x3</th><th align="center" valign="middle" >x4</th><th align="center" valign="middle" >x5</th></tr></thead><tr><td align="center" valign="middle" >lwage</td><td align="center" valign="middle" >hours</td><td align="center" valign="middle" >IQ</td><td align="center" valign="middle" >KWW</td><td align="center" valign="middle" >educ</td><td align="center" valign="middle" >exper</td></tr><tr><td align="center" valign="middle" >x6</td><td align="center" valign="middle" >x7</td><td align="center" valign="middle" >x8</td><td align="center" valign="middle" >x9</td><td align="center" valign="middle" >x10</td><td align="center" valign="middle" >x11</td></tr><tr><td align="center" valign="middle" >tenure</td><td align="center" valign="middle" >age</td><td align="center" valign="middle" >married</td><td align="center" valign="middle" >black</td><td align="center" valign="middle" >south</td><td align="center" valign="middle" >urban</td></tr></tbody></table></table-wrap><p>表1. WAGE2中的变量说明</p></sec><sec id="s6_1"><title>3.2. 统计特征</title><p>运用MATLAB来进行统计分析，运行代码，得到的统计结果如下表2~5，代码见附录1。</p><p>1) 平均值</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> Average values of variables in wage</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >y</th><th align="center" valign="middle" >x1</th><th align="center" valign="middle" >x2</th><th align="center" valign="middle" >x3</th><th align="center" valign="middle" >x4</th><th align="center" valign="middle" >x5</th><th align="center" valign="middle" >x6</th><th align="center" valign="middle" >x7</th><th align="center" valign="middle" >x8</th><th align="center" valign="middle" >x9</th><th align="center" valign="middle" >x10</th><th align="center" valign="middle" >x11</th></tr></thead><tr><td align="center" valign="middle" >6.779</td><td align="center" valign="middle" >43.929</td><td align="center" valign="middle" >101.28</td><td align="center" valign="middle" >35.744</td><td align="center" valign="middle" >13.468</td><td align="center" valign="middle" >11.564</td><td align="center" valign="middle" >7.2342</td><td align="center" valign="middle" >33.08</td><td align="center" valign="middle" >0.893</td><td align="center" valign="middle" >0.1283</td><td align="center" valign="middle" >0.3412</td><td align="center" valign="middle" >0.7176</td></tr></tbody></table></table-wrap><p>表2. WAGE2中的变量的平均值</p><p>2) 中位数</p><table-wrap id="table3" ><label><xref ref-type="table" rid="table3">Table 3</xref></label><caption><title> Median of variables in wage</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >y</th><th align="center" valign="middle" >x1</th><th align="center" valign="middle" >x2</th><th align="center" valign="middle" >x3</th><th align="center" valign="middle" >x4</th><th align="center" valign="middle" >x5</th><th align="center" valign="middle" >x6</th><th align="center" valign="middle" >x7</th><th align="center" valign="middle" >x8</th><th align="center" valign="middle" >x9</th><th align="center" valign="middle" >x10</th><th align="center" valign="middle" >x11</th></tr></thead><tr><td align="center" valign="middle" >6.8079</td><td align="center" valign="middle" >40</td><td align="center" valign="middle" >102</td><td align="center" valign="middle" >37</td><td align="center" valign="middle" >12</td><td align="center" valign="middle" >11</td><td align="center" valign="middle" >7</td><td align="center" valign="middle" >33</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >1</td></tr></tbody></table></table-wrap><p>表3. WAGE2中的变量的中位数</p><p>3) 众数</p><table-wrap id="table4" ><label><xref ref-type="table" rid="table4">Table 4</xref></label><caption><title> Modes of variables in wage</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >y</th><th align="center" valign="middle" >x1</th><th align="center" valign="middle" >x2</th><th align="center" valign="middle" >x3</th><th align="center" valign="middle" >x4</th><th align="center" valign="middle" >x5</th><th align="center" valign="middle" >x6</th><th align="center" valign="middle" >x7</th><th align="center" valign="middle" >x8</th><th align="center" valign="middle" >x9</th><th align="center" valign="middle" >x10</th><th align="center" valign="middle" >x11</th></tr></thead><tr><td align="center" valign="middle" >6.9078</td><td align="center" valign="middle" >40</td><td align="center" valign="middle" >96</td><td align="center" valign="middle" >38</td><td align="center" valign="middle" >12</td><td align="center" valign="middle" >11</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >30</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >1</td></tr></tbody></table></table-wrap><p>表4. WAGE2中的变量的众数</p><p>4) 方差</p><table-wrap id="table5" ><label><xref ref-type="table" rid="table5">Table 5</xref></label><caption><title> Variance of variables in wage</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >y</th><th align="center" valign="middle" >x1</th><th align="center" valign="middle" >x2</th><th align="center" valign="middle" >x3</th><th align="center" valign="middle" >x4</th><th align="center" valign="middle" >x5</th><th align="center" valign="middle" >x6</th><th align="center" valign="middle" >x7</th><th align="center" valign="middle" >x8</th><th align="center" valign="middle" >x9</th><th align="center" valign="middle" >x10</th><th align="center" valign="middle" >x11</th></tr></thead><tr><td align="center" valign="middle" >0.1774</td><td align="center" valign="middle" >52.19</td><td align="center" valign="middle" >226.58</td><td align="center" valign="middle" >58.351</td><td align="center" valign="middle" >4.8253</td><td align="center" valign="middle" >19.137</td><td align="center" valign="middle" >25.758</td><td align="center" valign="middle" >9.6584</td><td align="center" valign="middle" >0.0956</td><td align="center" valign="middle" >0.112</td><td align="center" valign="middle" >0.225</td><td align="center" valign="middle" >0.2028</td></tr></tbody></table></table-wrap><p>表5. WAGE2中的变量的方差</p><p>通过(1) (2) (3) (4)平均数，中位数，众数，与方差的数据特征，我们可以发现，y，x4，x8，x9，x10，x11的数据方差比较小，说明数据分布是较为集中的，它们的中位数与众数都是几乎相同的，说明在中位数附近的数据是较为集中的。</p><p>5) 图1是12个变量的相关系数矩阵</p><p>图1. WAGE2中的变量的相关系数</p><p>由12个变量的相关系数图可以看出，对数工资y与变量x1，x9，x10成反比，与x2，x3，x4，x5，x6，x7，x8，x11成正比，其中与x2的相关性最大，其相关系数为0.3148，说明了对数工资与智商之间的相关性最强。</p></sec><sec id="s6_2"><title>3.3. 统计作图</title><p>通过统计作图可以直观的发现数据特征，运用MATLAB画图，得到的统计结果如下，代码见附录2。</p><p>1) 12个变量的盒形图，见图2。</p><p>图2. WAGE2中的变量的盒形图</p><p>上图盒形图更加直观的体现了数据的集中于分散程度，还提供了上四分位数，中位数，下四分位数的信息，能够跟家直观的反应统计特征信息。例如从上图可以观察到变量y与x8，x9，x10，x11的数据都是较为集中，并且还可以根据分位点，中位数来判断数据的分布情况。</p><p>2) 样本概率图形。</p><p>对y这个变量做概率图形，由前面的概率特征可知，平均值为6.779众数为6.9078。我们想要求得对数工资y在区间[6, 7.5]概率，如下图3结果。</p><p>图3. 对数工资的样本概率图形</p><p>可以直观的发现对数工资y在区间[6, 7.5]概率是92.4%，这说明的大多数数据都集中在6到7.5这个区间，只有极小部分不在这个区间。也可以类似的去查看其他变量的数据分布所占比例。</p></sec></sec><sec id="s7"><title>4. AIC, BIC, CV模型选择与分析</title><sec id="s7_1"><title>4.1. 问题回顾</title><p>本章用线性模型研究“对数薪水”和其他协变量之间的关系，考虑12个带有嵌套结构的备选模型</p><p>模型1： y i = β 0 + ε i ， ε i ~ i i d N ( 0 , σ 2 )</p><p>模型2： y i = β 0 + β 1 x i + ε i ，<inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/7-2580639x53_hanspub.png" xlink:type="simple"/></inline-formula></p><p>………</p><p>模型12： y i = β 0 + β 1 x i + ⋯ + β 11 x 11 ε i ， ε i ~ i i d N ( 0 , σ 2 )</p><p>旨在用AIC, BIC, CV来从这12个模型中选择合适的模型，更好的解释对数薪水与其他协变量之间的关系，其中的变量说明见表1。</p></sec><sec id="s7_2"><title>4.2. 对WAGE2中的全部数据来进行模型选择</title><p>1) 本节目的：依托WAGE2中所有的935个数据，使用CV，AIC和BIC，从上述12个备选模型里选择合适的模型。</p><p>2) 根据2.2节AIC, BIC模型的实现步骤先对全部数据进行模型选择，运行MATLAB代码，见附录3，可以得到AIC, BIC选择模型的结果。</p><p>结果如下表6。</p><table-wrap id="table6" ><label><xref ref-type="table" rid="table6">Table 6</xref></label><caption><title> AIC values of 12 model</title></caption><table><tbody><thead><tr><th align="center" valign="middle"  colspan="12"  >12个模型的AIC</th></tr></thead><tr><td align="center" valign="middle" >MODEL1</td><td align="center" valign="middle" >MODEL2</td><td align="center" valign="middle" >MODEL3</td><td align="center" valign="middle" >MODEL4</td><td align="center" valign="middle" >MODEL5</td><td align="center" valign="middle" >MODEL6</td><td align="center" valign="middle" >MODEL7</td><td align="center" valign="middle" >MODEL8</td><td align="center" valign="middle" >MODEL9</td><td align="center" valign="middle" >MODEL10</td><td align="center" valign="middle" >MODEL11</td><td align="center" valign="middle" >MODEL12</td></tr><tr><td align="center" valign="middle" >1039.3</td><td align="center" valign="middle" >1039.2</td><td align="center" valign="middle" >940.51</td><td align="center" valign="middle" >899.48</td><td align="center" valign="middle" >880.18</td><td align="center" valign="middle" >859.21</td><td align="center" valign="middle" >842.4</td><td align="center" valign="middle" >843.43</td><td align="center" valign="middle" >823.75</td><td align="center" valign="middle" >814.16</td><td align="center" valign="middle" >800.79</td><td align="center" valign="middle" >759.2700765</td></tr></tbody></table></table-wrap><p>表6. 12个模型的AIC值</p><p>其中最小的AIC的值为759.2700765，对应的模型为12，故有AIC准则确定最优的模型应该为第12个。</p><table-wrap id="table7" ><label><xref ref-type="table" rid="table7">Table 7</xref></label><caption><title> BIC values of 12 model</title></caption><table><tbody><thead><tr><th align="center" valign="middle"  colspan="12"  >12个模型的BIC</th></tr></thead><tr><td align="center" valign="middle" >MODEL1</td><td align="center" valign="middle" >MODEL2</td><td align="center" valign="middle" >MODEL3</td><td align="center" valign="middle" >MODEL4</td><td align="center" valign="middle" >MODEL5</td><td align="center" valign="middle" >MODEL6</td><td align="center" valign="middle" >MODEL7</td><td align="center" valign="middle" >MODEL8</td><td align="center" valign="middle" >MODEL9</td><td align="center" valign="middle" >MODEL10</td><td align="center" valign="middle" >MODEL11</td><td align="center" valign="middle" >MODEL12</td></tr><tr><td align="center" valign="middle" >1049</td><td align="center" valign="middle" >1053.7</td><td align="center" valign="middle" >959.87</td><td align="center" valign="middle" >923.68</td><td align="center" valign="middle" >909.23</td><td align="center" valign="middle" >893.09</td><td align="center" valign="middle" >881.13</td><td align="center" valign="middle" >887</td><td align="center" valign="middle" >872.16</td><td align="center" valign="middle" >867.4</td><td align="center" valign="middle" >858.87</td><td align="center" valign="middle" >822.1971814</td></tr></tbody></table></table-wrap><p>表7. 12个模型的BIC值</p><p>由表7知，其中最小的BIC的值为822.1971814，对应的模型为12，故由BIC准则确定最优的模型也是第12个。</p><p>3) 用CV来对全部数据处理，选出最优的模型。</p><p>用935个数据，每次抽出一行作为验证集，剩下的934个样本作为训练集，总共需要进行935次，运行MATLAB代码得到如下次结果，代码见附录4。</p><p>将CV记作12个模型935次预测误差求和，则最小的CV值就对应最优的模型。</p><table-wrap id="table8" ><label><xref ref-type="table" rid="table8">Table 8</xref></label><caption><title> CV values of 12 model</title></caption><table><tbody><thead><tr><th align="center" valign="middle"  colspan="12"  >12个模型的CV(935次的预测误差求和)</th></tr></thead><tr><td align="center" valign="middle" >MODEL1</td><td align="center" valign="middle" >MODEL2</td><td align="center" valign="middle" >MODEL3</td><td align="center" valign="middle" >MODEL4</td><td align="center" valign="middle" >MODEL5</td><td align="center" valign="middle" >MODEL6</td><td align="center" valign="middle" >MODEL7</td><td align="center" valign="middle" >MODEL8</td><td align="center" valign="middle" >MODEL9</td><td align="center" valign="middle" >MODEL10</td><td align="center" valign="middle" >MODEL11</td><td align="center" valign="middle" >MODEL12</td></tr><tr><td align="center" valign="middle" >166.01</td><td align="center" valign="middle" >166.14</td><td align="center" valign="middle" >149.5</td><td align="center" valign="middle" >143.1</td><td align="center" valign="middle" >140.21</td><td align="center" valign="middle" >137.11</td><td align="center" valign="middle" >134.71</td><td align="center" valign="middle" >134.87</td><td align="center" valign="middle" >132.06</td><td align="center" valign="middle" >130.7</td><td align="center" valign="middle" >128.87</td><td align="center" valign="middle" >123.2714065</td></tr></tbody></table></table-wrap><p>表8. 12个模型的CV值</p><p>由上表8的结果知，最小的CV值为123,2714065，对应的模型为第12个，故由CV的判别准则第12个模型是最优的。</p><p>综上：AIC, BIC, CV这三个判别准则所选的模型都是第12个模型，所以第12个模型就是最优模型。</p><p>4) 用最小二乘法对第12个模型进行拟合，运行MATLAB代码，见附录5，加结果如下：</p><p>第12个模型中y与x的散点图如下图4。</p><p>图4. 第12个模型的散点图</p><p>最小二乘估计的参数结果如下表9。</p><table-wrap id="table9" ><label><xref ref-type="table" rid="table9">Table 9</xref></label><caption><title> CV values of 12 model</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >β 0</th><th align="center" valign="middle" >β 1</th><th align="center" valign="middle" ><inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/7-2580639x59_hanspub.png" xlink:type="simple"/></inline-formula></th><th align="center" valign="middle" >β 3</th><th align="center" valign="middle" >β 4</th><th align="center" valign="middle" >β 5</th><th align="center" valign="middle" >β 6</th><th align="center" valign="middle" >β 7</th><th align="center" valign="middle" >β 8</th><th align="center" valign="middle" >β 9</th><th align="center" valign="middle" >β 10</th><th align="center" valign="middle" >β 11</th></tr></thead><tr><td align="center" valign="middle" >5.2797</td><td align="center" valign="middle" >−0.006</td><td align="center" valign="middle" >0.0033</td><td align="center" valign="middle" >0.0035</td><td align="center" valign="middle" >0.0492</td><td align="center" valign="middle" >0.0105</td><td align="center" valign="middle" >0.01</td><td align="center" valign="middle" >0.0054</td><td align="center" valign="middle" >0.195</td><td align="center" valign="middle" >−0.142</td><td align="center" valign="middle" >−0.081</td><td align="center" valign="middle" >0.1775</td></tr></tbody></table></table-wrap><p>表9. 12个模型的CV值</p><p>第12个模型拟合的方程如下</p><p>y = 5.2797 − 0.006 x 1 + 0.0033 x 2 + 0.0035 x 3 + 0.0492 x 4 + 0.0105 x 5 + 0.01 x 6     + 0.0054 x 7 + 0.195 x 8 − 0.142 x 9 − 0.081 x 10 + 0.1775 x 11</p></sec><sec id="s7_3"><title>4.3. 经济学原理对4.2的结果进行解释</title><p>由4.2的结果知，AIC, BIC与CV所选的模型都为第12个模型，且由最小二乘估计得到了第12个模型的拟合的方程</p><p>y = 5.2797 − 0.006 x 1 + 0.0033 x 2 + 0.0035 x 3 + 0.0492 x 4 + 0.0105 x 5 + 0.01 x 6     + 0.0054 x 7 + 0.195 x 8 − 0.142 x 9 − 0.081 x 10 + 0.1775 x 11</p><p>我们发现，</p><p>1) y与变量x1的系数为负值，说明lwage与hours是成反比的关系，hours每减少1个单位，lwage增加0.006个单位，说明了现代社会对效率的要求越来越高，效率越高，报酬越多；</p><p>2) y与变量x2的系数为正值，说明lwage与IQ是成正比关系，说明智商每增加一个单位，对数工资就增加0.0033个单位，同时也说明了智商高的人获得的工资报酬就越高；</p><p>3) y与变量x3的系数为正值，说明lwage与kww是成正比关系，说明世界工作知识得分每增加一个单位，对数工资就增加0.0035个单位；</p><p>4) y与变量x4的系数为正值，说明lwage与educ是成正比关系，说明教育每增加一个单位，对数工资就增加0.0492个单位；</p><p>5) y与变量x5的系数为正值，说明lwage与exper是成正比关系，说明工作经验每增加一个单位，对数工资就增加0.0105个单位。</p><p>6) y与变量x6的系数为正值，说明lwage与enure是成正比关系，说明与现任雇主共事年限每增加一个单位，对数工资就增加0.01个单位。</p><p>7) y与变量x7的系数为正值，说明lwage与age是成正比关系，说明在一定的年龄范围内，年龄每增加一个单位，对数工资就增加0.0054个单位。因为在一定年龄范围内，年龄大的人相对来讲工作经验会多一点，知识储备会多一些，所以获得的工资报酬也会相对的高一些。</p><p>8) y与变量x8的系数为正值，说明lwage与married是成正比关系，说明已婚每增加一个单位，对数工资就增加0.195个单位。</p><p>9) y与变量x9的系数为负值，说明lwage与black是成反比关系，说明黑人获得的工资会更少一些，同时也说明了现代社会依然存在着种族歧视。</p><p>10) y与变量x10的系数为负值，说明lwage与south是成反比关系，说明越靠近南边，工资越少，因为当前全球区域经济发展不平衡，例如南非，经济发展落后，所以工资报酬会更低一点。</p><p>11) y与变量x11的系数为正值，说明lwage与urban是成正比关系，说明了生活在标准城市统计区的人工资报酬会更高一点。因为标准城市区域经济会相对发达一点，所以工资报酬会相对较高一点。</p></sec><sec id="s7_4"><title>4.4. 将WAGE2的数据分为训练集与测试集，重新进行模型选择</title><p>在4.2节中，我们只对模型进行了一次选择，并不很具有说服力，所以在本小节，我们对模型重复进行1000次选择，采用随机抽样的方法将数据集随机地分为训练集(500个样本)和测试集(435个样本)，依托训练集，使用CV，AIC和BIC，从12个备选模型里选择模型，并用选出的模型预测测试集里的测试样本，考察预测误差评价CV，AIC和BIC三种模型选择准则中哪种准则的表现最好。</p><p>运行MATLAB代码，得到结果，代码见附录6。</p><p>1) 图5是12个模型与运行1000次得到的AIC，维度为12行1000列。由于空间有限，仅显示部分结果。</p><p>图5. 运行1000次得到的AIC值</p><p>可以发现，1000次运行结果中都是第12个模型的AIC的值最小，故选择第12个模型为最优模型。</p><p>下图是最小AIC对应模型的预测误差(即第12个模型的预测误差)，因为重复进行1000次，故有1000个预测误差，空间有限仅显示前10次的结果，见表10。</p><table-wrap id="table10" ><label><xref ref-type="table" rid="table1">Table 1</xref>0</label><caption><title> Prediction error of corresponding model for minimum AI</title></caption><table><tbody><thead><tr><th align="center" valign="middle"  colspan="10"  >最小AIC对应模型的预测误差(即第12个模型的预测误差)</th></tr></thead><tr><td align="center" valign="middle" >第1次</td><td align="center" valign="middle" >第2次</td><td align="center" valign="middle" >第3次</td><td align="center" valign="middle" >第4次</td><td align="center" valign="middle" >第5次</td><td align="center" valign="middle" >第6次</td><td align="center" valign="middle" >第7次</td><td align="center" valign="middle" >第8次</td><td align="center" valign="middle" >第9次</td><td align="center" valign="middle" >第10次</td></tr><tr><td align="center" valign="middle" >0.12283</td><td align="center" valign="middle" >0.12899</td><td align="center" valign="middle" >0.13141</td><td align="center" valign="middle" >0.13486</td><td align="center" valign="middle" >0.12908</td><td align="center" valign="middle" >0.14693</td><td align="center" valign="middle" >0.13845</td><td align="center" valign="middle" >0.1344</td><td align="center" valign="middle" >0.12962</td><td align="center" valign="middle" >0.11813</td></tr></tbody></table></table-wrap><p>表10. 最小AIC对应模型的预测误差</p><p>2) 下图是12个模型与运行1000次得到的BIC，也仅展示部分结果，见图6。</p><p>图6. 运行1000次得到的BIC值</p><p>同样可以发现，1000次运行结果中都是第12个模型的BIC的值最小，故选择第12个模型为最优模型。</p><p>下图是最小BIC对应模型的预测误差(即第12个模型的预测误差)，因为重复进行1000次，故有1000个预测误差，空间有限仅显示前10次的结果，见表11。</p><table-wrap id="table11" ><label><xref ref-type="table" rid="table1">Table 1</xref>1</label><caption><title> Prediction error of minimum BIC corresponding mode</title></caption><table><tbody><thead><tr><th align="center" valign="middle"  colspan="10"  >最小BIC对应模型的预测误差(即第12个模型的预测误差)</th></tr></thead><tr><td align="center" valign="middle" >第1次</td><td align="center" valign="middle" >第2次</td><td align="center" valign="middle" >第3次</td><td align="center" valign="middle" >第4次</td><td align="center" valign="middle" >第5次</td><td align="center" valign="middle" >第6次</td><td align="center" valign="middle" >第7次</td><td align="center" valign="middle" >第8次</td><td align="center" valign="middle" >第9次</td><td align="center" valign="middle" >第10次</td></tr><tr><td align="center" valign="middle" >0.122830573</td><td align="center" valign="middle" >0.128987541</td><td align="center" valign="middle" >0.131413267</td><td align="center" valign="middle" >0.134855128</td><td align="center" valign="middle" >0.129082835</td><td align="center" valign="middle" >0.146934749</td><td align="center" valign="middle" >0.138448017</td><td align="center" valign="middle" >0.134397175</td><td align="center" valign="middle" >0.129622311</td><td align="center" valign="middle" >0.118126556</td></tr></tbody></table></table-wrap><p>表11. 最小BIC对应模型的预测误差</p><p>3) 下图是CV运行1000次得到的预测误差，共12行1000列，篇幅限制，仅展示部分结果，见图7。</p><p>图7. 运行1000次CV的预测误差</p><p>下图是1000次中每次选中的模型，篇幅限制，仅展示部分结果，见表12。</p><table-wrap id="table12" ><label><xref ref-type="table" rid="table1">Table 1</xref>2</label><caption><title> Optimal model for each selection in 1000 time</title></caption><table><tbody><thead><tr><th align="center" valign="middle"  colspan="10"  >1000次中每次选中的最优模型</th></tr></thead><tr><td align="center" valign="middle" >第1次</td><td align="center" valign="middle" >第2次</td><td align="center" valign="middle" >第3次</td><td align="center" valign="middle" >第4次</td><td align="center" valign="middle" >第5次</td><td align="center" valign="middle" >第6次</td><td align="center" valign="middle" >第7次</td><td align="center" valign="middle" >第8次</td><td align="center" valign="middle" >第9次</td><td align="center" valign="middle" >第10次</td></tr><tr><td align="center" valign="middle" >7</td><td align="center" valign="middle" >11</td><td align="center" valign="middle" >4</td><td align="center" valign="middle" >6</td><td align="center" valign="middle" >7</td><td align="center" valign="middle" >12</td><td align="center" valign="middle" >12</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >3</td><td align="center" valign="middle" >12</td></tr></tbody></table></table-wrap><p>表12. 1000次中每次选中的最优模型</p><p>下图是1000次中每个模型被选中的概率。</p><table-wrap id="table13" ><label><xref ref-type="table" rid="table1">Table 1</xref>3</label><caption><title> Proportion of each model selected in 1000 time</title></caption><table><tbody><thead><tr><th align="center" valign="middle"  colspan="12"  >1000次中每个模型被选中的比例</th></tr></thead><tr><td align="center" valign="middle" >MODEL1</td><td align="center" valign="middle" >MODEL2</td><td align="center" valign="middle" >MODEL3</td><td align="center" valign="middle" >MODEL4</td><td align="center" valign="middle" >MODEL5</td><td align="center" valign="middle" >MODEL6</td><td align="center" valign="middle" >MODEL7</td><td align="center" valign="middle" >MODEL8</td><td align="center" valign="middle" >MODEL9</td><td align="center" valign="middle" >MODEL10</td><td align="center" valign="middle" >MODEL11</td><td align="center" valign="middle" >MODEL12</td></tr><tr><td align="center" valign="middle" >0.114</td><td align="center" valign="middle" >0.093</td><td align="center" valign="middle" >0.111</td><td align="center" valign="middle" >0.088</td><td align="center" valign="middle" >0.052</td><td align="center" valign="middle" >0.062</td><td align="center" valign="middle" >0.043</td><td align="center" valign="middle" >0.038</td><td align="center" valign="middle" >0.036</td><td align="center" valign="middle" >0.042</td><td align="center" valign="middle" >0.093</td><td align="center" valign="middle" >0.228</td></tr></tbody></table></table-wrap><p>表13. 1000次中每个模型被选中的比例</p><p>由表13，可以发现第12个模型被选中的比例最高，为22.8%，其他模型被选中的比例明显都比较小，所以CV模型选中的依然是第12个模型。</p><p>综上：AIC, BIC, CV三个模型选出的全部为第12个模型最优，故认为第12个模型为最优的模型。</p></sec></sec><sec id="s8"><title>5. 研究结论</title><p>依托前面的知识准备，通过第三章的描述性统计分析，可以清楚直观的看到数据的分布特征及其变量的相关关系。然后在第四章用AIC, BIC, CV准则依托全部数据来进行模型选择，最后3个准则选出的最优模型均为第12个模型，故此，对第12个模型用最小二乘法进行了拟合，求得参数，得到方程，进而用经济学原理对求得的第12个模型进行解释。但是考虑到一次实验结果并不是十分具有说服力，因此，又将实验重复1000次，再次看模型选择的结果，结果发现AIC, BIC在这1000次实验中一致选择的是第12个模型，而CV选择的模型依概率算是占比最高的，为22.8%，说明在1000次实验中，选择第12个模型的次数占228次。而选择其他模型的比例最高占据11.4%，故此一致认为第12个模型是最优的。</p></sec><sec id="s9"><title>文章引用</title><p>王俊艳. 基于AIC, BIC, CV准则的模型选择Model Selection Based on AIC, BIC, CV Criteria[J]. 统计学与应用, 2020, 09(04): 546-565. https://doi.org/10.12677/SA.2020.94059</p></sec><sec id="s10"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.36873-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Yang, Y. (2005) Can the Strengths of AIC and BIC Be Shared? A Conflict between Model Indentification and Regression Estimation. Biometrika, 92, 937-950. https://doi.org/10.1093/biomet/92.4.937</mixed-citation></ref><ref id="hanspub.36873-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Flynn, C.J., Hurvich, C.M. and Simonoff, J.S. (2013) Efficiency for Regularization Parameter Selection in Penalized Likelihood Estimation of Misspecified Models. Journal of the American Statistical Association, 108, 1031-1043. 
https://doi.org/10.1080/01621459.2013.801775</mixed-citation></ref><ref id="hanspub.36873-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Shao, J. (1993) Linear Model Selection by Cross-Validation. Journal of the American statistical Association, 88, 486-494. https://doi.org/10.1080/01621459.1993.10476299</mixed-citation></ref><ref id="hanspub.36873-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">https://blog.csdn.net/qq_30142403/article/details/80457050</mixed-citation></ref></ref-list></back></article>