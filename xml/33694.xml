<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">JISP</journal-id><journal-title-group><journal-title>Journal of Image and Signal Processing</journal-title></journal-title-group><issn pub-type="epub">2325-6753</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/JISP.2020.91004</article-id><article-id pub-id-type="publisher-id">JISP-33694</article-id><article-categories><subj-group subj-group-type="heading"><subject>JISP20200100000_23050405.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  一种改善人脸识别效率的快速筛选方法研究
  Study on the Faster Novel Screening Technology for Improving the Efficiency of Face Recognition
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>徐</surname><given-names>建亮</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>魏</surname><given-names>小华</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>方</surname><given-names>坤礼</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>刘</surname><given-names>文军</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>衢州职业技术学院，浙江 衢州</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>02</day><month>12</month><year>2019</year></pub-date><volume>09</volume><issue>01</issue><fpage>27</fpage><lpage>35</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
  
    人脸识别是一种重要的身份鉴别技术，具有广泛的应用前景。目前，如何使人脸识别系统具有快速且准确的识别效果是值得研究的方向，通过局部显著的特征和有效减少比对次数的分类方法为解决上述问题的方案。现今人脸识别系统多为提取整个人脸图像特征，接着逐一与数据库中的图像进行比对，以获得识别结果。在本文中，提出一种筛选技术，能有效避免比对特征过大和比对次数过多的问题，为了设计出最佳的筛选技术，以变异数分析探讨局部显著特征对识别率的影响，以获得最佳的筛选技术流程。结果显示所提出的筛选技术与原始系统相比，在Extended Yale Face Database B与MECL人脸数据库当中，不仅具有相同的识别率，在识别时间上更提升了105.8%与50%的效率。故证实筛选技术不仅拥有相同的识别效果，还能大幅的降低识别时间。
    Face recognition is an important identification technology and has a wide application prospect. Nowadays, how to make the face recognition faster and more accurate is one of the pursuing targets in this field. The target can be achieved through a local significant feature and effectively reducing the number of comparisons. Currently, most of the face recognition methods are used to extract the features of the entire face image, and through one-by-one comparisons with the images in the database to obtain final results. In this study, a screening technique is proposed that can effectively improve the defects of over-compared features and excessive comparing times. In order to design this screening technology, the influence of locally significant features on the recognition rate is explored by using variance analysis to obtain the optimal screening technology process. The studied results show that to compare with the current methods, the proposed technology not only can maintain the same recognition rate, but also can improve the recognition efficiencies upon 115.5% and 52.9% on the recognition time subject to the face databases of Extended Yale Face Database B and MECL, respectively. 
  
 
</p></abstract><kwd-group><kwd>人脸侦测，人脸识别，筛选技术，变异分析, Face Detection</kwd><kwd> Face Recognition</kwd><kwd> Screening Technology</kwd><kwd> Mutation Analysis</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>一种改善人脸识别效率的快速筛选方法研究<sup> </sup></title><p>徐建亮，魏小华，方坤礼，刘文军</p><p>衢州职业技术学院，浙江 衢州</p><p>收稿日期：2019年12月5日；录用日期：2019年12月23日；发布日期：2019年12月30日</p><disp-formula id="hanspub.33694-formula50"><graphic xlink:href="//html.hanspub.org/file/4-2670213x5_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>人脸识别是一种重要的身份鉴别技术，具有广泛的应用前景。目前，如何使人脸识别系统具有快速且准确的识别效果是值得研究的方向，通过局部显著的特征和有效减少比对次数的分类方法为解决上述问题的方案。现今人脸识别系统多为提取整个人脸图像特征，接着逐一与数据库中的图像进行比对，以获得识别结果。在本文中，提出一种筛选技术，能有效避免比对特征过大和比对次数过多的问题，为了设计出最佳的筛选技术，以变异数分析探讨局部显著特征对识别率的影响，以获得最佳的筛选技术流程。结果显示所提出的筛选技术与原始系统相比，在Extended Yale Face Database B与MECL人脸数据库当中，不仅具有相同的识别率，在识别时间上更提升了105.8%与50%的效率。故证实筛选技术不仅拥有相同的识别效果，还能大幅的降低识别时间。</p><p>关键词 :人脸侦测，人脸识别，筛选技术，变异分析</p><disp-formula id="hanspub.33694-formula51"><graphic xlink:href="//html.hanspub.org/file/4-2670213x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2020 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/4-2670213x7_hanspub.png" /> <img src="//html.hanspub.org/file/4-2670213x8_hanspub.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>2002年汤姆克鲁斯主演的电影《关键报告》中，街头识别系统随时扫描识别过往路人身份的情节，正逐渐在你我的生活中上演。由于人脸识别具备远距离运作非接触式的特性，为人带来的便利更胜于其它生物识别技术，举凡阿汤哥电影《不可能的任务》中的虹膜识别，或是警方办案常使用的指纹识别等，因此，当其技术藩篱被突破时，随之而来的应用不计其数。根据知名市场研究公司MarketsandMarkets推估，人脸识别市场产值在五年内可望以13.9%的年均复合增长率(Compound Average Growth Rate, CAGR)成长，由2017年的40.5亿美元跃升至2022年的77.6亿美元。</p><p>近年来人脸识别技术 [<xref ref-type="bibr" rid="hanspub.33694-ref1">1</xref>] [<xref ref-type="bibr" rid="hanspub.33694-ref2">2</xref>] [<xref ref-type="bibr" rid="hanspub.33694-ref3">3</xref>] [<xref ref-type="bibr" rid="hanspub.33694-ref4">4</xref>] [<xref ref-type="bibr" rid="hanspub.33694-ref5">5</xref>] 的进展有赖于深度学习技术的突破，2014年香港中文大学宣布其人脸验证系统通过深度学习模型强大的计算和学习能力大幅提升脸部识别准确性，在国际知名的人脸数据库LFW逾千组不同光暗、表情及拍摄角度的脸部照片上准确率高达99.15%，首次超越人类肉眼识别的准确度，2015年，百度同样利用深度学习技术 [<xref ref-type="bibr" rid="hanspub.33694-ref6">6</xref>]，将人脸验证系统准确率推升至99.7%，逼近LFW数据库的极限。为了能够衡量人脸识别模型的能力，2016年华盛顿大学提出了MegaFace公开数据库，提供实验者仿真数据库存有一百万张人脸时的识别效果，大幅提高了识别的难度，此时(2016年末)仅有少数几个如Google等顶尖组织的识别率能够达到70%。时至2018年4月，依据官方记录，已有数十个组织得以跨越70%水平，微软中国必应实验室的数据为83.758%，若进一步将肇因于MegaFace数据库本身错误状况予以剔除，准确率更高达98.998%，显示当今人脸识别技术已可挑战百万等级的用户规模。人脸识别技术的发展并不仅局限于算法等软件层面，2019年9月，苹果召开新品发表大会，新一代旗舰机iPhoneX11问世，人脸识别成功进军到智能型手持装置，成为新时代解锁选项。有别于传统使用的光学摄影机，iPhoneX11使用其顶部一小块约0.5公分区域，由前置镜头、红外线镜头、泛光感应组件及点阵投影仪等零件所组成的深度镜头系统进行人脸识别，藉由非可见光扫描人脸的3D几何结构，将身份破解率从Touch ID指纹的五万分之一降至百万分之一。观察2018年世界行动通讯大会(MWC)，3D感测技术已被产业界广泛采用，诸多厂商如三星、Nokia、Sony、华硕等非苹果阵营相继推出3D感测机种。根据科技市场调查机构Counterpoint预测，2020年将有超过10亿支智能手机导入脸部解锁，其60%会采用3D技术 [<xref ref-type="bibr" rid="hanspub.33694-ref7">7</xref>]。</p><p>人脸识别逐渐移往终端设备恰巧符合当今边缘运算、甚至行动边缘运算的潮流，过去受限于终端设备的运算能力不足，数据必须回传至后端系统才能进行处理，如今，随着AI加速芯片的发展，终端设备就具备复杂运算的能力。在更多终端设备能够支持人脸识别及万物联网的环境下，未来数年势必还会有更多元丰富的人脸识别应用相继推出。</p></sec><sec id="s4"><title>2. 人脸识别系统</title><p>人脸识别系统主要目的为辨别人脸图像与数据库中的哪个人脸图像相同，在分类的过程中会因比对特征的大小以及特征比对次数的多寡，造成识别速度缓慢。因此，为了有效提升识别速度的效率并拥有准确的识别效果，本文将以原始的人脸识别系统作为基础，设计一利用脸部五官特征眼睛、鼻子和嘴巴作为识别特征，并依序以五官特征进行分类筛选的筛选技术，以减少分类过程所需的时间。</p><p>本文使用Xiaoyang Tan等人 [<xref ref-type="bibr" rid="hanspub.33694-ref8">8</xref>] 在2010年所提出的预处理方法，以消除图像受照明的影响，再以局部二值模式(LBP)对五官进行特征提取，并与数据库中的人脸图像特征进行相似度计算，最后使用最近邻分类器与所设计的筛选技术进行分类，以获得识别结果。</p><p>研究主要目的为，如何以较为显着的特征进行识别，且有效减少特征比对次数以提升识别系统的效率，研究中使用MATLAB进行模拟。为探讨筛选技术对人脸识别系统的识别时间的状况，在整个实验过程中使用MATLAB软件仿真原始的人脸识别系统的识别情形。为了探讨脸部五官特征眼睛、鼻子和嘴巴对识别率的影响，将使用SPSS进行变异数分析(ANOVA)，探讨眼睛、鼻子和嘴巴之间，何者具有较为显着性的影响，并作为筛选技术的设计参考，以设计出最佳的筛选技术。最后一样使用MATALB模拟平台来了解识别率与识别时间的结果。图1显示人脸识别流程。</p><p>图1. 人脸识别流程</p></sec><sec id="s5"><title>3. 人脸数据库介绍</title><sec id="s5_1"><title>3.1. Extended Yale Face Database B</title><p>Extended Yale Face Database B是由38个人在64个不同照明条件下拍摄9种姿势而成，并且通过光源方向与中心相机轴之间的角度(12˚，25˚，50˚，77˚，90˚)将数据库分为5个子集，共2414张图像。本文采用数据库中每个人的第一张人脸图像作为等待比对的人脸数据库，共38张图像，并将子集1~3的所有正面图像作为测试图像，共1174张图像。</p></sec><sec id="s5_2"><title>3.2. 自制人脸数据库</title><p>自制人脸数据库是由5位实验室同学，经由每个同学表现出不同的脸部样貌分别拍摄出10张人脸图像，共50张所组合而成，并将此人脸数据库命名为机电整合(Mechatronic Laboratory, MECL)人脸数据库。本文采用每个人的第一张正面图像作为训练图像，共5张，并将所有人脸图像作为测试图像，共50张。</p></sec></sec><sec id="s6"><title>4. MATLAB识别系统建立</title><sec id="s6_1"><title>4.1. 实验设备</title><p>本文所使用的实验设备是Win10操作系统，详细规格如表1所示。然而，人脸识别系统中的预处理、识别率与识别时间都是通过MATLAB R2018b进行实验模拟，识别率与识别时间都分别进行10次的实验模拟，并取其平均值以作为最后实验模拟结果。</p></sec><sec id="s6_2"><title>4.2. 预处理</title><p>本文所使用的预处理是由三个步骤所组成，分别为伽玛校正、高斯差分滤波与对比均衡，经过预处理能有效改善照明所产生的阴影与亮光，并保留人脸图像中的特征。图2为预处理流程。</p><p>图2. 图像预处理流程</p><p>伽玛校正是一种非线性的亮度反映曲线，而γ是改善图像亮度的主要参数。当γ = 1，图像亮度相同；当γ &lt; 1，图像亮度会偏亮；当γ &gt; 1，图像亮度会偏暗。本文是以γ = 0.2作为默认值。高斯差分滤波是经由两个不同大小高斯核 σ 的高斯滤波器进行相减而得。图像以不同大小的高斯滤波器进行滤波，将产生不同程度的模糊图像，最后以两个不同程度的模糊图像进行相减，即可得到高斯差分滤波图像。本文是以 σ 1 = 1.0 、 σ 2 = 2.0 作为默认值，对比均衡是对图像整体强度进行些微的调整，能使图像的特征更加明显，Xiaoyang Tan等人 [<xref ref-type="bibr" rid="hanspub.33694-ref4">4</xref>] 提出了两个简单快速的方法，如公式(1)与公式(2)。在此α作为压缩因子，减少图像中受大值所影响， τ 是消除大值的阀值。</p><p>I ( x , y ) ← I ( x , y ) ( m e a n ( | I ( x ′ , y ′ ) | ) α ) 1 / α (1)</p><p>I ( x , y ) ← I ( x , y ) ( m e a n ( min τ | I ( x ′ , y ′ ) | ) α ) 1 / α (2)</p><p>图像经由上述的处理已经得到相当显着的特征，但仍然具有极端值。为了避免特征提取中产生不必要的麻烦，最后使用双曲正切函数(hyperbolic tangent)来压缩图像中过大的值，如公式(3)。本实验设定 α = 0.1 、 τ = 10 作为默认值。</p><p>I ( x , y ) ← τ tanh ( I ( x , y ) τ ) (3)</p><p>经过整个预处理链后，可发现原始图像受阴影所遮蔽的部分得到了大幅度的改善，凸显出图像重要的五官特征。图3为预处理的效果。</p><p>图3. 预处理的效果(左)原始图像(右)预处理后图像</p></sec><sec id="s6_3"><title>4.3. 特征提取</title><p>局部二值模式(LBP)是由Ojala等人 [<xref ref-type="bibr" rid="hanspub.33694-ref9">9</xref>] 所提出，用来描述图像特征且计算简单复杂度较低。原始的LBP是以3 &#215; 3方形区域中，将中心像素作为阀值并与相邻的八个像素进行比较，当大于阀值则将其设定为1，否则将其设定为0，因此，形成一个二进制数。图4为LBP运算方式。</p><p>图4. LBP运算方式</p><p>原始的LBP被局限于3 &#215; 3方形区域中，难以表现出完整的图像特征，为了改善此问题圆形LBP被提出，以圆形区域取代原始的方形区域，使原本3 &#215; 3的区域扩展至任何区域。而圆形LBP可经由不同的圆形半径R与取样点数量P，表现图像不同大小的纹路特征。</p><p>经由上述得知圆形LBP是通过不同的圆形半径R与取样点数量P产生2𝑃种LBP模式，经发现若取样点数量增加，LBP模式将伴随大幅度上升。因此，Ojala等人提出了等价模式(Uniform Pattern)对此问题进行改善，而经实验发现LBP二进制数大部分仅包含两次从0至1或1至0的转变，所以定义：当LBP二进制模式从0至1或1至0的转变最多只有两次时，将该LBP二进制模式作为一个等价模式种类。如图5特征提取流程图。</p><p>图5. 特征提取</p></sec><sec id="s6_4"><title>4.4. 变异数分析</title><p>实验中通过Extended Yale Face Database B作为分析数据库，探讨人脸五官特征与识别率的影响，并找出具显着性的特征，以运用于所提出的筛选技术。由于五官特征包含着眼睛、鼻子和嘴巴等较为显着的特征，故本文为了探讨以五官特征(眼睛、鼻子、嘴巴)对识别率是否造成影响。根据研究目的，进而提出研究假设(Hypothesis)，H1：特征对识别率有显着的影响。</p><p>首先，将数据库的子集1至子集3中将36个人的人脸图像作为分析对象，且每人拥有31张图像，并将分析对象分为3个组别分别是以眼睛、鼻子和嘴巴等不同特征作为识别特征以计算识别率，识别率定义如公式(4)所示。</p><p>识别率 = (正确识别图像数量/图像总数)∗100% (4)</p><p>然而使用单因子变异数来分析特征对识别率是否有着显着差异，分析结果如表1~4所示。由表3，变异数同构型检定发现其显着性为0.000小于所设定的阀值0.05，故三种样本的变异性为不同质且存在着显着性差异。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Variance with configuration check (features</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >Levene统计量</th><th align="center" valign="middle" >自由度1</th><th align="center" valign="middle" >自由度2</th><th align="center" valign="middle" >显着性</th></tr></thead><tr><td align="center" valign="middle" >9.915</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >33</td><td align="center" valign="middle" >0.000</td></tr></tbody></table></table-wrap><p>表1. 变异数同构型检定(特征)</p><p>经由表2，单因子变异数分析发现其显着性为0.019小于所设定的阀值0.05，因此，判定人脸五官特征的眼睛、鼻子和嘴巴存在着显着性差异。</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> One-way anova (features</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >来源</th><th align="center" valign="middle" >自由度</th><th align="center" valign="middle" >平方和</th><th align="center" valign="middle" >均方和</th><th align="center" valign="middle" >F值</th><th align="center" valign="middle" >显着性</th></tr></thead><tr><td align="center" valign="middle" >组间</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >2036</td><td align="center" valign="middle" >1017.8</td><td align="center" valign="middle" >4.46</td><td align="center" valign="middle" >0.019</td></tr><tr><td align="center" valign="middle" >组内</td><td align="center" valign="middle" >33</td><td align="center" valign="middle" >7356</td><td align="center" valign="middle" >228.4</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td></tr><tr><td align="center" valign="middle" >总和</td><td align="center" valign="middle" >35</td><td align="center" valign="middle" >9572</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td></tr></tbody></table></table-wrap><p>表2. 单因子变异数分析(特征)</p><p>经由上述单因子变异数分析结果为具有显着性差异，且变异数同构型检定为不同质，故选用Games-Howell多重比较以判断特征之间何者具有显着性差异。通过表3，Games-Howell多重比较与表4，叙述性统计分析可得知，眼睛的识别率(97.848%)与鼻子的识别率(79.568%)其显着性为0.024小于0.05，故具有显着性差异；眼睛的识别率(97.848%)与嘴巴的识别率(86.747%)其显着性为0.095，故没有显着性差异；鼻子的识别率(79.568%)与嘴巴的识别率(86.747%)其显着性为0.611大于0.05，故没有显着性差异。因此，可以推断脸部特征的显着性顺序为眼睛、嘴巴和鼻子。</p><table-wrap id="table3" ><label><xref ref-type="table" rid="table3">Table 3</xref></label><caption><title> Games-Howell multiple compariso</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle"  colspan="4"  >平均值差异</th><th align="center" valign="middle"  colspan="4"  >95%信赖区间</th></tr></thead><tr><td align="center" valign="middle"  rowspan="7"  >Games-Howell检定</td><td align="center" valign="middle" >(I)特征</td><td align="center" valign="middle" >(J)特征</td><td align="center" valign="middle" >(I-J)</td><td align="center" valign="middle"  colspan="2"  >标准差</td><td align="center" valign="middle" >显着性</td><td align="center" valign="middle" >下限</td><td align="center" valign="middle" >上限</td></tr><tr><td align="center" valign="middle" >眼睛</td><td align="center" valign="middle" >鼻子</td><td align="center" valign="middle" >18.28<sup>*</sup></td><td align="center" valign="middle"  colspan="2"  >5.89</td><td align="center" valign="middle" >0.024</td><td align="center" valign="middle" >2.55</td><td align="center" valign="middle" >34.16</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >嘴巴</td><td align="center" valign="middle" >11.10</td><td align="center" valign="middle"  colspan="2"  >4.83</td><td align="center" valign="middle" >0.095</td><td align="center" valign="middle" >−1.80</td><td align="center" valign="middle" >24.01</td></tr><tr><td align="center" valign="middle" >鼻子</td><td align="center" valign="middle" >眼睛</td><td align="center" valign="middle" >−18.28<sup>*</sup></td><td align="center" valign="middle"  colspan="2"  >5.89</td><td align="center" valign="middle" >0.024</td><td align="center" valign="middle" >−34.06</td><td align="center" valign="middle" >−2.60</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >嘴巴</td><td align="center" valign="middle" >−7.19</td><td align="center" valign="middle"  colspan="2"  >7.50</td><td align="center" valign="middle" >0.611</td><td align="center" valign="middle" >−26.07</td><td align="center" valign="middle" >11.72</td></tr><tr><td align="center" valign="middle" >嘴巴</td><td align="center" valign="middle" >眼睛</td><td align="center" valign="middle" >−11.10</td><td align="center" valign="middle"  colspan="2"  >4.83</td><td align="center" valign="middle" >0.095</td><td align="center" valign="middle" >−24.01</td><td align="center" valign="middle" >1.90</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >鼻子</td><td align="center" valign="middle" >7.18</td><td align="center" valign="middle"  colspan="2"  >7.50</td><td align="center" valign="middle" >0.611</td><td align="center" valign="middle" >−11.72</td><td align="center" valign="middle" >26.07</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td></tr></tbody></table></table-wrap><p>表3. Games-Howell多重比较</p><table-wrap id="table4" ><label><xref ref-type="table" rid="table4">Table 4</xref></label><caption><title> Descriptive statistical analysis (features</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >来源</th><th align="center" valign="middle" >数量</th><th align="center" valign="middle" >平均值</th><th align="center" valign="middle" >标准偏差</th><th align="center" valign="middle" >下限</th><th align="center" valign="middle" >上限</th><th align="center" valign="middle" >最小值</th><th align="center" valign="middle" >最大值</th></tr></thead><tr><td align="center" valign="middle" >眼睛</td><td align="center" valign="middle" >15</td><td align="center" valign="middle" >97.85</td><td align="center" valign="middle" >3.18</td><td align="center" valign="middle" >95.83</td><td align="center" valign="middle" >99.88</td><td align="center" valign="middle" >90.32</td><td align="center" valign="middle" >100</td></tr><tr><td align="center" valign="middle" >鼻子</td><td align="center" valign="middle" >15</td><td align="center" valign="middle" >79.57</td><td align="center" valign="middle" >20.15</td><td align="center" valign="middle" >66.76</td><td align="center" valign="middle" >92.37</td><td align="center" valign="middle" >41.94</td><td align="center" valign="middle" >96.77</td></tr><tr><td align="center" valign="middle" >嘴巴</td><td align="center" valign="middle" >15</td><td align="center" valign="middle" >86.75</td><td align="center" valign="middle" >16.42</td><td align="center" valign="middle" >76.32</td><td align="center" valign="middle" >97.18</td><td align="center" valign="middle" >54.84</td><td align="center" valign="middle" >100</td></tr><tr><td align="center" valign="middle" >合计</td><td align="center" valign="middle" >45</td><td align="center" valign="middle" >88.05</td><td align="center" valign="middle" >16.54</td><td align="center" valign="middle" >82.45</td><td align="center" valign="middle" >93.65</td><td align="center" valign="middle" >41.94</td><td align="center" valign="middle" >100</td></tr></tbody></table></table-wrap><p>表4. 叙述性统计分析(特征)</p></sec><sec id="s6_5"><title>4.5. 分类识别</title><p>实验中将待识别人脸图像进行预处理并提取五官LBP特征，便将待识别人脸五官特征与数据库中的五官LBP特征进行距离相似度计算，并使用K最近邻(KNN)分类器和所提出的筛选技术进行分类识别，以取得最后的识别结果。KNN是一种无须事先训练且易于理解实现的方法，通过将待分类图像与已知图像逐一进行距离相似度计算，并选取K个与待分类图像最相近的图像进行类别探讨，以获得分类结果。本文是以卡方距离作为距离相似度的计算方式，如公式(5)所示，若两张图像的卡方距离越小，代表两张图像的相似度越高，反之，若两张图像的卡方距离越大，代表两张图像的相似度越低。</p><p>χ 2 ( p , q ) = ∑ i ( p i − q i ) 2 ( p i + q i ) (5)</p><p>通过变异数分析的结果，得知脸部特征的显著性顺序为眼睛、嘴巴和鼻子。因此，筛选技术会先进行眼睛距离计算，并设定眼睛距离允许误差(𝑆𝑒,𝑡)作为阀值，当数据库中的图像与待识别图像的眼睛距离小于𝑆𝑒,𝑡，则将眼睛距离小于𝑆𝑒,𝑡的图像继续进行嘴巴距离计算，并设定嘴巴距离允许误差(𝑆𝑚,𝑡)作为阀值，若经眼睛筛选后的图像嘴巴距离依然小于𝑆𝑚,𝑡，则进行最后的鼻子距离计算，以找出距离最近的人脸图像，若途中图像眼睛或嘴巴距离大于𝑆𝑒,𝑡或𝑆𝑚,𝑡，则判定为不相似不继续进行计算，详细流程如图八所示。根据图6的筛选技术流程以MATLAB进行人脸识别系统流程仿真，可以得知在Extended Yale Face Database B数据库中，使用筛选技术的识别率为96.85%与识别时间为0.016秒，相较于原始系统的识别率96.85%与识别时间0.035秒，在识别时间上有效的提升105.8%的效率。然而，在MECL人脸数据库中，使用筛选技术的识别率为100%与识别时间为0.027秒，相较于原始系统的识别率100%与识别时间0.018秒，在识别时间上有效的提升50%的效率。</p><p>图6. 筛选技术流程</p><table-wrap id="table5" ><label><xref ref-type="table" rid="table5">Table 5</xref></label><caption><title> Screening technology promote efficienc</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >方法</th><th align="center" valign="middle" >原始系统</th><th align="center" valign="middle" >筛选技术</th><th align="center" valign="middle" >提升效率(%)</th></tr></thead><tr><td align="center" valign="middle" >Extended Yale Face Database B</td><td align="center" valign="middle" >0.035</td><td align="center" valign="middle" >0.017</td><td align="center" valign="middle" >105.8</td></tr><tr><td align="center" valign="middle" >MECL</td><td align="center" valign="middle" >0.027</td><td align="center" valign="middle" >0.018</td><td align="center" valign="middle" >50</td></tr></tbody></table></table-wrap><p>表5. 筛选技术的提升效率</p></sec></sec><sec id="s7"><title>5. 结论</title><p>本文提出一种筛选技术运用于人脸识别系统，是以变异数分析作为其筛选技术的依据，并通过MATLAB软件作为仿真平台。原始系统在Extended Yale Face Database B和MECL人脸数据库当中，所需的识别时间为0.034秒以及0.026秒，而筛选技术仅需要0.016秒以及0.017秒，如表5所示，故可以证明筛选技术比原始系统更具有优势。</p></sec><sec id="s8"><title>致谢</title><p>衷心地感谢本文所引用的这些优秀文章的作者，他们的文章提供很大的帮助；同时也感谢衢州职业技术学院提供了一个研究创作的卓越平台。</p></sec><sec id="s9"><title>基金项目</title><p>诚挚地感谢衢州科技计划项目(No2018k25)和教育厅一般科研项目(Y201839845)赞助该项课题。</p></sec><sec id="s10"><title>文章引用</title><p>徐建亮,魏小华,方坤礼,刘文军. 一种改善人脸识别效率的快速筛选方法研究Study on the Faster Novel Screening Technology for Improving the Efficiency of Face Recognition[J]. 图像与信号处理, 2020, 09(01): 27-35. https://doi.org/10.12677/JISP.2020.91004</p></sec><sec id="s11"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.33694-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">(2017) Facial Recognition Market by Component (Soft ware Tools and Services), Technology, Use Case (Emotion Recognition, Attendance Tracking and Monitoring, Access Control, Law Enforcement), End-User, and Region-Global Forecast to 2022. https://www.marketsandmarkets.com/</mixed-citation></ref><ref id="hanspub.33694-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Kaya, Y., Kayci, L. and Uyar, M. (2015) Automatic Identification of Butterfly Species Based on Local Binary Patterns and Artificial Neural Network. Applied Soft Computing, 28, 132-137. https://doi.org/10.1016/j.asoc.2014.11.046</mixed-citation></ref><ref id="hanspub.33694-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Tang, Z., Su, Y.C., Er, M.J., Qi, F., Zhang, L. and Zhou, J.Y. (2015) A Local Binary Pattern Based Texture Descriptors for Classification of Tea Leaves. Neurocomputing, 168, 1011-1023. https://doi.org/10.1016/j.neucom.2015.05.024</mixed-citation></ref><ref id="hanspub.33694-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Zhang, Y. and Hua, C.J. (2015) Driver Fatigue Recognition Based on Facial Expression Analysis Using Local Binary Patterns. Optik, 126, 4501-4505. https://doi.org/10.1016/j.ijleo.2015.08.185</mixed-citation></ref><ref id="hanspub.33694-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Alelaiwi, A., Abdul, W., Solaiman Dewan, M., Migdadi, M. and Muhammed, G. (2016) Steerable Pyramid Transform and Local Binary Pattern Based Robust Face Recognition for E-Health Secured Login. Computers and Electrical Engineering, 53, 435-443. https://doi.org/10.1016/j.compeleceng.2016.01.008</mixed-citation></ref><ref id="hanspub.33694-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Huang, G.B., et al. (2008) Labeled Faces in the Wild: A Database for Studying Face Recognition in Unconstrained Environments. Workshop on Faces in Real-Life Images: Detection, Alignment, and Recognition.</mixed-citation></ref><ref id="hanspub.33694-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Ira, K.-S., et al. (2016) The MegaFace Benchmark: 1 Million Faces for Recognition at Scale. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Las Vegas, 27-30 June 2016.</mixed-citation></ref><ref id="hanspub.33694-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Tan, X.Y. and Triggs, B. (2010) Enhanced Local Texture Feature Sets for Face Recognition under Difficult Lighting Conditions. IEEE Transactions on Image Processing, 19, 1635-1650. https://doi.org/10.1109/TIP.2010.2042645</mixed-citation></ref><ref id="hanspub.33694-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Xu, Y., Zhang, Z., Lu, G.M. and Yang, J. (2016) Approximately Symmetrical Face Images for Image Preprocessing in Face Recognition and Sparse Representation Based Classification. Pattern Recognition, 54, 68-82.  
https://doi.org/10.1016/j.patcog.2015.12.017</mixed-citation></ref></ref-list></back></article>