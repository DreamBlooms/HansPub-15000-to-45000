<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">JISP</journal-id><journal-title-group><journal-title>Journal of Image and Signal Processing</journal-title></journal-title-group><issn pub-type="epub">2325-6753</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/JISP.2016.53011</article-id><article-id pub-id-type="publisher-id">JISP-17967</article-id><article-categories><subj-group subj-group-type="heading"><subject>JISP20160300000_29890874.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  利用离散余弦变换与Wallis的人脸光照处理算法
  Face Illumination Processing Using Discrete Cosine Transform and Wallis Algorithm
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>杨</surname><given-names>志军</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>何</surname><given-names>雪</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>熊</surname><given-names>文怡</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>聂</surname><given-names>祥飞</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib></contrib-group><aff id="aff1"><addr-line>重庆三峡学院电子与信息工程学院，重庆</addr-line></aff><aff id="aff2"><addr-line>null</addr-line></aff><author-notes><corresp id="cor1">* E-mail:<email>yangzj158@163.com(杨志)</email>;</corresp></author-notes><pub-date pub-type="epub"><day>12</day><month>07</month><year>2016</year></pub-date><volume>05</volume><issue>03</issue><fpage>81</fpage><lpage>87</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   本文提出了一种基于离散余弦变换与Wallis的人脸光照处理算法，该算法首先将人脸图像变换到对数域，在对数域中计算离散余弦变换(DCT)，舍弃部分低频DCT系数，再计算其离散余弦反变换。然后用Wallis算法对人脸图像的高频部分进行增强。在人脸识别阶段，采用主成分分析法(PCA)提取人脸特征，运用基于余弦距离的最近邻分类器进行分类判别。在Yale B正面人脸库中的实验结果表明，本文提出的方法可以削弱人脸光照的影响，合理选择相关参数，人脸识别率能达到好的效果。 In this paper, a novel approach based on discrete cosine transform (DCT) and Wallis for face illumination is discussed. Firstly, the DCT is calculated in logarithm domain for face image. Some low-frequency coefficients are discarded in zigzag pattern. Secondly, after inverse discrete cosine transform (IDCT), the Wallis algorithm is used to enhance the high-frequency detail of face image. Thirdly, the principal component analysis (PCA) and the nearest neighborhood classifier using cosine distance are adopted for face recognition. The experiment results on Yale B frontal face database demonstrate that the presented algorithm can decrease the influence of face illumination. The face recognition rate has a good effect when some parameters are chosen properly.
    
  
 
</p></abstract><kwd-group><kwd>人脸光照处理，离散余弦变换，Wallis算法，人脸识别, Face Illumination Processing</kwd><kwd> Discrete Cosine Transform</kwd><kwd> Wallis</kwd><kwd> Face Recognition</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>利用离散余弦变换与Wallis的人脸光照处理算法<sup> </sup></title><p>杨志军，何雪，熊文怡，聂祥飞<sup>*</sup></p><p>重庆三峡学院电子与信息工程学院，重庆</p><disp-formula id="hanspub.17967-formula1"><graphic xlink:href="http://html.hanspub.org/file/1-2670083x7_hanspub.png"  xlink:type="simple"/></disp-formula><p>收稿日期：2016年6月19日；录用日期：2016年7月6日；发布日期：2016年7月12日</p><disp-formula id="hanspub.17967-formula2"><graphic xlink:href="http://html.hanspub.org/file/1-2670083x8_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>本文提出了一种基于离散余弦变换与Wallis的人脸光照处理算法，该算法首先将人脸图像变换到对数域，在对数域中计算离散余弦变换(DCT)，舍弃部分低频DCT系数，再计算其离散余弦反变换。然后用Wallis算法对人脸图像的高频部分进行增强。在人脸识别阶段，采用主成分分析法(PCA)提取人脸特征，运用基于余弦距离的最近邻分类器进行分类判别。在Yale B正面人脸库中的实验结果表明，本文提出的方法可以削弱人脸光照的影响，合理选择相关参数，人脸识别率能达到好的效果。</p><p>关键词 :人脸光照处理，离散余弦变换，Wallis算法，人脸识别</p><disp-formula id="hanspub.17967-formula3"><graphic xlink:href="http://html.hanspub.org/file/1-2670083x9_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s3"><title>1. 引言</title><p>光照问题，是人脸识别中面临的主要问题 [<xref ref-type="bibr" rid="hanspub.17967-ref1">1</xref>] - [<xref ref-type="bibr" rid="hanspub.17967-ref3">3</xref>] 。同一人脸因光照变化引起的差异大于不同人脸在相同条件下的差异，针对这个问题提出了许多的人脸光照处理算法，这些算法主要分为三类 [<xref ref-type="bibr" rid="hanspub.17967-ref4">4</xref>] ：提取光照不变特征的方法、预处理和光照归一化的方法、人脸建模的方法。提取光照不变特征方法的原理是提取人脸图像中光照不敏感特征进行人脸判别。例如：Mohsen [<xref ref-type="bibr" rid="hanspub.17967-ref5">5</xref>] 等提出SQI和局部权重二值模式相结合的光照不变性的人脸识别算法，该算法注重人脸图像的局部信息，避免了只考虑全局人脸图像而忽视了局部细节信息。Ramaiah [<xref ref-type="bibr" rid="hanspub.17967-ref6">6</xref>] 等提出利用卷积神经网络进行人脸识别，运用人脸样本训练自动生成神经网络，进行人脸分类，但该方法需要在大样本集上训练以及测试，同时卷积神经网络的训练较复杂，很难把握卷积层和采样层的层数选择。Shermina [<xref ref-type="bibr" rid="hanspub.17967-ref7">7</xref>] 等融合离散余弦变换与主成分分析法的光照不变性人脸识别系统，提取人脸光照不敏感特征。预处理和光照归一化的方法主要应用于人脸图像的预处理阶段，该方法在不使用任何人脸模型与表面信息的条件下改善人脸光照条件。主要方法有直方图均衡、伽玛矫正、对数变换等。该类方法在一定程度上削弱了光照变化对人脸识别的影响，但很难恢复局部阴影区域的人脸特征，特别是对人脸识别具有重要作用的人脸细节特征区域。人脸建模方法的基本原理是在空间的一些适当的子空间或流形去学习人脸图像光照条件变化的程度,如子空间投影法 [<xref ref-type="bibr" rid="hanspub.17967-ref8">8</xref>] 、光照锥法 [<xref ref-type="bibr" rid="hanspub.17967-ref9">9</xref>] 、curvelet局部特征 [<xref ref-type="bibr" rid="hanspub.17967-ref10">10</xref>] 等。这类方法需要大量不同光照条件下的人脸图像作为训练样本，因此在实际应用中受到一定的限制。</p><p>本文提出了一种基于离散余弦变换与Wallis变换的人脸光照处理算法。光照处理流程框图如图1所示，首先将人脸图像变换到对数域，计算人脸图像的离散余弦变换，舍弃部分低频系数，离散余弦反变换后用Wallis算法增强人脸图像的高频成分。本文方法主要将人脸图像的高频成分作为人脸识别的重要元素，其光照处理的效果由识别率表征。</p></sec><sec id="s4"><title>2. 算法介绍</title><sec id="s4_1"><title>2.1. 图像的对数变换</title><p>于任意图像<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2670083x10_hanspub.png" xlink:type="simple"/></inline-formula>，可以看成是反射分量<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2670083x11_hanspub.png" xlink:type="simple"/></inline-formula>和光照分量<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2670083x12_hanspub.png" xlink:type="simple"/></inline-formula>的乘积 [<xref ref-type="bibr" rid="hanspub.17967-ref11">11</xref>] ：</p><disp-formula id="hanspub.17967-formula4"><label>(1)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/1-2670083x13_hanspub.png"  xlink:type="simple"/></disp-formula><p>图1. 人脸图像光照处理流程框图</p><p>其中，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2670083x15_hanspub.png" xlink:type="simple"/></inline-formula>对应图像的快变化部分，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2670083x16_hanspub.png" xlink:type="simple"/></inline-formula>对应图像的慢变化部分。对式(1)两边取对数，得：</p><disp-formula id="hanspub.17967-formula5"><label>(2)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/1-2670083x17_hanspub.png"  xlink:type="simple"/></disp-formula><p>从式(1)和式(2)可以看出，对于时间域的人脸图像，反射分量<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2670083x18_hanspub.png" xlink:type="simple"/></inline-formula>与光照分量<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2670083x19_hanspub.png" xlink:type="simple"/></inline-formula>是相乘的关系，而在对数域中却变成了相加的关系。所以在对数域中对人脸图像进行光照处理即是在对数域中减去光照分量，类似于对图像进行高通滤波。</p></sec><sec id="s4_2"><title>2.2. 图像的离散余弦变换(DCT)</title><p>对于图像而言，其2维DCT [<xref ref-type="bibr" rid="hanspub.17967-ref12">12</xref>] 定义如下：</p><disp-formula id="hanspub.17967-formula6"><label>(3)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/1-2670083x20_hanspub.png"  xlink:type="simple"/></disp-formula><p>反变换定义如下：</p><disp-formula id="hanspub.17967-formula7"><label>(4)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/1-2670083x21_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中</p><disp-formula id="hanspub.17967-formula8"><graphic xlink:href="http://html.hanspub.org/file/1-2670083x22_hanspub.png"  xlink:type="simple"/></disp-formula><p><inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2670083x23_hanspub.png" xlink:type="simple"/></inline-formula>是图像的大小，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2670083x24_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2670083x25_hanspub.png" xlink:type="simple"/></inline-formula>式图像时间域的坐标，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2670083x26_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2670083x27_hanspub.png" xlink:type="simple"/></inline-formula>对应<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2670083x28_hanspub.png" xlink:type="simple"/></inline-formula>系数坐标。</p><p>在式(3)中，当<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2670083x29_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2670083x30_hanspub.png" xlink:type="simple"/></inline-formula>都等于0时，则是(3)可以写为：</p><disp-formula id="hanspub.17967-formula9"><label>(5)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/1-2670083x31_hanspub.png"  xlink:type="simple"/></disp-formula><p><inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2670083x32_hanspub.png" xlink:type="simple"/></inline-formula>变换后，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2670083x33_hanspub.png" xlink:type="simple"/></inline-formula>就是直流系数<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2670083x34_hanspub.png" xlink:type="simple"/></inline-formula>位于<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2670083x35_hanspub.png" xlink:type="simple"/></inline-formula>块DCT系数的左上角，其余的<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2670083x36_hanspub.png" xlink:type="simple"/></inline-formula>个系数的能量分布按Z字型方式依次递减。在本文的实验中，离散余弦变换后，保留直流分量，其余系数从低频到高频按照Z字型方式逐个舍弃。</p></sec><sec id="s4_3"><title>2.3. 图像的Wallis变换</title><p>图像进行Wallis变换时，考虑到人眼的视觉特性中包含对数环节，因此在图像锐化时，首先进行对数变换，可以对暗区的细节进行较好的处理。其计算公式为：</p><disp-formula id="hanspub.17967-formula10"><label>(6)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/1-2670083x37_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2670083x38_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2670083x39_hanspub.png" xlink:type="simple"/></inline-formula>对应原图像，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2670083x40_hanspub.png" xlink:type="simple"/></inline-formula>对应Wallis变换后的图像。<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2670083x41_hanspub.png" xlink:type="simple"/></inline-formula>对应以10为底的对数函数。</p><p>在图像进行Wallis变换时，同时应注意：</p><p>1) 为了防止对0取对数，计算时应为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2670083x42_hanspub.png" xlink:type="simple"/></inline-formula>；</p><p>2) 因为对数值很小(<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2670083x43_hanspub.png" xlink:type="simple"/></inline-formula>)，所以计算时用<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2670083x44_hanspub.png" xlink:type="simple"/></inline-formula>。其中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2670083x45_hanspub.png" xlink:type="simple"/></inline-formula>；</p></sec></sec><sec id="s5"><title>3. 实验</title><sec id="s5_1"><title>3.1. 人脸库介绍</title><p>本文采用Yale B正面人脸库进行实验，该数据库共包含10个人的9种不同姿态，每种姿态又包含64种不同的光照情况。因为本文只研究光照处理的问题，所以实验中只使用正面姿态的人脸图像。人脸图像的尺寸是<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2670083x46_hanspub.png" xlink:type="simple"/></inline-formula>，将所有图像按照入射光的不同角度分为5个子集。</p><p>1) 子集1，角度小于12度(共70个样本)。</p><p>2) 子集2，角度位于13~25度之间(共120个样本)。</p><p>3) 子集3，角度位于26~50度之间(共120个样本)。</p><p>4) 子集4，角度位于51~77度之间(共140个样本)。</p><p>5) 子集5，角度大于77度(共190个样本)。</p><p>人脸光照处理后，规范化其均值和方差分别为0和1，利用主成分分析法(PCA)提取人脸特征(特征向量数<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2670083x47_hanspub.png" xlink:type="simple"/></inline-formula>为50)，使用基于余弦距离的最近邻分类器进行分类判别。</p></sec><sec id="s5_2"><title>3.2. 实验结果</title><p>在Yale B正面人脸库中的实验结果如图2所示。图2显示的是人脸光照处理后的效果对比图，其中(a)列是原图，(b)列是经离散余弦变换单独处理后的人脸图像，(c)列是经Wallis变换单独处理后的人脸图像。(d)列是经本文所提方法处理后的人脸图像。从图2中可以看出，经本文方法处理后的人脸图像，其灰度范围得到很大的调整，对于极端光照的处理效果尤其明显。光照处理完成后，人脸图像不仅保留了重要的人脸识别特征，而且其特征更加明显，如人脸鼻子、嘴巴、眼睛等纹理特征、位置、大小、轮廓等。因此从本文方法光照处理后的人脸图像清晰度可以看出，该光照处理方法对光照具有很好的鲁棒性。</p></sec><sec id="s5_3"><title>3.3. 实验结果对比</title><p>表1中列出了不同YaleB人脸库子集的图像作为训练样本时的最小人脸错误识别率。从表1中可以看出，子集1作为训练样本，DCT舍弃系数个数为15时，平均错误识别率为0.53%。子集2作为训练样本，DCT舍弃系数个数为17时，平均错误识别率为0.19%。子集3作为训练样本，DCT舍弃系数个数为10时，平均错误识别率为0.19%。子集4作为训练样本，DCT舍弃系数个数为16时，平均错误识别率为0。子集5作为训练样本，DCT舍弃系数个数为18时，平均错误识别率为1.33%。从所有子集作为训练集的平均识别率中可以看出，除了子集5的平均识别率稍低，其他子集的识别率都能够达到99%以上，其中子集4作为训练集时，平均识别率达到100%。从子集4和子集5作训练集时的平均识别率可以看出，本文所提方法，在处理光照条件较差时能达到理想的效果，但是在处理极端光照时又存在一定的不足。综合整个人脸识别的识别率来看，本文所提方法的光照处理效果明显。</p><p>表2中列出了部分现有人脸识别算法的人脸平均错误识别率，从表2中可以看出：DCT [<xref ref-type="bibr" rid="hanspub.17967-ref12">12</xref>] 的平均</p><p>图2. 不同方法处理后的人脸图像</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Experiment resul</title></caption><table><tbody><thead><tr><th align="center" valign="middle"  rowspan="2"  >训练组</th><th align="center" valign="middle"  colspan="5"  >人脸错误识别率(%)</th></tr></thead><tr><td align="center" valign="middle"  colspan="5"  >测试组</td></tr><tr><td align="center" valign="middle"  rowspan="2"  >子集1</td><td align="center" valign="middle" >子集2</td><td align="center" valign="middle" >子集3</td><td align="center" valign="middle" >子集4</td><td align="center" valign="middle" >子集5</td><td align="center" valign="middle" >平均</td></tr><tr><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0.71</td><td align="center" valign="middle" >1.05</td><td align="center" valign="middle" >0.53</td></tr><tr><td align="center" valign="middle"  rowspan="2"  >子集2</td><td align="center" valign="middle" >子集1</td><td align="center" valign="middle" >子集3</td><td align="center" valign="middle" >子集4</td><td align="center" valign="middle" >子集5</td><td align="center" valign="middle" >平均</td></tr><tr><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0.71</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0.19</td></tr><tr><td align="center" valign="middle"  rowspan="2"  >子集3</td><td align="center" valign="middle" >子集1</td><td align="center" valign="middle" >子集2</td><td align="center" valign="middle" >子集4</td><td align="center" valign="middle" >子集5</td><td align="center" valign="middle" >平均</td></tr><tr><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0.83</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0.19</td></tr><tr><td align="center" valign="middle"  rowspan="2"  >子集4</td><td align="center" valign="middle" >子集1</td><td align="center" valign="middle" >子集2</td><td align="center" valign="middle" >子集3</td><td align="center" valign="middle" >子集5</td><td align="center" valign="middle" >平均</td></tr><tr><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0</td></tr><tr><td align="center" valign="middle"  rowspan="2"  >子集5</td><td align="center" valign="middle" >子集1</td><td align="center" valign="middle" >子集2</td><td align="center" valign="middle" >子集3</td><td align="center" valign="middle" >子集4</td><td align="center" valign="middle" >平均</td></tr><tr><td align="center" valign="middle" >0</td><td align="center" valign="middle" >4.17</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0.71</td><td align="center" valign="middle" >1.33</td></tr></tbody></table></table-wrap><p>表1. 实验结果</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> Recognition rate comparison with different metho</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >算法</th><th align="center" valign="middle" >DCT</th><th align="center" valign="middle" >OLHE</th><th align="center" valign="middle" >Tan</th><th align="center" valign="middle" >Vu</th><th align="center" valign="middle" >本文算法</th></tr></thead><tr><td align="center" valign="middle" >平均错误率</td><td align="center" valign="middle" >0.55</td><td align="center" valign="middle" >0.9</td><td align="center" valign="middle" >1.94</td><td align="center" valign="middle" >1.75</td><td align="center" valign="middle" >0.45</td></tr></tbody></table></table-wrap><p>表2. 不同方法的人脸错误识别率比较</p><p>错误识别率为0.55%，OLHE [<xref ref-type="bibr" rid="hanspub.17967-ref13">13</xref>] 的平均错误识别率为0.9%，Tan [<xref ref-type="bibr" rid="hanspub.17967-ref14">14</xref>] 的平均错误识别率为1.94%，Vu [<xref ref-type="bibr" rid="hanspub.17967-ref15">15</xref>] 的平均错误识别率为1.75%，本文光照处理后的人脸平均错误识别率为0.45%。因此从人脸平均错误识别率中可以看出，本文的方法在光照处理后的平均错误识别率小于现有的一些光照处理算法的平均错误识别率，即在光照处理性能方面优于现有的一些算法，因此本文所提方法对不同角度的光照具有一定的抑制作用。</p></sec></sec><sec id="s6"><title>4. 总结</title><p>本文提出了一种基于离散余弦变换与Wallis相结合的人脸光照处理，该算法首先将人脸图像变换到对数域，在对数域中计算图像的离散余弦变换，舍弃部分低频系数，离散余弦反变换后用Wallis变换增强人脸图像的高频成分。在人脸分类阶段，提取人脸特征的方法是主成分分析法，分类器采用的是基于余弦距离的最近邻分类器。在Yale B正面人脸库中的实验结果表明，本文所提方法对不同角度的光照具有很好的抑制作用，光照处理后的人脸识别效果优于现有的一些光照处理算法。未来的工作是在更大型的人脸库中测试本算法的有效性。</p></sec><sec id="s7"><title>基金项目</title><p>重庆市教委自然科学基金；基金号：KJ121114。</p></sec><sec id="s8"><title>文章引用</title><p>杨志军,何 雪,熊文怡,聂祥飞. 利用离散余弦变换与Wallis的人脸光照处理算法 Face Illumination Processing Using Discrete Cosine Transform and Wallis Algorithm[J]. 图像与信号处理, 2016, 05(03): 81-87. http://dx.doi.org/10.12677/JISP.2016.53011</p></sec><sec id="s9"><title>参考文献 (References)</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.17967-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Ochoa-Villegas, M.A., Nolazco-Flores, J.A., Barron-Cano, O., et al. (2015) Addressing the Illumination Challenge in Two-Dimensional Face Recognition: A Survey. IET Computer Vision, 9, 978-992.  
http://dx.doi.org/10.1049/iet-cvi.2014.0086</mixed-citation></ref><ref id="hanspub.17967-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Kaymak, Ç., Sarıcı, R. and Uçar, A. (2015) Illumination Invariant Face Recognition Using Principal Component Analysis—An Overview. Machine Vision and Mechatronics in Practice. Springer Berlin Heidelberg, 269-285.</mixed-citation></ref><ref id="hanspub.17967-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Pai, A.G., Fernandes, S.L., Nayak, K., et al. (2015) Recognizing Human Faces under Varying Degree of Illumination: A Comprehensive Survey. International Conference on Electronics and Communication Systems. IEEE, Coimbatore, 26-27 February 2015, 577-582.</mixed-citation></ref><ref id="hanspub.17967-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Shah, J.H., Sharif, M., Raza, M., et al. (2015) Robust Face Recognition Technique under Varying Illumination. Journal of Applied Research &amp; Technology, 13, 97-105. http://dx.doi.org/10.1016/S1665-6423(15)30008-0</mixed-citation></ref><ref id="hanspub.17967-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Biglari, M., Mirzaei, F. and Ebrahimpour-Komeh, H. (2013) Illumination Invariant Face Recognition Using SQI and Weighted LBP Histogram. First Iranian Conference on Pattern Recognition and Image Analysis (PRIA), Birjand, 6-8 March 2013, 1-7.</mixed-citation></ref><ref id="hanspub.17967-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Ramaiah, N.P., Ijjina, E.P. and Mohan, C.K. (2015) Illumination Invariant Face Recognition Using Convolutional Neural Networks. 2015 IEEE International Conference on Signal Processing, Informatics, Communication and Energy Systems (SPICES), Kozhikode, 19-21 February 2015, 1-4.</mixed-citation></ref><ref id="hanspub.17967-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Shermina, J. (2011) Illumination Invariant Face Recognition Using Discrete Cosine Transform and Principal Component Analysis. 2011 International Conference on Emerging Trends in Electrical and Computer Technology (ICETECT), Tamil Nadu, 23-24 March 2011, 826-830.</mixed-citation></ref><ref id="hanspub.17967-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Manolovay, A., Tonchev, K., Boumbarov, O., et al. (2011) Recognition of Facial Images with Subspace Projection and Dissimilarity Representation. IEEE 6th International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications (IDAACS), 1, 444-449.</mixed-citation></ref><ref id="hanspub.17967-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Chen, J., Xia, C., Ying, H., et al. (2013) Using Facial Symmetry in the Illumination Cone Based 3D Face Reconstruction. IEEE International Conference on Image Processing, Melbourne, 15-18 September 2013, 3700-3704.</mixed-citation></ref><ref id="hanspub.17967-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Elaiwat, S., Bennamoun, M., Boussaid, F., et al. (2014) 3-D Face Recognition Using Curvelet Local Features. IEEE Signal Processing Letters, 21, 172-175. http://dx.doi.org/10.1109/LSP.2013.2295119</mixed-citation></ref><ref id="hanspub.17967-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Faraji, M.R. and Qi, X. (2014) Face Recognition under Varying Illumination Based on Adaptive Homomorphic Eight Local Directional Patterns. IET Computer Vision, 9, 390-399. http://dx.doi.org/10.1049/iet-cvi.2014.0200</mixed-citation></ref><ref id="hanspub.17967-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Chen, W.L., Er, M.J. and Wu, S.Q. (2006) Illumination Compensation and Normalization for Robust Face Recognition Using Discrete Cosine Transform in Logarithm Domain. IEEE Transaction on Systems, Man, and Cybernetics, Part B: Cybernetics, 36, 458-466. http://dx.doi.org/10.1109/TSMCB.2005.857353</mixed-citation></ref><ref id="hanspub.17967-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Lee, P., Wu, S. and Hung, Y. (2012) Illumination Compensation Using Oriented Local Histogram Equalization and Its Application to Face Recognition. IEEE Transactions on Image Processing, 21, 4290-4289.  
http://dx.doi.org/10.1109/TIP.2012.2202670</mixed-citation></ref><ref id="hanspub.17967-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">Tan, X. and Triggs, B. (2010) Enhanced Local Texture Feature Sets for Face Recognition under Difficult Lighting Conditions. Transactions on Image Processing, 19, 4177-4189.</mixed-citation></ref><ref id="hanspub.17967-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">Vu, N. and Caplier, A. (2009) Illumination-Robust Face Recognition Using Retina Modeling. 2009 16th IEEE International Conference on Image Processing (ICIP), Cairo, 7-10 November 2009, 3289-3292.</mixed-citation></ref></ref-list></back></article>