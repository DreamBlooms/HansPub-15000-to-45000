<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">AAM</journal-id><journal-title-group><journal-title>Advances in Applied Mathematics</journal-title></journal-title-group><issn pub-type="epub">2324-7991</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/AAM.2019.89183</article-id><article-id pub-id-type="publisher-id">AAM-32281</article-id><article-categories><subj-group subj-group-type="heading"><subject>AAM20190900000_52835055.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>数学与物理</subject></subj-group></article-categories><title-group><article-title>
 
 
  指数分布下可靠性参数的推断
  Inference of Reliability Parameters under Exponential Distribution
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>魏</surname><given-names>秋月</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>王</surname><given-names>春玲</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>赵</surname><given-names>昕</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>北京建筑大学理学院，北京</addr-line></aff><aff id="aff3"><addr-line>北京工商大学嘉华学院，北京</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>03</day><month>09</month><year>2019</year></pub-date><volume>08</volume><issue>09</issue><fpage>1562</fpage><lpage>1573</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   本文研究了单参数指数分布下参数 的区间估计方法，给出了单参指数分布中参数 的两种广义枢轴量、参数的广义置信区间的解析解及频率性质理论证明，同时给出了假设检验问题的广义p值，另外给出三种已有方法，即Bayes方法、大样本近似估计方法和Bootstrap重抽样方法，通过Monte Carlo方法对四种方法进行模拟，模拟结果表明：广义推断和Bayes方法的覆盖概率在样本量较小的情况下保持在给定置信水平附近，且平均置信长度较小，另外本文又比较了四种方法对于假设检验问题犯第一类错误概率与检验的势，模拟结果验证了广义推断方法的良好性能。 In this paper, we study the interval estimation method of parameter   under single pa-rameter exponential distribution. Two kinds of generalized pivots of parameter   in single parameter exponential distribution, analytical solutions of generalized confidence interval of parameter and theoretical proof of frequency property are given. At the same time, the generalized p value of hypothesis testing problem is given. In addition, three existing methods, namely Bayes method, approximate estimation method of large sample and Bootstrap resampling method are given. Four methods are simulated by Monte Carlo method. The simulation results show that the coverage probability of generalized inference and Bayes method remains near the confidence level when sample size is small, and the average confidence length is smaller. In addition, this paper compares the error 1 probability and the power for hypothesis testing. The simulation results verify the good performance of the generalized inference method. 
  
 
</p></abstract><kwd-group><kwd>指数分布，广义推断，Bootstrap，Bayes，大样本近似估计, Exponential Distribution</kwd><kwd> Generalized Inference</kwd><kwd> Bayes</kwd><kwd> Bootstrap</kwd><kwd> Large Sample Approximation Estimation</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>指数分布下可靠性参数的推断<sup> </sup></title><p>魏秋月<sup>1</sup>，王春玲<sup>1</sup>，赵昕<sup>2</sup></p><p><sup>1</sup>北京建筑大学理学院，北京</p><p><sup>2</sup>北京工商大学嘉华学院，北京</p><disp-formula id="hanspub.32281-formula64"><graphic xlink:href="//html.hanspub.org/file/8-2621031x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>收稿日期：2019年9月1日；录用日期：2019年9月16日；发布日期：2019年9月23日</p><disp-formula id="hanspub.32281-formula65"><graphic xlink:href="//html.hanspub.org/file/8-2621031x7_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>本文研究了单参数指数分布下参数 P ( X &gt; Y ) 的区间估计方法，给出了单参指数分布中参数 P ( X &gt; Y ) 的两种广义枢轴量、参数的广义置信区间的解析解及频率性质理论证明，同时给出了假设检验问题的广义p值，另外给出三种已有方法，即Bayes方法、大样本近似估计方法和Bootstrap重抽样方法，通过Monte Carlo方法对四种方法进行模拟，模拟结果表明：广义推断和Bayes方法的覆盖概率在样本量较小的情况下保持在给定置信水平附近，且平均置信长度较小，另外本文又比较了四种方法对于假设检验问题犯第一类错误概率与检验的势，模拟结果验证了广义推断方法的良好性能。</p><p>关键词 :指数分布，广义推断，Bootstrap，Bayes，大样本近似估计</p><disp-formula id="hanspub.32281-formula66"><graphic xlink:href="//html.hanspub.org/file/8-2621031x10_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2019 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/8-2621031x11_hanspub.png" /> <img src="//html.hanspub.org/file/8-2621031x12_hanspub.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>关于随机变量Y小于随机变量X的概率的估计和推导问题，起源于应力强度模型，它是由Bimbaxmi于1956年提出来的，主要是讨论应力和强度相互作用的效果。应力定义为引起元件、装置和材料失效的载荷，强度定义为当承受外部载荷和环境时，元件装置或材料能满意地完成规定的任务而没有失效的能力。一般地，机械产品的强度和工作应力均为随机变量，可靠性定义为影响失效的应力没有超过控制失效的强度的概率，在使用中，当Y表示应力，X代表强度时，则装置的可靠性的数学形式可以描述为 P ( Y &lt; X ) 。后来 P ( Y &lt; X ) 也在其他领域有了不同的意义，例如在生物特征学中，若Y代表患者接受药物A治疗后的剩余寿命，X代表患者接受药物B治疗后的剩余寿命，如果让患者来选择药物，则患者主要通过 P ( Y &lt; X ) 的值来选择使用何种药物。</p><p>指数分布作为一类典型的分布在工业生产、医学、机械工程、桥梁工程等领域常用来描述变量的分布，本文基于单参数和双参数指数分布来研究 P ( Y &lt; X ) 。Owen，Craswell和Hanson (1964) [<xref ref-type="bibr" rid="hanspub.32281-ref1">1</xref>] 利用非参数正态近似的方法给出了当X和Y分别为服从正态分布的相互独立的随机变量时 P ( Y &lt; X ) 的置信限，Enis和Geisser (1971) [<xref ref-type="bibr" rid="hanspub.32281-ref2">2</xref>] 利用Bayes方法给出了单参数指数分布的 P ( Y &lt; X ) 的估计，Tong (1977) [<xref ref-type="bibr" rid="hanspub.32281-ref3">3</xref>] 给出了当X和Y分别服从单参数指数分布时 P ( Y &lt; X ) 的一致最小方差无偏估计，Chaos (1982) [<xref ref-type="bibr" rid="hanspub.32281-ref4">4</xref>] 给出了 P ( Y &lt; X ) 的极大似然估计及其均方误差，D. S. Bai和Y. W. Hong (1992) [<xref ref-type="bibr" rid="hanspub.32281-ref5">5</xref>] 给出了大样本单参数情况下此问题的渐近分布，本文在已有文献的基础上，构造了两变量服从单参数指数分布时 P ( Y &lt; X ) 的广义枢轴量，给出检验问题的解析解以及频率性质证明。利用Bayes方法得到当两变量服从单参数指数分布时 P ( Y &lt; X ) 的置信区间，并与大样本近似估计方法和Bootstrap重抽样方法进行了对比。</p></sec><sec id="s4"><title>2. 变量为单参数指数分布情形</title><p>当随机变量X与Y分别服从单参数指数分布且相互独立时，有：</p><p>T = P ( X &gt; Y ) = ∫ 0 + ∞   λ 1 e − λ 1 y d x ∫ 0 x   λ 2 e − λ 2 y d y = λ 2 λ 1 + λ 2 .</p><sec id="s4_1"><title>2.1. 广义推断的方法</title><p>Tsui K. W.，Weerahandi [<xref ref-type="bibr" rid="hanspub.32281-ref6">6</xref>] 和Weerahandi [<xref ref-type="bibr" rid="hanspub.32281-ref7">7</xref>] 提出了广义推断的理论，并且给出广义推断方法来求检验的广义p值及参数的广义置信区间。</p><p>设 X 1 , ⋯ , X m 与 Y 1 , ⋯ , Y n 分别为从指数分布总体 exp ( λ 1 ) 和 exp ( λ 2 ) 中抽取的样本，由于 ∑ i = 1 m   X i 与 ∑ j = 1 n   Y j 是独立的充分统计量，且有：</p><p>U = 2 λ 1 ∑ i = 1 m   X i ~ χ 2 ( 2 m ) ,   V = 2 λ 2 ∑ j = 1 n   Y j ~ χ 2 ( 2 n ) ,</p><p>因此可构造广义枢轴量：</p><p>R λ 1 = U 2 ∑ i = 1 m x i ,   R λ 2 = V 2 ∑ j = 1 n y j , (1)</p><p>其中： ∑ i = 1 m   x i , ∑ j = 1 n   y i 分别是 ∑ i = 1 m   X i 和 ∑ j = 1 n   Y j 的样本观测值，因此可以得到参数T的广义枢轴量：</p><p>R T = R λ 2 R λ 1 + R λ 2 , (2)</p><p>容易证明 R T 确实是T的广义枢轴量。</p><p>考虑假设检验问题：</p><p>H 0 : T ≤ T 0 ,   H 1 : T &gt; T 0 (3)</p><p>其中 T 0 为已知常数，则对于假设检验问题(3)可给出广义p值为：</p><p>p = P r ( R T ( X , Y , x , y , λ 1 , λ 2 ) ≤ r ( x , y , x , y , λ 1 , λ 2 ) | T = T 0 ) = P r ( V / ( 2 ∑ j = 1 n y j ) U / ( 2 ∑ i = 1 m x i ) + V / ( 2 ∑ j = 1 n y i ) ≤ T 0 ) = P r ( V ≤ T 0 ⋅ U ⋅ ∑ j = 1 n y i ( 1 − T 0 ) ⋅ ∑ i = 1 m x i ) = E U ( F V ( T 0 ⋅ U ⋅ ∑ j = 1 n y i ( 1 − T 0 ) ∑ i = 1 m x i ) ) ,</p><p>其中 r ( x , y , x , y , λ 1 , λ 2 ) 是给定样本下参数的广义枢轴量的观测值， F V ( ⋅ ) 自由度为2n的卡方分布的分布函数。根据假设检验与区间估计的一一对应关系，我们可以得到T的置信系数为 γ 单侧置信下限：</p><p>P ( R T ( X , Y , x , y , λ 2 , λ 2 ) ≥ c ) = P r ( U ≤ V ∑ i = 1 m x i ( 1 / c − 1 ) ∑ j = 1 n y i ) = E V ( F U ( V ∑ i = 1 m x i ( 1 / c − 1 ) ∑ j = 1 n y i ) ) = γ ,</p><p>其中 F U ( ⋅ ) 是自由度为2m的卡方分布的分布函数。因此，T的置信系数为 γ 的置信区间为 ( − ∞ , c γ ) ，其中 c γ 满足：</p><p>E V ( F U ( V ∑ i = 1 m x i ( 1 / c γ − 1 ) ∑ j = 1 n y i ) ) = γ .</p><p>另外,由于 ∑ i = 1 m   X i 与 ∑ j = 1 n   Y j 是独立的充分统计量，且有：</p><p>λ 1 m ∑ i = 1 m X i λ 2 n ∑ j = 1 n Y i ~ F ( 2 m ,2 n ) ,</p><p>即：</p><p>λ 1 X &#175; λ 2 Y &#175; ~ F ( 2 m ,2 n ) ,</p><p>其中 X &#175; = ∑ i = 1 m   X i m 、 Y &#175; = ∑ j = 1 n   Y j n ，则可以得到 λ 1 λ 2 的广义枢轴量为：</p><p>R λ 1 λ 2 = W y &#175; x &#175; ,</p><p>其中W是服从自由度为2m和2n的F分布， x &#175; 与 y &#175; 分别是 X &#175; ， Y &#175; 的观测值，由此有：</p><p>R T = 1 1 + R λ 1 / λ 2 .</p><p>下面给出关于假设检验问题(3)的广义p值检验犯第一类错误的概率以及参数的双侧置信区间覆盖概率的算法。我们通过Monte Carlo方法来实现。</p><p>i) 分别从两个指数分布总体中抽取样本量分别为m和n的样本，得到观测值 { ( x 1 , ⋯ , x m ) , ( y 1 , ⋯ , y n ) } ：</p><p>ii) 计算 ∑ i = 1 m   x i ; ∑ j = 1 n   y j ：</p><p>iii) 产生 U ~ χ 2 ( 2 m ) 与 V ~ χ 2 ( 2 n ) 的实现值；</p><p>iv) 按(1)和(2)给出的公式计算 R T ；</p><p>v) 重复步骤(iii)-(iv) M次，得到M个 R T 的值，将这一系列 R T 从小到大排列，取其 α / 2 分位点与 1 − α / 2 分位点，分别记为 g ^ L , g ^ U ，得到参数T的一个双侧广义置信区间。计算M个 R T 中小于等于真值T的比率，作为假设检验问题(3)的广义p值；</p><p>vi) 重复步骤i)~v) L次，计算这L次得到的T的广义置信区间中包含真实值的个数，作为置信区间的覆盖概率，计算广义p值小于0.05的概率，作为检验犯第一类错误的概率。</p>频率性质<p>下面给出可靠性参数广义置信区间的频率性质。根据文献 [<xref ref-type="bibr" rid="hanspub.32281-ref8">8</xref>] ，有如下引理：</p><p>引理1：设 X ~ P θ , θ ∈ Θ , θ ^ x ( E ) , E ~ Q 是 θ 的Fiducial模型， g ( θ ) 是 θ 的正规参数函数，在Q下 g ( θ ^ x ( E ) ) 的分布是 g ( θ ) 的Fiducial分布。记 F ( G ) x ( g ) 为 g ( θ ) 的Fiducial分布函数，若</p><p>g ^ α ( x ) = i n f { g : F ( G ) x ( g ) ≥ α }</p><p>是Fiducial分布的 α 分位数， α ∈ ( 0,1 ) ，则有：</p><p>P θ ( g ( θ ) &lt; g ^ α ( X ) ) = α</p><p>对所有 θ ∈ Θ 成立，即作为 g ( θ ) 的置信下限， g ^ α ( x ) 具有频率意义下的实际置信水平 1 − α 。</p><p>定理1：单参数指数分布可靠性参数 T = λ 2 λ 1 + λ 2 的广义置信区间具有频率意义下的实际置信水平 1 − α ，即 P ( g ^ L &lt; λ 2 λ 1 + λ 2 &lt; g ^ U ) = 1 − α 。</p><p>证明：</p><p>P ( g ^ L &lt; λ 2 λ 1 + λ 2 &lt; g ^ U ) = P ( λ 2 λ 1 + λ 2 &lt; g ^ U ) − P ( λ 2 λ 1 + λ 2 &lt; g ^ L ) = P ( F R T ( λ 2 λ 1 + λ 2 ) &lt; 1 − α 2 ) − P ( F R T ( λ 2 λ 1 + λ 2 ) &lt; α 2 ) ,</p><p>其中， F R T 表示 R T 的分布函数。由于：</p><p>P ( F R T ( λ 2 λ 1 + λ 2 ) &lt; 1 − α 2 ) = P ( P ( U / 2 ∑ i = 1 m x i U / 2 ∑ i = 1 m x i + V / 2 ∑ j = 1 n y i ≤ λ 2 λ 1 + λ 2 ) &lt; 1 − α 2 )</p><p>根据枢轴方程 U = 2 λ 1 ∑ i = 1 m   X i , V = 2 λ 2 ∑ j = 1 n   Y j ，设 2 ∑ i = 1 m   X i = U * λ 1 , 2 ∑ j = 1 n   Y j = V * λ 2 ，其中 ( U * , V * ) 分别与 ( U , V ) 独立同分布。根据引理1，上式可表示为：</p><p>P ( P ( U * V * ≤ U V ) &lt; 1 − α ) = P U * / V * ( F U / V ( U * V * ) &gt; α / 2 ) = 1 − α / 2 ,</p><p>其中， F U / V ( ⋅ ) 是 U V 的分布函数。同理</p><p>P ( F T ( λ 2 λ 1 + λ 2 ) &lt; α / 2 ) = α / 2</p><p>因此 P ( g ^ L &lt; λ 2 λ 1 + λ 2 &lt; g ^ U ) = 1 − α 。得证。</p></sec><sec id="s4_2"><title>2.2. 基于渐近正态的大样本方法</title><p>设 X 1 , ⋯ , X m 与 Y 1 , ⋯ , Y n 分别为从指数分布总体 exp ( λ 1 ) 和 exp ( λ 2 ) 中抽取的样本，由于 λ 1 ， λ 2 的极大似然估计分别为：</p><p>λ ^ 1 = 1 X &#175; ,   λ ^ 2 = 1 Y &#175; ,</p><p>则根据极大似然估计的不变性得到T的极大似然估计为：</p><p>T ^ = X &#175; X &#175; + Y &#175; . (4)</p><p>下面考虑在大样本情况下T的极大似然估计的渐近分布，根据D. S. Bai和Y. W. Hong (1992)，令 n = n 1 + n 2 ，其中 n 1 和 n 2 分别表示从两个指数分布总体抽取的样本数。令 b = n 1 n ，当 n → ∞ 时，有 n ( T ^ − T ) → L N ( 0, T 2 ( 1 − T ) 2 b ( 1 − b ) ) ，因此， n b ( 1 − b ) T ( 1 − T ) ( T ^ − T ) → L N ( 0,1 ) 。这样，我们可以得到参数T的近似置信区间</p><p>[ T ^ − U 1 − α / 2 ⋅ T ^ ( 1 − T ^ ) n b ( 1 − b ) , T ^ + U 1 − α / 2 ⋅ T ^ ( 1 − T ^ ) n b ( 1 − b ) ] ,</p><p>其中 U 1 − α / 2 是标准正态分布的 1 − α / 2 分位点。</p><p>对于假设检验问题(3)，得到检验的p值为：</p><p>p = 1 − Φ ( n b ( 1 − b ) T 0 ( 1 − T 0 ) ( T ^ − T 0 ) ) ,</p><p>其中， Φ 是标准正态分布的累积分布函数。</p></sec><sec id="s4_3"><title>2.3. Bootstrap-t方法</title><p>Bootstrap方法最早是由斯坦福大学教授Efron于1977年提出的，该方法认为经验分布函数能够较好地拟合总体分布，下面给出基于bootstrap方法的指数分布可靠性参数的区间估计中较常用的一种方法，Bootstrap-t区间估计 [<xref ref-type="bibr" rid="hanspub.32281-ref9">9</xref>] 。</p><p>记 T ^ 是T的极大似然估计， V ^ ( T ^ ) 是 T ^ 的方差估计， T ^ * 是通过Boostrap样本得到的T的极大似然估计， V ^ ( T ^ * ) 是 T ^ 的方差的Bootstrap估计。</p><p>i) 分别从两个指数分布总体抽取样本量为 n 1 和 n 2 的样本集合，记为 W 1 、 W 2 ；</p><p>ii) 通过样本 W 1 、 W 2 利用公式(4)求出 T ^ ；</p><p>iii) 分别从 W 1 与 W 2 中再抽取样本量为 n 1 和 n 2 的Bootstrap样本，记为 Q 1 和 Q 2 ；</p><p>iv) 通过样本 Q 1 和 Q 2 求出 Z * = T ^ * − T ^ V ^ ( T ^ * ) 1 / 2 ；</p><p>v) 重复步骤(iii)-(iv) M次，得到M个 T ^ ，从小到大排序，取其 α 分位点 z α / 2 与 1 − α 分位点 z 1 − α / 2 ，得到参数T的一个双侧Bootstrap置信区间 ( T ^ − z 1 − α / 2 * V ^ ( T ^ ) 1 / 2 , T ^ − z α / 2 * V ^ ( T ^ ) 1 / 2 ) ；</p><p>vi) 重复步骤i)~v) L次，计算这L次得到的T的置信区间中包含真实值的概率，作为置信区间的覆盖概率。</p></sec><sec id="s4_4"><title>2.4. Bayes方法</title><p>通过抽取的样本 X = ( X 1 , ⋯ , X m ) ， Y = ( Y 1 , ⋯ , Y n ) 可以得到似然方程为：</p><p>L ( λ 1 , λ 2 | x , y ) = λ 1 m λ 2 n e − λ 1 ∑ i = 1 m x i − λ 2 ∑ j = 1 n y i , λ 1 &gt; 0 , λ 2 &gt; 0 ,</p><p>取 λ 1 、 λ 2 的先验分布为非信息先验分布： π ( λ i ) = 1 λ i , λ i &gt; 0 , i = 1 , 2</p><p>因此在给定X、Y下， λ 1 和 λ 2 的后验分布函数为：</p><p>Π 1 ( λ 1 | x ) = λ 1 m − 1 exp ( − λ 1 ∑ i = 1 m x i ) ∫ 0 + ∞ λ 1 m − 1 exp ( − λ 1 ∑ i = 1 m x i ) d λ 1 = λ 1 m − 1 ( ∑ i = 1 m x i ) m exp ( − λ 1 ∑ i = 1 m x i ) Γ ( m ) , (5)</p><p>Π 2 ( λ 2 | y ) = λ 2 n − 1 exp ( − λ 2 ∑ j = 1 n y i ) ∫ 0 + ∞ λ 2 n − 1 exp ( − λ 2 ∑ j = 1 n y i ) d λ 1 = λ 2 n − 1 ( ∑ j = 1 n y i ) n exp ( − λ 2 ∑ j = 1 n y i ) Γ ( n ) , (6)</p><p>得到 λ 1 和 λ 2 的后验分布分别是参数为 ( m , ∑ i = 1 m   x i ) 和 ( n , ∑ j = 1 n   y j ) 的伽玛分布。</p><p>我们通过Monte Carlo模拟来确定T的置信区间，下面给出具体算法：</p><p>i) 通过公式(5)和(6)产生 λ 1 和 λ 2 ；</p><p>ii) 通过得到的 ( λ 1 , λ 2 ) ，计算得到T；</p><p>iv) 重复步骤(i)-(ii) M次，得到 T 1 , ⋯ , T M ，并将它们从小到大排序；</p><p>v) 取其 α / 2 分位点与 1 − α / 2 分位点，得到参数T的一个置信区间；</p><p>vi) 重复步骤i)~v) L次，计算这L次得到的置信区间中包含真实值T的概率作为置信区间的覆盖概率。</p></sec></sec><sec id="s5"><title>3. 模拟与结论</title><p>我们通过模拟研究来比较四种方法所得到的置信区间和假设检验的表现。在模拟设计中，分别取两样本量为(5,5)，(15,10)，(20,15)，(0,30)。M取5000，L取2000，相关参数的选定在表格中给出。其中，CP表示覆盖概率，IL表示区间长度，GV代表文章所提出的广义枢轴量方法，LS代表基于大样本近似估计方法，TIR表示检验犯第一类错误的概率。从表1~表3的模拟结果可以看出，对于单参数指数分布，广义推断、大样本方法和Bayes方法的覆盖概率在样本量较小的情况下具有好的表现，且广义推断方法和Bayes方法得到的平均置信长度较小，二者的效果更好，Bootstrap方法随着样本量的增加，覆盖概率会逐渐接近名义水平。同时对于单参数指数分布情况下的假设检验问题，给出了不同方法的检验犯第一类错误的概率以及检验的功效，从表4和表5的模拟结果可以看出，广义推断方法和Bayes方法的检验犯第一类错误的概率在名义水平附近，且当样本量较小时，效果也很令人满意。观察表6与表7的结果发现，广义推断方法检验的功效与渐进正态的大样本方法和Bayes方法的功效没有显著差异，小于Bootstrap方法的功效，原因是在这些情况下Bootstrap方法犯第一类错误的概率大于名义水平。另外，当效应的真值原理原假设时，广义p值检验的功效趋于1的速度与其他三种方法的速度是相近的。</p><table-wrap-group id="1"><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> The main coverage probability and average confidence length of the two-sided confidence interval of the single-parameter exponential distribution parameter T 95</title></caption><table-wrap id="1_1"><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" ></th><th align="center" valign="middle"  colspan="2"  >( m , n ) = ( 5 , 5 )</th><th align="center" valign="middle"  colspan="2"  >( m , n ) = ( 15 , 10 )</th><th align="center" valign="middle"  colspan="2"  >( m , n ) = ( 20 , 15 )</th><th align="center" valign="middle"  colspan="2"  >( m , n ) = ( 30 , 30 )</th></tr></thead><tr><td align="center" valign="middle" >( λ 1 , λ 2 ) )</td><td align="center" valign="middle" >方法</td><td align="center" valign="middle" >CP</td><td align="center" valign="middle" >IL</td><td align="center" valign="middle" >CP</td><td align="center" valign="middle" >IL</td><td align="center" valign="middle" >CP</td><td align="center" valign="middle" >IL</td><td align="center" valign="middle" >CP</td><td align="center" valign="middle" >IL</td></tr><tr><td align="center" valign="middle" >(1,2)</td><td align="center" valign="middle" >GV</td><td align="center" valign="middle" >0.942</td><td align="center" valign="middle" >0.5018</td><td align="center" valign="middle" >0.951</td><td align="center" valign="middle" >0.3441</td><td align="center" valign="middle" >0.939</td><td align="center" valign="middle" >0.2893</td><td align="center" valign="middle" >0.958</td><td align="center" valign="middle" >0.2218</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >LS</td><td align="center" valign="middle" >0.941</td><td align="center" valign="middle" >0.4493</td><td align="center" valign="middle" >0.956</td><td align="center" valign="middle" >0.3215</td><td align="center" valign="middle" >0.954</td><td align="center" valign="middle" >0.2783</td><td align="center" valign="middle" >0.951</td><td align="center" valign="middle" >0.2115</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bayes</td><td align="center" valign="middle" >0.948</td><td align="center" valign="middle" >0.5035</td><td align="center" valign="middle" >0.948</td><td align="center" valign="middle" >0.3433</td><td align="center" valign="middle" >0.945</td><td align="center" valign="middle" >0.2899</td><td align="center" valign="middle" >0.950</td><td align="center" valign="middle" >0.2211</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bootstrap-t</td><td align="center" valign="middle" >0.925</td><td align="center" valign="middle" >0.6413</td><td align="center" valign="middle" >0.944</td><td align="center" valign="middle" >0.3708</td><td align="center" valign="middle" >0.937</td><td align="center" valign="middle" >0.3084</td><td align="center" valign="middle" >0.947</td><td align="center" valign="middle" >0.2150</td></tr><tr><td align="center" valign="middle" >(3,2)</td><td align="center" valign="middle" >GV</td><td align="center" valign="middle" >0.952</td><td align="center" valign="middle" >0.5246</td><td align="center" valign="middle" >0.956</td><td align="center" valign="middle" >0.3619</td><td align="center" valign="middle" >0.954</td><td align="center" valign="middle" >0.3082</td><td align="center" valign="middle" >0.952</td><td align="center" valign="middle" >0.2373</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >LS</td><td align="center" valign="middle" >0.961</td><td align="center" valign="middle" >0.4573</td><td align="center" valign="middle" >0.949</td><td align="center" valign="middle" >0.3369</td><td align="center" valign="middle" >0.955</td><td align="center" valign="middle" >0.2915</td><td align="center" valign="middle" >0.962</td><td align="center" valign="middle" >0.2292</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bayes</td><td align="center" valign="middle" >0.945</td><td align="center" valign="middle" >0.524</td><td align="center" valign="middle" >0.948</td><td align="center" valign="middle" >0.3613</td><td align="center" valign="middle" >0.957</td><td align="center" valign="middle" >0.3086</td><td align="center" valign="middle" >0.955</td><td align="center" valign="middle" >0.2374</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bootstrap-t</td><td align="center" valign="middle" >0.898</td><td align="center" valign="middle" >0.7050</td><td align="center" valign="middle" >0.936</td><td align="center" valign="middle" >0.3889</td><td align="center" valign="middle" >0.924</td><td align="center" valign="middle" >0.2930</td><td align="center" valign="middle" >0.963</td><td align="center" valign="middle" >0.2438</td></tr></tbody></table></table-wrap><table-wrap id="1_2"><table><tbody><thead><tr><th align="center" valign="middle" >(5,2)</th><th align="center" valign="middle" >GV</th><th align="center" valign="middle" >0.953</th><th align="center" valign="middle" >0.4750</th><th align="center" valign="middle" >0.953</th><th align="center" valign="middle" >0.3163</th><th align="center" valign="middle" >0.948</th><th align="center" valign="middle" >0.2681</th><th align="center" valign="middle" >0.954</th><th align="center" valign="middle" >0.2055</th></tr></thead><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >LS</td><td align="center" valign="middle" >0.953</td><td align="center" valign="middle" >0.4360</td><td align="center" valign="middle" >0.941</td><td align="center" valign="middle" >0.3101</td><td align="center" valign="middle" >0.954</td><td align="center" valign="middle" >0.2915</td><td align="center" valign="middle" >0.948</td><td align="center" valign="middle" >0.2032</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bayes</td><td align="center" valign="middle" >0.949</td><td align="center" valign="middle" >0.4765</td><td align="center" valign="middle" >0.950</td><td align="center" valign="middle" >0.3167</td><td align="center" valign="middle" >0.952</td><td align="center" valign="middle" >0.2682</td><td align="center" valign="middle" >0.943</td><td align="center" valign="middle" >0.2046</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bootstrap-t</td><td align="center" valign="middle" >0.918</td><td align="center" valign="middle" >0.6316</td><td align="center" valign="middle" >0.933</td><td align="center" valign="middle" >0.3331</td><td align="center" valign="middle" >0.939</td><td align="center" valign="middle" >0.2544</td><td align="center" valign="middle" >0.942</td><td align="center" valign="middle" >0.2086</td></tr><tr><td align="center" valign="middle" >(7,2)</td><td align="center" valign="middle" >GV</td><td align="center" valign="middle" >0.946</td><td align="center" valign="middle" >0.4287</td><td align="center" valign="middle" >0.963</td><td align="center" valign="middle" >0.2756</td><td align="center" valign="middle" >0.948</td><td align="center" valign="middle" >0.2320</td><td align="center" valign="middle" >0.943</td><td align="center" valign="middle" >0.1762</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >LS</td><td align="center" valign="middle" >0.949</td><td align="center" valign="middle" >0.4190</td><td align="center" valign="middle" >0.955</td><td align="center" valign="middle" >0.3097</td><td align="center" valign="middle" >0.951</td><td align="center" valign="middle" >0.2641</td><td align="center" valign="middle" >0.959</td><td align="center" valign="middle" >0.1786</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bayes</td><td align="center" valign="middle" >0.951</td><td align="center" valign="middle" >0.4286</td><td align="center" valign="middle" >0.949</td><td align="center" valign="middle" >0.2769</td><td align="center" valign="middle" >0.952</td><td align="center" valign="middle" >0.2319</td><td align="center" valign="middle" >0.948</td><td align="center" valign="middle" >0.1753</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bootstrap-t</td><td align="center" valign="middle" >0.907</td><td align="center" valign="middle" >0.5267</td><td align="center" valign="middle" >0.928</td><td align="center" valign="middle" >0.2664</td><td align="center" valign="middle" >0.939</td><td align="center" valign="middle" >0.2132</td><td align="center" valign="middle" >0.955</td><td align="center" valign="middle" >0.1775</td></tr></tbody></table></table-wrap></table-wrap-group><p>表1. 单参数指数分布的参数T的95%双侧置信区间的主要覆盖概率和平均置信长度</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> The main coverage probability and average confidence length of the two-sided confidence interval of the single-parameter exponential distribution parameter T 95</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" ></th><th align="center" valign="middle"  colspan="2"  >( m , n ) = ( 5 , 5 )</th><th align="center" valign="middle"  colspan="2"  >( m , n ) = ( 15 , 10 )</th><th align="center" valign="middle"  colspan="2"  >( m , n ) = ( 20 , 15 )</th><th align="center" valign="middle"  colspan="2"  >( m , n ) = ( 30 , 30 )</th></tr></thead><tr><td align="center" valign="middle" >( λ 1 , λ 2 )</td><td align="center" valign="middle" >方法</td><td align="center" valign="middle" >CP</td><td align="center" valign="middle" >IL</td><td align="center" valign="middle" >CP</td><td align="center" valign="middle" >IL</td><td align="center" valign="middle" >CP</td><td align="center" valign="middle" >IL</td><td align="center" valign="middle" >CP</td><td align="center" valign="middle" >IL</td></tr><tr><td align="center" valign="middle" >(1,4)</td><td align="center" valign="middle" >GV</td><td align="center" valign="middle" >0.959</td><td align="center" valign="middle" >0.4101</td><td align="center" valign="middle" >0.948</td><td align="center" valign="middle" >0.2619</td><td align="center" valign="middle" >0.951</td><td align="center" valign="middle" >0.2200</td><td align="center" valign="middle" >0.952</td><td align="center" valign="middle" >0.1631</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >LS</td><td align="center" valign="middle" >0.916</td><td align="center" valign="middle" >0.4129</td><td align="center" valign="middle" >0.944</td><td align="center" valign="middle" >0.2696</td><td align="center" valign="middle" >0.952</td><td align="center" valign="middle" >0.2150</td><td align="center" valign="middle" >0.956</td><td align="center" valign="middle" >0.1684</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bayes</td><td align="center" valign="middle" >0.945</td><td align="center" valign="middle" >0.4108</td><td align="center" valign="middle" >0.946</td><td align="center" valign="middle" >0.2647</td><td align="center" valign="middle" >0.953</td><td align="center" valign="middle" >0.2202</td><td align="center" valign="middle" >0.950</td><td align="center" valign="middle" >0.1632</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bootstrap-t</td><td align="center" valign="middle" >0.908</td><td align="center" valign="middle" >0.4900</td><td align="center" valign="middle" >0.928</td><td align="center" valign="middle" >0.2638</td><td align="center" valign="middle" >0.946</td><td align="center" valign="middle" >0.2225</td><td align="center" valign="middle" >0.947</td><td align="center" valign="middle" >0.1684</td></tr><tr><td align="center" valign="middle" >(3,4)</td><td align="center" valign="middle" >GV</td><td align="center" valign="middle" >0.947</td><td align="center" valign="middle" >0.5307</td><td align="center" valign="middle" >0.952</td><td align="center" valign="middle" >0.3710</td><td align="center" valign="middle" >0.957</td><td align="center" valign="middle" >0.3147</td><td align="center" valign="middle" >0.95</td><td align="center" valign="middle" >0.2414</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >LS</td><td align="center" valign="middle" >0.968</td><td align="center" valign="middle" >0.4613</td><td align="center" valign="middle" >0.965</td><td align="center" valign="middle" >0.3390</td><td align="center" valign="middle" >0.954</td><td align="center" valign="middle" >0.2942</td><td align="center" valign="middle" >0.948</td><td align="center" valign="middle" >0.2320</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bayes</td><td align="center" valign="middle" >0.951</td><td align="center" valign="middle" >0.5315</td><td align="center" valign="middle" >0.956</td><td align="center" valign="middle" >0.3704</td><td align="center" valign="middle" >0.946</td><td align="center" valign="middle" >0.3143</td><td align="center" valign="middle" >0.952</td><td align="center" valign="middle" >0.2418</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bootstrap-t</td><td align="center" valign="middle" >0.918</td><td align="center" valign="middle" >0.6899</td><td align="center" valign="middle" >0.937</td><td align="center" valign="middle" >0.3778</td><td align="center" valign="middle" >0.956</td><td align="center" valign="middle" >0.3327</td><td align="center" valign="middle" >0.945</td><td align="center" valign="middle" >0.2336</td></tr><tr><td align="center" valign="middle" >(5,4)</td><td align="center" valign="middle" >GV</td><td align="center" valign="middle" >0.942</td><td align="center" valign="middle" >0.5334</td><td align="center" valign="middle" >0.941</td><td align="center" valign="middle" >0.3702</td><td align="center" valign="middle" >0.943</td><td align="center" valign="middle" >0.3156</td><td align="center" valign="middle" >0.950</td><td align="center" valign="middle" >0.2432</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >LS</td><td align="center" valign="middle" >0.977</td><td align="center" valign="middle" >0.4625</td><td align="center" valign="middle" >0.946</td><td align="center" valign="middle" >0.3405</td><td align="center" valign="middle" >0.952</td><td align="center" valign="middle" >0.2962</td><td align="center" valign="middle" >0.948</td><td align="center" valign="middle" >0.2333</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bayes</td><td align="center" valign="middle" >0.952</td><td align="center" valign="middle" >0.5322</td><td align="center" valign="middle" >0.951</td><td align="center" valign="middle" >0.3710</td><td align="center" valign="middle" >0.955</td><td align="center" valign="middle" >0.3162</td><td align="center" valign="middle" >0.952</td><td align="center" valign="middle" >0.2432</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bootstrap-t</td><td align="center" valign="middle" >0.913</td><td align="center" valign="middle" >0.6955</td><td align="center" valign="middle" >0.925</td><td align="center" valign="middle" >0.3667</td><td align="center" valign="middle" >0.933</td><td align="center" valign="middle" >0.3316</td><td align="center" valign="middle" >0.937</td><td align="center" valign="middle" >0.2495</td></tr><tr><td align="center" valign="middle" >(7,4)</td><td align="center" valign="middle" >GV</td><td align="center" valign="middle" >0.944</td><td align="center" valign="middle" >0.5124</td><td align="center" valign="middle" >0.948</td><td align="center" valign="middle" >0.3511</td><td align="center" valign="middle" >0.947</td><td align="center" valign="middle" >0.2992</td><td align="center" valign="middle" >0.945</td><td align="center" valign="middle" >0.2294</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >LS</td><td align="center" valign="middle" >0.956</td><td align="center" valign="middle" >0.4520</td><td align="center" valign="middle" >0.955</td><td align="center" valign="middle" >0.3303</td><td align="center" valign="middle" >0.946</td><td align="center" valign="middle" >0.2848</td><td align="center" valign="middle" >0.947</td><td align="center" valign="middle" >0.2226</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bayes</td><td align="center" valign="middle" >0.952</td><td align="center" valign="middle" >0.5151</td><td align="center" valign="middle" >0.948</td><td align="center" valign="middle" >0.3510</td><td align="center" valign="middle" >0.953</td><td align="center" valign="middle" >0.2982</td><td align="center" valign="middle" >0.950</td><td align="center" valign="middle" >0.2295</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bootstrap-t</td><td align="center" valign="middle" >0.933</td><td align="center" valign="middle" >0.7028</td><td align="center" valign="middle" >0.942</td><td align="center" valign="middle" >0.3738</td><td align="center" valign="middle" >0.945</td><td align="center" valign="middle" >0.3143</td><td align="center" valign="middle" >0.951</td><td align="center" valign="middle" >0.2209</td></tr></tbody></table></table-wrap><p>表2. 单参数指数分布的参数T的95%双侧置信区间的主要覆盖概率和平均置信长度</p><table-wrap-group id="3"><label><xref ref-type="table" rid="table3">Table 3</xref></label><caption><title> The main coverage probability and average confidence length of the two-sided confidence interval of the single-parameter exponential distribution parameter T 95</title></caption><table-wrap id="3_1"><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" ></th><th align="center" valign="middle"  colspan="2"  >( m , n ) = ( 5 , 5 )</th><th align="center" valign="middle"  colspan="2"  >( m , n ) = ( 15 , 10 )</th><th align="center" valign="middle"  colspan="2"  >( m , n ) = ( 20 , 15 )</th><th align="center" valign="middle"  colspan="2"  >( m , n ) = ( 30 , 30 )</th></tr></thead><tr><td align="center" valign="middle" >( λ 1 , λ 2 )</td><td align="center" valign="middle" >方法</td><td align="center" valign="middle" >CP</td><td align="center" valign="middle" >IL</td><td align="center" valign="middle" >CP</td><td align="center" valign="middle" >IL</td><td align="center" valign="middle" >CP</td><td align="center" valign="middle" >IL</td><td align="center" valign="middle" >CP</td><td align="center" valign="middle" >IL</td></tr><tr><td align="center" valign="middle" >(1,8)</td><td align="center" valign="middle" >GV</td><td align="center" valign="middle" >0.952</td><td align="center" valign="middle" >0.2867</td><td align="center" valign="middle" >0.954</td><td align="center" valign="middle" >0.1760</td><td align="center" valign="middle" >0.943</td><td align="center" valign="middle" >0.1410</td><td align="center" valign="middle" >0.947</td><td align="center" valign="middle" >0.1040</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >LS</td><td align="center" valign="middle" >0.945</td><td align="center" valign="middle" >0.4356</td><td align="center" valign="middle" >0.942</td><td align="center" valign="middle" >0.2040</td><td align="center" valign="middle" >0.945</td><td align="center" valign="middle" >0.4356</td><td align="center" valign="middle" >0.947</td><td align="center" valign="middle" >0.1132</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bayes</td><td align="center" valign="middle" >0.949</td><td align="center" valign="middle" >0.2935</td><td align="center" valign="middle" >0.949</td><td align="center" valign="middle" >0.1764</td><td align="center" valign="middle" >0.955</td><td align="center" valign="middle" >0.1419</td><td align="center" valign="middle" >0.947</td><td align="center" valign="middle" >0.1037</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bootstrap-t</td><td align="center" valign="middle" >0.898</td><td align="center" valign="middle" >0.3349</td><td align="center" valign="middle" >0.919</td><td align="center" valign="middle" >0.1553</td><td align="center" valign="middle" >0.932</td><td align="center" valign="middle" >0.1311</td><td align="center" valign="middle" >0.943</td><td align="center" valign="middle" >0.1030</td></tr></tbody></table></table-wrap><table-wrap id="3_2"><table><tbody><thead><tr><th align="center" valign="middle" >(3,8)</th><th align="center" valign="middle" >GV</th><th align="center" valign="middle" >0.945</th><th align="center" valign="middle" >0.4677</th><th align="center" valign="middle" >0.946</th><th align="center" valign="middle" >0.3142</th><th align="center" valign="middle" >0.948</th><th align="center" valign="middle" >0.2630</th><th align="center" valign="middle" >0.946</th><th align="center" valign="middle" >0.1995</th></tr></thead><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >LS</td><td align="center" valign="middle" >0.948</td><td align="center" valign="middle" >0.4347</td><td align="center" valign="middle" >0.952</td><td align="center" valign="middle" >0.3028</td><td align="center" valign="middle" >0.957</td><td align="center" valign="middle" >0.4541</td><td align="center" valign="middle" >0.962</td><td align="center" valign="middle" >0.2266</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bayes</td><td align="center" valign="middle" >0.954</td><td align="center" valign="middle" >0.4704</td><td align="center" valign="middle" >0.948</td><td align="center" valign="middle" >0.3138</td><td align="center" valign="middle" >0.951</td><td align="center" valign="middle" >0.2633</td><td align="center" valign="middle" >0.943</td><td align="center" valign="middle" >0.1995</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bootstrap-t</td><td align="center" valign="middle" >0.912</td><td align="center" valign="middle" >0.5974</td><td align="center" valign="middle" >0.946</td><td align="center" valign="middle" >0.3340</td><td align="center" valign="middle" >0.945</td><td align="center" valign="middle" >0.2454</td><td align="center" valign="middle" >0.954</td><td align="center" valign="middle" >0.1934</td></tr><tr><td align="center" valign="middle" >(5,8)</td><td align="center" valign="middle" >GV</td><td align="center" valign="middle" >0.947</td><td align="center" valign="middle" >0.5204</td><td align="center" valign="middle" >0.952</td><td align="center" valign="middle" >0.3607</td><td align="center" valign="middle" >0.955</td><td align="center" valign="middle" >0.3051</td><td align="center" valign="middle" >0.958</td><td align="center" valign="middle" >0.2342</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >LS</td><td align="center" valign="middle" >0.959</td><td align="center" valign="middle" >0.4541</td><td align="center" valign="middle" >0.963</td><td align="center" valign="middle" >0.3329</td><td align="center" valign="middle" >0.954</td><td align="center" valign="middle" >0.2885</td><td align="center" valign="middle" >0.962</td><td align="center" valign="middle" >0.2266</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bayes</td><td align="center" valign="middle" >0.950</td><td align="center" valign="middle" >0.5204</td><td align="center" valign="middle" >0.947</td><td align="center" valign="middle" >0.3609</td><td align="center" valign="middle" >0.945</td><td align="center" valign="middle" >0.3053</td><td align="center" valign="middle" >0.952</td><td align="center" valign="middle" >0.2343</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bootstrap-t</td><td align="center" valign="middle" >0.903</td><td align="center" valign="middle" >0.6790</td><td align="center" valign="middle" >0.937</td><td align="center" valign="middle" >0.3911</td><td align="center" valign="middle" >0.944</td><td align="center" valign="middle" >0.2468</td><td align="center" valign="middle" >0.946</td><td align="center" valign="middle" >0.2387</td></tr><tr><td align="center" valign="middle" >(7,8)</td><td align="center" valign="middle" >GV</td><td align="center" valign="middle" >0.949</td><td align="center" valign="middle" >0.5362</td><td align="center" valign="middle" >0.949</td><td align="center" valign="middle" >0.3738</td><td align="center" valign="middle" >0.956</td><td align="center" valign="middle" >0.3191</td><td align="center" valign="middle" >0.956</td><td align="center" valign="middle" >0.2453</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >LS</td><td align="center" valign="middle" >0.976</td><td align="center" valign="middle" >0.4637</td><td align="center" valign="middle" >0.954</td><td align="center" valign="middle" >0.3418</td><td align="center" valign="middle" >0.954</td><td align="center" valign="middle" >0.2973</td><td align="center" valign="middle" >0.953</td><td align="center" valign="middle" >0.2347</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bayes</td><td align="center" valign="middle" >0.949</td><td align="center" valign="middle" >0.5363</td><td align="center" valign="middle" >0.951</td><td align="center" valign="middle" >0.3743</td><td align="center" valign="middle" >0.952</td><td align="center" valign="middle" >0.3186</td><td align="center" valign="middle" >0.951</td><td align="center" valign="middle" >0.2451</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bootstrap-t</td><td align="center" valign="middle" >0.908</td><td align="center" valign="middle" >0.7121</td><td align="center" valign="middle" >0.942</td><td align="center" valign="middle" >0.4132</td><td align="center" valign="middle" >0.946</td><td align="center" valign="middle" >0.2958</td><td align="center" valign="middle" >0.954</td><td align="center" valign="middle" >0.5204</td></tr></tbody></table></table-wrap></table-wrap-group><p>表3. 单参数指数分布的参数T的95%双侧置信区间的主要覆盖概率和平均置信长度</p><table-wrap id="table4" ><label><xref ref-type="table" rid="table4">Table 4</xref></label><caption><title> The probability of making the first type of error in hypothesis tes</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" ></th><th align="center" valign="middle" >( m , n ) = ( 5 , 5 )</th><th align="center" valign="middle" >( m , n ) = ( 15 , 10 )</th><th align="center" valign="middle" >( m , n ) = ( 20 , 15 )</th><th align="center" valign="middle" >( m , n ) = ( 30 , 30 )</th></tr></thead><tr><td align="center" valign="middle" >( λ 1 , λ 2 )</td><td align="center" valign="middle"  colspan="5"  >TIR</td></tr><tr><td align="center" valign="middle" >(1,2)</td><td align="center" valign="middle" >GV</td><td align="center" valign="middle" >0.041</td><td align="center" valign="middle" >0.043</td><td align="center" valign="middle" >0.047</td><td align="center" valign="middle" >0.049</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >LS</td><td align="center" valign="middle" >0.011</td><td align="center" valign="middle" >0.032</td><td align="center" valign="middle" >0.038</td><td align="center" valign="middle" >0.036</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bayes</td><td align="center" valign="middle" >0.041</td><td align="center" valign="middle" >0.043</td><td align="center" valign="middle" >0.047</td><td align="center" valign="middle" >0.049</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bootstrap</td><td align="center" valign="middle" >0.089</td><td align="center" valign="middle" >0.062</td><td align="center" valign="middle" >0.059</td><td align="center" valign="middle" >0.054</td></tr><tr><td align="center" valign="middle" >(3,2)</td><td align="center" valign="middle" >GV</td><td align="center" valign="middle" >0.0475</td><td align="center" valign="middle" >0.061</td><td align="center" valign="middle" >0.058</td><td align="center" valign="middle" >0.0525</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >LS</td><td align="center" valign="middle" >0.065</td><td align="center" valign="middle" >0.07</td><td align="center" valign="middle" >0.063</td><td align="center" valign="middle" >0.056</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bayes</td><td align="center" valign="middle" >0.046</td><td align="center" valign="middle" >0.048</td><td align="center" valign="middle" >0.049</td><td align="center" valign="middle" >0.050</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bootstrap</td><td align="center" valign="middle" >0.081</td><td align="center" valign="middle" >0.69</td><td align="center" valign="middle" >0.063</td><td align="center" valign="middle" >0.057</td></tr><tr><td align="center" valign="middle" >(5,2)</td><td align="center" valign="middle" >GV</td><td align="center" valign="middle" >0.05</td><td align="center" valign="middle" >0.043</td><td align="center" valign="middle" >0.056</td><td align="center" valign="middle" >0.044</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >LS</td><td align="center" valign="middle" >0.083</td><td align="center" valign="middle" >0.073</td><td align="center" valign="middle" >0.074</td><td align="center" valign="middle" >0.062</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bayes</td><td align="center" valign="middle" >0.048</td><td align="center" valign="middle" >0.049</td><td align="center" valign="middle" >0.052</td><td align="center" valign="middle" >0.051</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bootstrap</td><td align="center" valign="middle" >0.085</td><td align="center" valign="middle" >0.079</td><td align="center" valign="middle" >0.069</td><td align="center" valign="middle" >0.059</td></tr><tr><td align="center" valign="middle" >(7,2)</td><td align="center" valign="middle" >GV</td><td align="center" valign="middle" >0.054</td><td align="center" valign="middle" >0.047</td><td align="center" valign="middle" >0.059</td><td align="center" valign="middle" >0.047</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >LS</td><td align="center" valign="middle" >0.099</td><td align="center" valign="middle" >0.086</td><td align="center" valign="middle" >0.081</td><td align="center" valign="middle" >0.071</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bayes</td><td align="center" valign="middle" >0.046</td><td align="center" valign="middle" >0.047</td><td align="center" valign="middle" >0.054</td><td align="center" valign="middle" >0.052</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bootstrap</td><td align="center" valign="middle" >0.087</td><td align="center" valign="middle" >0.089</td><td align="center" valign="middle" >0.091</td><td align="center" valign="middle" >0.062</td></tr></tbody></table></table-wrap><p>表4. 检验犯第一类错误的概率</p><table-wrap id="table5" ><label><xref ref-type="table" rid="table5">Table 5</xref></label><caption><title> The probability of making the first type of error in hypothesis tes</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" ></th><th align="center" valign="middle" >( m , n ) = ( 5 , 5 )</th><th align="center" valign="middle" >( m , n ) = ( 15 , 10 )</th><th align="center" valign="middle" >( m , n ) = ( 20 , 15 )</th><th align="center" valign="middle" >( m , n ) = ( 30 , 30 )</th></tr></thead><tr><td align="center" valign="middle" >( λ 1 , λ 2 )</td><td align="center" valign="middle"  colspan="5"  >TIR</td></tr><tr><td align="center" valign="middle" >(1,8)</td><td align="center" valign="middle" >GV</td><td align="center" valign="middle" >0.055</td><td align="center" valign="middle" >0.037</td><td align="center" valign="middle" >0.049</td><td align="center" valign="middle" >0.051</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >LS</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0.014</td><td align="center" valign="middle" >0.015</td><td align="center" valign="middle" >0.027</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bayes</td><td align="center" valign="middle" >0.056</td><td align="center" valign="middle" >0.052</td><td align="center" valign="middle" >0.049</td><td align="center" valign="middle" >0.051</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bootstrap</td><td align="center" valign="middle" >0.083</td><td align="center" valign="middle" >0.081</td><td align="center" valign="middle" >0.075</td><td align="center" valign="middle" >0.053</td></tr><tr><td align="center" valign="middle" >(3,8)</td><td align="center" valign="middle" >GV</td><td align="center" valign="middle" >0.045</td><td align="center" valign="middle" >0.051</td><td align="center" valign="middle" >0.055</td><td align="center" valign="middle" >0.046</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >LS</td><td align="center" valign="middle" >0.072</td><td align="center" valign="middle" >0.029</td><td align="center" valign="middle" >0.037</td><td align="center" valign="middle" >0.033</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bayes</td><td align="center" valign="middle" >0.044</td><td align="center" valign="middle" >0.046</td><td align="center" valign="middle" >0.052</td><td align="center" valign="middle" >0.051</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bootstrap</td><td align="center" valign="middle" >0.083</td><td align="center" valign="middle" >0.079</td><td align="center" valign="middle" >0.071</td><td align="center" valign="middle" >0.059</td></tr><tr><td align="center" valign="middle" >(5,8)</td><td align="center" valign="middle" >GV</td><td align="center" valign="middle" >0.056</td><td align="center" valign="middle" >0.046</td><td align="center" valign="middle" >0.051</td><td align="center" valign="middle" >0.052</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >LS</td><td align="center" valign="middle" >0.020</td><td align="center" valign="middle" >0.046</td><td align="center" valign="middle" >0.041</td><td align="center" valign="middle" >0.045</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bayes</td><td align="center" valign="middle" >0.053</td><td align="center" valign="middle" >0.052</td><td align="center" valign="middle" >0.048</td><td align="center" valign="middle" >0.049</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bootstrap</td><td align="center" valign="middle" >0.085</td><td align="center" valign="middle" >0.078</td><td align="center" valign="middle" >0.066</td><td align="center" valign="middle" >0.052</td></tr><tr><td align="center" valign="middle" >(7,8)</td><td align="center" valign="middle" >GV</td><td align="center" valign="middle" >0.057</td><td align="center" valign="middle" >0.047</td><td align="center" valign="middle" >0.051</td><td align="center" valign="middle" >0.054</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >LS</td><td align="center" valign="middle" >0.032</td><td align="center" valign="middle" >0.048</td><td align="center" valign="middle" >0.046</td><td align="center" valign="middle" >0.049</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bayes</td><td align="center" valign="middle" >0.046</td><td align="center" valign="middle" >0.047</td><td align="center" valign="middle" >0.048</td><td align="center" valign="middle" >0.053</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bootstrap</td><td align="center" valign="middle" >0.087</td><td align="center" valign="middle" >0.078</td><td align="center" valign="middle" >0.072</td><td align="center" valign="middle" >0.060</td></tr></tbody></table></table-wrap><p>表5. 检验犯第一类错误的概率</p><table-wrap id="table6" ><label><xref ref-type="table" rid="table6">Table 6</xref></label><caption><title> The power of the hypothesis tes</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" ></th><th align="center" valign="middle" >( m , n ) = ( 5 , 5 )</th><th align="center" valign="middle" >( m , n ) = ( 15 , 10 )</th><th align="center" valign="middle" >( m , n ) = ( 20 , 15 )</th><th align="center" valign="middle" >( m , n ) = ( 30 , 30 )</th></tr></thead><tr><td align="center" valign="middle" >( λ 1 , λ 2 )</td><td align="center" valign="middle"  colspan="5"  >TIR</td></tr><tr><td align="center" valign="middle" >(1,2)</td><td align="center" valign="middle" >GV</td><td align="center" valign="middle" >0.129</td><td align="center" valign="middle" >0.199</td><td align="center" valign="middle" >0.264</td><td align="center" valign="middle" >0.415</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >LS</td><td align="center" valign="middle" >0.074</td><td align="center" valign="middle" >0.184</td><td align="center" valign="middle" >0.247</td><td align="center" valign="middle" >0.351</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bayes</td><td align="center" valign="middle" >0.135</td><td align="center" valign="middle" >0.211</td><td align="center" valign="middle" >0.256</td><td align="center" valign="middle" >0.395</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bootstrap</td><td align="center" valign="middle" >0.201</td><td align="center" valign="middle" >0.272</td><td align="center" valign="middle" >0.322</td><td align="center" valign="middle" >0.706</td></tr><tr><td align="center" valign="middle" >(3,2)</td><td align="center" valign="middle" >GV</td><td align="center" valign="middle" >0.434</td><td align="center" valign="middle" >0.765</td><td align="center" valign="middle" >0.891</td><td align="center" valign="middle" >0.991</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >LS</td><td align="center" valign="middle" >0.590</td><td align="center" valign="middle" >0.856</td><td align="center" valign="middle" >0.931</td><td align="center" valign="middle" >0.986</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bayes</td><td align="center" valign="middle" >0.441</td><td align="center" valign="middle" >0.747</td><td align="center" valign="middle" >0.883</td><td align="center" valign="middle" >0.984</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bootstrap</td><td align="center" valign="middle" >0.765</td><td align="center" valign="middle" >0.909</td><td align="center" valign="middle" >0.950</td><td align="center" valign="middle" >0.991</td></tr><tr><td align="center" valign="middle" >(5,2)</td><td align="center" valign="middle" >GV</td><td align="center" valign="middle" >0.361</td><td align="center" valign="middle" >0.662</td><td align="center" valign="middle" >0.805</td><td align="center" valign="middle" >0.952</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >LS</td><td align="center" valign="middle" >0.535</td><td align="center" valign="middle" >0.796</td><td align="center" valign="middle" >0.0876</td><td align="center" valign="middle" >0.973</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bayes</td><td align="center" valign="middle" >0.374</td><td align="center" valign="middle" >0.658</td><td align="center" valign="middle" >0.800</td><td align="center" valign="middle" >0.959</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bootstrap</td><td align="center" valign="middle" >0.736</td><td align="center" valign="middle" >0.0865</td><td align="center" valign="middle" >0.919</td><td align="center" valign="middle" >0.978</td></tr><tr><td align="center" valign="middle" >(7,2)</td><td align="center" valign="middle" >GV</td><td align="center" valign="middle" >0.354</td><td align="center" valign="middle" >0.589</td><td align="center" valign="middle" >0.762</td><td align="center" valign="middle" >0.942</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >LS</td><td align="center" valign="middle" >0.52560.761</td><td align="center" valign="middle" >0.854</td><td align="center" valign="middle" >0.961</td><td align="center" valign="middle" ></td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bayes</td><td align="center" valign="middle" >0.334</td><td align="center" valign="middle" >0.625</td><td align="center" valign="middle" >0.755</td><td align="center" valign="middle" >0.934</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bootstrap</td><td align="center" valign="middle" >0.716</td><td align="center" valign="middle" >0.854</td><td align="center" valign="middle" >0.907</td><td align="center" valign="middle" >0.973</td></tr></tbody></table></table-wrap><p>表6. 检验的功效</p><table-wrap id="table7" ><label><xref ref-type="table" rid="table7">Table 7</xref></label><caption><title> The power of the hypothesis tes</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" ></th><th align="center" valign="middle" >( m , n ) = ( 5 , 5 )</th><th align="center" valign="middle" >( m , n ) = ( 15 , 10 )</th><th align="center" valign="middle" >( m , n ) = ( 20 , 15 )</th><th align="center" valign="middle" >( m , n ) = ( 30 , 30 )</th></tr></thead><tr><td align="center" valign="middle" >( λ 1 , λ 2 )</td><td align="center" valign="middle"  colspan="5"  >TIR</td></tr><tr><td align="center" valign="middle" >(1,8)</td><td align="center" valign="middle" >GV</td><td align="center" valign="middle" >0.055</td><td align="center" valign="middle" >0.626</td><td align="center" valign="middle" >0.774</td><td align="center" valign="middle" >0.932</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >LS</td><td align="center" valign="middle" >0.059</td><td align="center" valign="middle" >0.460</td><td align="center" valign="middle" >0.667</td><td align="center" valign="middle" >0.900</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bayes</td><td align="center" valign="middle" >0.336</td><td align="center" valign="middle" >0.614</td><td align="center" valign="middle" >0.765</td><td align="center" valign="middle" >0.932</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bootstrap</td><td align="center" valign="middle" >0.727</td><td align="center" valign="middle" >0.865</td><td align="center" valign="middle" >0.907</td><td align="center" valign="middle" >0.978</td></tr><tr><td align="center" valign="middle" >(3,8)</td><td align="center" valign="middle" >GV</td><td align="center" valign="middle" >0.326</td><td align="center" valign="middle" >0.607</td><td align="center" valign="middle" >0.754</td><td align="center" valign="middle" >0.929</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >LS</td><td align="center" valign="middle" >0.257</td><td align="center" valign="middle" >0.585</td><td align="center" valign="middle" >0.735</td><td align="center" valign="middle" >0.916</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bayes</td><td align="center" valign="middle" >0.323</td><td align="center" valign="middle" >0.588</td><td align="center" valign="middle" >0.745</td><td align="center" valign="middle" >0.927</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bootstrap</td><td align="center" valign="middle" >0.706</td><td align="center" valign="middle" >0.839</td><td align="center" valign="middle" >0.935</td><td align="center" valign="middle" >0.965</td></tr><tr><td align="center" valign="middle" >(5,8)</td><td align="center" valign="middle" >GV</td><td align="center" valign="middle" >0.408</td><td align="center" valign="middle" >0.713</td><td align="center" valign="middle" >0.849</td><td align="center" valign="middle" >0.978</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >LS</td><td align="center" valign="middle" >0.471</td><td align="center" valign="middle" >0.775</td><td align="center" valign="middle" >0.874</td><td align="center" valign="middle" >0.975</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bayes</td><td align="center" valign="middle" >0.405</td><td align="center" valign="middle" >0.721</td><td align="center" valign="middle" >0.863</td><td align="center" valign="middle" >0.974</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bootstrap</td><td align="center" valign="middle" >0.765</td><td align="center" valign="middle" >0.899</td><td align="center" valign="middle" >0.945</td><td align="center" valign="middle" >0.989</td></tr><tr><td align="center" valign="middle" >(7,8)</td><td align="center" valign="middle" >GV</td><td align="center" valign="middle" >0.546</td><td align="center" valign="middle" >0.867</td><td align="center" valign="middle" >0.952</td><td align="center" valign="middle" >0.995</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >LS</td><td align="center" valign="middle" >0.652</td><td align="center" valign="middle" >0.914</td><td align="center" valign="middle" >0.973</td><td align="center" valign="middle" >0.998</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bayes</td><td align="center" valign="middle" >0.529</td><td align="center" valign="middle" >0.951</td><td align="center" valign="middle" >0.946</td><td align="center" valign="middle" >0.996</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Bootstrap</td><td align="center" valign="middle" >0.528</td><td align="center" valign="middle" >0.867</td><td align="center" valign="middle" >0.977</td><td align="center" valign="middle" >0.998</td></tr></tbody></table></table-wrap><p>表7. 检验的功效</p><p>根据上述结果可以发现，广义推断方法在可靠性参数推断的区间估计与假设检验方面的表现都很好，此优点在样本量很小的情况下更为显著，另外广义枢轴量法可以用于构造讨厌参数存在时兴趣参数的置信区间以及解决带讨厌参数的假设检验问题，因此当传统频率学派方法无法给出精确方法且大样本难以获取时，广义推断方法可以有效地解决这类问题。</p></sec><sec id="s6"><title>文章引用</title><p>魏秋月,王春玲,赵 昕. 指数分布下可靠性参数的推断Inference of Reliability Parameters under Exponential Distribution[J]. 应用数学进展, 2019, 08(09): 1562-1573. https://doi.org/10.12677/AAM.2019.89183</p></sec><sec id="s7"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.32281-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Owen, D.B. Craswell, K.J. and Hanson, D.L. (1964) Nonparametric Upper Confidence Bounds for   and Confidence Limits for   when X and Y Are Normal. Journal of the American Statistical Association, 59, 906-924. &lt;br&gt;https://doi.org/10.1080/01621459.1964.10480739</mixed-citation></ref><ref id="hanspub.32281-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Enis, P. and Geisser, S. (1971) Estimation of the Probability that  . Journal American Statistical Association, 66, 162-168. &lt;br&gt;https://doi.org/10.1080/01621459.1971.10482238</mixed-citation></ref><ref id="hanspub.32281-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Tong, H. (1974) A Note on the Estimation of   in the Exponential Case. Technometrics, 16, 625. 
&lt;br&gt;https://doi.org/10.2307/1267617</mixed-citation></ref><ref id="hanspub.32281-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Chao, A. (1982) On Comparing Estimators of   in the Ex-ponential Case. IEEE Transaction on Reliability, R-31, 389-392. &lt;br&gt;https://doi.org/10.1109/TR.1982.5221387</mixed-citation></ref><ref id="hanspub.32281-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Bai, D.S. and Hong, Y.W. (1992) Estimation of   in the Exponential Case with Common Location Parameter. Communications in Statistics-Theory and Methods, 21, 269-282. &lt;br&gt;https://doi.org/10.1080/03610929208830777</mixed-citation></ref><ref id="hanspub.32281-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Tsui, K.W. and Weerahandi, S. (1989) Generalized p-Values in Significance Testing of Hypotheses in the Presence of Nuisance Parameters. Journal American Statistical Association, 84, 602-607.  
&lt;br&gt;https://doi.org/10.1080/01621459.1989.10478810</mixed-citation></ref><ref id="hanspub.32281-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Weerahandi, S. (1993) Generalized Confidence Intervals. Journal of the American Statistical Association, 88, 899-905.  
&lt;br&gt;https://doi.org/10.1080/01621459.1993.10476355</mixed-citation></ref><ref id="hanspub.32281-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">徐兴忠, 李国英.枢轴分布族中的Fiducial推断[J]. 中国科学A辑, 2006, 36(3): 340-360.</mixed-citation></ref><ref id="hanspub.32281-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Baklizi, A. (2003) Confidence Intervals For   in The Exponential Case with Common Location Parameter. Journal of Modern Applied Statistical Methods, 2. &lt;br&gt;https://doi.org/10.22237/jmasm/1067645220</mixed-citation></ref></ref-list></back></article>