<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">JISP</journal-id><journal-title-group><journal-title>Journal of Image and Signal Processing</journal-title></journal-title-group><issn pub-type="epub">2325-6753</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/JISP.2015.43008</article-id><article-id pub-id-type="publisher-id">JISP-15708</article-id><article-categories><subj-group subj-group-type="heading"><subject>JISP20150300000_70135006.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于视频的雾天驾驶场景及其能见度识别算法研究
  Research of Fog Driving Scenarios and Visibility Recognition Algorithm Based on Video
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>朱</surname><given-names>舞雪</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>宋</surname><given-names>春林</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>同济大学电子与信息工程学院，上海</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>02</day><month>07</month><year>2015</year></pub-date><volume>04</volume><issue>03</issue><fpage>67</fpage><lpage>77</lpage><history><date date-type="received"><day>Aug.</day>	<month>15th,</month>	<year>2014</year></date><date date-type="rev-recd"><day>Sep.</day>	<month>25th,</month>	<year>2014</year>	</date><date date-type="accepted"><day>Oct.</day>	<month>4th,</month>	<year>2014</year></date></history><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   获取实时、全面、准确的道路交通场景信息是预防交通事故的重要前提和基本保障，也是实现城市交通智能化的关键。针对雾天驾驶场景及其能见度的识别，传统算法存在复杂度高、鲁棒性差的问题，且多为固定场景下的识别，很难应用于移动的驾驶场景下。本文提出了一种基于单目视觉的雾天识别和能见度估计算法。该算法以柯什米德定律为基础，通过限定Hough变换的极角、半径，压缩投票空间，减少了计算量和复杂度。自定义的区域增长条件，较好的解决了移动场景下的道路分割准确度差的问题。利用加权平均的图像亮度拐点估计方法，能有效地排除干扰，保证拐点估计的准确度。仿真结果表明，算法能实现移动场景下的雾天及能见度识别，精确度、实时性、鲁棒性较好。 Obtaining real-time, comprehensive and accurate road traffic information is the important pre-condition and basic guarantee to prevent traffic accidents, and also is the key to realize the urban traffic intelligent. For recognition of fog driving scenarios and visibility, the traditional algorithm has the problems of high complexity, poor robustness, and more using in fixed scene; it is difficult to apply to mobile driving scenarios. This paper proposed a fog and visibility estimation algorithm based on monocular vision. The algorithm, based on the law of Koschmieder, compresses Hough transformation vote space and reduces calculation amount and complexity by limiting polar angle and radius. Custom regional growth solves the problem of poor accuracy in the mobile scenarios’ road segmentation. The weighted average of luminance method which is used in estimation of inflection point can effectively remove interference and ensure accuracy. The simulation results show that the algorithm can realize the recognition of fog and visibility in mobile scenarios with high accuracy, real-time performance and robustness.
    
  
 
</p></abstract><kwd-group><kwd>雾检测，能见度，柯什米德定律，区域分割，Hough变换, Fog Detection</kwd><kwd> Visibility</kwd><kwd> Koschmieder</kwd><kwd> Region Segmentation</kwd><kwd> Hough Transformation</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>基于视频的雾天驾驶场景及其能见度识别算法研究<sup> </sup></title><p>朱舞雪，宋春林</p><p>同济大学电子与信息工程学院，上海</p><p>Email: zhuwuxue1115@163.com</p><p>收稿日期：2015年7月1日；录用日期：2015年7月14日；发布日期：2015年7月20日</p><disp-formula id="hanspub.15708-formula4926"><graphic xlink:href="http://html.hanspub.org/file/5-2670053x5_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>获取实时、全面、准确的道路交通场景信息是预防交通事故的重要前提和基本保障，也是实现城市交通智能化的关键。针对雾天驾驶场景及其能见度的识别，传统算法存在复杂度高、鲁棒性差的问题，且多为固定场景下的识别，很难应用于移动的驾驶场景下。本文提出了一种基于单目视觉的雾天识别和能见度估计算法。该算法以柯什米德定律为基础，通过限定Hough变换的极角、半径，压缩投票空间，减少了计算量和复杂度。自定义的区域增长条件，较好的解决了移动场景下的道路分割准确度差的问题。利用加权平均的图像亮度拐点估计方法，能有效地排除干扰，保证拐点估计的准确度。仿真结果表明，算法能实现移动场景下的雾天及能见度识别，精确度、实时性、鲁棒性较好。</p><p>关键词 :雾检测，能见度，柯什米德定律，区域分割，Hough变换</p><disp-formula id="hanspub.15708-formula4927"><graphic xlink:href="http://html.hanspub.org/file/5-2670053x6_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s3"><title>1. 引言</title><p>“车祸猛于虎”，当下，汽车正进入千家万户的生活。据统计，我国每年的道路交通伤亡事故高达二十万例，其中恶劣天气——雾天导致的交通事故尤为严重。人们己经越来越认识到交通场景信息采集的重要性，获取实时、全面、准确的道路交通场景信息是预防交通事故的重要前提和基本保障，也是实现城市交通智能化的关键。因此，对雾天驾驶场景及其能见度进行智能识别，是一项必要且急迫的工作，具有很好的现实意义。</p><p>传统的雾天及能见度的识别主要依靠物理传感装置(湿度、气压、红外传感器，雷达、激光等)，该方法应用较为广泛，但设备的安装和维护成本较高。在图像理解和计算机识别方面，文献 [<xref ref-type="bibr" rid="hanspub.15708-ref1">1</xref>] 利用雾的模糊效应，实现雾天的识别，同时结合道路消失点的检测估计能见度。该算法的优点是同时实现了雾天驾驶场景与能见度的识别，但计算量大，易受环境干扰，鲁棒性较差。文献 [<xref ref-type="bibr" rid="hanspub.15708-ref2">2</xref>] 提出了利用双目视觉技术结合不同对比度估计能见度的方法，但其不能进行雾天场景的检测。文献 [<xref ref-type="bibr" rid="hanspub.15708-ref3">3</xref>] 通过将交通视频的当前背景与晴天背景相减得到差分图像，提取差分图像的纹理特征来识别雾天，实时性较好，但只适用于固定场景下的雾天识别。文献 [<xref ref-type="bibr" rid="hanspub.15708-ref4">4</xref>] 利用图像的退化模型获取与天气现象相关的参量，从而达到识别天气的目的。但是在雨或霾的天气条件下，所测得扩散函数的跨度值与晴天和薄雾天气条件下所得的有重叠，会导致天气现象的误判。文献 [<xref ref-type="bibr" rid="hanspub.15708-ref5">5</xref>] 通过提取图像功率谱斜率、对比度、噪声和饱和度等特征，构造支持向量机，实现雾天的识别。但其识别率较低，复杂度较高，难以满足实时性的要求。</p><p>针对雾天与能见度识别算法存在的算法复杂度高，且难以对两者同时准确识别的问题。本文提出了一种基于单目视觉的雾天识别和能见度估计算法。该算法以柯什米德定律为基础，建立驾驶场景下的摄像机模型。利用Canny算子进行边缘检测，通过限定Hough变换的极角，降低投票空间数据量，降低了车道线检测的计算量和复杂度。自定义的区域增长条件，对道路区域分割的适用性更强，能满足实时性、有效性的要求。利用加权平均的图像亮度拐点估计，进一步保证了拐点估计的准确度。仿真结果表明，算法能实现移动场景下的雾天及能见度识别，精确度、实时性、鲁棒性较好。</p></sec><sec id="s4"><title>2. 驾驶场景模型</title><p>在单目摄像机系统，道路被近似假设为平面 [<xref ref-type="bibr" rid="hanspub.15708-ref6">6</xref>] ，以估计图像中的像素所对应的实际距离。本文的研究基于车载单目摄像机捕获的视频信息，图1给出了车载单目摄像机在交通场景下的模型。</p><p>图1中，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x7_hanspub.png" xlink:type="simple"/></inline-formula>坐标系表示图像中的像素坐标系，其中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x8_hanspub.png" xlink:type="simple"/></inline-formula>分别代表像素的行数和列数。<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x9_hanspub.png" xlink:type="simple"/></inline-formula>为光轴在图像平面上的投影，H为摄像机的相对高度，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x10_hanspub.png" xlink:type="simple"/></inline-formula>为摄像机光轴于地平线之间的夹角。f表示摄像机的焦距，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x11_hanspub.png" xlink:type="simple"/></inline-formula>、<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x12_hanspub.png" xlink:type="simple"/></inline-formula>为单位像素的水平、垂直尺寸，本文中假设<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x13_hanspub.png" xlink:type="simple"/></inline-formula>。</p><p>由于光在大气中传播时会发生衰减，Koschmieder [<xref ref-type="bibr" rid="hanspub.15708-ref7">7</xref>] 于1924年提出了一个物体本身光强度与在一定距离处观测到的光强度的关系模型，此模型被广泛应用于计算机视觉领域。其关系如下：</p><disp-formula id="hanspub.15708-formula4928"><label>(1)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-2670053x14_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中为物体本身亮度，为大气亮度，为在距离d处观测到的亮度，表示消光系数。该公式表明在雾天物体的亮度以指数因子递减。将公式(1)左右两边同除以得到下列公式：</p><disp-formula id="hanspub.15708-formula4929"><label>(2)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-2670053x15_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x16_hanspub.png" xlink:type="simple"/></inline-formula>表示物体相对于背景的对比度，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x17_hanspub.png" xlink:type="simple"/></inline-formula>表示在距离d处物体的对比度。为了保证物体的可见度，对比度<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x18_hanspub.png" xlink:type="simple"/></inline-formula>必须大于某一阈值，国际照明委员会将对比度阈值设为0.05。通过求解公式(2)可以推导出能见度距离。</p><disp-formula id="hanspub.15708-formula4930"><label>(3)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-2670053x19_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s5"><title>3. 雾天与能见度识别算法</title><p>雾天与能见度识别的算法包括基于Canny算子的边缘检测、基于Hough变换的车道线检测、消失点估计、区域增长、拐点估计、雾天和能见度识别等模块，算法流程图如图2所示。</p><sec id="s5_1"><title>3.1. 边缘检测</title><p>常用的边缘检测算子有Sobel、Canny、Prewitt等。本文采用Canny算子，它是于1986年由John F. Canny提出，具有低误码率、高定位精度和抑制虚假边缘等优点 [<xref ref-type="bibr" rid="hanspub.15708-ref8">8</xref>] [<xref ref-type="bibr" rid="hanspub.15708-ref9">9</xref>] 。原始彩色图像信息量大，处理速度慢，所以首先进行灰度化。对灰度图进行边缘检测，能够提取图像中的灰度级突变、纹理结构变化、色彩变换等信息。</p><p>图1. 交通场景下的摄像机模型</p><p>图2. 算法流程图</p><p>对灰度图进行公式(4)的高斯滤波，去除噪声，得到平滑后的图像<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x22_hanspub.png" xlink:type="simple"/></inline-formula>；</p><disp-formula id="hanspub.15708-formula4931"><label>(4)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-2670053x23_hanspub.png"  xlink:type="simple"/></disp-formula><p>然后用一阶偏导的有限差分来计算梯度的幅值和方向。梯度矢量的模和方向分别如式(5) (6)所示，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x24_hanspub.png" xlink:type="simple"/></inline-formula>反映了图像的边缘强度，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x25_hanspub.png" xlink:type="simple"/></inline-formula>反映了边缘的方向。图像的边缘点则为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x26_hanspub.png" xlink:type="simple"/></inline-formula>方向上使<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x27_hanspub.png" xlink:type="simple"/></inline-formula>取得局部最大值的点；</p><disp-formula id="hanspub.15708-formula4932"><label>(5)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-2670053x28_hanspub.png"  xlink:type="simple"/></disp-formula><disp-formula id="hanspub.15708-formula4933"><label>(6)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-2670053x29_hanspub.png"  xlink:type="simple"/></disp-formula><p>仅仅得到全局的梯度并不足以确定边缘，因为确定边缘，必须保留梯度最大的点。所以需要进行非极大值抑制。将梯度角离散为圆周的四个扇区之一，以便用3*3的窗口作抑制运算。四个扇区的标号为0到3，对应3*3邻域的四种可能。在每个点上，邻域的中心像素<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x30_hanspub.png" xlink:type="simple"/></inline-formula>与沿着梯度线的两个像素相比。如果<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x31_hanspub.png" xlink:type="simple"/></inline-formula>的梯度值不比沿梯度线的两个相邻像素梯度值大，则令<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x32_hanspub.png" xlink:type="simple"/></inline-formula>。</p><p>最后用双阈值算法检测和连接边缘。对非极大值抑制图像作用两个阈值<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x33_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x34_hanspub.png" xlink:type="simple"/></inline-formula>，其中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x35_hanspub.png" xlink:type="simple"/></inline-formula>。由于<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x36_hanspub.png" xlink:type="simple"/></inline-formula>的阈值较高，去除大部分噪音，但同时也损失了有用的边缘信息。而<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x37_hanspub.png" xlink:type="simple"/></inline-formula>的阈值较低，保留了较多的信息。所以结合两个阈值作用的图像，连接边缘。</p><p>连接边缘的具体步骤如下：对<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x38_hanspub.png" xlink:type="simple"/></inline-formula>作用的图像进行扫描，当遇到一个非零灰度的像素<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x39_hanspub.png" xlink:type="simple"/></inline-formula>时，跟踪以<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x40_hanspub.png" xlink:type="simple"/></inline-formula>为开始点的轮廓线，直到轮廓线的终点<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x41_hanspub.png" xlink:type="simple"/></inline-formula>。考察<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x42_hanspub.png" xlink:type="simple"/></inline-formula>作用的图像中与<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x43_hanspub.png" xlink:type="simple"/></inline-formula>作用的图像中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x44_hanspub.png" xlink:type="simple"/></inline-formula>点位置对应的点<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x45_hanspub.png" xlink:type="simple"/></inline-formula>的8邻近区域。如果在<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x46_hanspub.png" xlink:type="simple"/></inline-formula>点的8邻近区域中有非零像素<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x47_hanspub.png" xlink:type="simple"/></inline-formula>存在，则将其包括到<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x48_hanspub.png" xlink:type="simple"/></inline-formula>作用的图像中，作为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x49_hanspub.png" xlink:type="simple"/></inline-formula>点。从<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x50_hanspub.png" xlink:type="simple"/></inline-formula>开始，重复第一步，直到无法继续为止。当完成对包含<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x51_hanspub.png" xlink:type="simple"/></inline-formula>的轮廓线的连结之后，将这条轮廓线标记为已经访问。回到第一步，寻找下一条轮廓线。重复第一步、第二步、第三步，直到<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x52_hanspub.png" xlink:type="simple"/></inline-formula>作用的图像中找不到新轮廓线为止。</p></sec><sec id="s5_2"><title>3.2. 车道线与消失点估计</title><p>Hough变换是图像处理中从图像中识别几何形状的基本方法之一[<xref ref-type="bibr" rid="hanspub.15708-ref10">10</xref>] 。其基本原理在于利用点与线的对偶性，将原始图像空间给定的曲线通过曲线表达形式变为参数空间的一个点。这样就把原始图像中给定曲线的检测问题转化为寻找参数空间的峰值问题。Hough变换的参数方程为：</p><disp-formula id="hanspub.15708-formula4934"><label>(7)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-2670053x53_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x54_hanspub.png" xlink:type="simple"/></inline-formula>为图像空间中直线到坐标原点的距离，范围为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x55_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x56_hanspub.png" xlink:type="simple"/></inline-formula>为图像对角线长度；<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x57_hanspub.png" xlink:type="simple"/></inline-formula>为直线与<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x58_hanspub.png" xlink:type="simple"/></inline-formula>轴之间的夹角，范围为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x59_hanspub.png" xlink:type="simple"/></inline-formula>。</p><p>由于车道线信息主要位于图像的下半部分，而上半部分多为天空、树木、路标等无效信息。所以在进行Hough变换时，只选取部分图像进行处理。不仅减少了信息的处理量，提高运算速度，而且减少了干扰，提高了检测精度。其次，传统离散Hough变换的投票空间为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x60_hanspub.png" xlink:type="simple"/></inline-formula> (假设N为图像中的目标点数，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x61_hanspub.png" xlink:type="simple"/></inline-formula>的变化步长为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x62_hanspub.png" xlink:type="simple"/></inline-formula>)，所以目标点的数量是影响Hough变换计算量的关键因素。为了减少计算量，本文提出了限定<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x63_hanspub.png" xlink:type="simple"/></inline-formula>值的思想。根据大量的样本分析和观察，设定<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x64_hanspub.png" xlink:type="simple"/></inline-formula>的取值范围为：<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x65_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x66_hanspub.png" xlink:type="simple"/></inline-formula>的范围为：<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x67_hanspub.png" xlink:type="simple"/></inline-formula>，其中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x68_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x69_hanspub.png" xlink:type="simple"/></inline-formula>分别为图像的宽度。通过Hough变换后，得到检测的车道线。车道线的交点即消失点。</p></sec><sec id="s5_3"><title>3.3. 自定义区域增长</title><p>由于图像中的道路部分混杂着雾信息，所以本算法的目的就是通过从下到上一行一行的扫描，寻找连续梯度变化最小的区域。从图像的底部选择灰度等级为该行灰度中间值的点作为区域增长的种子点。从种子点开始，当像素<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x70_hanspub.png" xlink:type="simple"/></inline-formula>满足下述条件时，才能被加入增长区域<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x71_hanspub.png" xlink:type="simple"/></inline-formula>：</p><p>1) 该像素不属于增长区域：</p><disp-formula id="hanspub.15708-formula4935"><label>(8)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-2670053x72_hanspub.png"  xlink:type="simple"/></disp-formula><p>2) 该像素不属于边缘点：</p><disp-formula id="hanspub.15708-formula4936"><label>(9)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-2670053x73_hanspub.png"  xlink:type="simple"/></disp-formula><p>3) 该像素与种子点之间满足下述关系：</p><disp-formula id="hanspub.15708-formula4937"><label>(10)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-2670053x74_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x75_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x76_hanspub.png" xlink:type="simple"/></inline-formula>为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x77_hanspub.png" xlink:type="simple"/></inline-formula>与<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x78_hanspub.png" xlink:type="simple"/></inline-formula>之间的线的行数，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x79_hanspub.png" xlink:type="simple"/></inline-formula>为最大垂直梯度。</p><p>4) 该像素与其下方的像素满足下述关系：</p><disp-formula id="hanspub.15708-formula4938"><label>(11)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-2670053x80_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s5_4"><title>3.4. 加权平均的拐点估计</title><p>本文的区域增长算法能较好的分割道路与天空的边界。但是由于道路上可能存在车辆、广告牌、路标等干扰信息，造成灰度变化拐点的不准确。本文提出了取连续三帧图像区域增长极限的纵坐标值，构成一个大的数据集。计算该数据集的加权平均数，以此计算最优的拐点值。</p><p>具体方法是，首先去掉数据集中的最大、最小值，然后计算剩余数据的平均值、中值，并将其加入到数据集中。统计数据集中每个数出现的频次，频次与数据总量的比值，作为该数据的权值。最终得到该数据集的加权平均值，作为灰度变化的拐点值。保证实时性的基础上，大大提高了算法的准确度。</p></sec><sec id="s5_5"><title>3.5. 雾检测与能见度估计</title><p>图像灰度变化的拐点代表了雾天驾驶场景下的可视点，而道路的消失点指晴天情况下的可视点。所以当拐点位置低于消失点位置时，可判定为雾天，反之则为晴天。</p><p>根据摄像机模型进一步估计可见距离。据图1建立公式：</p><disp-formula id="hanspub.15708-formula4939"><label>(12)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-2670053x81_hanspub.png"  xlink:type="simple"/></disp-formula><p>由于<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x82_hanspub.png" xlink:type="simple"/></inline-formula>为摄像机光轴于地平线之间的夹角，所以在图像坐标系中，地平线也可以表示为</p><disp-formula id="hanspub.15708-formula4940"><label>(13)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-2670053x83_hanspub.png"  xlink:type="simple"/></disp-formula><p>结合公式(4)、(5)，推导出下式：</p><disp-formula id="hanspub.15708-formula4941"><label>(14)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-2670053x84_hanspub.png"  xlink:type="simple"/></disp-formula><p>根据世界坐标系与图像坐标系的关系，得出下述公式</p><disp-formula id="hanspub.15708-formula4942"><label>(15)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-2670053x85_hanspub.png"  xlink:type="simple"/></disp-formula><p>所以，假设在道路上，距离原点d处有一点M，则其坐标可以表示为：<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x86_hanspub.png" xlink:type="simple"/></inline-formula>。将其代入公式(15)，得到下式：</p><disp-formula id="hanspub.15708-formula4943"><label>(16)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-2670053x87_hanspub.png"  xlink:type="simple"/></disp-formula><p>最终，得到图像中位于第v行的像素所代表的世界坐标系中的实际距离d，其关系式如下：</p><disp-formula id="hanspub.15708-formula4944"><label>(17)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-2670053x88_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x89_hanspub.png" xlink:type="simple"/></inline-formula>代表了图像中的地平线位置，而<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x90_hanspub.png" xlink:type="simple"/></inline-formula>。</p><p>由于<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x91_hanspub.png" xlink:type="simple"/></inline-formula>，将式(17)代入得：</p><disp-formula id="hanspub.15708-formula4945"><label>(18)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-2670053x92_hanspub.png"  xlink:type="simple"/></disp-formula><p>对公式(18)中的v求导，得：</p><disp-formula id="hanspub.15708-formula4946"><label>(19)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-2670053x93_hanspub.png"  xlink:type="simple"/></disp-formula><p>再次求导，得</p><disp-formula id="hanspub.15708-formula4947"><label>(20)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-2670053x94_hanspub.png"  xlink:type="simple"/></disp-formula><p>令<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x95_hanspub.png" xlink:type="simple"/></inline-formula>，则其有两个解。其中一个解为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x96_hanspub.png" xlink:type="simple"/></inline-formula>，即消光系数为0，显然无意义。另一个解为：</p><disp-formula id="hanspub.15708-formula4948"><label>(21)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-2670053x97_hanspub.png"  xlink:type="simple"/></disp-formula><p>所以根据式(3)和式(21)，可以得到可见距离的计算公式为：</p><disp-formula id="hanspub.15708-formula4949"><label>(22)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-2670053x98_hanspub.png"  xlink:type="simple"/></disp-formula><p><inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x99_hanspub.png" xlink:type="simple"/></inline-formula>为图像中灰度变化的拐点位置，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x100_hanspub.png" xlink:type="simple"/></inline-formula>为地平线位置，最终得到可见距离的估计值。</p></sec></sec><sec id="s6"><title>4. 结果分析</title><p>图3为多种边缘检测的结果比较，可以看出，Canny算子相比Sobel算子和Prewitt算子，对实际边缘的敏感度较高，且不易带入伪边缘。利用Canny算子的边缘检测要优于Sobel算子和Prewitt算子。图4为车道线检测的仿真结果，结果表明，限定极角和半径的Hough变换，能高效准确的实现车道线和消失点的检测。图5为多种区域分割的结果比较，Otsu阈值分割的准确率不够高，部分天空区域被分割到道路区域。迭代式阈值分割，能有效的分割道路与天空区域，但计算量较大。自定义区域增长的道路分割方法，既能有效的分割天空与道路区域，又能利用车道线的检测结果，压缩区域分割的数据处理量，减少计算量，提高处理速度。且当路面上存在部分遮挡物时，该算法仍能有效地提取道路区域。图6给出了消失点位置与拐点位置。其中，红色线为检测到的车道线及其延长线，交点为道路消失点。黑色线代表地平线，即消失点所在位置。蓝色线为拐点所在位置。</p><p>根据柯什米的定律可以计算消光系数，得到可见距离，并将雾天分为低雾、中雾、大雾，如表1所示。表2给出了在不同天气状况下的雾天检测结果统计表(表3为已有文献算法的雾天检测结果)。</p><p>仿真结果表明，本文的雾天检测算法对视频样本的正确检测率达到90%以上。通过与文献 [<xref ref-type="bibr" rid="hanspub.15708-ref5">5</xref>] 中算法的检测结果的比较，可以看出本文算法检测结果的正确率远远高于文献 [<xref ref-type="bibr" rid="hanspub.15708-ref5">5</xref>] 中算法的检测结果。图7给出了本文算法对能见度测量的误差，结果表明，误差距离控制在(−10 m, 10 m)之间。说明了该算法提供了精确的雾及能见度的检测结果(晴、低雾、中雾、高雾)。结果输出时，根据连续三个雾等级信号来判断当前天气状态，提高了系统的精确性。算法运算速度快，满足实时性的要求。摄像机的参数已知时，该算法可以用于不同的安装环境中。</p></sec><sec id="s7"><title>5. 结束语</title><p>雾天驾驶场景及其能见度的识别，是预防交通事故的重要前提也是实现智能交通的关键。本文基于计算机单目视觉技术，提出了一种以柯什米德定律为基础的简单高效的移动场景下的雾天及能见度识别算法，并用不同的天气场景数据进行测试，仿真结果表明，算法精确度、实时性、鲁棒性较好，对智能交通具有重要意义。但是本文算法在路面起伏较大的情况下的准确度较差，这是该算法的一个缺点，在后续的研究中将解决此问题。</p><p>图3. 几种边缘检测算子的比较。(a) 雾天；(b) Canny算子；(c) Sobel算子；(d) Prewitt算子</p><p>图4. 消失点估计</p><p>图5. 多种区域分割结果比较。(a) Otsu阈值分割；(b) 迭代式阈值分割；(c) 自定义区域增长</p><p>图6. 不同场景下的消失点位置与拐点位置</p><p>图7. 能见度测量误差统计</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Fog classif</title></caption><table><tbody><thead><tr><th align="center" valign="middle"  colspan="2"  >能见度</th><th align="center" valign="middle"  rowspan="2"  >雾的分类</th></tr></thead><tr><td align="center" valign="middle" >最小</td><td align="center" valign="middle" >最大</td></tr><tr><td align="center" valign="middle" >1000 m</td><td align="center" valign="middle" ><inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670053x112_hanspub.png" xlink:type="simple"/></inline-formula>m</td><td align="center" valign="middle" >无雾</td></tr><tr><td align="center" valign="middle" >300 m</td><td align="center" valign="middle" >1000 m</td><td align="center" valign="middle" >薄雾</td></tr><tr><td align="center" valign="middle" >100 m</td><td align="center" valign="middle" >300 m</td><td align="center" valign="middle" >中雾</td></tr><tr><td align="center" valign="middle" >0 m</td><td align="center" valign="middle" >100 m</td><td align="center" valign="middle" >浓雾</td></tr></tbody></table></table-wrap><p>表1. 雾天分类</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> Fog detection result with the proposed algorith</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >天气</th><th align="center" valign="middle" >检测总数</th><th align="center" valign="middle" >检测正确数</th><th align="center" valign="middle" >检测正确率</th></tr></thead><tr><td align="center" valign="middle" >晴天</td><td align="center" valign="middle" >19,031</td><td align="center" valign="middle" >17,607</td><td align="center" valign="middle" >92.52%</td></tr><tr><td align="center" valign="middle" >薄雾</td><td align="center" valign="middle" >16,354</td><td align="center" valign="middle" >15,004</td><td align="center" valign="middle" >91.75%</td></tr><tr><td align="center" valign="middle" >中雾</td><td align="center" valign="middle" >10,675</td><td align="center" valign="middle" >9937</td><td align="center" valign="middle" >93.09%</td></tr><tr><td align="center" valign="middle" >浓雾</td><td align="center" valign="middle" >18,587</td><td align="center" valign="middle" >17,498</td><td align="center" valign="middle" >94.15%</td></tr></tbody></table></table-wrap><p>表2. 本文算法雾天检测结果</p><table-wrap id="table3" ><label><xref ref-type="table" rid="table3">Table 3</xref></label><caption><title> Fog detection result in paper [1</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >天气</th><th align="center" valign="middle" >检测总数</th><th align="center" valign="middle" >检测正确数</th><th align="center" valign="middle" >检测正确率</th></tr></thead><tr><td align="center" valign="middle" >薄雾及晴天</td><td align="center" valign="middle" >17,511</td><td align="center" valign="middle" >14,236</td><td align="center" valign="middle" >81.3%</td></tr><tr><td align="center" valign="middle" >中雾</td><td align="center" valign="middle" >10,675</td><td align="center" valign="middle" >9405</td><td align="center" valign="middle" >88.1%</td></tr><tr><td align="center" valign="middle" >浓雾</td><td align="center" valign="middle" >8587</td><td align="center" valign="middle" >7170</td><td align="center" valign="middle" >83.5%</td></tr></tbody></table></table-wrap><p>表3. 文献[<xref ref-type="bibr" rid="hanspub.15708-ref1">1</xref>] 算法的雾天检测结果</p></sec><sec id="s8"><title>基金项目</title><p>上海市自然科学基金(14ZR1442700)。</p></sec><sec id="s9"><title>文章引用</title><p>朱舞雪,宋春林, (2015) 基于视频的雾天驾驶场景及其能见度识别算法研究Research of Fog Driving Scenarios and Visibility Recognition Algorithm Based on Video. 图像与信号处理,03,67-77. doi: 10.12677/JISP.2015.43008</p></sec><sec id="s10"><title>参考文献 (References)</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.15708-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Bronte, S., Bergasa, L.M. and Alcantarilla, P.F. (2009) Fog detection system based on computer vision techniques. International IEEE Conference on Intelligent Transportation Systems, St. Louis, 4-7 October 2009, 1-6. 
&lt;br&gt;http://dx.doi.org/10.1109/itsc.2009.5309842</mixed-citation></ref><ref id="hanspub.15708-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Hautiere, N., Labayrade, R. and Aubert, D. (2006) Real-time disparity contrast combination for onboard estimation of the visibility distance. IEEE Transactions on Intelligent Transportation Systems, 7, 201-212. 
&lt;br&gt;http://dx.doi.org/10.1109/TITS.2006.874682</mixed-citation></ref><ref id="hanspub.15708-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">宋洪军, 陈阳舟, 郜园园 (2013) 基于交通视频的雾天检测与去雾方法研究. 控制工程, 6, 1156-1160.</mixed-citation></ref><ref id="hanspub.15708-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">宋晓建, 杨玲(2011) 基于图像退化模型的天气现象识别. 成都信息工程学院学报, 2, 132-136.</mixed-citation></ref><ref id="hanspub.15708-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">李骞, 范茵, 张璟, 李宝强 (2011) 基于室外图像的天气现象识别方法. 计算机应用, 6, 1624-1627.</mixed-citation></ref><ref id="hanspub.15708-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Negru, M. and Nedevschi, S. (2013) Image based fog detection and visibility estimation for driving assistance systems. IEEE International Conference on Intelligent Computer Communication &amp; Processing, 5-7 September 2013, 163-168. 
&lt;br&gt;http://dx.doi.org/10.1109/iccp.2013.6646102</mixed-citation></ref><ref id="hanspub.15708-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Hautiére, N., et al. (2006) Automatic fog detection and estimation of visibility distance through use of an onboard camera. Machine Vision &amp; Applications, 17, 8-20. &lt;br&gt;http://dx.doi.org/10.1007/s00138-005-0011-1</mixed-citation></ref><ref id="hanspub.15708-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Canny, J. (1986) A computational approach to edge detection. IEEE Transactions on Pattern Analysis &amp; Machine Intelligence, PAMI-8, 184-203. &lt;br&gt;http://dx.doi.org/10.1109/tpami.1986.4767851</mixed-citation></ref><ref id="hanspub.15708-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">袁萍 (2014) 高速公路恶劣天气及交通状况智能分析系统研究与实现. 硕士论文, 西南交通大学, 成都.</mixed-citation></ref><ref id="hanspub.15708-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Salvucci, D.D. (2004) Inferring driver intent: A case study in lane-change detection. Human Factors &amp; Ergonomics Society Annual Meeting Proceedings, 48, 2228-2231. &lt;br&gt;http://dx.doi.org/10.1177/154193120404801905</mixed-citation></ref></ref-list></back></article>