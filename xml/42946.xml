<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">SEA</journal-id><journal-title-group><journal-title>Software Engineering and Applications</journal-title></journal-title-group><issn pub-type="epub">2325-2286</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/SEA.2021.103025</article-id><article-id pub-id-type="publisher-id">SEA-42946</article-id><article-categories><subj-group subj-group-type="heading"><subject>SEA20210300000_51697502.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>工程技术</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于眼动追踪方法的可视化技术综述
  Survey of Visualization Techniques Based on Eye Tracking Method
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>朱</surname><given-names>姝蔓</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>潘</surname><given-names>伟杰</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>吕</surname><given-names>健</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>方</surname><given-names>年丽</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>邹</surname><given-names>悦</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib></contrib-group><aff id="aff1"><addr-line>贵州大学现代制造技术重点实验室，贵州 贵阳</addr-line></aff><aff id="aff2"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>07</day><month>06</month><year>2021</year></pub-date><volume>10</volume><issue>03</issue><fpage>213</fpage><lpage>221</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
  本文通过对现有相关技术的概述，介绍了应用于眼动追踪数据的可视化方法。眼动追踪在实验室条件下常用于挖掘用户认知能力、评估用户行为。对眼动实验的数据进行定性分析，是探索用户偏好并指导设计优化的重要手段。文章介绍了眼动追踪技术的基础理论和可视化技术的概念，总结了对眼动追踪的数据进行可视化的方法类型，在此基础上探讨了此技术应用的难题和瓶颈，最后对其在设计领域的应用前景进行了展望与总结。
   In this paper, the visualization method applied to eye tracking data is introduced through an overview of existing related technologies. Eye tracking is often used to mine users’ cognitive ability and evaluate users’ behavior under laboratory conditions. Qualitative analysis of eye movement experiment data is an important means to explore user preferences and guide design optimization. This paper introduces the basic theory of eye tracking technology and the concept of visualization technology, summarizes the types of visualization methods for eye tracking data, discusses the difficulties and bottlenecks of the application of this technology, and finally makes a prospect and summary of its application prospects in the field of design.
 
</p></abstract><kwd-group><kwd>眼动，可视化，数据分析，兴趣区，注视点，综述, Eye movement</kwd><kwd> Visualization</kwd><kwd> Data Analysis</kwd><kwd> AOI</kwd><kwd> Fixation Point</kwd><kwd> Overview</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>摘要</title><p>本文通过对现有相关技术的概述，介绍了应用于眼动追踪数据的可视化方法。眼动追踪在实验室条件下常用于挖掘用户认知能力、评估用户行为。对眼动实验的数据进行定性分析，是探索用户偏好并指导设计优化的重要手段。文章介绍了眼动追踪技术的基础理论和可视化技术的概念，总结了对眼动追踪的数据进行可视化的方法类型，在此基础上探讨了此技术应用的难题和瓶颈，最后对其在设计领域的应用前景进行了展望与总结。</p></sec><sec id="s2"><title>关键词</title><p>眼动，可视化，数据分析，兴趣区，注视点，综述</p></sec><sec id="s3"><title>Survey of Visualization Techniques Based on Eye Tracking Method</title><p>Shuman Zhu, Weijie Pan, Jian Lv, Nianli Fang, Yue Zou</p><p>Key Laboratory of Advanced Manufacturing Technology, Ministry of Education, Guizhou University, Guiyang Guizhou</p><p><img src="//html.hanspub.org/file/1-2690524x4_hanspub.png" /></p><p>Received: Apr. 8<sup>th</sup>, 2021; accepted: May 31<sup>st</sup>, 2021; published: Jun. 7<sup>th</sup>, 2021</p><p><img src="//html.hanspub.org/file/1-2690524x5_hanspub.png" /></p></sec><sec id="s4"><title>ABSTRACT</title><p>In this paper, the visualization method applied to eye tracking data is introduced through an overview of existing related technologies. Eye tracking is often used to mine users’ cognitive ability and evaluate users’ behavior under laboratory conditions. Qualitative analysis of eye movement experiment data is an important means to explore user preferences and guide design optimization. This paper introduces the basic theory of eye tracking technology and the concept of visualization technology, summarizes the types of visualization methods for eye tracking data, discusses the difficulties and bottlenecks of the application of this technology, and finally makes a prospect and summary of its application prospects in the field of design.</p><p>Keywords:Eye movement, Visualization, Data Analysis, AOI, Fixation Point, Overview</p><disp-formula id="hanspub.42946-formula3"><graphic xlink:href="//html.hanspub.org/file/1-2690524x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2021 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/1-2690524x7_hanspub.png" /> <img src="//html.hanspub.org/file/1-2690524x8_hanspub.png" /></p></sec><sec id="s5"><title>1. 引言</title><p>人类获取外界信息时主要依赖视觉的作用，而眼睛的运动是揭示人的视觉机制和认知活动的直接方法。研究眼睛运动可以有效地理解人的意图，从而进行图像图形、产品等的可用性评估，以及地图、建筑、场景等的偏好测试。眼动追踪技术作为机器视觉的一种，近年来发展迅速，相关设备已经能准确定位瞳孔位置、计算人的注视点，从而获得大量眼动特征数据，广泛应用于人机交互、智能设计等领域。这些数据以文本为主，难以直观地理解，必须要对其进行定量和定性处理，映射出易识别的图形特征，从而方便人们理解其涵义。</p><p>本文总结了眼动追踪实验的基础框架，并针对眼动数据的可视化方法进行分类和讨论，结合研究难点对未来研究与应用趋势进行展望。</p></sec><sec id="s6"><title>2. 眼动追踪实验</title><sec id="s6_1"><title>2.1. 眼动概念</title><p>眼睛运动的模式主要分为定位眼动和非定位眼动两种，其中最常用的便于研究者分析眼动数据的三种模式是：眼跳(saccade)、注视(fixation)、平滑尾随跟踪(smooth pursuit) [<xref ref-type="bibr" rid="hanspub.42946-ref1">1</xref>]。</p><p>1) 眼跳：也称扫视，指在被注视目标上的一系列停留点之间的快速跳动，是双眼的联合移动，视角在1˚~40˚之间，持续时间30~120 ms，当持续时间超过100 ms以上时，停留点被称为注视点。一般只有在获得注视点时，才能获取信息。</p><p>2) 注视：在被注视目标上停留时间至少持续100 ms的停留点。眼球注视时伴随着微小的生理震颤，颤动幅度一般保持在1˚以内。</p><p>3) 平滑尾随跟踪：眼球跟随动态目标缓慢移动，通常物体运动速度低于50˚/s，同样是双眼的联合移动，通常伴随着注视和眼跳。实际上人的双眼几乎总是同步运动。</p><p>这三种运动均属于定位眼动，非定位眼动涉及到的是瞳孔扩张等眼球的自适应调节，此处不展开叙述。</p></sec><sec id="s6_2"><title>2.2. 实验参数</title><p>眼动数据包括注视点的位置和时间，每项记录中会包括时间、空间位置(坐标)、用户标识符、注视持续时间、刺激标识符等 [<xref ref-type="bibr" rid="hanspub.42946-ref2">2</xref>]。眼动实验中，根据所需，通常选择眼睛在目标区域的注视时长、注视次数、注视顺序等参数作为样本数据进行采集 [<xref ref-type="bibr" rid="hanspub.42946-ref3">3</xref>]。</p><p>1) 注视时长：包括总的注视时间和在目标上停留的时间，反映提取信息的难易度。在目标上停留时间越长，一般表示被试者提取信息遇到困难。</p><p>2) 注视次数：包括总注视次数和在目标上停留的次数。目标被注视次数越多，表示越重要。</p><p>3) 注视顺序：被试者在多个预设目标之间的注视转换顺序。</p><p>此外，在视觉搜索类任务中还会记录第一次到达目标的时间，用以衡量搜索任务是否有困难、原设计是否合理。</p></sec><sec id="s6_3"><title>2.3. 测量方法</title><p>随着科技的发展，眼动追踪技术从干扰式发展到非干扰式。在计算机处理能力不够的时代，人们采用的眼动仪运作原理比较简单，大致可分为机械记录法、电流记录法和电磁感应法等，会对被试者造成影响，且准确性较低 [<xref ref-type="bibr" rid="hanspub.42946-ref4">4</xref>]。</p><p>近年的眼动仪采用的非干扰式追踪技术，主要包括角膜反射法、巩膜–虹膜边缘法、瞳孔–角膜反射向量法等。前二者都是利用光线记录眼球位置。第三种利用摄像机拍摄眼睛图像，通过图像处理得到瞳孔中心位置，从而获得视线向量坐标，是现在最广泛使用的方式，精度较高，干扰小，头部误差小。瞳孔–角膜反射向量法通过固定眼摄像机获取眼球图像，利用亮瞳孔和暗瞳孔的原理，提取出眼球图像内的瞳孔，再用角膜反射法校正摄像机与眼球的相对位置。角膜反射点位置作基点，瞳孔中心位置代表视线位置。</p></sec><sec id="s6_4"><title>2.4. 硬件设备</title><p>用于记录分析眼动数据的系统或设备称为眼动仪，早在上世纪八十年代末就已出现商用眼动仪 [<xref ref-type="bibr" rid="hanspub.42946-ref5">5</xref>]。目前使用比较广泛的眼动仪有Model Mon EOG眼动仪、EyeLink系列眼动仪、Tobii系列眼动仪、SMI眼动仪等 [<xref ref-type="bibr" rid="hanspub.42946-ref6">6</xref>]。其中EyeLink系列采样的时间分辨率与空间分辨率都较高，Tobii系列则采用了先进的头动补偿算法，被试在实验过程中可以小幅度地转动头部，因此在特定领域具有特别优势，如研究婴儿或特殊人群的眼动行为。表1选择这两类眼动仪中各两款类型进行性能指标对比。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Performance comparison of four eye tracking device</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >系列名称</th><th align="center" valign="middle"  colspan="2"  >EyeLink</th><th align="center" valign="middle"  colspan="2"  >Tobii</th></tr></thead><tr><td align="center" valign="middle" >型号</td><td align="center" valign="middle" >EyeLink II</td><td align="center" valign="middle" >EyeLink 1000</td><td align="center" valign="middle" >TX3000</td><td align="center" valign="middle" >Glasses</td></tr><tr><td align="center" valign="middle" >穿戴方式</td><td align="center" valign="middle" >头戴式</td><td align="center" valign="middle" >塔台式</td><td align="center" valign="middle" >摄像头式</td><td align="center" valign="middle" >眼镜式</td></tr><tr><td align="center" valign="middle" >双眼采样率</td><td align="center" valign="middle" >250 Hz (均值)</td><td align="center" valign="middle" >500 Hz</td><td align="center" valign="middle" >60/120/300 Hz</td><td align="center" valign="middle" >30 Hz</td></tr><tr><td align="center" valign="middle" >追踪原理</td><td align="center" valign="middle" >瞳孔−角膜反射</td><td align="center" valign="middle" >瞳孔−角膜反射</td><td align="center" valign="middle" >瞳孔−角膜反射</td><td align="center" valign="middle" >瞳孔−角膜反射</td></tr><tr><td align="center" valign="middle" >追踪范围</td><td align="center" valign="middle" >水平+/−28˚；垂直+/−22˚</td><td align="center" valign="middle" >水平+/−32˚；垂直+/−25˚</td><td align="center" valign="middle" >水平+/−30˚；垂直+/−25˚</td><td align="center" valign="middle" >水平+/−56˚；垂直+/−40˚</td></tr><tr><td align="center" valign="middle" >凝视位置误差</td><td align="center" valign="middle" >0.25˚~0.5˚</td><td align="center" valign="middle" >0.25˚~0.5˚</td><td align="center" valign="middle" >&lt;0.4˚</td><td align="center" valign="middle" >&lt;0.5˚</td></tr><tr><td align="center" valign="middle" >数据分析软件</td><td align="center" valign="middle" >Data Viewer</td><td align="center" valign="middle" >Data Viewer</td><td align="center" valign="middle" >Tobii Studio</td><td align="center" valign="middle" >Tobii Studio</td></tr></tbody></table></table-wrap><p>表1. 四种眼动追踪设备性能比较</p></sec><sec id="s6_5"><title>2.5. 处理软件及数据处理</title><p>目前主要眼动数据处理软件是基于ScanEval软件包开发的，它能够提供大量的统计和获取数据的方法，对数据实时分析、反馈，包括训练系统评估、界面评价等。以上文提到的Tobii公司自主研发的Tobii Studio软件为例，它支持广泛的刺激材料，如文本、图片、视频、屏幕记录、网页、使用场景摄像机的实际物体或场景以及外部视频源等。</p><p>1) 数据记录：包括眼动数据和用户视频、声音、鼠标点击、击键等全方位的数据，并在记录过程中提供问卷功能，收集被试者的回答。</p><p>2) 可视化分析：提供注视轨迹图、热点图、集簇分析图和蜂群图视频，并提供自动或手动划分兴趣区域两种划分方式。</p><p>3) 数据统计：图表的制作和导出，可将数据放在软件内分析或导出到SPSS或MATLAB等外部程序中分析。</p><p>对于原始眼动数据在使用前必须进行预处理，主要分为数据平滑和去噪、有效区域校准或补偿、识别定位等。数据平滑和去噪，是基于连续点对数据进行均值处理，获得平滑数据，降低突变的噪声干扰(如用户头部的运动)；利用小波变换对信号进行过滤，保留100 Hz以下信号。有效区域校准或补偿，指剔除脱离有效区域的数据信息，或对持续时间不够的采样点进行聚类等数据加工的方式。识别定位，指基于差分和区域匹配的眼跳识别，利用差分算法实现眼动波动点识别，利用区域匹配算法实现眼动的位置识别。</p></sec></sec><sec id="s7"><title>3. 可视化技术</title><sec id="s7_1"><title>3.1. 数据可视化技术的意义</title><p>可视化是利用计算机图形学和图像处理技术将数据、信息或知识转换成图形或图像表达出来。数据、信息、知识是作为可视化分析输入端的不同分类法，它们分别对应DIKW (The data-information-knowledge- wisdom hierarchy)体系的资料层、资讯层和知识层。分析资料间关系获得资讯，可以用来回答“是什么”一类的简单问题；在行动上应用资讯则产生知识，可以回答规律、方法等复杂问题。即数据可以看作信息的计算机化表示，从知识系统的角度来看，数据则是一种简单的知识形式。因此，数据可视化的主要目标是获取信息的空间特征 [<xref ref-type="bibr" rid="hanspub.42946-ref7">7</xref>]，通过可视化技术将数据转化为人类可学习的信息，将获得的信息与其他技术结合应用，使信息集合成知识、变得有用，从而发现原始数据中不易观察到的数据间的联系，并可以在此基础上推理出新的知识。</p><p>创建可视化的过程就是创建将数据映射到图像集的函数，通过这一函数促使人类有效和高效地获取信息或知识。目前很多数据可视化网站提供交互式的可视化信息，个人和企业用户可浏览动态数据，以及协作并共享自定义的图表，例如Power-BI。这些便捷的信息帮助用户快速连接到大量数据源、发现问题和创建解决方案。实验室环境下，实验人员研究可视化规范、研发产品、对多行业普及，帮助构建更加合理的可视化体系，同时成果也便于对实验数据进行统计与分析。</p></sec><sec id="s7_2"><title>3.2. 数据可视化方法分类</title><p>应用于不同类型数据的可视化方法不同，本文介绍五种常见类型。</p><p>1) 像素。可视化一维值可以使用像素颜色。例如一个顾客信息表包含了四个维：收入，信贷额度，成交量和年龄。对所有顾客按收入的递增顺序来排序，并使用这个序，在四个可视化窗口中安排顾客的数据，值越小，颜色相应就越淡。如图1所示，收入与信贷额度成正比，收入中等的客户成交量最大，而收入与年龄没有明确相关性。</p><p>2) 几何投影。如图2所示，几何投影技术在二维显示可视化的高维空间，帮助用户发现数据集在多维空间的关系。通常情况，二维到三维数据点可使用基于笛卡尔坐标的散点图表示，使用不同的颜色或形状来表示不同维度。对于维数超过4的数据集，可以使用散点图矩阵和平行坐标，其中平行坐标可以表示超高维数据。</p><p>3) 图符。使用少量的图符表示多维数据值，常用的图符有切尔诺夫脸和人物线条画。切尔诺夫脸由统计学家赫尔曼切尔诺夫引进，每张脸代表一个n维数据点，对称图符18维，非对称有36维，如图3所示。它利用人识别面部特征的思维能力，使大型数据表更容易被人理解。人物线条画是由四肢、躯体、头部组成的几何人形，数据的两个维被映射到显示轴上，其余的被映射到四肢角度和长度。</p><p>图1. 基于像素的数据可视化</p><p>图2. 平行坐标</p><p>图3. 切尔诺夫脸</p><p>图4. 树图</p><p>4) 层次。层次可视化也是对大型高维数据进行可视化的一种技术。它将高维数据的所有维划分成子集。典型案例是“世界中的世界”和“树图”。前者是将数据集中某一些维的值固定，观察某一个维随着它们的变化是如何变化的。固定的维处在外世界，被观察的维是内世界，用户可以在外世界中改变内世界原点位置，查看内世界的变化结果。“树图”则是把层次数据显示为成嵌套矩形的集合，矩形面积表示数据重要度。</p><p>5) 标签云。可视化文本和社会网络的非数值数据常用到标签云(词云)。使用标签大小表示用户使用频次，两个标签节点之间的连线宽度表示二者之间的相关强度。</p><p>数据可视化方法需要学习才能被用户理解和使用，不具备天然地被人识别的特性。降低学习成本，提高交互效率，是科学地对数据进行可视化的原则。</p></sec></sec><sec id="s8"><title>4. 眼动数据的可视化方法</title><sec id="s8_1"><title>4.1. 统计图表</title><p>常用的统计图表包括条形图、散点图、箱线图等 [<xref ref-type="bibr" rid="hanspub.42946-ref8">8</xref>]。条形图多为直方图，例如Dixon等人为评价不同的图像融合方法，用直方图表示眼睛定位的准确性 [<xref ref-type="bibr" rid="hanspub.42946-ref9">9</xref>]；散点图用于绘制二维数据，例如眼动的振幅和速度；箱线图用来表现数据的静态分布。此类图表具有普遍适应性，并不是专门为眼动数据实现可视化制定的方法，因此能够传递的信息有限。</p></sec><sec id="s8_2"><title>4.2. 基于注视点的可视化</title><p>注视点相关的眼动数据主要包括眼睛随着时间移动的路径和注视点的集合，其运动长短、流程、转换、复杂度等对于研究用户注意力和搜索、认知能力有重要意义。可以通过这类数据发现用户观察策略和实验预期策略的不同，一般用户和专家用户的搜索策略异同，可以用来寻找多数人的典型搜索路径以及调查用户可能遇到的困难等。基于注视点的可视化方法可分为以下四种。</p><p>1) 随时间变化的轨迹地图。用于可视化时态数据。通常用二维坐标系统表示，如图5所示，一个轴用来表示时间，另一个轴代表某种眼动追踪数据，如垂直固定位置，这种技术允许实验者来比较被试扫视路径的相似性，以及发现扫视总趋势是向上向下、或是水平移动。但由于时间和眼动数据被分离，难以在其他空间维度上来度量路径相似性。</p><p>图5. 随时间变化的眼动轨迹</p><p>2) 注意力地图。在实验材料上标定一个或多个固定位置，并将之叠加在实验的动态刺激之上，即标记点随刺激物运动而运动；改变注意力地图，可以识别多个被试之间的注意力同步率。注意力地图的主要目的是确定吸引大量注意力的刺激物，从而可用来确定兴趣区(AOI)。</p><p>注意力地图的主要表现方式是热区图，它将用户的注视点个数、注视持续时间用颜色和透明度表示，并通常作为半透明层叠加在刺激材料上；一般红色等暖色表示注视点集中或持续时间长的区域，蓝色等冷色表示相反区域，同时可以给色块进行模糊处理，注视点稀疏的区域模糊度高。</p><p>注意力地图可以以三维形式表现，通常将实验材料投影在X-Y平面上，Z轴上的高度表现注视点的集中度等。其优点是直观、易理解，但不能表现注视点随时间变化的移动，同时无法区别注视点集中和注视持续时间长两种不同指标。</p><p>3) 扫描路径。将注视点按任意扫视序列用直线连接得到的路径被称为扫描路径，描述了视线在刺激物上的静态覆盖。扫视路径表现形式较为多样，在扫视过多的情况下可以进行透明度处理，从而暴露眼睛运动较为集中的路径趋势，如图6(a)；对于路径重叠严重的情况，可以将时间分段进行观察，或者隐藏部分路径；扫描路径也能进行动态记录，用来展示时间顺序；在观察三维物体或者在三维空间产生的扫描路径上，可将空间展开变为二维，也直接在三维空间表示。此外还可对两个不同相邻注视点间的连线进行颜色处理，以颜色表示先后顺序，如图6(b)；将注视点用圆点表示，和扫描路径同时展示等等。</p><p>图6. 扫描路径</p><p>4) 时空立方体(Space-time Cube)。这是原本用于地理信息科学研究领域的一种可视化技术，在STC中，眼睛的扫描路径、注视点和集群信息是静态的，能够观察到用户兴趣持续时间，不需要在数据中进行顺序搜索。STC的优点在于可以同时直接描述来自多个被试者的眼动数据，从而能够有效地识别重要的兴趣区。</p></sec><sec id="s8_3"><title>4.3. 基于兴趣区的可视化</title><p>兴趣区(Area of Interest)是指在实验刺激材料上人为指定的区域，可以是固定位置也可以是随机位置。国内学者划分AOI有多种角度，包括划分不同形状、页面布局、以设计要素分区、分层划分(如结构层与色彩层等) [<xref ref-type="bibr" rid="hanspub.42946-ref10">10</xref>]。</p><p>在复杂项目中将质化研究和量化研究混合，包括顺序法、转换法、并行法3种设计；顺序解释设计、顺探究设计、并行转换设计、顺序转换设计、并行嵌套设计和并行三角互证设计6种类型 [<xref ref-type="bibr" rid="hanspub.42946-ref11">11</xref>]。在进行AOIs划分前一般需要进行数据同步，为使数据以某种顺序进行组合 [<xref ref-type="bibr" rid="hanspub.42946-ref12">12</xref>]。</p><p>1) 表示兴趣区的时间线。用颜色对AOI进行编码，每一段表示一个时间跨度，包括时间主轴和一个副轴，副轴可以表示AOIs或被试者。当AOIs数量较少时，可以有效地进行多个被试之间的扫描路径对比。图7中的围巾图是此种方法的表现形式之一。</p><p>图7. 围巾图</p><p>2) 三维空间。对于三维刺激材料的眼动数据进行空间分析，应用场景可以是真实世界的空间或者虚拟现实环境，对实体对象或虚拟模型进行三维AOI覆盖，然后处理AOIs的颜色、透明度等，为其附加上相关信息，如注视持续时间等。</p><p>3) AOIs相关关系。使用矩阵表示两个AOI之间的转换百分比或转换频率。常用矩阵形式如图8，每个单元格表示两个相对应AOI之间的转换次数，一般转换次数少所对应的单元格用浅色填充。这种可视化方式可以用于对视觉搜索策略进行直观地比较，确定界面是否合理，例如当整个矩阵呈现深色，说明被试在所有AOI之间的扫视太多，搜索出现困难。</p><p>图8. AOI矩阵</p></sec><sec id="s8_4"><title>4.4. 眼动数据可视化在设计中的应用</title><p>在设计领域，眼动追踪数据的可视化可以反映用户心理，包括满意度和偏好因此可以用于对建筑、室内和公共环境的评价，以及用户界面设计、交互设计和产品设计 [<xref ref-type="bibr" rid="hanspub.42946-ref13">13</xref>]。</p><p>较为广泛的应用是指导用户界面设计，眼动追踪数据可视化可用在用户界面可用性评估中，在用户完成实验任务的过程中，通过分析相关参数，如注视时长，可以得到用户的操作效率、满意度、兴趣度等信息来评价界面的合理性。例如，用户的扫描路径过于复杂，注视点分布在非任务目标上，说明界面表现形式不佳，给用户视觉搜索带来了困难。这里的界面可以是传统纸质广告、图像，也可以是电子设备的界面，以及控制系统界面等等。</p><p>在公共环境方面，主要是通过主观评价进行的，没有绝对的标准。在产品设计中，可以将设计要素分割开来分别进行评价，结合人机工程学进行产品优化。</p></sec></sec><sec id="s9"><title>5. 发展趋势及难点</title><p>眼动数据的可视化研究拥有广泛前景，未来发展趋势和难点可能有：</p><p>1) 协同设计的应用。利用眼动追踪技术的优势和可视化的分析方法帮助提高两个相关用户群的协同工作效率，或是利用专家的眼动数据指导新手工作，其中新手学习的是经过可视化的眼动数据。</p><p>2) 探索视觉认知机制中的眼动数据可视化，如何区别展示选择注意和简单主动关注两种视觉认知机制瞎的眼动数据特点。</p><p>3) 可视化方法创新和可视化评价，例如使用特定可视化方法更准确地检测对象的预测算法，可以在可视化交互这一动态过程中显示目标的位置和形状 [<xref ref-type="bibr" rid="hanspub.42946-ref14">14</xref>]。对于一种可视化方法的应用是否有效的评价，有助于指导实验者进行可视化方法选择和匹配。</p></sec><sec id="s10"><title>6. 结语</title><p>本文通过对眼动追踪技术和可视化技术的介绍，引入针对眼动追踪数据的可视化方法。眼动数据的可视化方式可以按照基于注视点和基于兴趣区分为两大类。注视点相关的可视化信息，包括扫描路径、注意力地图等，通常在评价用户搜寻效率方面有效。兴趣区相关的可视化信息可以表现为用户在搜寻或阅读中兴趣消耗的区域和时长。一般两类方法需要结合互补，以达到较为完善的分析效果。最后提出眼动数据可视化技术面临的难点和瓶颈，并对其未来进行展望。</p></sec><sec id="s11"><title>基金项目</title><p>国家自然科学基金52065010；贵州省科学技术基金项目(黔科合基础[<xref ref-type="bibr" rid="hanspub.42946-ref2018">2018</xref>]1049)。</p></sec><sec id="s12"><title>文章引用</title><p>朱姝蔓,潘伟杰,吕 健,方年丽,邹 悦. 基于眼动追踪方法的可视化技术综述Survey of Visualization Techniques Based on Eye Tracking Method[J]. 软件工程与应用, 2021, 10(03): 213-221. https://doi.org/10.12677/SEA.2021.103025</p></sec><sec id="s13"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.42946-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">程时伟, 孙凌云. 眼动数据可视化综述[J]. 计算机辅助设计与图形学学报, 2014, 26(5): 698-707.</mixed-citation></ref><ref id="hanspub.42946-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Andrienko, G., Andrienko, N., Burch, M., et al. (2012) Visual Analytics Methodology for Eye Movement Studies. IEEE Transac-tions on Visualization and Computer Graphics, 18, 2889-2898. 
&lt;br&gt;https://doi.org/10.1109/TVCG.2012.276</mixed-citation></ref><ref id="hanspub.42946-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">赵新灿, 左洪福, 任勇军. 眼动仪与视线跟踪技术综述[J]. 计算机工程与应用, 2006, 42(12): 118-120.</mixed-citation></ref><ref id="hanspub.42946-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">闫国利, 田宏杰. 眼动记录技术与方法综述[J]. 应用心理学, 2004, 10(2): 55-58.</mixed-citation></ref><ref id="hanspub.42946-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">孟春宁. 人眼检测与跟踪的方法及应用研究[D]: [博士学位论文]. 天津: 南开大学, 2013: 104-105.</mixed-citation></ref><ref id="hanspub.42946-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">闫国利, 白学军. 眼动分析技术的基础及应用[M]. 北京: 北京师范大学出版社, 2018: 37-55.</mixed-citation></ref><ref id="hanspub.42946-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Chen, M., Ebert, D., Hagen, H., Laramee, R.S., et al. (2009) Data, Information, and Knowledge in Visual-ization. IEEE Computer Graphics and Applications, 29, 12-19. &lt;br&gt;https://doi.org/10.1109/MCG.2009.6</mixed-citation></ref><ref id="hanspub.42946-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Blascheck, T., Kurzhals, K., Raschke, M., et al. (2017) Visualization of Eye Tracking Data: A Taxonomy and Survey. Computer Graphics Forum, 18, 2889-2898. &lt;br&gt;https://doi.org/10.1111/cgf.13079</mixed-citation></ref><ref id="hanspub.42946-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Dixon, T.D., Li, J., Noyes, J.M., et al. (2007) Scanpath Analysis of Fused Multi-Sensor Images with Luminance Change: A Pilot Study. International Conference on Information Fusion, 1, 65-72.</mixed-citation></ref><ref id="hanspub.42946-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">王新亭, 方雪, 张琰, 等. 基于混合方法的眼动实验AOI划分及设计评价[J]. 天津科技大学学报, 2017, 32(6): 47-52.</mixed-citation></ref><ref id="hanspub.42946-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Blank, C.A. (2010) SAGE Handbook of Mixed Methods in Social &amp; Behavioral Research. SAGE Publications.</mixed-citation></ref><ref id="hanspub.42946-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Blascheck, T., John, M., Kurzhals, K., et al. (2015) VA2: A Visual Analytics Approach for II Evaluating Visual Analytics. IEEE Transactions on Visualization &amp; Computer Graphics, 22, 61-70.  
&lt;br&gt;https://doi.org/10.1109/TVCG.2015.2467871</mixed-citation></ref><ref id="hanspub.42946-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Park, H.-S. (2016) A Review on the Application of Eye-Tracking in Design Areas. Journal of the Ergonomics Society of Korea, 35, 391-401. &lt;br&gt;https://doi.org/10.5143/JESK.2016.35.5.391</mixed-citation></ref><ref id="hanspub.42946-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">Alam, S.S. and Jianu, R. (2017) Analyzing Eye-Tracking In-formation in Visualization and Data Space: From Where on the Screen to What on the Screen. IEEE Educational Activities Department, 23, 1492-1505.  
&lt;br&gt;https://doi.org/10.1109/TVCG.2016.2535340</mixed-citation></ref></ref-list></back></article>