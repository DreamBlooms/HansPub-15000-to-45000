<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2019.92051</article-id><article-id pub-id-type="publisher-id">CSA-29066</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20190200000_78894314.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于卷积神经网络和Softmax的蛋白质二级结构预测
  Protein Secondary Structure Prediction Using Convolutional Neural Network and Softmax
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>王</surname><given-names>蕾蕾</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>成</surname><given-names>金勇</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib></contrib-group><aff id="aff1"><addr-line>null</addr-line></aff><aff id="aff2"><addr-line>齐鲁工业大学(山东省科学院)，计算机科学与技术学院，山东 济南</addr-line></aff><pub-date pub-type="epub"><day>29</day><month>01</month><year>2019</year></pub-date><volume>09</volume><issue>02</issue><fpage>450</fpage><lpage>457</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   蛋白质二级结构预测是生物信息学的重要组成部分，在生物信息学领域具有重要意义。本文提出了一种新的卷积神经网络结合Softmax分类器的算法预测蛋白质二级结构。首先用改进的卷积神经网络对蛋白质氨基酸序列进行特征提取，然后把卷积神经网络中第三次卷积后的输出作为Softmax分类器的输入并进行训练和预测。我们将本文提出的方法在25PDB数据集上做了3-折交叉验证，结果证明蛋白质二级结构预测的准确率有提高。 Protein secondary structure prediction belongs to bioinformatics, and it’s important in research area. In this paper, we propose a new prediction way of protein using convolutional neural networks and Softmax. First, the improved convolutional neural network is used to extract the characteristics of the protein amino acid sequence, and then the third convolved output in the convolutional neural network is used as input to the Softmax classifier, and these data are trained and predicted. The dataset is a typical 25PDB dataset for protein. In terms of accuracy, the method is the cross validation based on the 3-fold. The results demonstrate that the accuracy of protein secondary structure prediction is improved. 
  
 
</p></abstract><kwd-group><kwd>蛋白质二级结构，卷积神经网络，Softmax分类器, Protein Secondary Structure</kwd><kwd> Convolutional Neural Networks</kwd><kwd> Softmax Classifier</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>基于卷积神经网络和Softmax的蛋白质二级结构预测<sup> </sup></title><p>王蕾蕾，成金勇</p><p>齐鲁工业大学(山东省科学院)，计算机科学与技术学院，山东 济南</p><p><img src="//html.hanspub.org/file/30-1541304x1_hanspub.png" /></p><p>收稿日期：2019年2月9日；录用日期：2019年2月21日；发布日期：2019年2月28日</p><disp-formula id="hanspub.29066-formula64"><graphic xlink:href="//html.hanspub.org/file/30-1541304x5_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>蛋白质二级结构预测是生物信息学的重要组成部分，在生物信息学领域具有重要意义。本文提出了一种新的卷积神经网络结合Softmax分类器的算法预测蛋白质二级结构。首先用改进的卷积神经网络对蛋白质氨基酸序列进行特征提取，然后把卷积神经网络中第三次卷积后的输出作为Softmax分类器的输入并进行训练和预测。我们将本文提出的方法在25PDB数据集上做了3-折交叉验证，结果证明蛋白质二级结构预测的准确率有提高。</p><p>关键词 :蛋白质二级结构，卷积神经网络，Softmax分类器</p><disp-formula id="hanspub.29066-formula65"><graphic xlink:href="//html.hanspub.org/file/30-1541304x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2019 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/30-1541304x7_hanspub.png" /> <img src="//html.hanspub.org/file/30-1541304x8_hanspub.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>人类基因组计划(Human Genome Project, HGP) [<xref ref-type="bibr" rid="hanspub.29066-ref1">1</xref>] 是科学史上的三大伟大计划之一，生物信息学是为了应对计划中的基因测序问题而产生的一门学科。众所周知，蛋白质是生命系统中生命体进行生命活动的主宰者，是生命体不可或缺的一部分。目前，研究蛋白质的结构和功能已经成为生物信息学研究的一个重要的领域。此前为了得到蛋白质的结构主要是运用实验方法，如X射线晶体衍射和核磁共振的方法等 [<xref ref-type="bibr" rid="hanspub.29066-ref2">2</xref>] 。但是，现实中最大的问题是我们生命系统中绝大部分的蛋白质的结构是不能用实验方法得到的，所以只能用人工智能预测其结构。所以，蛋白质二级结构预测课题应运而生。所谓蛋白质二级结构的预测 [<xref ref-type="bibr" rid="hanspub.29066-ref3">3</xref>] ，其最重要的步骤是首先归纳我们已经知道结构的蛋白质序列，然后进行预测，预测时主要用到的是统计学方法和目前新兴的人工智能算法等。所以，在蛋白质二级结构发展的今天，已经出现了很多用来预测蛋白质二级结构的方法，如神经网络方法 [<xref ref-type="bibr" rid="hanspub.29066-ref4">4</xref>] 、隐马尔可夫模型 [<xref ref-type="bibr" rid="hanspub.29066-ref5">5</xref>] 方法等。</p><p>深度学习 [<xref ref-type="bibr" rid="hanspub.29066-ref6">6</xref>] 是机器学习算法中人工神经网络研究衍生出的一个新的方法，其概念是在2006年被提出来的。其包含多种算法，如自动编码器 [<xref ref-type="bibr" rid="hanspub.29066-ref7">7</xref>] 、深信度网络 [<xref ref-type="bibr" rid="hanspub.29066-ref8">8</xref>] 及卷积神经网络等。卷积神经网络分类识别算法是由Yann LeCun等人 [<xref ref-type="bibr" rid="hanspub.29066-ref9">9</xref>] 最早提出并应用在手写字体识别上的。卷积神经网络主要是用权值共享的思想降低网络学习的复杂度。本文提出了一种改进的卷积神经网络和Softmax [<xref ref-type="bibr" rid="hanspub.29066-ref10">10</xref>] 相结合的方法，构建了一个10层的卷积神经网络，先用卷积神经网络对蛋白质二级结构的特征进行提取，把进入全连接层前的特征输入到Softmax分类器中，对提取到的特征进行分类预测实验。结果显示，本文的方法在25PDB (Protein Data Bank，简称PDB)数据集上的预测准确率有提高。</p></sec><sec id="s4"><title>2. 基于卷积神经网络和Softmax的蛋白质二级结构预测</title><sec id="s4_1"><title>2.1. 卷积神经网络原理</title><p>近年来，随着深度学习算法的不断发展，卷积神经网络引起了广大研究者的关注。卷积神经网络(Convolutional Neural Networks, CNN) [<xref ref-type="bibr" rid="hanspub.29066-ref11">11</xref>] 的概念是上世纪60年代Hubel和Wiesel [<xref ref-type="bibr" rid="hanspub.29066-ref12">12</xref>] 两位研究者在研究神经元的时候发现的一种独特的网络结构，其独特之处在于卷积神经网络可以有效地降低网络的复杂性。卷积神经网络通过卷积和池化操作能很好地提取到输入数据的关键特征，所以目前卷积神经网络在模式分类领域中得到了广泛的关注和应用。CNN卷积过程的数学表达式如下所示：</p><p>s ( i , j ) = ( X * W ) ( i , j ) + b = ∑ k − 1 n _ i n ( X k * W k ) ( i , j ) + b (1)</p><p>公式中，n_in是输入数据组成的矩阵个数，X<sub>k</sub>是第k个的输入矩阵。W<sub>k</sub>则是卷积过程中我们选取的卷积核里的第k个子卷积核矩阵。 s ( i , j ) 表示的是卷积核W对应位置的元素在其输出矩阵中的值。</p><p>卷积神经网络的基本结构包括卷积层、池化层和全连接层。卷积层主要执行的是卷积操作，其中用到的方法主要是局部连接和权值共享的方法，主要是在模拟大脑中有局部感受野的细胞，从而能够从获得的信息中提取出一些初级特征的过程。池化层主要执行的是下采样操作，包括最大值池化和平均池化等方法。输入的数据经过池化层的下采样操作后，输出的数据矩阵会变小，但是数量不变，所以池化层能够对从上一层的卷积层中输出的数据进行压缩，这样就能减小计算的复杂度、从而使学习参数数量减少，同时能有效地防止过拟合问题。在卷积神经网络模型中，最后的一层或是几层就是全连接层，全连接层的主要功能是对前面卷积和池化操作提取的特征进行加权求和，能够保证输入的数据在进行池化操作后保留下来的少量数据特征能够尽可能的重现原来的输入数据。</p><p>图1中，input为数据以矩阵的形式输入卷积神经网络，输入的数据进行卷积操作，得到C<sub>1</sub>层，C<sub>1</sub>层的数据进行下采样操作，得到S<sub>1</sub>层，卷积神经网络完成第一次卷积、下采样操作。第一次卷积—下采样操作的输出作为下一次卷积操作的输入，进行第二次卷积、下采样操作，以此类推，直到最后一次卷积操作完成，把卷积、下采样后得到的特征进行全连接并作为卷积神经网络提取特征的输出，把输出的数据输入到分类器中进行分类，得到我们所需要的分类结果。</p><p>图1. 卷积神经网络结构图</p></sec><sec id="s4_2"><title>2.2. Softmax回归模型</title><p>传统的逻辑回归模型主要处理的是二分类的问题，如Logistic回归模型 [<xref ref-type="bibr" rid="hanspub.29066-ref13">13</xref>] 。面对多分类问题时，传统的逻辑回归模型不能满足分类需要，继而衍生出了一种用于多分类问题的回归模型——Softmax回归模型。传统的逻辑回归模型函数为：</p><p>h θ ( x ) = 1 1 + exp ( − θ T x ) (2)</p><p>其损失函数对应如下：</p><p>J ( θ ) = − 1 m [ ∑ i = 1 m y ( i ) log h θ ( x ( i ) ) + ( 1 − y ( i ) ) log ( 1 − h θ ( x ( i ) ) ) ] (3)</p><p>其中， x ( i ) 是输入的样本数据， y ( i ) 是对应的标签数据，θ是训练的模型参数，m是样本的总数，因为传统的逻辑回归应用于二分类问题，所以m的取值为2。在多分类问题中，我们用到的是Softmax回归，其中 y ( i ) 可以取 k ( k &gt; 2 ) 个值，对应的m取值为k。</p><p>对于给定的输入x，针对每一个类别j估算出其概率值 p = ( y = j | x ) 。也就是说，针对每一种分类的结果估算其出现的概率。所以，对于 y = k ( k &gt; 2 ) 时回归模型函数的形式如下：</p><p>h θ ( x ( i ) ) = [ p ( y ( i ) = 1 | x ( i ) ; θ ) p ( y ( i ) = 2 | x ( i ) ; θ ) ⋮ p ( y ( i ) = k | x ( i ) ; θ ) ] = 1 ∑ j = 1 k e θ j T x ( i ) [ θ 1 T x ( i ) θ 2 T x ( i ) ⋮ θ k T x ( i ) ] (4)</p><p>为了使公式看起来更加简便，用 θ 表示全部的模型参数，在Softmax回归中，把 θ 1 , θ 2 , ⋯ , θ k 按行排列组成一个矩阵 θ ，如下所示：</p><p>θ = [ — θ 1 T — — θ 2 T — ⋮ — θ K T — ] (5)</p><p>Softmax回归所对应的损失函数如下所示：</p><p>J ( θ ) = − 1 m [ ∑ i = 1 m ∑ j = 1 k 1 { y ( i ) = j } log e θ j T x ( i ) ∑ l = 1 k e θ l T x ( i ) ] (6)</p><p>在上面的公式中， 1 { . } 表示的是示性函数。</p><p>从以上可以推出，对于给定的输入数据x，针对每一个类别j估算出的其概率值 p = ( y = j | x ) 如下所示：</p><p>P ( y ( i ) = j | x ( i ) ; θ ) = e θ j T x ( i ) ∑ l = 1 k e θ j T x ( i ) (7)</p></sec><sec id="s4_3"><title>2.3. 卷积神经网络和Softmax网络模型</title><p>为了简化计算量和解决反向传播时出现的梯度消失问题，在卷积层之后加入了Relu激活层。本文的网络结构包括输入层、卷积层、池化层、Relu激活层和全连接层。一般的卷积神经网络是在全连接之后，对所提取的特征进行分类预测，本文是提取第三层卷积层之后的特征，输入到Softmax分类器中进行训练和预测。</p><p>主要的网络结构图和参数设置如图2所示。</p></sec></sec><sec id="s5"><title>3. 实验和分析</title><p>主要介绍蛋白质数据库以及本文的实验过程和结果分析。</p><p>图2. 卷积神经网络–Softmax网络结构图</p><sec id="s5_1"><title>3.1. 蛋白质数据库</title><p>在蛋白质二级结构预测的研究中，非同源蛋白质数据集25PDB数据集经常被用到。我们用本文提出的方法在25PDB数据集上做了交叉验证 [<xref ref-type="bibr" rid="hanspub.29066-ref14">14</xref>] ，并把交叉验证的结果和其他方法做了比较。25PDB数据集包含了1673条相似性不超过25%的蛋白质序列。我们在准确率测试方面，是基于3-折交叉验证(3-fold cross validation)。</p><p>通过位置特异性叠代BLAST (Position-Specific Iterated BLAST, PSI-BLAST)程序进调用三次迭代并进行序列的对比就能获得位置特异性打分矩阵(Position-Specific Scoring Matrix, PSSM) [<xref ref-type="bibr" rid="hanspub.29066-ref15">15</xref>] 。PSSM矩阵包含了物种的进化信息，同时其特有的滑动窗口技术保留了蛋白质序列中相邻氨基酸的关系。多序列比对 [<xref ref-type="bibr" rid="hanspub.29066-ref16">16</xref>] ，从字面意思理解就是我们利用蛋白质序列的相似性对序列进行对比。实际操作中，我们很难知道每一个蛋白质序列的结构和组成，这就要求我们从NCBT nr数据库中搜索与其相关的同源序列的信息，预测我们所需蛋白质的结构。主要的操作是运行PSI-BLAST程序从NCBT nr数据库中搜索到25PDB相关蛋白质的同源序列信息之后，生成对应的20 * 13的PSSM矩阵。把PSSM矩阵用于蛋白质二级结构预测时，要选择一个滑动窗口，本文我们用到的滑动窗口大小为13，沿着PSSM矩阵每滑动一次，就可以提取出一个20 * 13的特征向量，即生成一个260维的特征向量。</p></sec><sec id="s5_2"><title>3.2. 实验过程</title><p>首先通过运行PSI-BLAST程序搜索nr数据库生成对应PSSM矩阵。用大小为13的滑动窗口沿着PSSM矩阵中的蛋白质序列滑动，得到了一个260维的数据。把数据作为卷积神经网络的输入，用3 * 3的卷积核对数据进行卷积操作，经过3次卷积操作，把卷积神经网络第三次卷积后提取到的特征输出作为Softmax分类器的输入，用Softmax对提取的特征进行训练和预测，得到预测结果也就是蛋白质二级结构的三种形式：C (卷曲)、E (链残基)和H (卷曲)。主要的流程图如图3所示：</p><p>图3. 实验流程图</p><p>在数据处理的滑动窗口选择和在卷积神经网络提取特征时卷积核大小的选择上我们做了反复多次试验。在处理PSSM矩阵时，我们分别选取了9、11、13、15和17作为滑动窗口的大小，分别得到了数据维数为180维、220维、260维、300维和340维的矩阵，经过实验得出，滑动窗口大小为13的时候，预测的效果是最好的。在卷积核大小的选择上，我们分别以2 * 2，3 * 3，4 * 4和5 * 5作为卷积核的大小进行实验，最后我们设置的卷积层分别是600个4 * 4的卷积核、300个2 * 2的卷积核和200个2 * 2的卷积核。</p></sec><sec id="s5_3"><title>3.3. 实验结果及分析</title><p>一个预测算法的好坏主要是通过衡量其预测精度来决定的。蛋白质二级结构的预测精度可以对正确预测的螺旋和折叠数量来进行计算。本文用到的衡量的方法是Q<sub>3</sub>和片段重叠准确率(Segment Overlap Score, SOV)方法。</p><p>Q<sub>3</sub>是被用于残基上的，通过计算正确预测的蛋白质残基占已知蛋白质二级结构序列中总的残基数的比例计算出。Q<sub>3</sub>值的范围为 [ 0 , 1 ] ，1表示准确预测。Q<sub>3</sub>就可以表示为：</p><p>Q 3 = 正 确 预 测 的 残 基 数 残 基 总 数 (8)</p><p>SOV方法是由Burkhard Rost [<xref ref-type="bibr" rid="hanspub.29066-ref17">17</xref>] 等人提出的一个基于重叠片段比值的测度。与Q<sub>3</sub>正确率的计算方法不同的是，SOV方法计算的是能够正确预测蛋白质二级结构的片段比例，从影响因素的角度来看，SOV会忽略一些蛋白质二级结构元素末端的小错误。</p><p>本文把25PDB数据集分成三份并编号为1、2和3，选择其中的一份作为训练集，剩余的两份作为测试集。我们依次以1、2和3作为测试集，用传统的卷积神经网络和本文的网络结构对其进行了训练和预测，得到了Q<sub>3</sub>和SOV的平均值。</p><p>对于本文用到的25PDB数据集，只使用卷积神经网络对训练集和测试集进行分类预测的Q<sub>3</sub>正确率和SOV如下表1所示：</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> The results of convolutional neural networ</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" ></th><th align="center" valign="middle" >1</th><th align="center" valign="middle" >2</th><th align="center" valign="middle" >3</th><th align="center" valign="middle" >平均</th></tr></thead><tr><td align="center" valign="middle"  rowspan="2"  >训练集</td><td align="center" valign="middle" >Q<sub>3</sub></td><td align="center" valign="middle" >77.41</td><td align="center" valign="middle" >76.50</td><td align="center" valign="middle" >76.97</td><td align="center" valign="middle" >76.96</td></tr><tr><td align="center" valign="middle" >SOV</td><td align="center" valign="middle" >73.29</td><td align="center" valign="middle" >72.42</td><td align="center" valign="middle" >72.04</td><td align="center" valign="middle" >72.58</td></tr><tr><td align="center" valign="middle"  rowspan="2"  >测试集</td><td align="center" valign="middle" >Q<sub>3</sub></td><td align="center" valign="middle" >76.34</td><td align="center" valign="middle" >75.52</td><td align="center" valign="middle" >75.85</td><td align="center" valign="middle" >75.90</td></tr><tr><td align="center" valign="middle" >SOV</td><td align="center" valign="middle" >72.69</td><td align="center" valign="middle" >71.61</td><td align="center" valign="middle" >71.66</td><td align="center" valign="middle" >71.98</td></tr></tbody></table></table-wrap><p>表1. 卷积神经网络预测结果</p><p>对于25PDB数据集，先使用改进的卷积神经网络进行特征提取，再提取第三层卷积层的特征输入到softmax分类器中进行分类预测的Q<sub>3</sub>正确率和SOV如下表2所示：</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> The results of convolutional neural network-Softma</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" ></th><th align="center" valign="middle" >1</th><th align="center" valign="middle" >2</th><th align="center" valign="middle" >3</th><th align="center" valign="middle" >平均</th></tr></thead><tr><td align="center" valign="middle"  rowspan="2"  >训练集</td><td align="center" valign="middle" >Q<sub>3</sub></td><td align="center" valign="middle" >78.41</td><td align="center" valign="middle" >78.41</td><td align="center" valign="middle" >78.31</td><td align="center" valign="middle" >78.37</td></tr><tr><td align="center" valign="middle" >SOV</td><td align="center" valign="middle" >73.62</td><td align="center" valign="middle" >74.43</td><td align="center" valign="middle" >73.56</td><td align="center" valign="middle" >73.87</td></tr><tr><td align="center" valign="middle"  rowspan="2"  >测试集</td><td align="center" valign="middle" >Q<sub>3</sub></td><td align="center" valign="middle" >77.01</td><td align="center" valign="middle" >76.99</td><td align="center" valign="middle" >77.18</td><td align="center" valign="middle" >77.06</td></tr><tr><td align="center" valign="middle" >SOV</td><td align="center" valign="middle" >72.79</td><td align="center" valign="middle" >73.11</td><td align="center" valign="middle" >73.08</td><td align="center" valign="middle" >72.99</td></tr></tbody></table></table-wrap><p>表2. 卷积神经网络和Softmax预测结果</p><p>从上表预测结果可以看出，对于蛋白质数据集25PDB，只使用传统的卷积神经网络对蛋白质数据进行分类预测，在训练集上的Q<sub>3</sub>正确率是76.96%，在测试集上的Q<sub>3</sub>正确率是75.90%，本文的方法是在传统的卷积神经网络中加入了Relu激活层，对蛋白质数据集进行特征提取，把卷积神经网络第三次卷积得到的特征作为Softmax分类器的输入对特征数据进行分类预测，在训练集上的Q<sub>3</sub>正确率是78.37%，在测试集上的Q<sub>3</sub>正确率是77.06%。本文的方法相较于经典的卷积神经网络方法在训练集和测试集上Q<sub>3</sub>平均预测精度分别提高了1.14%和1.16%。因为自动编码器可以不断调整它的各层的参数，得到每一层的权重，因而能够捕捉可以代表输入数据的最重要的因素，是一种尽可能复现输入信号的神经网络，所以预测结果提高了。但是自动编码器没有全局优化，输入的重建可能不是学习通用表征的理想度量，所以预测正确率的提高不是很明显。</p></sec></sec><sec id="s6"><title>4. 总结</title><p>本文结合了改进了卷积神经网络方法，在传统的卷积神经网络方法中加入了Relu激活层，简化了计算量并优化了梯度消失问题，直接提取第三层卷积层的特征作为输出，在分类预测方面引入了Softmax分类函数。把改进的卷积神经网络对蛋白质数据集25PDB经过卷积层、Relu激活层和池化层之后提取到的第三层卷积后的特征作为Softmax分类器的输入，用Softmax分类器对提取到的特征进行训练和预测。从表1和表2中可以看出只用卷积神经网络对25PDB数据集进行训练和预测的Q<sub>3</sub>和SOV分别是75.90%和71.98%，在本文的方法中的Q<sub>3</sub>和SOV分别是77.06%和72.99%，预测结果都有提高。卷积神经网络通过卷积和下采样操作能最大程度地提取到数据重要的信息，本文的方法在卷积神经网络中加入了Relu激活层，并把第三层卷积提取到的特征直接作为Softmax分类器的输入，最大程度地保留了原始信息，简化了计算量并解决了梯度消失问题。所以提高了预测结果的精度。</p></sec><sec id="s7"><title>基金项目</title><p>本研究获得山东省自然科学基金(No. ZR2017LB024)项目资助。</p></sec><sec id="s8"><title>文章引用</title><p>王蕾蕾,成金勇. 基于卷积神经网络和Softmax的蛋白质二级结构预测Protein Secondary Structure Prediction Using Convolutional Neural Network and Softmax[J]. 计算机科学与应用, 2019, 09(02): 450-457. https://doi.org/10.12677/CSA.2019.92051</p></sec><sec id="s9"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.29066-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Dulbecco, R. (1986) A Turning Point in Cancer Research: Sequencing the Human Genome. Science, 231, 1055-1057.  
&lt;br&gt;https://doi.org/10.1126/science.3945817</mixed-citation></ref><ref id="hanspub.29066-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Zvelebil, M.J. and Baum, J.O. (2007) Understanding Bioinformatics. Garland Sci-ence, USA.  
&lt;br&gt;https://doi.org/10.1201/9780203852507</mixed-citation></ref><ref id="hanspub.29066-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">岳俊杰, 冯华, 梁龙. 蛋白质结构预测实验指南[M]. 北京: 化学工业出版社, 2010.</mixed-citation></ref><ref id="hanspub.29066-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Kaufman, L. and Rousseeuw, P.J. (2009) Finding Groups in Data: An Introduction to Cluster Analysis. John Wiley &amp; Sons, New York.</mixed-citation></ref><ref id="hanspub.29066-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Huang, Z. (1997) Clustering Large Data Sets with Mixed Numeric and Categorical Values. Proceedings of the 1st Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD), 21-34.</mixed-citation></ref><ref id="hanspub.29066-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">LeCun, Y., Bengio, Y. and Hinton, G. (2015) Deep Learning. Nature, 521, 436. &lt;br&gt;https://doi.org/10.1038/nature14539</mixed-citation></ref><ref id="hanspub.29066-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">曲建岭, 杜辰飞, 邸亚洲, 等. 深度自动编码器的研究与展望[J]. 计算机与现代化, 2014(8): 128-134.</mixed-citation></ref><ref id="hanspub.29066-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">张阳, 刘伟铭, 吴义虎. 基于深信度网络分类算法的行人检测方法[J]. 计算机应用研究, 2016, 33(2): 594-597.</mixed-citation></ref><ref id="hanspub.29066-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">LeCun, Y., Bottou, L., Bengio, Y., et al. (1998) Gradient-Based Learning Applied to Document Recognition. Proceedings of the IEEE, 86, 2278-2324. &lt;br&gt;https://doi.org/10.1109/5.726791</mixed-citation></ref><ref id="hanspub.29066-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Memisevic, R., Zach, C., Pollefeys, M., et al. (2010) Gated Softmax Classification. Advances in Neural Information Processing Systems, 1603-1611.</mixed-citation></ref><ref id="hanspub.29066-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Long, J., Shelhamer, E. and Darrell, T. (2017) Fully Convolutional Networks for Semantic Segmentation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 39, 3431-3440.</mixed-citation></ref><ref id="hanspub.29066-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Hubel, D.H. and Wiesel, T.N. (1962) Receptive Fields, Binocular Interaction and Functional Architecture in the Cat's Visual Cortex. The Journal of Physiology, 160, 106-154. &lt;br&gt;https://doi.org/10.1113/jphysiol.1962.sp006837</mixed-citation></ref><ref id="hanspub.29066-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Hosmer Jr., D.W., Lemeshow, S. and Sturdivant, R.X. (2013) Applied Lo-gistic Regression. John Wiley &amp; Sons, New York. &lt;br&gt;https://doi.org/10.1002/9781118548387</mixed-citation></ref><ref id="hanspub.29066-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">范永东. 模型选择中的交叉验证方法综述[D]: [硕士学位论文]. 太原: 山西大学, 2013.</mixed-citation></ref><ref id="hanspub.29066-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">Altschul, S.F., Gish, W., Miller, W., et al. (1990) Basic Local Alignment Search Tool. Journal of Molecular Biology, 215, 403-410. &lt;br&gt;https://doi.org/10.1016/S0022-2836(05)80360-2</mixed-citation></ref><ref id="hanspub.29066-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">邹权, 郭茂祖, 韩英鹏, 等. 多序列比对算法的研究进展[J]. 生物信息学, 2010, 8(4): 311-315.</mixed-citation></ref><ref id="hanspub.29066-ref17"><label>17</label><mixed-citation publication-type="other" xlink:type="simple">Zemla, A., Venclovas, Č., Fidelis, K., et al. (1999) A Modified Definition of Sov, a Segment-Based Measure for Protein Secondary Structure Prediction Assessment. Proteins: Structure, Function, and Bioinformatics, 34, 220-223.  
&lt;br&gt;https://doi.org/10.1002/(SICI)1097-0134(19990201)34:2&lt;220::AID-PROT7&gt;3.0.CO;2-K</mixed-citation></ref></ref-list></back></article>