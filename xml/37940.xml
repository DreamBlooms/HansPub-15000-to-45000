<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">AIRR</journal-id><journal-title-group><journal-title>Artificial Intelligence and Robotics Research</journal-title></journal-title-group><issn pub-type="epub">2326-3415</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/AIRR.2020.94025</article-id><article-id pub-id-type="publisher-id">AIRR-37940</article-id><article-categories><subj-group subj-group-type="heading"><subject>AIRR20200400000_34288364.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject><subject> 工程技术</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于ROS-Unity的移动机器人虚实交互场景构建方法的研究
  Research on Constructing Virtual-Real Interactive Scene of Mobile Robot Based on ROS-Unity
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>张</surname><given-names>朝兴</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>刘</surname><given-names>忠跃</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>田</surname><given-names>龙淼</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>郭</surname><given-names>伦</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>王</surname><given-names>怡欣</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>西南石油大学，四川 成都</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>29</day><month>09</month><year>2020</year></pub-date><volume>09</volume><issue>04</issue><fpage>217</fpage><lpage>231</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
  针对工业生产过程中出现的人工巡检工作量大、工业环境存在潜在危险等情况，本文提出了一种将ROS机器人操作系统与Unity3D软件相结合的方法。通过构建虚实交互场景，实现控制虚拟机器人和真实机器人交互移动，真实机器人反馈回来的环境信息也能映射于虚拟场景中，形成一种虚实交互的控制形式，相较于传统机器人控制，虚实交互控制可以使用户身历其境，拥有切实现场体验，统筹全局，也可用于机器人算法训练、观测状态信息、参数优化等。本项目通过ROS系统使用SLAM算法构建现实场景地图，并将其映射到Unity3D环境，以构建工业生产虚拟场景，同时将ROS作为Unity与真实机器人交互的中间件，采用OpenCV作为视觉交互，在无线通信、Rosbridge框架等技术的支持下实现数据交互，最终设计出了此虚实交互场景构建方案。
   In view of the large manual inspection workload and potential hazards in the industrial environ-ment during the industrial production process, this paper proposes a method to combine the ROS robot operating system with Unity3D software. By constructing virtual and real interactive scenes, the interactive movement of virtual robots and real robots can be controlled. The environment information fed back by the real robots can also be mapped in the virtual scene, forming a virtual and real interactive control form. Compared with traditional robot control, virtual and real inter-active control, it can enable users to immerse themselves in the environment, have a practical on-site experience, coordinate the overall situation, and can also be used for robot algorithm training, observation status information, parameter optimization, etc. This project uses the SLAM algorithm to build a real scene map through the ROS system and maps it to the Unity3D environ-ment to build a virtual scene of industrial production. At the same time, ROS is used as the mid-dleware for Unity and real robot interaction, and OpenCV is used as the visual interaction, and in wireless communication, Rosbridge framework and other technologies support data interaction, and finally we designed this virtual-real interaction scenario construction plan.
 
</p></abstract><kwd-group><kwd>ROS，Unity，SLAM，Gmapping，Rosbridge，机器视觉，WiFi, ROS</kwd><kwd> Unity</kwd><kwd> SLAM</kwd><kwd> Gmapping</kwd><kwd> Rosbridge</kwd><kwd> Machine Vision</kwd><kwd> WiFi</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>摘要</title><p>针对工业生产过程中出现的人工巡检工作量大、工业环境存在潜在危险等情况，本文提出了一种将ROS机器人操作系统与Unity3D软件相结合的方法。通过构建虚实交互场景，实现控制虚拟机器人和真实机器人交互移动，真实机器人反馈回来的环境信息也能映射于虚拟场景中，形成一种虚实交互的控制形式，相较于传统机器人控制，虚实交互控制可以使用户身历其境，拥有切实现场体验，统筹全局，也可用于机器人算法训练、观测状态信息、参数优化等。本项目通过ROS系统使用SLAM算法构建现实场景地图，并将其映射到Unity3D环境，以构建工业生产虚拟场景，同时将ROS作为Unity与真实机器人交互的中间件，采用OpenCV作为视觉交互，在无线通信、Rosbridge框架等技术的支持下实现数据交互，最终设计出了此虚实交互场景构建方案。</p></sec><sec id="s2"><title>关键词</title><p>ROS，Unity，SLAM，Gmapping，Rosbridge，机器视觉，WiFi</p></sec><sec id="s3"><title>Research on Constructing Virtual-Real Interactive Scene of Mobile Robot Based on ROS-Unity</title><p>Chaoxing Zhang, Zhongyue Liu, Longmiao Tian, Lun Guo, Yixin Wang</p><p>Southwest Petroleum University, Chengdu Sichuan</p><p><img src="//html.hanspub.org/file/1-2610211x4_hanspub.png" /></p><p>Received: Sep. 8<sup>th</sup>, 2020; accepted: Sep. 22<sup>nd</sup>, 2020; published: Sep. 29<sup>th</sup>, 2020</p><p><img src="//html.hanspub.org/file/1-2610211x5_hanspub.png" /></p></sec><sec id="s4"><title>ABSTRACT</title><p>In view of the large manual inspection workload and potential hazards in the industrial environment during the industrial production process, this paper proposes a method to combine the ROS robot operating system with Unity3D software. By constructing virtual and real interactive scenes, the interactive movement of virtual robots and real robots can be controlled. The environment information fed back by the real robots can also be mapped in the virtual scene, forming a virtual and real interactive control form. Compared with traditional robot control, virtual and real interactive control, it can enable users to immerse themselves in the environment, have a practical on-site experience, coordinate the overall situation, and can also be used for robot algorithm training, observation status information, parameter optimization, etc. This project uses the SLAM algorithm to build a real scene map through the ROS system and maps it to the Unity3D environment to build a virtual scene of industrial production. At the same time, ROS is used as the middleware for Unity and real robot interaction, and OpenCV is used as the visual interaction, and in wireless communication, Rosbridge framework and other technologies support data interaction, and finally we designed this virtual-real interaction scenario construction plan.</p><p>Keywords:ROS, Unity, SLAM, Gmapping, Rosbridge, Machine Vision, WiFi</p><disp-formula id="hanspub.37940-formula4"><graphic xlink:href="//html.hanspub.org/file/1-2610211x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2020 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/1-2610211x7_hanspub.png" /> <img src="//html.hanspub.org/file/1-2610211x8_hanspub.png" /></p></sec><sec id="s5"><title>1. 引言</title><p>工业生产历来都是支撑一个国家甚至世界的支柱型产业，其是推动社会发展的重要因素之一。如何提高工业生产效率，如何提高工业生产的安全性、可靠性等都已成为各大工业生产公司必须考虑的问题。而随着“工业4.0”的这一概念的提出，为提速工业生产开辟了一条全新的道路。“工业4.0”以智能制造为核心，提出使用信息技术带领工业生产行业从数字化走向网络化、智能化 [<xref ref-type="bibr" rid="hanspub.37940-ref1">1</xref>]。而与之相对应的即是智能机器人领域，即是体现生产智能化程度的重要标志之一，它是减轻人工劳动量、提高生产效率、降低人员安全风险极为有效的方式，特别在此次新冠疫情防控下，智能机器人极大体现了其优势，这也说明了无接触式的远程控制技术的必然趋势。</p><p>本项目即针对此方向结合虚实交互提出了此研究方案，利用WiFi无线通信，使电脑与ROS机器人建立通信连接，实现相同局域网内远程信息交互。同时以工业生产中的物料配送过程为模拟事例，将ROS机器人作为载体，在激光雷达帮助下采用SLAM算法生成二维地图，并在此基础上利用Unity构建工业生产虚拟场景。在运动过程中，虚拟配送机器人会在Unity的Navigation导航功能的帮助下从起点将物料送至生产加工口，其运动的同时会通过WiFi发送运动控制指令带动ROS机器人做同轨迹运动。此外，ROS机器人搭载的OpenCV摄像头会作出识别交通信号灯的动作协助虚拟与现实机器人完成配送任务。</p></sec><sec id="s6"><title>2. 机器人运动模型的建立</title><sec id="s6_1"><title>2.1. 硬件的选择</title><p>本项目采用两轮差速移动机器人作为研究对象，实体图如下图1。根据其控制流程，可以将机器人分为以树莓派3B+控制板为核心的主控制器，解析指令并控制机器人的所有动作；为建图提供环境数据的激光雷达模块；提供机器视觉交互的OpenCV广角摄像头；提供机器人姿态数据的9轴IMU板块等。驱动上，机器人采用两个光电编码直流电机实现差速控制。</p><p>图1. ROS机器人实物图</p></sec><sec id="s6_2"><title>2.2. 移动机器人运动控制</title><p>机器人采用两轮差速驱动方式，每个轮子各带有独立的执行机构(光电编码步进电机)，同时机器人后方安装了钢珠万向轮，与前方的两驱动轮构成三脚架支撑结构。执行指令由树莓派控制板解析成相应脉冲电信号，并分别发送给两个驱动电机，控制机器人行进。下位机的具体控制流程如下图2：</p><p>图2. 下位机控制流程图</p></sec></sec><sec id="s7"><title>3. 虚拟场景的构建</title><sec id="s7_1"><title>3.1. SLAM地图建建立</title><p>针对实验环境地图构建的方法上，我们采用即时定位与地图构建(Simultaneous Localization and Mapping, SLAM)技术 [<xref ref-type="bibr" rid="hanspub.37940-ref2">2</xref>]，该技术目前被广泛的应用于地图构建。SLAM的核心思想是根据机器人的观测值 z 1 : t (地图中的点)和里程计测量序列 u 1 : t − 1 (机器人轨迹)来估计机器人轨迹分布 x 1 : t 和地图m，以此获得联合后验概率函数 P ( x 1 : t , m | z 1 : t , u 1 : t − 1 ) ，而为了简化计算，往往将其拆分成位姿状态估计和地图状态估计，即：</p><p>P ( x 1 : t , m | z 1 : t , u 1 : t − 1 ) = P ( m | x 1 : t , z 1 : t ) P ( x 1 : t | z 1 : t , u 1 : t − 1 )</p><p>这一举措即是RBPF(粒子滤波算法)的思想，而我们采用的Gmapping算法技术在RBPF基础上，针对RBPF所有粒子多和频繁执行采样问题提出了改进提议分布和选择性采样，优化了常规RBPF算法，使得实现SLAM建图更加准确。</p><p>常规RBPF粒子滤波算法总体可概括为采样、权重计算、重采样、地图估计。而Gmapping在此基础上提出改进提议分布，在激光雷达的帮助下获取比里程计更准确的环境数据，得到改进后的建议分布 [<xref ref-type="bibr" rid="hanspub.37940-ref3">3</xref>]：</p><p>P ( x t | m t − 1 ( i ) , x t − 1 ( i ) , z t , u t − 1 ) = P ( z t | m t − 1 ( i ) , x t ) P ( x t | x t − 1 ( i ) , u t − 1 ) P ( z t | m t − 1 ( i ) , x i − 1 ( i ) , u t − 1 )</p><p>且其计算权重时的公式为：</p><p>w t ( i ) = P ( x 1 : t ( i ) | z 1 : t , u 1 : t − 1 ) π ( x 1 : t ( i ) | z 1 : t , u 1 : t − 1 )</p><p>使用贝叶斯加全概率展开等变换，可以得权重计算近似为：</p><p>w t ( i ) ∝ w t − 1 ( i ) ⋅ P ( z t | m t − 1 ( i ) , x i − 1 ( i ) , u t − 1 )</p><p>而随着粒子不断的迭代，在选择性采样的协助下，低权重粒子被舍去，高权重粒子被采纳，在重采样的过程中，以设定阀值 N e f f 的方式来评估粒子权重分散程度，即：</p><p>N e f f = 1 ∑ i = 1 M ( φ ( i ) ) 2</p><p>其中 φ ( i ) 表示粒子归一化的权重，在粒子数目为M的情况下，只有在 N e f f &lt; 1 2 时，系统才会进行重采样 [<xref ref-type="bibr" rid="hanspub.37940-ref4">4</xref>]。</p><p>在SLAM的实现上，算法上ROS提供了实现Gamaping算法的功能包，在完成功能包中的相关参数配置以及激光雷达、里程计的配置后，即可实现定位与建图的功能。</p><p>图3是机器人执行建图时当前系统运行节点关系图：</p><p>图3. SLAM建图节点关系图</p><p>图3中可直观的观察到建图时系统涉及到的节点，以及节点间发布订阅话题的关系。其中/slam_gampping作为Gmapping算法的核心节点分别订阅了来自/hawkbot_lds节点发布的激光雷达/scan话题、/robot_state_publisher的底盘与里程计原点坐标变换/tf_static话题、/imu_complementary_filer的IMU提供的相对定位信息/tf话题、/base_link_to_laser的底座与激光雷达坐标变换/tf话题，此外/teleop则提供键盘控制话题，最终所有的输出都将作为/robot_pose_ekf节点的输入来控制机器人的移动。</p><p>在启动/slam_gmapping节点的同时，一并启动Rviz组件，地图将在Rviz中建立。完成二维地图构建后，在命令行终端使用指令：</p><disp-formula id="hanspub.37940-formula5"><graphic xlink:href="//html.hanspub.org/file/1-2610211x24_hanspub.png"  xlink:type="simple"/></disp-formula><p>将建立好的地图保存后，文件名即为map_1，保存的二维地图(图4)和真实的实验场景(图5)：</p><p>图4. 机器人构建的二维地图</p><p>图5. 机真实实验场景图</p></sec><sec id="s7_2"><title>3.2. ROS地图到Unity场景</title><sec id="s7_2_1"><title>3.2.1. ROS地图的尺寸计算</title><p>根据上文所述，在Gmapping建图过程中，使用ROS指令可以保存的构建的地图文件，其中会生成一个map_1.yaml和一个map_1.pgm文件，地图图像保存在map_1.pgm文件中，map_1.yaml文件则是对地图的参数的说明，而map_1.pgm文件可以通过Ubuntu中的GIMP图片编辑软件转成.png格式用于Unity加工，根据map_1.yaml文件中的resolution(分辨率)参数，其代表的是每个像素对应的实际距离(0.05 m/pixel)，再利用GIMP测量工具(图6)，测量出地图轮廓的像素值，再乘以分辨率即可知实际距离。</p><p>图6. GIMP测量图</p><p>实际实验场地尺寸计算公式即为：</p><p>实际距离=测量像素值&#215;分辨率(resolution)</p><p>以下是对图5地图中每一条黑线(边界)的像素尺寸的测量值列表1：</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Experiment of map size measuremen</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >边编号</th><th align="center" valign="middle" >第一次测量(/像素)</th><th align="center" valign="middle" >第二次测量(/像素)</th><th align="center" valign="middle" >第三次测量(/像素)</th><th align="center" valign="middle" >平均像素(/像素)</th><th align="center" valign="middle" >实际尺寸(/m)</th></tr></thead><tr><td align="center" valign="middle" >①</td><td align="center" valign="middle" >43.6</td><td align="center" valign="middle" >42.4</td><td align="center" valign="middle" >44.2</td><td align="center" valign="middle" >43.40</td><td align="center" valign="middle" >2.17</td></tr><tr><td align="center" valign="middle" >②</td><td align="center" valign="middle" >28.3</td><td align="center" valign="middle" >27.8</td><td align="center" valign="middle" >29.1</td><td align="center" valign="middle" >28.40</td><td align="center" valign="middle" >1.42</td></tr><tr><td align="center" valign="middle" >③</td><td align="center" valign="middle" >31.3</td><td align="center" valign="middle" >32.7</td><td align="center" valign="middle" >31.9</td><td align="center" valign="middle" >31.97</td><td align="center" valign="middle" >1.60</td></tr><tr><td align="center" valign="middle" >④</td><td align="center" valign="middle" >44.9</td><td align="center" valign="middle" >45.1</td><td align="center" valign="middle" >45.6</td><td align="center" valign="middle" >45.2</td><td align="center" valign="middle" >2.26</td></tr><tr><td align="center" valign="middle" >⑤</td><td align="center" valign="middle" >53.7</td><td align="center" valign="middle" >52.3</td><td align="center" valign="middle" >54.3</td><td align="center" valign="middle" >53.43</td><td align="center" valign="middle" >2.67</td></tr></tbody></table></table-wrap><p>表1. 地图尺寸测量实验</p><p>由此我们可以在没有人员到实际场景进行手工测量的情况下便可实现远程尺寸测量。</p></sec><sec id="s7_2_2"><title>3.2.2. Unity虚拟场景构建与导航网格烘焙</title><p>结合Unity中像素与距离的关系，对导入的地图文件进行适当放缩，即可达到尺寸匹配的效果。经过查阅Unity中场景元素的属性,基础单位为米，参照导入Unity的ROS地图创建并调节出对应尺寸的GameObject对象“plane”，以该对象为载体调用C#脚本代码计算出plane对象的尺寸即求出ROS地图在Unity虚拟环境中的尺寸，关键代码如下：</p><disp-formula id="hanspub.37940-formula6"><graphic xlink:href="//html.hanspub.org/file/1-2610211x28_hanspub.png"  xlink:type="simple"/></disp-formula><p>以宽度 w 虚 为例，为plane添加MeshFilter组件，以此获取原始宽度default_w，再将原始宽度乘以放缩比即可得实际宽度map_w，长度 l 虚 以此类推，数据取整，计算出虚拟场景得：</p><p>l 虚 &#215; w 虚 = 10 &#215; 13</p><p>与对于④号边与⑤号边实际长度的比值k分别为：</p><p>k 1 = w 虚 l 4 = 4.425 ， k 2 = l 虚 l 5 = 4.869 ， k _ = ( k 1 + k 2 ) &#247; 2 = 4.647</p><p>则虚拟机器人与显示机器人的速度关系即根据该虚实交互比值来限定，以此提高两者的同步性能。</p><p>导入Unity后，为了更加体现出本项目的实用性，我们利用Unity在ROS地图基础上模拟构建了一个工业生产场景(如图7)。</p><p>在虚拟机器人的运动控制方面，我们采用Unity的导航功能，模拟虚拟机器人将物料配送到入料口的过程，该功能需要采用的Unity的Navigation导航网格 [<xref ref-type="bibr" rid="hanspub.37940-ref5">5</xref>] 组件进行网格烘焙，同时为虚拟机器人添加上NavMeshAgent组件，而导航网格的作用是使得添加了NavMeshAgent组件的物体能够在导航网格上以最优路径移动到设定的终点，由此可实现自动配送物料的功能。</p><p>图7. Unity添加工业模型并导航烘焙后的虚拟场景</p></sec><sec id="s7_2_3"><title>3.2.3. Unity虚拟场景操作界面</title><p>为了测试便利以及交互性的提高，我们使用Unity的GUI界面技术 [<xref ref-type="bibr" rid="hanspub.37940-ref6">6</xref>] 在Unity客户端设计了用于人机交互的操作界面(如图8)，同时在PC端连接了外接摄像头，该摄像头处于实验场景，可将真实场景画面传送至Unity操作界面。在点击运行后，Unity会同时运行两个程序线程，主线程完成加载客户端界面，副线程则完成与ROS的网络链接。</p><p>界面上的操作区，空白处用于显示提示信息，“开启信号灯识别”按钮用于Unity接收识别信号灯的控制信号，如遇红灯则提示“通行状态如下：红灯停车等待中”，无信号灯或者为绿灯则提示“通行状态如下：可通行”。而“前进”、“左转”、“停止”、“右转”、“后退”按钮则可手动控制ROS机器人移动。“启动导航”按钮则是进行虚实交互控制的启动按钮，当按下该按钮后，提示“机器人已启动”，虚拟机器人首先移动，Unity发布控制信息给ROS机器人使之随动。具体的操作流程如图9。</p><p>图8. Unity初始化操作界面</p><p>图9. Unity界面操作流程图</p></sec></sec><sec id="s7_3"><title>3.3. 虚实交互方式</title><sec id="s7_3_1"><title>3.3.1. Unity导航对ROS机器人运动控制</title><p>针对Unity与ROS机器人的运动交互上，我们运用到了Unity导航功能中的NavMeshPath类型组件，通过定义该类型的变量path，将导航起始点坐标作为输入，path作为输出，调用NavMesh.CalculatePath()函数即可计算出导航的路径信息并保存在变量path中，path中所包含的Corners数组则存储了导航路径的所有关键点的坐标，因为Unity导航路线是由Corners关键点连接起来的(如图10所示)，通过比较相邻两点的坐标，可以很容易得到两点间的距离和方向转角。</p><p>图10. Unity界面操作流程图</p><p>如图设CD近似与轴重合(即此时机器人的正方向为CD)，故CD与轴夹角为，同时设 D ( x d , y d ) ， E ( x e , y e ) ，D、E点与轴的夹角分别为 θ 1 、 θ 2 ，若机器人从C点移动到D点，在D点停止时机器人的正向仍为CD，则以此时状态移动到E点的过程有：</p><p>tan θ 1 = x e − x d y e − y d ， θ 1 = arctan x e − x d y e − y d ， Δ θ 1 = θ 1 − θ 0</p><p>即为机器人C到D的末态方向与D到E的初态方向夹角，同理可得E到F点的运动方向夹角为： Δ θ 2 = θ 2 − θ 1 ，同时DE的运动距离为：</p><p><inline-formula><inline-graphic xlink:href="//html.hanspub.org/file/1-2610211x47_hanspub.png" xlink:type="simple"/></inline-formula>或 y e − y d cos Δ θ 1</p><p>以上述方法可计算出任意相邻关键点的距离与转角，并将其转化为控制信息即可对ROS现实机器人进行虚实交互控制。</p></sec><sec id="s7_3_2"><title>3.3.2. 机器视觉识别交通信号灯</title><p>在现代工业场景中，为了更好的协调各个车辆工作的有序进行，必然会存在指示灯这类设施。于是，我们基于机器视觉为机器人设计了，针对识别交通信号灯控制其移动与停止的功能。</p><p>我们以一广角摄像头作为视觉交互设备。使用OpenCV开源计算机视觉库 [<xref ref-type="bibr" rid="hanspub.37940-ref7">7</xref>] 实现视觉识别算法，并利用ROS所提供的CV_bridge视觉框架将OpenCV和ROS结合，实现通过ROS平台控制机器人调用视觉识别功能。ROS本身并不能直接使用OpenCV开源库函数，而在ROS提供的CV_bridge的帮助下可将两者紧密地联系起来，通过其内部函数，可将OpenCV返回的Mat类型图像数据转换为ROS内部通讯机制能够识别的sensor_msgs/image消息格式进行传输，也可逆向转换。而交通信号灯的识别，则是基于OpenCV的颜色空间模型 [<xref ref-type="bibr" rid="hanspub.37940-ref7">7</xref>] 来实现颜色识别的。</p><p>在颜色模型选择上，我们使用RGB和HSV。RGB是最为常用的颜色空间模型，其显示效果同人眼所见最为相近，但是对于机器来说，RGB很难较好的反应图像中的具体信息。而HSV模型包含的色调(H)、饱和度(S)、亮度(V)三个参量，能够实现图像的特征调节凸显所要识别的颜色，可极大提高颜色间的对比效率。</p><p>由于基于ROS平台运行，摄像头读入的RGB信息转换为的是ROS的图像数据，通过话题发布此消息，经CV_bridge将该消息转换为OpenCV图像数据，再经一系列图像处理(如图10)，即可识别出特定颜色。针对交通信号灯，主要是对红色与绿色的识别，经过操作界面(如图12)调节得红色的三参数取值范围分别为H[0,10]，S[43,255]，V[46,255]，绿色的三参数取值范围分别是H[35,77]，S[43,255]，V[46,255]。</p><p>识别算法的实现过程如图11，同时红色识别并框选如图13，绿色类似。</p><p>图11. 算法流程图</p><p>图12. HSV操作界面</p><p>图13. 红色识别框选效果</p><p>而在虚实交互上，识别到红色指示和识别到绿色指示时，该节点会发布/traffic_deal话题，该话题会发送红色与绿色的对应数据，Unity通过订阅此话题即可让虚拟机器人知道此时是红灯还是绿灯。</p></sec></sec></sec><sec id="s8"><title>4. 虚实交互的通信机制</title><sec id="s8_1"><title>4.1. 机器人与PC端的通信方式——WiFi</title><p>为了尽可能的减少对机器人运动束缚，采用无线控制方式是最为合适的，结合树莓派3B+拥有无线网卡的特点，使树莓派产生WiFi热点，PC端连接此热点，可实现同域网中，使用PC端远程控制机器人。经过对无线网卡的配置，在连接热点后，我们采用SecureCRT远程桌面软件，以SSH协议 [<xref ref-type="bibr" rid="hanspub.37940-ref8">8</xref>] 方式通过机器人IP地址远程登录树莓派系统，登录成功后，便可在SecureCRT中开启终端输入指令行远程对机器人进行操作。</p><p>与此同时，因为PC端处于连接树莓派热点的情况下，故PC端的虚拟机Ubuntu系统中通过ping通机器人IP的方式，可使虚拟机中ROS系统与机器人中的ROS系统实现数据互通，即在PC端的虚拟机中可对机器人上的ROS发布的话题进行订阅处理等操作，这样可将大型数据的处理交由PC端来完成，如SLAM建图等，大大降低了树莓派的工作负荷。</p></sec><sec id="s8_2"><title>4.2. ROS与Unity的通信桥梁——Rosbridge</title><p>本项目能够实现使ROS平台与Unity进行数据交互，进而实现虚实交互功能的主要助手即是ROS官方为开发者提供的用于与非ROS系统进行交互通信的Rosbridge_suite功能包，该功能包为外部程序提供了能够调用ROS功能的JSON API，包括话题的订阅、消息的发布、服务的调用、参数的设置和获取以及图片信息的传递等，这些功能的调用指令都是以JSON格式发布的。而负责通信传输层管理的是Rosbridge_suite中的Rosbridge_server子功能包，它针对不同通信架构提供了包括WebSocket、TCP、UDP在内的几种通信方案。其中WebSocket针对Browser/Server架构，主要用于与Web浏览器进行交互的服务器；TCP与UDP则是针对Client/Server架构，该架构中UDP通信响应速度快，但会发生丢失数据包的情况，因此存在不确定性；而TCP通信因为需要三次握手 [<xref ref-type="bibr" rid="hanspub.37940-ref9">9</xref>]，所以使得传输过程更加稳定准确。由此我们选用Rosbridge的TCP通信方式,并在ROS的Socket通信链路 [<xref ref-type="bibr" rid="hanspub.37940-ref10">10</xref>] 的帮助下搭建起ROS与Unity的通信桥梁。Rosbridge的TCP通信服务端开启指令如下：</p><disp-formula id="hanspub.37940-formula7"><graphic xlink:href="//html.hanspub.org/file/1-2610211x52_hanspub.png"  xlink:type="simple"/></disp-formula><p>启动后，终端窗口提示默认port(端口号)为9090，IP则为PC端虚拟机Ubuntu系统的IP地址。在Unity客户端使用C#语言绑定连接该IP地址与9090端口号，即可实现Unity与ROS平台的TCP通信连接。与Unity连接成功后终端窗口的提示如图14：</p><p>图14. Unity与Rosbridge连接成功提示</p></sec><sec id="s8_3"><title>4.3. ROS与Unity的通信桥梁——Rosbridge</title><p>Rosbridge协议是用于发送基于JSON格式的ROS指令的规范。应该说所有外部程序都必须遵守该协议才能调用ROS的相关功能。下面是使用Unity发布话题的JSON格式数据：</p><disp-formula id="hanspub.37940-formula8"><graphic xlink:href="//html.hanspub.org/file/1-2610211x54_hanspub.png"  xlink:type="simple"/></disp-formula><p>其作用是发布控制机器人角速度与线速度的话题,“op”表示操作动作，这里“publish”即是发布，话题名为“/cmd_vel”,“msg”表示发布的消息内容，即设定xyz轴上的线速度(linear)和角速度(angular)。而Unity客户端接收到ROS端发送的数据仍然是遵循Rosbridge协议的JSON格式。Unity通过脚本解析与判断这些JSON格式字符串，即可获得ROS传输的有用数据，以此实现给虚拟场景传递和反馈信息的功能。</p><p>而在虚拟机器人与现实ROS机器人的运动交互上，即是由Unity虚拟机器人在NavMeshAgent导航移动的同时，不断发布/cmd_vel话题给ROS机器人，控制ROS机器人的线角速度与虚拟机器人的移动趋于相同，从而实现虚实交互控制。</p><p>虚实交互的另一方面，ROS机器人遇到指示灯时，节点获取并识别信号灯信息，一方面该节点会根据识别信息发布控制ROS机器人运动与停止的/cmd_vel话题，另一方面又会发布/traffic_deal话题，Unity在Rosbridge的帮助下，通过以下JSON格式语句订阅此话题</p><disp-formula id="hanspub.37940-formula9"><graphic xlink:href="//html.hanspub.org/file/1-2610211x55_hanspub.png"  xlink:type="simple"/></disp-formula><p>而该话题发布的识别信息则将以下面JSON格式返回Unity，从而使虚拟机器人知道此时处于红灯需要停止，反之为无信号或绿灯可继续行驶。</p><disp-formula id="hanspub.37940-formula10"><graphic xlink:href="//html.hanspub.org/file/1-2610211x56_hanspub.png"  xlink:type="simple"/></disp-formula><p>由此在Rosbridge协议的帮助下便实现了ROS与Unity的双向虚实数据的交互。</p><p>图15. 导航路径模拟图</p></sec></sec><sec id="s9"><title>5. 实验与分析</title><p>Unity与ROS的交互测试，即Unity导航对机器人的控制。ROS与Unity交互的过程仍然是遵循ROS节点通信机制，在Rosbridge的帮助下，Unity作为ROS的外部组件也可以被ROS系统视作为一个节点，同样拥有节点的基本功能。虚拟到现实交互过程中，以Unity作为主控方，当执行导航前，Unity生成由关键点组成的导航路线，执行导航过程中，关键点将路线分段，测试在不同速度通过时，观察Unity虚拟机器人与ROS机器人移动的同步情况，根据关键点坐标使用Matlab软件绘制出了实验的导航路径图(图15)，并根据测量虚实机器人移动距离与转角得出误差相对较小的线、角速度配速。</p><p>根据上文得到的虚实交互比 =4.647，以此作为实验的比例因数，进行速度匹配测试，我们通过虚拟机器人的关键点坐标可以计算出被关键点分割后所形成路段的距离，即为两个关键点之间虚拟机器人所行走的距离，利用可以求出理论上真实机器人应该走的距离，而对应于真实机器人所行走的距离，我们可以手工测得，由此计算出理论与实际的线速度差值，经过对ROS机器人线速度的多次不同设定，我们使用Matlab软件绘制出了对应配速下的差值与0线比较的折线图(如图16)：</p><p>图16. 不同线速度下虚实移动距离的误差情况</p><p>在角速度的测试上，同样通过关键点坐标值，我们可以计算出理论上ROS真实机器人在对应点上应该转动的角度，通过获取机器人上IMU板块的转角数据即可知道实际所转动的角度，由此可绘制出在不同角速度下，理论与实际转角的差值与0线比较的折线图(如图17)。</p><p>由实验结果分析可得，ROS机器人线速度在设定在0.25 m/s时，理论与实际之间的距离差的折线最接近0值，即移动距离误差最小；角速度上，根据每个关键点上理论与实际的转角差折线图，可以较为清晰的看出，在1.2 rad/s时，转角差最接近于0线。由此可以得到误差相对较小时的线速度、角速度分别为：0.25 m/s、1.2 rad/s。</p><p>图17. 不同角速度下虚实转角的误差情况</p></sec><sec id="s10"><title>6. 结束语</title><p>本项目以工业生产为背景，针对如何实现虚实交互技术这一问题提出了结合使用ROS机器人操作系统和Unity3D软件的研究思路，并在Gmapping算法、WiFi、Rosbridge、OpenCV等技术的支持下，实现了SLAM建图、无线通信、TCP通信、交通信号灯识别等功能，较完整地构成了一套由虚拟场景机器人控制真实机器人运动，真实机器人反馈现实信息至虚拟场景的虚实交互方案。为虚实交互技术的实现提供了较为可靠的参考。通过各项功能实验证实，得出了以下主要结论：</p><p>1) 在实现SLAM地图构建上，通过对Gmapping算法解析与多次的实验，已可进行稳定的室内环境二维地图的构建，为Unity虚拟场景构建提供了较为准确的基础。</p><p>2) 在ROS与Unity的通信上，通过ROS机器人发出WiFi热点能够使机器人与PC端建立连接，并在此基础上使用ROS中的Rosbridge架构打开ROS与外部的TCP通信接口，供Unity进行连接，实现了ROS与Unity环境的信息互通，从而建立起了虚实交互的通道。</p><p>3) 在交通信号灯识别上，在CV_bridge协助下，将OpenCV视觉技术与ROS系统结合，利用HSV颜色空间识别算法，实现了对红色、绿色的框选识别，从而能够为虚、实机器人反馈现实场景的控制信息。</p><p>4) 根据对虚拟、现实机器人线、角速度的配速实验，分析实验结果得出误差相对较小的ROS机器人线、角速度的配速分别为：0.25 m/s、1.2 rad/s。在此配速下，ROS真实机器人的运动轨迹最为接近于虚拟机器人的导航轨迹。</p></sec><sec id="s11"><title>文章引用</title><p>张朝兴,刘忠跃,田龙淼,郭伦,王怡欣. 基于ROS-Unity的移动机器人虚实交互场景构建方法的研究 Research on Constructing Virtual-Real Interactive Scene of Mobile Robot Based on ROS-Unity[J]. 人工智能与机器人研究, 2020, 09(04): 217-231. https://doi.org/10.12677/AIRR.2020.94025</p></sec><sec id="s12"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.37940-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">王喜文. 应对工业4.0的中国进路[J]. 新疆师范大学学报(哲学社会科学版), 2018, 39(3): 87-93.</mixed-citation></ref><ref id="hanspub.37940-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">王林荣, 黄涛. 基于ROS的激光SLAM室内建图定位导航智能机器人设计[J]. 无线互联科技, 2020, 17(4): 64-66, 75.</mixed-citation></ref><ref id="hanspub.37940-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">刘媛媛, 公建宁, 张萌, 谢昊天, 李伟. 基于单舵轮AGV的Gmapping SLAM导航算法研究[J]. 制造业自动化, 2020, 42(2): 128-130, 139.</mixed-citation></ref><ref id="hanspub.37940-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">刘文之. 基于激光雷达的SLAM和路径规划算法研究与实现[D]: [硕士学位论文]. 哈尔滨: 哈尔滨工业大学, 2018: 25-30.</mixed-citation></ref><ref id="hanspub.37940-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">刘雪梅, 周雨, 孟莨钦, 张朝兴, 刘忠跃. 基于虚实交互的机器人运动场景构建方法的研究[J]. 人工智能与机器人研究, 2019, 8(3): 166-182.</mixed-citation></ref><ref id="hanspub.37940-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">郭宇承, 谷学静, 石琳. 虚拟现实与交互设计[M]. 武汉: 武汉大学出版社, 2015: 141-144.</mixed-citation></ref><ref id="hanspub.37940-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">侯宾, 张文志, 戴源成, 田洪强. 基于OpenCV的目标物体颜色及轮廓的识别方法[J]. 现代电子技术, 2014, 37(24): 76-79, 83.</mixed-citation></ref><ref id="hanspub.37940-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">苏庆林, 李蕾. Python基于SSH协议实现Linux系统远程管理方法研究[J]. 信息系统工程, 2019(12): 51-52, 55.</mixed-citation></ref><ref id="hanspub.37940-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">熊兵, 赵锦元, 廖年冬. 基于TCP三次握手特性的高效连接管理方法[J]. 计算机工程, 2013(11): 83-86, 90.</mixed-citation></ref><ref id="hanspub.37940-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">申勇. 基于位姿估计的云机器人实时通信研究[D]: [硕士学位论文]. 沈阳: 东北大学, 2017: 53-62.</mixed-citation></ref></ref-list></back></article>