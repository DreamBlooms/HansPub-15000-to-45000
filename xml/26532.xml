<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">JISP</journal-id><journal-title-group><journal-title>Journal of Image and Signal Processing</journal-title></journal-title-group><issn pub-type="epub">2325-6753</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/JISP.2018.74021</article-id><article-id pub-id-type="publisher-id">JISP-26532</article-id><article-categories><subj-group subj-group-type="heading"><subject>JISP20180400000_23504821.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  低空视频影像自适应关键帧提取与快速拼接
  Adaptive Key Frames Extraction and Fast Image Mosaic of Low Altitude Aerial Video
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>李</surname><given-names>含伦</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>李</surname><given-names>丰凯</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff3"><addr-line>首都师范大学三维信息获取与应用教育部重点实验室，北京</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><aff id="aff2"><addr-line>中国电子科技集团公司第三研究所，北京</addr-line></aff><pub-date pub-type="epub"><day>22</day><month>08</month><year>2018</year></pub-date><volume>07</volume><issue>04</issue><fpage>179</fpage><lpage>190</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
  
    无人飞行器超低空飞行，获取图像幅宽小，数量多，重复率高，为获取全测区的图像需要图像拼接。目前航空影像拼接广泛使用基于特征匹配的图像配准方法。特征匹配的计算量大，错误率高，影响了图像拼接的速度。针对上述问题提出了一种自适应关键帧的图像拼接方法。该方法根据基准影像和给定的重叠度自适应提取关键帧影像，使用正解和反解相结合的方法完成对关键帧影像的正射校正。通过坐标解算得到每个关键帧影像中需要参与拼接的部分，然后使用横向流型拼接方法将每个关键帧中参与拼接的部分拼接形成测区全图。实验结果表明本文方法在保证较高的拼接精度下可以实现航拍影像的快速实时拼接，很大程度上提高了图像拼接的效率。本文方法可以实现航拍影像快速拼接，满足现场数据检验以及其它快速应急响应的需求，在灾害应急保障与救援中有重要应用意义。
    Images captured by unmanned aerial vehicle have small image width, large quantity, and high overlap rate. In order to get the image of whole measurement area, image mosaicking is necessary. Feature matching method is widely used in the field of aerial image mosaicing. Feature matching has many disadvantages such as heavy burden of calculation, high error rate, so affected the speed of image stitching greatly. To solve those problems, an adaptive key frame was proposed. Extracting method extracts key frame images according to overlap rate of images and gets the orthographical correction of key frame images by using the combination of direct method and inverse solution method. The part involved in image mosaicing of every key frame was obtained by using its coordinates. Then we get the mosaiced image of the whole area by using flow pattern stitching method. Experimental results show that the method proposed in this paper can realize real-time aerial image stitching with high precision and can improve the efficiency of image mosacing sig-nificantly. The method proposed in this paper can realize real-time aerial image stitching and meet requirements of rapid response, especially in disaster emergency response and rescue. 
  
 
</p></abstract><kwd-group><kwd>快速实时拼接，关键帧提取，正射校正，精度评价, Real-Time Mosaic</kwd><kwd> Extract Key Frames</kwd><kwd> Orthographical Correction</kwd><kwd> Accuracy Eevaluation</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>低空视频影像自适应关键帧提取与快速拼接<sup> </sup></title><p>李含伦<sup>1</sup>，李丰凯<sup>2</sup></p><p><sup>1</sup>中国电子科技集团公司第三研究所，北京</p><p><sup>2</sup>首都师范大学三维信息获取与应用教育部重点实验室，北京</p><p><img src="//html.hanspub.org/file/1-2670157x1_hanspub.png" /></p><p>收稿日期：2018年7月27日；录用日期：2018年8月15日；发布日期：2018年8月22日</p><disp-formula id="hanspub.26532-formula3"><graphic xlink:href="//html.hanspub.org/file/1-2670157x5_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>无人飞行器超低空飞行，获取图像幅宽小，数量多，重复率高，为获取全测区的图像需要图像拼接。目前航空影像拼接广泛使用基于特征匹配的图像配准方法。特征匹配的计算量大，错误率高，影响了图像拼接的速度。针对上述问题提出了一种自适应关键帧的图像拼接方法。该方法根据基准影像和给定的重叠度自适应提取关键帧影像，使用正解和反解相结合的方法完成对关键帧影像的正射校正。通过坐标解算得到每个关键帧影像中需要参与拼接的部分，然后使用横向流型拼接方法将每个关键帧中参与拼接的部分拼接形成测区全图。实验结果表明本文方法在保证较高的拼接精度下可以实现航拍影像的快速实时拼接，很大程度上提高了图像拼接的效率。本文方法可以实现航拍影像快速拼接，满足现场数据检验以及其它快速应急响应的需求，在灾害应急保障与救援中有重要应用意义。</p><p>关键词 :快速实时拼接，关键帧提取，正射校正，精度评价</p><disp-formula id="hanspub.26532-formula4"><graphic xlink:href="//html.hanspub.org/file/1-2670157x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2018 by authors and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/1-2670157x7_hanspub.png" /> <img src="//html.hanspub.org/file/1-2670157x8_hanspub.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>无人飞行器具有快速、灵活、低成本、高影像分辨率等特点，可以提供测区的第一手影像资料，有效弥补了遥感卫星的重访周期不足。因此，在灾害监测，资源勘察、紧急救援、国土安全评估、空间决策支持等应用领域具有广阔的潜在应用前景 [<xref ref-type="bibr" rid="hanspub.26532-ref1">1</xref>] 。一般无人飞行器超低空飞行获取影像幅宽小，数量大，分辨率高，重叠度高。无人飞行器易产生大倾角且倾斜无规律，造成图像存在不规则重叠区、几何畸变。这些因素对无人机图像的拼接效率及拼接效果有着严重的影响，使得无人机系统的实际应用受到很大制约 [<xref ref-type="bibr" rid="hanspub.26532-ref2">2</xref>] 。为及时、准确地反映整个测区情况，需要将获得的影像现场快速拼接，形成测区全图。因此，快速拼接问题成为无人机遥感领域研究的重要内容之一 [<xref ref-type="bibr" rid="hanspub.26532-ref3">3</xref>] [<xref ref-type="bibr" rid="hanspub.26532-ref4">4</xref>] [<xref ref-type="bibr" rid="hanspub.26532-ref5">5</xref>] [<xref ref-type="bibr" rid="hanspub.26532-ref6">6</xref>] 。根据影像配准的方法大致可将影像拼接技术分为三类：①基于影像灰度的方法：该类方法通过计算图像间重叠部分的灰度差SSD (Sum of Squared Difference)等相似度指标，优化模型参数，但由于计算出的参数对光照条件和旋转角度等比较敏感，所以对无人飞行器航拍影像并不适合 [<xref ref-type="bibr" rid="hanspub.26532-ref7">7</xref>] ；②基于变换域的方法：该类方法首先利用傅立叶变换将影像由空域变换到频域，然后通过它们的相互功率直接计算得出两幅影像间的平移矢量，进而实现影像的配准 [<xref ref-type="bibr" rid="hanspub.26532-ref8">8</xref>] 。③基于图像特征的方法：该类方法具有一定的尺度不变性，旋转不变性，对于光线、噪声、微视角改变具有鲁棒性，因此是航空影像拼接的主要方法。其重点在于特征因子的选取，但是这种方法计算量较大，耗时较长。</p><p>图像拼接方面的研究已较深入，2002年刘金根等提出了一种基于特征区域分割的图像拼接算法 [<xref ref-type="bibr" rid="hanspub.26532-ref9">9</xref>] ，2004年赵向阳等(文献4)提出了一种全自动稳健的图像拼接融合算法，2009年王勇等(文献5)提出了一种感兴趣区域寻优搜索的全自动图像拼接算法。但是，他们拼接的图像非遥感影像，特别是在超低空无人飞行器获取的视频影像方面，目前还没有较成熟的拼接技术。尚明姝 [<xref ref-type="bibr" rid="hanspub.26532-ref10">10</xref>] 采用Harris提取角点，利用最小中值法去除局外点，实现图像拼接。韩文超 [<xref ref-type="bibr" rid="hanspub.26532-ref11">11</xref>] 利用SIFT算子实现了无人机影像的自动拼接。由于基于特征匹配的图像配准方法要搜索和匹配特征点对，计算量大，耗时长很大程度上影响了图像拼接的效率，无法满足实时启用需求。针对上述提到的问题，提出了低空小幅宽视频影像自适应关键帧提取与快速拼接方法，可以保证在较高的精度下实现超低空无人飞行器获取视频影像的快速拼接，满足现场数据检验以及其它快速应急响应的需求。</p></sec><sec id="s4"><title>2. 方法介绍</title><sec id="s4_1"><title>2.1. 关键帧提取</title><p>在选定基准帧影像后，为了提高图像拼接的效率，获取满足重叠度要求的影像对需要提取关键帧影像。判定当前帧图像是否为关键帧的依据是当前帧与参考帧之间的重叠度 [<xref ref-type="bibr" rid="hanspub.26532-ref12">12</xref>] 。在选定了重叠度和参考帧之后，计算当前帧与基准帧的重叠度，若重叠度满足要求，则将当前帧选为关键帧，否则移动到下一帧，循环上述过程。在选定关键帧之后，再进行下一关键帧的提取。Li Jing [<xref ref-type="bibr" rid="hanspub.26532-ref13">13</xref>] 等人采用逐帧计算的方法进行关键帧提取，其缺点在于效率太低，不适合时效性要求较高的应用领域。Fadaeieslam [<xref ref-type="bibr" rid="hanspub.26532-ref14">14</xref>] 和李岩山 [<xref ref-type="bibr" rid="hanspub.26532-ref15">15</xref>] 等人通过Kalman滤波预测影像四个角点的运行轨迹，进而计算相邻帧影像之间的重叠度。当拼接的范围增大时，随着误差累积等因素的影响，精确的影像角点位置很难获得，因此影响了Kalman滤波预测的准确性，进而影响关键帧的提取精度。刘善磊 [<xref ref-type="bibr" rid="hanspub.26532-ref16">16</xref>] 等人根据摄像机的内部参数、飞行平台的速度、地面像对高等先验知识计算相邻帧之间的理论重叠度，进而按照固定的帧间隔提取关键帧。然而，当这些先验知识无法获取或者地形条件发生改变时，该方法无法获取满足重叠度要求的关键帧。</p><p>为了解决上述问题和提高关键帧的提取效率，本文提出了一种自适应关键帧的提取方法，该方法分为两个阶段，一是：统计阶段，二是：提取阶段。在统计阶段通过给定的基准帧和重叠度(根据摄影测量的一般要求，本文设定70%至90%)逐帧计算当前帧与基准帧的重叠度。若重叠度满足要求则记录当前帧与基准帧的帧差，循环上述过程，若重叠度小于设定的下限则停止计算。最后取所有帧差的均值为固定帧差间隔k，至此，统计阶段完成。在提取阶段主要是通过固定帧间隔k提取关键帧。若当前帧与参考帧的重叠度满足给定的阈值范围，则将当前帧记录为关键帧。在重叠度无法满足要求时，若当前帧与参考帧的重叠度大于阈值范围上限(90%)，则以当前帧为基准向前逐帧搜索，并且计算当前帧与参考帧的重叠度，直至重叠度满足要求，将当前帧记录为关键帧。若当前帧与参考帧的重叠度小于给定的阈值下限(70%)，则以当前帧为基准向后逐帧搜索并且计算当前帧与参考帧的重叠度，直至重叠度满足要求，将当前帧记录为关键帧，重复上述过程，直至所有的关键帧提取完成。在提取关键帧的同时，还对提取的关键帧进行了正射校正，为后续的图像快速拼接提供原始的数据。关键帧提取算法流程图如图1所示。</p><p>本文将重叠度定义为两幅图像重叠区域的面积与第一幅图像面积的比值。首先通过共线方程解算出两幅图像在地面的覆盖范围，并计算这个覆盖范围的外包矩形。然后对这个外包矩形进行离散化处理，如图2，在x方向和y方向采用一定的固定间隔(建议使用像素的地面分辨率)生成离散化格网点。统计既在第一幅图像覆盖范围内又在第二幅图像范围内的点数目N和仅在第一幅图像覆盖范围内的点数目M，N/M即为两幅图像之间的重叠度。</p></sec><sec id="s4_2"><title>2.2. 影像正射校正</title><p>传感器物理模型根据相机所在的位置、相机的姿态、地面的高程，使用共线方程计算每个像素在地面点的坐标，采用一定的插值方法，即可获得地面正射图像。这种不需要控制点的传感器物理模型非常适合本文所采集图像的正射几何校正。</p><p>目前实现航拍图像几何校正的方法主要包括正解法和反解法。其中正解法从原始的图像出发，根据正解公式逐个计算所有像素纠正后的坐标，然后使用一定的插值方法即可完成航拍图像的正射校正。反解法思路与正解法刚好相反，其从纠正后的正射图像出发，以一定的分辨率划分格网，计算每个格网在</p><p>图1. 关键帧的提取算法流程图</p><p>图2. 重叠度的计算</p><p>原始图像中的坐标，并将这个坐标处的像素值赋予正射格网点。当某个格网点在原始图像中的坐标不为整数时，则需要进行一定的插值处理，这是目前较为常用的方法。然而，本文所采用的飞行载体为飞艇，其飞行姿态的倾角变化很大，很难直接确定一幅航拍图像在地面的覆盖范围。针对这种情况，本文采用正解和反解相结合的方法。假设飞行高度足够大，单幅图像覆盖的范围内地面起伏有限，可近似将该区域看作一个平面。假设存在一幅图像，如图3(a)，图像四个角点分别为a、b、c和d，其在像空间坐标系中的坐标分别为 ( x a , y a , − f ) ， ( x b , y b , − f ) ， ( x c , y c , − f ) 和 ( x d , y d , − f ) ，使用共线方程可计算其在四个角点在物方坐标系中的坐标 ( X A , Y A ) 、 ( X B , Y B ) 、 ( X C , Y C ) 和 ( X D , Y D ) ，如图3(b)中虚线梯形的四个角点。由于图像只能以矩形的形式存储，还需要根据这些坐标在X方向和Y方向的最大值和最小值确定正射图像在物方坐标系中的范围，如图3虚线梯形的外侧的实线矩形。</p><p>确定正射图像范围后，还需要估算正射图像的分辨率，航高为 Z s − Z A ，相机在X方向的视场角为 α ，在X方向上的像素个数为M，那么图像的分辨率为D，其表达式如式(1)。根据分辨率即可划分正射图像的分辨率网格，如图4。O点位置为外接矩形的左下角位置，假设校正后的图像中存在一个像素位置P，其像素坐标为 ( m , n ) ，那么这个像素位置对应的实际位置在本地摄影测量坐标系中的位置为 ( X P , Y P ) ，其计算方程如式(2)所示。根据每个像素在物方坐标系的位置使用共线方程可求得其在像方空间坐标系中的位置；由于该位置的坐标一般不是整数，可以使用一定的插值方法计算该位置的灰值，然后将该位置的像素的灰度值赋予正射图像中的像素，即可完成正射校正。</p><p>D = 2 ( Z S − Z A ) sin α 2 M (1)</p><p>{ X P = m i n ( X A + X B + X C + X D ) + m D Y P = m i n ( Y A + Y B + Y C + Y D ) + n D (2)</p></sec><sec id="s4_3"><title>2.3. 正视频影像的快速拼接算法原理</title><p>图像拼接当前广泛使用的方法是基于特征匹配的图像配准方法，目前常用的图像特征描述方法有Moravec特征点检测方法 [<xref ref-type="bibr" rid="hanspub.26532-ref17">17</xref>] 、Susan特征点检测方法 [<xref ref-type="bibr" rid="hanspub.26532-ref18">18</xref>] 、Harris特征点检测方法 [<xref ref-type="bibr" rid="hanspub.26532-ref19">19</xref>] 、SIFT特征点检测方法 [<xref ref-type="bibr" rid="hanspub.26532-ref20">20</xref>] 等。由于SIFT特征具有尺度不变性，旋转不变性，对于光线、噪声、微视角改变具有鲁棒性，因此广泛地应用于图像拼接中 [<xref ref-type="bibr" rid="hanspub.26532-ref21">21</xref>] [<xref ref-type="bibr" rid="hanspub.26532-ref22">22</xref>] 。但是基于图像内部特征点的方法需要在特征点检测，粗匹配，误匹配剔除，全局的平差等方面耗费大量的计算时间，使得其无法满足应急响应和现场数据质量检查等方面的需求。另一方面，基于图像特征的拼接方法与图像内部特征的丰富程度有很大的关系，在图像特征比较丰富的区域(比如城市区域)，以特征点匹配为基础的方法能够取得很好的匹配效果。而在特征比较弱的区域(植被区域或沙漠区域等)，这种方法几乎无法得到正确的匹配结果。</p><p>图3. 图像正射校正</p><p>图4. 分辨率格网划分</p><p>为了解决上述问题，本文提出了针对航空视频影像的横向流型快速拼接方法。该方法使用惯性测量单元(IMU)实时提供的姿态角数据将视频流中的关键帧影像校正成正射图像。经正射校正后，可近似认为任何两幅关键帧影像之间只存在平移变换关系，然后选择一幅图像作为基准帧图像，计算所有关键帧影像与其之间的旋转关系由于每幅图像均有其独自的覆盖区域，当两幅图像之间的间距过大时，两幅图像可能不包含公共区域，因此二者之间的平移关系无法直接计算。本文提供了一种间接的方法计算二者之间的平移关系。假定M<sub>i</sub><sub>,j</sub>表示影像I<sub>i</sub>和影像I<sub>j</sub>之间的平移关系。M<sub>i</sub><sub>,j</sub>可表示为式(3)，x<sub>i</sub><sub>,j</sub>和y<sub>i</sub><sub>,j</sub>分别表示影像I<sub>i</sub>和影像I<sub>j</sub>之间在行方向和列方向之间的平移关系。</p><p>M i , j = [ 1 0 x i , j 0 1 y i , j 0 0 1 ] (3)</p><p>如果我们需要将影像I<sub>i</sub>投影到影像I<sub>j</sub>，可以先使用I<sub>i</sub>将影像投影到I<sub>k</sub>，然后再使用M<sub>k</sub><sub>,j</sub>将结果投影到I<sub>j</sub>。矩阵M<sub>i</sub><sub>,j</sub>可表达为式(4)。使用这种方法所有的正射影像 I 1 , I 2 , ⋯ , I N 均可计算其与参考图像之间的转换矩阵。如果第一幅正射影像为参考图像，P<sub>j</sub><sub>,1</sub>为图像I<sub>j</sub>和图像I<sub>1</sub>之间的投影矩阵，P<sub>j</sub><sub>,1</sub>可表示为式(5)。</p><p>M i , j = M i , k M k , j (4)</p><p>P j , 1 = ∏ i = 2 j M i , i - 1 (5)</p><p>假定所有正射图像的尺寸均为m &#215; n，每幅图像参与拼接的起始行行号为H。则影像I<sub>j</sub>中需要参与拼接的条带的宽度为 x i , i − 1 。假设拼接后的影像为Z，Z图像中实际数据的起始位置为 [ r , c ] 。在拼接过程中只需要把影像I<sub>j</sub>中第H行和 H + x i , i − 1 行之间的条带直接写入到Z中第 r + P j - 1 , 1 ( 1 , 3 ) 行与 r + P j , 1 ( 1 , 3 ) 行之间，第 c + P j - 1 , 1 ( 2 , 3 ) 列与 c + P j , 1 ( 2 , 3 ) 列之间的区域即可完成图像的拼接。选择一幅图像作为基准帧图像，根据相邻两幅关键帧图像之间的平移关系，计算每幅图像与基准帧图像之间的平移关系估算拼接后全局图像的尺寸。根据相邻两幅之间的平移参数，计算出待拼接图像中需要参与拼接的区域，如图5(a)，并将这些条带裁出，并计算每个条带在整体图像中的位置，并将这些条带写入到相应区域，完成拼接，如图5(b)。与传统方法相比，这种方法不需要实时GPS位置数据和地面高程数据，不需要检测与图像内容相关的特征点或角点，稳定性更高，普适性更强。这种方法具有更快的处理速度，几乎可以实现实时处理，满足现场勘验飞行参数正确与否，检测数据遗漏与否，以及快速应急响应的需求。这种拼接方法只使用了经过校正后的正射图像中很窄的条带，舍去了造成鬼影的冗余部分，因此拼接效果好，无鬼影，拼接后的影像数据可以用于深度分析。快速拼接的算法流程如图6所示。</p><p>图5. 图像拼接</p><p>图6. 快速拼接算法流程图</p></sec></sec><sec id="s5"><title>3. 实验与分析</title><sec id="s5_1"><title>3.1. 关键帧提取</title><p>本文实验使用的数据是由课题组研发的蓝天一号(ASQ-HAA380)所采集的青海省海北藏族自治州的影像数据。由于飞艇在飞行过程中受气流的影响，造成航拍影像存在不规则的重叠区域。如果按照固定帧差提取关键帧影像则不能很好的满足相邻关键帧影像对之间的重叠度要求，从而影响了图像拼接的质量。按照固定帧差提取关键帧影像也不能适应测区内地表变化较大的情况。而本文提出的计算重叠度的方法可以快速有效的计算出两幅图像的重叠度，结合自适应关键帧的提取方法可以快速有效的提取关键帧影像。实验结果表明本文提出的自适应关键帧提取方法有效稳定，并且能适应测区内地表变换较大的情况，全面优于利用固定帧间隔的提取结果，获得重叠度分布均衡的提取结果，为后续的图像处理打下了坚实的基础。以第一测区为例，用本文方法提取的关键帧影像总数为99，该测区共有4566帧影像，关键帧提取的比例为2.1682%。以固定帧差间隔提取的关键帧影像的数目为96。表1为自适应关键帧提取方法和固定帧差间隔提取法的重叠度统计结果对比。如图7(a)所示，按照固定帧差间隔提取关键帧拼接成的影像存在局部明显错位的情况，而本文方法能够获得较好的拼接结果，如图7(b)所示。</p></sec><sec id="s5_2"><title>3.2. 图像正射校正</title><p>先通过共线方程求解出图像所覆盖的范围，然后在区域内生成网格点，最后通过共线方程反求网格点在图像中的坐标，然后插值获得这些点的灰度值，完成图像的正射校正。正射校正的步骤如下：</p><p>1) 从图像坐标系到像平面坐标系的转换。首先获取图像的大小，记图像的宽为m，高为n，生成两个列向量，然后根据得到的两个列向量离散化生成图像坐标系。将生成的坐标系的每个点的横坐标减去m/2，纵坐标减去n/2，这样就将坐标原点移到了坐标网的中心，完成了图像坐标系到像平面坐标系的转换。</p><p>2) 通过共线方程解求图像覆盖的地面范围。根据摄影测量知识使用共线方程将第一步中得到的像平面坐标系下的各点计算得到其在地面摄影测量坐标系下的坐标。</p><p>3) 根据图像覆盖的地面范围，生成离散化地面坐标网格点。根据第二步可以得到该图像在地面的覆盖范围，从而得到其在横坐标方向的覆盖范围和在纵坐标方向的覆盖范围。根据实际情况定义地面坐标网格的间距，据此生成离散化的各网格点在地面摄影测量坐标系下的坐标。</p><p>4) 通过共线方程反求地面离散化坐标网格点在像平面坐标系下的坐标，完成图像的正射校正。根据第三步生成各点的坐标通过共线方程反求各点在像平面坐标系下的坐标，然后插值得到这些点的灰度值，完成图像的正射校正。</p><p>选择两幅图像，第一幅图像，为飞艇飞过牧场时采集的图像，除了一条道路之外，内部几乎不包含任何人工地物；图像为飞艇在城市区域采集的图像，内部包含大量的人工地物。使用前文提到的方法，将图像转化为正射图像(图8)。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Comparison of adaptive key frame extraction method and fixed frame interval extraction metho</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >方法</th><th align="center" valign="middle" >最大值</th><th align="center" valign="middle" >最小值</th><th align="center" valign="middle" >平均值</th><th align="center" valign="middle" >方差</th></tr></thead><tr><td align="center" valign="middle" >自适应关键帧提取</td><td align="center" valign="middle" >0.8999</td><td align="center" valign="middle" >0.7</td><td align="center" valign="middle" >0.77777</td><td align="center" valign="middle" >0.06256</td></tr><tr><td align="center" valign="middle" >固定帧差</td><td align="center" valign="middle" >0.9436</td><td align="center" valign="middle" >0.4586</td><td align="center" valign="middle" >0.751751</td><td align="center" valign="middle" >0.90657</td></tr></tbody></table></table-wrap><p>表1. 自适应关键帧提取方法和固定帧间隔提取法重叠度统计结果的对比</p><p>图7. 图像拼接结果对比</p><p>图8. 正射校正前的影像和正射校正后的影像</p></sec><sec id="s5_3"><title>3.3. 图像的快速实时拼接</title><p>为进一步评估本文方法拼接航带图像的性能，使用提取的关键帧影像拼接成全测区的影像。本文的实验环境为MATLAB 2012B实验的机器配置如表2所示。</p><p>由于SIFT特征具有尺度不变性，旋转不变性，对于光线、噪声具有鲁棒性，因此广泛的应用于图像拼接中。但是SIFT特征匹配的计算量大，错误率高，从而很大程度上影响图像拼接的速度。采用本文提出的自适应关键帧提取方法通过坐标解算得到相邻关键帧的数学模型，从而很大程度上的提高了图像的拼接速度，实现了图像的快速拼接。为说明本文方法的有效性，本文采用了一定的方法对图像拼接的结果做了精度评价，具体方法见下一节。表3为标准SIFT方法和本文方法在相邻两幅关键帧影像拼接时的结果对比。从表3可以得出，标准SIFT方法与本文方法在图像配准精度方面几乎不存在差异，但是本文方法用时仅为标准SIFT方法的十分之一。</p><p>表4为使用Agisoft Photo Scan商业软件及SIFT特征匹配方法和本文方法拼接测区内人工地物较多自然地物较少的比较好匹配区域的结果对比。实验结果表明三种方法都能获得很好的图像拼接结果，几乎很难用肉眼发现它们之间的差别。但本文方法用时为SIFT特征匹配方法的十分之一，Agisoft Photo Scan商业软件的二十分之一。本文方法几乎可以实现图像的快速实时拼接，很大程度上提高了图像拼接的效率。图像拼接的结果如图9，图9(a)为第一测区拼接结果，图9(b)为第二测区拼接结果。</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> Properties of the compute</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" >配置</th></tr></thead><tr><td align="center" valign="middle" >操作系统</td><td align="center" valign="middle" >Windows 8.1</td></tr><tr><td align="center" valign="middle" >CPU</td><td align="center" valign="middle" >Core i7-4720HQ</td></tr><tr><td align="center" valign="middle" >内存</td><td align="center" valign="middle" >8 GB</td></tr><tr><td align="center" valign="middle" >硬盘</td><td align="center" valign="middle" >三星SSD 850</td></tr></tbody></table></table-wrap><p>表2. 实验的机器配置</p><table-wrap id="table3" ><label><xref ref-type="table" rid="table3">Table 3</xref></label><caption><title> Comparison of the results of two key frame image stitchin</title></caption><table><tbody><thead><tr><th align="center" valign="middle"  colspan="5"  >标准SIFT方法</th><th align="center" valign="middle"  colspan="4"  >本文方法</th></tr></thead><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >Rx</td><td align="center" valign="middle" >Ry</td><td align="center" valign="middle" >Rt</td><td align="center" valign="middle" >time</td><td align="center" valign="middle" >Rx</td><td align="center" valign="middle" >Ry</td><td align="center" valign="middle" >Rt</td><td align="center" valign="middle" >time</td></tr><tr><td align="center" valign="middle" >Data 1</td><td align="center" valign="middle" >0.825</td><td align="center" valign="middle" >1.125</td><td align="center" valign="middle" >1.395</td><td align="center" valign="middle" >18.26</td><td align="center" valign="middle" >0.771</td><td align="center" valign="middle" >1.031</td><td align="center" valign="middle" >1.253</td><td align="center" valign="middle" >1.74</td></tr><tr><td align="center" valign="middle" >Data 2</td><td align="center" valign="middle" >0.239</td><td align="center" valign="middle" >0.425</td><td align="center" valign="middle" >0.486</td><td align="center" valign="middle" >16.73</td><td align="center" valign="middle" >0.267</td><td align="center" valign="middle" >0.585</td><td align="center" valign="middle" >0.643</td><td align="center" valign="middle" >1.73</td></tr><tr><td align="center" valign="middle" >Data 3</td><td align="center" valign="middle" >0.847</td><td align="center" valign="middle" >1.296</td><td align="center" valign="middle" >1.589</td><td align="center" valign="middle" >17.64</td><td align="center" valign="middle" >0.640</td><td align="center" valign="middle" >0.994</td><td align="center" valign="middle" >1.153</td><td align="center" valign="middle" >1.76</td></tr><tr><td align="center" valign="middle" >Data 4</td><td align="center" valign="middle" >1.652</td><td align="center" valign="middle" >1.254</td><td align="center" valign="middle" >2.031</td><td align="center" valign="middle" >19.32</td><td align="center" valign="middle" >1.541</td><td align="center" valign="middle" >1.092</td><td align="center" valign="middle" >1.972</td><td align="center" valign="middle" >1.82</td></tr><tr><td align="center" valign="middle" >Data 5</td><td align="center" valign="middle" >1.328</td><td align="center" valign="middle" >0.965</td><td align="center" valign="middle" >2.352</td><td align="center" valign="middle" >18.78</td><td align="center" valign="middle" >1.789</td><td align="center" valign="middle" >0.747</td><td align="center" valign="middle" >1.938</td><td align="center" valign="middle" >1.76</td></tr></tbody></table></table-wrap><p>表3. 两幅关键帧影像拼接时的结果对比</p><p>注：Rx为X方向的中误差，Ry为Y方向中误差，Rt为总中误差(单位像素)，time为消耗的时间(单位秒)。</p><table-wrap id="table4" ><label><xref ref-type="table" rid="table4">Table 4</xref></label><caption><title> Comparison of results of image stitchin</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >方法</th><th align="center" valign="middle" >第一测区用时</th><th align="center" valign="middle" >第二测区用时</th></tr></thead><tr><td align="center" valign="middle" >Agisoft PhotoScan</td><td align="center" valign="middle" >841.56秒</td><td align="center" valign="middle" >946.68秒</td></tr><tr><td align="center" valign="middle" >SIFT特征匹配方法</td><td align="center" valign="middle" >417.67秒</td><td align="center" valign="middle" >520.36秒</td></tr><tr><td align="center" valign="middle" >本文方法</td><td align="center" valign="middle" >39.51秒</td><td align="center" valign="middle" >48.31秒</td></tr></tbody></table></table-wrap><p>表4. 图像拼接实验结果对比</p><p>为对比本文方法和Agisoft Photo Scan软件在人工地物较少自然地物较多的难匹配区域的配准情况，以第二测区内飞艇飞过牧场时采集的图像为例，如图10(a)所示Agisoft Photo Scan软件不能得到正确的结果，如图10(b)所示，本文方法依然能获得正确的拼接结果。</p></sec><sec id="s5_4"><title>3.4. 图像拼接的精度评价</title><p>为了证明本文方法的可靠性，采用了一定的方法对图像的拼接结果做了精度评价。首先使用SIFT算法检测出一对关键帧影像对的特征点，并使用RANSCA算法 [<xref ref-type="bibr" rid="hanspub.26532-ref23">23</xref>] 剔除误匹配的特征点对，然后将所有特征点对欧氏距离平方的均值定义为该影像对的误差R<sup>2</sup>作为该影像对的精度评价标准。如式(6)所示，其中n为特征点对的总数， ( x a , y a ) 为该特征点在第一幅图像中的坐标， ( x b , y b ) 为该特征点在第二幅图像中的坐标。</p><p>R 2 = ∑ i = 1 n ( x a - delta x i - x b ) 2 + ( y a − delta y i − y b ) 2 n (6)</p><p>循环上述过程，求得每个关键帧影像对的误差R<sup>2</sup>，然后取所有关键帧影像对的误差R<sup>2</sup>的均值N<sup>2</sup>为整幅图像拼接的精度评价标准。如式(7)所示，其中m为关键帧影像对的总数：</p><p>N 2 = ∑ i = 1 m R 2 m (7)</p><p>以测区一为例，表5为自适应关键帧方法和SIFT特征匹配方法拼接结果的精度对比。</p><p>图9. (a) 第一测区图像拼接结果；(b) 第二测区图像拼接结果</p><p>图10. 弱特征区域的图像拼接结果对比</p><table-wrap id="table5" ><label><xref ref-type="table" rid="table5">Table 5</xref></label><caption><title> Comparison of adaptive key frame extraction methods and SIFT feature matching method of image stitching accuracy. Unit (pixels</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >方法</th><th align="center" valign="middle" >X方向最大值</th><th align="center" valign="middle" >Y方向最大值</th><th align="center" valign="middle" >误差平均值</th></tr></thead><tr><td align="center" valign="middle" >自适应关键帧提取</td><td align="center" valign="middle" >4.9596</td><td align="center" valign="middle" >6.5356</td><td align="center" valign="middle" >6.7617</td></tr><tr><td align="center" valign="middle" >SIFT特征匹配</td><td align="center" valign="middle" >5.4403</td><td align="center" valign="middle" >5.9761</td><td align="center" valign="middle" >6.0685</td></tr></tbody></table></table-wrap><p>表5. 自适应关键帧提取方法和SIFT特征匹配方法的图像拼接精度对比。单位(像素)</p><p>从表5可以得出本文方法具有较高的拼接精度和目前较为流行的SIFT特征匹配方法相比在拼接精度上几乎不存在差异。</p></sec></sec><sec id="s6"><title>4. 结语</title><p>本文提出的自适应关键帧提取方法利用坐标解算在满足一定精度的要求下，可以很大程度上提高航拍影像拼接的效率。实验结果表明本文方法与目前较为流行的SIFT特征匹配方法相比，在拼接精度方面几乎相同，但是速度加快了10.57倍，相对于成熟的商业软件Agisoft Photo Scan速度加快了近20倍。由于SIFT特征匹配的计算量大，错误率高，从而很大程度上影响图像拼接的速度和精度。SIFT特征搜索速度和匹配的速度和图像的大小密切有关，时间复杂度为m &#215; n，其中m为图像的高，n为图像的宽，因此图像范围越大，本文方法加速比越大，优势越明显。在人工地物较少自然地物较多的弱特征区域(如植被区域) Agisoft Photo Scan软件不能完成航拍影像的拼接，而本文方法依然可以得到正确的结果。使用本文的方法可以实现航空影像的快速拼接，特别是在灾害应急保障与救援中有重要应用意义，能够提供灾区的第一手影像资料，为决策部门的决策提供重要依据，因此本文提出的方法有一定的应用意义。</p></sec><sec id="s7"><title>基金项目</title><p>本文资助项目为“十三五”装备预研共用技术：基于多谱信息的复杂环境分类技术(41412010301)。</p></sec><sec id="s8"><title>文章引用</title><p>李含伦,李丰凯. 低空视频影像自适应关键帧提取与快速拼接 Adaptive Key Frames Extraction and Fast Image Mosaic of Low Altitude Aerial Video[J]. 图像与信号处理, 2018, 07(04): 179-190. https://doi.org/10.12677/JISP.2018.74021</p></sec><sec id="s9"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.26532-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">崔红霞, 孙杰, 林宗坚. 无人机遥感设备的自动化控制系统[J]. 测绘科学, 2004, 29(1): 47-49.</mixed-citation></ref><ref id="hanspub.26532-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">张建. 无人机高清视频图像实时拼接算法研究[D]: [硕士学位论文]. 沈阳: 沈阳大学, 2014.</mixed-citation></ref><ref id="hanspub.26532-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">李长春, 齐修东, 雷添杰, 等. 基于改进SURF算法的无人机遥感影像快速拼接[J]. 地理与地理信息科学, 2013, 29(5): 22-25.</mixed-citation></ref><ref id="hanspub.26532-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">杨常清, 王孝通, 徐晓刚, 等. 基于特征空间的航空影像自动配准算法[J]. 测绘学报, 2005, 34(3): 218-222.</mixed-citation></ref><ref id="hanspub.26532-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">赵向阳, 杜利民. 一种全自动稳健的图像拼接融合算法[J]. 中国图象图形学报, 2004, 9(4): 417-422.</mixed-citation></ref><ref id="hanspub.26532-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">王勇, 何晓川, 刘清华, 等. 一种感兴趣区域寻优搜索的全自动图像拼接算法[J]. 电子与信息学报, 2009, 31(2): 261-264.</mixed-citation></ref><ref id="hanspub.26532-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Szeliski, R. (1996) Video Mosaics for Virtual Environments. IEEE Computer Graphics &amp; Applications, 16, 22-30.  
https://doi.org/10.1109/38.486677</mixed-citation></ref><ref id="hanspub.26532-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Kuglin, C.D. and Mines, D.C. (1975) The Phase Correlation Image Alignment Method. Proceedings of IEEE International Conference on Cybernetics and Society, New York, 9, 163-165.</mixed-citation></ref><ref id="hanspub.26532-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">刘金根, 吴志鹏, 刘上乾, 等.一种基于特征区域分割的图像拼接算法[J]. 西安电子科技大学学报: 自然科学版, 2002, 29(6): 768-771.</mixed-citation></ref><ref id="hanspub.26532-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">尚明姝, 解凯. 一种基于特征的全自动图像拼接算法[J]. 网络新媒体技术, 2006, 27(6): 747-750.</mixed-citation></ref><ref id="hanspub.26532-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">韩文超. 基于POS系统的无人机遥感图像拼接技术研究与实现[D]: [硕士学位论文]. 南京: 南京大学, 2011.</mixed-citation></ref><ref id="hanspub.26532-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">任超锋. 航空视频影像的正射影像制作关键技术研究[D]: [硕士学位论文]. 武汉: 武汉大学, 2014.</mixed-citation></ref><ref id="hanspub.26532-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Sun, J., Xie, J., Li, J., et al. (2012) A Key-Frame Selection Method for Semi-automatic 2D-to-3D Conversion. Communications in Computer &amp; Information Science, 331, 465-470. https://doi.org/10.1007/978-3-642-34595-1_63</mixed-citation></ref><ref id="hanspub.26532-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">Fadaeieslam, M.J., Fathy, M. and Soryani, M. (2009) Key Frames Selection into Panoramic Mosaics. Proceedings of the 7th International Conference on Information, Communications and Signal Processing, Macau, 8-10 December 2009, 1-5.</mixed-citation></ref><ref id="hanspub.26532-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">李岩山, 裴继红, 谢维信, 等. 一种新的无人机航拍序列图像快速拼接方法[J]. 电子学报, 2012, 40(5): 935-940.</mixed-citation></ref><ref id="hanspub.26532-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">刘善磊, 赵银娣, 王光辉, 等. 一种关键帧的自动提取方法[J]. 测绘科学, 2012, 37(5): 112-114, 117.</mixed-citation></ref><ref id="hanspub.26532-ref17"><label>17</label><mixed-citation publication-type="other" xlink:type="simple">彭晓东, 林宗坚. 无人飞艇低空航测系统[J]. 测绘科学, 2009, 34(4): 11-14.</mixed-citation></ref><ref id="hanspub.26532-ref18"><label>18</label><mixed-citation publication-type="other" xlink:type="simple">Hao, J., Yu, S.X. and Martin, D.R. (2011) Linear Scale and Rotation Invariant Matching. IEEE Transactions on Pattern Analysis &amp; Machine Intelligence, 33, 1339-1355. https://doi.org/10.1109/TPAMI.2010.212</mixed-citation></ref><ref id="hanspub.26532-ref19"><label>19</label><mixed-citation publication-type="other" xlink:type="simple">Wang, J., Peng, J., Wu, J., et al. (2013) Image Fusion with Double Sparse Representation in Wavelet Domain. 4th IEEE International Conference on Software Engineering and Service Science (ICSESS), Beijing, 23-25 May 2013, 1006-1009.</mixed-citation></ref><ref id="hanspub.26532-ref20"><label>20</label><mixed-citation publication-type="other" xlink:type="simple">曹楠, 王萍. 基于SIFT特征匹配的图像无缝拼接算法[J]. 计算机与应用化学, 2011, 28(2): 242-244.</mixed-citation></ref><ref id="hanspub.26532-ref21"><label>21</label><mixed-citation publication-type="other" xlink:type="simple">Lowe, D.G. (1999) Object Recognition from Local Scale-Invariant Features. Proceedings of the Seventh IEEE Interna-tional Conference on Computer Vision, Kerkyra, 20-27 September 1999, 1150-1157 vol.2.</mixed-citation></ref><ref id="hanspub.26532-ref22"><label>22</label><mixed-citation publication-type="other" xlink:type="simple">Lowe, D.G. (2004) Distinctive Image Features from Scale-Invariant Keypoints. International Journal of Computer Vision, 60, 91-110. https://doi.org/10.1023/B:VISI.0000029664.99615.94</mixed-citation></ref><ref id="hanspub.26532-ref23"><label>23</label><mixed-citation publication-type="other" xlink:type="simple">Fischler, M.A. and Bolles, R.C. (1987) Random Sample Consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography. Readings in Computer Vision: Issues, Problems, Principles, and Paradigms. Morgan Kaufmann Publishers Inc., 726-740.</mixed-citation></ref></ref-list></back></article>