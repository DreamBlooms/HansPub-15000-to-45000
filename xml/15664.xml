<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">JISP</journal-id><journal-title-group><journal-title>Journal of Image and Signal Processing</journal-title></journal-title-group><issn pub-type="epub">2325-6753</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/JISP.2015.43006</article-id><article-id pub-id-type="publisher-id">JISP-15664</article-id><article-categories><subj-group subj-group-type="heading"><subject>JISP20150300000_46280474.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  目标检测的红外和可见光图像融合
  Infrared and Visible Light Images Fusion Utilizing Object Detection
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>李</surname><given-names>婵飞</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>胡</surname><given-names>锦龙</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>韩</surname><given-names>彦净</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff3"><addr-line>中科院光电技术研究所，四川 成都</addr-line></aff><aff id="aff2"><addr-line>重庆邮电大学移通学院，重庆</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>02</day><month>07</month><year>2015</year></pub-date><volume>04</volume><issue>03</issue><fpage>47</fpage><lpage>52</lpage><history><date date-type="received"><day>Jun.</day>	<month>26th,</month>	<year>2014</year></date><date date-type="rev-recd"><day>Jul.</day>	<month>4th,</month>	<year>2014</year>	</date><date date-type="accepted"><day>Aug.</day>	<month>1st,</month>	<year>2014</year></date></history><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   针对红外图像和可见光图像融合，提出了一种基于目标检测的图像融合方法。该方法运用目标检测技术将红外图像分割为目标和背景区域，同时运用非下采样轮廓波变换将红外背景区域和可见光图像融合得到融合背景图像，然后将融合背景图像和红外目标区域融合得到最终融合图像。实验结果表明，该方法具有可行性和高效性，且比其他图像融合方法具有更好的性能。&lt;br/&gt;A new image fusion method for infrared and visible light image based on object detection technique is proposed in this paper. The object detection is utilized to separate infrared image into object and background region. And NSCT is applied to fuse the background and visible light image. The final fused image is obtained by fusing the background fused image and infrared object image. Fusion experiments indicate that the proposed method is efficient and effective. Besides, it achieves better performance than the conventional fusion methods.
    
  
 
</p></abstract><kwd-group><kwd>图像处理，图像融合，目标检测，非下采样轮廓波变换, Image Processing</kwd><kwd> Image Fusion</kwd><kwd> Object Detection</kwd><kwd> Nonsubsampled Contourlet Transform (NSCT)</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>目标检测的红外和可见光图像融合<sup> </sup></title><p>李婵飞<sup>1</sup>，胡锦龙<sup>2</sup>，韩彦净<sup>1</sup></p><p><sup>1</sup>重庆邮电大学移通学院，重庆</p><p><sup>2</sup>中科院光电技术研究所，四川 成都</p><p>Email: 454329847@qq.com</p><p>收稿日期：2015年6月26日；录用日期：2015年7月9日；发布日期：2015年7月14日</p><disp-formula id="hanspub.15664-formula2756"><graphic xlink:href="http://html.hanspub.org/file/3-2670046x5_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>针对红外图像和可见光图像融合，提出了一种基于目标检测的图像融合方法。该方法运用目标检测技术将红外图像分割为目标和背景区域，同时运用非下采样轮廓波变换将红外背景区域和可见光图像融合得到融合背景图像，然后将融合背景图像和红外目标区域融合得到最终融合图像。实验结果表明，该方法具有可行性和高效性，且比其他图像融合方法具有更好的性能。</p><p>关键词 :图像处理，图像融合，目标检测，非下采样轮廓波变换</p><disp-formula id="hanspub.15664-formula2757"><graphic xlink:href="http://html.hanspub.org/file/3-2670046x6_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s3"><title>1. 引言</title><p>图像融合不是简单的数据叠加，而是对多个图像传感器获得的互补或冗余信息进行集合的过程。它使得新图像满足图像处理中的特征提取、目标识别或分割的需要。因此，图像融合技术被广泛应用于计算机视觉、军事、遥感和医学等领域。</p><p>红外图像和可见光图像分别是通过红外成像传感器与可见光成像传感器获得的。由于两种传感器工作原理不同, 性能也就不同。红外图像能较好地反应图像的热目标特性，但对场景亮度变化特征不敏感, 且图像清晰度较低；可见光图像能够较好地反应目标所在的场景细节信息，且清晰度较高。红外和可见光图像融合能有效地综合红外图像目标特征信息和可见光图像的场景细节信息，得到信息更全面的融合图像 [<xref ref-type="bibr" rid="hanspub.15664-ref1">1</xref>] 。</p><p>拉普拉斯金字塔 [<xref ref-type="bibr" rid="hanspub.15664-ref2">2</xref>] (LP)和小波变换 [<xref ref-type="bibr" rid="hanspub.15664-ref3">3</xref>] [<xref ref-type="bibr" rid="hanspub.15664-ref4">4</xref>] (DWT)是较常用的多分辨率图像融合工具。但是，它们都缺乏平移不变性，且方向分析能力有限，不能全面地表示图像信息。非下采样轮廓波变换 [<xref ref-type="bibr" rid="hanspub.15664-ref5">5</xref>] (NSCT)变换是一种多尺度、多方向、平移不变的多分辨率工具，利用该工具进行图像融合能有效提取源图像的方向细节信息，得到融合效果较好的图像。</p><p>现阶段的红外和可见光图像融合技术大部分都是对图像融合准则进行研究，该类融合方法不能很好地保留可见光图像背景细节信息，突出红外目标人物信息 [<xref ref-type="bibr" rid="hanspub.15664-ref6">6</xref>] [<xref ref-type="bibr" rid="hanspub.15664-ref7">7</xref>] 。为此，本文引进了目标检测技术。在图像融合前利用目标检测技术将红外图像分割为背景和目标图像；然后利用NSCT变换将红外背景和可见光图像进行融合得到融合背景图像；再将该融合背景图像和红外目标图像融合得到最后的融合图像。</p></sec><sec id="s4"><title>2. 目标检测</title><p>图像的目标区域里包含重要目标信息，且目标信息应尽可能地保留，目标检测的目地就是分割出源图像的目标和背景区域。在红外图像中，热目标人物特征比较清晰，且目标区域灰度均值要远高于背景区域灰度均值，因此可利用这一特征将红外图像中的目标人物检测出来。本文运用一种结合灰度直方图熵法 [<xref ref-type="bibr" rid="hanspub.15664-ref8">8</xref>] 和Sobel [<xref ref-type="bibr" rid="hanspub.15664-ref9">9</xref>] 边缘检测的红外图像目标检测方法，该方法可以较准确地检测出红外目标图像。</p><p>首先，运用一维灰度直方图熵法得到红外图像分割目标的阈值；再运用Sobel边缘检测得到红外图像可能的目标图像边缘，计算得到边缘内部区域均值；最后，比较均值和阈值的大小。如果均值 &gt; 阈值，对应区域是目标区域；否则就是背景区域。经过这些步骤检测出红外图像的目标区域，进而得到背景区域。</p></sec><sec id="s5"><title>3. NSCT变换</title><p>非下采样轮廓波变换(Nonsubsampled Contourlet Transform，NSCT)是一种重要的多尺度几何分析工具。它具备平移不变性，有很好的方向性，能更好地表达图像的边缘方向信息。</p><p>NSCT变换首先运用非下采样塔式滤波器组NSP对图像进行多尺度分解，再运用非下采样方向滤波器组NSDFB对第一步得到的各带通子带图像进行分解，得到图像不同尺度、方向上的子带系数。</p><p>NSCT的多尺度特性是通过平移不变的滤波器结构获得的，它利用一个双通道二维非下采样滤波器组完成类似于拉普拉斯金字塔的分解。图像经过一级NSP分解得到一个与源图像大小相同的低频子带和高频子带图像，经过<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670046x7_hanspub.png" xlink:type="simple"/></inline-formula>级分解得到<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670046x8_hanspub.png" xlink:type="simple"/></inline-formula>个不同尺度下的高频子带图像和1个低频子带图像。对某一尺度下的子带图像运用NSDFB进行<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670046x9_hanspub.png" xlink:type="simple"/></inline-formula>级分解，就能得到与原图像大小相同的<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670046x10_hanspub.png" xlink:type="simple"/></inline-formula>个不同方向的子带图像，如图1所示。</p></sec><sec id="s6"><title>4. 融合准则</title><p>图像融合规则是多分辨率图像融合的核心，它的优劣对融合图像质量的好坏起着重要作用。融合准则主要包括低频和高频子带融合准则。</p><p>图像的低频子带主要包含源图像的近似特性，占据图像的主要能量。在本文融合方法中，低频采用高斯模糊逻辑[<xref ref-type="bibr" rid="hanspub.15664-ref10">10</xref>] 权值融合准则。该融合准则可以较好的保持红外图像的目标信息和可见光图像的背景细节信息，融合准则如下：</p><disp-formula id="hanspub.15664-formula2758"><label>(1)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/3-2670046x11_hanspub.png"  xlink:type="simple"/></disp-formula><disp-formula id="hanspub.15664-formula2759"><label>(2)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/3-2670046x12_hanspub.png"  xlink:type="simple"/></disp-formula><disp-formula id="hanspub.15664-formula2760"><label>(3)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/3-2670046x13_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670046x14_hanspub.png" xlink:type="simple"/></inline-formula>表示融合图像低频系数，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670046x15_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670046x16_hanspub.png" xlink:type="simple"/></inline-formula>分别表示红外和可见光图像的低频系数，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670046x17_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670046x18_hanspub.png" xlink:type="simple"/></inline-formula>分别表示红外和可见光图像的低频权值系数。</p><p>本文融合方法中，高频子带采用绝对值取大法的融合准则，该融合准则既能够得到边缘细节较丰富、清晰度较高的融合图像，又可以提高融合速度。</p></sec><sec id="s7"><title>5. 基于目标检测的红外和可见光图像融合</title><p>本文提出一种基于目标检测的红外和可见光图像融合方法，具体步骤如下：</p><p>图1. NSCT分解示意图</p><p>1) 运用节1一维灰度直方图熵和Sobel边缘检测相结合的目标检测方法将红外图像分割为目标与背景区域；</p><p>2) 运用节2的NSCT变换将红外背景和可见光图像分别分解为低频子带和高频子带；</p><p>3) 运用节3的高斯模糊逻辑融合准则将红外背景区域低频子带和可见光图像低频子带进行融合得到融合背景图像低频子带；运用节3的绝对值取大融合准则将红外背景区域高频子带和可见光图像高频子带进行融合得到融合背景图像高频子带；</p><p>4) 运用NSCT逆变换将融合背景图像低频和高频子带融合得到融合背景图像；</p><p>5) 运用加权融合准则将红外目标和融合背景融合图像融合得到最终融合图像。具体准则如下：</p><disp-formula id="hanspub.15664-formula2761"><label>(4)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/3-2670046x20_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670046x21_hanspub.png" xlink:type="simple"/></inline-formula>表示融合图像，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670046x22_hanspub.png" xlink:type="simple"/></inline-formula>表示红外目标图像，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670046x23_hanspub.png" xlink:type="simple"/></inline-formula>表示背景融合图像，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670046x24_hanspub.png" xlink:type="simple"/></inline-formula>表示权重系数，且<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670046x25_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2670046x26_hanspub.png" xlink:type="simple"/></inline-formula>。</p></sec><sec id="s8"><title>6. 实验结果与分析</title><p>为了验证所提出方法的有效性，选择两组典型的红外和可见光图像进行实验。融合方法分别为基于Laplacian塔变换的图像融合方法(LPT)，基于小波变换的图像融合方法(DWT)，基于NSCT变换的图像融合方法(NSCT)与本文提出的方法。它们的分解层数均为4层，高频融合准则均为绝对值取大法。LPT、DWT和NSCT1低频融合准则为均值法；NSCT2低频融合准则为高斯模糊逻辑权值法(NSCT2)。融合结果如图2和图3所示。</p><p>从图2和图3可知，本文融合方法得到的融合图像对比度最高，目标人物最清晰，且能较好地反映道路、栏杆等细节信息，便于人眼观察。</p><p>然而，主观评价极易受人的视觉特性、心理状态等因素影响，为了更客观科学地对实验结果进行评价分析，特采用标准差，信息熵，互信息[<xref ref-type="bibr" rid="hanspub.15664-ref11">11</xref>] [<xref ref-type="bibr" rid="hanspub.15664-ref12">12</xref>] 三项指标进行分析，结果如表1和表2所示。</p><p>从表1和表2可知，本文融合算法融合图像的标准差、信息熵、互信息都要高于其它融合方法，说明本文融合方法获得到的融合图像清晰度最高，且能很好地保留源图像的有用信息。</p><p>综合可知，本文融合算法的融合效果优于其它方法。</p><p>图2. 实验1</p><p>图3. 实验2</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> The objective evaluation for simulation </title></caption><table><tbody><thead><tr><th align="center" valign="middle" >融合方法</th><th align="center" valign="middle" >标准差</th><th align="center" valign="middle" >信息熵</th><th align="center" valign="middle" >互信息</th></tr></thead><tr><td align="center" valign="middle" >LPT</td><td align="center" valign="middle" >27.1194</td><td align="center" valign="middle" >6.5760</td><td align="center" valign="middle" >1.3763</td></tr><tr><td align="center" valign="middle" >DWT</td><td align="center" valign="middle" >27.5566</td><td align="center" valign="middle" >6.5931</td><td align="center" valign="middle" >1.3838</td></tr><tr><td align="center" valign="middle" >NSCT1</td><td align="center" valign="middle" >26.7258</td><td align="center" valign="middle" >6.5376</td><td align="center" valign="middle" >1.4501</td></tr><tr><td align="center" valign="middle" >NSCT2</td><td align="center" valign="middle" >37.2609</td><td align="center" valign="middle" >7.0800</td><td align="center" valign="middle" >2.0285</td></tr><tr><td align="center" valign="middle" >本文方法</td><td align="center" valign="middle" >37.6422</td><td align="center" valign="middle" >7.1082</td><td align="center" valign="middle" >2.0434</td></tr></tbody></table></table-wrap><p>表1. 实验1客观评价指标表</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> The objective evaluation for simulation </title></caption><table><tbody><thead><tr><th align="center" valign="middle" >融合方法</th><th align="center" valign="middle" >标准差</th><th align="center" valign="middle" >信息熵</th><th align="center" valign="middle" >互信息</th></tr></thead><tr><td align="center" valign="middle" >LPT</td><td align="center" valign="middle" >28.1624</td><td align="center" valign="middle" >6.6266</td><td align="center" valign="middle" >1.4045</td></tr><tr><td align="center" valign="middle" >DWT</td><td align="center" valign="middle" >28.3135</td><td align="center" valign="middle" >6.6247</td><td align="center" valign="middle" >1.3935</td></tr><tr><td align="center" valign="middle" >NSCT1</td><td align="center" valign="middle" >27.5884</td><td align="center" valign="middle" >6.5782</td><td align="center" valign="middle" >1.4651</td></tr><tr><td align="center" valign="middle" >NSCT2</td><td align="center" valign="middle" >37.5797</td><td align="center" valign="middle" >7.0903</td><td align="center" valign="middle" >2.0140</td></tr><tr><td align="center" valign="middle" >本文方法</td><td align="center" valign="middle" >37.8319</td><td align="center" valign="middle" >7.1055</td><td align="center" valign="middle" >2.0225</td></tr></tbody></table></table-wrap><p>表2. 实验2客观评价指标表</p></sec><sec id="s9"><title>7. 结论</title><p>本文提出一种基于目标检测红外与可见光图像融合方法。该方法首先运用目标检测技术将红外图像分割为目标和背景区域，同时运用非下采样轮廓波变换将红外背景区域和可见光图像融合得到融合背景图像，最后将融合背景图像和红外目标区域融合得到最终融合图像。文章采用红外和可见光图像系列进行实验，结果表明运用本方法所得的融合图像能较好地保留红外图像目标信息，具有清晰度较高的背景信息，且具有最高的标准差、信息熵、互信息，是一种可行有效的融合方法。</p></sec><sec id="s10"><title>文章引用</title><p>李婵飞,胡锦龙,韩彦净, (2015) 目标检测的红外和可见光图像融合Infrared and Visible Light Images Fusion Utilizing Object Detection. 图像与信号处理,03,47-52. doi: 10.12677/JISP.2015.43006</p></sec><sec id="s11"><title>参考文献 (References)</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.15664-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Yin, S., Cao, L., Ling, Y. and Jin, G. (2010) One color contrast enhanced infrared and visible image fusion method. Infrared Physics &amp; Technology, 53, 146-150. &lt;br&gt;http://dx.doi.org/10.1016/j.infrared.2009.10.007</mixed-citation></ref><ref id="hanspub.15664-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Liu, G., Jing, Z.-L., Sun, S.-Y., et al. (2004) Image fusion based on expectation maximization algorithm and steerable pyramid. Chinese Optics Letters, 2, 386-389.</mixed-citation></ref><ref id="hanspub.15664-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Mallat, S. (1989) A theory for multiresolution signal decomposition: The wavelet representation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 11, 674-693. &lt;br&gt;http://dx.doi.org/10.1109/34.192463</mixed-citation></ref><ref id="hanspub.15664-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Chao, R., Zhang, K. and Li, Y.-J. (2004) A image fusion method based on wavelet transform. Chinese Journal of Electronics, 32, 750-753.</mixed-citation></ref><ref id="hanspub.15664-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">da Cunha, A.L., Zhou, J. and Do, M.N. (2006) The nonsubsampled contourlet transform: theory, design, and applications. IEEE Transactions on Image Processing, 15, 3089-3101. &lt;br&gt;http://dx.doi.org/10.1109/TIP.2006.877507</mixed-citation></ref><ref id="hanspub.15664-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">刘信乐 (2013) 红外图像和可见光图像融合方法研究. 硕士论文, 电子科技大学, 成都.</mixed-citation></ref><ref id="hanspub.15664-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Piella, G. (2003) A general framework for multiresolution image fusion: from pixels to regions. Information Fusion, 4, 259-280. &lt;br&gt;http://dx.doi.org/10.1016/S1566-2535(03)00046-0</mixed-citation></ref><ref id="hanspub.15664-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Kapur, J., Sahop, P. and Wong, A. (1985) A new method for grey-level picture thresholding using the entropy of the histogram. Computer Vision Graphics and Image Processing, 29, 210-239.  
&lt;br&gt;http://dx.doi.org/10.1016/S0734-189X(85)90156-2</mixed-citation></ref><ref id="hanspub.15664-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Comaniciu, D. and Meer, P. (2002) Mean shift: A robust approach toward feature space analysis. IEEE Transaction on Pattern Analysis and Machine Intelligence, 24, 603-619. &lt;br&gt;http://dx.doi.org/10.1109/34.1000236</mixed-citation></ref><ref id="hanspub.15664-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Yin, S.F., Cao, L.C., Tan, Q.F. and Jin, G.F. (2010) Infrared and visible image fusion based on NSCT and fuzzy logic. IEEE International Conference on Mechatronics and Autormation, Xi’an, 4-7 August 2010, 671-675.  
&lt;br&gt;http://dx.doi.org/10.1109/icma.2010.5588318</mixed-citation></ref><ref id="hanspub.15664-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">陈天华, 林雨辰 (2013) 基于 NSCT 变换的红外与可见光图像融合方法. 北京交通大学学报, 6, 18-21.</mixed-citation></ref><ref id="hanspub.15664-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">李勇 (2013) 基于多尺度分解的多源图像融合算法研究. 博士论文, 吉林大学, 吉林.</mixed-citation></ref></ref-list></back></article>