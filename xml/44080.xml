<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">AAM</journal-id><journal-title-group><journal-title>Advances in Applied Mathematics</journal-title></journal-title-group><issn pub-type="epub">2324-7991</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/AAM.2021.107259</article-id><article-id pub-id-type="publisher-id">AAM-44080</article-id><article-categories><subj-group subj-group-type="heading"><subject>AAM20210700000_64860132.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>数学与物理</subject></subj-group></article-categories><title-group><article-title>
 
 
  计算机视觉目标跟踪的可信估计
  Trusted Estimation of Object Tracking in Computer Vision
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>李</surname><given-names>杨</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>李</surname><given-names>喆</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>长春理工大学理学院，吉林 长春</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>01</day><month>07</month><year>2021</year></pub-date><volume>10</volume><issue>07</issue><fpage>2486</fpage><lpage>2493</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
  计算机视觉领域，目标跟踪是一项具有许多现实应用的视觉任务，对运动的目标进行精准估计成为了一项具有重要意义的工作。本文将区间算法应用到计算机视觉目标跟踪中，基于频谱滤波器，利用区间运算实现计算机视觉目标跟踪问题的可信估计。当目标跟踪失败时，利用颜色识别对每一帧背景进行预处理，预估目标所在的区域范围，从而更好的确定目标位置。
   In the field of computer vision, target tracking is a visual task with many practical applications. Accurate estimation of moving targets has become an important work. In this paper, the interval algorithm is applied to computer vision target tracking. Based on the spectral filter, the interval operation is used to realize the trusted estimation of computer vision target tracking problem. When the target tracking fails, the color recognition is used to preprocess the background of each frame to estimate the range of the target area, so as to better determine the target location.
 
</p></abstract><kwd-group><kwd>计算机视觉，目标跟踪，可信估计, Computer Vision</kwd><kwd> Target Tracking</kwd><kwd> Trusted Estimation</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>摘要</title><p>计算机视觉领域，目标跟踪是一项具有许多现实应用的视觉任务，对运动的目标进行精准估计成为了一项具有重要意义的工作。本文将区间算法应用到计算机视觉目标跟踪中，基于频谱滤波器，利用区间运算实现计算机视觉目标跟踪问题的可信估计。当目标跟踪失败时，利用颜色识别对每一帧背景进行预处理，预估目标所在的区域范围，从而更好的确定目标位置。</p></sec><sec id="s2"><title>关键词</title><p>计算机视觉，目标跟踪，可信估计</p></sec><sec id="s3"><title>Trusted Estimation of Object Tracking in Computer Vision<sup> </sup></title><p>Yang Li, Zhe Li</p><p>School of Science, Changchun University of Science and Technology, Changchun Jilin</p><p><img src="//html.hanspub.org/file/25-2621715x4_hanspub.png?20210726092145376" /></p><p>Received: Jun. 19<sup>th</sup>, 2021; accepted: Jul. 11<sup>th</sup>, 2021; published: Jul. 23<sup>rd</sup>, 2021</p><p><img src="//html.hanspub.org/file/25-2621715x5_hanspub.png?20210726092145376" /></p></sec><sec id="s4"><title>ABSTRACT</title><p>In the field of computer vision, target tracking is a visual task with many practical applications. Accurate estimation of moving targets has become an important work. In this paper, the interval algorithm is applied to computer vision target tracking. Based on the spectral filter, the interval operation is used to realize the trusted estimation of computer vision target tracking problem. When the target tracking fails, the color recognition is used to preprocess the background of each frame to estimate the range of the target area, so as to better determine the target location.</p><p>Keywords:Computer Vision, Target Tracking, Trusted Estimation</p><disp-formula id="hanspub.44080-formula15"><graphic xlink:href="//html.hanspub.org/file/25-2621715x6_hanspub.png?20210726092145376"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2021 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/25-2621715x7_hanspub.png?20210726092145376" /> <img src="//html.hanspub.org/file/25-2621715x8_hanspub.png?20210726092145376" /></p></sec><sec id="s5"><title>1. 引言</title><p>目标跟踪就是对视频图像序列中的运动目标进行检测、提取、识别和跟踪，获得运动目标的运动参数，如目标质心位置、速度等，以及运动轨迹，从而进行进一步处理与分析，实现对运动目标的行为理解 [<xref ref-type="bibr" rid="hanspub.44080-ref1">1</xref>]。目标跟踪作为一门跨学科的前沿技术，融合了图像处理、模式识别、人工智能、自动控制等多种不同领域的理论知识 [<xref ref-type="bibr" rid="hanspub.44080-ref2">2</xref>]，并且在视频理解、机器人导航、智能监控等领域都有着广泛的应用，因此跟踪算法的研究具有重要的意义。</p><p>目标跟踪过程中能够影响跟踪结果的因素有很多，如何提高目标跟踪的稳定性成为了计算机视觉方向一个需要突破的难题。近年来，众多科研学者致力于此方向的研究，所提出的算法可以大致分为两类：基于部分跟踪算法和整体跟踪算法。</p><p>Prokhorov [<xref ref-type="bibr" rid="hanspub.44080-ref3">3</xref>] 等人提出了一个层次化的外观的表示模型用于跟踪，基于利用多个量化级别的共享信息的图形模型，通过对像素和超像素的联合分类来找到目标的最可能位置，在所有级别获得最佳配置。雷震等人 [<xref ref-type="bibr" rid="hanspub.44080-ref4">4</xref>] 提出了一种新的多部件联合在线跟踪分割算法(JOTS)，将跟踪和分割融合为一个统一的能量优化框架来处理视频分割任务。卢湖川等人 [<xref ref-type="bibr" rid="hanspub.44080-ref5">5</xref>] 中提出了一个基于超混合的判别外观模型，能够解决严重遮挡问题，并且能够从漂移中恢复跟踪的目标。Malik等人 [<xref ref-type="bibr" rid="hanspub.44080-ref6">6</xref>] 提出了一种从背景中重复分割图形的跟踪模式，用于解决长时间跟踪时物体的外观、形状和比例变化对计算结果产生的影响。</p><p>不同的是，整体的跟踪方法似乎更受欢迎，例如高效且具有良好鲁棒性优点的基于相关滤波器(CF)的模型。在CF模型的基础上出现了相关滤波器的一些正则化方法，此类型的方法从空间抑制背景区域以解决杂乱背景对跟踪器性能的影响。崔振等人 [<xref ref-type="bibr" rid="hanspub.44080-ref7">7</xref>] 提出一种新的方法称为递归目标参与跟踪(RTT)，用来解决估计误差的累积和传播。Danelljan等人 [<xref ref-type="bibr" rid="hanspub.44080-ref8">8</xref>] 提出了高精度的用于跟踪的空间正则化判别相关滤波器(SRDCF)。与此同时Danelljan等人 [<xref ref-type="bibr" rid="hanspub.44080-ref9">9</xref>] 还研究了基于DCF的两个跟踪框架(标准DCF框架和SRDCF框架)中卷积特征的影响，标准的基于DCF的方法依赖于手工制作的特性来进行稳健的图像描述，提出建议在基于DCF的框架中使用卷积特征来进行视觉跟踪。</p><p>跟踪结果的准确率会随着外部环境的变化而大幅度的下降，同时一些传统的目标跟踪滤波器自身也会存在很多缺点。针对如何提高目标跟踪结果准确率的问题，学者们给出了不同的答案。朱明敏等人 [<xref ref-type="bibr" rid="hanspub.44080-ref10">10</xref>] 提出一种可以实时高效准确的跟踪快速运动目标的长时核相关滤波(LKCF)跟踪算法，此算法引入了CN颜色特征及基于光流法的再检测机制，当目标跟踪失败时可以对失踪的目标进行重新获得。徐烨超 [<xref ref-type="bibr" rid="hanspub.44080-ref11">11</xref>] 提出了IFCT (基于独立特征通道的跟踪)，用来解决基于相关滤波器(CF)的视觉目标跟踪算法中非充分学习、非置信结合和非弹性更新在内的三个缺陷，并且提出了RCF (基于独立特征通道的可逆向学习相关滤波器)以解决场景导致的模型漂移和算法导致的模型漂移等问题。张雷 [<xref ref-type="bibr" rid="hanspub.44080-ref12">12</xref>] 等人提出来基于KCF的多尺度目标跟踪的方法，解决了目标跟踪问题中有关目标尺度估计的困难。</p><p>与基于CF的方法的整体回归不同，崔振等 [<xref ref-type="bibr" rid="hanspub.44080-ref13">13</xref>] 人提出了对每个像素的多个局部区域的跟踪模型进行回归的频谱滤波器(SFT)跟踪方法。本文将Rump区间算法应用到频谱滤波器(SFT)的跟踪模型中，实现目标跟踪问题的可信估计，同时利用颜色识别提高跟踪结果的准确性。</p></sec><sec id="s6"><title>2. 目标跟踪的可信估计</title><p>定理1：区间矩阵 A ∈ I ℝ m &#215; n ( m ≤ n ) ，和区间向量 b ∈ I ℝ m 满足 0 ∉ b ，如果verifylss函数对下列区间</p><p>线性系统成功运行</p><p>( A T − I n O m , n A ) ( w x ) = ( 0 b )</p><p>则区间矩阵 A 是满秩的。</p>频谱滤波器<p>在给定视频帧的情况下，由于连续视频帧中目标的运动的变化不容易被察觉，首先在前一帧的边界框周围确定一个小的候选区域。为了减少局部外观变化对跟踪的影响，将候选区域建模为具有旋转不变性和平移不变性的像素网格图。</p><p>将像素空间网格结构建模为无向加权图，加权图 G = { V , ε , W } 由一组顶点 V = ( | V | = N ) 和一组边 ε ，邻域矩阵W为连接的边分配的正值。此外，每个顶点都与信号相关，即从其坐标位置提取多通道特征向量。形式上特征提取函数 f : v → R d 定义了顶点信号，其中d是特征维数。</p><p>谱图理论中图Laplacian算子L是一个关键的算子，定义为 L = D − W ，其中 D ∈ ℝ N &#215; N 是对角矩阵 D i i = Σ j W i j 。一种常用的方法是归一化图Laplacian，即将每个权重 W i j 与一个因子 1 D i i D j j 相乘，即</p><p>L n o r m = D − 1 2 L D − 1 2 = I − D − 1 2 W D − 1 2 , (1)</p><p>其中L为实对称矩阵，其具有完整的正交特征向量，其特征向量 { u l } 满足 L u l = λ l u l ( l = 1 , 2 , ⋯ , N ) ，其中 { λ l } 是非负实特征值。假设所有的特征值都是有序的则 0 = λ 1 &lt; λ 2 ≤ λ 3 ≤ ⋯ ≤ λ N = λ max 。</p><p>在矩阵表达式中 L = U Λ U T ，其中 Λ = d i a g ( λ 1 , λ 2 , ⋯ , λ N ) 。</p><p>步骤1 滤波器函数的构造</p><p>x的傅里叶变换 x = U T x 以及逆变换 x = U x ^ ，其中 x ^ 是产生的频率信号。</p><p>设滤波器函数 g ( ⋅ ) ，输入信号x上的频率滤波定义为 z ^ ( λ l ) = x ^ ( λ l ) g ^ ( λ l ) ，或为逆图傅里叶变换</p><p>z ( i ) = ∑ l − 1 N x ^ ( λ l ) g ^ ( λ l ) u ^ l ( i ) , (2)</p><p>其中 z ^ ( λ l ) , x ^ ( λ l ) , g ^ ( λ l ) 是对应频谱 λ l 的傅里叶系数。通过使用矩阵表示法，信号x被过滤为</p><p>z = g ^ ( L ) x = U [ g ^ ( λ 1 ) ⋯ 0 ⋮ ⋱ ⋮ 0 ⋯ g ^ ( λ N ) ] U T x . (3)</p><p>步骤2 函数的求解</p><p>给定的输入x和输出z，通过特征值分解求解可求得(3)中的 g ( ⋅ ) ，同时利用K阶的Chebyshev展开式来逼近频域中的 g ( ⋅ ) 降低计算量。</p><p>Chebyshev展开式由递归关系定义为</p><p>T k ( x ) = 2 x T k − 1 ( x ) − T k − 2 ( x ) ,</p><p>其中 T 0 = 1 ,   T 1 = x 。</p><p>在适当的Sobolev空间中，Chebyshev多项式的集合构成了一个基，因此[−1,1]中任何一个函数都可</p><p>以通过展开来表示 f ( x ) = ∑ k = 0 ∞ a k T k ( x ) 。</p><p>为使得LaplacianL的特征值 { λ l } 落在[−1,1]中，将其缩放并转换为 λ ˜ l = 2 λ max λ l − 1 ，并在 { λ ˜ l } 上使用</p><p>Chebyshev多项式，考虑多项式分量的线性组合，则K阶滤波器</p><p>g ^ ( λ l ) = ∑ k = 0 K − 1 θ k T k ( λ ˜ l ) , (4)</p><p>其中 θ ∈ ℝ K 是多项式系数的参数向量，K是多项式的阶。由(3) (4)有</p><p>z = U [ ∑ k = 0 K − 1 θ k T k ( λ ˜ l ) ⋯ 0 ⋮ ⋱ ⋮ 0 ⋯ ∑ k = 0 K − 1 θ k T k ( λ ˜ l ) ] U T x</p><p>= ∑ k = 0 K − 1 θ k U [ T k ( λ ˜ l ) ⋯ 0 ⋮ ⋱ ⋮ 0 ⋯ T k ( λ ˜ l ) ] U T x (5)</p><p>= ∑ k = 0 K − 1 θ k T k ( U [ λ ˜ l ⋯ 0 ⋮ ⋱ ⋮ 0 ⋯ λ ˜ l ] U T ) x (6)</p><p>= ∑ k = 0 K − 1 θ k T k ( 2 λ max L − I ) x (7)</p><p>在(6)，(7)上使用Laplacian矩阵的谱分解 L = U d i a g ( [ λ 1 , ⋯ , λ N ] ) U T 。通过(5)和(6)利用滤波函数的基</p><p>本计算即</p><p>L k = U d i a g ( [ λ 1 k , ⋯ , λ N k ] ) U T = ( U d i a g [ λ 1 , ⋯ , λ N ] U T ) k (8)</p><p>在(7)中的K阶多项式是拉普拉斯图上的一个精确的K局部化滤波函数。为了得到图上的局部滤波响应，只需对拉普拉斯矩阵L进行运算，即多项式的每一项都可以作为滤波基， θ 是需要求解的参数。</p><p>步骤3 跟踪目标模型的建立</p><p>在视觉跟踪中，从多通道特征 X ∈ ℝ N &#215; d 中回归峰值映射 y ∈ ℝ N &#215; 1 ，其中N候选区域内的像素数(即顶</p><p>点)，每一行X对应一个顶点的信号。</p><p>L ˜ = 2 λ max L − I ，将(7)中定义的滤波器基变成 { T 0 ( L ˜ ) , T 1 ( L ˜ ) , ⋯ , T K − 1 ( L ˜ ) } 。</p><p>给定一个信号和x和滤波器参数 θ = { θ 0 , θ 2 , ⋯ , θ K − 1 } ，采用K个滤波器基的线性组合获得局部滤波响</p><p>应z。使用K个滤波器基对图进行滤波，将滤波参数和特征投影函数的学习结合到一个最小二乘回归模型中</p><p>arg min w ‖ F ( X ) w − y ‖ 2 + γ ‖ w ‖ 2 , (9)</p><p>其中 γ 是平衡参数， F ( X ) 在特征维数上连接K滤波器基的响应，</p><p>F ( X ) = [ T 0 ( L ˜ ) X , T 1 ( L ˜ ) X , ⋯ , T K − 1 ( L ˜ ) X ] . (10)</p><p>因此，根据定理1，跟踪模型中的系数w可以利用Rump区间算法估计求解为</p><p>( ( F ( X ) ) T − I n O m , n F ( X ) ) ( w x ) = ( 0 y ) . (11)</p><p>步骤4 跟踪目标的坐标的计算</p><p>初始化拉普拉斯矩阵L，从候选区域中提取特征X，计算(10)方程中的K阶响应 F ( X ) ，利用(11)获取得分</p><p>y ˜ = F ( X ) w</p><p>通过找到得分最大的目标中心获取被跟踪目标的最终坐标。</p></sec><sec id="s7"><title>3. 颜色识别</title><p>跟踪过程中由于外部环境的影响会导致跟踪失败，为了提高模型对目标捕获的准确性，在基于区间算法的频谱滤波器跟踪模型中增加颜色识别部分。首先从目标图像中抽取颜色特征，彩色图像得格式有很多，本节以RGB的格式来提取颜色特征。</p><sec id="s7_1"><title>3.1. 提取颜色特征</title><p>当物体的呈蓝色时，物体的蓝色分量值大于红色、绿色分量值，则蓝色特征的提取公式</p><p>D ( x , y ) = 2 B ( x , y ) − R ( x , y ) − G ( x , y ) .</p><p>当物体呈黄色时，物体的红色分量和绿色分量值大于蓝色分量，并且红色和绿色分量之间的差距较小时，则黄色特征的提取公式</p><p>D ( x , y ) = R ( x , y ) + G ( x , y ) − 2 B ( x , y ) − k &#215; A B S ( R ( x , y ) − G ( x , y ) ) ,</p><p>其中，系数k的选择取决于黄色的个体差异，当背景颜色不是纯黄色而是偏于绿色或红色的时候，系数k的值可以适当减少。</p><p>当物体呈黑色时，物体的红色、绿色、蓝色三个分量的值都比较小，同时三个分量之间的差异也比较小，则黑色特征的提取公式</p><p>D ( x , y ) = 255 &#215; 3 − ( R ( x , y ) + G ( x , y ) + B ( x , y ) ) − k &#215; ( A B S ( R ( x , y ) − G ( x , y ) )   + A B S ( R ( x , y ) − B ( x , y ) ) A B S ( B ( x , y ) − G ( x , y ) ) )</p><p>其中，系数k的选择取决于黑色的纯正程度。</p><p>当物体的呈白色时，物体的红色、绿色、蓝色三个分量的值都比较大，但是三个分量之间的差异比较小，则白色特征的提取公式</p><p>D ( x , y ) = R ( x , y ) + G ( x , y ) + B ( x , y ) − k &#215; ( A B S ( R ( x , y ) − G ( x , y ) )   + A B S ( R ( x , y ) − B ( x , y ) ) A B S ( B ( x , y ) − G ( x , y ) ) )</p><p>其中，系数k的选择取决于白色的纯正程度。</p></sec><sec id="s7_2"><title>3.2. 选取阈值</title><p>经过颜色特征的提取之后，原彩色图像变成了几个灰度图像。在对每个灰度图像进行搜索时，一般需要进行二值化的处理，此时阈值的选择成为了首要问题。</p><p>在这里采用依据背景和物体之间的类间方差最大，而背景之间以及物体之间的类内方差最小的大津方法。</p><p>设一块图像区域的灰度值为 f ( i , j ) ( i = 1 , ⋯ , m ; j = 1 , ⋯ , n ) ，则阈值计算公式</p><p>s u m = ∑ i = 1 m ∑ j = 1 n f i j   d o t s = m &#215; n , (10)</p><p>D k 为灰度直方图 ( k = 0 ~ 255 ) ，</p><p>a = ∑ k = 1 g k &#215; D k   b = ∑ k = 1 g D k , (11)</p><p>t 1 = b &#215; d o t s − b &#215; b   t 2 = s u m &#215; b − d o t s &#215; a , (12)</p><p>p = t 2 &#215; t 2 t 1 &#215; d o t s &#215; d o t s , (13)</p><p>计算g从1到255时，p的值，找出最大的p就是所求的阈值。</p></sec></sec><sec id="s8"><title>4. 实验结果及分析</title><p>图1. 实验结果1</p><p>图2. 实验结果2</p><p>如图1、图2所示，明确的给出了本文改进前算法的部分跟踪结果，从跟踪结果中可以清楚地看出，当目标与背景颜色对比鲜明、图中物体颜色反差较为明显，目标物体未发生形变的状态下跟踪效果较为良好，可以很清晰的看出物体的颜色，物体的轮廓等。</p><p>图3. 实验结果3</p><p>图4. 实验结果4</p><p>如图3、图4所示，改进前的方法无法清晰地给出跟踪结果，当跟踪环境未能达到理想的状态下，且目标物体发生较大形变时，容易导致目标物体的跟踪失败，此时采用改进后的跟踪方法能够对目标重新准确的跟踪。</p><p>通过以上的跟踪实验可以得出，针对跟踪失败的案例，在对目标物体进行跟踪识别前，利用颜色识别对目标背景进行处理，以此获取目标物体颜色的RGB阈值。再根据选定的RGB阈值范围，在视频帧中选定在RGB阈值范围内的区域进行调试，对目标进行重新获取，再利用频谱滤波器跟踪模型确定重新捕获的目标在背景中的位置。</p><p>从实验中可以清晰地看出，与原有的计算方法相比下，改进后的计算方法确实能够更好更明确的对目标物体进行捕捉跟踪，但该算法也存在着一些弊端的短板，例如计算的过程较为复杂、计算效率比较低等，所以跟踪效率方面依旧存在着很大的提升空间。在未来该算法需要通过进一步的优化和研究，从而取得更为准确的计算结果，实现更高效率的跟踪。</p></sec><sec id="s9"><title>5. 总结</title><p>在目标物体跟踪的过程中，会存在着很多直接影响跟踪计算结果的准确性的因素，例如跟踪目标物体的形状、尺寸的大小、位置的改变，和跟踪目标背景环境以及光照的条件的改变，以及目标物体被遮挡以及部分被遮挡等，都会导致的目标物体跟踪出现失败。针对这些难点，本文提出基于区间算法的频谱滤波器跟踪方法，即通过利用区间运算来计算跟踪模型系数值的区间，从而实现目标物体跟踪的可信估计。当目标物体跟踪失败，利用目标物体颜色，估计目标物体的位置区域范围，实现目标的重新捕获跟踪。通过实验可以证明，与原有的跟踪方法相比，改进后的跟踪计算方法能更准确的对目标进行跟踪。</p></sec><sec id="s10"><title>文章引用</title><p>李 杨,李 喆. 计算机视觉目标跟踪的可信估计Trusted Estimation of Object Tracking in Computer Vision[J]. 应用数学进展, 2021, 10(07): 2486-2493. https://doi.org/10.12677/AAM.2021.107259</p></sec><sec id="s11"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.44080-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">卢晓鹏. 视频序列中目标跟踪技术研究[D]: [博士学位论文]. 北京: 中国科学院电子研究所, 2007.</mixed-citation></ref><ref id="hanspub.44080-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">张娟, 毛晓波, 陈铁军. 运动目标跟踪算法研究综述[J]. 计算机应用研究, 2009, 26(12): 4407-4410.</mixed-citation></ref><ref id="hanspub.44080-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Hong, Z., Wang, C., Mei, X., Prokhorov, D. and Tao, D. (2014) Tracking Using Multilevel Quantizations. In: Fleet, D., Pajdla. T., Schiele, B., Tuytelaars, T., Eds., Computer Vision-ECCV 2014, ECCV 2014, Lecture Notes in Computer Science, 8694, 155-171. &lt;br&gt;https://doi.org/10.1007/978-3-319-10599-4_11</mixed-citation></ref><ref id="hanspub.44080-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Wen, L., Du, D., Zhen, L., Li, S.Z. and Yang, M.H. (2015) Jots: Joint Online Tracking and Segmentation. 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 6, 2226-2234.  
&lt;br&gt;https://doi.org/10.1109/CVPR.2015.7298835</mixed-citation></ref><ref id="hanspub.44080-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Wang, S., Lu, H., Yang, F. and Yang, M.H. (2011) Superpixel Tracking. 2011 International Conference on Computer Vision, 24, 1323-1330.</mixed-citation></ref><ref id="hanspub.44080-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Ren, X. and Malik, J. (2007) Tracking as Repeated Figure/Ground Segmentation. 2007 IEEE Conference on Computer Vision and Pattern Recognition, 1, 1-8. &lt;br&gt;https://doi.org/10.1109/CVPR.2007.383177</mixed-citation></ref><ref id="hanspub.44080-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Cui, Z., Xiao, S., Feng, J. and Yan, S. (2016) Recurrently Target-Attending Tracking. 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 1, 1449-1458. &lt;br&gt;https://doi.org/10.1109/CVPR.2016.161</mixed-citation></ref><ref id="hanspub.44080-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Danelljan, M., Häger, F., Khan, S. and Felsberg, M. (2015) Learning Spatially Regularized Correlation Filters for Visual Tracking. 2015 IEEE International Conference on Computer Vision (ICCV), 1, 4310-4318.  
&lt;br&gt;https://doi.org/10.1109/ICCV.2015.490</mixed-citation></ref><ref id="hanspub.44080-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Danelljan, M., Häger, F., Khan, S. and Felsberg, M. (2015) Convolutional Features for Correlation Filter Based Visual Tracking. 2015 IEEE International Conference on Computer Vision Workshop (ICCVW), 1, 58-66.  
&lt;br&gt;https://doi.org/10.1109/ICCVW.2015.84</mixed-citation></ref><ref id="hanspub.44080-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">朱明敏, 胡茂海. 基于相关滤波器的长时视觉目标跟踪方法[J]. 计算机应用, 2017, 37(5): 1466-1470.</mixed-citation></ref><ref id="hanspub.44080-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">徐烨超. 基于相关滤波器的视觉目标跟踪方法研究[D]: [硕士学位论文]. 南京: 南京邮电大学, 2019.</mixed-citation></ref><ref id="hanspub.44080-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">张雷, 王延杰, 刘艳滢. 基于相关滤波器的视觉目标跟踪方法[J]. 光电子·激光, 2015(7): 1349-1357.</mixed-citation></ref><ref id="hanspub.44080-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Cui, Z., Cai, Y.Y. and Zheng, W.M. (2019) Spectral Filter Tracking. 2019 IEEE Transactions on Image Processing, 28, 2479-2489. &lt;br&gt;https://doi.org/10.1109/TIP.2018.2886788</mixed-citation></ref></ref-list></back></article>