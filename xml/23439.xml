<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">AAM</journal-id><journal-title-group><journal-title>Advances in Applied Mathematics</journal-title></journal-title-group><issn pub-type="epub">2324-7991</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/AAM.2018.71003</article-id><article-id pub-id-type="publisher-id">AAM-23439</article-id><article-categories><subj-group subj-group-type="heading"><subject>AAM20180100000_15240507.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>数学与物理</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于SVM的小微企业评级
  Rating of Small and Micro Businesses Based on SVM
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>李</surname><given-names>超</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>王</surname><given-names>海辉</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib></contrib-group><aff id="aff1"><addr-line>北京航空航天大学，北京</addr-line></aff><author-notes><corresp id="cor1">* E-mail:<email>lichao1509118@buaa.edu.cn(李超)</email>;<email>whh@buaa.edu.cn(王海)</email>;</corresp></author-notes><pub-date pub-type="epub"><day>16</day><month>01</month><year>2018</year></pub-date><volume>07</volume><issue>01</issue><fpage>10</fpage><lpage>19</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   随着经济不断转型，小微企业为我国经济发展注入了新的活力。为了增强小微企业的风险管理水平，从而提高其成活率，就必须进行有效的风险评价。对我国小微企业进行风险评级，可以运用支持向量机(SVM)方法，并依据建立的风险评价指标体系，通过对选取的样本数据进行SVM分类训练，评估我国部分小微企业风险等级水平。从而方便企业管理者根据风险水平，采取切实有效风险控制措施，促进小微企业良性发展。 With the transformation of the economy, small and micro businesses have injected new vitality into the economic development of our country. In order to enhance the risk management level of small and micro businesses and to improve their survival rate, effective risk assessment must be carried out. We can use the method of support vector machine (SVM) for the risk rating of small and micro businesses. Based on the established risk assessment index system, we can evaluate the risk level of some small and micro businesses through SVM classification training on selected sample data. Therefore, it is convenient for the enterprise managers to take effective risk control measures to promote the benign development of small and micro businesses according to the risk level. 
  
 
</p></abstract><kwd-group><kwd>小微企业，风险评级，支持向量机，分类训练, Small and Micro Businesses</kwd><kwd> Risk Rating</kwd><kwd> Support Vector Machine</kwd><kwd> Classification Training</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>基于SVM的小微企业评级<sup> </sup></title><p>李超，王海辉</p><p>北京航空航天大学，北京</p><p>收稿日期：2017年12月15日；录用日期：2018年1月11日；发布日期：2018年1月18日</p><disp-formula id="hanspub.23439-formula4"><graphic xlink:href="//html.hanspub.org/file/3-2620562x5_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>随着经济不断转型，小微企业为我国经济发展注入了新的活力。为了增强小微企业的风险管理水平，从而提高其成活率，就必须进行有效的风险评价。对我国小微企业进行风险评级，可以运用支持向量机(SVM)方法，并依据建立的风险评价指标体系，通过对选取的样本数据进行SVM分类训练，评估我国部分小微企业风险等级水平。从而方便企业管理者根据风险水平，采取切实有效风险控制措施，促进小微企业良性发展。</p><p>关键词 :小微企业，风险评级，支持向量机，分类训练</p><disp-formula id="hanspub.23439-formula5"><graphic xlink:href="//html.hanspub.org/file/3-2620562x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2018 by authors and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/3-2620562x7_hanspub.png" /> <img src="//html.hanspub.org/file/3-2620562x8_hanspub.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>近年来，我国股权众筹行业高速发展，项目数量和平台数量都大幅增长。股权众筹在增加投资者理财方式的同时，更完善了小微企业的融资渠道，从而提高了金融市场的效率，促进了我国创新创业，推动了经济结构转型。股权众筹虽然有优势有活力，可以降低获取信息的成本，但也不可避免地存在着虚假信息，各利益相关者信用风险问题很大，所以股权众筹行业乱象丛生 [<xref ref-type="bibr" rid="hanspub.23439-ref1">1</xref>] 。尤其是这两年互联网众筹平台跑路、倒闭、作假事件屡屡发生，互联网金融行业的信用风险不容乐观。如何对股权众筹信用风险进行分析，并采取量化的方法对其进行风险评级，进而提高小微企业抵御风险的能力，已成为学术界、工业界研究的重点 [<xref ref-type="bibr" rid="hanspub.23439-ref2">2</xref>] 。</p><p>从过去的研究来看，对小微企业风险的研究大部分集中在定性分析上，即使涉及到定量方法，也多是层次分析法、模糊评价法等传统方法。这些方法不适合股权众筹平台这种影响因素繁多复杂的系统，而且评价结果的可靠性和精确性无法保证。随着互联网技术的不断创新发展，风险评价也向着标准化、系统化和精确化方向推进，出现了新的将计算机模拟与风险评价相结合的方法。支持向量机法(SVM)作为一种备受推崇的数据挖掘技术，已经在文本识别、人脸识别、银行信用风险评估等诸多实践领域得到广泛应用 [<xref ref-type="bibr" rid="hanspub.23439-ref3">3</xref>] 。本文将SVM方法引入我国小微企业风险评级中，以提高风险评价精度和效率。<sup> </sup></p></sec><sec id="s4"><title>2. 构建小微企业风险评级指标体系</title><p>小微企业所面临的风险因素多而复杂，本文从科学、全面、量化和可操作等角度出发，建立一套科学合理的风险指标体系。根据小微企业的特点，将风险评价指标体系分为5个一级指标和18个二级指标，指标体系具体构建为行业市场环境、产品竞争力、企业基本情况、管理团队素质和财务数据表现五个一级指标，其相应的二级指标以及与一级指标的关系如图1。</p></sec><sec id="s5"><title>3. SVM的基本原理</title><p>支持向量机(SVM)核心思想是建立一个最优分类线或最优超平面作为决策曲面，将多类样本正确地进行分类。即先通过一定量的样本进行训练，通过不断检验与优化得到较高的训练精度，确定一个最优的决策函数再对分类问题进行处理。我们以二分类问题为例分析一下具体过程 [<xref ref-type="bibr" rid="hanspub.23439-ref4">4</xref>] 。</p><sec id="s5_1"><title>3.1. 线性可分问题</title><p>图2中分别是两类样本，支持向量机方法就是寻找最优分类线将两类样本分开，分类线表示为</p><p>图1. 我国小微企业风险评级指标体系</p><p>图2. 寻找两类样本的最优分类线</p><p>( w ⋅ x ) + b = 0 ，最优分类线代表着最大分类间隔，可用如下最优化问题表示：</p><p>min w , b   1 2 ‖ w ‖ 2 (1)</p><p>s .t .       y i ( ( ( w ⋅ x i ) + b ) + 1 ) ≥ 1 ,   i = 1 , ⋯ , l (2)</p><p>其中的约束要求各数据点 ( x i , y i ) 到分类面的距离大于等于1。其中， y i 为数据的分类。</p><p>引入Lagrange函数可将上述问题转化为对偶问题：</p><p>min α   1 2 ∑ i = 1 l ∑ j = 1 l y i y α j i α j ( x i ⋅ x j ) − ∑ j = 1 l α j (3)</p><p>s .t .       ∑ i = 1 l y i α i = 0 (4)</p><p>α i ≥ 0 (5)</p><p>求解上述问题得到最优解：</p><p>w * = ∑ i = 1 l y i a i * x i ,     b * = y j − ∑ i = 1 l y i α i ( x i ⋅ x j ) (6)</p><p>将参数代入原式，即可得到最优分类平面。</p></sec><sec id="s5_2"><title>3.2. 线性不可分问题</title><p>对于线性不可分问题，原来对间隔的要求不能达到。引入松弛变量 ξ i ，使约束条件弱化为： y i ( ( ( w ⋅ x i ) + b ) + 1 ) ≥ 1 − ξ i 。但是，我们仍然希望该松弛变量 ξ i 最小化。于是，在优化目标函数中使用惩罚参数 C 来引入对 ξ i 最小化的目标。此时模型为：</p><p>min w , b   1 2 ‖ w ‖ 2 + C ∑ i = 1 l ξ i (7)</p><p>s .t .       y i ( ( ( w ⋅ x i ) + b ) + 1 ) ≥ 1 − ξ i ,   i = 1 , ⋯ , l (8)</p><p>以此为原问题，其对偶问题为：</p><p>min α   1 2 ∑ i = 1 l ∑ j = 1 l y i y α j i α j ( x i ⋅ x j ) − ∑ j = 1 l α j (9)</p><p>s .t .       ∑ i = 1 l y i α i = 0 (10)</p><p>0 ≤ α i ≤ C (11)</p><p>求解得到最优解为：</p><p>w * = ∑ i = 1 l y i a i * x i ,     b * = y j − ∑ i = 1 l y i α i ( x i ⋅ x j ) (12)</p></sec><sec id="s5_3"><title>3.3. 非线性问题</title><p>对于非线性问题，可以将低维空间中的曲线(曲面)映射为高维空间中的直线或平面。数据经这种映射后，在高维空间中是线性可分的。设映射为 x ′ = ϕ ( x ) ，则高维空间中的线性支持向量机模型为：</p><p>min α   1 2 ∑ i = 1 l ∑ j = 1 l y i y α j i α j ( ϕ ( x i ) ⋅ ϕ ( x j ) ) − ∑ j = 1 l α j (13)</p><p>s .t .       ∑ i = 1 l y i α i = 0 (14)</p><p>0 ≤ α i ≤ C (15)</p><p>由于数据被映射到高维空间， ϕ ( x i ) ⋅ ϕ ( x j ) 的计算量比 x i ⋅ x j 大得多。此时引入了 “核函数”：</p><p>K ( x i , x j ) = ϕ ( x i ) ⋅ ϕ ( x j ) (16)</p><p>由上式可见，核函数的作用是，在将 x 映射到高维空间的同时，也计算了两个数据的在高维空间的内积，使计算量回归到 x i ⋅ x j 的量级。</p></sec></sec><sec id="s6"><title>4. 基于SVM的风险评级</title><sec id="s6_1"><title>4.1. 收集并处理样本数据</title><p>根据图1风险评价指标体系搜集相关的样本数据，本文选取130家小微企业作为研究对象，并搜集他们2017年的原始数据资料，部分企业数据见表1。</p><p>观察数据集中每一个评级的数量分布，结果见表2。</p><p>可见，各个评级的样本分布相对均衡。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Original data of the first 10 enterprise</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" >X1</th><th align="center" valign="middle" >X2</th><th align="center" valign="middle" >X3</th><th align="center" valign="middle" >X4</th><th align="center" valign="middle" >X5</th><th align="center" valign="middle" >X6</th><th align="center" valign="middle" >X7</th><th align="center" valign="middle" >X8</th><th align="center" valign="middle" >X9</th><th align="center" valign="middle" ></th></tr></thead><tr><td align="center" valign="middle" >coolook</td><td align="center" valign="middle" >0.35</td><td align="center" valign="middle" >241</td><td align="center" valign="middle" >8</td><td align="center" valign="middle" >2200</td><td align="center" valign="middle" >100</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >36</td><td align="center" valign="middle" >13.38</td><td align="center" valign="middle" >6</td><td align="center" valign="middle" ></td></tr><tr><td align="center" valign="middle" >e代泊</td><td align="center" valign="middle" >0.75</td><td align="center" valign="middle" >805</td><td align="center" valign="middle" >10</td><td align="center" valign="middle" >320</td><td align="center" valign="middle" >90</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >46</td><td align="center" valign="middle" >292.83</td><td align="center" valign="middle" >10</td><td align="center" valign="middle" ></td></tr><tr><td align="center" valign="middle" >看孩子</td><td align="center" valign="middle" >0.46</td><td align="center" valign="middle" >487</td><td align="center" valign="middle" >6</td><td align="center" valign="middle" >30</td><td align="center" valign="middle" >20</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >22</td><td align="center" valign="middle" >125.08</td><td align="center" valign="middle" >13</td><td align="center" valign="middle" ></td></tr><tr><td align="center" valign="middle" >骑乐无穷</td><td align="center" valign="middle" >0.47</td><td align="center" valign="middle" >379</td><td align="center" valign="middle" >19</td><td align="center" valign="middle" >3800</td><td align="center" valign="middle" >580</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >51</td><td align="center" valign="middle" >114</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" ></td></tr><tr><td align="center" valign="middle" >潮牌pr</td><td align="center" valign="middle" >0.47</td><td align="center" valign="middle" >85</td><td align="center" valign="middle" >7</td><td align="center" valign="middle" >140</td><td align="center" valign="middle" >50</td><td align="center" valign="middle" >8</td><td align="center" valign="middle" >23</td><td align="center" valign="middle" >100</td><td align="center" valign="middle" >4</td><td align="center" valign="middle" ></td></tr><tr><td align="center" valign="middle" >悟空音乐</td><td align="center" valign="middle" >0.57</td><td align="center" valign="middle" >185</td><td align="center" valign="middle" >27</td><td align="center" valign="middle" >300</td><td align="center" valign="middle" >60</td><td align="center" valign="middle" >3</td><td align="center" valign="middle" >32</td><td align="center" valign="middle" >200</td><td align="center" valign="middle" >5</td><td align="center" valign="middle" ></td></tr><tr><td align="center" valign="middle" >脉圈</td><td align="center" valign="middle" >0.34</td><td align="center" valign="middle" >461</td><td align="center" valign="middle" >9</td><td align="center" valign="middle" >450</td><td align="center" valign="middle" >88</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >27</td><td align="center" valign="middle" >119</td><td align="center" valign="middle" >3</td><td align="center" valign="middle" ></td></tr><tr><td align="center" valign="middle" >慧金天下</td><td align="center" valign="middle" >0.56</td><td align="center" valign="middle" >484</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >450</td><td align="center" valign="middle" >90</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >30</td><td align="center" valign="middle" >5649.72</td><td align="center" valign="middle" >7</td><td align="center" valign="middle" ></td></tr><tr><td align="center" valign="middle" >羽乐圈</td><td align="center" valign="middle" >0.57</td><td align="center" valign="middle" >553</td><td align="center" valign="middle" >27</td><td align="center" valign="middle" >8000</td><td align="center" valign="middle" >66</td><td align="center" valign="middle" >4</td><td align="center" valign="middle" >37</td><td align="center" valign="middle" >123.21</td><td align="center" valign="middle" >8</td><td align="center" valign="middle" ></td></tr><tr><td align="center" valign="middle" >聘宝</td><td align="center" valign="middle" >0.35</td><td align="center" valign="middle" >513</td><td align="center" valign="middle" >4</td><td align="center" valign="middle" >2000</td><td align="center" valign="middle" >400</td><td align="center" valign="middle" >7</td><td align="center" valign="middle" >44</td><td align="center" valign="middle" >488.81</td><td align="center" valign="middle" >6</td><td align="center" valign="middle" ></td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >X10</td><td align="center" valign="middle" >X11</td><td align="center" valign="middle" >X12</td><td align="center" valign="middle" >X13</td><td align="center" valign="middle" >X14</td><td align="center" valign="middle" >X15</td><td align="center" valign="middle" >X16</td><td align="center" valign="middle" >X17</td><td align="center" valign="middle" >X18</td><td align="center" valign="middle" >评级</td></tr><tr><td align="center" valign="middle" >coolook</td><td align="center" valign="middle" >3</td><td align="center" valign="middle" >6</td><td align="center" valign="middle" >12</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >830</td><td align="center" valign="middle" >0.020</td><td align="center" valign="middle" >4</td><td align="center" valign="middle" >1</td></tr><tr><td align="center" valign="middle" >e代泊</td><td align="center" valign="middle" >6</td><td align="center" valign="middle" >8</td><td align="center" valign="middle" >17</td><td align="center" valign="middle" >4</td><td align="center" valign="middle" >7800</td><td align="center" valign="middle" >258</td><td align="center" valign="middle" >1340</td><td align="center" valign="middle" >0.069</td><td align="center" valign="middle" >4</td><td align="center" valign="middle" >1</td></tr><tr><td align="center" valign="middle" >看孩子</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >8</td><td align="center" valign="middle" >12</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >300</td><td align="center" valign="middle" >626</td><td align="center" valign="middle" >350</td><td align="center" valign="middle" >0.090</td><td align="center" valign="middle" >4</td><td align="center" valign="middle" >0</td></tr><tr><td align="center" valign="middle" >骑乐无穷</td><td align="center" valign="middle" >4</td><td align="center" valign="middle" >6</td><td align="center" valign="middle" >10</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >500</td><td align="center" valign="middle" >0.100</td><td align="center" valign="middle" >3</td><td align="center" valign="middle" >2</td></tr><tr><td align="center" valign="middle" >潮牌pr</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >8</td><td align="center" valign="middle" >8</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >300</td><td align="center" valign="middle" >0.070</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >2</td></tr><tr><td align="center" valign="middle" >悟空音乐</td><td align="center" valign="middle" >3</td><td align="center" valign="middle" >6</td><td align="center" valign="middle" >6</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >1243</td><td align="center" valign="middle" >604</td><td align="center" valign="middle" >350</td><td align="center" valign="middle" >0.100</td><td align="center" valign="middle" >2.5</td><td align="center" valign="middle" >2</td></tr><tr><td align="center" valign="middle" >脉圈</td><td align="center" valign="middle" >5</td><td align="center" valign="middle" >8</td><td align="center" valign="middle" >13</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >500</td><td align="center" valign="middle" >686</td><td align="center" valign="middle" >200</td><td align="center" valign="middle" >0.035</td><td align="center" valign="middle" >3</td><td align="center" valign="middle" >1</td></tr><tr><td align="center" valign="middle" >慧金天下</td><td align="center" valign="middle" >3</td><td align="center" valign="middle" >9</td><td align="center" valign="middle" >10</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >500</td><td align="center" valign="middle" >755</td><td align="center" valign="middle" >400</td><td align="center" valign="middle" >0.074</td><td align="center" valign="middle" >3.5</td><td align="center" valign="middle" >1</td></tr><tr><td align="center" valign="middle" >羽乐圈</td><td align="center" valign="middle" >4</td><td align="center" valign="middle" >6</td><td align="center" valign="middle" >6</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >300</td><td align="center" valign="middle" >0.130</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >1</td></tr><tr><td align="center" valign="middle" >聘宝</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >9</td><td align="center" valign="middle" >12</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >500</td><td align="center" valign="middle" >504</td><td align="center" valign="middle" >600</td><td align="center" valign="middle" >0.170</td><td align="center" valign="middle" >3</td><td align="center" valign="middle" >1</td></tr></tbody></table></table-wrap><p>表1. 前10家企业原始数据</p><p>我们进一步观察每一个指标的取值分布，见表3。</p><p>观察发现数据取值范围差异很大，因为SVM要用到距离，所以必须做标准化处理，这里采用Min-Max标准化方法处理，结果见表4。</p><p>可以看到所有数据都在0~1之间，可以进行后续的距离计算。</p></sec><sec id="s6_2"><title>4.2. 组建样本训练集，训练模型</title><p>把前91家公司数据作为训练集，后39家公司数据作为测试集，用SVM来进行模型构建。SVM有两个主要的参数可以设置：核函数参数kernel和约束惩罚参数C。其中约束惩罚函数C为对超过约束条件的样本的惩罚项。C值越大，惩罚越大，支持向量机的决策边界越窄。我们选用最简单的线性核函数，C采用200，训练得到最初的模型。</p></sec><sec id="s6_3"><title>4.3. 模型性能评估</title><p>首先，要得到我们训练的模型在测试集上的预测结果，然后对模型的性能进行评估。模型准确率、</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> Rating distributio</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >0</th><th align="center" valign="middle" >58</th></tr></thead><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" >46</td></tr><tr><td align="center" valign="middle" >2</td><td align="center" valign="middle" >26</td></tr></tbody></table></table-wrap><p>表2. 各评级分布</p><table-wrap id="table3" ><label><xref ref-type="table" rid="table3">Table 3</xref></label><caption><title> Statistical data of various indicator</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" >mean</th><th align="center" valign="middle" >std</th><th align="center" valign="middle" >min</th><th align="center" valign="middle" >25%</th><th align="center" valign="middle" >50%</th><th align="center" valign="middle" >75%</th><th align="center" valign="middle" >max</th></tr></thead><tr><td align="center" valign="middle" >X1</td><td align="center" valign="middle" >0.524461538</td><td align="center" valign="middle" >0.114513203</td><td align="center" valign="middle" >0.34</td><td align="center" valign="middle" >0.46</td><td align="center" valign="middle" >0.56</td><td align="center" valign="middle" >0.58</td><td align="center" valign="middle" >0.75</td></tr><tr><td align="center" valign="middle" >X2</td><td align="center" valign="middle" >458.6769231</td><td align="center" valign="middle" >161.6385198</td><td align="center" valign="middle" >85</td><td align="center" valign="middle" >379</td><td align="center" valign="middle" >484</td><td align="center" valign="middle" >548</td><td align="center" valign="middle" >805</td></tr><tr><td align="center" valign="middle" >X3</td><td align="center" valign="middle" >12.09230769</td><td align="center" valign="middle" >16.05776692</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >3</td><td align="center" valign="middle" >8</td><td align="center" valign="middle" >15</td><td align="center" valign="middle" >113</td></tr><tr><td align="center" valign="middle" >X4</td><td align="center" valign="middle" >1907.830769</td><td align="center" valign="middle" >7455.064861</td><td align="center" valign="middle" >11</td><td align="center" valign="middle" >267</td><td align="center" valign="middle" >450</td><td align="center" valign="middle" >1000</td><td align="center" valign="middle" >60,000</td></tr><tr><td align="center" valign="middle" >X5</td><td align="center" valign="middle" >548.2153846</td><td align="center" valign="middle" >2505.925452</td><td align="center" valign="middle" >11</td><td align="center" valign="middle" >80</td><td align="center" valign="middle" >110</td><td align="center" valign="middle" >200</td><td align="center" valign="middle" >20,000</td></tr><tr><td align="center" valign="middle" >X6</td><td align="center" valign="middle" >2.461538462</td><td align="center" valign="middle" >1.905332566</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >4</td><td align="center" valign="middle" >8</td></tr><tr><td align="center" valign="middle" >X7</td><td align="center" valign="middle" >30.47692308</td><td align="center" valign="middle" >16.60494714</td><td align="center" valign="middle" >3</td><td align="center" valign="middle" >21</td><td align="center" valign="middle" >28</td><td align="center" valign="middle" >37</td><td align="center" valign="middle" >102</td></tr><tr><td align="center" valign="middle" >X8</td><td align="center" valign="middle" >654.3972308</td><td align="center" valign="middle" >1213.803404</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >114</td><td align="center" valign="middle" >200</td><td align="center" valign="middle" >583.33</td><td align="center" valign="middle" >5649.72</td></tr><tr><td align="center" valign="middle" >X9</td><td align="center" valign="middle" >5.015384615</td><td align="center" valign="middle" >3.026970792</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >3</td><td align="center" valign="middle" >4</td><td align="center" valign="middle" >7</td><td align="center" valign="middle" >13</td></tr><tr><td align="center" valign="middle" >X10</td><td align="center" valign="middle" >2.123076923</td><td align="center" valign="middle" >1.335359224</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >3</td><td align="center" valign="middle" >6</td></tr><tr><td align="center" valign="middle" >X11</td><td align="center" valign="middle" >7.169230769</td><td align="center" valign="middle" >1.359083489</td><td align="center" valign="middle" >5</td><td align="center" valign="middle" >6</td><td align="center" valign="middle" >7</td><td align="center" valign="middle" >8</td><td align="center" valign="middle" >10</td></tr><tr><td align="center" valign="middle" >X12</td><td align="center" valign="middle" >9.661538462</td><td align="center" valign="middle" >3.37007774</td><td align="center" valign="middle" >3</td><td align="center" valign="middle" >7</td><td align="center" valign="middle" >10</td><td align="center" valign="middle" >12</td><td align="center" valign="middle" >22</td></tr><tr><td align="center" valign="middle" >X13</td><td align="center" valign="middle" >1.292307692</td><td align="center" valign="middle" >1.123713072</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >4</td></tr><tr><td align="center" valign="middle" >X14</td><td align="center" valign="middle" >3602.753846</td><td align="center" valign="middle" >7914.165782</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >500</td><td align="center" valign="middle" >3300</td><td align="center" valign="middle" >37,800</td></tr><tr><td align="center" valign="middle" >X15</td><td align="center" valign="middle" >318.7230769</td><td align="center" valign="middle" >280.2317152</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >270</td><td align="center" valign="middle" >525</td><td align="center" valign="middle" >1087</td></tr><tr><td align="center" valign="middle" >X16</td><td align="center" valign="middle" >1134.692308</td><td align="center" valign="middle" >1788.638536</td><td align="center" valign="middle" >100</td><td align="center" valign="middle" >300</td><td align="center" valign="middle" >600</td><td align="center" valign="middle" >1500</td><td align="center" valign="middle" >13,000</td></tr><tr><td align="center" valign="middle" >X17</td><td align="center" valign="middle" >0.330229231</td><td align="center" valign="middle" >1.873030315</td><td align="center" valign="middle" >0.0033</td><td align="center" valign="middle" >0.0667</td><td align="center" valign="middle" >0.1</td><td align="center" valign="middle" >0.12</td><td align="center" valign="middle" >15.25</td></tr><tr><td align="center" valign="middle" >X18</td><td align="center" valign="middle" >3.769230769</td><td align="center" valign="middle" >2.105873887</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >3</td><td align="center" valign="middle" >4.5</td><td align="center" valign="middle" >10</td></tr></tbody></table></table-wrap><p>表3. 各项指标统计数据</p><table-wrap id="table4" ><label><xref ref-type="table" rid="table4">Table 4</xref></label><caption><title> Statistical data of various indicators after standardizatio</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" >mean</th><th align="center" valign="middle" >std</th><th align="center" valign="middle" >min</th><th align="center" valign="middle" >25%</th><th align="center" valign="middle" >50%</th><th align="center" valign="middle" >75%</th><th align="center" valign="middle" >max</th></tr></thead><tr><td align="center" valign="middle" >X1</td><td align="center" valign="middle" >0.449906191</td><td align="center" valign="middle" >0.279300496</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0.292682927</td><td align="center" valign="middle" >0.536585366</td><td align="center" valign="middle" >0.585365854</td><td align="center" valign="middle" >1</td></tr><tr><td align="center" valign="middle" >X2</td><td align="center" valign="middle" >0.518995726</td><td align="center" valign="middle" >0.224497944</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0.408333333</td><td align="center" valign="middle" >0.554166667</td><td align="center" valign="middle" >0.643055556</td><td align="center" valign="middle" >1</td></tr><tr><td align="center" valign="middle" >X3</td><td align="center" valign="middle" >0.107011572</td><td align="center" valign="middle" >0.142104132</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0.026548673</td><td align="center" valign="middle" >0.07079646</td><td align="center" valign="middle" >0.132743363</td><td align="center" valign="middle" >1</td></tr><tr><td align="center" valign="middle" >X4</td><td align="center" valign="middle" >0.031619643</td><td align="center" valign="middle" >0.124273865</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0.004267449</td><td align="center" valign="middle" >0.007318008</td><td align="center" valign="middle" >0.016486356</td><td align="center" valign="middle" >1</td></tr><tr><td align="center" valign="middle" >X5</td><td align="center" valign="middle" >0.026875551</td><td align="center" valign="middle" >0.125365223</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0.003451899</td><td align="center" valign="middle" >0.004952724</td><td align="center" valign="middle" >0.0094552</td><td align="center" valign="middle" >1</td></tr><tr><td align="center" valign="middle" >X6</td><td align="center" valign="middle" >0.208791209</td><td align="center" valign="middle" >0.272190367</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0.142857143</td><td align="center" valign="middle" >0.428571429</td><td align="center" valign="middle" >1</td></tr><tr><td align="center" valign="middle" >X7</td><td align="center" valign="middle" >0.277544678</td><td align="center" valign="middle" >0.167726739</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0.181818182</td><td align="center" valign="middle" >0.252525253</td><td align="center" valign="middle" >0.343434343</td><td align="center" valign="middle" >1</td></tr><tr><td align="center" valign="middle" >X8</td><td align="center" valign="middle" >0.115671733</td><td align="center" valign="middle" >0.214881142</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0.020004532</td><td align="center" valign="middle" >0.03522922</td><td align="center" valign="middle" >0.103090612</td><td align="center" valign="middle" >1</td></tr><tr><td align="center" valign="middle" >X9</td><td align="center" valign="middle" >0.334615385</td><td align="center" valign="middle" >0.252247566</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0.166666667</td><td align="center" valign="middle" >0.25</td><td align="center" valign="middle" >0.5</td><td align="center" valign="middle" >1</td></tr><tr><td align="center" valign="middle" >X10</td><td align="center" valign="middle" >0.353846154</td><td align="center" valign="middle" >0.222559871</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0.166666667</td><td align="center" valign="middle" >0.333333333</td><td align="center" valign="middle" >0.5</td><td align="center" valign="middle" >1</td></tr><tr><td align="center" valign="middle" >X11</td><td align="center" valign="middle" >0.433846154</td><td align="center" valign="middle" >0.271816698</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0.2</td><td align="center" valign="middle" >0.4</td><td align="center" valign="middle" >0.6</td><td align="center" valign="middle" >1</td></tr><tr><td align="center" valign="middle" >X12</td><td align="center" valign="middle" >0.350607287</td><td align="center" valign="middle" >0.177372513</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0.210526316</td><td align="center" valign="middle" >0.368421053</td><td align="center" valign="middle" >0.473684211</td><td align="center" valign="middle" >1</td></tr><tr><td align="center" valign="middle" >X13</td><td align="center" valign="middle" >0.323076923</td><td align="center" valign="middle" >0.280928268</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0.25</td><td align="center" valign="middle" >0.5</td><td align="center" valign="middle" >1</td></tr><tr><td align="center" valign="middle" >X14</td><td align="center" valign="middle" >0.095310948</td><td align="center" valign="middle" >0.209369465</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0.013227513</td><td align="center" valign="middle" >0.087301587</td><td align="center" valign="middle" >1</td></tr><tr><td align="center" valign="middle" >X15</td><td align="center" valign="middle" >0.293213502</td><td align="center" valign="middle" >0.257802866</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0.248390064</td><td align="center" valign="middle" >0.482980681</td><td align="center" valign="middle" >1</td></tr><tr><td align="center" valign="middle" >X16</td><td align="center" valign="middle" >0.080208706</td><td align="center" valign="middle" >0.13865415</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0.015503876</td><td align="center" valign="middle" >0.03875969</td><td align="center" valign="middle" >0.108527132</td><td align="center" valign="middle" >1</td></tr><tr><td align="center" valign="middle" >X17</td><td align="center" valign="middle" >0.021442622</td><td align="center" valign="middle" >0.122848244</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0.004158277</td><td align="center" valign="middle" >0.006342356</td><td align="center" valign="middle" >0.007654115</td><td align="center" valign="middle" >1</td></tr><tr><td align="center" valign="middle" >X18</td><td align="center" valign="middle" >0.307692308</td><td align="center" valign="middle" >0.233985987</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0.111111111</td><td align="center" valign="middle" >0.222222222</td><td align="center" valign="middle" >0.388888889</td><td align="center" valign="middle" >1</td></tr></tbody></table></table-wrap><p>表4. 标准化后各项指标统计数据</p><p>召回率和f1-score见表5。</p><p>具体的评级预测结果见表6。</p><p>该混淆矩阵中对角线的元素表示模型正确预测数，对角元素之和表示模型整体预测正确的样本数。而非对角线元素上的值则可以反映模型在哪些类的预测上容易犯错，例如评级2均有三次被预测为0和1。</p><p>最终分类正确率：0.866666666667。</p></sec><sec id="s6_4"><title>4.4. 模型性能提升</title><p>各项指标可以进一步提高，我们进行参数调优，可以改善模型性能，进一步提升模型效果。</p><p>首先是核函数，通过循环依次取不同的核函数，准确率见表7。</p><p>可以看到，最好的是“rbf”这个核函数，可将正确率提升至：0.883333333333。</p><p>核函数确定后，我们再来看C的取值。第一次给定这样一个列表：c_list = [0.01,0.1,1,10,100,500]，循环依次取值，准确率见表8。</p><p>可以看到，在C = 500左右模型效果提升很大，可以进一步探究C = 500左右的正确率变化情况。所以给定这样一个列表c_list2 = [100,200,300,400,500,600]，循环依次取值，准确率见表9。</p><p>可以发现C = 500时模型效果确实不错，可将正确率提升至：0.933333333333，评价指标及混淆矩阵见表10和表11。</p><p>为了进一步提升模型的效果，我们重点关注惩罚因子C是否会有更优的取值。因为求SVM最优参</p><table-wrap id="table5" ><label><xref ref-type="table" rid="table5">Table 5</xref></label><caption><title> Model evaluation inde</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" >precision</th><th align="center" valign="middle" >recall</th><th align="center" valign="middle" >f1-score</th><th align="center" valign="middle" >support</th></tr></thead><tr><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0.85</td><td align="center" valign="middle" >0.96</td><td align="center" valign="middle" >0.9</td><td align="center" valign="middle" >24</td></tr><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" >0.88</td><td align="center" valign="middle" >0.96</td><td align="center" valign="middle" >0.92</td><td align="center" valign="middle" >23</td></tr><tr><td align="center" valign="middle" >2</td><td align="center" valign="middle" >0.88</td><td align="center" valign="middle" >0.54</td><td align="center" valign="middle" >0.67</td><td align="center" valign="middle" >13</td></tr><tr><td align="center" valign="middle" >avg/total</td><td align="center" valign="middle" >0.87</td><td align="center" valign="middle" >0.87</td><td align="center" valign="middle" >0.86</td><td align="center" valign="middle" >60</td></tr></tbody></table></table-wrap><p>表5. 模型评价指标</p><table-wrap id="table6" ><label><xref ref-type="table" rid="table6">Table 6</xref></label><caption><title> Model rating result</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" >0</th><th align="center" valign="middle" >1</th><th align="center" valign="middle" >2</th></tr></thead><tr><td align="center" valign="middle" >0</td><td align="center" valign="middle" >23</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >1</td></tr><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >22</td><td align="center" valign="middle" >0</td></tr><tr><td align="center" valign="middle" >2</td><td align="center" valign="middle" >3</td><td align="center" valign="middle" >3</td><td align="center" valign="middle" >7</td></tr></tbody></table></table-wrap><p>表6. 模型评级结果</p><table-wrap id="table7" ><label><xref ref-type="table" rid="table7">Table 7</xref></label><caption><title> The corresponding accuracy of each kernel functio</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >kernel</th><th align="center" valign="middle" >Accuracy</th></tr></thead><tr><td align="center" valign="middle" >linear</td><td align="center" valign="middle" >0.866667</td></tr><tr><td align="center" valign="middle" >rbf</td><td align="center" valign="middle" >0.883333</td></tr><tr><td align="center" valign="middle" >poly</td><td align="center" valign="middle" >0.633333</td></tr><tr><td align="center" valign="middle" >sigmoid</td><td align="center" valign="middle" >0.4</td></tr></tbody></table></table-wrap><p>表7. 各核函数对应准确率</p><table-wrap id="table8" ><label><xref ref-type="table" rid="table8">Table 8</xref></label><caption><title> The corresponding accuracy of each C valu</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >C</th><th align="center" valign="middle" >Accuracy</th></tr></thead><tr><td align="center" valign="middle" >0.01</td><td align="center" valign="middle" >0.4</td></tr><tr><td align="center" valign="middle" >0.1</td><td align="center" valign="middle" >0.4</td></tr><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" >0.433333</td></tr><tr><td align="center" valign="middle" >10</td><td align="center" valign="middle" >0.65</td></tr><tr><td align="center" valign="middle" >100</td><td align="center" valign="middle" >0.816667</td></tr><tr><td align="center" valign="middle" >500</td><td align="center" valign="middle" >0.933333</td></tr></tbody></table></table-wrap><p>表8. 各C值对应准确率</p><table-wrap id="table9" ><label><xref ref-type="table" rid="table9">Table 9</xref></label><caption><title> The corresponding accuracy of each C valu</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >C</th><th align="center" valign="middle" >Accuracy</th></tr></thead><tr><td align="center" valign="middle" >100</td><td align="center" valign="middle" >0.816667</td></tr><tr><td align="center" valign="middle" >200</td><td align="center" valign="middle" >0.883333</td></tr><tr><td align="center" valign="middle" >300</td><td align="center" valign="middle" >0.9</td></tr><tr><td align="center" valign="middle" >400</td><td align="center" valign="middle" >0.916667</td></tr><tr><td align="center" valign="middle" >500</td><td align="center" valign="middle" >0.933333</td></tr><tr><td align="center" valign="middle" >600</td><td align="center" valign="middle" >0.933333</td></tr></tbody></table></table-wrap><p>表9. 各C值对应准确率</p><table-wrap id="table10" ><label><xref ref-type="table" rid="table1">Table 1</xref>0</label><caption><title> Model evaluation inde</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" >precision</th><th align="center" valign="middle" >recall</th><th align="center" valign="middle" >f1-score</th><th align="center" valign="middle" >support</th></tr></thead><tr><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0.92</td><td align="center" valign="middle" >0.96</td><td align="center" valign="middle" >0.94</td><td align="center" valign="middle" >24</td></tr><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" >0.96</td><td align="center" valign="middle" >0.96</td><td align="center" valign="middle" >0.96</td><td align="center" valign="middle" >23</td></tr><tr><td align="center" valign="middle" >2</td><td align="center" valign="middle" >0.92</td><td align="center" valign="middle" >0.85</td><td align="center" valign="middle" >0.88</td><td align="center" valign="middle" >13</td></tr><tr><td align="center" valign="middle" >avg/total</td><td align="center" valign="middle" >0.93</td><td align="center" valign="middle" >0.93</td><td align="center" valign="middle" >0.93</td><td align="center" valign="middle" >60</td></tr></tbody></table></table-wrap><p>表10. 模型评价指标</p><table-wrap id="table11" ><label><xref ref-type="table" rid="table1">Table 1</xref>1</label><caption><title> Model rating result</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" >0</th><th align="center" valign="middle" >1</th><th align="center" valign="middle" >2</th></tr></thead><tr><td align="center" valign="middle" >0</td><td align="center" valign="middle" >23</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >1</td></tr><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >22</td><td align="center" valign="middle" >0</td></tr><tr><td align="center" valign="middle" >2</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >11</td></tr></tbody></table></table-wrap><p>表11. 模型评级结果</p><p>数本质上是一个二次凸规划问题，即求解函数最优值，而遗传算法最主要的用处就是函数最优化。因为遗传算法是一种高效的随机搜索算法，而且克服了诸如网格搜索法等容易陷入局部最优的缺点，可以通过多次尝试，找到全局最优解。同时遗传算法也会同时考虑kernel参数，避免模型出现过拟合现象 [<xref ref-type="bibr" rid="hanspub.23439-ref5">5</xref>] 。我们基于遗传算法的SVM算法如下：</p><p>步骤1：初始化种群，随机生成初始种群个体；</p><p>步骤2：将种群中各个体基因串解码为相应核函数编号、核函数参数和错误惩罚因子，并将参数代入SVM，以训练数据和测试数据对其进行训练和测试；</p><p>步骤3：按照适应度计算法则，计算每个个体的适应度值；</p><p>步骤4：判断是否满足终止条件，如果满足终止条件，退出循环，遗传优化结束，得到优化参数组合，否则转到步骤5；</p><p>步骤5：执行选择算子，按照最优保存、最差取代的原则进行；</p><p>步骤6：执行交叉算子和变异算子，交叉概率取0.7，变异概率取0.1，形成新一代个体后，返回步骤2继续执行。</p><p>我们用这个模型来进行参数优化，最终选取核函数“rbf”以及惩罚因子C = 700，评价指标及混淆矩阵见表12和表13。</p><p>正确率可以达到：0.966666666667。</p></sec><sec id="s6_5"><title>4.5. 模型对照</title><p>为了更好的说明模型效果，我们以逻辑回归模型作为对比，且选择调优后的参数，这里C = 1000，penalty = “l1”，solver = “liblinear”，评价指标及混淆矩阵见表14和表15。</p><p>正确率可以达到：0.85，效果不如SVM模型。</p></sec></sec><sec id="s7"><title>5. 结论</title><p>通过对我国小微企业风险评级的研究，我们发现：</p><p>1) 与逻辑回归方法相比，SVM方法在准确率等各项评价指标都明显更优，而且可以通过参数调优不断提升指标，从而更好的对企业风险进行评级。该方法对小微企业风险评价与预测这一复杂的领域有</p><table-wrap id="table12" ><label><xref ref-type="table" rid="table1">Table 1</xref>2</label><caption><title> Model evaluation inde</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" >precision</th><th align="center" valign="middle" >recall</th><th align="center" valign="middle" >f1-score</th><th align="center" valign="middle" >support</th></tr></thead><tr><td align="center" valign="middle" >0</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >0.96</td><td align="center" valign="middle" >0.98</td><td align="center" valign="middle" >24</td></tr><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" >0.96</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >0.98</td><td align="center" valign="middle" >23</td></tr><tr><td align="center" valign="middle" >2</td><td align="center" valign="middle" >0.92</td><td align="center" valign="middle" >0.92</td><td align="center" valign="middle" >0.92</td><td align="center" valign="middle" >13</td></tr><tr><td align="center" valign="middle" >avg/total</td><td align="center" valign="middle" >0.97</td><td align="center" valign="middle" >0.97</td><td align="center" valign="middle" >0.97</td><td align="center" valign="middle" >60</td></tr></tbody></table></table-wrap><p>表12. 模型评价指标</p><table-wrap id="table13" ><label><xref ref-type="table" rid="table1">Table 1</xref>3</label><caption><title> Model rating result</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" >0</th><th align="center" valign="middle" >1</th><th align="center" valign="middle" >2</th></tr></thead><tr><td align="center" valign="middle" >0</td><td align="center" valign="middle" >23</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >1</td></tr><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >23</td><td align="center" valign="middle" >0</td></tr><tr><td align="center" valign="middle" >2</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >12</td></tr></tbody></table></table-wrap><p>表13. 模型评级结果</p><table-wrap id="table14" ><label><xref ref-type="table" rid="table1">Table 1</xref>4</label><caption><title> Model evaluation inde</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" >precision</th><th align="center" valign="middle" >recall</th><th align="center" valign="middle" >f1-score</th><th align="center" valign="middle" >support</th></tr></thead><tr><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0.92</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >0.96</td><td align="center" valign="middle" >24</td></tr><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" >0.78</td><td align="center" valign="middle" >0.91</td><td align="center" valign="middle" >0.84</td><td align="center" valign="middle" >23</td></tr><tr><td align="center" valign="middle" >2</td><td align="center" valign="middle" >0.86</td><td align="center" valign="middle" >0.46</td><td align="center" valign="middle" >0.6</td><td align="center" valign="middle" >13</td></tr><tr><td align="center" valign="middle" >avg/total</td><td align="center" valign="middle" >0.85</td><td align="center" valign="middle" >0.85</td><td align="center" valign="middle" >0.84</td><td align="center" valign="middle" >60</td></tr></tbody></table></table-wrap><p>表14. 模型评价指标</p><table-wrap id="table15" ><label><xref ref-type="table" rid="table1">Table 1</xref>5</label><caption><title> Model rating result</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" >0</th><th align="center" valign="middle" >1</th><th align="center" valign="middle" >2</th></tr></thead><tr><td align="center" valign="middle" >0</td><td align="center" valign="middle" >24</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >0</td></tr><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >21</td><td align="center" valign="middle" >1</td></tr><tr><td align="center" valign="middle" >2</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >6</td><td align="center" valign="middle" >6</td></tr></tbody></table></table-wrap><p>表15. 模型评级结果</p><p>很重要的指导作用。</p><p>2) 对SVM参数直接调优可以得到更好的效果，本文引入了遗传算法进行参数调优，可以得到最优化的结果。</p></sec><sec id="s8"><title>文章引用</title><p>李 超,王海辉. 基于SVM的小微企业评级Rating of Small and Micro Businesses Based on SVM[J]. 应用数学进展, 2018, 07(01): 10-19. http://dx.doi.org/10.12677/AAM.2018.71003</p></sec><sec id="s9"><title>参考文献 (References)</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.23439-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">侯合银. 高新技术创业企业风险的系统分析: 辨识与规避[J]. 科技管理研究, 2008, 28(10): 132-135.</mixed-citation></ref><ref id="hanspub.23439-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">袁莉, 李宏男. 基于SVM的建筑企业信用评价研究[J]. 价值工程, 2009, 28(3): 141-144.</mixed-citation></ref><ref id="hanspub.23439-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">姚奕, 叶中行. 基于支持向量机的银行客户信用评估系统研究[J]. 系统仿真学报, 2004, 16(4): 783-786.</mixed-citation></ref><ref id="hanspub.23439-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">章兢, 张小刚. 数据挖掘算法及其工程应用[M]. 北京: 机械工业出版社, 2006.</mixed-citation></ref><ref id="hanspub.23439-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Li, L.M., Wen, G.R. and Wang, S.C. (2008) Parameters Selection of Support Vector Regression Based on Genetic Algorithm. Computer Engineering and Applications, 44, 23-26.</mixed-citation></ref></ref-list></back></article>