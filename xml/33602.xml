<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2019.912267</article-id><article-id pub-id-type="publisher-id">CSA-33602</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20191200000_13272066.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  利用文本特征增强与注意力机制提高图像问答准确率
  Improve Image Question and Answer Accuracy by Using Text Feature Enhancement and Attention Mechanism
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>江</surname><given-names>邹</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>蒋</surname><given-names>慕蓉</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>赵</surname><given-names>春娜</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>黄</surname><given-names>亚群</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>云南大学信息学院，云南 昆明</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>29</day><month>11</month><year>2019</year></pub-date><volume>09</volume><issue>12</issue><fpage>2403</fpage><lpage>2410</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   图像问答是深度学习在计算机视觉领域成功应用的主要方向之一，在人工智能、自然语言处理、图像识别等方面有着广泛应用。图像问答的准确率不仅与图像问答系统中特征融合模块的设计有关，而且与图像特征与问题特征语义层次匹配程度有关。本文首先将图像的文本特征和视觉特征融合后作为图像增强特征，之后对问题提取文本特征，再加入注意力机制，将图像增强特征与问题文本特征进行特征融合，对融合特征做出答案预测。实验结果表明，本文方法可以解决图像特征与文本特征层次不匹配的问题，提高图像问答系统的准确率。 Image question and answer is one of the main directions for the successful application of deep learning in the field of computer vision. It has been widely used in artificial intelligence, natural language processing, image recognition and so on. The accuracy of the image question and answer is not only related to the design of the feature fusion module in the image question answering system, but also related to the degree of matching between the image feature and the semantic level of the question feature. In this paper, the text features and visual features of the image are first combined as the enhanced features of the image. Then, the text features are extracted from the question, and then the attention mechanism is added. The enhanced features of the image and the text features of the question are merged, and make answer prediction for fusion features. The experimental results show that the proposed method can solve the problem of mismatch between image features and text features, and improve the accuracy of the image question answering system. 
  
 
</p></abstract><kwd-group><kwd>图像文本特征，图像问答，注意力机制，特征增强, Text Feature of the Image</kwd><kwd> Image Q&amp;A</kwd><kwd> Attention Mechanism</kwd><kwd> Feature Enhancement</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>利用文本特征增强与注意力机制提高图像问答准确率<sup> </sup></title><p>江邹，蒋慕蓉<sup>*</sup>，赵春娜，黄亚群</p><p>云南大学信息学院，云南 昆明</p><p>收稿日期：2019年12月5日；录用日期：2019年12月18日；发布日期：2019年12月25日</p><disp-formula id="hanspub.33602-formula29"><graphic xlink:href="//html.hanspub.org/file/24-1541613x6_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>图像问答是深度学习在计算机视觉领域成功应用的主要方向之一，在人工智能、自然语言处理、图像识别等方面有着广泛应用。图像问答的准确率不仅与图像问答系统中特征融合模块的设计有关，而且与图像特征与问题特征语义层次匹配程度有关。本文首先将图像的文本特征和视觉特征融合后作为图像增强特征，之后对问题提取文本特征，再加入注意力机制，将图像增强特征与问题文本特征进行特征融合，对融合特征做出答案预测。实验结果表明，本文方法可以解决图像特征与文本特征层次不匹配的问题，提高图像问答系统的准确率。</p><p>关键词 :图像文本特征，图像问答，注意力机制，特征增强</p><disp-formula id="hanspub.33602-formula30"><graphic xlink:href="//html.hanspub.org/file/24-1541613x7_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2019 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/24-1541613x8_hanspub.png" /> <img src="//html.hanspub.org/file/24-1541613x9_hanspub.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>图像问答是指给定一张图像和一个用自然语言描述的问题，计算机能自主根据图像内容做出相应回答的过程，它是深度学习在计算机视觉领域成功应用的主要研究方向之一。随着人工智能、自然语言处理、深度学习、图像识别等技术的发展，图像问答在汽车导航、盲人识路、机器人系统等领域有广泛应用 [<xref ref-type="bibr" rid="hanspub.33602-ref1">1</xref>]。</p><p>图像问答的实现方式主要采用CNN-RNN框架 [<xref ref-type="bibr" rid="hanspub.33602-ref2">2</xref>] [<xref ref-type="bibr" rid="hanspub.33602-ref3">3</xref>] [<xref ref-type="bibr" rid="hanspub.33602-ref4">4</xref>]。其中，CNN为卷积神经网络，主要用于图像特征提取，RNN为循环神经网络，主要对问题文本特征的提取。由于CNN使用了全局图像特征来表示输入图像，会导致一些无关或噪音信息输入到问答模块，对生成答案造成干扰，因此，将注意力机制引入到CNN-RNN框架中并与图像问答相结合的方法已成为图像问答系统的主流方法 [<xref ref-type="bibr" rid="hanspub.33602-ref5">5</xref>]。Li等人 [<xref ref-type="bibr" rid="hanspub.33602-ref6">6</xref>] 提出基于属性和描述的图像问答并引入注意力机制，将任务拆分为解释和推理两个步骤，首先理解图像的内容，然后根据理解对答案进行推理。Yuan等人 [<xref ref-type="bibr" rid="hanspub.33602-ref7">7</xref>] 提出基于图像全局–局部特征以及注意力机制的图像文本描述算法，充分利用了图像的全局和局部特征。Liu等人 [<xref ref-type="bibr" rid="hanspub.33602-ref8">8</xref>] 提出构建联合多图像特征的Global-Local Fusion模型来做信息增广，采用混阶注意力模型来提取与问题相关的局部特征信息。Yu等人 [<xref ref-type="bibr" rid="hanspub.33602-ref9">9</xref>] 提出基于图注意力网络的视觉问答，将注意力机制先后用于图像的一元表达和二元表达上，把图像建模成一个图模型，图注意力模型就是在图像的图结构表达上进行推理。Lin等人 [<xref ref-type="bibr" rid="hanspub.33602-ref10">10</xref>] 提出多级注意力机制视觉问答模型，基于注意力机制的算法，利用问题的多重文本粒度来融合各种特征。这些方法都是使用CNN提取图像视觉特征与问题文本特征直接进行融合，再加入注意力机制生成每个图像区域的权重，视觉特征的不完整以及权重的选取都会导致图像特征与问题特征语义层次的不匹配，影响图像问答的结果。</p><p>针对图像特征与问题特征语义层次不匹配的问题，本文分别对图像进行视觉特征提取和图像文本特征提取并将两种特征合并后作为图像的增强特征，然后再对问题提取问题文本特征，采用MCB的融合方式进行特征融合，最后模型对融合特征做出答案预测。在问题的特征提取中采用了长短期记忆网络LSTM，在图像的特征提取中采用VGG-16模型和Neural模型相结合的方法，提取图像的视觉特征和文本特征，并将两种特征融合作为图像的增强特征与问题文本特征进行MCB融合后进行答案预测，提高图像问答系统的准确率。</p></sec><sec id="s4"><title>2. 本文方法描述</title><p>图像问答是指用一幅图像和一个与该图像内容相关的问题作为输入，要求系统最终输出该问题的正确答案。本文实现步骤描述如下：将图像传入Neural模型生成图像的文本特征，同时传入改进后的VGG-16模型生成图像的视觉特征，引入注意力机制并将两者特征融合作为图像的增强特征，然后再将问题的文本特征提取，将两种特征采用MCB方式融合并依次通过全连接层和Softmax层分类后，得到最终的结果。模型架构如图1所示：</p><p>图1. 模型架构</p><sec id="s4_1"><title>2.1. 提取图像增强特征</title><p>提取图像特征是指将一张以像素形式的图像输入，输出为具有高层语义信息的特征向量v。作为特征提取器的卷积神经网络都是在ImageNet图像识别任务中提出的标准模型，常见的有VGG-16、VGG-19、GoogLe-Net以及ResNet，借助这些CNN模型能够间接的利用ImageNet上的大量训练数据对图像进行更好的特征提取。本文采用VGG-16预训练模型，去掉模型的最后两层，从全连接层提取具有4096维的特征，作为图像的视觉特征v1。</p><p>图2为模型经过第一层处理后得到的卷积和池化特征图。图3为模型经过提取具有4096维特征的特征图。</p><p>图2. (a) 第一层卷积特征图；(b) 第一层池化特征图</p><p>图3. (a) 卷积后的特征图；(b) 池化后的特征图</p><p>为获取图像的文本特征。本文采用Neural模型来生成图像对应的文本描述。输入一幅图像，采用随机采样得到第一个单词，然后将其输入到长短期记忆网络LSTM中得到第二个单词，一直重复操作直到结束符号或者达到预先设定的句子最大长度，这样就得到了图像的文本描述，再利用最大化后验概率对该文本描述进行验证。经过反复学习，最终输出描述图像内容的一句话，作为该图像的文本特征v2。</p><p>图4为利用Neural模型生成的图像文本特征样例。</p><p>图4. 图像文本样例</p><p>将图像视觉特征v1与图像文本特征v2进行MCB融合，即可得到图像特征v。即利用两个特征的外积来计算：</p><p>v 1 ⊗ v 2 = v 1 v 2 T (1)</p><p>将图像视觉特征v1与图像文本特征v2进行外积运算后线性变换W，得到隐含表达z，</p><p>z = W [ v 1 ⊗ v 2 ] (2)</p><p>再将表达z经过卷积/FFT得到融合后的结果即为图像增强特征v。</p></sec><sec id="s4_2"><title>2.2. 提取问题文本特征</title><p>提取问题文本特征是指输入一个以英文问句形式输入的问题 Q = { w 1 , ⋯ , w N } ，(其中 w i 是将问题分词后得到的英文单词，N为问题的长度)，输出为问题的特征向量q。</p><p>首先需要将英文单词表示为词向量。假设V是语料库确定的词典，则每个单词首先将会被转换为 | V | 维的one-hot向量。经过one-hot编码后的问题为 Q o = { w 1 o , ⋯ , w N o } ，随后每个单词的one-hot向量将被嵌入到词向量空间中：</p><p>Q e = W e Q o (3)</p><p>其中 W e 的第i列是V中第i个单词对应的词向量表达。</p><p>然后，利用LSTM对词向量 Q e 进行编码，得到一个固定长度的特征向量q。</p><p>图5为问题文本特征提取的流程图。</p><p>图5. 问题特征提取流程图</p></sec><sec id="s4_3"><title>2.3. 将注意力机制加入到图像特征提取中</title><p>注意力机制就是从一系列局部特征 X = [ x 1 , ⋯ , x n ] 中寻找与引导条件g最相关的部分。加入注意力机制操作可分为两步：第一步是为每个局部特征 x i 产生一个权重 a i 用于表明该局部特征与引导特征g之间的相关性，然后利用 S i = a i / ∑ j a j 计算出每个 x i 对应softmax值，来表示每个 x i 获得关注的概率大小；第二步是求所有局部特征的加权和，得到的向量 x ˜ 代表根据引导条件g在输入特征X上的关注结果。</p><p>图6为在图像特征提取中引入注意力机制得到的焦点图。</p><p>图6. 视觉注意力机制感兴趣的焦点图</p></sec><sec id="s4_4"><title>2.4. 将图像特征和问题特征融合</title><p>将图像特征v和问题特征q进行MCB融合，得到融合后的特征m。</p></sec><sec id="s4_5"><title>2.5. 答案预测</title><p>首先根据训练集确定一些比较常见的答案组成候选答案集A，然后将每个候选答案看作一个类，预测正确答案在候选答案集A上的概率分布，最后取概率最大的候选答案 a ˜ 作为预测结果，计算公式如(4)所示。</p><p>a ˜ = max { P ( a | I , Q ) } (4)</p><p>其中，预测答案a一般采用多层感知机MLP加Softmax函数实现。</p></sec></sec><sec id="s5"><title>3. 实验结果分析</title><sec id="s5_1"><title>3.1. 评价指标</title><p>对应每一个问题，假设系统输出的答案为a，对于该答案是否正确，本文采用的是VQA官网 [<xref ref-type="bibr" rid="hanspub.33602-ref11">11</xref>] 给出的评价标准：</p><p>A c c ( a ) = min ( 1 , ∑ 1 k I ( a i = a ) 3 )</p><p>在上面公式中， a 1 , a 2 , ⋯ , a k 是每个问题的正确标注答案的集合，k一般取值为10，预测答案只要与3个及以上的标注答案一致，即被认为是正确的。</p></sec><sec id="s5_2"><title>3.2. 实验数据集</title><p>本文采用的数据集为VQA2.0 [<xref ref-type="bibr" rid="hanspub.33602-ref11">11</xref>]，其中训练集有82,783张图像，443,757个问题；验证集有40,504张图像，214,354个问题；测试集有81,434张图像，447,793个问题。在VQA2.0中，每一张图像平均有5个问题，每个问题有10个预选答案。图像、问题和答案之间存在着一一对应的关系。</p></sec><sec id="s5_3"><title>3.3. 实验结果与分析</title><p>图7为本文实验的部分结果。</p><p>图7. 图像问答实例</p><p>为了验证本文方法的有效性，选取VQA官网上的几个相关模型与本文模型在VQA2.0数据集上进行对比，结果如表1所示。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Results of each model on the datase</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >model</th><th align="center" valign="middle" >yes/no</th><th align="center" valign="middle" >number</th><th align="center" valign="middle" >other</th><th align="center" valign="middle" >overall</th></tr></thead><tr><td align="center" valign="middle" >Prior [<xref ref-type="bibr" rid="hanspub.33602-ref11">11</xref>]</td><td align="center" valign="middle" >61.26</td><td align="center" valign="middle" >0.40</td><td align="center" valign="middle" >1.26</td><td align="center" valign="middle" >26.13</td></tr><tr><td align="center" valign="middle" >Language-only [<xref ref-type="bibr" rid="hanspub.33602-ref11">11</xref>]</td><td align="center" valign="middle" >67.88</td><td align="center" valign="middle" >30.59</td><td align="center" valign="middle" >29.13</td><td align="center" valign="middle" >46.21</td></tr><tr><td align="center" valign="middle" >d-LSTM + n-I [<xref ref-type="bibr" rid="hanspub.33602-ref11">11</xref>]</td><td align="center" valign="middle" >72.23</td><td align="center" valign="middle" >36.20</td><td align="center" valign="middle" >39.68</td><td align="center" valign="middle" >56.27</td></tr><tr><td align="center" valign="middle" >Our-1</td><td align="center" valign="middle" >78.82</td><td align="center" valign="middle" >38.56</td><td align="center" valign="middle" >51.26</td><td align="center" valign="middle" >59.86</td></tr><tr><td align="center" valign="middle" >Our-2</td><td align="center" valign="middle" >83.37</td><td align="center" valign="middle" >44.29</td><td align="center" valign="middle" >55.39</td><td align="center" valign="middle" >63.45</td></tr></tbody></table></table-wrap><p>表1. 各模型在数据集上的结果</p><p>其中“yes/no”、“number”以及“other”分别对应三种不同答案类型下模型预测答案的正确率，“overall”则是在对应数据集上的总体表现。Prior表示用训练集上最常见的答案来回答测试集上的问题，Language-only是仅利用问题对答案去进行预测，采用的是单个LSTM架构，d-LSTM + n-I是一个基础视觉问答模型，Our-1是未进行图像文本特征提取的模型，Our-2是把图像文本特征和视觉特征融合作为最终图像特征的模型。从表1中可以看出，答案为yes/no类型的问题，本文模型准确率在80%左右，比前面所提到的模型准确率高出10%左右；答案为number类型的问题，本文模型准确率在40%左右，比前面所提到的模型准确率高出8%左右；答案为other类型的问题，本文模型准确率在55%左右，比前面所提到的模型准确率高出15%左右；总体来说本文模型准确率比前面所提到的模型准确率高出10%左右。Our-1模型是未提取图像文本特征直接采用图像的视觉特征作为图像特征的模型，与模型Our-2相比，各种类型的问题准确率均高出5%左右，由此可见，本文所提出的模型，利用图像文本特征和视觉特征融合后作为图像的增强特征，图像问答的准确率较高。</p></sec></sec><sec id="s6"><title>4. 总结</title><p>本文对图像分别进行视觉特征提取和文本特征提取，并将两种特征融合为最终的图像特征，目的是从多个角度来真正的理解图像中的内容；再加入注意力机制，可以在推理答案的过程中更加关注图像与问题对应部分的信息，而不是将图像和问题进行粗略的处理，进一步加强了图像局部特征与问题特征的相关性，提高了图像问答系统预测答案的准确度。</p><p>从实验结果来看，虽然本文使用的模型能达到不错的效果，仍然存在一定不足：</p><p>1) 本文方法对于“yes/no”问题的回答效果相较于其它问题来说虽然表现最好，但离一个成熟的图像问答系统来说，回答此类问题的准确率还需要进一步提高。</p><p>2) 本文方法对于“number”问题的回答效果较差，这是由于所用的神经网络对于少数或者边界比较模糊或者有遮挡物的物体识别准确率不高导致的，需要对神经网络模型做进一步改进。</p></sec><sec id="s7"><title>基金项目</title><p>国家自然科学基金(61862062)和云南省高校科技创新团队支持计划项目(IRTSTYN)。</p></sec><sec id="s8"><title>文章引用</title><p>江 邹,蒋慕蓉,赵春娜,黄亚群. 利用文本特征增强与注意力机制提高图像问答准确率Improve Image Question and Answer Accuracy by Using Text Feature Enhancement and Attention Mechanism[J]. 计算机科学与应用, 2019, 09(12): 2403-2410. https://doi.org/10.12677/CSA.2019.912267</p></sec><sec id="s9"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.33602-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">张天. 用于图像问答的深层注意力网络结构研究[D]: [硕士学位论文]. 云南: 云南大学, 2017.</mixed-citation></ref><ref id="hanspub.33602-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Malinowski, M. and Fritz, M. (2014) Multi-World Approach to Question Answering about Real-World Scenes Based on Uncertain Input. Proceedings of the Advances in Neural Information Processing Systems, Montreal, 8-13 December 2014, 1682-1690.</mixed-citation></ref><ref id="hanspub.33602-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Gao, H., Mao, J., Zhou, J., et al. (2015) Are You Talking to a Machine? Dataset and Methods for Mul-tilingual Image Question. Proceedings of the Advances in Neural Information Processing Systems, Cornell University, Ithaca, New York, 2 November 2015, 2296-2304.</mixed-citation></ref><ref id="hanspub.33602-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Malinowski, M., Rohrbach, M. and Fritz, M. (2015) Ask Your Neurons: A Neural-Based Approach to Answering Questions about Images. Proceedings of the IEEE International Conference on Computer Vision, Santiago, 7-13 December 2015, 1-9. &lt;br&gt;https://doi.org/10.1109/ICCV.2015.9</mixed-citation></ref><ref id="hanspub.33602-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Wu, Q., Shen, C., Liu, L., et al. (2016) What Value Do Explicit High Level Concepts Have in Vision to Language Problems? Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Las Vegas, 27-30 June 2016, 203-212. &lt;br&gt;https://doi.org/10.1109/CVPR.2016.29</mixed-citation></ref><ref id="hanspub.33602-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">李庆. 基于深度神经网络和注意力机制的图像问答研究[D]: [硕士学位论文]. 合肥: 中国科学技术大学, 2018.</mixed-citation></ref><ref id="hanspub.33602-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">袁爱红. 图像内容的语义描述与理解[D]: [博士学位论文]. 陕西: 中国科学院大学, 2018.</mixed-citation></ref><ref id="hanspub.33602-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">刘瑾莱. 基于深层神经网络推理的图像问答技术研究和应用[D]: [硕士学位论文]. 北京: 北京邮电大学, 2019.</mixed-citation></ref><ref id="hanspub.33602-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">于东飞. 基于注意力机制与高层语义的视觉问答研究[D]: [博士学位论文]. 合肥: 中国科学技术大学, 2019.</mixed-citation></ref><ref id="hanspub.33602-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">林靖豪. 用于视频问答的多级注意力循环神经网络算法研究[D]: [硕士学位论文]. 杭州: 浙江大学, 2018.</mixed-citation></ref><ref id="hanspub.33602-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">https://visualqa.org/.</mixed-citation></ref></ref-list></back></article>