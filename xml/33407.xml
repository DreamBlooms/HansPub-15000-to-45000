<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">HJDM</journal-id><journal-title-group><journal-title>Hans Journal of Data Mining</journal-title></journal-title-group><issn pub-type="epub">2163-145X</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/HJDM.2020.101002</article-id><article-id pub-id-type="publisher-id">HJDM-33407</article-id><article-categories><subj-group subj-group-type="heading"><subject>HJDM20200100000_56401303.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于模式感知元分块技术的Web实体解析算法
  Web Entity Resolution Algorithm Based on Schema-Aware Meta-Blocking Technology
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>韦</surname><given-names>海浪</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>李</surname><given-names>贵</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>李</surname><given-names>征宇</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>韩</surname><given-names>子扬</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>曹</surname><given-names>科研</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib></contrib-group><aff id="aff1"><addr-line>沈阳建筑大学信息与控制工程学院，辽宁 沈阳</addr-line></aff><aff id="aff2"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>11</day><month>12</month><year>2019</year></pub-date><volume>10</volume><issue>01</issue><fpage>16</fpage><lpage>29</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
  实体解析ER (Entity Resolution)是识别一个或多个数据源中同一实体记录。对于在多数据源中直接比较每对记录计算复杂度较大的问题，通常采用分块的方法。由于在Web数据源中大部分是模式未知的，通常采用元分块技术，虽然减少了丢失可能的匹配，但是增加了在同一块中放置不匹配实体记录的可能性。为此提出了一种基于局部敏感哈希的属性匹配归纳法从多个Web大数据集中对属性进行匹配划分，去除了属性间冗余的比较；然后通过一种基于聚合熵加权图的元分块技术，来提高Web数据源的分块质量，去除了分块中实体记录之间多余的比较，降低了算法的复杂度。最后采用实际数据集进行实验验证了该算法的有效性。
   Entity Resolution is the identification of the same Entity record in one or more data sources. For problems with high complexity of directly comparing each pair of records in multiple data sources, chunking is usually adopted. Since most of the Schema are unknown in Web data sources, Me-ta-blocking techniques are commonly used, which reduce the possibility of missing matches but in-crease the possibility of placing mismatched entity records in the same block. To solve the above problems, an attribute matching induction method based on locally sensitive hashing is proposed to conduct attribute’s matching division from multiple Web big data sets to remove redundant com-parison among attributes. Then, a block technique based on aggregation entropy weighted graph is used to improve the block quality of Web data sets, remove redundant comparisons in the blocks and reduce the complexity of the algorithm. Finally, the effectiveness of the algorithm is verified by experiments with actual data sets.
 
</p></abstract><kwd-group><kwd>实体解析，聚合熵，元分块，局部敏感哈希, Entity Resolution</kwd><kwd> Aggregation Entropy</kwd><kwd> Meta-Blocking</kwd><kwd> Locally Sensitive Hash</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>基于模式感知元分块技术的Web实体解析算法<sup> </sup></title><p>韦海浪，李贵，李征宇，韩子扬，曹科研</p><p>沈阳建筑大学信息与控制工程学院，辽宁 沈阳</p><p><img src="//html.hanspub.org/file/2-1760189x1_hanspub.png" /></p><p>收稿日期：2019年11月19日；录用日期：2019年12月4日；发布日期：2019年12月11日</p><disp-formula id="hanspub.33407-formula24"><graphic xlink:href="//html.hanspub.org/file/2-1760189x5_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>实体解析ER (Entity Resolution)是识别一个或多个数据源中同一实体记录。对于在多数据源中直接比较每对记录计算复杂度较大的问题，通常采用分块的方法。由于在Web数据源中大部分是模式未知的，通常采用元分块技术，虽然减少了丢失可能的匹配，但是增加了在同一块中放置不匹配实体记录的可能性。为此提出了一种基于局部敏感哈希的属性匹配归纳法从多个Web大数据集中对属性进行匹配划分，去除了属性间冗余的比较；然后通过一种基于聚合熵加权图的元分块技术，来提高Web数据源的分块质量，去除了分块中实体记录之间多余的比较，降低了算法的复杂度。最后采用实际数据集进行实验验证了该算法的有效性。</p><p>关键词 :实体解析，聚合熵，元分块，局部敏感哈希</p><disp-formula id="hanspub.33407-formula25"><graphic xlink:href="//html.hanspub.org/file/2-1760189x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2020 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/2-1760189x7_hanspub.png" /> <img src="//html.hanspub.org/file/2-1760189x8_hanspub.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>现阶段，实体解析问题是数据质量领域比较热门的研究领域。正如基于Web的实体和关系的挖掘来建立大型通用知识库那样，只有将不同的数据源集成时，这些数据的真正价值才会被挖掘出来以供企业、政府和研究人员利用 [<xref ref-type="bibr" rid="hanspub.33407-ref1">1</xref>]。</p><p>实体解析指的是识别一个或多个数据源中同一实体记录的任务 [<xref ref-type="bibr" rid="hanspub.33407-ref2">2</xref>]。对实体集合中所有可能匹配的记录进行比较是一个二次方问题。因此在庞大的数据集中采用传统的比较方法是不切实际的。为此，通常将类似的记录分块，然后只比较那些出现在同一块中的记录可以提高实体解析算法的效率。但是对于多个数据源中的数据来说，通常有着不同的模式，那么数据源之间的模式匹配就必须在实体解析之前进行。而对于Web上大量高度异构和有噪音的数据来说，传统的模式匹配将不再适用。目前主要采用模式未知(Schema-agnostic)的模块划分方法解决这个问题。传统的模式未知分块技术是标记分块(Token blocking) [<xref ref-type="bibr" rid="hanspub.33407-ref3">3</xref>] [<xref ref-type="bibr" rid="hanspub.33407-ref4">4</xref>]。这种技术指的是将数据集中出现的每个标记数据(Token)都看作是一个模块划分键 [<xref ref-type="bibr" rid="hanspub.33407-ref2">2</xref>]。因此，每个分块会与一个标记数据相关联，并且包含这个标记数据出现的所有实体记录。标记分块可将每个记录都放置在多个分块中，虽然减少了丢失可能的匹配，但是却增加了不匹配的实体记录放置在同一个块中的可能性。本文在采用基于局部敏感哈希的属性匹配归纳的基础上引入并改进了一种松散模式感知的元分块技术 [<xref ref-type="bibr" rid="hanspub.33407-ref5">5</xref>] [<xref ref-type="bibr" rid="hanspub.33407-ref6">6</xref>]，在保证较高的召回率的同时，也提高了精准率。</p><p>本文主要贡献如下：</p><p>1) 将具有大量属性的Web源数据集中的属性依据信息熵和等价类的方法进行属性选择和分类，以减少数据集中的不相关属性的比较；</p><p>2) 引入了局部敏感哈希的预处理步骤，将属性匹配归纳法(Attribute-match induction)应用到具有大量属性的Web数据集中，利用属性匹配归纳法进行属性匹配和划分，以减少不相关的属性之间冗余比较；</p><p>3) 依据属性匹配和划分的模式信息，利用改进了的基于聚合熵加权图的元分块方法消除了多余比较；</p><p>4) 最后对该算法进行了实验验证。</p></sec><sec id="s4"><title>2. 相关工作</title><p>在实体解析(ER)中为了提高效率通常采用分块技术 [<xref ref-type="bibr" rid="hanspub.33407-ref7">7</xref>] [<xref ref-type="bibr" rid="hanspub.33407-ref8">8</xref>]，现阶段的分块技术分为两大类：一类是基于模式的分块技术，有后缀数组(Suffix Array) [<xref ref-type="bibr" rid="hanspub.33407-ref3">3</xref>]，q-grams [<xref ref-type="bibr" rid="hanspub.33407-ref9">9</xref>]，和Canopy Clustering [<xref ref-type="bibr" rid="hanspub.33407-ref10">10</xref>] 等方法，另一类是模式未知的分块技术，例如：标记分块(Token Blocking) [<xref ref-type="bibr" rid="hanspub.33407-ref4">4</xref>] 和属性匹配归纳法(Attribute-match induction) [<xref ref-type="bibr" rid="hanspub.33407-ref4">4</xref>] [<xref ref-type="bibr" rid="hanspub.33407-ref11">11</xref>]。</p><p>在模式未知的分块技术中，属性聚类(Attribute Clusting) [<xref ref-type="bibr" rid="hanspub.33407-ref4">4</xref>] 和文献 [<xref ref-type="bibr" rid="hanspub.33407-ref6">6</xref>] 中的方法TYPiMatch将统计出来的数据信息提取到特定的分块键中。属性聚类依赖于对数据集中所有可能匹配的属性进行比较，而对于那些相似度较高的属性对来说，这是一个低效的过程，因为绝大多数的比较都是多余的。本文基于局部敏感哈希的预处理步骤旨在解决这个问题。TYPiMatch [<xref ref-type="bibr" rid="hanspub.33407-ref4">4</xref>] 是在Web通用数据集中从属性集中识别出频繁出现的字段(数值，字符串)，并使用这些信息来选择分块键，但是它不能有效地扩展到大数据集中。</p><p>元分块 [<xref ref-type="bibr" rid="hanspub.33407-ref5">5</xref>] [<xref ref-type="bibr" rid="hanspub.33407-ref6">6</xref>] 旨在提高数据分块技术产生的块集合质量。现有的元分块技术是完全模式未知的。在本文中采用的是利用Web数据源中松散模式信息的元分块技术，来提高分块质量。</p></sec><sec id="s5"><title>3. 相关概念及理论</title><sec id="s5_1"><title>3.1. 相关概念及评价方法</title><p>实体概要：</p><p>由一个特殊的标识符和一组属性名和属性值组成的元组 { 〈 a 1 , v 1 〉 , 〈 a 2 , v 2 〉 , 〈 a 3 , v 3 〉 , ⋯ , 〈 a n , v n 〉 } 。在这里用 A ε = { a 1 , a 2 , a 3 , ⋯ , a 4 } 表示与实体集合 ε = { p 1 , p 2 , p 3 , ⋯ , p n } 相关联的一组有匹配可能性的属性集。实体</p><p>集合 ε 是一组实体记录。如果两个实体记录 p i , p j ∈ ε 指向现实世界同一个对象那么它们是匹配的( p i ≈ p j )；实体解析(ER)是识别给定的实体集合 ε 中相匹配实体记录的任务。</p><p>实体解析主要分为两种情况：</p><p>1) Clean-Clean ER：输入两个无重复的实体集合 ε 1 和 ε 2 ，并对来自不同数据源中的实体概要</p><p>{ ( p i , p j ) | p i ∈ ε 1 , p j ∈ ε 2 } 进行比较，对Clean-Clean ER最直接的解决方法需要 | ε 1 | &#215; | ε 2 | 次比较；</p><p>2) dirty ER：输入含有重复记录的集合 ε ，并对所有可能匹配的实体概要进行了比较。最直接的解决方法是执行 | ε i | 2 次比较。 | ε i | 是一个实体集合 ε i 的基数。</p><p>实现实体解析的有效途径是对实体概要进行适当的模块划分，即根据模块划分键(索引准则)索引相似的实体概要，将实际的比较限制在同一块中，以减少实体解析算法复杂性。使用 β = { b 1 , b 2 , ⋯ , b i } 表示一组块集合，它的基数 ‖ β ‖ = ∑ b i ∈ β ‖ b i ‖ ，其中 ‖ b i ‖ 是块 b i 中的比较次数。</p><p>本文使用召回率(PC)和精准率(PQ)来评估块集合 β 的质量 [<xref ref-type="bibr" rid="hanspub.33407-ref7">7</xref>]。 P C ( β ) 指检测到的重复实体概要与实际重复实体概要之间的比值； P Q ( β ) 指的是实际的比较次数中有效的比较所占的比率。本文还引入了F<sub>1</sub>-score [<xref ref-type="bibr" rid="hanspub.33407-ref7">7</xref>]。</p><p>公式： P C ( β ) = | D β | | D δ | ； P Q ( β ) = | D β | ‖ β ‖ ； F 1 ( β ) = 2 ⋅ P C ( β ) ⋅ P Q ( β ) P C ( β ) + P Q (β)</p><p>D β 是在块 β 中出现的一组重复实体概要， D δ 是一组在集合 ε 中出现的所有重复实体概要。</p><p>通常情况下，模式未知的模块划分(元分块)可以保证较高的召回率(PC)，但牺牲了精准率(PQ)。低精确率(PQ)是由于多余的比较造成的：冗余的比较指重复的比较一组实体概要；多余的比较是对非匹配的实体概要进行的比较( p i ≈ p j )。</p><p>因此本文采用属性匹配归纳法和元分块方法来减少这些多余和冗余的比较，来提高实体解析算法的效率。</p></sec><sec id="s5_2"><title>3.2. 属性匹配归纳法</title><p>属性匹配归纳法的目标是，在模式未知的情况下，在两个实体集合 ε 1 , ε 2 中从属性值的分布规律中归纳出相似度较高的属性对组。可以利用这些信息来提高模式不可知的分块技术的效率。</p><p>属性匹配归纳法：给定两个实体集合 ε 1 , ε 2 ，依据相似度测量来识别相似属性对</p><p>{ 〈 a i , a j 〉 | a i ∈ A ε 1 , a j ∈ A ε 2 } ，并利用这些属性对来产生属性分区。即，将属性名称空间 ( A ε 1 &#215; A ε 2 ) 划分成不重叠的子集。</p><p>属性对空间的聚类划分主要基于四个步骤：属性值转换、属性表示模型、属性对的相似性度量和聚类算法。</p><p>i) 属性值转换：给定两个实体集合 ε 1 , ε 2 ，使用元组 〈 a j , τ ( V a j ) 〉 表示实体集合中的每一个属性， a j ∈ A ε i 是一个属性名， τ 是一个属性值转换函数，生成一组从值 V a j 中派生出来的标记来表示属性 a j 存在于</p><p>ε 中。函数 τ 通常是一组文本转换函数(包括标记化、去除禁用词、词元化等)。给定一个转换函数 τ ，</p><p>两个实体集合 ε 1 和 ε 2 中可能的属性值就是 T A = T a ε 1 ∩ T a ε 2 ，其中 T a ε = ∪ a i ∈ A ε τ ( V a i ) 。</p><p>ii) 属性表示模型：用矢量 T i 来表示每一个属性 a i ，每一个值 v i n ∈ T i 与元素 t i ∈ T A 相关联。如果 t n ∉ τ ( V a i ) ，那么 v i n 就等于0。如果 t n ∈ τ ( V a i ) ，那么 v i n 就使用加权函数计算的值表示，比如：加权函数可采用TF-IDF(t<sub>n</sub>)，或者在 τ ( V a i ) 中的元素 t n 使用二进制表示(即：如果 t n ∈ τ ( V a i ) 那么 V i n = 1 ，否则 V i n 为</p><p>0)。例如：属性值转换 是将值转换成标记，采用二进制表示这些标记，然后把属性集被表示为一个矩阵：列对应于属性；行对应于实体集合中出现的可能的标记；如果标记 t n 出现在属性 a i 中，每一个元素表示为 V i n = 1 否则表示为0。</p><p>iii) 相似度测量：对于每一个可能的属性对 ( a j , a k ) ∈ ( A ε 1 &#215; A ε 2 ) 的相似度，是通过测量矢量 T i 和 T k 的相似性来比较的(比如：相似性函数可采用Dice，Jaccard，Cosine)。注意，相似性度量方法必须与属性模型表示兼容；例如，Jaccard的相似度不能与TF-IDF的权值同时使用。</p><p>iv) 聚类算法：该算法输入属性表示模型及其实体概要的相似度，对它们的属性名进行非重叠分区，它的输出是属性分区。</p></sec><sec id="s5_3"><title>3.3. 元分块</title><p>元分块的主要思想是重组一个由冗余分块技术生成的块集合，观测两个实体概要共用的属性块越多，匹配的概率就越大，在重组的同时，将它们放在同一个块中。</p><p>元分块：给定一个块集合 β ，重构标记分块，采用剪枝策略生成一个新的块集合 ，在保证(PC)召回率不变的情况下提高了PQ (精准率)。即： P Q ( β ′ ) ≫ P Q ( β ) 以及 P C ( β ′ ) ≈ P C ( β ) 。</p><p>元分块图：使用加权图 G β { V β , E β , W β } 表示一个块集合 β 。 V β 表示所有 p i ∈ ε 的节点集。如果两个实体概要至少在同一个块中出现一次，那么两个实体概要之间存在一条边： E β = { e i j : ∃ p i , p j ∈ ε | | β i j | &gt; 0 } 是一组边； β i j = β i ∩ β j ， β i 和 β j 分别是包含 p i 和 p j 的两个块。 W β 是与边相关的一组权值。权值表示匹配的可能性；这是采用边修剪策略的基准，用来保留匹配可能性更大的边。</p><p>剪枝方法：在元分块技术中可以采用两种修剪方法，一种是基于基数的，指的是先确定比较的数量以及执行的时间然后依据 权重保留Top-k的边，但是这种方法牺牲了召回率；另一种是基于权值的，通过权重阈值来保留最有可能匹配的边。两种修剪标准都可以应用在局部或全局上。在第一种情况下，Top-k边和权重阈值 θ 可以应用在以节点为中心的剪枝策略中。即对每个节点及其相邻的边进行剪枝操作；在第二种情况下，Top-k边是在所有的边中选择的，阈值 θ 对于所有边都是唯一的。</p><p>剪枝策略：利用这些特征，可以组成四种修剪策略。权边修剪(WEP)去除所有的权值小于 θ 的边。基数边修剪(CEP)按降序对所有边进行排序，并且只保留前k个边。权值节点修剪(WNP)，依次考虑每个节点 n i 和它的相邻边，并修剪那些低于全局阈值 θ i 的边。类似于WNP的基数节点修剪(CNP)是以节点为中心的，但是不是一个权重阈值，而是采用了基数阈值 k i (即：为每个节点保留Top k i 个边)。</p><p>在修剪的最后，每一组由边连接的节点构成的连通图组成一个新的块。当两个相匹配的实体概要最终只能出现在同一个块集合中时，元分块就从根本上消除了冗余的比较。</p></sec></sec><sec id="s6"><title>4. 松散模式感知元分块方法模型</title><p>主体思想：首先采用一种属性匹配归纳法对多个Web数据集中属性进行匹配划分，然后重组基于标记分块方法的块集合，组成元分块图，最后利用聚合熵对基于图的元分块加以改进，以达到对多数据源进行实体解析的目的。</p><p>该方法输入两个实体集合(图1)。主要由三个阶段组成，如图2中：单数据源属性选择、多数据源松散属性匹配归纳、基于聚合熵加权图的元分块。下面详细介绍下面的三个步骤。</p><p>图1. (a) 来自四个不同数据源的实体记录的集合；(b) 用标记模块划分生成的块集合</p><p>图2. 松散模式感知元分块方法流程图</p><sec id="s6_1"><title>4.1. 单数据源属性选择</title><p>在单数据源中，由于数据集中含有大量的数据属性，这些数据属性对于接下来的实体解析来说，其重要程度是不同的，所以本文采用属性选择方法来选择相对重要的属性集，以减少所需分析数据属性比较的次数，使处理后的数据属性集能更有效的进行实体解析。</p><p>本文将属性分为两类：</p><p>分类属性：根据属性的取值，可以将其分为多个类别的属性。例如：楼盘类型可以分为别墅、洋房、高层等类别。</p><p>值属性：每一个属性值都是唯一存在的字符型以及数值型数据，不能将他们归为多个类的属性。例如：楼盘名、建筑面积等。</p><sec id="s6_1_1"><title>4.1.1. 分类属性选择</title><p>在信息论中，用熵(Entropy)表示随机变量不确定性的度量，也就是说熵值越大，其随机变量的不确定性就越大，即数据集中随机变量的取值就越多。设X是一个含有限个值的离散随机变量，p(x)为x在数据集X中的出现的概率，则随机变量X的熵定义为：</p><p>H ( X ) = − ∑ i = 1 n     p ( x ) log p (x)</p><p>对于分类属性而言，属性熵值越大，划分后得到的子集纯度就越高，选择这类熵值较大的属性，去查找重复记录，更具备说服力。由于在单个数据源中分类属性的数量较多，所以在本文中，计算出每个分类属性的熵值 H ( X ) 并且按照从大到小的顺序排列，然后选择熵值中间值作为阈值 ε ，熵值大于这个阈值 ε 的属性，将它们作为候选集以进行接下来的算法步骤。</p></sec><sec id="s6_1_2"><title>4.1.2. 值属性选择</title><p>值属性包含了数值型属性和字符型属性，对于数值型属性选择之前需要对其进行离散化处理，本文采用等宽法将属性值分为具有相同宽度的区间，区间的个数K根据实际情况来决定，比如将建筑面积划</p><p>分为 [ 70 , 90 ) 、 [ 90 , 110 ) 、 [ 110 , 130 ) 等。并使各个区间中的实体记录不存在交集。对于字符型属性，在进</p><p>行选择之前，采用上文3.2节中属性值转换的方法，将属性值进行规范化，例如：在不同数据源中表示相同的地址的方式是不一样的，采用属性值转换的方法，将此类属性值统一化。</p><p>对于值属性，在进行实体解析的时候其重要程度也是不一样的，如下表1中，建筑面积的信息量比楼盘名称的信息量要少。事实上有可能的是他们的楼盘是不同的但是建筑面积是相同的。在进行实体解析时，楼盘名称更能有效的判断是否重复，本文使用熵值为每个值属性分配一个权值，属性的熵值越大说明信息量越大，则该值属性更有说服力。同样的计算出每个值属性的信息熵 H ( X ) ，然后选择熵值中间值作为阈值 ε ，熵值大于这个阈值 ε 的属性，将它们作为候选集以进行接下来的算法步骤。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Part of the household tabl</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >楼盘名称</th><th align="center" valign="middle" >户编号</th><th align="center" valign="middle" >面积</th><th align="center" valign="middle" >类型</th><th align="center" valign="middle" >楼层</th></tr></thead><tr><td align="center" valign="middle" >大有恬园二期</td><td align="center" valign="middle" >6号1单元4层2号</td><td align="center" valign="middle" >[90，110)</td><td align="center" valign="middle" >住宅</td><td align="center" valign="middle" >4</td></tr><tr><td align="center" valign="middle" >哈佛世纪</td><td align="center" valign="middle" >4号2单元21层1号</td><td align="center" valign="middle" >[90，110)</td><td align="center" valign="middle" >住宅</td><td align="center" valign="middle" >21</td></tr><tr><td align="center" valign="middle" >中庚香海小镇</td><td align="center" valign="middle" >966-200号2层2号</td><td align="center" valign="middle" >[30，50)</td><td align="center" valign="middle" >住宅</td><td align="center" valign="middle" >2</td></tr><tr><td align="center" valign="middle" >中庚香海金鼎</td><td align="center" valign="middle" >15-1号</td><td align="center" valign="middle" >[70，90)</td><td align="center" valign="middle" >公建</td><td align="center" valign="middle" >1</td></tr><tr><td align="center" valign="middle" >盛通家园</td><td align="center" valign="middle" >40-8号2单元4层3号</td><td align="center" valign="middle" >[50，70)</td><td align="center" valign="middle" >住宅</td><td align="center" valign="middle" >4</td></tr><tr><td align="center" valign="middle" >世纪英伦</td><td align="center" valign="middle" >69-21号5单元8层2号</td><td align="center" valign="middle" >[50，70)</td><td align="center" valign="middle" >住宅</td><td align="center" valign="middle" >8</td></tr><tr><td align="center" valign="middle" >合美华庭</td><td align="center" valign="middle" >303号3单元2层1号</td><td align="center" valign="middle" >[70，90)</td><td align="center" valign="middle" >住宅</td><td align="center" valign="middle" >2</td></tr><tr><td align="center" valign="middle" >冠信香泉谷</td><td align="center" valign="middle" >54号12层2号</td><td align="center" valign="middle" >[130，150)</td><td align="center" valign="middle" >住宅</td><td align="center" valign="middle" >12</td></tr><tr><td align="center" valign="middle" >柏悦国际公寓</td><td align="center" valign="middle" >37号31层3号</td><td align="center" valign="middle" >[50，70)</td><td align="center" valign="middle" >公寓</td><td align="center" valign="middle" >31</td></tr></tbody></table></table-wrap><p>表1. 部分户表</p></sec></sec><sec id="s6_2"><title>4.2. 多数据源松散属性匹配归纳法</title><p>这里介绍了一种属性匹配归纳法来对属性空间划分。此外，本文对属性聚类的主要改进是提出了一个基于局部敏感哈希的预处理步骤来扩展到Web大数据集中。</p><sec id="s6_2_1"><title>4.2.1. 局部敏感哈希预处理步骤</title><p>根据本文第3.2节中属性匹配归纳法的介绍，需要对所有可能匹配的属性对计算相似度，其中所需</p><p>的总的时间复杂度为 O ( N 1 , N 2 ) ， N 1 , N 2 分别是 A ε 1 和 A ε 2 的基数。然而Web的半结构化数据通常涉及较</p><p>高的维度(数据源通常有成千上万个属性值)问题，采用传统的属性匹配归纳法划分属性组会导致较高的时间复杂度；并且，对于每个属性来说，只有少数或者几乎没有相似的实体记录会被发现。因此，本文使用局部敏感哈希预处理步骤对属性表示模型降维，既可以减少传统属性匹配归纳法的复杂度，同时保证了属性对分区的质量。</p><p>局部敏感哈希算法(LSH)可以减少高维度空间的维数，并且保证相似度不变，来减少属性值比较的数量。使用属性表示模型和Jaccard相似度，Min-hashing和banding方法来降低比较所有可能匹配的属性对的复杂度。</p><p>属性模型表示为一个矩阵，其中每个列都是属性a<sub>j</sub>的向量T<sub>j</sub>。在这个矩阵的行中，一个列的Min-hash值是该列首次出现在序列中元素的位置。因此，用n个哈希函数对行进行交换，产生含有n个Min-hash值的向量；这个向量叫做Min-hash签名。在交换序列后两列中产生相同的Min-hash值的概率等于Jaccard的相似度；因此，Min-hashing保留了变换矩阵的相似度，从而减少了表示属性的向量的维度。然而，即使Min-hash签名的数量相对较小，但是计算所有可能签名对的相似度的复杂度也较高；因此，可以将这些签名划分为很多个bands，在至少一个band上Min-hash值相同的签名被认为是候选配对的，并作为属性匹配归纳算法的输入(适用于迭代只有通过这些候选配对代替所有可能的属性对)。</p><p>将n个Min-hash值作为签名，分为b个band，并且令 r = n / b 行Min-hash值为一个band， s r 表示两个band相同的概率， 1 − s r 表示两个band不相同的概率，每一个band都不相同的概率是 ( 1 − s r ) b ，则两个属性在至少一个band上完全相同的概率是 1 − ( 1 − s r ) b 。这个函数具有S型曲线特征，拐点代表的是相似性的阈值。这个阈值可以近似为 ( 1 / b ) 1 / r 。例如，选择b = 30和r = 5，只需要对具有Jaccard相似度大于~0.5的属性对进行属性聚类(示例图3)。这样就减少了属性对之间求相似度的计算复杂度。</p><p>图3. r = 5和b = 30的LSH s曲线。箭头表示估计的阈值</p></sec><sec id="s6_2_2"><title>4.2.2. 松散属性匹配归纳法</title><p>本文4.2节中属性匹配归纳法加以改进，松散属性匹配归纳法主要由下面四个步骤组成：属性值标记化；基于局部敏感哈希预处理后的二进制属性表示模型；相似度测量采用Jaccard系数；算法1用来作为改进后的聚类算法。</p><p>算法1：属性聚类算法</p><p>输入：基于局部敏感哈希处理后的属性表示模型A<sub>1</sub>、A<sub>2</sub></p><p>输出：一个聚类结果：K</p><p>1) edges←{}sim←Map</p><p>2) Max←Map Cand←Map</p><p>//属性匹配最大相似度</p><p>3) foreach a i ∈ A 1 , a j ∈ A 2 do</p><p>4) sim←( i,a <sub>j</sub>&gt;,similarity( τ i , τ j )) <sub></sub></p><p>5) if Sim.get( i,a <sub>j</sub>&gt;) &gt; Max.get(a <sub>i</sub>) then <sub></sub></p><p>6) Max←(a<sub>i</sub>,sim)</p><p>7) if Sim.get( i,a <sub>j</sub>&gt;) &gt; Max.get(a <sub>j</sub>) then <sub></sub></p><p>8) Max←(a<sub>j</sub>,sim)</p><p>//属性匹配，找出候选集</p><p>9) foreach a i ∈ A 1 , a j ∈ A 2 do</p><p>10) if Sim.get( i,a <sub>j</sub>&gt;) ≥ (a∙Max.get(a <sub>i</sub>)) then <sub></sub></p><p>11) Candidates←(a<sub>i</sub>,a<sub>j</sub>)</p><p>12) if Sim.get( i,a <sub>j</sub>&gt;) ≥ (a∙Max.get(a <sub>j</sub>)) then <sub></sub></p><p>13) Candidates←(a<sub>j</sub>,a<sub>i</sub>)</p><p>14) foreach a i ∈ A 1 ， a j ∈ Candidatesget(a<sub>i</sub>) do</p><p>15) if a i ∈ Candidatesget(a<sub>j</sub>) then</p><p>16) edges← i,a <sub>j</sub>&gt; <sub></sub></p><p>17) K←getConnectedComponentsGrThan1(edges)</p><p>return K</p><p>上述算法1首先计算出两个数据源中所有可能匹配的属性之间的相似度，以及它们的最大相似度值(第2~8行)。第4行使用Jaccard系数作为相似度度量。在第9~13行使用松散的属性匹配归纳法来找出属性的候选匹配集，根据阈值来判断最相似的属性(例如：0.9.maxSimValue)。如果一个属性 a i 在它的候选匹配对象中有属性 a j ，那么边 〈 a i , a j 〉 被收集(第14~16行)。最后，用这些边构建基数大于1的图连通分量，表示为聚类(第17行)。选择使用多节点聚类可以收集所有属性，也就是可以确保包含所有可能的标记(模块键)。</p></sec></sec><sec id="s6_3"><title>4.3. 松散模式感知元分块方法</title><p>本节描述了基于图的模式感知元分块技术中的两个步骤。在第一步中，分块图 G β { V β , E β , W β } 使用</p><p>聚合熵来对边进行加权来表示在块中出现的实体记录的相关性。第二步是一个新的修剪标准，来去除块中多余的比较。</p><sec id="s6_3_1"><title>4.3.1. 分块图加权</title><p>以图1中图1(a)和图1(b)为例子，通过标记分块之后派生出的元分块图如图5，图中每个边的权值表示的是在标记分块图中相似记录出现的次数，将权值小于一定阈值的边修剪后得到图5(b)，但是仍然有</p><p>多余的两条边 e p 1 − p 2 和 e p 3 − p 4 没有被去掉。</p><p>为了解决图4问题。采用了属性匹配归纳法之后的相关属性组，消除了“中体奥林匹克花园”的不同的语义，将“中体奥林匹克花园”相关的块划分为两个新块，一个指地块，一个指项目名称，从图5(a)</p><p>中可以看出边 e p 1 − p 2 和 e p 3 − p 4 的权值都降低了。在元分块图5(b)中更改了全局阈值后正确地删除了一个多余的边( e p 1 − p 2 )。提高了精确度，并且保持了召回率。但是仍然存在一个多余的比较( e p 3 − p 4 )。</p><p>图4. (a) 派生的模块划分图；(b) 重构的分块图：虚线表示修剪的边，红色表示多余的比较没有被去掉</p><p>图5. 模块划分键在元分块上消除歧义的效果</p><p>为了消除这个多余的比较，本文使用4.1.1节中介绍的信息熵来描述在属性匹配归纳之后重新生成的每个属性聚类。在该方法中，分块键的重要性与它得到的属性熵成正比。为此，通过计算聚合熵，得到了每组属性的熵值。一组属性 C k 的聚合熵的定义是：</p><p>H &#175; ( C k ) = 1 | C k | ⋅ ∑ A i ∈ C k H (Aj)</p><p>将模式不可知的分块方法(如标记分块)与属性匹配归纳法相结合时，每个分块键 b i 都与一个聚类 C k 唯一相关联，即 b i → C k 。在图1(b)中“中体奥林匹克花园”，消除在不同数据源中语义不同的问题后，可以将它划分为聚类 c 1 的中分块键“中体奥林匹克花园_c1”，以及聚类 c 2 中的分块键“中体奥林匹克花园_c2”； c 1 指的是项目名，而 c 2 指的是实体概要中的地址。如图5中对“中体奥林匹克花园”进一步分块后，每一组分块键 β j 关联的熵 h ( β j ) ：</p><p>h ( β j ) = 1 | β j | ⋅ ∑ b i ∈ β j h (bi)</p><p>h ( b i ) = H &#175; ( C k ) 是与一个分块键 b i → C k 相关联的熵。</p><p>为了表述两个实体概要 p u 和 p v 之间的权重，在表2中显示了在给定块集合中描述实体 p u 和 p v 的联合概率分布的统计表。例如：单元格 n 12 代表了在 p v 不存在 p u 存在时的块数量(没有 p v 表示为“ &#172; ”)；单元 n 2 + 表示 p u 不存在的块的数量(独立于 p v )。这些值也称为观测值。括号中的值是从图1(b)的块集合中派生出来的值，这里以实体概要 p 1 和 p 3 为例。利用皮尔森的卡方(chi-squared)测试( χ 2 ) [<xref ref-type="bibr" rid="hanspub.33407-ref12">12</xref>] 来判断分块内的 p u 和 p v 的独立性；即，测试 p u 的分布在块(表的第一行)中存在时， p v 的分布是否与 p u 不存在的情况下(表中的第二行) p v 的分布相同。在实践中，卡方(chi-squared)测试测量了假设 p u 和 p v 在块中独立出现时，观测到的( n i j )和预期( u i j )样本数(对于 i = 1 , 2 ; j = 1 , 2 )之间的偏差。因此，统计表的每个单元的预期值是： u i j = ( n i + ⋅ n + j ) / n + + 。</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> Associated tables of p u , p </title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" >p v ( p 3 )</th><th align="center" valign="middle" >&#172; p v ( p 3 )</th><th align="center" valign="middle" ></th></tr></thead><tr><td align="center" valign="middle" >p u ( p 1 )</td><td align="center" valign="middle" >n 11 ( 4 )</td><td align="center" valign="middle" >n 12 ( 2 )</td><td align="center" valign="middle" >n 1 + ( 6 )</td></tr><tr><td align="center" valign="middle" >&#172; p u ( p 1 )</td><td align="center" valign="middle" >n 21 ( 3 )</td><td align="center" valign="middle" >n 22 ( 3 )</td><td align="center" valign="middle" >n 2 + ( 6 )</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >n + 1 ( 7 )</td><td align="center" valign="middle" >n + 2 ( 5 )</td><td align="center" valign="middle" >n + + ( 12 )</td></tr></tbody></table></table-wrap><p>表2. p u 、 p v 关联表</p><p>因此，表示实体概要的节点 p u 和 p v 节点之间的权值 W u v 是按照如下公式计算的：</p><p>W u v = χ 2 ⋅ h ( β u v ) = ∑ i ∈ { 1 , 2 } ∑ j ∈ { 1 , 2 } n i j − u i j u i j ⋅ h ( β u v )</p><p>最终求得每个边的权值如图9(b)所示。</p></sec><sec id="s6_3_2"><title>4.3.2. 图修剪</title><p>事实上，当使用基于边数的阈值选择时，就会出现以下问题。以权值的平均值为标准。</p><p>图6. (a) 两个额外的实体概要；(b) 为节点p<sub>1</sub>为中心的分块图表示</p><p>以图6中为例。图6(b)显示了 G p 1 ，以节点实体概要 p 1 为中心。如果实体集合(如图1(a))仅由实体概要集 { p 1 , p 2 , p 3 , p 4 } 组成，生成的图 G p 1 只有4个节点和3条边。在这个场景中，边权值(本地的修剪阈值)的平均值略大于2。因此，只有在修剪阶段保留了 p 1 和 p 3 之间的边界。但是，如果将图6(a)中的两个实体概要添加到实体集合中，则将两个节点和两个边添加到 G p 1 中。这将使阈值变为1.8。因此，在修剪阶</p><p>段保留了 p 1 和 p 4 之间的边界。为了防止图剪枝步骤中受到边数的影响，本文提出了一个权值节点修剪(WNP)中的阈值选择策略。</p><p>基本思想：首先确定每个节点的阈值，在以节点为中心的分块图中，具有最高权值的边代表着分块和加权函数组合的相似度上限；因此，本文选择一个与相邻边数无关的阈值，考虑这个上界的一小部分：</p><p>θ i &#175; = M c ，在这里M是最大的权值，c是任意常数。在真实数据集中显示为具有有效性的c值是c = 2；</p><p>c值越高实现更高的召回率(PC)，但代价是牺牲精准度(PQ)。</p><p>确定了每个节点的本地阈值后，执行的最后一个步骤是保留边。不过，在以节点为中心的修剪中， p i 和 p j 之间的每一个边 e i j 都与两个阈值有关： θ i 和 θ j ； θ j 和 θ j 分别是与 p i 和 p j 相关的阈值。因此，如图7(b)所示，每条边 e i j 都有一个权值：(i)小于 θ i 和 θ j ，(ii)大于 θ i 和 θ j ，(iii)小于 θ i 和大于 θ j ，或(iv)大于 θ i 和小于 θ j 。案例(i)和(ii)并不模糊，因此 e i j 在第一个案例中被丢弃，并保留第二个案例。但是，案例(iii)和(iv)是不明确的。</p><p>现有的元分块论文提出的两种不同的解决这种歧义的方法：重新定义WNP(wnp1)：如果它的权值</p><p>超过了两个阈值中的一个，就会保留 e i j (wnp1)，相对的WNP(wnp2)为：如果它的权值大于 θ i 和 θ j ，那么就保留它的边界。本文中使用唯一的通用阈值，等于： θ i j = ( θ i + θ j ) / d ，d是一个常数；对于d = 2，所得到的阈值 θ i j 等于两个相关的本地阈值的平均值，如果大于该阈值则保留它的边界。</p><p>如图7修剪阶段之后的在图8(c)中显示最后一个模块划分图。多余的边 e p 3 − p 4 现在已经被正确地移除。</p><p>图7. 权重阈值：从 p i 到 p j 的定向边表明了 e i j 的边的权值比 θ i 高；从 p j 到 p i 的一个有向边表明， e i j 边的权值比 θ j 高</p><p>图8. 属性熵信息对元分块的影响</p></sec></sec></sec><sec id="s7"><title>5. 实验评估</title><sec id="s7_1"><title>5.1. 数据集</title><p>本文采用“面向领域的Web数据抽取”项目所抽取到的多个数据源的房地产数据进行实验。抽取到的数据如下表3所示。</p><table-wrap id="table3" ><label><xref ref-type="table" rid="table3">Table 3</xref></label><caption><title> Statistics of information extracted from real estat</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >城市</th><th align="center" valign="middle" >许可信息</th><th align="center" valign="middle" >楼盘</th><th align="center" valign="middle" >楼栋</th><th align="center" valign="middle" >户型</th><th align="center" valign="middle" ></th></tr></thead><tr><td align="center" valign="middle" >北京</td><td align="center" valign="middle" >7610</td><td align="center" valign="middle" >2212</td><td align="center" valign="middle" >12,348</td><td align="center" valign="middle"  colspan="2"  >881,294</td></tr><tr><td align="center" valign="middle" >上海</td><td align="center" valign="middle" >17,404</td><td align="center" valign="middle" >5404</td><td align="center" valign="middle" >307,450</td><td align="center" valign="middle"  colspan="2"  >3,512,295</td></tr><tr><td align="center" valign="middle" >广州</td><td align="center" valign="middle" >8927</td><td align="center" valign="middle" >1321</td><td align="center" valign="middle" >63,231</td><td align="center" valign="middle"  colspan="2"  >1,669,550</td></tr><tr><td align="center" valign="middle" >深圳</td><td align="center" valign="middle" >2908</td><td align="center" valign="middle" >1561</td><td align="center" valign="middle" >10,430</td><td align="center" valign="middle"  colspan="2"  >1,140,545</td></tr><tr><td align="center" valign="middle" >沈阳</td><td align="center" valign="middle" >6221</td><td align="center" valign="middle" >1567</td><td align="center" valign="middle" >30,733</td><td align="center" valign="middle"  colspan="2"  >1,945,833</td></tr><tr><td align="center" valign="middle" >...</td><td align="center" valign="middle" >...</td><td align="center" valign="middle" >...</td><td align="center" valign="middle" >...</td><td align="center" valign="middle"  colspan="2"  >...</td></tr><tr><td align="center" valign="middle" >总计</td><td align="center" valign="middle" >160,651</td><td align="center" valign="middle" >35,926</td><td align="center" valign="middle" >772,732</td><td align="center" valign="middle"  colspan="2"  >31,019,981</td></tr></tbody></table></table-wrap><p>表3. 房地产抽取信息量统计</p></sec><sec id="s7_2"><title>5.2. 实验方法</title><p>本文采用三种分块方法进行实体解析实验(见表4)。</p><table-wrap id="table4" ><label><xref ref-type="table" rid="table4">Table 4</xref></label><caption><title> Blocking method</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >Name</th><th align="center" valign="middle" >Description</th></tr></thead><tr><td align="center" valign="middle" >标记分块</td><td align="center" valign="middle" >传统的分块方法，将数据集中出现的每个标记数据作为模块划分键，然后分块</td></tr><tr><td align="center" valign="middle" >元分块</td><td align="center" valign="middle" >在标记分块方法的基础上，重组块集合，将共用属性块多的实体概要放在同一属性块中</td></tr><tr><td align="center" valign="middle" >松散模式感知元分块</td><td align="center" valign="middle" >在元分块的基础上采用基于局部敏感哈希的属性匹配归纳法进行预处理，然后使用基于聚合熵加权的方法对元分块进行进一步的改进</td></tr></tbody></table></table-wrap><p>表4. 分块方法</p></sec><sec id="s7_3"><title>5.3. 实验结果及分析</title><p>分别从沈阳市的楼盘表、楼栋表、户型表中抽取10,000条数据进行标注，再从各标注数据表中抽取3000条数据，重复数量分别为606,396,511。</p><p>评价指标：本文采用精确度(precision)、召回率(recall)、F<sub>1</sub>-score，对实验结果进行评估分析。精确度(P)是分块正确的正例数量占所有分为正例的百分比，召回率(R)是分块正确的正例数量占实际正例数量的百分比，F<sub>1</sub>-score是它们的调和均值。</p><p>通过表5，可以看出，三个表中标记分块方法效果最差，松散模式感知元方法效果最好，采用松散模式感知元分块方法很大程度的提高了实体解析的效率。本文中的模式感知的元分块方法在标记分块的基础上，保证了召回率的同时，显著的提高了比较的准确率。通过图9可以看出，三个表中标记分块方法的比较次数最大，而采用松散模式感知元分块方法的比较次数最小，很大程度的减少了比较次数，提高了实体解析效率。</p><table-wrap id="table5" ><label><xref ref-type="table" rid="table5">Table 5</xref></label><caption><title> Experimental result</title></caption><table><tbody><thead><tr><th align="center" valign="middle"  rowspan="2"  ></th><th align="center" valign="middle"  colspan="3"  >标记分块</th><th align="center" valign="middle"  colspan="3"  >元分块</th><th align="center" valign="middle"  colspan="3"  >松散模式感知元分块</th></tr></thead><tr><td align="center" valign="middle" >P (%)</td><td align="center" valign="middle" >R (%)</td><td align="center" valign="middle" >F1 (%)</td><td align="center" valign="middle" >P (%)</td><td align="center" valign="middle" >R (%)</td><td align="center" valign="middle" >F1 (%)</td><td align="center" valign="middle" >P (%)</td><td align="center" valign="middle" >R (%)</td><td align="center" valign="middle" >F1 (%)</td></tr><tr><td align="center" valign="middle" >楼盘</td><td align="center" valign="middle" >83.71</td><td align="center" valign="middle" >86.33</td><td align="center" valign="middle" >84.99</td><td align="center" valign="middle" >91.16</td><td align="center" valign="middle" >88.11</td><td align="center" valign="middle" >89.61</td><td align="center" valign="middle" >96.06</td><td align="center" valign="middle" >90.65</td><td align="center" valign="middle" >93.28</td></tr><tr><td align="center" valign="middle" >楼栋</td><td align="center" valign="middle" >79.23</td><td align="center" valign="middle" >81.44</td><td align="center" valign="middle" >85.10</td><td align="center" valign="middle" >85.10</td><td align="center" valign="middle" >84.16</td><td align="center" valign="middle" >84.63</td><td align="center" valign="middle" >89.13</td><td align="center" valign="middle" >89.12</td><td align="center" valign="middle" >87.86</td></tr><tr><td align="center" valign="middle" >户型</td><td align="center" valign="middle" >80.16</td><td align="center" valign="middle" >84.71</td><td align="center" valign="middle" >82.37</td><td align="center" valign="middle" >86.96</td><td align="center" valign="middle" >85.52</td><td align="center" valign="middle" >86.23</td><td align="center" valign="middle" >93.66</td><td align="center" valign="middle" >89.15</td><td align="center" valign="middle" >91.35</td></tr></tbody></table></table-wrap><p>表5. 实验结果</p><p>图9. 分块方法比较次数</p></sec></sec><sec id="s8"><title>6. 结束语</title><p>在Web大数据集中进行实体解析操作时，由于数据量较大，采用直接比较的方法会导致算法复杂度较高，所以这里采用了基于聚合熵加权图的元分块的方法，降低比较的次数，又由于处理不同数据源，模式不同，所以采用了基于局部敏感哈希的属性匹配归纳法对属性空间划分，本文结合上述两种方法，对多数据源中数据进行实体解析，减少了算法中大量冗余和多余的比较，提高了算法的效率，通过实验表明，该方法的效果明显优于传统的模式未知的标记分块方法，在保证召回率的同时，提高了精确度。</p></sec><sec id="s9"><title>文章引用</title><p>韦海浪,李 贵,李征宇,韩子扬,曹科研. 基于模式感知元分块技术的Web实体解析算法Web Entity Resolution Algorithm Based on Schema-Aware Meta-Blocking Technology[J]. 数据挖掘, 2020, 10(01): 16-29. https://doi.org/10.12677/HJDM.2020.101002</p></sec><sec id="s10"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.33407-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">[1]	Dong, X.L. and Srivastava, D. (2015) Big Data Integration. Synthesis Lectures on Data Management.  
https://doi.org/10.2200/S00578ED1V01Y201404DTM040</mixed-citation></ref><ref id="hanspub.33407-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Christen, P. (2012) A Survey of Indexing Tech-niques for Scalable Record Linkage and Deduplication. IEEE Transactions on Knowledge and Data Engineering, 24, 1537-1555. https://doi.org/10.1109/TKDE.2011.127</mixed-citation></ref><ref id="hanspub.33407-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Papadakis, G., Alexiou, G., Papastefanatos, G. and Koutrika, G. (2015) Schema-Agnostic vs. Schema-Based Configurations for Blocking Methods on Homogeneous Data. Proceedings of the VLDB Endowment, 9, 312-323.  
https://doi.org/10.14778/2856318.2856326</mixed-citation></ref><ref id="hanspub.33407-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Papadakis, G., Ioannou, E., Palpanas, T., Niederee, C. and Nejdl, W. (2013) A Blocking Framework for Entity Resolution in Highly Heterogeneous Information Spaces. IEEE Transac-tions on Knowledge and Data Engineering, 25, 2665-2682. https://doi.org/10.1109/TKDE.2012.150</mixed-citation></ref><ref id="hanspub.33407-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Papadakis, G., Papastefanatos, G. and Koutrika, G. (2014) Super-vised Meta-Blocking. Proceedings of the VLDB Endowment, 7, 1929-1940. https://doi.org/10.14778/2733085.2733098</mixed-citation></ref><ref id="hanspub.33407-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Papadakis, G., Papastefanatos, G., Palpanas, T. and Koubarakis, M. (2016) Scaling Entity Resolution to Large, Heterogeneous Data with Enhanced Meta-Blocking. 19th International Conference on Extending Database Technology, Bordeaux, 15-18 March 2016, 221-232.</mixed-citation></ref><ref id="hanspub.33407-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Kopcke, H. and Rahm, E. (2010) Frameworks for Entity Matching: A Comparison. Data &amp; Knowledge Engineering, 69, 197-210. https://doi.org/10.1016/j.datak.2009.10.003</mixed-citation></ref><ref id="hanspub.33407-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Naumann, F. and Herschel, M. (2010) An Introduction to Du-plicate Detection. Synthesis Lectures on Data Management. https://doi.org/10.2200/S00262ED1V01Y201003DTM003</mixed-citation></ref><ref id="hanspub.33407-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Gravano, L., Ipeirotis, P.G., Jagadish, H.V., Koudas, N., Muthukrishnan, S. and Srivastava, D. (2001) Approximate String Joins in a Database (Almost) for Free. 27th International Conference on Very Large Data Bases, 11-14 September 2001, 491-500.</mixed-citation></ref><ref id="hanspub.33407-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">McCallum, A., Nigam, K. and Ungar, L.H. (2000) Efficient Clustering of High-Dimensional Data Sets with Application to Reference Matching. 6th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Boston, 20-23 August 2000, 169-178. https://doi.org/10.1145/347090.347123</mixed-citation></ref><ref id="hanspub.33407-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Ma, Y. and Tran, T. (2013) Typimatch: Type-Specific Un-supervised Learning of Keys and Key Values for Heterogeneous Web Data Integration. 6th ACM International Confer-ence on Web Search and Data Mining, Rome, 4-8 February 2013, 325-334. https://doi.org/10.1145/2433396.2433439</mixed-citation></ref><ref id="hanspub.33407-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Agresti, A. and Kateri, M. (2011) Categorical Data Analysis. In: Interna-tional Encyclopedia of Statistical Science, Springer, Berlin, 206-208. https://doi.org/10.1007/978-3-642-04898-2_161</mixed-citation></ref></ref-list></back></article>