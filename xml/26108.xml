<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2018.87125</article-id><article-id pub-id-type="publisher-id">CSA-26108</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20180700000_57627295.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于Kinect的健身动作识别与评价
  Fitness Movement Recognition and Evaluation Based on Kinect
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>王</surname><given-names>怡</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>朱</surname><given-names>晓文</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>曲</surname><given-names>成璋</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>武汉商学院信息工程学院，湖北 武汉</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>17</day><month>07</month><year>2018</year></pub-date><volume>08</volume><issue>07</issue><fpage>1134</fpage><lpage>1145</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   随着健康问题越来越受到人们的重视，运动健身越来越被广大人民所接受。如何更有效的运动健身并合理减少身体伤害，是现今科学健身运动的研究热点之一。本文利用Kinect收集健身动作数据，对动作进行自动分类，与标准动作进行比对评分，计算出易受伤程度。具体的，首先通过对骨架点的收集和预处理，从骨架点数据中提取特征值，计算权重并对特征值归一化，得到健身动作的动作测试数据集和模板数据集。通过KNN算法对测试数据进行分类与识别，得到测试动作的分类结果。对应分类结果，利用评价和易受伤害计算模型，最终得到健身动作的评分和建议。实验表明，提取的骨架数据特征对所有动作识别仅配合微调的KNN算法就能有较好的效果，并比神经网络算法更具有广泛性。动作评价和易受伤分析可以减少运动伤害，提高健身运动趣味性。 As health issue enrolling a more important role in daily life, sports and fitness movements are accepted increasingly by the majority of people. How to exercise more effectively and reduce physical injuries reasonably is one of the hottest researches in the current scientific fitness movement. In this paper, we use Kinect to collect fitness movement data, then automatically classify the movements, and compare them with standard movements to calculate the degree of vulnerability. Specifically, we collect and preprocess the skeleton data of person’s movements first, and then we extract the feature and normalize the weight to form a representative feature among all movements. Second, we classify all the movements by little tuned KNN algorithm, and form the movement’s template model by similarity calculation. Third, we evaluate the movements based on the identified template and the injury model to guide the performance of movement. The experiments show the features we extract for all movements can represent the movement well that only little tuned KNN algorithm can get a competitive recognition result. We has compared neural net algorithm and KNN that the former is less generalized than the latter. The score and suggestion of fitness movement can reduce sports injuries and improve the enjoyment of fitness sports.
    
  
 
</p></abstract><kwd-group><kwd>KNN算法，静态动作分类，骨骼数据，标准化评分, KNN</kwd><kwd> Static Action Classification</kwd><kwd> Skeleton Data</kwd><kwd> Standardized Score</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>基于Kinect的健身动作识别与评价<sup> </sup></title><p>王怡，朱晓文，曲成璋<sup>*</sup></p><p>武汉商学院信息工程学院，湖北 武汉</p><disp-formula id="hanspub.26108-formula26"><graphic xlink:href="//html.hanspub.org/file/9-1541083x5_hanspub.png"  xlink:type="simple"/></disp-formula><p>收稿日期：2018年7月5日；录用日期：2018年7月20日；发布日期：2018年7月27日</p><disp-formula id="hanspub.26108-formula27"><graphic xlink:href="//html.hanspub.org/file/9-1541083x6_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>随着健康问题越来越受到人们的重视，运动健身越来越被广大人民所接受。如何更有效的运动健身并合理减少身体伤害，是现今科学健身运动的研究热点之一。本文利用Kinect收集健身动作数据，对动作进行自动分类，与标准动作进行比对评分，计算出易受伤程度。具体的，首先通过对骨架点的收集和预处理，从骨架点数据中提取特征值，计算权重并对特征值归一化，得到健身动作的动作测试数据集和模板数据集。通过KNN算法对测试数据进行分类与识别，得到测试动作的分类结果。对应分类结果，利用评价和易受伤害计算模型，最终得到健身动作的评分和建议。实验表明，提取的骨架数据特征对所有动作识别仅配合微调的KNN算法就能有较好的效果，并比神经网络算法更具有广泛性。动作评价和易受伤分析可以减少运动伤害，提高健身运动趣味性。</p><p>关键词 :KNN算法，静态动作分类，骨骼数据，标准化评分</p><disp-formula id="hanspub.26108-formula28"><graphic xlink:href="//html.hanspub.org/file/9-1541083x7_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2018 by authors and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/9-1541083x8_hanspub.png" /> <img src="//html.hanspub.org/file/9-1541083x9_hanspub.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>随着信息化时代的快速发展，新型科技在传统领域的应用也愈发广泛。传统的体育行业中，人们愈来愈注重提高身体素质，健身日渐成为青年人运动的首选方式。但是，青年人在运动时，多因热身不充足、动作不标准而造成运动伤害。如何规范动作，减少运动伤害，更加健康、有效并具有趣味性的运动成为了热门的研究内容。</p><p>规范运动动作需要对动作进行识别分类，与模板对应计算评分结果。因此动作规范化的重点是动作识别分类和动作评分。动作识别分类中，常见的方法有支持向量机(support vector machine, SVM) [<xref ref-type="bibr" rid="hanspub.26108-ref1">1</xref>] ，K最近邻(K-nearest-neighbor, KNN) [<xref ref-type="bibr" rid="hanspub.26108-ref2">2</xref>] ，人工神经网络(Artificial Neural Networks, ANN) [<xref ref-type="bibr" rid="hanspub.26108-ref3">3</xref>] 等。Lin L等 [<xref ref-type="bibr" rid="hanspub.26108-ref4">4</xref>] 提出基于Kinect的静态人体姿势评分方法，李红波等 [<xref ref-type="bibr" rid="hanspub.26108-ref5">5</xref>] 对评分进行修改，能够有效对动作进行评分。</p><p>KNN算法能够有效分类静态动作，神经网络具有较高的自学习和自适应能力。评分方法基于模板数据和测试数据特征向量的角度差，对一般常见健身动作可评分。</p><p>本文选取KNN算法和神经网络算法作为识别算法并将两者计算结果进行对比，对于基于个人的运动识别领域样本数据不宜选取过多而影响用户体验的原则，选择能够准确识别错误特征并推广性更佳的KNN算法作为模型最终方法。在进行运动分类后，针对运动的标准性和易受伤性，通过获取24维特征值并对评分公式进行修改，最终对用户动作是否易受伤和是否有锻炼效果进行综合评分，为用户的运动提供了有效的科学指导。</p></sec><sec id="s4"><title>2. 相关技术</title><sec id="s4_1"><title>2.1. 基于Kinect的骨架特征选取</title><p>Kinect设备是由微软公司研发，能够在不使用控制器的情况下进行人机交互。在硬件上，从左往右依次是红外线发射器、RGB彩色摄影机和红外线摄影机。中间的镜头用来采集彩色图像，两边的镜头则用来采集深度数据。</p><p>建立模板所用的数据，依据骨架关节点提取 [<xref ref-type="bibr" rid="hanspub.26108-ref6">6</xref>] 。由Kinect获取的人体骨架图，如图1所示。其中包括头、肩、肘、脊柱、髋、膝、脚踝等20个三维关节点。获取到的关节点不可直接使用，需要对60维数据进行预处理。将跳动点、异常值等与常规骨架点不相符的一帧数据去掉，提高骨架数据的可靠性、稳定性，增强匹配率并降低误差。</p></sec><sec id="s4_2"><title>2.2. 动作分类与评分方法</title><sec id="s4_2_1"><title>2.2.1. 动作分类</title><p>KNN (K最近邻，k-Nearest Neighbor)算法，即一个测试数据在特征空间中到模板的距离，在距离最小的K个数据中，属于某一类的数量最多，测试数据也属于此类别，并具有此类模板具有的特性。KNN算法结合其他领域的方法，在众多方向均有应用 [<xref ref-type="bibr" rid="hanspub.26108-ref7">7</xref>] [<xref ref-type="bibr" rid="hanspub.26108-ref8">8</xref>] [<xref ref-type="bibr" rid="hanspub.26108-ref9">9</xref>] [<xref ref-type="bibr" rid="hanspub.26108-ref10">10</xref>] 。</p><p>假设由Kinect收集模板数据集M和测试数据集T，测试数据共有k个。将数据集处理后，得到距离特征和角度特征，组合形成特征值。其中有u类动作，v维特征值，对每个特征设置权重w。将测试数据与模板数据集中某一动作的特征值对应相减，特征距离差添加权重，将其相加计算出的距离差，代表了两动作之间的差距。 D l 是测试动作与模板动作之间的距离差。</p><p>D l = s q r t { [ C test ( 1 , v ) − C model ( u , v ) ] 2 ⋅ w } (1)</p></sec><sec id="s4_2_2"><title>2.2.2. 动作评分</title><p>运动评分是为了减少运动损伤的情况，现有研究包括了针对运动损伤风险因素与目标之间的关联度，对运动受伤风险进行评估 [<xref ref-type="bibr" rid="hanspub.26108-ref11">11</xref>] ；基于大数据的运动损伤程度评估 [<xref ref-type="bibr" rid="hanspub.26108-ref12">12</xref>] ；利用SVM建立运动损伤与运动强度之间的关系模型 [<xref ref-type="bibr" rid="hanspub.26108-ref13">13</xref>] 等方面。</p><p>图1. 人体骨架关节</p><p>针对Kinect获取的静态人体姿势，Lin L等 [<xref ref-type="bibr" rid="hanspub.26108-ref4">4</xref>] 提出了一种静态动作的评分方法。计算模板的特征向量与测试数据的特征向量之间的夹角作为特征角度，对每个特征角度赋予不同权重，得到归一化角度值，并加入分段惩罚因子。将两者综合，得到准确度计算公式。李红波等 [<xref ref-type="bibr" rid="hanspub.26108-ref5">5</xref>] 对惩罚因子进行了修改，使评分更佳合理。评分公式与惩罚因子如下。</p><p>1) 提出的静态姿势识别准确度计算公式( α max 为最大的 α i )</p><p>S = { f ( α max ) ⋅ [ ( Z s t − Z ) ⋅ 100 − S s t Z s t + Z s t ]             0 ≤ Z ≤ Z s t 0                                                                                                                     Z ≥ Z s t (2)</p><p>2) 设置肢体偏移极限函数作为惩罚因子(M为预设肢体偏移最大角度阈值)</p><p>f ( α max ) = { 1 − 0.3 M 2 ⋅ α max 2           0 ≤ α max ≤ 10 / 3 M 0                                             α max ≥ 10 / 3 M (3)</p></sec></sec></sec><sec id="s5"><title>3. 静态动作识别与评分</title><p>本文选择KNN算法，加入权重对健身动作进行分类。进一步的健身动作评分中，在上述方法基础上，面向健身动作的标准化和易受伤部位，重新设定惩罚因子，并对权重的分布进行了调整。本文得到静态健身动作评分与建议的过程，如图2。</p><sec id="s5_1"><title>3.1. 测试及模板数据获取</title><p>常用的动作分类方法有三类，本文使用模板分类的方法 [<xref ref-type="bibr" rid="hanspub.26108-ref14">14</xref>] 。选取静态动作6个，包含热身运动1个，腿部练习2个，腰部练习1个，手臂练习1个，全身协调性练习1个。收集静态健身动作的测试数据，共20名实验者，6类动作，每类动作每人做5次，共收集600个动作数据，每个样本骨骼帧数最低为90帧。同时，收集来自江汉大学体育学院的专业运动人员的健身动作作为评分的标准。选择专业运动员的健身动作作为模板，构造较精确的模板数据库，使综合评分更具有说服力。收集动作时，控制实验者到Kinect的距离在1.5 m~2.5 m之间。</p><p>6种健身动作的镜面示范，如图3所示。</p><p>在600个动作数据中随机抽取5个数据作为模板，对5个数据取均值得到分类模板。在评分过程中，用标准健身动作作为评分模板。最终得到的分类模板和标准评分模板包括6类动作，每类动作5个数据，其余均为测试数据。</p><p>在计算特征值距离时，将模板中5组数据求均值，合为一组数据，即每个模板为一组24维特征值。将每个动作的模板库中的模板数据合为一组数据，增加模板的鲁棒性，更加合理、有效的对健身动作进行分类。</p></sec><sec id="s5_2"><title>3.2. 特征值选取及分类</title><p>根据问卷调查分析“健身人群主要针对的训练部位及运动受伤情况”，在静态健身动作的设计中，选取针对腰、腿以及全身协调性的动作。因为运动而受伤的人占了1/2，人们对运动受伤主要是动作不标准和未热身或运动安排不当造成的。根据每个动作不同的特点和侧重部位，选择了12维距离特征和12维角度特征(共24维特征值)，用以提取静态健身动作的模型。</p><p>处理后的关节点经过权重计算，选择贡献度较高的特征如表1所示。</p><p>图2. 静态健身动作分类与评分</p><p>图3. 六类健身动作示意图</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> 24 d characteristic</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >序号</th><th align="center" valign="middle" >距离特征</th><th align="center" valign="middle" >序号</th><th align="center" valign="middle" >角度特征</th></tr></thead><tr><td align="center" valign="middle" >2</td><td align="center" valign="middle" >右膝盖–脊柱</td><td align="center" valign="middle" >14</td><td align="center" valign="middle" >右肘角度(右手腕–右肘–右肩)</td></tr><tr><td align="center" valign="middle" >3</td><td align="center" valign="middle" >左脚踝–脊柱</td><td align="center" valign="middle" >15</td><td align="center" valign="middle" >左肩角度(左肘–左肩–肩中心)</td></tr><tr><td align="center" valign="middle" >4</td><td align="center" valign="middle" >右脚踝–脊柱</td><td align="center" valign="middle" >16</td><td align="center" valign="middle" >右肩角度(右肘–右肩–肩中心)</td></tr><tr><td align="center" valign="middle" >5</td><td align="center" valign="middle" >左手肘–脊柱</td><td align="center" valign="middle" >17</td><td align="center" valign="middle" >左膝角度(左胯–左膝盖–左脚踝)</td></tr><tr><td align="center" valign="middle" >6</td><td align="center" valign="middle" >右手肘–脊柱</td><td align="center" valign="middle" >18</td><td align="center" valign="middle" >右膝角度(右胯–右膝盖–右脚踝)</td></tr><tr><td align="center" valign="middle" >7</td><td align="center" valign="middle" >左手腕–脊柱</td><td align="center" valign="middle" >19</td><td align="center" valign="middle" >左胯角度(脊柱–胯中心–左膝盖)</td></tr><tr><td align="center" valign="middle" >8</td><td align="center" valign="middle" >右手腕–脊柱</td><td align="center" valign="middle" >20</td><td align="center" valign="middle" >右胯角度(脊柱–胯中心–右膝盖)</td></tr><tr><td align="center" valign="middle" >9</td><td align="center" valign="middle" >左膝盖–左肘</td><td align="center" valign="middle" >21</td><td align="center" valign="middle" >胯展开角度(左膝盖–胯中心–右膝盖)</td></tr><tr><td align="center" valign="middle" >10</td><td align="center" valign="middle" >右膝盖–右肘</td><td align="center" valign="middle" >22</td><td align="center" valign="middle" >肩展开角度(左肘–两肩中心–右肘)</td></tr><tr><td align="center" valign="middle" >11</td><td align="center" valign="middle" >“左膝盖–左肘”与“右膝盖–右肘”距离差</td><td align="center" valign="middle" >23</td><td align="center" valign="middle" >脊椎倾斜程度 (脊柱与空间z轴夹角)</td></tr><tr><td align="center" valign="middle" >12</td><td align="center" valign="middle" >左右膝关节角度差</td><td align="center" valign="middle" >24</td><td align="center" valign="middle" >站立脚倾斜程度 (站立脚与空间z轴夹角)</td></tr></tbody></table></table-wrap><p>表1. 24维特征</p><p>在距离的选取中，选择了“膝盖–肘”距离计算动作的幅度和伸展性。并计算“左膝盖–左肘”与“右膝盖–右肘”特征距离的差、左膝盖关节角度与右膝盖关节角度的差，根据左右两边动作的差异度进行静态健身动作的分类。</p><p>在角度的选取中，增加了“左膝盖–胯中心–右膝盖”胯中心角度，“左肘–肩中心–右肘”肩中心角度作为动作标准程度的度量因子，脊椎的倾斜程度和站立脚倾斜程度则作为健身动作是动作评分和建议的基础。</p><p>图4包含肩、肘、胯、膝盖以及胯展开角度和肩展开角度，共10个特征角度。图5为脊柱的倾斜程度、站立脚小腿倾斜程度的角度示意图。上述共12个特征角度，通过计算得到12维特征值。</p><p>图4. 关节点角度与距离</p><p>图5. 脊柱、站立脚与z轴角度示意图</p><p>为减少三维坐标系中的提取动作特征时产生的误差 [<xref ref-type="bibr" rid="hanspub.26108-ref15">15</xref>] ，使用特征向量对三维角度进行描述。 n 1 = ( x 1 , y 1 , z 1 ) 与 n 2 = ( x 2 , y 2 , z 2 ) 两关节点组成特征向量n</p><p>n = ( x 2 − x 1 , y 2 − y 1 , z 2 − z 1 ) (4)</p><p>特征角度的计算，以右肩、右肘、右手腕举例。“右肩-右肘”特征向量 A ( x W B , y W B , z W B ) 和“右手腕-右肘”特征向量 B ( x S B , y S B , z S B ) ，计算特征角度余弦值。</p><p>cos θ = x W B ⋅ x S B + y W B ⋅ y S B + z W B ⋅ z S B x W B 2 + y W B 2 + z W B 2 ⋅ x S B 2 + y S B 2 + z S B 2 ,     θ ∈ ( 0 , 180 ∘ ) (5)</p><p>将用于分类的8个特征角度进行归一化，重新赋予权值。</p><p>1) 计算各个特征角度值之和(第l个特征角度 θ l )</p><p>θ sum = ∑ l = 0 l = k θ l (6)</p><p>2) 对 α l 赋不同权重 w l ，减少模板与测试动作中角度差异性带来的误差</p><p>w i = 1 − e − θ l θ sum ∑ l = 0 l = k 1 − e − θ l θ sum (7)</p><p>3) 得到归一化的角度值</p><p>cos θ l = ∑ l = 0 l = k θ l ⋅ w l (8)</p><p>由表1所示，得到关节点角度序列 P = { cos θ 1 , cos θ 2 , ⋯ , cos θ 12 } ，图3中空心圆到脊柱均为距离特征，共10维距离特征。</p><p>d l = ( x 2 − x 1 ) 2 + ( y 2 − y 1 ) 2 + ( z 2 − z 1 ) 2 (9)</p><p>通过对角度值计算，最终得到12维距离特征序列 d = { d 1 , d 2 , d 3 , ⋯ , d 12 } 。</p><p>关节点角度序列与距离特征序列组合成24维特征序列，对距离和角度特征进行归一化处理，得到无量纲特征序列即为最终24维特征。</p><p>C = { d 1 , d 2 , ⋯ , d 12 , cos θ ′ 1 , cos θ ′ 2 , ⋯ , cos θ ′ 12 } (10)</p><p>因健身动作多具有伸展性，动作重叠可能性不高且标准明确，因此本文选取KNN算法并添加权重对健身动作进行分类，得到较好结果。但KNN算法的计算方式并不适合动作标准性较强的健身动作，本文每个动作的模板库中的所有模板动作求均值合并成一个，为增加模板的鲁棒性，提高分类效果。</p><p>C test 测试数据集中某一测试数据， C ave-model 模板数据的均值模板。</p><p>D = s q r t { [ C test − C ave-model ] 2 ⋅ w } (11)</p></sec><sec id="s5_3"><title>3.3. 评分方法</title><p>本文针对健身动作的锻炼效果和易受伤情况进行判断，并给予合理建议。健身动作是否标准，依据特征值与模板的差异度分析。易受伤判断基于关节点角度进行判定，根据各关节运动幅度 [<xref ref-type="bibr" rid="hanspub.26108-ref16">16</xref>] ，对关节点可运动角度进行设定。对标准的运动角度进行小范围的扩展，得到关于惩罚因子和特征角度 θ 的梯形分段函数f</p><p>f = { 0                                                                                                                       θ &lt; β 1 ∪ θ &gt; β 2 ( 1 cos α 1 − cos β 1 ) ⋅ cos θ + cos β 1 cos β 1 − cos α 1               β 1 &lt; θ &lt; α 1 1                                                                                                                               α 1 &lt; θ &lt; α 2 ( 1 cos α 2 − cos β 2 ) ⋅ cos θ + cos β 2 cos β 2 − cos α 2               α 2 &lt; θ &lt; β 2       θ ∈ [ 0 , 180 ∘ ] , f ∈ [ 0 , 1 ] (12)</p><p>如公式12所示分段函数，由于Kinect的精确度、相同运动对不同人的影响不同，设定 α 1 和 α 2 作为标准动作的范围，小于 β 1 或大于 β 2 的角度值定义为易受伤部分， β 1 α 1 与 α 2 β 2 之间的部分有易受伤趋势。因此，对有受伤趋势的关节添加线性惩罚函数，使其缓和的对函数值修改，相较于某一标准角度值确定是否易受伤，更加科学合理，如图6所示。</p><p>易受伤情况针对每个不同的关节角度具有变动性，对不同情况下关节运动情况设定易受伤程度的函数评定标准。如表2所示。</p><p>图6. 分段惩罚函数</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> Vulnerable Angle function settin</title></caption><table><tbody><thead><tr><th align="center" valign="middle"  colspan="2"  >函数值f 关节点</th><th align="center" valign="middle" >角度值表示</th><th align="center" valign="middle" >f = 1</th><th align="center" valign="middle" >f ⊂ ( 0 , 1 )</th><th align="center" valign="middle" >f = 0</th></tr></thead><tr><td align="center" valign="middle"  rowspan="3"  >肩关节</td><td align="center" valign="middle"  rowspan="2"  >α<sub>1</sub>大于60˚α<sub>2</sub> (˚)</td><td align="center" valign="middle" >α<sub>1</sub>脊柱向量与手臂的夹角</td><td align="center" valign="middle"  rowspan="2"  >0~105</td><td align="center" valign="middle"  rowspan="2"  >105~135</td><td align="center" valign="middle"  rowspan="2"  >135~180</td></tr><tr><td align="center" valign="middle" >α<sub>2</sub>上臂外展角度</td></tr><tr><td align="center" valign="middle" >α<sub>3</sub> (˚)</td><td align="center" valign="middle" >α<sub>3</sub>手臂向内旋转角度</td><td align="center" valign="middle" >0~30</td><td align="center" valign="middle" >30~45</td><td align="center" valign="middle" >45~180</td></tr><tr><td align="center" valign="middle" >肘关节</td><td align="center" valign="middle" >α<sub>4</sub> (˚)</td><td align="center" valign="middle" >α<sub>4</sub>手肘弯曲角度</td><td align="center" valign="middle" >45~180</td><td align="center" valign="middle" >30~45</td><td align="center" valign="middle" >0~30</td></tr><tr><td align="center" valign="middle" >颈椎</td><td align="center" valign="middle" >α<sub>5</sub> (˚)</td><td align="center" valign="middle" >α<sub>5</sub>颈椎弯曲角度</td><td align="center" valign="middle" >60~105</td><td align="center" valign="middle" >45~60/105~135</td><td align="center" valign="middle" >0~45/135~180</td></tr><tr><td align="center" valign="middle"  rowspan="3"  >髋关节</td><td align="center" valign="middle"  rowspan="2"  >膝关节伸直α<sub>6</sub> (˚)</td><td align="center" valign="middle" >α<sub>6</sub>腿抬起角度(腿向内摆动)</td><td align="center" valign="middle" >0~45</td><td align="center" valign="middle" >45~60</td><td align="center" valign="middle" >60~180</td></tr><tr><td align="center" valign="middle" >α<sub>6</sub>腿抬起角度(腿向外摆动)</td><td align="center" valign="middle" >0~60</td><td align="center" valign="middle" >60~90</td><td align="center" valign="middle" >90~180</td></tr><tr><td align="center" valign="middle" >膝关节弯曲α<sub>7</sub> (˚)</td><td align="center" valign="middle" >α<sub>7</sub>胯角度</td><td align="center" valign="middle" >0~120</td><td align="center" valign="middle" >120~135</td><td align="center" valign="middle" >135~180</td></tr><tr><td align="center" valign="middle"  rowspan="5"  >膝关节</td><td align="center" valign="middle"  rowspan="2"  >膝关节弯曲α<sub>8</sub> (˚)</td><td align="center" valign="middle" >α<sub>8</sub>小腿抬起角度角度(内旋)</td><td align="center" valign="middle" >0~45</td><td align="center" valign="middle" >45~60</td><td align="center" valign="middle" >60~180</td></tr><tr><td align="center" valign="middle" >α<sub>8</sub>小腿抬起角度(外旋)</td><td align="center" valign="middle" >0~30</td><td align="center" valign="middle" >30~45</td><td align="center" valign="middle" >45~180</td></tr><tr><td align="center" valign="middle"  rowspan="2"  >膝关节弯曲α<sub>9</sub> (˚)</td><td align="center" valign="middle" >α<sub>9</sub>大腿旋转角度(外展)</td><td align="center" valign="middle" >0~90</td><td align="center" valign="middle" >90~135</td><td align="center" valign="middle" >135~180</td></tr><tr><td align="center" valign="middle" >α<sub>9</sub>大腿旋转角度(内敛)</td><td align="center" valign="middle" >0~30</td><td align="center" valign="middle" >30~45</td><td align="center" valign="middle" >45~180</td></tr><tr><td align="center" valign="middle" >α<sub>10</sub> (˚)</td><td align="center" valign="middle" >α<sub>10</sub>膝关节弯曲程度</td><td align="center" valign="middle" >90~180</td><td align="center" valign="middle" >45~90</td><td align="center" valign="middle" >0~45</td></tr><tr><td align="center" valign="middle" >脊椎</td><td align="center" valign="middle" >α<sub>11</sub> (˚)</td><td align="center" valign="middle" >α<sub>11</sub>在无弯腰锻炼时，脊柱倾斜角度</td><td align="center" valign="middle" >0~15</td><td align="center" valign="middle" >15~45</td><td align="center" valign="middle" >45~180</td></tr><tr><td align="center" valign="middle" >站立脚</td><td align="center" valign="middle" >α<sub>12</sub> (˚)</td><td align="center" valign="middle" >α<sub>12</sub>站立脚倾斜角度</td><td align="center" valign="middle" >0~15</td><td align="center" valign="middle" >15~45</td><td align="center" valign="middle" >45~180</td></tr></tbody></table></table-wrap><p>表2. 易受伤角度函数设定</p><p>除去划分不同情况的α<sub>1</sub>，剩余夹角 { α 2 , α 3 ⋯ , α 12 } 组成惩罚函数，最终得到一个11维惩罚因子。</p><p>F = min { f 1 , f 2 , ⋯ , f 11 } (13)</p><p>评分时使用标准数据模板，再次计算测试动作与模板之间的距离，特征权重W。将惩罚因子与动作标准度的距离差相结合，得到最终评分 D s t ，并对 f &lt; 0.6 的角度进行提示，给出合理的健身运动建议。</p><p>D s t = { 1 − s q r t [ ( t e s t − D ave-model ) 2 ⋅ W i ⋅ F ] } ⋅ 100 (14)</p></sec></sec><sec id="s6"><title>4. 实验与结果分析</title><sec id="s6_1"><title>4.1. 实验步骤</title><p>实验中主要是将骨架关节点转化为24维特征值，录入6种健身动作的评分模板数据和测试数据。依据KNN算法，计算测试动作到分类模板动作的特征值距离和，距离和最小的为分类结果。综合易受伤情况，最终得出健身动作的分类结果和运动评分建议。</p><p>实验步骤如下：</p><p>1) 录入6种健身动作测试数据和标准模板数据；</p><p>2) 对数据进行预处理，并根据3.2.中公式提取健身动作特征值；</p><p>3) 根据公式11计算测试动作与分类模板动作特征值的距离差之和，得出分类结果；</p><p>4) 根据公式12计算易受伤惩罚函数的值；</p><p>5) 根据公式11计算测试动作与对应标准模板动作特征值的距离差之和，得出标准化程度；</p><p>6) 由公式12、13及14，综合计算标准化程度和易受伤程度；</p><p>7) 输出健身动作的评分和建议。</p></sec><sec id="s6_2"><title>4.2. 实验设计与实验环境</title><p>为规范健身动作，减少健身运动产生的意外伤害。本文对20组动作进行了分类并评分，对600个动作进行分类，使用神经网络与KNN进行对照，证明本文所提出的的特征值与权重可分类健身动作。</p><p>实验的硬件平台为：Kinect for Windows一台，实验所用计算机为dell Inspiron 5548，主要配置包括：Intel(R) Core(TM) i5-5200U，2.20 GHz主频双核处理器，内存为4GB；系统开发环境为Windows 10操作系统，Visual Studio 2013和Kinect SDK v1.7.0。</p><p>获取人体关节点数据时，将从摄像头获取的展示在界面中的骨架数据skeletonFrame传输到skeletons数组。设置复选框，点击复选框一次，用文件流输出skeletons数组中各个关节点的数据，再次点击复选框，停止数据输出。</p></sec><sec id="s6_3"><title>4.3. 健身动作分类与对比实验</title><p>通过在KNN算法中设定特征值的权重，对测试数据进行分类。分别计算距离特征和角度特征的权重，距离特征与角度特征权重和的比例为6:4。12维距离特征均分0.6权重，角度特征除去12维角度特征中后4维评分角度。剩余8维特征角度使用公式(5)~(8)进行加权角度特征计算，将得到角度权重和设为0.4。</p><p>选择模板在分类中有重要意义，若模板选择不合理，因此得到的分类结果和评分结果也将与动作不符合。为得到合理的分类结果，在6个动作的对应测试动作数据集中，每类随机抽取5个数据作为模板，对5个数据取均值得到最终模板。</p><p>此方法选择的模板，因测试动作大多标准程度不高，分类结果随模板的变动而变动，因此取10次随机模板分类结果的平均值作为最终分类结果。如表3所示。</p><table-wrap id="table3" ><label><xref ref-type="table" rid="table3">Table 3</xref></label><caption><title> KNN classificatio</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" >动作一/%</th><th align="center" valign="middle" >动作二/%</th><th align="center" valign="middle" >动作三/%</th><th align="center" valign="middle" >动作四/%</th><th align="center" valign="middle" >动作五/%</th><th align="center" valign="middle" >动作六/%</th></tr></thead><tr><td align="center" valign="middle" >动作一</td><td align="center" valign="middle" >100</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td></tr><tr><td align="center" valign="middle" >动作二</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >100</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td></tr><tr><td align="center" valign="middle" >动作三</td><td align="center" valign="middle" >0.6</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >98.8</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" >0.6</td></tr><tr><td align="center" valign="middle" >动作四</td><td align="center" valign="middle" >0.5</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" >98.5</td><td align="center" valign="middle" >0.25</td><td align="center" valign="middle" >0.5</td></tr><tr><td align="center" valign="middle" >动作五</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" >100</td><td align="center" valign="middle" ></td></tr><tr><td align="center" valign="middle" >动作六</td><td align="center" valign="middle" >1.33</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >0.67</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" >98</td></tr></tbody></table></table-wrap><p>表3. KNN分类情况</p><p>由表3可知动作三、四、六均出现少量分类错误的情况。在平均值的计算中，部分动作显示分类错误次数较多，发现不标准动作固定出现在两三个测试者中。绘制6个动作模板特征的折线图，将随机模板与在测试数据中人工挑选动作较标准动作进行对比，如图7、图8所示。</p><p>通过二维图像的显示这些动作特征，发现距离特征平稳且两种模板的趋势较为一致，角度特征则存在较大差异性。在距离特征中，“o—”折线(动作三)在特征9、10存在较大误差。在角度特征中，“—”折线(动作四)在特征5存在较大变动，“o-”折线(动作六)在特征4和特征6存在误差。因此，在动作三、四、六中分类结果存在误差的可能性较大。</p><p>将上述KNN算法结果与神经网络计算结果进行比较，得到表4的对比结果。</p><p>选择除评分所用标准模板数据，其余600组动作数据，选择400组进行神经网络训练，200组测试。</p><p>由表4可知，KNN算法与神经网络算法的分类结果对比，即神经网络在第六类有少量错误数据。因此在MATLAB中显示错误动作六的图像，由图像可知，动作确实存在错误，即识别正确。因测试动作的不标准，导致动作三和动作四的分类错误。</p><p>KNN能够准确找出错误动作与不标准动作，并识别错误角度给出提示。因此选择KNN算法进行分类，并在分类的基础上对健身动作进行评分。</p></sec><sec id="s6_4"><title>4.4. 健身动作评分结果</title><p>评价中特征值23和24已在评分中定义易受伤角度函数，剩余22维特征平分评分权重。添加惩罚函数，对表2中减分范围内角度进行提示，并减去对应分数。最终，使用公式14得到测试健身动作的评分。在评分的过程中，存在分数上的差异。将评分结果大于80分，标记为“优秀”；评分大于60且小于80，标记为“合格”；评分小于60为“不合格”。</p><p>同时，将评分结果为“合格”的数据再次进行判断，当对应模板与测试数据的四肢角度特征值相差过大，则直接对评分结果减去20分，判定为不合格，并给予对应关节错误的提示。图9使用本文的评分方法，对动作评分的效果和评分是否正确合理进行对比展示。</p><p>使用文献 [<xref ref-type="bibr" rid="hanspub.26108-ref5">5</xref>] 中公式，用于判断动作是否标准，而本文关注关节是否易受伤、动作是否标准，因此有大量错误评分，不利于健身动作的评分，未予展示对比评分。</p><p>选取部分动作展示，包括了不同分数段的标准动作和测试动作对比。动作不标准扣分，关节点角度在易受伤范围内，扣分的同时给予运动提示。动作三对比图中，测试动作不标准，对测试动作不同程度扣分，动作四对比图中，测试动作左肘过于拉伸导致左肩向后拉伸过度，易产生运动伤害，因此给予运动建议。</p></sec><sec id="s6_5"><title>4.5. 实验可修改方向</title><p>1) 由于录入数据样本时，Kinect对识别衣物的遮挡和动作中骨架的重叠会有影响，导致骨架点确立</p><p>图7. 距离特征挑选模板与随机模板对比</p><p>图8. 8个角度特征挑选模板对随机模板对比</p><p>图9. 评分结果</p><table-wrap id="table4" ><label><xref ref-type="table" rid="table4">Table 4</xref></label><caption><title> Comparison results between KNN algorithm and neural networ</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >使用算法</th><th align="center" valign="middle" >动作一</th><th align="center" valign="middle" >动作二</th><th align="center" valign="middle" >动作三</th><th align="center" valign="middle" >动作四</th><th align="center" valign="middle" >动作五</th><th align="center" valign="middle" >动作六</th></tr></thead><tr><td align="center" valign="middle" >KNN算法</td><td align="center" valign="middle" >100</td><td align="center" valign="middle" >100</td><td align="center" valign="middle" >98.8</td><td align="center" valign="middle" >98.5</td><td align="center" valign="middle" >100</td><td align="center" valign="middle" >98</td></tr><tr><td align="center" valign="middle" >神经网络</td><td align="center" valign="middle" >100</td><td align="center" valign="middle" >100</td><td align="center" valign="middle" >100</td><td align="center" valign="middle" >100</td><td align="center" valign="middle" >100</td><td align="center" valign="middle" >97.56</td></tr></tbody></table></table-wrap><p>表4. KNN算法与神经网络的对比结果</p><p>而骨架无法确定，运动过程中骨架点定位不准确，骨架信息无法正确表示，问题源自于运行系统的鲁棒性；</p><p>2) Kinect对体型不同的人骨架识别效果不同，对身材匀称、体重适中的健身者辨识度较高。对过高过瘦、或略微肥胖的健身者来说，收集数据时易产生数据异常 [<xref ref-type="bibr" rid="hanspub.26108-ref17">17</xref>] ；</p><p>3) 运动模板包括了标准的动作模板和分类模板，因未经过锻炼的人动作大多不标准。是否模板可以自适应调整，在收集到的动作模型中，挑选更好的模板进行替换；</p><p>4) 可以对评分类别、易受伤部位等进行细化，更为准确的判定运动受伤情况。</p></sec></sec><sec id="s7"><title>5. 结论</title><p>本文利用Kinect，使用KNN算法对健身动作进行，并提出健身运动中易于受伤的关节角度，并对其进行识别和提示，给予相应的建议。本方法收集六种健身动作的数据，提取骨架关节点角度特征，使用KNN算法对动作进行分类，评价分类成功率99.06%。</p><p>最终通过实验，得到测试动作对应的分类结果与评分，并给予运动建议。</p><p>本文提出了一种易受伤的评分标准，易受伤惩罚函数以及易受伤角度的选取，达到规范动作、减少运动伤害的目的。最终实验表明，本文方法能够进行分类与评分，效果良好。静态动作分类的效果一般，下一步实现对错误动作能够识别，增加部分特征的权重，提高错误动作识别程度，为更准确的对健身动作进行评分评价。</p></sec><sec id="s8"><title>基金项目</title><p>大学生创新创业资助项目(课题编号：201711654009)。</p></sec><sec id="s9"><title>文章引用</title><p>王 怡,朱晓文,曲成璋. 基于Kinect的健身动作识别与评价 Fitness Movement Recognition and Evaluation Based on Kinect[J]. 计算机科学与应用, 2018, 08(07): 1134-1145. https://doi.org/10.12677/CSA.2018.87125</p></sec><sec id="s10"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.26108-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">梁修容, 杨正益. 基于聚类和SVM的数据分类方法与实验研究[J]. 西南师范大学学报(自然科学版), 2018, 43(3): 91-96.</mixed-citation></ref><ref id="hanspub.26108-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">顾蒙蒙. 基于KNN算法的跑步姿态监测与识别[D]: [硕士学位论文]. 上海: 东华大学, 2017.</mixed-citation></ref><ref id="hanspub.26108-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">焦李成, 杨淑媛, 刘芳, 王士刚, 冯志玺. 神经网络七十年:回顾与展望[J]. 计算机学报, 2016, 39(0): 1697-1716.</mixed-citation></ref><ref id="hanspub.26108-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Liu, L., Wu, X., Wu, L., et al. (2012) Static Human Gesture Grading Based on Kinect. 5th Internation-al Congress on Image and Signal Processing, 1390-1393.</mixed-citation></ref><ref id="hanspub.26108-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">李红波, 李双生, 孙舶源. 基于Kinect骨骼数据的人体动作姿势识别方法[J]. 计算机工程与设计, 2016, 37(4): 969-975.</mixed-citation></ref><ref id="hanspub.26108-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">辛义忠, 邢志飞. 基于Kinect的人体动作识别方法[J]. 计算机工程与设计, 2016, 37(4): 1056-1061.</mixed-citation></ref><ref id="hanspub.26108-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">王枭. 基于改进KNN算法的二手房评估[D]: [硕士学位论文]. 哈尔滨: 哈尔滨商业大学, 2017.</mixed-citation></ref><ref id="hanspub.26108-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">李博, 郭琛, 任慧. 基于加权K近邻算法的抽象画图像情感分布预测[J]. 中国传媒大学学报(自然科学版), 2018, 25(1): 36-40.</mixed-citation></ref><ref id="hanspub.26108-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">黄贤英, 熊李媛, 刘英涛, 李沁东. 基于类别特征改进的KNN短文本分类算法[J]. 计算机工程与科学, 2018, 40(1): 148-154.</mixed-citation></ref><ref id="hanspub.26108-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">黄文明, 莫阳. 基于文本加权KNN算法的中文垃圾短信过滤[J]. 计算机工程, 2017, 43(3): 193-199.</mixed-citation></ref><ref id="hanspub.26108-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">邵丽. 基于关联规则的运动损伤风险评估仿真[J]. 现代电子技术, 2018(10): 172-174, 178.</mixed-citation></ref><ref id="hanspub.26108-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">李少聪, 马德, 李少琼. 基于大数据的运动损伤程度评估模型[J]. 现代电子技术, 2018, 41(6): 183-186.</mixed-citation></ref><ref id="hanspub.26108-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">李少聪, 马德, 李少琼. 运动损伤与运动强度的关系建模仿真分析[J]. 现代电子技术, 2017, 40(24): 37-39.</mixed-citation></ref><ref id="hanspub.26108-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">郑中华. 基于肢体动作的人体姿态识别研究[D]: [硕士学位论文]. 西安: 西安工业大学, 2015.</mixed-citation></ref><ref id="hanspub.26108-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">朱国刚, 曹林. 基于Kinect传感器骨骼信息的人体动作识别[J]. 计算机仿真, 2014, 31(12): 329-333, 345.</mixed-citation></ref><ref id="hanspub.26108-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">矫玮, 等. 运动损伤学双语教程[M]. 北京: 北京体育大学出版社, 35-42.</mixed-citation></ref><ref id="hanspub.26108-ref17"><label>17</label><mixed-citation publication-type="other" xlink:type="simple">朱金宁, 李红娟. 青少年运动损伤与体质内因相关性分析[J]. 武汉体育学院学报, 2017, 51(4): 96-100.</mixed-citation></ref></ref-list></back></article>