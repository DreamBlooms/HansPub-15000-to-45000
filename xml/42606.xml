<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2021.115145</article-id><article-id pub-id-type="publisher-id">CSA-42606</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20210500000_34822668.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于深度学习的遥感影像松材线虫病树提取
  Remote Sensing Image Extraction of Pine Wood Nematode Disease Tree Based on Deep Learning
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>吴</surname><given-names>思琪</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib></contrib-group><aff id="aff1"><label>1</label><addr-line>null</addr-line></aff><aff id="aff2"><label>1</label><addr-line>长江大学地球科学学院，湖北 武汉</addr-line></aff><pub-date pub-type="epub"><day>08</day><month>05</month><year>2021</year></pub-date><volume>11</volume><issue>05</issue><fpage>1419</fpage><lpage>1426</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   松材线虫病对我国松树类物种具有极大的伤害，需要对病虫区域进行准确高效的确定以提早防治。这种病在传播方式上具有跳跃特性。它具有传播途径多种多样、发病部位较隐蔽难以发现、病情潜伏时间长、发病速度迅速、治理不方便等特点，严重时会导致大量松树病死，导致环境和森林景观的严重损坏，并可能导致严重的经济和环境损失。本论文通过使用深度学习目标检测中的RetinaNet方法，将无人机拍摄的影像作为训练样本，充分利用深度学习目标检测方法的优势，将其对比SSD和YOLO v3方法的识别效果，实现病虫树木的高效判别。对松材线虫病树区域展开定位研究，在节省人工成本的同时能迅速防止病虫害对松树的疾病扩散，为清除和防治病害区域扩散至更大范围提供有效帮助。 Pine wood nematode disease is very harmful to pine species in China, so it is necessary to determine the pest area accurately and efficiently in order to prevent it in advance. The disease has a leaping characteristic in its mode of transmission. It has the characteristics of diversity, strong concealment of transmission route, long incubation period of disease, fast transmission speed and inconvenient management. When it is serious, a large number of pine trees will die, causing serious damage to environment and forest landscape, and may lead to serious economic and environmental damage. In this paper, through the use of RetinaNet method in deep learning target detection, the unmanned aerial vehicle images are taken as training samples, making full use of the advantages of deep learning target detection method, the recognition effect of SSD and Yolo V3 method is compared, and the efficient identification of pest trees is realized. The research on the location of pine wood nematode disease tree area can save the labor cost and prevent the spread of diseases and insect pests on pine trees quickly, which can provide effective help for clearing and controlling the spread of disease area to a wider range. 
  
 
</p></abstract><kwd-group><kwd>松材线虫病，深度学习，目标检测, Pine Wood Nematode Disease</kwd><kwd> Deep Learning</kwd><kwd> Target Detection</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>摘要</title><p>松材线虫病对我国松树类物种具有极大的伤害，需要对病虫区域进行准确高效的确定以提早防治。这种病在传播方式上具有跳跃特性。它具有传播途径多种多样、发病部位较隐蔽难以发现、病情潜伏时间长、发病速度迅速、治理不方便等特点，严重时会导致大量松树病死，导致环境和森林景观的严重损坏，并可能导致严重的经济和环境损失。本论文通过使用深度学习目标检测中的RetinaNet方法，将无人机拍摄的影像作为训练样本，充分利用深度学习目标检测方法的优势，将其对比SSD和YOLO v3方法的识别效果，实现病虫树木的高效判别。对松材线虫病树区域展开定位研究，在节省人工成本的同时能迅速防止病虫害对松树的疾病扩散，为清除和防治病害区域扩散至更大范围提供有效帮助。</p></sec><sec id="s2"><title>关键词</title><p>松材线虫病，深度学习，目标检测</p></sec><sec id="s3"><title>Remote Sensing Image Extraction of Pine Wood Nematode Disease Tree Based on Deep Learning<sup> </sup></title><p>Siqi Wu</p><p>School of Geosciences, Yangtze University, Wuhan Hubei</p><p><img src="//html.hanspub.org/file/22-1542173x4_hanspub.png" /></p><p>Received: Apr. 24<sup>th</sup>, 2021; accepted: May 19<sup>th</sup>, 2021; published: May 26<sup>th</sup>, 2021</p><p><img src="//html.hanspub.org/file/22-1542173x5_hanspub.png" /></p></sec><sec id="s4"><title>ABSTRACT</title><p>Pine wood nematode disease is very harmful to pine species in China, so it is necessary to determine the pest area accurately and efficiently in order to prevent it in advance. The disease has a leaping characteristic in its mode of transmission. It has the characteristics of diversity, strong concealment of transmission route, long incubation period of disease, fast transmission speed and inconvenient management. When it is serious, a large number of pine trees will die, causing serious damage to environment and forest landscape, and may lead to serious economic and environmental damage. In this paper, through the use of RetinaNet method in deep learning target detection, the unmanned aerial vehicle images are taken as training samples, making full use of the advantages of deep learning target detection method, the recognition effect of SSD and Yolo V3 method is compared, and the efficient identification of pest trees is realized. The research on the location of pine wood nematode disease tree area can save the labor cost and prevent the spread of diseases and insect pests on pine trees quickly, which can provide effective help for clearing and controlling the spread of disease area to a wider range.</p><p>Keywords:Pine Wood Nematode Disease, Deep Learning, Target Detection</p><disp-formula id="hanspub.42606-formula38"><graphic xlink:href="//html.hanspub.org/file/22-1542173x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2021 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/22-1542173x7_hanspub.png" /> <img src="//html.hanspub.org/file/22-1542173x8_hanspub.png" /></p></sec><sec id="s5"><title>1. 引言</title><p>松材线虫是松树的毁灭性病害，在1982年被人们发现时便迅速蔓延，对大片的松林构成了毁灭性威胁。它具有传播途径多种多样、发病部位较隐蔽难以发现、病情潜伏时间长难以提前察觉、发病速度迅速、治理不方便等特点 [<xref ref-type="bibr" rid="hanspub.42606-ref1">1</xref>]。树木针叶颜色逐渐变成黄色或者褐色是被感染松树的表面症状，而红褐色的针叶是重病时期松树。为了防治松材线虫对森林资源的伤害，必须及时清理死树或者染上疾病的松树 [<xref ref-type="bibr" rid="hanspub.42606-ref2">2</xref>]。此外，一旦病情蔓延会造成大量的松树死亡，如果不及早发现和治疗，松材线虫病的出现将会给国家带来巨大的经济损失以及对森林的生态产生一定的破坏。根据不完全统计，松材线虫病已在浙江、广东、四川的244个县级行政区域及其他16个省出现，累计死亡松树达到500多万株，造成的直接和间接经济损失达到约275亿元 [<xref ref-type="bibr" rid="hanspub.42606-ref3">3</xref>]。</p><p>如今病虫区域的检测有很多种，其中人工方式监测病害树木虽然可行但部分发病区耗时耗力、成本高且人力难以到达。但是如果可以利用将无人机技术、卫星导航定位技术、计算机技术等手段相结合的方式 [<xref ref-type="bibr" rid="hanspub.42606-ref4">4</xref>]，便能对松材线虫病树进行实时的监测，这样有害生物监测和预警就会变得高效有用，还可以解决一旦病情爆发发现不及时的重大问题 [<xref ref-type="bibr" rid="hanspub.42606-ref5">5</xref>]。</p><p>目前，利用遥感技术识别枯木的方法多种多样 [<xref ref-type="bibr" rid="hanspub.42606-ref6">6</xref>]。在对研究区马尾松进行多光谱校正和分割后，使用依赖于先验知识的决策树分类方法对马尾松进行信息提取 [<xref ref-type="bibr" rid="hanspub.42606-ref7">7</xref>]。并且在监测过程中，还可以通过松树的纹理和颜色的特征，利用隶属函数法对患病松树进行识别，进而可以将松树的疾病程度分为轻度、中度和重度。利用计算机图像分析技术比如说图像分割算法提取无人机航拍图像中的害虫区域。利用面向对象分类算法和支持向量机、k近邻、随机森林等机器学习分类算法对无人机高光谱图像中的植被种类和灾害等级进行分类 [<xref ref-type="bibr" rid="hanspub.42606-ref8">8</xref>]。</p><p>与传统的目标探测相比，深度学习模型具有较强的表现能力，多尺度问题上的特征提取和时间效率上有优势。这种病虫树的有效提取，不仅可以降低人工筛选的成本，而且可以对人迹罕至的深山林区进行监测，提高病虫树的筛选效率，及时发现病虫树和枯树，防止进一步扩大病虫害的范围，并减少因病虫害造成的经济损失 [<xref ref-type="bibr" rid="hanspub.42606-ref9">9</xref>]。本文主要研究深度学习目标检测的方法RetinaNet结合ResNet主干网络对松材线虫病枯死树训练样本进行训练，训练出来的模型能很好地识别受灾地区松材线虫病树的位置。</p></sec><sec id="s6"><title>2. 基于深度学习的目标检测发展</title><p>在过去十年中，自然图像对象检测算法可分为两个不同的阶段，第一阶段是在2013年的期间基于传统的人工时代，第二个阶段则是以深度学习为基础进行的目标检测。如果从目标检测技术演变的角度来看，技术的发展则分别经历了包围框回归时期、多参考窗口时期、深度神经网络兴起时期、难样本挖掘与聚焦时期和多尺度多端口检测时期 [<xref ref-type="bibr" rid="hanspub.42606-ref10">10</xref>]。</p><p>此外，在图像识别领域，目前深度学习通过构建神经网络学习的方法使错误率降低，可以分为基于候选区域的方法和回归方法。前者是two-stage类，主要包括SPP-Net [<xref ref-type="bibr" rid="hanspub.42606-ref11">11</xref>]、RCNN [<xref ref-type="bibr" rid="hanspub.42606-ref12">12</xref>]、Fast R-CNN [<xref ref-type="bibr" rid="hanspub.42606-ref13">13</xref>]、Faster R-CNN [<xref ref-type="bibr" rid="hanspub.42606-ref13">13</xref>] 等，包括候选区域提取，特征提取，卷积神经网络分类和回归的边界框。这种基于候选区域的检测方法与以往基于机器学习的检测方法相比检测精度有了很大的提高，但处理速度不能满足实时检测的要求，与病树检测对时效性要求较高的要求违背。后者是基于回归的one-stage类方法，主要有SSD [<xref ref-type="bibr" rid="hanspub.42606-ref14">14</xref>] 和YOLO [<xref ref-type="bibr" rid="hanspub.42606-ref15">15</xref>] 系列算法。目标检测任务被这些算法看成回归问题，直接返回目标类别和目标边界框，大大提高了检测速度，但检测精度不及前者算法。正是因为检测速度比two-stage快，因此精度方面相比就有所下降。其根本原因就是one-stage类别虽然检测速度快但却受制于类别不平衡。类别不平衡是指在目标检测算法的前期会生成一大波的包含物体的一个紧致矩形边界框。在检测一幅常规的图片中，需要识别的对象并不会有很多，这意味着绝大多数的先验框属于不需要识别的背景，导致先验框数量爆炸。先验框中属于背景的框远远超出识别物体的边界框，所以如果分类器会自动地把所有先验框统一归类为背景框，这样精度即使可以刷得很高，但很明显不符合要求。在第一次生成类别极不平衡的先验框中one-stage类型的目标检测直接就进行难度极大的细分类，希望能直接输出先验框和检测的结果。而损失函数无法从根本上解决类别的巨大不平衡，这样还是会导致模型的训练失败。因此，one-stage类型的检测在保持住了检测速度的同时却丧失了检测精度 [<xref ref-type="bibr" rid="hanspub.42606-ref16">16</xref>]。</p></sec><sec id="s7"><title>3. RetinaNet的突破</title><sec id="s7_1"><title>3.1. Focal Loss的特点</title><p>RetinaNet其实在目标检测的框架上相对于YOLO、SSD没有什么特别改进，脸书团队通过后续实验证明了Focal loss可在one-stage类型中的成功使用，最终以two-stage系相似或者更加优秀的效果和更快的速率实现。</p><p>Focal loss的特点在于两个方面一是控制了正负样本的权重，二是控制容易分类和难分类样本的权重 [<xref ref-type="bibr" rid="hanspub.42606-ref17">17</xref>]。正负样本就是一张图可能会生成巨大数量的候选框，只有少部分有我们要检测的物体，有这些物体的候选框就是正样本，没有就是负样本。对于常用的交叉熵loss公式(1)。</p><p>C E ( p , y ) = C E ( p t ) = − log ( p t ) (1)</p><p>显然需要在公式上做改动减少正样本和负样本的影响，可以通过增加系数 α t 实现即将交叉熵变为公式(2)。</p><p>C E ( p t ) = − α t log ( p t ) (2)</p><p>当真实标签为1的时候， α t = α ；当真实标签为otherwise也就是0的时候， α t = 1 − α ， α 的范围也是0到1。当把 α 的值设置在0到0.5之间的时候公式(3)和公式(4)。</p><p>α t = α   ( y = 1 ) (3)</p><p>α t = 1 − α   ( otherwise ) (4)</p><p>这两种情况中 α 的值可以看出，正样本的权重降低，而负样本的权重增加。当把 α 的值设置在0.5到1之间的时候，正样本的权重增加，而负样本的权重降低。如此一来 α 就能解决正负样本权重不平衡的问题。</p><p>同理，控制容易分类和难分类样本的权重的问题也需要得到解决。调节正负样本权重的公式(5)。</p><p>F L ( p t ) = − ( 1 − p t ) γ log ( p t ) = ( 1 − p t ) γ C E ( y ^ ) i (5)</p><p>容易分类的样本是当输入的样本为正样本时，pt接近于1意味着此时的网络可以正确识别输入进来的样本，那么权重就会很小。难分类的样本是当输入的样本为负样本时，pt接近于0时，此时当前网络没有办法正确识别输入进来的样本，那么权重与容易分类的样本的权重相比会大很多。</p><p>如果pt的值接近于0时，调制系数 ( 1 − p t ) γ 的值就会趋于1，这样对交叉熵的贡献很大。如果该值接近于1，对应的调制系数就趋于0，也就是对于交叉熵贡献就会很小。这样pt能控制难以分类和容易分类样本的权重，前面提到通过控制α的大小能调节正负样本对loss的贡献。这样将这两个可控的因素合在一起就变成最终版本的focal loss公式(6) [<xref ref-type="bibr" rid="hanspub.42606-ref18">18</xref>]。</p><p>F L ( p t ) = − α t ( 1 − p t ) γ log ( p t ) (6)</p></sec><sec id="s7_2"><title>3.2. RetinaNet的实现思路</title><p>由图1中RetinaNet抽象的结构图可知，主要分为三个部分。第一个部分是主干网络的特征提取，主干网络是ResNet深度残差网络。有一条残差边经过处理直接从某一个特征层的输入跨越到某一个特征层的输出也就是意味着将靠前若干层的某一层数据输出跨越到后面输入的数据层 [<xref ref-type="bibr" rid="hanspub.42606-ref19">19</xref>]。第二个部分是在主干特征提取网络里面加上的图像金字塔(feature pyramid net)，主要解决的是物体检测中的多尺度问题，通过简单的网络连接改变，在基本不增加原有模型计算量的情况下，大幅度提升了小物体检测的性能，它通过高层特征进行上采样和低层特征进行自顶向下的连接。第三个部分是将前面提取到的有效的特征层传输过class + box subnets获得预测结果。class subnet可以用于预测每一个网格内每一个先验框的种类。box subnet是预测每一个网格上每一个先验框调整结构。</p><p>图1. RetinaNet网络结构</p></sec></sec><sec id="s8"><title>4. 实验过程</title><p>本次实验数据选用航空遥感数据10张湖北省宜昌市夷陵区航空遥感影像(大小13,527 &#215; 9113，分辨率0.1米)大图，将其裁剪成200小图，然后通过一款开源的图像标注工具labellmg，采集每张图片中病树的训练样本。实验选用台式机作为部署平台，硬件信息如表1所示。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Specific information of computer hardware environmen</title></caption><table><tbody><thead><tr><th align="center" valign="middle"  colspan="3"  >硬件信息</th><th align="center" valign="middle"  colspan="2"  >环境信息</th></tr></thead><tr><td align="center" valign="middle" >平台</td><td align="center" valign="middle" >型号</td><td align="center" valign="middle" >主频/内存</td><td align="center" valign="middle" >平台</td><td align="center" valign="middle" >版本</td></tr><tr><td align="center" valign="middle" >RAM</td><td align="center" valign="middle" >ChannelB-DIMM1</td><td align="center" valign="middle" >16G</td><td align="center" valign="middle" >tensorflow-gpu</td><td align="center" valign="middle" >1.13.2</td></tr><tr><td align="center" valign="middle" >CPU</td><td align="center" valign="middle" >i7-9700</td><td align="center" valign="middle" >3.0 GHz</td><td align="center" valign="middle" >CUDA</td><td align="center" valign="middle" >10.0</td></tr><tr><td align="center" valign="middle" >GPU</td><td align="center" valign="middle" >GTX 1650</td><td align="center" valign="middle" >12G</td><td align="center" valign="middle" >CUDNN</td><td align="center" valign="middle" >7.4.1.5</td></tr><tr><td align="center" valign="middle" >Windows 10</td><td align="center" valign="middle" >64位</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >Python</td><td align="center" valign="middle" >3.6</td></tr></tbody></table></table-wrap><p>表1. 计算机硬件环境具体信息</p><p>病树的数据集为VOC2007格式，模型的训练必须依赖数据集，将文件夹命名为VOCdevkit。该数据集格式中会有三类文件夹分别名为Annotations文件夹，ImageSets文件夹和JPEGImages文件夹。Annotations文件夹内存放的是与图像对应的检测目标的标签文件，该文件是对图片的解释，不同的图片对应于一个同名的xml文件，也与图片文件夹里的图片相对应。ImageSets文件夹中的txt文件将VOCdevkit里保存的图片分类为各种集合。</p><p>此外，深度学习目标检测的模型训练过程中通过设置初始化参数、调整数据规模是提高整体训练效率的有效方式。参数的设置需要在不断调整中充分考虑到训练精度、训练速度和硬件条件。初始化参数方面，num_classes代表需要检测的种类，本论文只需要检测病树区域也就是病树区域，因此num_classes设置为1。验证集和数据集划分时，设置90%的用于训练剩下10%的用于验证，因此val_split设置为0.1。训练参数方面，batch_size、learning rate和epochs非常重要。batch_size代表一次训练所选取的样本数，它大小影响模型的优化程度和速度，同时其直接影响到GPU内存的使用情况，batch_size设置为2。learning rate是监督学习以及深度学习中重要的超参，其决定着目标函数能否收敛到局部最小值以及何时收敛到最小值，合适的学习率能够使目标函数在合适的时间内收敛到局部最小值，learning rate设置为0.001。epochs为向前和向后传播中所有批次的单次训练迭代，考虑到数据集，epochs设置大小为100。在本文中，使用微软发布的Microsoft COCO作为预训练数据集，该数据集包含约30多万张图片、200多万个物体被标注、分为91个类型，每一类物体的图片包含精确的分割信息，是目前每张图片平均包含目标数最多的数据集。通过该数据集训练原始的RetinaNet，将训练后的模型参数对本文模型中相同的部分进行初始化，然后再用自己制作的病树数据集继续训练，这样可以实现迁移学习，解决样本不足的问题。</p></sec><sec id="s9"><title>5. 结果分析</title>结果精度评价<p>在目标检测模型中，为了定量评价模型性能需要用到一些重要指标，包括精确度(Precision)、召回率(Recall)和F1 score。</p><p>这些评价指数依赖于TP、FP和FN。TP (True Positive)就是指那些正样本被正确分类。FP (False Positives)就是指那些负样本被错误的分类为正样本。FN (False Negatives)就是正样本被错误的分类成负样本。</p><p>精确度翻译就是分类时被认为是正样本而且确实是正样本的部分占所有分类过程中被当作是正样本的比例。那么预测为正就有两种可能了，一种就是把正类预测为正类(TP)，另一种就是把负类预测为正类(FP)，也就是精确度如公式(7)。</p><p>T P &#247; ( T P + F P ) (7)</p><p>召回率公式实际上就是分类时正样本确实被正确分类的部分占所有的正样本包括被错误分类正样本的百分比。那也有两种可能，一种是把原来的正类预测成正类(TP)，另一种就是把原来的正类预测为负类(FN)召回率如公式(8)。</p><p>T P &#247; ( T P + F N ) (8)</p><p>在本次实验中，在同一环境下分别使用RetinaNet、YOLO v3和SSD 3种目标检测主流one-stage类检测框架，并用同样的标记好的病树数据集进行训练，对最终的预测结果进行分析对比，3种框架平台的训练识别效果如图2所示。其中红色框为算法检测到的病树区域，黄色框为漏检的病树区域，蓝色框为错检的病树区域。各个框架对病树的识别效果如表2所示。由识别效果得出，在实验区域相同的情况下基于one-stage类检测框架种RetinaNet的识别效果最好，没有错检的病树区域，少数病树区域未能被框架检测到，精确度、召回率和F1 score在三种框架皆为最高分别高达100%、90.4%和94.9%。其次的效果是YOLO v3，能够基本实现对病树区域的判别，但是一旦病树区域较多或者病区接近时便出现漏检和错检的情况。相比之下同样基于one-stage类检测框架的SSD的识别效果最差，不仅将区域相近的病树错检，而且还有一些明显病死的枯树没有被框架识别，但总体上看SSD算法和YOLO v3算法的精确度和召回率都很接近。</p><p>图2. 多张病树区域检测结果图</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> The recognition effect of each frame on disease tre</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >检测方法</th><th align="center" valign="middle" >TP</th><th align="center" valign="middle" >FN</th><th align="center" valign="middle" >FP</th><th align="center" valign="middle" >精确度</th><th align="center" valign="middle" >召回率</th><th align="center" valign="middle" >F1 score</th></tr></thead><tr><td align="center" valign="middle" >RetinaNet</td><td align="center" valign="middle" >19</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" >100%</td><td align="center" valign="middle" >90.4%</td><td align="center" valign="middle" >94.9%</td></tr><tr><td align="center" valign="middle" >SSD</td><td align="center" valign="middle" >12</td><td align="center" valign="middle" >8</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >92.3%</td><td align="center" valign="middle" >60%</td><td align="center" valign="middle" >72.7%</td></tr><tr><td align="center" valign="middle" >YOLO V3</td><td align="center" valign="middle" >13</td><td align="center" valign="middle" >8</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >92.8%</td><td align="center" valign="middle" >61.9%</td><td align="center" valign="middle" >74.2%</td></tr></tbody></table></table-wrap><p>表2. 各个框架对病树的识别效果</p></sec><sec id="s10"><title>6. 总结与展望</title><p>从整体上来说，实现了RetinaNet深度学习网络对无人机影像中的真实场景下松材线虫病树区域目标物的高效检测，比SSD和YOLO v3检测效果更好，论证了Focal loss的改进使RetinaNet有更好的优越性。实验结果显示，该方式能够有效准确地检测无人机影像中的病树区域，既能减少人工筛查的成本，更能监测人工无法到达的深山林区，提升了筛查病害树木的效率，及时发现害病树木和枯死树木，防止病害进一步扩大感染范围，减少病虫害造成的经济损失，为以后深度学习在松材线虫病树的应用提供更加先进的思路。</p><p>但同时也存在个别病树区域未识别到的现象，在后续的研究中可以通过提高病树集图片的质量、数量和多样性来给模型提供更丰富的病树特征，增强模型的识别效果；也可以通过提高计算机硬件配置、计算速度从而修改框架参数获得更好的拟合模型。</p></sec><sec id="s11"><title>文章引用</title><p>吴思琪. 基于深度学习的遥感影像松材线虫病树提取Remote Sensing Image Extraction of Pine Wood Nematode Disease Tree Based on Deep Learning[J]. 计算机科学与应用, 2021, 11(05): 1419-1426. https://doi.org/10.12677/CSA.2021.115145</p></sec><sec id="s12"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.42606-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">曾全, 孙华富, 杨远亮, 周建华, 杨超. 无人机监测松材线虫病的精度比较[J]. 四川林业科技, 2019, 40(3): 92-95, 114.</mixed-citation></ref><ref id="hanspub.42606-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">武红敢, 牟晓伟, 杨清钰, 王成波. 无人机遥感技术在重庆市沙坪坝区松材线虫病监测中的应用[J]. 林业资源管理, 2019(2): 109-115.</mixed-citation></ref><ref id="hanspub.42606-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">林孝春. 松材线虫病的危害及防控措施综述[J]. 华东森林经理, 2015, 29(3): 28-30.</mixed-citation></ref><ref id="hanspub.42606-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">马菁. 基于遥感技术的松材线虫病早期预警[D]: [硕士学位论文]. 北京: 北京林业大学, 2012.</mixed-citation></ref><ref id="hanspub.42606-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">张裕, 杨海涛. 基于深度学习的轻量化遥感图像目标检测方法[J]. 信息技术, 2019, 43(9): 163-167.</mixed-citation></ref><ref id="hanspub.42606-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">葛宏立. 基于多源遥感信息的松材线虫病综合监测预警系统研究——两个遥感图像专题信息提取新方法[J]. 中国科技成果, 2013(21): 37-38.</mixed-citation></ref><ref id="hanspub.42606-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">隋雪莲, 张涛, 曲乔新. 深度学习在遥感影像目标识别与定位中的应用研究[J]. 科技创新与应用, 2019(34): 180-181.</mixed-citation></ref><ref id="hanspub.42606-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">张学敏. 基于支持向量数据描述的遥感图像病害松树识别研究[D]: [硕士学位论文]. 合肥: 安徽大学, 2014.</mixed-citation></ref><ref id="hanspub.42606-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">吴琼. 基于遥感图像的松材线虫病区域检测算法研究[D]: [硕士学位论文]. 合肥: 安徽大学, 2013.</mixed-citation></ref><ref id="hanspub.42606-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">叶钊. 目标检测技术研究进展[C]//中国计算机用户协会网络应用分会. 中国计算机用户协会网络应用分会2019年第二十三届网络新技术与应用年会论文集. 中国计算机用户协会网络应用分会: 北京联合大学北京市信息服务工程重点实验室, 2019: 245-249.</mixed-citation></ref><ref id="hanspub.42606-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">He, K., Zhang, X., Ren, S. and Sun, J. (2014) Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition. IEEE Transactions on Pattern Analysis &amp; Machine Intelligence, 37, 1904-1916.  
&lt;br&gt;https://doi.org/10.1109/TPAMI.2015.2389824</mixed-citation></ref><ref id="hanspub.42606-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Girshick, R., Donahue, J., Darrell, T. and Malik, J. (2013) Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation. 2014 IEEE Conference on Computer Vision and Pattern Recognition, Columbus, 23-28 June 2014, 580-587. &lt;br&gt;https://doi.org/10.1109/CVPR.2014.81</mixed-citation></ref><ref id="hanspub.42606-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Ren, S., He, K., Girshick, R. and Sun, J. (2017) Faster R-CNN: To-wards Real-Time Object Detection with Region Proposal Networks. IEEE Transactions on Pattern Analysis &amp; Machine Intelligence, 39, 1137-1149.  
&lt;br&gt;https://doi.org/10.1109/TPAMI.2016.2577031</mixed-citation></ref><ref id="hanspub.42606-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">Liu, W., Anguelov, D., Erhan, D., et al. (2016) SSD: Single Shot MultiBox Detector. In: Leibe, B., Matas, J., Sebe, N. and Welling, M., Eds., Computer Vision—ECCV 2016. ECCV 2016. Lecture Notes in Computer Science, Vol. 9905, Springer, Cham, 21-37. &lt;br&gt;https://doi.org/10.1007/978-3-319-46448-0_2</mixed-citation></ref><ref id="hanspub.42606-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">Redmon, J., Divvala, S., Girshick, R. and Farhadi, A. (2016) You Only Look Once: Unified, Real-Time Object Detection. 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Las Vegas, 27-30 June 2016, 779-788. &lt;br&gt;https://doi.org/10.1109/CVPR.2016.91</mixed-citation></ref><ref id="hanspub.42606-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">赵旭江. 基于卷积神经网络的遥感图像目标检测与识别[D]: [硕士学位论文]. 合肥: 中国科学技术大学, 2018.</mixed-citation></ref><ref id="hanspub.42606-ref17"><label>17</label><mixed-citation publication-type="other" xlink:type="simple">邓小桐, 曹铁勇, 方正, 郑云飞. 改进RetinaNet 的伪装人员检测方法研究[J]. 计算机工程与应用, 2021, 57(5): 190-196.</mixed-citation></ref><ref id="hanspub.42606-ref18"><label>18</label><mixed-citation publication-type="other" xlink:type="simple">Lin, T.Y., Goyal, P., Girshick, R., et al. (2017) Focal Loss for Dense Object Detection. 2017 IEEE In-ternational Conference on Computer Vision (ICCV), Venice, 22-29 October 2017, 2999-3007. &lt;br&gt;https://doi.org/10.1109/ICCV.2017.324</mixed-citation></ref><ref id="hanspub.42606-ref19"><label>19</label><mixed-citation publication-type="other" xlink:type="simple">宋欢欢, 惠飞, 景首才, 郭兰英, 马峻岩. 改进的RetinaNet模型的车辆目标检测[J]. 计算机工程与应用, 2019, 55(13): 225-230.</mixed-citation></ref></ref-list></back></article>