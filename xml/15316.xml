<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2015.55022</article-id><article-id pub-id-type="publisher-id">CSA-15316</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20150500000_56697720.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  决策树C4.5算法属性取值优化研究
  C4.5 of Decision Tree Algorithm Optimization of Property Values
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>黄</surname><given-names>世反</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>沈</surname><given-names>勇</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>王</surname><given-names>瑞芳</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>马</surname><given-names>华丽</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>陈</surname><given-names>长赓</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>张</surname><given-names>宇昊</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>云南大学软件学院，云南 昆明 </addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>27</day><month>05</month><year>2015</year></pub-date><volume>05</volume><issue>05</issue><fpage>171</fpage><lpage>178</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   在决策树算法中，属性取值种类的多少决定着决策树分支数量的多少。基于此，提出了一种新的属性取值优化的方法，实例证明该方法确实能优化生成决策树的分支数量，达到精简生成决策树结构的目的，且该方法对原C4.5算法的分类正确率没有影响。&lt;br/&gt;About the decision tree algorithm, the quantity of the attribute value types determines the quantity of the decision tree branch. Based on this, we put forward a new method which can optimize attribute value. The examples show that the method can optimize the quantity of the decision tree branch, and reach the purpose that simplifies the decision tree structure. This method has no effect on the classification accuracy of the C4.5 algorithm.
    
  
 
</p></abstract><kwd-group><kwd>决策树，C4.5算法，属性取值，优化, Decision Tree</kwd><kwd> C4.5 Algorithm</kwd><kwd> Property Values</kwd><kwd> Optimization</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>决策树C4.5算法属性取值优化研究<sup> </sup></title><p>黄世反<sup>*</sup>，沈勇，王瑞芳，马华丽，陈长赓，张宇昊</p><p>云南大学软件学院，云南 昆明</p><p>Email: <sup>*</sup>974794674@qq.com</p><p>收稿日期：2015年5月7日；录用日期：2015年5月23日；发布日期：2015年5月28日</p><disp-formula id="scirp.15316-formula3216"><graphic xlink:href="http://html.hanspub.org/file/5-1540454x6_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>在决策树算法中，属性取值种类的多少决定着决策树分支数量的多少。基于此，提出了一种新的属性取值优化的方法，实例证明该方法确实能优化生成决策树的分支数量，达到精简生成决策树结构的目的，且该方法对原C4.5算法的分类正确率没有影响。</p><p>关键词 :决策树，C4.5算法，属性取值，优化</p><disp-formula id="scirp.15316-formula3217"><graphic xlink:href="http://html.hanspub.org/file/5-1540454x7_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s3"><title>1. 引言</title><p>决策树算法是一种最简单、最直接、最有效的文本分类算法。最早的决策树算法是ID3算法[<xref ref-type="bibr" rid="scirp.15316-ref1">1</xref>] ，于1986年由Quinlan提出，该算法是一种基于信息熵的决策树分类算法。由于该算法是以信息熵作为属性选择的标准，偏向于选择属性取值较多的属性，而属性取值较多的属性往往分类的贡献不大。因此，于1993年Quinlan在ID3算法的基础上又提出了一种改进算法，即C4.5算法 [<xref ref-type="bibr" rid="scirp.15316-ref2">2</xref>] 。该算法采用信息增益率作为属性选择的标准，继承了ID3算法的所有优点，克服了ID3算法中偏向于选择属性取值较多的属性作为测试属性的不足，同时还能对连续属性与未知属性进行处理，在剪枝方面也有很大的改进。</p><p>C4.5算法作为经典的决策树分类算法，已被广泛的应用到各个领域。但其仍然存在以下不足之处：1) 在计算信息增益的过程中(包括：分类所需信息量、信息熵、分割信息量)涉及的复杂的对数运算，计算机每一次计算都需要调用库函数，增大了生成决策树所需的时间开销；2) 生成决策树中分支数量过多，部分分支还能进行合并，进一步精简生成决策树的结构。</p><p>针对以上不足，已有很多学者提出了改进优化算法。文献 [<xref ref-type="bibr" rid="scirp.15316-ref3">3</xref>] ，作者通过引入高等数学中等价无穷的原理，对C4.5算法中的计算公式进行了改进，用简单的四则混合运算取代了复杂的对数运算，减少了生成决策树所需的时间开销。文献 [<xref ref-type="bibr" rid="scirp.15316-ref4">4</xref>] ，作者提出了一种对属性取值进行优化合并的方法，该方法通过将属性的不同取值分成多个样本子集，并计算各个样本子集的熵以及样本子集的平均熵值，并将熵值大于平均熵值的样本子集进行合并，并重新定义一个属性取值替代原数据表中的属性取值，实例证明该方法确实能起到精简生成决策树结构的作用。</p><p>本文针对生成决策树分支数量过多的不足，提出了一种新的属性取值优化方法，并用实例分析验证了该方法的有效性。</p></sec><sec id="s4"><title>2. C4.5算法介绍</title><p>C4.5算法是一种基于信息熵的决策分类算法，该算法的核心思想是根据信息熵原理，选择样本集中信息增益率最大的属性作为分类属性，并根据该属性的不同取值构造决策树的分支，再对子集进行递归构造，直到完成决策树的构造 [<xref ref-type="bibr" rid="scirp.15316-ref5">5</xref>] 。</p><p>假设样本空间D中有正例集P个、反例集N个，且D = P + N，则一棵决策树能对待分类数据集做出正确类别判断所需的信息量为：</p><disp-formula id="scirp.15316-formula3218"><label>(1)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-1540454x8_hanspub.png"  xlink:type="simple"/></disp-formula><p>如果以属性A作为决策树的根节点，且A具有V个值 <inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-1540454x9_hanspub.png" xlink:type="simple"/></inline-formula> ，它将H分为V个样本子集 <inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-1540454x10_hanspub.png" xlink:type="simple"/></inline-formula> ，设 <inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-1540454x11_hanspub.png" xlink:type="simple"/></inline-formula> 中共有d个数据集，其中有p个正例和n个反例，则子集 <inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-1540454x12_hanspub.png" xlink:type="simple"/></inline-formula> 的信息熵 <inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-1540454x13_hanspub.png" xlink:type="simple"/></inline-formula> 可由下式计算：</p><disp-formula id="scirp.15316-formula3219"><label>(2)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-1540454x14_hanspub.png"  xlink:type="simple"/></disp-formula><p>以属性A为根节点分类的信息熵为：</p><disp-formula id="scirp.15316-formula3220"><label>(3)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-1540454x15_hanspub.png"  xlink:type="simple"/></disp-formula><p>则，以属性A为根节点的信息增益为：</p><disp-formula id="scirp.15316-formula3221"><label>(4)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-1540454x16_hanspub.png"  xlink:type="simple"/></disp-formula><p>在C4.5算法中，是以信息增益率来选择分类属性的，而信息增益率等于信息增益与分割信息量的比值，其中分割信息量可由下式计算：</p><disp-formula id="scirp.15316-formula3222"><label>(5)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-1540454x17_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中， <inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-1540454x18_hanspub.png" xlink:type="simple"/></inline-formula> 表示属性A的所有取值中，任意样本子集占总样本集的比例。则，信息增益率可由下式计算：</p><disp-formula id="scirp.15316-formula3223"><label>(6)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-1540454x19_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s5"><title>3. C4.5算法中属性取值的优化改进</title><sec id="s5_1"><title>3.1. 算法改进的基本思想</title><p>如何很好的选择测试属性决定着所构造决策树模型的质量，而所选测试属性的可能取值的数量与树的分支数量成正比。在C4.5算法中，一切计算的依据来源于信息论中的熵。因此，本文在信息熵的计算过程中，通过对测试属性的优化改进，以减少决策树的分支数量，提高决策树的质量。</p><p>根据信息熵的定义，熵值越大，对分类决策的贡献就越小。反之，熵值越小，对分类决策的贡献就越大，即能确定更多待分类对象所属类别。当信息熵为零时，对分类决策的贡献最大。当信息熵为零时，只存在两种情况，所有样本子集同属于正例集或者反例集(本文只研究只有两种决策属性的情况)。基于此，本节算法改进的基本思想为：对于给定的一组数据集，计算每个属性的信息增益率，选取信息增益最大的属性，将该属性按照属性取值的不同划分为多个样本子集，计算每一个样本子集的信息熵，取出信息熵为零的所有样本子集，并将其同属正例集或反例集的样本子集进行合并，定义新的属性取值，得到一个新的、复合的样本子集，并用该复合样本子集在测试集中替换构成该复合子集的样本子集。最后，再利用新的数据集来建立决策树。</p></sec><sec id="s5_2"><title>3.2. 改进后算法的计算步骤</title><p>由上一节的分析，我们可以得到改进后算法的基本计算步骤，如下所示：</p><p>1) 根据给定的测试集，计算各个属性的信息增益率；</p><p>2) 选择信息增益率最大的属性，将该属性按照属性取值的不同划分为多个样本子集；</p><p>3) 计算各样本子集的信息熵；</p><p>4) 选取出所有信息熵为零的样本子集，并将其中同属于正例集或反例集的样本子集进行合并，自定义新的属性取值，得到一个新的、复合的样本子集；</p><p>5) 用新形成的复合样本子集取代原数据集中组成该复合样本子集的各个样本子集；</p><p>6) 利用新形成的数据集，计算信息增益率，其余部分与C4.5算法相同。</p></sec></sec><sec id="s6"><title>4. 实例分析</title><p>表1是对学生某次考试成绩的描述，已经过离散化处理，并按照分数段将各科目分为优、良、中、差，总评分为两类：合格与不合格，如表1所示。</p><sec id="s6_1"><title>4.1. 采用第3节中的改进算法对表1进行优化及决策树的生成过程</title><p>本文中对分类所需信息量、信息熵、信息增益、分割信息的计算采用文献 [<xref ref-type="bibr" rid="scirp.15316-ref6">6</xref>] 中改进的C4.5算法计算公式进行计算。与文献 [<xref ref-type="bibr" rid="scirp.15316-ref3">3</xref>] 类似，文献 [<xref ref-type="bibr" rid="scirp.15316-ref6">6</xref>] 也是通过引入高等数学中等价无穷小的理论，对C4.5算法计算公式中繁多的对数运算进行了优化。不同的是，二者优化后的计算公式略有不同，文献 [<xref ref-type="bibr" rid="scirp.15316-ref6">6</xref>] 优化后得到的计算公式更加简洁、直观，方便计算。因此，本文选用文献 [<xref ref-type="bibr" rid="scirp.15316-ref6">6</xref>] 中的优化结果来进行相关计算。</p><p>1) 计算各属性的信息增益率</p><disp-formula id="scirp.15316-formula3224"><graphic xlink:href="http://html.hanspub.org/file/5-1540454x20_hanspub.png"  xlink:type="simple"/></disp-formula><p><img src="http://html.hanspub.org/file/5-1540454x21_hanspub.png" /> <img src="http://html.hanspub.org/file/5-1540454x22_hanspub.png" /></p><p><img src="http://html.hanspub.org/file/5-1540454x23_hanspub.png" /> <img src="http://html.hanspub.org/file/5-1540454x24_hanspub.png" /></p><p>2) 选取信息增益率最大的属性划分样本子集</p><p>由表1可得，我们可以将属性文综划分为：<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-1540454x25_hanspub.png" xlink:type="simple"/></inline-formula>、<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-1540454x26_hanspub.png" xlink:type="simple"/></inline-formula>、<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-1540454x27_hanspub.png" xlink:type="simple"/></inline-formula>、<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-1540454x28_hanspub.png" xlink:type="simple"/></inline-formula>四个样本子集。</p><p>3) 计算各样本子集的信息熵</p><p>属性文综各样本子集信息熵如下：</p><disp-formula id="scirp.15316-formula3225"><graphic xlink:href="http://html.hanspub.org/file/5-1540454x29_hanspub.png"  xlink:type="simple"/></disp-formula><p>4) 合并信息熵为零且同属正例集或反例集的样本子集</p><p>在属性文综的各样本子集中，信息熵为零的有三个子集： <inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-1540454x30_hanspub.png" xlink:type="simple"/></inline-formula> 、 <inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-1540454x31_hanspub.png" xlink:type="simple"/></inline-formula> 及 <inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-1540454x32_hanspub.png" xlink:type="simple"/></inline-formula> ，其中 <inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-1540454x33_hanspub.png" xlink:type="simple"/></inline-formula> 和 <inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-1540454x34_hanspub.png" xlink:type="simple"/></inline-formula> 同属合格，而 <inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-1540454x35_hanspub.png" xlink:type="simple"/></inline-formula> 属于不合格，因此可以将 <inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-1540454x36_hanspub.png" xlink:type="simple"/></inline-formula> 、 <inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-1540454x37_hanspub.png" xlink:type="simple"/></inline-formula> 进行合并，并定义新的属性取值为：优良。</p><p>5) 合并后的新数据集如表2所示。</p><p>经属性优化合并后，属性文综的属性取值由原来的四个变为现在的三个，这样就能减少生成决策树的分支数量。</p><p>6) 决策树的生成</p><p>a) 以属性文综为根节点建立决策树如图1所示。</p><p>b) 将剩余属性计算其信息增益率如下：</p><disp-formula id="scirp.15316-formula3226"><graphic xlink:href="http://html.hanspub.org/file/5-1540454x38_hanspub.png"  xlink:type="simple"/></disp-formula><disp-formula id="scirp.15316-formula3227"><graphic xlink:href="http://html.hanspub.org/file/5-1540454x39_hanspub.png"  xlink:type="simple"/></disp-formula><p>由计算结果可得，属性英语的信息增益率最大，计算属性英语各个样本子集的信息熵，合并属性取值后得到表3。</p><p>选取属性英语作为第二层分类属性，生成的决策树如图2所示。</p><p>c) 将剩余属性调用1到5得到表4</p><p>到此，在剩余属性中，随便选择哪个都能确定分类。最终的决策树如图3所示。</p></sec><sec id="s6_2"><title>4.2. 利用文献[<xref ref-type="bibr" rid="scirp.15316-ref6">6</xref>] 中改进的C4.5算法及表1生成决策树</title><p>由表1可知，决策属性为总评，共有20个属性值，其中正例值有17个，反例值有3个，分类所需信息量为：</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Instantiation data tabl</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >序号</th><th align="center" valign="middle" >语文</th><th align="center" valign="middle" >数学</th><th align="center" valign="middle" >英语</th><th align="center" valign="middle" >文综</th><th align="center" valign="middle" >总评</th></tr></thead><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >差</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >合格</td></tr><tr><td align="center" valign="middle" >2</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >合格</td></tr><tr><td align="center" valign="middle" >3</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >合格</td></tr><tr><td align="center" valign="middle" >4</td><td align="center" valign="middle" >优</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >合格</td></tr><tr><td align="center" valign="middle" >5</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >合格</td></tr><tr><td align="center" valign="middle" >6</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >差</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >差</td><td align="center" valign="middle" >不合格</td></tr><tr><td align="center" valign="middle" >7</td><td align="center" valign="middle" >优</td><td align="center" valign="middle" >差</td><td align="center" valign="middle" >差</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >不合格</td></tr><tr><td align="center" valign="middle" >8</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >优</td><td align="center" valign="middle" >优</td><td align="center" valign="middle" >优</td><td align="center" valign="middle" >合格</td></tr><tr><td align="center" valign="middle" >9</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >优</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >合格</td></tr><tr><td align="center" valign="middle" >10</td><td align="center" valign="middle" >优</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >合格</td></tr><tr><td align="center" valign="middle" >11</td><td align="center" valign="middle" >差</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >差</td><td align="center" valign="middle" >不合格</td></tr><tr><td align="center" valign="middle" >12</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >合格</td></tr><tr><td align="center" valign="middle" >13</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >差</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >合格</td></tr><tr><td align="center" valign="middle" >14</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >优</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >合格</td></tr><tr><td align="center" valign="middle" >15</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >差</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >合格</td></tr><tr><td align="center" valign="middle" >16</td><td align="center" valign="middle" >优</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >优</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >合格</td></tr><tr><td align="center" valign="middle" >17</td><td align="center" valign="middle" >优</td><td align="center" valign="middle" >优</td><td align="center" valign="middle" >优</td><td align="center" valign="middle" >优</td><td align="center" valign="middle" >合格</td></tr><tr><td align="center" valign="middle" >18</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >差</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >合格</td></tr><tr><td align="center" valign="middle" >19</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >差</td><td align="center" valign="middle" >优</td><td align="center" valign="middle" >合格</td></tr><tr><td align="center" valign="middle" >20</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >合格</td></tr></tbody></table></table-wrap><p>表1. 实例数据表</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> After the first method processing and merging data tabl</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >序号</th><th align="center" valign="middle" >语文</th><th align="center" valign="middle" >数学</th><th align="center" valign="middle" >英语</th><th align="center" valign="middle" >文综</th><th align="center" valign="middle" >总评</th></tr></thead><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >差</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >合格</td></tr><tr><td align="center" valign="middle" >2</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >优良</td><td align="center" valign="middle" >合格</td></tr><tr><td align="center" valign="middle" >3</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >优良</td><td align="center" valign="middle" >合格</td></tr><tr><td align="center" valign="middle" >4</td><td align="center" valign="middle" >优</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >优良</td><td align="center" valign="middle" >合格</td></tr><tr><td align="center" valign="middle" >5</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >合格</td></tr><tr><td align="center" valign="middle" >6</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >差</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >差</td><td align="center" valign="middle" >不合格</td></tr><tr><td align="center" valign="middle" >7</td><td align="center" valign="middle" >优</td><td align="center" valign="middle" >差</td><td align="center" valign="middle" >差</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >不合格</td></tr><tr><td align="center" valign="middle" >8</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >优</td><td align="center" valign="middle" >优</td><td align="center" valign="middle" >优良</td><td align="center" valign="middle" >合格</td></tr><tr><td align="center" valign="middle" >9</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >优</td><td align="center" valign="middle" >优良</td><td align="center" valign="middle" >合格</td></tr><tr><td align="center" valign="middle" >10</td><td align="center" valign="middle" >优</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >合格</td></tr><tr><td align="center" valign="middle" >11</td><td align="center" valign="middle" >差</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >差</td><td align="center" valign="middle" >不合格</td></tr><tr><td align="center" valign="middle" >12</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >优良</td><td align="center" valign="middle" >合格</td></tr><tr><td align="center" valign="middle" >13</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >差</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >合格</td></tr><tr><td align="center" valign="middle" >14</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >优</td><td align="center" valign="middle" >优良</td><td align="center" valign="middle" >合格</td></tr><tr><td align="center" valign="middle" >15</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >差</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >合格</td></tr><tr><td align="center" valign="middle" >16</td><td align="center" valign="middle" >优</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >优</td><td align="center" valign="middle" >优良</td><td align="center" valign="middle" >合格</td></tr><tr><td align="center" valign="middle" >17</td><td align="center" valign="middle" >优</td><td align="center" valign="middle" >优</td><td align="center" valign="middle" >优</td><td align="center" valign="middle" >优良</td><td align="center" valign="middle" >合格</td></tr><tr><td align="center" valign="middle" >18</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >差</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >合格</td></tr><tr><td align="center" valign="middle" >19</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >差</td><td align="center" valign="middle" >优良</td><td align="center" valign="middle" >合格</td></tr><tr><td align="center" valign="middle" >20</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >合格</td></tr></tbody></table></table-wrap><p>表2. 经方法一处理第一次合并后的数据表</p><table-wrap id="table3" ><label><xref ref-type="table" rid="table3">Table 3</xref></label><caption><title> After the first method processing and second merging data tabl</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >序号</th><th align="center" valign="middle" >语文</th><th align="center" valign="middle" >数学</th><th align="center" valign="middle" >英语</th><th align="center" valign="middle" >总评</th></tr></thead><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >差</td><td align="center" valign="middle" >合格</td></tr><tr><td align="center" valign="middle" >5</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >中良</td><td align="center" valign="middle" >合格</td></tr><tr><td align="center" valign="middle" >7</td><td align="center" valign="middle" >优</td><td align="center" valign="middle" >差</td><td align="center" valign="middle" >差</td><td align="center" valign="middle" >不合格</td></tr><tr><td align="center" valign="middle" >10</td><td align="center" valign="middle" >优</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >中良</td><td align="center" valign="middle" >合格</td></tr><tr><td align="center" valign="middle" >13</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >差</td><td align="center" valign="middle" >中良</td><td align="center" valign="middle" >合格</td></tr><tr><td align="center" valign="middle" >15</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >差</td><td align="center" valign="middle" >中良</td><td align="center" valign="middle" >合格</td></tr><tr><td align="center" valign="middle" >18</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >差</td><td align="center" valign="middle" >中良</td><td align="center" valign="middle" >合格</td></tr><tr><td align="center" valign="middle" >20</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >中良</td><td align="center" valign="middle" >合格</td></tr></tbody></table></table-wrap><p>表3. 经方法一处理第二次合并后的数据表</p><table-wrap id="table4" ><label><xref ref-type="table" rid="table4">Table 4</xref></label><caption><title> After the first method processing and third merging data tabl</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >序号</th><th align="center" valign="middle" >语文</th><th align="center" valign="middle" >数学</th><th align="center" valign="middle" >总评</th></tr></thead><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" >中</td><td align="center" valign="middle" >良</td><td align="center" valign="middle" >合格</td></tr><tr><td align="center" valign="middle" >7</td><td align="center" valign="middle" >优</td><td align="center" valign="middle" >差</td><td align="center" valign="middle" >不合格</td></tr></tbody></table></table-wrap><p>表4. 经方法一处理第三次合并后的数据表</p><p>图1. 生成决策树第一步</p><p>图2. 生成决策树第二步</p><p>图3. 由本文改进算法最终生成的决策树图</p></sec></sec></body><back><ref-list><title>References</title><ref id="hanspub.15316-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Quinlan, J.R. (1986) Induction of decision trees. Machine Learning, 1, 81-106.</mixed-citation></ref><ref id="hanspub.15316-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Quinlan, J.R. (1993) C4.5: Pro-grams for machine learning. Morgan Kaufmann, San Mateo.</mixed-citation></ref><ref id="hanspub.15316-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">黄爱辉 (2009) 决策树C4.5算法的改进及应用. 科学技术与工程, 1, 34-36.</mixed-citation></ref><ref id="hanspub.15316-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">刘鹏, 姚正, 尹俊杰 (2006) 一种有效的C4.5改进模型. 清华大学学报：自然科学版, 46, 996-1001.</mixed-citation></ref><ref id="hanspub.15316-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">李强 (2006) 创建决策树算法的比较研究-ID3, C4.5, C5.0算法的比较. 甘肃科学学报, 12, 84-87.</mixed-citation></ref><ref id="hanspub.15316-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">周琦 (2012) 改进的C4.5决策树算法研究及在高考成绩预测分析中的应用. 广西大学, 南宁.</mixed-citation></ref></ref-list></back></article>