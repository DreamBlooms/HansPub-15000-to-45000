<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">ASS</journal-id><journal-title-group><journal-title>Advances in Social Sciences</journal-title></journal-title-group><issn pub-type="epub">2169-2556</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/ASS.2021.104112</article-id><article-id pub-id-type="publisher-id">ASS-41555</article-id><article-categories><subj-group subj-group-type="heading"><subject>ASS20210400000_34185659.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>人文社科</subject></subj-group></article-categories><title-group><article-title>
 
 
  面孔生命性知觉的影响因素和加工机制
  The Influential Factors and Processing Mechanism of Animacy Perception of Face
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>许</surname><given-names>冰</given-names></name><xref ref-type="aff" rid="aff1"><sub>1</sub></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib></contrib-group><aff id="aff1"><label>1</label><addr-line>广州大学教育学院，广东 广州</addr-line></aff><pub-date pub-type="epub"><day>15</day><month>04</month><year>2021</year></pub-date><volume>10</volume><issue>04</issue><fpage>819</fpage><lpage>826</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
  面孔生命性知觉是指区分真实面孔和人工面孔的适应性能力。近年来，研究者利用行为学实验、事件相关电位技术和脑成像等方法考察面孔生命性知觉的影响因素和加工机制。眼睛及面部整体特征、面孔性别、面孔情绪和社交联结是主要影响因素。在加工机制上，真实面孔与人工面孔既有共同激活的区域，又有各自特异性的脑区。目前尚存的争议主要集中在面孔生命性知觉的产生阶段。未来研究可以结合时代背景对面孔生命性知觉的脑机制进行更多探索。
   The animacy perception of face refers to the adaptive ability to distinguish real faces from artifi-cial faces. In recent years, researchers have used behavioral experiments, event-related potential technology and brain imaging technology to investigate the influential factors and processing mechanism of animacy perception of face. Eye features and the whole features of face, face gender, face emotion and social connection were the main influential factors. In terms of processing mechanism, real face and artificial face have both commonly activated regions and specific brain regions. At present, the controversy mainly focused on the stage of animacy perception of face. Future research can explore the neural mechanism of animacy perception of face with the background of the times.
 
</p></abstract><kwd-group><kwd>面孔加工，生命性知觉，真实面孔，人工面孔, Face Processing</kwd><kwd> Animacy Perception</kwd><kwd> Real faces</kwd><kwd> Artificial Faces</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>摘要</title><p>面孔生命性知觉是指区分真实面孔和人工面孔的适应性能力。近年来，研究者利用行为学实验、事件相关电位技术和脑成像等方法考察面孔生命性知觉的影响因素和加工机制。眼睛及面部整体特征、面孔性别、面孔情绪和社交联结是主要影响因素。在加工机制上，真实面孔与人工面孔既有共同激活的区域，又有各自特异性的脑区。目前尚存的争议主要集中在面孔生命性知觉的产生阶段。未来研究可以结合时代背景对面孔生命性知觉的脑机制进行更多探索。</p></sec><sec id="s2"><title>关键词</title><p>面孔加工，生命性知觉，真实面孔，人工面孔</p></sec><sec id="s3"><title>The Influential Factors and Processing Mechanism of Animacy Perception of Face</title><p>Bing Xu</p><p>School of Education of Guangzhou University, Guangzhou Guangdong</p><p><img src="//html.hanspub.org/file/1-2392630x4_hanspub.png" /></p><p>Received: Mar. 9<sup>th</sup>, 2021; accepted: Apr. 8<sup>th</sup>, 2021; published: Apr. 15<sup>th</sup>, 2021</p><p><img src="//html.hanspub.org/file/1-2392630x5_hanspub.png" /></p></sec><sec id="s4"><title>ABSTRACT</title><p>The animacy perception of face refers to the adaptive ability to distinguish real faces from artificial faces. In recent years, researchers have used behavioral experiments, event-related potential technology and brain imaging technology to investigate the influential factors and processing mechanism of animacy perception of face. Eye features and the whole features of face, face gender, face emotion and social connection were the main influential factors. In terms of processing mechanism, real face and artificial face have both commonly activated regions and specific brain regions. At present, the controversy mainly focused on the stage of animacy perception of face. Future research can explore the neural mechanism of animacy perception of face with the background of the times.</p><p>Keywords:Face Processing, Animacy Perception, Real faces, Artificial Faces</p><disp-formula id="hanspub.41555-formula4"><graphic xlink:href="//html.hanspub.org/file/1-2392630x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2021 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/1-2392630x7_hanspub.png" /> <img src="//html.hanspub.org/file/1-2392630x8_hanspub.png" /></p></sec><sec id="s5"><title>1. 引言</title><p>生命性(animacy)是物质世界客观存在的一种基本属性。一般来说，人们能够较轻松地区分出有生命的物体和无生命的物体。但如果涉及到要用文字来解释何为生命时，事情就不是如此简单了。关于生命性的定义，不同的研究者也有不同的观点。部分研究者认为，生命性是一个范畴概念，也是一个二分变量，存在于自然界的物体可以简单地划分为两类：有生命的(living)和无生命的(non-living) [<xref ref-type="bibr" rid="hanspub.41555-ref1">1</xref>]；另一部分研究者认为，生命性是一个较复杂的连续变量 [<xref ref-type="bibr" rid="hanspub.41555-ref2">2</xref>]，在这个连续体中，人的生命性最高，其次是动、植物，最末端则是无生命的物体 [<xref ref-type="bibr" rid="hanspub.41555-ref3">3</xref>]。早在婴儿时期，人类就拥有了区分有生命物体和无生命物体的能力，即具备了生命性知觉(perception of animacy) [<xref ref-type="bibr" rid="hanspub.41555-ref4">4</xref>] [<xref ref-type="bibr" rid="hanspub.41555-ref5">5</xref>]。2岁的婴幼儿对于两者特征的区分就有清晰的心理表征 [<xref ref-type="bibr" rid="hanspub.41555-ref6">6</xref>]，3~5岁的儿童可以从客体的运动或静止、构造属性等方面区分人和石头以及人和洋娃娃 [<xref ref-type="bibr" rid="hanspub.41555-ref7">7</xref>]。而对阿尔兹海默症的患者而言，生命性知觉是他们尚存的能力之一 [<xref ref-type="bibr" rid="hanspub.41555-ref8">8</xref>]。由此看来，生命性知觉似乎是人类与生俱来的本能 [<xref ref-type="bibr" rid="hanspub.41555-ref9">9</xref>]。</p><p>在日常生活中，面孔是常见的生命性刺激之一。一张鲜活的面孔提供了与个体的年龄、性别、种族、情绪和吸引力等特征相关的社会信息，对人类进化和社会交往的助益不言而喻。以往研究表明，个体在几百毫秒内就可以完成对面孔的识别 [<xref ref-type="bibr" rid="hanspub.41555-ref10">10</xref>] [<xref ref-type="bibr" rid="hanspub.41555-ref11">11</xref>]，即便在无意识状态中，我们也能准确而快速地检测到面孔 [<xref ref-type="bibr" rid="hanspub.41555-ref12">12</xref>]。这意味着，人类是天生的面孔识别专家，匆匆一瞥后，与面孔相关的诸多信息即刻在头脑中得到加工。此外，相比其他无生命物体，面孔的独特还体现在吸引注意的优先性上。研究表明，即便在高感知负载的条件下，面孔也比其他物体更能捕获注意 [<xref ref-type="bibr" rid="hanspub.41555-ref13">13</xref>]。人们甚至会在根本不存在的面孔的物体上(如月球表面、云朵或面包片等)感知到面孔。从面孔的进化意义来说，漏报似乎比虚报要付出的代价更大 [<xref ref-type="bibr" rid="hanspub.41555-ref14">14</xref>]，正因如此，我们有更强烈的倾向去感知面孔的存在。</p><p>近年来，随着仿真技术和人工智能的发展，人工面孔(artificial face，如玩偶、机器人、蜡像等)开始频繁地出现在大众眼前。尽管人工面孔制作技术日渐精细化，在外型上与真实面孔(real face/human face)高度相似，但个体还是能敏锐且准确地区分真实面孔和人工面孔。其中，生命性知觉发挥着重要的作用，它让个体具备快速觉察视野范围内的面孔是否具有生命性的能力。以往研究表明，真实面孔的加工速度 [<xref ref-type="bibr" rid="hanspub.41555-ref15">15</xref>]、记忆效果 [<xref ref-type="bibr" rid="hanspub.41555-ref16">16</xref>] 和可信度 [<xref ref-type="bibr" rid="hanspub.41555-ref17">17</xref>] 均明显优于人工面孔。那么，这种加工差异从何而来？面孔的哪些信息会影响生命性知觉的判断？加工真实面孔和人工面孔的神经机制有何不同？本文将从以上三个问题出发，总结面孔生命性知觉领域内已有的研究成果，并对未来可行的研究方向做出展望。</p></sec><sec id="s6"><title>2. 生命性知觉的相关理论</title><sec id="s6_1"><title>2.1. 生命性监控假说</title><p>在生产力水平低下的远古时期，人类只能以狩猎和采摘果实等方式获取食物。面对资源丰富又危险重重的环境，他们必须具备区分生物和非生物的能力，从而避免自己的生命受到潜在捕食者的威胁。据此，New等人提出生命性监控假说(the animate monitoring hypothesis)，他们认为人类认知系统中存在一个特殊的生命性监控系统，确保我们在复杂视觉环境中优先搜索生命性刺激(如面孔) [<xref ref-type="bibr" rid="hanspub.41555-ref18">18</xref>]。因为生命性刺激具有不可预测、自发运动的可能，他们可以在毫无预警地情况下快速改变行动轨迹，甚至发起暴力行为。生命性监控系统的存在，使个体对生命保持高度警醒，有利于规避危险和生存繁衍 [<xref ref-type="bibr" rid="hanspub.41555-ref19">19</xref>]。</p><p>依据生命性监控假说，这种敏感于生命性刺激的认知机制是适应环境后通过进化得来，也就是说，生命性加工优势不仅能在发育健全的成年人身上观察到，恐怕在婴幼儿身上也存在类似的加工优势。最近的一项研究首次为这一说法提供了证据支持，研究结果显示，4~5岁的儿童与成年人的表现一致，对于生命性刺激的记忆明显好于非生命刺激 [<xref ref-type="bibr" rid="hanspub.41555-ref20">20</xref>]。综上，人类更多是迫于生存需求进化出区分生物和非生物的监控系统，其中可能也包括了区分真实面孔与人工面孔的功能。而且，对生命性刺激的加工优势由来已久，并不完全是后天的学习经验所致。</p></sec><sec id="s6_2"><title>2.2. 早期和晚期加工理论</title><p>进一步地，研究者们采用事件相关电位(event-related potentials, ERP)技术考察面孔生命性知觉在面孔加工过程中的时间节点，主要存在两种观点：一种是早期加工理论，认为面孔生命性知觉发生在面孔加工早期；一种是晚期加工理论，主张面孔生命性知觉在面孔加工的晚期阶段出现。</p><p>早期加工理论的证据主要来自于P1成分敏感于生命性的研究。Balas和Koldewyn的研究结果显示，相比于真实面孔，人工面孔所诱发的P1成分(出现在刺激呈现后的100~140 ms)更大，而两种面孔在N170和LPP等较晚期的成分上并无显著差异 [<xref ref-type="bibr" rid="hanspub.41555-ref21">21</xref>]。这似乎表明，区分有生命和无生命面孔的过程发生在认知加工早期，以早期ERP成分——P1作为代表指标。然而，另有研究者发现真实面孔和人工面孔的差异并非体现在P1上，如Nihei等人的研究表明，与非面孔刺激相比，面孔刺激和Arcimboldo 画作(将蔬菜和花朵等物体组合成面孔)都能诱发P1成分，且两种刺激的P1波幅无显著差别 [<xref ref-type="bibr" rid="hanspub.41555-ref22">22</xref>]。相反，Wheatley等人只在较晚期的LPP (late positive potential)成分(约400 ms后)上找到了真实面孔和人工面孔的差异 [<xref ref-type="bibr" rid="hanspub.41555-ref23">23</xref>]，从而验证了面孔生命性加工发生在晚期阶段的观点 [<xref ref-type="bibr" rid="hanspub.41555-ref24">24</xref>]。</p><p>综上，目前对于面孔生命性知觉的发生时段尚存争议。以P1成分为指标的早期加工理论认为，面孔生命性知觉的加工阶段同时甚至早于面孔结构编码阶段；以LPP成分为指标的晚期加工理论认为，生命性知觉属于复杂的高阶信息，需要在面孔结构加工之后进行精细编码，因而发生在晚期阶段。</p></sec></sec><sec id="s7"><title>3. 面孔生命性知觉的影响因素</title><p>一张面孔中不仅包含了结构和特征等知觉信息，也包括了性别、情绪、种族等社会信息。即便人工面孔在某些程度上与真实面孔高度相似，我们依然能准确地判断出呈现在面前的这张面孔是真是假。哪些因素在面孔生命性知觉的判断过程中起着关键作用？总结以往的研究结果，本文概述了四个主要的影响因素：眼睛及面部整体特征，面孔性别，面孔情绪，社会交往。</p><sec id="s7_1"><title>3.1. 眼睛及面部整体特征</title><p>俗话说：“眼睛是心灵的窗户。”眼睛在传递情绪、意图和非言语信息中都发挥着不可替代的作用，人们甚至可以通过眼部的特征来准确感知一张面孔是否具有生命。以往研究表明，眼睛在面部特征中是预测面孔生命性的最佳线索，人类对由眼睛所携带的特定线索非常敏感，能够依此决定对生命的分类感知 [<xref ref-type="bibr" rid="hanspub.41555-ref25">25</xref>]。此外，Balas和Horski探讨是否可以通过移植真人眼睛来“移植生命”，其结果显示，虽然已把真人眼睛移植到人工面孔上，但却没能发现判断人工面孔具有生命性的概率增大；相反，当把人工眼睛移植到真实面孔上时，判断真实面孔不具有生命性的概率却显著增大 [<xref ref-type="bibr" rid="hanspub.41555-ref26">26</xref>]。这至少说明眼睛并非是产生生命性知觉的唯一因素，其他的面部特征也可能影响对面孔生命性的判断。而真实眼睛和人工眼睛对判断面孔生命性是否具有不对称的影响，这一点还需获得更多的实证证据支持。</p><p>简而言之，在面孔的诸多特征中，眼部特征对判断面孔生命性所占的权重最大，但个体不能以单一特征感知生命，最终的判断还需结合各种不同强度的特征，即依赖于对面部整体特征的加工。</p></sec><sec id="s7_2"><title>3.2. 面孔性别</title><p>Balas的研究还考察了面孔性别与真实面孔、人工面孔的相互影响 [<xref ref-type="bibr" rid="hanspub.41555-ref27">27</xref>]。结果表明，面孔刺激的性别会影响真实面孔和人工面孔生命性的主观评分，具体来说，参与者更倾向于把女性面孔看成是人工面孔，更容易将男性面孔视为真实面孔；同样的，不同生命性的面孔也会影响性别分类，亦即人工面孔看起来更女性化，真实面孔看起来更男性化。对此，研究者认为可以从知觉层面来解释：相比男性面孔，女性面孔的皮肤通常更白、更有光泽，下巴轮廓更窄，且有更大的眼睛和更小的嘴鼻，这些特征与人工面孔(如芭比娃娃)的典型特征是一致的。因此，人工面孔与女性面孔更为相似，而且这种相似可能是由于女性面孔物化所导致。</p><p>然而，近期的研究否定了女性面孔物化的解释。Bowling和Banissy采用计算机生成的没有明显女性特征的面孔作为刺激材料，发现当要求参与者评价面孔的生命性和心智性时，女性面孔还是更容易被看成是人工面孔 [<xref ref-type="bibr" rid="hanspub.41555-ref28">28</xref>]。这说明即便尽可能地控制女性面孔的物化特征，性别对面孔生命性依然存在强有力的影响，而这种影响背后的神经机制目前尚不清楚。</p></sec><sec id="s7_3"><title>3.3. 面孔情绪</title><p>对于面孔生命性知觉而言，Bowling和Banissy认为情绪的影响也是不容忽视的。前文所提到的眼部特征也是传递情绪信息的关键线索之一，如果生命性知觉在一定程度上反映的是觉察情绪的能力，那么相比于面无表情的中性面孔，一张情绪性面孔的生命性可能更强 [<xref ref-type="bibr" rid="hanspub.41555-ref28">28</xref>]。研究结果证明，面孔情绪确实能够调节人们的面孔生命性知觉，具体而言，快乐面孔被感知为有生命性的阈值低于中性面孔，也就是说，快乐面孔更有可能被感知为有生命的面孔。但由于该研究中只用到了中性面孔和快乐面孔，尚不可知这种影响是否仅适用于快乐面孔，其结论的普适性有待进一步验证。未来的研究应侧重于探讨面孔消极情绪和积极情绪在面孔生命性知觉中的作用，以及不同的情绪是否会对生命性知觉产生不同的影响。</p></sec><sec id="s7_4"><title>3.4. 社交联结</title><p>除了来自刺激本身的自下而上的知觉信息(眼睛及面部整体特征)和社会信息(性别、情绪)之外，自上而下的个体特征也对面孔生命性知觉有所影响。当主动发起社交时，我们需要有效检测环境中潜在的可联结目标(如活生生的人)。Powers等人认为，个体的社交联结动机未能得到满足时，仅需要较少的自下而上的信息来检测可联结的目标 [<xref ref-type="bibr" rid="hanspub.41555-ref29">29</xref>]。他们的结果表明，倾向于认为自己与社会脱节的个体会降低生命性知觉阈限，换言之，在生命性信息极少的环境中，社交联结更少的人也会持续寻找生命性信息。这是社交联结能影响面孔生命性知觉的首个证据，从进化的角度来看，这种适应性策略也能保证社交联结最大化。</p></sec></sec><sec id="s8"><title>4. 面孔生命性知觉的加工机制</title><p>近年来，部分研究采用ERP、功能性核磁共振成像(functional magnetic resonance imaging, fMRI)技术考察了面孔生命性知觉的加工机制。ERP技术能采集到高时间分辨率(毫秒级)的数据，fMRI技术能提供高空间分辨率的数据，两种技术在一定程度上相辅相成，互为补充。</p><p>在ERP领域，研究者们发现N170这种ERP指标是面孔特异性成分 [<xref ref-type="bibr" rid="hanspub.41555-ref30">30</xref>]，换言之，与其他类别的刺激(如房子、汽车等)相比，面孔刺激所诱发的N170显著更大 [<xref ref-type="bibr" rid="hanspub.41555-ref31">31</xref>] [<xref ref-type="bibr" rid="hanspub.41555-ref32">32</xref>]。目前的研究显示，类似N170这种面孔加工的神经指标也敏感于面孔生命性，相比于非面孔刺激，面孔刺激或面孔相似(face-like)的刺激所诱发的N170更大 [<xref ref-type="bibr" rid="hanspub.41555-ref33">33</xref>] [<xref ref-type="bibr" rid="hanspub.41555-ref34">34</xref>] [<xref ref-type="bibr" rid="hanspub.41555-ref35">35</xref>]。此外，Wheatley等人对比真实面孔、人工面孔和时钟三类材料，结果表明，真实面孔和人工面孔所诱发的N170均显著大于物体的N170，但真实面孔和人工面孔的差异主要体现在晚期成分LPP上。因此，他们提出面孔生命性知觉可能包含两个阶段：第一阶段是对面孔或面孔相似刺激的快速检测，第二阶段是对面孔信息进行精细加工和编码，而生命性信息可能在第二阶段才得到加工 [<xref ref-type="bibr" rid="hanspub.41555-ref23">23</xref>]。然而，正如前文所提到的早期(P1)和晚期(LPP)知觉理论之争，目前ERP结果的不统一使得面孔生命性知觉的加工时程还无法确定。究其原因，可预见的是生命性信息难以从面孔其他信息中分离出来，以及刺激材料和实验范式上的差异。</p><p>在fMRI领域，研究者发现相比于其他物体类别，面孔刺激能够显著地激活大脑中的梭状回区域(fusiform face area, FFA)，即面孔识别相关的区域 [<xref ref-type="bibr" rid="hanspub.41555-ref36">36</xref>] [<xref ref-type="bibr" rid="hanspub.41555-ref37">37</xref>]。随后，Gobbini等人发现，当对真实面孔和人工面孔进行加工时，FFA、颞上沟区(superior temporal sulcus region, STS)和镜像神经元系统(human mirror neuron system)均被激活 [<xref ref-type="bibr" rid="hanspub.41555-ref38">38</xref>]。而且，在内侧前额叶皮层(medial prefrontal cortex, mPFC)和前颞叶皮层(anterior temporal cortex)中，真实面孔比人工面孔唤起了更强烈的活动，这说明有生命的物体和无生命的物体在大脑加工中也有所不同 [<xref ref-type="bibr" rid="hanspub.41555-ref39">39</xref>]。另有研究证明，生命性物体的加工激活大脑的腹外侧视觉区域(ventrolateral visual brain regions)，非生命性物体的加工激活腹内侧区域(ventromedial regions) [<xref ref-type="bibr" rid="hanspub.41555-ref40">40</xref>]。而对于神经损伤患者的研究进一步显示，患者在生命类别上表现出语义缺陷，但对非生命类别的知识却并无缺损 [<xref ref-type="bibr" rid="hanspub.41555-ref41">41</xref>]，这表明有生命的物体和无生命的物体的神经机制有所差异，至少在解剖结构上两者的加工可能处于不同区域。</p><p>总的来说，面孔和面孔相似刺激均能诱发N170，说明个体能准确区分面孔和其他类别的刺激。在时间上，对面孔生命性知觉加工时程的探讨主要集中在P1、LPP等成分上，目前还需更多的证据以得到较为统一的结论；在空间上，有生命的物体与无生命物体之间可能既有共同的激活脑区，也有不同的加工区域。</p></sec><sec id="s9"><title>5. 总结与展望</title><p>面孔生命性知觉作为一项重要的适应性能力，在原始社会有助于生存繁衍，并将遗传物质传递给后代，从而在我们的认知系统中留下印记。从目前研究成果中可以得到三点重要的结论：1) 对于真实面孔与人工面孔的加工差异，或许可以用生命性监控假说来解释，简言之，这种差异主要是通过进化而产生的一种适应性机制，此外，后天的学习经验也有一定的帮助；2) 面孔生命性知觉会受到眼睛及面部整体特征、面孔性别、面孔情绪和社交联结等因素的影响；3) 关于面孔生命性知觉的神经机制，研究主要从时间进程和空间定位两方面进行了探讨。在时间上，面孔生命性知觉的加工时程还存在早期(P1成分)和晚期(LPP成分)之争；在空间上，真实面孔和人工面孔可能既存在共同激活脑区(如FFA、STS等区域)，又存在不同的加工区域(如腹内侧与腹外侧视觉区域)。虽然对面孔生命性知觉的研究已取得一些进展，但还远远不能揭示这一问题的全貌。以下指出一些可能的问题，留待后来的研究者继续深入探索。</p><p>第一，生命与非生命之间的界限何在？以往有研究考察了“看起来像面孔”和“有生命的面孔”两者差异的临界点，结果显示处于生命性知觉阈限附近的面孔，个体对其变化最为敏感 [<xref ref-type="bibr" rid="hanspub.41555-ref25">25</xref>]。而研究中所提到的生命性知觉阈限，指的是判断为真实面孔的最小生命性等级或判断为人工面孔的最大生命性等级。未来的研究可以进一步考察生命与非生命之间的转折点在哪里？两者在认知过程中是一种渐进的还是突变的关系？认识生命与非生命时，恐怖谷理论(the uncanny valley)曾提出，当一个物体与人类非常相似但又非人时，会诱发厌恶反感等负面情绪 [<xref ref-type="bibr" rid="hanspub.41555-ref42">42</xref>]。比如，有眼睛的石头比现实生活中见到的石头更为可爱 [<xref ref-type="bibr" rid="hanspub.41555-ref43">43</xref>]，但这种可爱程度随着石头与人的相似变得非常接近而减少，直到人们觉得怪异和恐怖。也就是说，物体与人类的相似性与其可爱度之间存在非线性的关系 [<xref ref-type="bibr" rid="hanspub.41555-ref44">44</xref>] [<xref ref-type="bibr" rid="hanspub.41555-ref45">45</xref>] [<xref ref-type="bibr" rid="hanspub.41555-ref46">46</xref>]。因此，探讨生命和非生命之间的界限是有必要的，未来也许能找到恐怖谷产生的原因并解决这一问题。</p><p>第二，随着人工智能技术的发展，人工面孔和真实面孔的加工是否会趋于一致？面孔生命性效应是否会不复存在？有趣的是，最近的研究体现了一种趋势，即对生命性的优先注意甚至可以推广到无生命但看起来像有生命的物体(乐高)上 [<xref ref-type="bibr" rid="hanspub.41555-ref47">47</xref>]。研究在五个实验中对比了乐高人和非人之间的加工差异，实验结果显示，即便控制了异质性并排除了低层次物理属性的干扰，与乐高中的非人物体相比，乐高人始终具有更快的变化检测速度和更高的定位精度。这一结果提供了一个重要的思路：我们对与人类相似但无生命的物体是否具有优先级泛化的可能？随着未来社会人工智能的普及，机器人越来越多地走进人类家庭，在这种社会现状下，生命性知觉又会发生何种变化？具体来说，对类似于真实面孔的人工面孔的熟悉性是否会影响面孔生命性知觉呢？这些问题都是需要进一步考虑和探索的。</p><p>从目前的研究结果来看，面孔是生命性刺激中较为特殊的一类，面孔生命性知觉是随着人类进化发展而来的一种适应性能力。时代发展瞬息万变，关于面孔生命性知觉的影响因素、加工机制，乃至其定义，都有可能需要不断更新并补足证据。但无论如何，生命对于我们而言都是极为特殊的，人类作为一种生命体，也许生来就会对同类生命体另眼相看。</p></sec><sec id="s10"><title>文章引用</title><p>许 冰. 面孔生命性知觉的影响因素和加工机制The Influential Factors and Processing Mechanism of Animacy Perception of Face[J]. 社会科学前沿, 2021, 10(04): 819-826. https://doi.org/10.12677/ASS.2021.104112</p></sec><sec id="s11"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.41555-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Gelman, R. and Spelke, E.S. (1981) The Development of Thoughts about Animate and Inanimate Objects: Implications for Research in Social Cognition. In: Flavell, J.H. and Ross, L., Eds., The Development of Social Cognition in Children, Cam-bridge University Press, Cambridge, 43-66.</mixed-citation></ref><ref id="hanspub.41555-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Sha, L., Haxby, J.V., Abdi, H., Guntupalli, J.S., Oosterhof, N.N., Halchenko, Y.O. and Connolly, A.C. (2015) The Animacy Continuum in the Human Ventral Vision Pathway. Journal of Cognitive Neuroscience, 27, 665-678.  
&lt;br&gt;https://doi.org/10.1162/jocn_a_00733</mixed-citation></ref><ref id="hanspub.41555-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Comrie, B. (1989) Language Universals and Linguistic Typology: Syntax and Morphology. University of Chicago Press, Chicago.</mixed-citation></ref><ref id="hanspub.41555-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Legerstee, M. (1992) A Review of the Animate-Inanimate Distinction in Infancy: Implications for Models of Social and Cognitive Knowing. Early Development and Parenting, 1, 59-67. &lt;br&gt;https://doi.org/10.1002/edp.2430010202</mixed-citation></ref><ref id="hanspub.41555-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Barrett, H.C., Todd, P.M., Miller, G.F. and Blythe, P.W. (2005) Accurate Judgments of Intention from Motion Cues Alone: A Cross-Cultural Study. Evolution and Human Behavior, 26, 313-331.  
&lt;br&gt;https://doi.org/10.1016/j.evolhumbehav.2004.08.015</mixed-citation></ref><ref id="hanspub.41555-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Rakison, D.H. and Poulin-Dubois, D. (2001) Developmental Origin of the Animate-Inanimate Distinction. Psychological Bulletin, 127, 209-228. &lt;br&gt;https://doi.org/10.1037/0033-2909.127.2.209</mixed-citation></ref><ref id="hanspub.41555-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">方富熹. 3-5岁儿童关于认知生物和非生物的实验研究[J]. 心理学报, 1985, 17(1): 64-72.</mixed-citation></ref><ref id="hanspub.41555-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Hodges, J.R., Graham, N. and Patterson, K. (1995) Charting the Progression in Semantic Dementia: Implications for the Organization of Semantic Memory. Memory, 3, 463-495. &lt;br&gt;https://doi.org/10.1080/09658219508253161</mixed-citation></ref><ref id="hanspub.41555-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">杨格晴, 祁新越, 允寒琦, 杨春亮. 生命何以特殊? 生命性对记忆的影响及认知机制[J]. 心理学进展, 2020, 10(8): 1274-1285. &lt;br&gt;https://doi.org/10.12677/ap.2020.108150</mixed-citation></ref><ref id="hanspub.41555-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Joyce, C. and Rossion, B. (2005) The Face-Sensitive N170 and VPP Components Manifest the Same Brain Processes: The Effect of Reference Electrode Site. Clinical Neurophysiology, 116, 2613-2631.  
&lt;br&gt;https://doi.org/10.1016/j.clinph.2005.07.005</mixed-citation></ref><ref id="hanspub.41555-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Zhang, Y., Li, J., Wang, Z., Zhao, L., Wang, W. and Miao, D. (2018) Perceptual Expertise Impacts Preattentive Processing of Visual Simple Feature: A Visual Mismatch Negativity Study. Neuroreport, 29, 341-346.  
&lt;br&gt;https://doi.org/10.1097/WNR.0000000000000947</mixed-citation></ref><ref id="hanspub.41555-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Jiang, Y., Costello, P. and He, S. (2007) Processing of Invisible Stimuli: Advantage of Upright Faces and Recognizable Words in Overcoming Interocular Suppression. Psychological Science, 18, 349-355.  
&lt;br&gt;https://doi.org/10.1111/j.1467-9280.2007.01902.x</mixed-citation></ref><ref id="hanspub.41555-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Lavie, N., Ro, T. and Russell, C. (2003) The Role of Perceptual Load in Processing Distractor Faces. Psychological Science, 14, 510-515. &lt;br&gt;https://doi.org/10.1111/1467-9280.03453</mixed-citation></ref><ref id="hanspub.41555-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">王昊, 杨志刚. 面孔空想性错视及其神经机制[J]. 心理科学进展, 2018, 26(11): 56-64.</mixed-citation></ref><ref id="hanspub.41555-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">王玲, 王静梅, 王军利, 卢英俊. 卡通面孔与真实面孔识别的ERP比较研究[J]. 心理研究, 2012(5): 19-28.</mixed-citation></ref><ref id="hanspub.41555-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">Balas, B. and Auen, A. (2019) Perceiving Animacy in Own- and Other-Species Faces. Frontiers in Psychology, 10, 29.  
&lt;br&gt;https://doi.org/10.3389/fpsyg.2019.00029</mixed-citation></ref><ref id="hanspub.41555-ref17"><label>17</label><mixed-citation publication-type="other" xlink:type="simple">Balas, B. and Pacella, J. (2017) Trustworthiness Perception Is Disrupted in Artificial Faces. Computers in Human Behavior, 77, 240-248. &lt;br&gt;https://doi.org/10.1016/j.chb.2017.08.045</mixed-citation></ref><ref id="hanspub.41555-ref18"><label>18</label><mixed-citation publication-type="other" xlink:type="simple">New, J., Cosmides, L. and Tooby, J. (2007) Category-Specific Attention for Animals Reflects Ancestral Priorities, Not Expertise. Proceedings of the National Academy of Sciences of the United States of America, 104, 16598-16603.  
&lt;br&gt;https://doi.org/10.1073/pnas.0703913104</mixed-citation></ref><ref id="hanspub.41555-ref19"><label>19</label><mixed-citation publication-type="other" xlink:type="simple">向敬兰. 生命性感知的研究述评[J]. 心理学进展, 2020, 10(11): 6.</mixed-citation></ref><ref id="hanspub.41555-ref20"><label>20</label><mixed-citation publication-type="other" xlink:type="simple">Loucks, J., Verrett, K. and Reise, B. (2020) Animates Engender Robust Memory Representations in Adults and Young Children. Cognition, 201, Article ID: 104284. &lt;br&gt;https://doi.org/10.1016/j.cognition.2020.104284</mixed-citation></ref><ref id="hanspub.41555-ref21"><label>21</label><mixed-citation publication-type="other" xlink:type="simple">Balas, B. and Koldewyn, K. (2013) Early Visual ERP Sensitivity to the Species and Animacy of Faces. Neuropsychologia, 51, 2876-2881. &lt;br&gt;https://doi.org/10.1016/j.neuropsychologia.2013.09.014</mixed-citation></ref><ref id="hanspub.41555-ref22"><label>22</label><mixed-citation publication-type="other" xlink:type="simple">Nihei, Y., Minami, T. and Nakauchi, S. (2018) Brain Activity Related to the Judgment of Face-Likeness: Correlation between EEG and Face-Like Evaluation. Frontiers in Human Neuroscience, 12, 56.  
&lt;br&gt;https://doi.org/10.3389/fnhum.2018.00056</mixed-citation></ref><ref id="hanspub.41555-ref23"><label>23</label><mixed-citation publication-type="other" xlink:type="simple">Wheatley, T., Weinberg, A., Looser, C., Moran, T. and Hajcak, G. (2011) Mind Perception: Real But Not Artificial Faces Sustain Neural Activity beyond the N170/VPP. PLoS ONE, 6, e17960.  
&lt;br&gt;https://doi.org/10.1371/journal.pone.0017960</mixed-citation></ref><ref id="hanspub.41555-ref24"><label>24</label><mixed-citation publication-type="other" xlink:type="simple">严世振. 面孔生命性知觉的神经机制[D]: [硕士学位论文]. 天津: 天津师范大学, 2019.</mixed-citation></ref><ref id="hanspub.41555-ref25"><label>25</label><mixed-citation publication-type="other" xlink:type="simple">Looser, C.E. and Wheatley, T. (2010) The Tipping Point of Animacy. How, When, and Where We Perceive Life in a Face. Psychological Science, 21, 1854-1862. &lt;br&gt;https://doi.org/10.1177/0956797610388044</mixed-citation></ref><ref id="hanspub.41555-ref26"><label>26</label><mixed-citation publication-type="other" xlink:type="simple">Balas, B. and Horski, J. (2012) You Can Take the Eyes out of the Doll, But.... Perception, 41, 361-364.  
&lt;br&gt;https://doi.org/10.1068/p7166</mixed-citation></ref><ref id="hanspub.41555-ref27"><label>27</label><mixed-citation publication-type="other" xlink:type="simple">Balas, B. (2013) Biological Sex Determines Whether Faces Look Real. Visual Cognition, 21, 766-788.  
&lt;br&gt;https://doi.org/10.1080/13506285.2013.823138</mixed-citation></ref><ref id="hanspub.41555-ref28"><label>28</label><mixed-citation publication-type="other" xlink:type="simple">Bowling, N.C. and Banissy, M.J. (2017) Emotion Expression Modulates Perception of Animacy from Faces. Journal of Experimental Social Psychology, 71, 83-95. &lt;br&gt;https://doi.org/10.1016/j.jesp.2017.02.004</mixed-citation></ref><ref id="hanspub.41555-ref29"><label>29</label><mixed-citation publication-type="other" xlink:type="simple">Powers, K.E., Worsham, A.L., Freeman, J.B., Wheatley, T. and Hea-therton, T.F. (2014) Social Connection Modulates Perceptions of Animacy. Psychological Science, 25, 1943-1948. &lt;br&gt;https://doi.org/10.1177/0956797614547706</mixed-citation></ref><ref id="hanspub.41555-ref30"><label>30</label><mixed-citation publication-type="other" xlink:type="simple">Bentin, S., Allison, T., Puce, A., Perez, E. and McCarthy, G. (1996) Electrophysiological Studies of Face Perception in Humans. Journal of Cognitive Neuroscience, 8, 551-565. &lt;br&gt;https://doi.org/10.1162/jocn.1996.8.6.551</mixed-citation></ref><ref id="hanspub.41555-ref31"><label>31</label><mixed-citation publication-type="other" xlink:type="simple">Eimer, M. (2000) Event-Related Brain Potentials Distinguish Processing Stages Involved in Face Perception and Recognition. Clinical Neurophysiology, 111, 694-705. &lt;br&gt;https://doi.org/10.1016/S1388-2457(99)00285-0</mixed-citation></ref><ref id="hanspub.41555-ref32"><label>32</label><mixed-citation publication-type="other" xlink:type="simple">Rossion, B. and Jacques, C. (2008) Does Physical Interstimulus Variance Account for Early Electrophysiological Face Sensitive Responses in the Human Brain? Ten Lessons on the N170. Neuroimage, 39, 1959-1979.  
&lt;br&gt;https://doi.org/10.1016/j.neuroimage.2007.10.011</mixed-citation></ref><ref id="hanspub.41555-ref33"><label>33</label><mixed-citation publication-type="other" xlink:type="simple">Churches, O., Baron-Cohen, S. and Ring, H. (2009) Seeing Face-Like Objects: An Event-Related Potential Study. Neuroreport, 20, 1290-1294. &lt;br&gt;https://doi.org/10.1097/WNR.0b013e3283305a65</mixed-citation></ref><ref id="hanspub.41555-ref34"><label>34</label><mixed-citation publication-type="other" xlink:type="simple">Caharel, S., Leleu, A., Bernard, C., Viggiano, M.P., Lalonde, R. and Rebai, M. (2013) Early Holistic Face-Like Processing of Arcimboldo Paintings in the Right Occipito-Temporal Cortex: Evidence from the N170 ERP Component. International Journal of Psychophysiology, 90, 157-164. &lt;br&gt;https://doi.org/10.1016/j.ijpsycho.2013.06.024</mixed-citation></ref><ref id="hanspub.41555-ref35"><label>35</label><mixed-citation publication-type="other" xlink:type="simple">Liu, T., Mu, S., He, H., Zhang, L., Fan, C., Ren, J., Zhang, M., He, W. and Luo, W. (2016) The N170 Component Is Sensitive to Face-Like Stimuli: A Study of Chinese Peking Opera Makeup. Cognitive Neurodynamics, 10, 535-541.  
&lt;br&gt;https://doi.org/10.1007/s11571-016-9399-8</mixed-citation></ref><ref id="hanspub.41555-ref36"><label>36</label><mixed-citation publication-type="other" xlink:type="simple">McCarthy, G., Puce, A., Gore, J.C. and Allison, T. (1997) Face-Specific Processing in the Human Fusiform Gyrus. Journal of Cognitive Neuroscience, 9, 605-610. &lt;br&gt;https://doi.org/10.1162/jocn.1997.9.5.605</mixed-citation></ref><ref id="hanspub.41555-ref37"><label>37</label><mixed-citation publication-type="other" xlink:type="simple">Gauthier, I., Behrmann, M. and Tarr, M.J. (1999) Can Face Recognition Really Be Dissociated from Object Recognition? Journal of Cognitive Neuroscience, 11, 349-370. &lt;br&gt;https://doi.org/10.1162/089892999563472</mixed-citation></ref><ref id="hanspub.41555-ref38"><label>38</label><mixed-citation publication-type="other" xlink:type="simple">Gobbini, M.I., Gentili, C., Ricciardi, E., Bellucci, C., Salvini, P., Laschi, C., Guazzelli, M. and Pietrini, P. (2011) Distinct Neural Systems Involved in Agency and Animacy Detection. Journal of Cognitive Neuroscience, 23, 1911-1920.  
&lt;br&gt;https://doi.org/10.1162/jocn.2010.21574</mixed-citation></ref><ref id="hanspub.41555-ref39"><label>39</label><mixed-citation publication-type="other" xlink:type="simple">Wiggett, A.J., Pritchard, I.C. and Downing, P.E. (2009) Animate and Inanimate Objects in Human Visual Cortex: Evidence for Task-Independent Category Effects. Neuropsychologia, 47, 3111-3117.  
&lt;br&gt;https://doi.org/10.1016/j.neuropsychologia.2009.07.008</mixed-citation></ref><ref id="hanspub.41555-ref40"><label>40</label><mixed-citation publication-type="other" xlink:type="simple">Downing, P.E., Chan, A.W., Peelen, M.V., Dodds, C.M. and Kanwisher, N. (2006) Domain Specificity in Visual Cortex. Cereb Cortex, 16, 1453-1461. &lt;br&gt;https://doi.org/10.1093/cercor/bhj086</mixed-citation></ref><ref id="hanspub.41555-ref41"><label>41</label><mixed-citation publication-type="other" xlink:type="simple">Warrington, E.K. and Shallice, T. (1984) Category Specific Semantic Im-pairments. Brain, 107, 829-854.  
&lt;br&gt;https://doi.org/10.1093/brain/107.3.829</mixed-citation></ref><ref id="hanspub.41555-ref42"><label>42</label><mixed-citation publication-type="other" xlink:type="simple">Mori, M. (1970) The Uncanny Valley. Energy, 7, 98-100.</mixed-citation></ref><ref id="hanspub.41555-ref43"><label>43</label><mixed-citation publication-type="other" xlink:type="simple">Wang, S., Lilienfeld, S.O. and Rochat, P. (2015) The Uncanny Valley: Existence and Explanations. Review of General Psychology, 19, 393-407. &lt;br&gt;https://doi.org/10.1037/gpr0000056</mixed-citation></ref><ref id="hanspub.41555-ref44"><label>44</label><mixed-citation publication-type="other" xlink:type="simple">Wang, S. and Rochat, P. (2017) Human Perception of Animacy in Light of the Uncanny Valley Phenomenon. Perception, 46, 1386-1411. &lt;br&gt;https://doi.org/10.1177/0301006617722742</mixed-citation></ref><ref id="hanspub.41555-ref45"><label>45</label><mixed-citation publication-type="other" xlink:type="simple">Katsyri, J., de Gelder, B. and Takala, T. (2019) Virtual Faces Evoke Only a Weak Uncanny Valley Effect: An Empirical Investigation with Controlled Virtual Face Images. Perception, 48, 968-991.  
&lt;br&gt;https://doi.org/10.1177/0301006619869134</mixed-citation></ref><ref id="hanspub.41555-ref46"><label>46</label><mixed-citation publication-type="other" xlink:type="simple">Wang, S., Cheong, Y.F., Dilks, D.D. and Rochat, P. (2020) The Uncanny Valley Phenomenon and the Temporal Dynamics of Face Animacy Perception. Perception, 49, 1069-1089. &lt;br&gt;https://doi.org/10.1177/0301006620952611</mixed-citation></ref><ref id="hanspub.41555-ref47"><label>47</label><mixed-citation publication-type="other" xlink:type="simple">LaPointe, M.R., Cullen, R., Baltaretu, B., Campos, M., Michalski, N., Sri Satgunarajah, S., Cadieux, M.L., Pachai, M.V. and Shore, D.I. (2016) An Attentional Bias for LEGO(R) People Using a Change Detection Task: Are LEGO(R) People Animate? Canadian Journal of Experimental Psychology, 70, 219-231. &lt;br&gt;https://doi.org/10.1037/cep0000077</mixed-citation></ref></ref-list></back></article>