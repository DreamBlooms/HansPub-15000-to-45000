<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">AAM</journal-id><journal-title-group><journal-title>Advances in Applied Mathematics</journal-title></journal-title-group><issn pub-type="epub">2324-7991</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/AAM.2018.79138</article-id><article-id pub-id-type="publisher-id">AAM-26850</article-id><article-categories><subj-group subj-group-type="heading"><subject>AAM20180900000_13558499.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>数学与物理</subject></subj-group></article-categories><title-group><article-title>
 
 
  S-分布时滞静态神经网络的全局指数收敛性
  Global Exponential Convergence of Static Neural Networks with S-Type Distributed Delays
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>张</surname><given-names>若军</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>张</surname><given-names>静静</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib></contrib-group><aff id="aff1"><addr-line>中国海洋大学数学科学学院，山东 青岛</addr-line></aff><aff id="aff2"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>06</day><month>09</month><year>2018</year></pub-date><volume>07</volume><issue>09</issue><fpage>1191</fpage><lpage>1196</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
  本文研究了一类具有S-分布时滞的静态神经网络，主要利用微分不等式技巧，建立了所讨论模型的解指数收敛到零的充分性条件，并给出了实例说明了所得结论的有效性。
   This paper is concerned with the exponential convergence for a class of static neural networks with S-type distributed delays. By applying the differential inequality techniques, the sufficient conditions to ensure that all solutions of the addressed system converge exponentially to zero are established. Moreover, an example is given to show the effectiveness of the obtained results.
 
</p></abstract><kwd-group><kwd>静态神经网络，全局指数收敛性，S-分布时滞, Static Neural Networks</kwd><kwd> Global Exponential Convergence</kwd><kwd> S-Type Distributed Delays</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>S-分布时滞静态神经网络的全局指数收敛性<sup> </sup></title><p>张若军，张静静</p><p>中国海洋大学数学科学学院，山东 青岛</p><p><img src="//html.hanspub.org/file/9-2620733x1_hanspub.png" /></p><p>收稿日期：2018年8月23日；录用日期：2018年9月10日；发布日期：2018年9月17日</p><disp-formula id="hanspub.26850-formula19"><graphic xlink:href="//html.hanspub.org/file/9-2620733x5_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>本文研究了一类具有S-分布时滞的静态神经网络，主要利用微分不等式技巧，建立了所讨论模型的解指数收敛到零的充分性条件，并给出了实例说明了所得结论的有效性。</p><p>关键词 :静态神经网络，全局指数收敛性，S-分布时滞</p><disp-formula id="hanspub.26850-formula20"><graphic xlink:href="//html.hanspub.org/file/9-2620733x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2018 by authors and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/9-2620733x7_hanspub.png" /> <img src="//html.hanspub.org/file/9-2620733x8_hanspub.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>近四十年来，人工神经网络因其在联想记忆、平行计算、模式识别、信号处理及优化问题等方面的重要理论价值及应用价值，被广泛关注，并逐渐成为极其活跃的研究热点 [<xref ref-type="bibr" rid="hanspub.26850-ref1">1</xref>] [<xref ref-type="bibr" rid="hanspub.26850-ref2">2</xref>] [<xref ref-type="bibr" rid="hanspub.26850-ref3">3</xref>] 。</p><p>根据基本变量选择的不同，连续型递归神经网络可以分为局域神经网络和静态神经网络两大类 [<xref ref-type="bibr" rid="hanspub.26850-ref4">4</xref>] 。局域神经网络模型的基本形式为</p><p>d x i ( t ) d t = − x i ( t ) + ∑ j = 1 n w i j g j ( x j ( t ) ) + I i ,   i = 1 , 2 , ⋯ , n . (1.1)</p><p>其中 x ( t ) = ( x 1 ( t ) , ⋯ , x n ( t ) ) T 表示神经元的内部状态，n是神经元的个数， w i j 表示神经元j到神经元i的连接权重， g j ( ⋅ ) 表示神经元j的信号函数， I i 表示神经元i的外部输入函数。</p><p>静态神经网络模型的基本形式为</p><p>d y i ( t ) d t = − y i ( t ) + g i ( ∑ j = 1 n w i j y j ( t ) + I i ) ,   i = 1 , 2 , ⋯ , n . (1.2)</p><p>其中 y ( t ) = ( y 1 ( t ) , ⋯ , y n ( t ) ) T 表示神经元的外部状态，余下的符号意义与模型(1.1)相同。</p><p>Hopfield模型、双向联想记忆模型和CNNs模型都属于局域神经网络模型，局域神经网络模型(1.1)已被广泛研究，得到了很多深刻的理论结果。递归反向传播网络、BCOp网络、BSB网络的模型则属于静态神经网络，具有重要的应用意义，但相比之下，静态神经网络模型(1.2)的研究则较少 [<xref ref-type="bibr" rid="hanspub.26850-ref5">5</xref>] 。</p><p>由于时间滞后效应在神经传导及信号传递过程中均不可避免，因此，时滞神经网络的动力行为研究更具现实意义。而S-分布时滞包含了离散与连续时滞两种情形 [<xref ref-type="bibr" rid="hanspub.26850-ref6">6</xref>] ，所以，S-分布时滞就具有更一般的意义。近年来，关于时滞静态神经网络动力行为研究的结果并不多见 [<xref ref-type="bibr" rid="hanspub.26850-ref7">7</xref>] [<xref ref-type="bibr" rid="hanspub.26850-ref8">8</xref>] [<xref ref-type="bibr" rid="hanspub.26850-ref9">9</xref>] 。综上，本文将考虑一类S-分布时滞的静态神经网络，采用对构成神经网络本身函数特征的考察，及建立合适的微分不等式的方法，给出这类S-分布时滞的静态神经网络全局指数收敛于零的判别法，并通过实例验证了所得结论的有效性。</p></sec><sec id="s4"><title>2. 主要结果</title><p>考虑如下一类S-分布时滞静态神经网络模型</p><p>x ′ i ( t ) = − c i ( t ) x i ( t ) + g i ( ∑ j = 1 n ∫ − r 0 x j ( t + θ ) d w i j ( θ ) + I i ( t ) ) ,     i = 1 , 2 , ⋯ , n . (2.1)</p><p>其中 c i ( t ) &gt; 0 为连续函数，表示在与神经网络不联通且无外部附加电压差情况下第i个神经元恢复孤立静息状态下的速率， w i j ( θ ) 是 [ − r , 0 ] ( r &gt; 0 ) 上关于 θ 单调不减的有界变差函数，其余符号的意义与模型(1.2)相同。</p><p>为方便，记 I = { 1 , 2 , ⋯ , n } ，对于 x ∈ R n , 定义 ‖ x ‖ = max i ∈ I | x i | 。以 C ( [ − r , 0 ] , R n ) 表示定义在 [ − r , 0 ] 上的n维连续向量函数空间。 C ( R , R n ) 表示 ( − ∞ , + ∞ ) 上的n维连续向量函数空间。 x ( t ) = x ( σ , ϕ , t ) = ( x 1 ( t ) , ⋯ , x n ( t ) ) T 表示模型(2.1)的一个满足初始条件</p><p>x ( σ + θ ) = ϕ ( θ ) ,   σ ∈ R,   θ ∈ [ − r ,0 ] . (2.2)</p><p>的解，其中 ϕ ( θ ) = ( ϕ 1 ( θ ) , ϕ 2 ( θ ) , ⋯ , ϕ n ( θ ) ) T ∈ C ( [ − r , 0 ] , R n ) 。</p><p>为后面证明方便，给出以下假设：</p><p>(H1) inf t ∈ R c i ( t ) = c i _ &gt; 0 ,   i ∈ I 。</p><p>(H2) ∫ − r 0 x j ( t + θ ) d w i j ( θ ) 是Lebesgue-Stieltjes可积的，且 0 ≤ ∫ − r 0 d w i j ( θ ) &lt; w i j &lt; + ∞ ,   i , j ∈ I 。</p><p>(H3) 存在 L i g &gt; 0 ，使得 | g i ( u ) | ≤ L i g | u | ,   u ∈ R,   i ∈ I 。</p><p>(H4) 对任意的 i ∈ I ，存在 ξ 1 , ξ 2 , ⋯ , ξ n &gt; 0 ,   c i _ &gt; λ &gt; 0 ，满足 max i ∈ I { ξ i − 1 L i g ∑ j = 1 n ξ j e λ r + 1 } &lt; c i _ − λ 且 | I i ( t ) | ≤ e − λ t , i ∈ I 。</p><p>(H5) max i ∈ I { 1 c i _ ξ i − 1 L i g ∑ j = 1 n ξ j w i j } &lt; 1 。</p><p>定理2.1. 若条件(H1)~(H5)成立，则模型(2.1)的解在 [ σ , + ∞ ] 上整体存在。</p><p>证明：设 x ( t ) = x ( σ , ϕ , t ) = ( x 1 ( t ) , x 2 ( t ) , ⋯ , x n ( t ) ) T 是模型(2.1)满足初始条件(2.2)的解。</p><p>令</p><p>y ( t ) = ( y 1 ( t ) , y 2 ( t ) , ⋯ , y n ( t ) ) T = ( ξ 1 − 1 x 1 ( t ) , ξ 2 − 1 x 2 ( t ) , ⋯ , ξ n − 1 x n ( t ) ) T</p><p>则有</p><p>y ′ i ( t ) = − c i ( t ) y i ( t ) + ξ i − 1 g i ( ∑ j = 1 n ∫ − r 0 x j ( t + θ ) d w i j ( θ ) + I i ( t ) ) ,   i ∈ I . (2.3)</p><p>当 t &gt; s &gt; σ 时，有</p><p>y ′ i ( s ) = − c i ( s ) y i ( s ) + ξ i − 1 g i ( ∑ j = 1 n ∫ − r 0 x j ( s + θ ) d w i j ( θ ) + I i ( s ) ) ,   i ∈ I . (2.4)</p><p>将(2.4)式两边乘以 e ∫ σ s c i ( u ) d u ，再从 σ 到t求积分，得</p><p>y i ( t ) = y i ( σ ) e − ∫ σ t c i ( u ) d u + ∫ σ t e − ∫ s t c i ( u ) d u [ ξ i − 1 g i ( ∑ j = 1 n ∫ − r 0 x j ( s + θ ) d ω i j ( θ ) + I i ( s ) ) ] d s ,   i ∈ I . (2.5)</p><p>由(2.5)式、初始条件(2.2)、条件(H1)~(H5)，得</p><p>| y i ( t ) | ≤ e − ∫ σ t c i ( u ) d u ξ i − 1 | ϕ i ( 0 ) | + | ∫ σ t e − ∫ s t c i ( u ) d u [ ξ i − 1 g i ( ∑ j = 1 n ∫ − r 0 x j ( s + θ ) w i j ( θ ) + I i ( s ) ) ] d s | ≤ e − ∫ σ t c i _ d u ξ i − 1 | ϕ i ( 0 ) | + ∫ σ t e − ∫ s t c i _ d u ξ i − 1 L i g ( | ∑ j = 1 n ∫ − r 0 x j ( s + θ ) d w i j ( θ ) | + | I i ( s ) | ) d s ≤ e − c i _ ( t − σ ) ξ i − 1 | ϕ i ( 0 ) | + ξ i − 1 L i g ∫ σ t e − c i _ ( t − s ) | ∑ j = 1 n ∫ − r 0 ξ j y j ( s + θ ) d w i j ( θ ) | d s + ξ i − 1 L i g ∫ σ t e − c i _ ( t − s ) e − λ s d s ≤ ξ i − 1 | ϕ i ( 0 ) | + 1 c i _ ξ i − 1 L i g ‖ y ‖ ∑ j = 1 n ξ j w i j + ξ i − 1 L i g e − λ σ λ − c i _ , (2.6)</p><p>得，</p><p>‖ y ‖ ≤ max i ∈ I { ξ i − 1 | ϕ i ( 0 ) | + ξ i − 1 L i g e − λ σ λ − c i _ + 1 c i _ ξ i − 1 L i g ‖ y ‖ ∑ j = 1 n ξ j w i j } , (2.7)</p><p>从而，</p><p>‖ y ‖ ≤ max i ∈ I { ξ i − 1 | ϕ i ( 0 ) | + ξ i − 1 L i g e − λ σ λ − c i _ } max i ∈ I { 1 − 1 c i _ ξ i − 1 L i g ∑ j = 1 n ξ j w i j } . (2.8)</p><p>y有界，因此模型(2.1)的解不会发生爆破，在 [ σ , + ∞ ] 上整体存在。</p><p>定理2.2. 假设条件(H1)-(H5)成立，则对于系统(2.1)满足初始条件(2.2)的任意解 x ( t ) ， x ( t ) 全局指数收敛到0，即存在常数 λ &gt; 0 , B &gt; 0 ，使得对 i ∈ I ，有</p><p>| x i ( t ) | ≤ B e − λ t .</p><p>证明：令 ‖ ϕ ‖ = max i { ξ i − 1 max t ∈ [ − r , 0 ] | ϕ i ( t ) | } 。当 t ∈ [ − r , 0 ] 时，对任给的 ε &gt; 0 ，由 ‖ ϕ ‖ 的定义及 λ &gt; 0 ，有</p><p>| y i ( t ) | = | ξ i − 1 ϕ i ( t ) | &lt; M ( ‖ ϕ ‖ + ε ) e − λ t .</p><p>从而，</p><p>‖ y ( t ) ‖ &lt; M ( ‖ ϕ ‖ + ε ) e − λ t ,   t ∈ [ − r , 0 ] . (2.9)</p><p>其中 M &gt; 0 充分大，使得</p><p>| L i g ξ i − 1 I i ( t ) | &lt; M ( ‖ ϕ ‖ + ε ) e − λ t ,   t ≥ 0 ,   i ∈ I .</p><p>下面证明，对任意的 t &gt; 0 ，有</p><p>‖ y ( t ) ‖ &lt; M ( ‖ ϕ ‖ + ε ) e − λ t . (2.10)</p><p>反证，若不然，则存在 i ∈ I , η &gt; 0 ，使得</p><p>‖ y ( η ) ‖ = | y i ( η ) | = M ( ‖ ϕ ‖ + ε ) e − λ η . (2.11)</p><p>且对 t ∈ [ − r , η ] ，有</p><p>| y i ( t ) | &lt; M ( ‖ ϕ ‖ + ε ) e − λ t . (2.12)</p><p>注意到，对 s ∈ [ 0 , t ] ,   t ∈ [ 0 , η ] ，有</p><p>y i ( t ) = y i ( 0 ) e − ∫ 0 t c i ( u ) d u + ∫ 0 t e − ∫ s t c i ( u ) d u ξ i − 1 g i [ ∑ j = 1 n ∫ − r 0 ξ j y j ( s + θ ) d ω i j ( θ ) + I i ( s ) ] d s ,</p><p>从而，当 η &gt; 0 时，利用(2.9)和(2.12)式，以及条件(H1)~(H5)，有</p><p>| y i ( η ) | = | y i ( 0 ) e − ∫ 0 η c i ( u ) d u + ∫ 0 η e − ∫ s η c i ( u ) d u ξ i − 1 g i [ ∑ j = 1 N ∫ − r 0 ξ j y j ( s + θ ) d w i j ( θ ) + I i ( s ) ] d s | ≤ M ( ‖ ϕ ‖ + ε ) e − c i _ η + ∫ 0 η e − c i _ ( η − s ) ξ i − 1 L i g [ ∑ j = 1 n | ∫ − r 0 ξ j y j ( s + θ ) d w i j ( θ ) | + | I i ( s ) | ] d s ≤ M ( ‖ ϕ ‖ + ε ) e − c i _ η + ∫ 0 η e − c i _ ( η − s ) [ ξ i − 1 L i g ∑ j = 1 n ξ j M ( ‖ ϕ ‖ + ε ) e − λ ( s − r ) w i j + M ( ‖ ϕ ‖ + ε ) e − λ s ] d s ≤ M ( ‖ ϕ ‖ + ε ) e − c i _ η + M ( ‖ ϕ ‖ + ε ) ∫ 0 η e − c i _ ( η − s ) [ ξ i − 1 L i g ∑ j = 1 n ξ j e − λ ( s − r ) w i j + e − λ s ] d s</p><p>≤ M ( ‖ ϕ ‖ + ε ) [ e − c i _ η + e − c i _ η ∫ 0 η e − ( λ − c i _ ) s ( ξ i − 1 L i g ∑ j = 1 n ξ j e λ r w i j + 1 ) d s ] &lt; M ( ‖ ϕ ‖ + ε ) e − c i _ η [ 1 + ∫ 0 η e − ( λ − c i _ ) s ( c i _ − λ ) d s ] &lt; M ( ‖ ϕ ‖ + ε ) e − c i _ η ⋅ e − ( λ − c i _ ) η = M ( ‖ ϕ ‖ + ε ) e − λ η .</p><p>此与(2.11)式矛盾，故(2.10)式成立，即对任意的 t &gt; 0 ，有</p><p>‖ y ( t ) ‖ &lt; M ( ‖ ϕ ‖ + ε ) e − λ t ,</p><p>从而，也有</p><p>‖ x ( t ) ‖ &lt; ξ M ( ‖ ϕ ‖ + ε ) e − λ t ,</p><p>其中 ξ = max i { ξ i } ,   i ∈ I 。即 ‖ x ( t ) ‖ ≤ B e − λ t ,   B = ξ M ( ‖ ϕ ‖ + ε ) 。</p></sec><sec id="s5"><title>3. 例子</title><p>例3.1. 考虑如下S-分布时滞静态神经网络</p><p>{ x ′ 1 ( t ) = − ( 5 + sin t ) x 1 ( t ) + g 1 ( ∫ − 1 0 x 1 ( t + θ ) d w 11 ( θ ) + ∫ − 1 0 x 2 ( t + θ ) d w 12 ( θ ) + e − 1 2 t sin t ) , x ′ 2 ( t ) = − ( 5 + cos t ) x 2 ( t ) + g 2 ( ∫ − 1 0 x 1 ( t + θ ) d w 21 ( θ ) + ∫ − 1 0 x 2 ( t + θ ) d w 22 ( θ ) + e − 1 2 t cos t ) . (3.1)</p><p>其中 t ≥ 0 , g 1 ( t ) = 1 12 x sin 3 x , g 2 ( x ) = 1 12 x cos 3 x , x i ( s ) = ϕ i ( s ) , s ∈ [ − 1 , 0 ] ， ϕ i ( x ) 为 [ − 1 , 0 ] 上的连续函数， w i j ( θ ) = e θ ,   i , j = 1 , 2 。</p><p>显然，这里 c 1 ( t ) = 5 + sin t , c 2 ( t ) = 5 + cos t ，故 c 1 _ = c 2 _ = 4 。 I 1 ( t ) = e − 1 2 t sin t , I 2 ( t ) = e − 1 2 t cos t ，取 λ = 1 2 ，故 c i _ &gt; λ &gt; 0 ， | I i ( t ) | ≤ e − λ t 。且有 L 1 g = L 2 g = 1 12 ， w i j = 1 ,   i , j = 1 , 2 。</p><p>取 ξ i = 1 , i = 1 , 2 。对 λ = 1 2 ,   i = 1 , 2 有 ξ i − 1 L i g ∑ j = 1 n ξ j e λ r + 1 = 1 6 e 1 2 + 1 &lt; 7 2 = c i _ − λ 成立，即满足 max i ∈ I { ξ i − 1 L i g ∑ j = 1 n ξ j e λ r + 1 } &lt; c i _ − λ 。且容易验证 max i ∈ I { 1 c i _ ξ i − 1 L i g ∑ j = 1 n ξ j w i j } &lt; 1 成立。</p><p>上述计算表明，模型(3.1)满足条件(H1)~(H5)，故由定理2.2知，系统(3.1)的解全局指数收敛到零向量 ( 0 , 0 ) T 。</p><p>注3.1. 本文没有采用文献中常见的变换 y ( t ) = x ( e t ) 及计算Lyapunov函数的Dini右上导数的方法来讨论Hopfield神经网络模型的指数收敛性 [<xref ref-type="bibr" rid="hanspub.26850-ref10">10</xref>] [<xref ref-type="bibr" rid="hanspub.26850-ref11">11</xref>] [<xref ref-type="bibr" rid="hanspub.26850-ref12">12</xref>] ，而是通过针对模型本身的构成函数的特点，给出保证网络全局指数收敛性的充分性条件，提供了一种新的研究方法。</p></sec><sec id="s6"><title>文章引用</title><p>张若军,张静静. S-分布时滞静态神经网络的全局指数收敛性Global Exponential Convergence of Static Neural Networks with S-Type Distributed Delays[J]. 应用数学进展, 2018, 07(09): 1191-1196. https://doi.org/10.12677/AAM.2018.79138</p></sec><sec id="s7"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.26850-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">马天瑾. 神经网络技术[M]. 青岛: 青岛海洋出版社, 1994.</mixed-citation></ref><ref id="hanspub.26850-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">阎平凡. 人工神经网络与模拟进化计算[M]. 北京: 清华大学出版社, 2001.</mixed-citation></ref><ref id="hanspub.26850-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">阮炯. 神经动力学模型方法与应用[M]. 北京: 科学出版社, 2001.</mixed-citation></ref><ref id="hanspub.26850-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Qiao, H., et al. (2003) A Reference Model Approach to Stability Analysis of Neural Networks. IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernet-ics), 33, 925-936. &lt;br&gt;https://doi.org/10.1109/TSMCB.2002.804368</mixed-citation></ref><ref id="hanspub.26850-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">王林山. 时滞递归神经网络[M]. 北京: 科学出版社, 2007.</mixed-citation></ref><ref id="hanspub.26850-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Wang, L.S. and Xu, D.Y. (2002) Global Asymptotic Stability of Bidirectional Associative Memory Neural Networks with S-Type Distributed Delays. International Journal of Systems Science, 33, 869-877.  
&lt;br&gt;https://doi.org/10.1080/00207720210161777</mixed-citation></ref><ref id="hanspub.26850-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Kwon, O.M., et al. (2014) New and Improved Results on Stability of Static Neural Networks with Interval Time-Varying Delays. Applied Mathematics and Computation, 239, 346-357.  
&lt;br&gt;https://doi.org/10.1016/j.amc.2014.04.089</mixed-citation></ref><ref id="hanspub.26850-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Liu, B., Ma, X.L. and Jia, X.-C. (2018) Further Results on H∞ State Estimation of Static Neural Networks with Time-Varying Delay. Neurocomputing, 285, 133-140. &lt;br&gt;https://doi.org/10.1016/j.neucom.2018.01.032</mixed-citation></ref><ref id="hanspub.26850-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Manivannan, R., Samidurai, R. and Zhu, Q.X. (2017) Further Improved Results on Stability and Dissipativity Analysis of Static Impulsive Neural Networks with Interval Time-Varying Delays. Journal of the Franklin Institute, 354, 6312-6340. &lt;br&gt;https://doi.org/10.1016/j.jfranklin.2017.07.040</mixed-citation></ref><ref id="hanspub.26850-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Arbi, A., et al. (2015) Stability Analysis for Delayed High-Order Type of Hopfield Neural Networks with Impulses. Neurocomputing, 165, 312-329. &lt;br&gt;https://doi.org/10.1016/j.neucom.2015.03.021</mixed-citation></ref><ref id="hanspub.26850-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Xu, C.J. and Li, P.L. (2017) Global Exponential Convergence of Neu-tral-Type Hopfield Neural Networks with Multi-Proportional Delays and Leakage Delays. Chaos, Solitons &amp; Fractals, 96, 139-144.  
&lt;br&gt;https://doi.org/10.1016/j.chaos.2017.01.012</mixed-citation></ref><ref id="hanspub.26850-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Wan, L., Zhou, Q.H. and Liu, J. (2017) Delay-Dependent Attractor Analysis of Hopfield Neural Networks with Time-Varying Delays. Chaos, Solitons &amp; Fractals, 101, 68-72. &lt;br&gt;https://doi.org/10.1016/j.chaos.2017.05.017</mixed-citation></ref></ref-list></back></article>