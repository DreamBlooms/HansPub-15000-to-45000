<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2015.512055</article-id><article-id pub-id-type="publisher-id">CSA-16613</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20151200000_95494866.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于视角优化的便携像机视频去抖算法
  Orientation Optimization Based 3D Video Stabilization for Portable Cameras
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>杨</surname><given-names>诚笃</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>许</surname><given-names>宏丽</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>尹</surname><given-names>辉</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>黄</surname><given-names>华</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib></contrib-group><aff id="aff1"><addr-line>北京交通大学计算机学院，北京</addr-line></aff><aff id="aff3"><addr-line>北京交通大学计算机学院，北京；北京交通大学交通数据分析与挖掘北京市重点实验室，北京</addr-line></aff><aff id="aff2"><addr-line>null</addr-line></aff><author-notes><corresp id="cor1">* E-mail:<email>13120440@bjtu.edu.cn(杨诚)</email>;</corresp></author-notes><pub-date pub-type="epub"><day>28</day><month>12</month><year>2015</year></pub-date><volume>05</volume><issue>12</issue><fpage>436</fpage><lpage>444</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
  针对便携式摄像机的视频去抖问题，本文提出一种基于摄像机视角优化的视频去抖算法。首先，通过struc- ture-from-motion算法估计摄像机连续运动位姿。其次，基于摄像机的空间位置进行多项式曲线拟合，得到摄像机运动的虚拟路径。然后，通过向量插值平滑视角朝向。最后，基于相机运动平滑曲线与平滑视角对视频帧进行筛选和修正实现视频去抖。实验证明，该算法很好地解决了2D去抖算法对摄像机运动参数估计不足的问题。在真实数据集上的实验结果验证了本文算法在针对便携式摄像机视频数据的去抖有效性。
   We present a novel view optimization algorithm in the paper for video stabilization. Most existing 2D video stabilization methods may fail to estimate the motion parameters of cameras. In order to solve above problems, we propose a video stabilization method based on 3D technology. Firstly, recovers the original 3D camera motion using the structure-from-motion system. Then, a virtual camera path is computed by polynomial curve fitting. And then, smoothes the view orientation by vectorial interpolation. Finally, corrects the frames which selected in conformity with the smooth- ing location and orientation of cameras. Our experiments on stabilizing challenging videos of real scenes demonstrate the effectiveness of our technique.
 
</p></abstract><kwd-group><kwd>视频去抖，视角优化，多项式拟合, Video Stabilization</kwd><kwd> Rotation Optimization</kwd><kwd> Polynomial Curve-Fitting</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>基于视角优化的便携像机视频去抖算法<sup> </sup></title><p>杨诚笃<sup>1</sup>，许宏丽<sup>1</sup>，尹辉<sup>1,2</sup>，黄华<sup>1,2</sup></p><p><sup>1</sup>北京交通大学计算机学院，北京</p><p><sup>2</sup>北京交通大学交通数据分析与挖掘北京市重点实验室，北京</p><disp-formula id="hanspub.16613-formula233"><graphic xlink:href="http://html.hanspub.org/file/2-1540532x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>收稿日期：2015年12月5日；录用日期：2015年12月25日；发布日期：2015年12月28日</p><disp-formula id="hanspub.16613-formula234"><graphic xlink:href="http://html.hanspub.org/file/2-1540532x7_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>针对便携式摄像机的视频去抖问题，本文提出一种基于摄像机视角优化的视频去抖算法。首先，通过struc- ture-from-motion算法估计摄像机连续运动位姿。其次，基于摄像机的空间位置进行多项式曲线拟合，得到摄像机运动的虚拟路径。然后，通过向量插值平滑视角朝向。最后，基于相机运动平滑曲线与平滑视角对视频帧进行筛选和修正实现视频去抖。实验证明，该算法很好地解决了2D去抖算法对摄像机运动参数估计不足的问题。在真实数据集上的实验结果验证了本文算法在针对便携式摄像机视频数据的去抖有效性。</p><p>关键词 :视频去抖，视角优化，多项式拟合</p><disp-formula id="hanspub.16613-formula235"><graphic xlink:href="http://html.hanspub.org/file/2-1540532x8_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s3"><title>1. 引言</title><p>随着家用便携摄像设备的普及，非专业拍摄的视频大量涌现。由于缺乏良好的固定措施和拍摄技巧，这些非专业视频往往存在视频视角晃动大、可观赏性不高的问题。一般可以采用去除抖动的方法对视频进行处理，提升视频的观赏质量。因此改善视频的可观赏性就成为非专业视频优化的一个主要挑战。</p><p>视频去抖是视频处理的中心问题之一，常见的视频去抖动主要是基于2D方法。</p><p>基于2D的方法主要通过估计单应性矩阵 [<xref ref-type="bibr" rid="hanspub.16613-ref1">1</xref>] ，如基于运动矢量的视频去抖动算法，通过块运动估计来估算摄像机的全局运动参数 [<xref ref-type="bibr" rid="hanspub.16613-ref2">2</xref>] - [<xref ref-type="bibr" rid="hanspub.16613-ref4">4</xref>] 。利用RANSAC算法 [<xref ref-type="bibr" rid="hanspub.16613-ref5">5</xref>] 或图像的SIFT特征匹配 [<xref ref-type="bibr" rid="hanspub.16613-ref6">6</xref>] 增强全局运动参数估计的鲁棒性。目前最先进的基于2D的去抖算法是由Shuaicheng Liu提出的对同一时段多特征点轨迹平滑 [<xref ref-type="bibr" rid="hanspub.16613-ref7">7</xref>] 。基于2D的方法虽然鲁棒性较强、计算代价较小，但不能合理描述相机的运动模型，无法对其运动路径和视角进行优化 [<xref ref-type="bibr" rid="hanspub.16613-ref8">8</xref>] 。</p><p>基于3D的视频去抖技术以多视角几何为基础 [<xref ref-type="bibr" rid="hanspub.16613-ref9">9</xref>] - [<xref ref-type="bibr" rid="hanspub.16613-ref11">11</xref>] ，通过构建相机运动模型并平滑相机运动参数以达到视频去抖的目的。相机抖动是产生视频抖动的根本原因，相机运动参数可直观反应相机运动，因此通过平滑相机运动参数去抖更加合理。</p><p>便携式相机的拍摄内容带有拍摄者的主观随意性，其视频图像往往不满足一般的图像处理技术所必需应用条件，一般的去抖动方法在处理此类视频时的效果欠佳。鉴于便携式摄像机视频中造成抖动的主要原因在于摄像机拍摄视角的非均匀变化，本文基于对视角优化进行运动补偿的思路，提出一种基于视角优化的3D视频去抖算法。主要贡献有：通过摄像机运动估计，对视频帧进行筛选和视角优化。实验结果表明，本文提出的方法能够解决2D去抖算法对摄像机运动估计不足的问题。</p></sec><sec id="s4"><title>2. 基于视角优化的去抖算法</title><p>利用便携式相机进行视频拍摄时，相机的运动路径一般较为简单、往复运动少，因此摄像机位置的短时震动对画面的可观赏性影响影响较小，使得视角的非均匀变化成为导致视频抖动的主要原因。因此，可以在估计摄像机位置的基础上，对相机位置进行曲线拟合，得到相机的主运动趋势后对相机运动参数进行筛选，并对相机朝向进行平滑处理。最后，根据相机视角平滑处理的结果对所选的帧进行视角变换，从而弱化或消除视角剧烈变化造成的视频抖动。</p><sec id="s4_1"><title>2.1. 算法原理</title><p>首先，通过运动结构重建(structure-from-motion, SFM) [<xref ref-type="bibr" rid="hanspub.16613-ref12">12</xref>] 恢复摄像机运动参数，并估算其姿态。运动结构重建由特征检测、KLT跟踪重构帧间关系，估算相机的运动参数，主要是相机位置与朝向。</p><p>其次，由最小二乘法对相机实际位置拟合，得到相机运动的平滑曲线。最小二乘法通过各个时刻相机实际位置拟合出与所有相机位置距离偏差最小的高次平滑曲线。此曲线反映相机平滑的整体运动的趋势。</p><p>再次，通过球面线性插值平滑相机视角。对任一时刻相机朝向和相机初始朝向进行球面线性插值，在不改变相机朝向运动趋势的同时，平滑相机朝向运动幅度。</p><p>最后，基于相机运动平滑曲线与平滑视角对视频帧进行筛选和修正。</p><p>其原理如图1所示。</p></sec><sec id="s4_2"><title>2.2. 算法流程</title><p>视频去抖算法：</p><p>图1. 算法原理图</p></sec></sec><sec id="s5"><title>3. 摄像机运动估计</title><p>估计摄像机的运动趋势可以分离摄像机的运动趋势和和抖动。视频拍摄过程中，摄像机的物理位置是连续变化的，高质量的专业视频拍摄中通常不存在无规则的随机抖动。对于非专业的便携式相机视频，缺乏专业的去抖处理，因而需要一定的手段估计摄像机的运动趋势，以平滑抖动。本文通过运动结构重建估算相机的位姿，并分别通过最小二乘法和球面线性插值法对位姿做平滑处理。</p><sec id="s5_1"><title>3.1. 运动结构重建</title><p>运动结构重建(SFM) [<xref ref-type="bibr" rid="hanspub.16613-ref12">12</xref>] 算法基于多视角几何，通过多幅图像的两两特征匹配，生成摄像机的运动参数和特征点的三维点云数据。如图2所示。</p><p>首先，对视频序列帧Image1、Image2、Image3中的特征点(x<sub>1</sub>, y<sub>1</sub>)、(x<sub>2</sub>, y<sub>2</sub>)、(x<sub>3</sub>, y<sub>3</sub>)进行两两匹配。</p><p>其次，寻找基线最大、匹配最好的两帧图像，并且基于其特征匹配估算本征矩阵，由本征矩阵还原相机外参并三角化特征点三维位置。</p><p>最后，逐步加入新的视频帧进行外参与特征点三维位置的计算，调整世界标系原点，直到所有视频帧都完成三维位置计算。</p></sec><sec id="s5_2"><title>3.2. 摄像机位姿估算</title><p>最小二乘法是一种数学回归技术。其算法通过最小化均方误差的思想，寻找离散数据的最佳匹配曲线。</p><p>对数学上一条曲线，可通过高次多项式进行拟合。通过最小二乘法，可由一组离散坐标点拟合出一条连续运动曲线的高次多项式表达式，以预测曲线上某点的坐标值。</p><p>由于非专业的便携式相机视频一般是帮助拍摄者回顾浏览路径的，一般不会有针对统一内容的反复拍摄。因此这类视频一般浏览路径简单，且主运动方向上的往复运动时间持续短暂，使得通过曲线拟合摄像机运动路径成为可能。如图3所示，由最小二乘拟合，基于每一时刻的摄像机真实位置估算出主运动趋势的平滑曲线，可以反映真实摄像机的主运动。</p><p>记i时刻相机坐标系与世界坐标系之间的旋转矩阵和平移向量为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540532x11_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540532x12_hanspub.png" xlink:type="simple"/></inline-formula>，则相机在世界坐标系下的位置<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540532x13_hanspub.png" xlink:type="simple"/></inline-formula>表示为：</p><disp-formula id="hanspub.16613-formula236"><label>(1)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/2-1540532x14_hanspub.png"  xlink:type="simple"/></disp-formula><p>式中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540532x15_hanspub.png" xlink:type="simple"/></inline-formula>是<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540532x16_hanspub.png" xlink:type="simple"/></inline-formula>的转置矩阵。</p><p>对摄像机位置P做最小二乘的多项式拟合得路径位置C：</p><p>图2. SFM算法对特征点的空间位置和摄像机运动模型的恢复</p><p>图3. 摄像机实际运动位置与优化后的虚拟摄像机路径</p><disp-formula id="hanspub.16613-formula237"><label>(2)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/2-1540532x19_hanspub.png"  xlink:type="simple"/></disp-formula><p>式中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540532x20_hanspub.png" xlink:type="simple"/></inline-formula>表示时刻i空间三维曲线的位置，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540532x21_hanspub.png" xlink:type="simple"/></inline-formula>表示在i时刻曲线C与摄像机真实位置<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540532x22_hanspub.png" xlink:type="simple"/></inline-formula>的偏差。</p></sec></sec><sec id="s6"><title>4. 相机视角平滑算法</title><p>球面线性插值是一种可以保持向量长度不变的线性插值方法，用于计算向量间角度变化的插值。以四元数为工具的球面线性插值算法 [<xref ref-type="bibr" rid="hanspub.16613-ref13">13</xref>] ，可以计算等角速度变化的向量角度线性插值，以达到使向量角度均匀变化的目的。</p><p>令相机朝向为相机坐标系中Z轴的正方向，记i时刻相机的旋转矩阵为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540532x23_hanspub.png" xlink:type="simple"/></inline-formula>，则相机在世界坐标系下的朝向 可表示为：</p><disp-formula id="hanspub.16613-formula238"><label>(3)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/2-1540532x24_hanspub.png"  xlink:type="simple"/></disp-formula><p>式中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540532x25_hanspub.png" xlink:type="simple"/></inline-formula>是<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540532x26_hanspub.png" xlink:type="simple"/></inline-formula>的转置矩阵。</p><p>由四元组<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540532x27_hanspub.png" xlink:type="simple"/></inline-formula>表示相机朝向旋转，其中：</p><disp-formula id="hanspub.16613-formula239"><label>(4)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/2-1540532x28_hanspub.png"  xlink:type="simple"/></disp-formula><p>表示由方向<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540532x29_hanspub.png" xlink:type="simple"/></inline-formula>转到方向<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540532x30_hanspub.png" xlink:type="simple"/></inline-formula>的旋转轴。</p><disp-formula id="hanspub.16613-formula240"><label>(5)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/2-1540532x31_hanspub.png"  xlink:type="simple"/></disp-formula><p>表示由方向<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540532x32_hanspub.png" xlink:type="simple"/></inline-formula>转到方向<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540532x33_hanspub.png" xlink:type="simple"/></inline-formula>的旋转角。</p><p>设 是两四元组<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540532x34_hanspub.png" xlink:type="simple"/></inline-formula>与<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540532x35_hanspub.png" xlink:type="simple"/></inline-formula>间的转角中值，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540532x36_hanspub.png" xlink:type="simple"/></inline-formula>为插值<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540532x37_hanspub.png" xlink:type="simple"/></inline-formula>与四元组<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540532x38_hanspub.png" xlink:type="simple"/></inline-formula>的相似程度，则<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540532x39_hanspub.png" xlink:type="simple"/></inline-formula>可由下式求得：</p><disp-formula id="hanspub.16613-formula241"><label>(6)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/2-1540532x40_hanspub.png"  xlink:type="simple"/></disp-formula><p>设首帧视角旋转为稳定旋转，平滑算法为：</p><disp-formula id="hanspub.16613-formula242"><graphic xlink:href="http://html.hanspub.org/file/2-1540532x41_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中alpha为迭代次数。</p></sec><sec id="s7"><title>5. 视频帧的筛选与修正</title><p>本文算法避免对视频帧做较大变换，以防止视频内容发生较大扭曲，因此选取距离虚拟路径最近且视角与虚拟视角最接近的视频帧做视角变换与修正。</p><sec id="s7_1"><title>5.1. 视频帧筛选算法</title><p>基于视角优化的视频帧筛选策略如下：</p><p>1) 首先选取摄像机位置距离虚拟路径较近的视频帧为待选变换帧。做各个时刻摄像机位置与虚拟路径的投影距离。路径上每个位置点可能有0个至几个摄像机与其距离是最近的，有的虚拟路径上也可能没有邻近的摄像机。</p><p>2) 如果路径上某位置没有邻近摄像机，则添加此位置的前后路径位置的摄像机位置为待选。</p><p>3) 根据待选摄像机，选取距离虚拟路径最近且视角与优化估计视角偏差ψ最小的视频帧为最优变换帧。</p><disp-formula id="hanspub.16613-formula243"><label>(7)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/2-1540532x42_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540532x43_hanspub.png" xlink:type="simple"/></inline-formula>表示虚拟路径位置i处的最优帧号。<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540532x44_hanspub.png" xlink:type="simple"/></inline-formula>为虚拟路径位置i处的摄像机优化朝向。<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540532x45_hanspub.png" xlink:type="simple"/></inline-formula>表示虚拟路径位置i的坐标。<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540532x46_hanspub.png" xlink:type="simple"/></inline-formula>与<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540532x47_hanspub.png" xlink:type="simple"/></inline-formula>表示第j时刻摄像机的实际位置坐标和朝向。<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540532x48_hanspub.png" xlink:type="simple"/></inline-formula>与<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540532x49_hanspub.png" xlink:type="simple"/></inline-formula>为权重常数，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540532x50_hanspub.png" xlink:type="simple"/></inline-formula>、<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540532x51_hanspub.png" xlink:type="simple"/></inline-formula>，分别表示位置偏差与朝向偏差在目标函数中所占的比重。</p><p>实际中可选<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540532x52_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540532x53_hanspub.png" xlink:type="simple"/></inline-formula>，在分别对位置偏差与朝向归一化的基础上使两者权重相等。</p></sec><sec id="s7_2"><title>5.2. 纸型</title><p>视角变换是通过适当的矩阵映射使一视角的图像矩阵变换为从另一视角看去的图像矩阵。通过变换视角，过滤掉连续的视频帧在视角上较大的晃动，使其在视觉上表现平滑。首先，通过内参投影矩阵使相平面坐标变换为对应摄像机坐标系下的坐标向量，然后通过旋转矩阵使此坐标向量变换为虚拟视角的摄像机坐标系下的坐标向量，最后再通过内参矩阵使坐标向量投影到虚拟像平面。</p><p>设摄像机在实际位置i具有旋转矩阵<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540532x54_hanspub.png" xlink:type="simple"/></inline-formula>，虚拟路径点j的摄像机旋转矩阵为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540532x55_hanspub.png" xlink:type="simple"/></inline-formula>。当摄像机内参矩阵为K时，虚拟像平面坐标点<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540532x56_hanspub.png" xlink:type="simple"/></inline-formula>与实际相平面坐标点<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540532x57_hanspub.png" xlink:type="simple"/></inline-formula>之间的关系为：</p><disp-formula id="hanspub.16613-formula244"><label>(8)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/2-1540532x58_hanspub.png"  xlink:type="simple"/></disp-formula></sec></sec><sec id="s8"><title>6. 实验分析</title><p>实验表明本文算法在无精确内参的条件下，通过3D摄像机运动估计可以达到视频去抖的目的。</p><p>实验配置为：intel(R)Xeon(R) E5620 2.40 Hz，内存12.0 GB，操作系统Windows Server 2008 R2 Standard。</p><p>本文数据集采用了Feng Liu提供的抖动视频数据集0018AF[<xref ref-type="bibr" rid="hanspub.16613-ref7">7</xref>] 和shakycar [<xref ref-type="bibr" rid="hanspub.16613-ref7">7</xref>] 。</p><p>视角平滑迭代参数alpha试验中取3~8就已经能产生很好的效果。</p><p>实验结果如图4所示。其中，射线表示相机视角朝向。图4(a)是视角平滑前数据集0018AF的摄像机真实朝向。图4(b)显示了对视角做平滑估计后的结果。本文算法在不改变相机真实运动轨迹的基础上，对相机视角进行平滑处理。图4(c)是Shuaicheng Liu的2d去抖算法对视角的处理情况。Shuaicheng Liu的算法在优化视角的同时改变了相机原始轨迹，没有真实反映出拍摄者的浏览路径。图4(d)~(f)分别表示了shakycar数据集视角平滑前后的视角变化和Shuaicheng Liu算法的视角变化。可以看出，本文算法在不改变相机原始轨迹的基础上，能更好的平滑视角朝向。</p><p>本文算法和Shuaicheng Liu的算法对视角平滑的对比结果如表1所示。其中平均角速度表示了相机视角变化的幅度，平局角速度越大说明视频抖动幅度越大。平均角加速度衡量视角变化的突然程度，平均角加速度越大所产生的视频抖动越剧烈。</p><p>表1的实验结果显示，本文的视角变换策略是有效的，并且对比Shuaicheng Liu算法有更好的视角平滑效果。</p><p>本文算法与Shuaicheng Liu的2D去抖算法的效果对比如图5所示。图5(a)~(c)分别是0018AF数据集原始数据、Shuaicheng Liu的2D去抖算法和本文算法对0018AF数据集第12至16帧数据的处理</p><p>图4. 视角平滑前后的对比。(a) 0018AF平滑前；(b) 0018AF平滑后；(c) Shuaicheng Liu的方法；(d) 0018AF平滑前；(e) 0018AF平滑后；(f) Shuaicheng Liu的方法</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Smoothing algorithm data contras</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >0018AF</th><th align="center" valign="middle" >原始数据</th><th align="center" valign="middle" >本文算法</th><th align="center" valign="middle" >Shuaicheng Liu算法</th></tr></thead><tr><td align="center" valign="middle" >平均角速度</td><td align="center" valign="middle" >0.3633</td><td align="center" valign="middle" >0.0106</td><td align="center" valign="middle" >0.0116</td></tr><tr><td align="center" valign="middle" >平均角加速度</td><td align="center" valign="middle" >0.0938</td><td align="center" valign="middle" >0.0012</td><td align="center" valign="middle" >0.0059</td></tr></tbody></table></table-wrap><p>表1. 平滑算法数据对比</p><p>图5. 本文算法与Shuaicheng Liu算法效果对比。(a) 0018AF第12至16帧原始视频帧；(b) 本文算法效果；(c) Shuaicheng Liu算法效果；(d) shakycar第22至26帧原始视频帧；(e) 本文算法效果；(f) Shuaicheng Liu算法效果</p><p>结果。图5(d)~(f)分别是shakycar原始数据、Shuaicheng Liu的2D去抖算法和本文算法对数据集第22至26帧数据的处理结果。图5(b)和图5(e)显示经本文算法处理的视频帧去除了视频抖动，且不存在图像局部区域的抖动问题。在图5(c)和图5(f)中，Shuaicheng Liu的去抖算法由于图像特征点分布不均匀，去抖处理产生了图像局部区域的抖动。本文算法，基于更合理的相机运动模型，避免了帧局部的失真。</p></sec><sec id="s9"><title>7. 结论</title><p>本文提出了一种基于对视角优化进行运动补偿的3D视频去抖算法，通过估计摄像机3D运动轨迹选帧并做视角优化进行视频去抖。我们采用视角优化的方法更合理地修正了摄像机的运动参数，稳定视频内容。实验证明本文算法在缺乏精确摄像机内参数的条件下，可以通过摄像机3D运动估计，很好的解决便携设备中普遍存在的视频抖动问题。</p></sec><sec id="s10"><title>文章引用</title><p>杨诚笃,许宏丽,尹辉,黄华. 基于视角优化的便携像机视频去抖算法 Orientation Optimization Based 3D Video Stabilization for Portable Cameras[J]. 计算机科学与应用, 2015, 05(12): 436-444. http://dx.doi.org/10.12677/CSA.2015.512055</p></sec><sec id="s11"><title>参考文献 (References)</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.16613-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">[1]	Hartley, R. and Zisserman, A. (2003) Multiple View Geometry in Computer Vision. Cambridge University Press, Cambridge.</mixed-citation></ref><ref id="hanspub.16613-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">宋利, 周源华, 周军. 基于运动矢量的视频去抖动算法[J]. 上海交通大学学报, 2004(z1): 63-66.</mixed-citation></ref><ref id="hanspub.16613-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Song, L., Zhou, Y.H. and Zhou, J. (2005) Robust Video Stabilization Based on Motion Vectors. Journal of Shanghai University (English Edition), 9, 46-51. &lt;br&gt;http://dx.doi.org/10.1007/s11741-005-0103-1</mixed-citation></ref><ref id="hanspub.16613-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">徐理东, 林行刚. 视频抖动矫正中全局运动参数的估计[J]. 清华大学学报: 自然科学版, 2007, 47(1): 92-95.</mixed-citation></ref><ref id="hanspub.16613-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">赵文华, 姚天翔, 叶秀清, 等. RANSAC算法在视频去抖动中的应用[J]. 电路与系统学报, 2005, 10(4): 91-94.</mixed-citation></ref><ref id="hanspub.16613-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">於俊, 汪增福. 基于SIFT特征匹配的实时鲁棒视频去抖系统[J]. 系统工程与电子技术, 2014, 36(2).</mixed-citation></ref><ref id="hanspub.16613-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Liu, S., Yuan, L., Tan, P. and Sun, J. (2013) Bundled Camera Paths for Video Stabilization. ACM Transactions on Graphics (TOG), 32, 78. &lt;br&gt;http://dx.doi.org/10.1145/2461912.2461995</mixed-citation></ref><ref id="hanspub.16613-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Liu, F., Gleicher, M., Jin, H. and Agarwala, A. (2009) Content-Preserving Warps for 3D Video Stabilization. ACM Transactions on Graphics (TOG), 28, 44.</mixed-citation></ref><ref id="hanspub.16613-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Kopf, J., Cohen, M.F. and Szeliski, R. (2014) First-Person Hyper-Lapse Videos. ACM Transactions on Graphics (TOG), 33, 78. &lt;br&gt;http://dx.doi.org/10.1145/2601097.2601195</mixed-citation></ref><ref id="hanspub.16613-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Ryu, Y.G., Roh, H.C. and Chung, M.J. (2010) 3D Video Stabi-lization for Humanoid Eyes Using Vision and Inertial Sensors Inspired by Human VOR. IEEE International Conference on Robotics and Biomimetics (ROBIO), 1780-1785.</mixed-citation></ref><ref id="hanspub.16613-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Buehler, C., Bosse, M. and McMillan, L. (2001) Non-Metric Image-Based Rendering for Video Stabilization. Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2, II-609.  
&lt;br&gt;http://dx.doi.org/10.1109/cvpr.2001.991019</mixed-citation></ref><ref id="hanspub.16613-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Snavely, N., Seitz, S.M. and Szeliski, R. (2006) Photo Tourism: Exploring Photo Collections in 3D. ACM Transactions on Graphics (TOG), 25, 835-846.</mixed-citation></ref><ref id="hanspub.16613-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Shoemake, K. (1985) Animating Rotation with Quaternion Curves. ACM SIGGRAPH Computer Graphics, 19, 245-254.  
&lt;br&gt;http://dx.doi.org/10.1145/325165.325242</mixed-citation></ref></ref-list></back></article>