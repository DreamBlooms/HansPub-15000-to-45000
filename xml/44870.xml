<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">JISP</journal-id><journal-title-group><journal-title>Journal of Image and Signal Processing</journal-title></journal-title-group><issn pub-type="epub">2325-6753</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/JISP.2021.104017</article-id><article-id pub-id-type="publisher-id">JISP-44870</article-id><article-categories><subj-group subj-group-type="heading"><subject>JISP20210400000_97326902.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  受生物视觉“图形–背景”分辨机制启发的遥感影像水体信息提取方法
  Water Body Information Extraction Method from Remote Sensing Images Inspired by Biological Visual Mechanism of FB Discrimination
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>徐</surname><given-names>梦溪</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>施</surname><given-names>建强</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>沈</surname><given-names>克永</given-names></name><xref ref-type="aff" rid="aff4"><sup>4</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>梁</surname><given-names>玉英</given-names></name><xref ref-type="aff" rid="aff4"><sup>4</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>南京工程学院，计算机工程学院，江苏 南京</addr-line></aff><aff id="aff4"><addr-line>南昌理工学院，计算机信息工程学院，江西 南昌</addr-line></aff><aff id="aff3"><addr-line>南京工程学院，能源与动力工程学院，江苏 南京</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>30</day><month>08</month><year>2021</year></pub-date><volume>10</volume><issue>04</issue><fpage>155</fpage><lpage>165</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
  蝇类昆虫–果蝇复眼视觉系统的高适应性和高可靠性是一种自然特性，对于视觉杂乱场景中感兴趣目标/区域(统称“图形”)的分辨和飞行追踪过程，在本质上却是良态和适定的。本文针对遥感影像水体信息提取所涉及的图像分割和“图形–背景(figure-backgrounds, FB)”分辨这一逆问题求解存在的病态的(不适定的)本质性困难，基于昆虫生理学研究的新发现，分析果蝇复眼视觉信息加工的神经过程，模拟其无需背景建模、先验信息以及不依赖于样本数据训练隐式模型，所具有的视觉杂乱背景且噪声干扰下“图形–背景”分辨的功能优势，提出一种仿蝇视觉“图形–背景”分辨的遥感影像水体提取方法，通过多组仿真实验，并与标准的归一化差异水体指数NDWI、改进的NDWI (MNDWI)、决策树模型以及SVM分类等方法做了分析对比，验证了新方法的优越性。
   The high adaptability and reliability of the compound visual system of flies and drosophila is a natural characteristic, and the identification and flight tracking process of the target/region of interest (general called “graphics”) in the visual clutter scene is essentially well-conditioned and well-adapted. This paper focuses on the ill-posed (not well-posed) inherent difficulties of image segmentation and inverse problem of “figure-backgrounds (FB)” resolution in water extraction from remote sensing images. Based on the new findings of insect physiology, the neural processing of compound visual information in drosophila is analyzed, and the implicit model is trained by simulating modeling without background and prior information, or relying on the sample data, which has the advantages of visual clutter and “figure-backgrounds” resolution under noise interference. A method of water extraction from remote sensing image based on simulating fly’s vision “figure-backgrounds” resolution is proposed. Compared with the standard normalized differential water body index (NDWI), improved NDWI (MNDWI), decision tree model and SVM classification method, the superiority of the new method is verified.
 
</p></abstract><kwd-group><kwd>遥感影像，水体信息提取，杂乱背景，仿生复眼信息处理，神经建模, Remote Sensing Image</kwd><kwd> Water Information Extraction</kwd><kwd> Cluttered Backgrounds</kwd><kwd> Information Processing of Bionic Compound Eye</kwd><kwd> Neural Modeling</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>摘要</title><p>蝇类昆虫–果蝇复眼视觉系统的高适应性和高可靠性是一种自然特性，对于视觉杂乱场景中感兴趣目标/区域(统称“图形”)的分辨和飞行追踪过程，在本质上却是良态和适定的。本文针对遥感影像水体信息提取所涉及的图像分割和“图形–背景(figure-backgrounds, FB)”分辨这一逆问题求解存在的病态的(不适定的)本质性困难，基于昆虫生理学研究的新发现，分析果蝇复眼视觉信息加工的神经过程，模拟其无需背景建模、先验信息以及不依赖于样本数据训练隐式模型，所具有的视觉杂乱背景且噪声干扰下“图形–背景”分辨的功能优势，提出一种仿蝇视觉“图形–背景”分辨的遥感影像水体提取方法，通过多组仿真实验，并与标准的归一化差异水体指数NDWI、改进的NDWI (MNDWI)、决策树模型以及SVM分类等方法做了分析对比，验证了新方法的优越性。</p></sec><sec id="s2"><title>关键词</title><p>遥感影像，水体信息提取，杂乱背景，仿生复眼信息处理，神经建模</p></sec><sec id="s3"><title>Water Body Information Extraction Method from Remote Sensing Images Inspired by Biological Visual Mechanism of FB Discrimination<sup> </sup></title><p>Mengxi Xu<sup>1</sup>, Jianqiang Shi<sup>2</sup>, Keyong Shen<sup>3</sup>, Yuying Liang<sup>3</sup></p><p><sup>1</sup>School of Computer Engineering, Nanjing Institute of Technology, Nanjing Jiangsu</p><p><sup>2</sup>School of Energy and Power Engineering, Nanjing Institute of Technology, Nanjing Jiangsu</p><p><sup>3</sup>College of Computer Information and Engineering, Nanchang Institute of Technology, Nanchang Jiangxi</p><p><img src="//html.hanspub.org/file/1-2670267x4_hanspub.png?20210831084926685" /></p><p>Received: Jul. 17<sup>th</sup>, 2021; accepted: Aug. 23<sup>rd</sup>, 2021; published: Aug. 30<sup>th</sup>, 2021</p><p><img src="//html.hanspub.org/file/1-2670267x5_hanspub.png?20210831084926685" /></p></sec><sec id="s4"><title>ABSTRACT</title><p>The high adaptability and reliability of the compound visual system of flies and drosophila is a natural characteristic, and the identification and flight tracking process of the target/region of interest (general called “graphics”) in the visual clutter scene is essentially well-conditioned and well-adapted. This paper focuses on the ill-posed (not well-posed) inherent difficulties of image segmentation and inverse problem of “figure-backgrounds (FB)” resolution in water extraction from remote sensing images. Based on the new findings of insect physiology, the neural processing of compound visual information in drosophila is analyzed, and the implicit model is trained by simulating modeling without background and prior information, or relying on the sample data, which has the advantages of visual clutter and “figure-backgrounds” resolution under noise interference. A method of water extraction from remote sensing image based on simulating fly’s vision “figure-backgrounds” resolution is proposed. Compared with the standard normalized differential water body index (NDWI), improved NDWI (MNDWI), decision tree model and SVM classification method, the superiority of the new method is verified.</p><p>Keywords:Remote Sensing Image, Water Information Extraction, Cluttered Backgrounds, Information Processing of Bionic Compound Eye, Neural Modeling</p><disp-formula id="hanspub.44870-formula4"><graphic xlink:href="//html.hanspub.org/file/1-2670267x6_hanspub.png?20210831084926685"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2021 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/1-2670267x7_hanspub.png?20210831084926685" /> <img src="//html.hanspub.org/file/1-2670267x8_hanspub.png?20210831084926685" /></p></sec><sec id="s5"><title>1. 引言</title><p>卫星遥感具有大范围探测、实时性高、信息丰富等优点，已经成为提取江河湖库等水体的位置、面积、轮廓(边界)及水位的一种有效手段。利用卫星遥感数据进行水体信息提取的数据源主要包含雷达遥感数据、光学遥感数据以及两者结合的数据。在可见光范围内，水体的反射率总体上比较低，不超过10%，一般为4%~5%，并随着波长的增大逐渐降低。在红外波谱段，水体吸收了近红外及短波红外谱段内绝大部分的入射能量，反射能量很少；而其它地物所吸收的能量较小，具有较高的反射率，这使得水体在红外波波谱段与植被、土壤、城市建筑等地物有明显区别，遥感影像水体提取正是利用目标地物在不同波谱段表现出不同的反射或辐射特性来确定水体的位置、面积和边界等。水体信息提取采用了低、中、高不同分辨率的卫星遥感手段，中低分辨率遥感具有良好的现势性和宏观性，高分辨率遥感影像解译质量高，但高分影像获取周期长、时间分辨率较低，低分影像可以监测到水体每日的变化情况，时间分辨率较高，不同分辨率影像能够在空间、时间上互补。</p><p>在基于光学的多光谱、高光谱遥感水体提取研究方面，目前应用最多的水体提取方法包括基于像元分类的阈值法、基于目标/区域分类的分类器法和不同方法的集成法三类。阈值法多应用于中、低分辨率影像，包括单波段法，多波段法的谱间关系法、比值法、水体指数法等 [<xref ref-type="bibr" rid="hanspub.44870-ref1">1</xref>] [<xref ref-type="bibr" rid="hanspub.44870-ref2">2</xref>] [<xref ref-type="bibr" rid="hanspub.44870-ref3">3</xref>] [<xref ref-type="bibr" rid="hanspub.44870-ref4">4</xref>]。分类器法更适用于地物细节信息丰富的中、高分辨率影像的水体提取，主要包括支持向量机、决策树、面向对象的方法，以及基于浅层学习和基于深度学习的方法 [<xref ref-type="bibr" rid="hanspub.44870-ref2">2</xref>] [<xref ref-type="bibr" rid="hanspub.44870-ref3">3</xref>] [<xref ref-type="bibr" rid="hanspub.44870-ref4">4</xref>] [<xref ref-type="bibr" rid="hanspub.44870-ref5">5</xref>]。集成法融合了阈值法、分类器法，以克服采用统一的全局性模型提取各个不同水体单元所存在的不足 [<xref ref-type="bibr" rid="hanspub.44870-ref6">6</xref>]。多年来有关遥感影像水体信息提取的研究，尽管已形成了许多有效的方法，但由于地表覆盖类型复杂、水体类型多样、浅滩/潮汐带/湿地等区域的水陆交叉、水体细小等，加上水体与山体等阴影混淆、污染水体和浮游植物引起的光谱差异、城市水系中水面漂浮物影响、空间分辨率受限下混合像元以及同物异谱和同谱异物现象等干扰因素，水体精细化提取方法的普适性和泛化能力还有待进一步提高 [<xref ref-type="bibr" rid="hanspub.44870-ref1">1</xref>] [<xref ref-type="bibr" rid="hanspub.44870-ref2">2</xref>] [<xref ref-type="bibr" rid="hanspub.44870-ref6">6</xref>]。</p><p>遥感影像中的光谱、纹理、局部结构、形状、颜色等特征信息是水体提取的关键要素，也是从背景中分割感兴趣目标/区域(统称为“图形”)以及辨识地物属性的重要依据。从计算机图像处理与模式识别的角度来看，水体提取所涉及的图像分割和“图形–背景(figure-backgrounds, FB)”分辨这一逆问题的求解，现有的诸如基于对象机理的动力学方程建模、数据驱动建模、基于学习方法受限于有限样本数据训练的建模等仍然解决不了求解的不适定(病态的)问题。模型与对象之间在在系统响应上难以做到“等价”，直接影响到图形–背景辨识的“精度”和水体信息的高质量解译。</p><p>大自然为从复杂背景中分辨感兴趣目标/区域提供了丰富的灵感来源。蝇类昆虫–果蝇复眼视觉系统的高适应性和高可靠性是一种自然特性，与灵长类动物的视觉系统相比，复眼分辨力和视觉计算资源尽管有限，对于视觉杂乱场景中(且噪声干扰条件下)“图形”的分辨和跟踪过程，在本质上却是良态和适定的 [<xref ref-type="bibr" rid="hanspub.44870-ref7">7</xref>] [<xref ref-type="bibr" rid="hanspub.44870-ref8">8</xref>]。受复眼视觉过程的启发，本文提出一种仿蝇视觉“图形–背景”分辨的遥感影像水体提取方法，探索独立于背景建模、先验信息以及不依赖于样本数据训练隐式模型的研究策略，为改进现有水体信息提取方法的局限性提供一种新途径。本文的主要贡献概括如下：</p><p>1) 借鉴复眼视觉系统的功能优势，基于最新的昆虫生理学研究发现，建立了一种新的仿生蝇视觉“图形–背景”分辨的遥感影像水体提取模型(water body extraction model from remote sensing images based on bionic drosophila vision of FB discrimination，简称WBEM-BDV)，模拟了视网膜–薄板–髓质–小叶视神经纤维网对于杂乱背景中“图形”的分割和辨识的神经计算过程。</p><p>2) 在对薄板单极细胞LMCs中一类L1、L5，髓质Tm3/Mi1等神经元(ON通道)，以及L2、L4、Tm1/Tm1(OFF通道)分别向下游层小叶投射的传递路径中，引入二级侧抑制机制，对被薄板分解成两条平行的ON和OFF通道的视觉信号，分别做二次视觉滤波(secondary visual filtering, SVF)，有效增强了杂乱背景下对“图形–背景”分辨的抗噪性能。</p><p>3) 通过模拟小叶及小叶板中小叶柱细胞LCs和小叶板切向细胞LPTCs对特征参数的提取和“图形–背景”辨识表现出的显著选择性神经过程，设计的光谱特征与空域特征交叉相关的多光谱遥感影像特征提取算法，经实验测试，验证了其在城市湖泊地区综合复杂特性背景下对于ON和OFF通道信号的整合，以及对于水体分割和辨识具有的敏感响应偏好和精细化的信息提取性能。</p></sec><sec id="s6"><title>2. 复眼视觉信息加工的神经通路和“图形–背景”分辨机制</title><p>蝇类昆虫–果蝇(drosophila)的头部有一对复眼，三只小的单眼(用于导航)和一对触角。复眼(compound eye)的形状呈曲面型，由小眼(ommatidium)成簇排列而成。单侧复眼大约有750~800小眼。每只小眼中包含8个感光细胞(即小眼视网膜细胞)和视紫红质(photopigment rhodopsin, Prh)等色素细胞，感光细胞R1~R8中，R1~R6负责大范围光谱的色觉 [<xref ref-type="bibr" rid="hanspub.44870-ref8">8</xref>] [<xref ref-type="bibr" rid="hanspub.44870-ref9">9</xref>]，R7和R8具有区分不同光谱的敏感性，R7对紫外光线敏感，R8对蓝、绿光敏感，主要负责感知偏振光和色觉 [<xref ref-type="bibr" rid="hanspub.44870-ref9">9</xref>] [<xref ref-type="bibr" rid="hanspub.44870-ref10">10</xref>]。场景光场被不同小眼中的不同感光细胞所感受，并产生各像点物像的光电转换响应，来自不同小眼的各像点物像在复眼视网膜上镶嵌聚集。感光细胞发送传像信号通向蝇脑内两侧的薄板(lamina)，薄板对各个小眼光感/传像信号进行整合，其功能特征类似视觉“胶片”。薄板与下游的髓质(medulla)、小叶(lobula)和小叶板(lobula plate)神经节层连续依次相连，而后汇聚到腹外侧原脑区VLP (ventrolateralprotocerebrum)，最后到达中央脑(central brain)的各个脑结构，形成复眼视觉信息加工处理的神经通路 [<xref ref-type="bibr" rid="hanspub.44870-ref7">7</xref>] [<xref ref-type="bibr" rid="hanspub.44870-ref9">9</xref>]。复眼感光部将获取到的光强、光谱、时间、空间等复合光信息传递给薄板–髓质–小叶组成的视叶(optic lobe)神经纤维网进行加工，提高成像的敏感度、信噪比以及静/动特征参数提取能力，实现“图形–背景”的分割和辨识。</p><p>复眼感光部和神经元线路结构遵循神经叠加原理，视叶的每层神经纤维网是对应于每个小眼六角形晶格的柱状组件重复排列 [<xref ref-type="bibr" rid="hanspub.44870-ref11">11</xref>]。视叶的柱状组织结构是从果蝇视野中每一个像素所对应的薄板层的每一个柱状组件开始，直接接受来自R1~R8感光细胞的投射，形成一个单一的柱状视觉单元(即所谓薄板弹药筒(laminar cartridges)结构形式)，然后，延伸至髓质、进入小叶和小叶板。薄板层的每一个柱状组件主要包含薄板单极细胞LMCs (lamina monopolar cells)，LMCs中L1~L5对接受的光信号能够选择性地调节信号的强度和频率分布，相近神经元彼此之间的侧抑制(lateral inhibition)现象使对比的差异增强、突出边缘，且具有显著的光照亮度适应性和对图像的细微间断处进行拟合以及聚类效应。L1~L5在将视觉信号传递给下游层之前，被分解成两条平行的ON (打开)和OFF (关闭)信号通道 [<xref ref-type="bibr" rid="hanspub.44870-ref12">12</xref>]。ON通道，对由暗变亮、亮色增强做出响应、对有光的边缘敏感，OFF通道，对由亮变暗、亮色衰减做出响应、对无光的边缘敏感。髓质层包括髓质固有细胞Mi (medullaintrinsic cells)、跨髓细胞Tm (transmedulla cells)、末稍髓质细胞Dm (distalmedulla cells)、跨层细胞(translamellar cells)以及位于髓质和小叶板间的传出细胞(centrifugal cells) C2、C3等类型。来自R1～R6的信号经薄板L1到髓质Mi1、Tm3再汇集于T4，形成ON通道的信号最强连接。类似的，从薄板L2、L3 (包括L2与L4的层内连接)到髓质Tm1，Tm2、Tm4和Tm9组成向下游小叶传递的另一OFF通道 [<xref ref-type="bibr" rid="hanspub.44870-ref10">10</xref>] [<xref ref-type="bibr" rid="hanspub.44870-ref13">13</xref>]。ON/OFF通道中各神经元对信号的处理存在时间差异，这种信号延迟线会对图形亮/暗色边缘分割以及亮/暗边移动的检测产生作用。R7/R8经薄板分别延伸至髓质层，并向小叶投射，小叶参与了光谱偏好、颜色和偏振光视觉 [<xref ref-type="bibr" rid="hanspub.44870-ref10">10</xref>]。小叶和小叶板是髓质的正下游层。小叶中小叶柱细胞(lobula columnar cells) LCs覆盖了绝大部分的小叶，与小叶板切向细胞LPTCs (lobula plate tangential cells)一起，它们的轴突大多数投射到原脑区或与颈及足、翅运动有关的神经元 [<xref ref-type="bibr" rid="hanspub.44870-ref7">7</xref>] [<xref ref-type="bibr" rid="hanspub.44870-ref11">11</xref>]。</p><p>有关复眼的组织学和神经生理学研究已有一个多世纪的历史。当今，其视觉系统也已成为研究计算机视觉与模式识别问题的重要模型 [<xref ref-type="bibr" rid="hanspub.44870-ref7">7</xref>] [<xref ref-type="bibr" rid="hanspub.44870-ref14">14</xref>] [<xref ref-type="bibr" rid="hanspub.44870-ref15">15</xref>]。特别是近十多年来，又取得了许多新的研究发现 [<xref ref-type="bibr" rid="hanspub.44870-ref9">9</xref>] [<xref ref-type="bibr" rid="hanspub.44870-ref10">10</xref>] [<xref ref-type="bibr" rid="hanspub.44870-ref12">12</xref>] [<xref ref-type="bibr" rid="hanspub.44870-ref13">13</xref>] [<xref ref-type="bibr" rid="hanspub.44870-ref16">16</xref>]。例如，在10年前，对于果蝇的ON、OFF信号通道还是未知的，对于“图形–背景”分辨机制更多的是猜测，而现在，有关ON、OFF通道的神经元细节和信号传导，LPTCs及其亚群对特征参数的提取和图形–背景辨识表现出的显著选择性等神经计算机理也越来越清晰，这为建立精细化的人工复眼视觉信息加工神经网络模型奠定了生物学基础。</p></sec><sec id="s7"><title>3. 仿蝇视觉“图形–背景”分辨的遥感影像水体提取模型(WBEM-BDV)</title><p>构建的仿生蝇视觉“图形–背景”分辨的遥感影像水体提取模型(简称WBEM-BDV模型)，设有视网膜层计算层、薄板层计算、髓质层计算层、小叶和小叶板层计算四个层级 [<xref ref-type="bibr" rid="hanspub.44870-ref17">17</xref>]。WBEM-BDV模型框架如图1示意。</p><p>1) 视网膜层计算</p><p>基于复眼感受光场和光谱的刺激，模拟视网膜感光细胞光电转换响应。设计“重叠捆绑”的三个3 &#215; 3小观察窗口，构建“仿小眼感受野”，来近似一个小眼的采样(x, y, k)，分别代表仿小眼感受野中心“像元”的坐标和k波段的采样。采用“仿小眼感受野”遍历地滑动扫描的方式，读取“光强–光谱”遥感影像信息，形成对遥感影像输入的网格化读取处理，模仿小眼感光传像信号的投射，在薄板层形成视觉“胶片”。</p><p>2) 薄板层计算</p><p>薄板层计算包括初级视觉滤波和半波整流，初级视觉滤波由模拟薄板单极细胞LMCs空域带通滤波和侧抑制滤波二个部分组成，其初级视觉滤波机制的核心是基于中心–周围对抗(centre-surrounding antagonism)的互抑制现象。薄板单极细胞LMCs中L1、L2~L5，每个神经元可以作为一个带通滤波器，带通滤波器由仿小眼感受野的采样输出和带通滤波器 H ( k ) 卷积得到 [<xref ref-type="bibr" rid="hanspub.44870-ref16">16</xref>] [<xref ref-type="bibr" rid="hanspub.44870-ref18">18</xref>] [<xref ref-type="bibr" rid="hanspub.44870-ref19">19</xref>] [<xref ref-type="bibr" rid="hanspub.44870-ref20">20</xref>] [<xref ref-type="bibr" rid="hanspub.44870-ref21">21</xref>]。LMCs相近神经元彼此之间的中心–周围对抗互抑制可由下式解析：</p><p>L A ( x , y , k ) = { | P e ( x , y , k ) − P i ( x , y , k ) | ,           if   P e ( x , y , k ) ≥ 0 , P i ( x , y , k ) ≥ 0 − | P e ( x , y , k ) − P i ( x , y , k ) | ,     if   P e ( x , y , k ) &lt; 0 , P i ( x , y , k ) &lt; 0 (1)</p><p>式中， P e 代表中心正高斯的兴奋信号， P i 代表周围负高斯的抑制信号。</p><p>采用半波整流方式，将视网膜感光传像信号分解成两条平行的ON和OFF通道进行处理：</p><p>ON通道：</p><p>L O N ( x , y , k ) = Z ( x , y ^ , k ) ,   if   Z ( x , y ^ , k ) &gt; 0 (2)</p><p>OFF通道：</p><p>L O F F ( x , y , k ) = − Z ( x , y ^ , k ) ,   if   Z ( x , y ^ , k ) &lt; 0 (3)</p><p>图1. WBEM-BDV模型框架</p><p>3) 髓质层计算与二次视觉滤波(ON-SVF、OFF-SVF)</p><p>髓质层对于ON和OFF通道信号的二次视觉滤波(secondary visual filtering, SVF)是通过二次侧抑制实现的，设像元坐标为 ( x , y ) 和相邻像元坐标为 ( u , v ) ，经侧抑制的输出信号为 [<xref ref-type="bibr" rid="hanspub.44870-ref16">16</xref>] [<xref ref-type="bibr" rid="hanspub.44870-ref21">21</xref>] [<xref ref-type="bibr" rid="hanspub.44870-ref22">22</xref>]：</p><p>O N L I ( x , y , k ) = ∬ O N ( u , v , k ) W 2 ( x − u , y − v ) d u d v (4)</p><p>O F F L I ( x , y , k ) = ∬ O F F ( u , v , k ) W 2 ( x − u , y − v ) d u d v (5)</p><p>上式中， W 2 ( x , y ) 为侧抑制核函数，其定义如下 [<xref ref-type="bibr" rid="hanspub.44870-ref16">16</xref>] [<xref ref-type="bibr" rid="hanspub.44870-ref22">22</xref>]：</p><p>W 2 ( x , y ) = A [ D 1 O G ( x , y ) ] + + B [ D 1 O G ( x , y ) ] − (6)</p><p>D 1 O G ( x , y ) = G σ 4 ( x , y ) − G σ 5 ( x , y ) (7)</p><p>其中， G σ ( x , y ) 为高斯函数A和B均为常量。</p><p>4) 小叶和小叶板层计算</p><p>大多数计算机视觉的图形–背景辨识方法通常是静态空域特征和动态时域特征分别处理的，很少考虑两类特征之间的交互作用，而蝇视觉的“图形–背景”分辨却是基于动态时域特征和静态空域特征综合作用的结果 [<xref ref-type="bibr" rid="hanspub.44870-ref23">23</xref>]。利用光谱特征与空域特征交叉相关的多光谱遥感影像特征提取算法设计，是实现仿蝇视觉“图形–背景”分辨的遥感影像水体提取的关键。</p><p>选择空间相邻两个像元的光谱强度值作为光谱与空域交互的特征提取算法流程的输入，采用对称交叉相乘的处理方式 [<xref ref-type="bibr" rid="hanspub.44870-ref20">20</xref>] [<xref ref-type="bibr" rid="hanspub.44870-ref21">21</xref>]，由下式表示：</p><p>R h ( x , y ) = I k l ( x , y ) I k m ( x + Δ d , y ) − I k l ( x + Δ d , y ) I k m ( x , y ) (8)</p><p>上式的 R h ( x , y ) 为 k l 波段与 k m 波段在水平方向上间隔为 Δ d 距离的光谱强度交叉相关后相减的结果。式中， ( x , y ) 表示像元的空间位置， R h 为特征提取算法的输出， I k l ( x , y ) 和 I k m ( x , y ) 分别是 k l 、 k m 波段在空间位置 ( x , y ) 上的光谱强度值， I k l ( x + Δ d , y ) 是 k l 波段在水平方向上与第 ( x , y ) 个像元间隔 Δ d 距离处的光谱强度值， I k m ( x + Δ d , y ) 也同理。</p><p>利用欧几里得距离可计算出空间位置点 ( x , y ) 上的特征信息 [<xref ref-type="bibr" rid="hanspub.44870-ref20">20</xref>]，支持“图形–背景”的分割和辨识。当像元间隔 Δ d = 1 时， M ( x , y ) 反映了 ( x , y ) 像元处的光谱强度变化，即，</p><p>M ( x , y ) = R h ( x , y ) 2 + R v ( x , y ) 2 (9)</p><p>式中， R h ( x , y ) ， R v ( x , y ) 是 ( x , y ) 像元分别在水平和垂直方向上的特征信息。</p></sec><sec id="s8"><title>4. 实验与分析</title><sec id="s8_1"><title>4.1. 实验数据</title><p>城市中的湖泊地区大多存在综合复杂特性：1) 地表覆盖(也包含各类人工绿化区块)的类型复杂；2) 水体与城市建筑物阴影混淆；3) 浅滩等水陆交叉且水体细小；4) 水体富营养化和浮游、浮叶植物引起的光谱差异；5) 空间分辨率受限下混合像元影响严重。使得水体信息的精细化提取(特别是基于中分辨率遥感影像)需要解决综合复杂性背景下的图像分割和解译。南京市百家湖地区具有上述城市湖泊地区综合复杂特性的典型性。实验中采用相同时期的法国SPOT-5以及美国Landsat-7遥感数据，并对实验结果做出人工目视判读评价，以及与地面测量数据进行对比分析。</p></sec><sec id="s8_2"><title>4.2. 基于SPOT-5近红外谱段影像的水体提取</title><p>1) SPOT-5数据</p><p>法国SPOT-5卫星上载有2台高分辨率几何成像装置(HRG)、1台高分辨率立体成像装置(HRS)、1台宽视域植被探测仪(VGT)等。HRG的观测参数示于表1。图2给出了2003年7月27日SPOT-5的HRG在近红外谱段获取的南京市百家湖遥感影像示例。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> HRG observation parameters carried by SPOT-</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >波谱段</th><th align="center" valign="middle" >类型</th><th align="center" valign="middle" >光谱范围(μm)</th><th align="center" valign="middle" >空间分辨率(m)</th></tr></thead><tr><td align="center" valign="middle" >PAN</td><td align="center" valign="middle" >全色(pan)</td><td align="center" valign="middle" >0.49~0.69</td><td align="center" valign="middle" >2.5、5</td></tr><tr><td align="center" valign="middle" >XS1</td><td align="center" valign="middle" >绿光(green)</td><td align="center" valign="middle" >0.49~0.61</td><td align="center" valign="middle" >10</td></tr><tr><td align="center" valign="middle" >XS1</td><td align="center" valign="middle" >红光(red)</td><td align="center" valign="middle" >0.61~0.68</td><td align="center" valign="middle" >10</td></tr><tr><td align="center" valign="middle" >XS3</td><td align="center" valign="middle" >近红外(near IR)</td><td align="center" valign="middle" >0.78~0.89</td><td align="center" valign="middle" >10</td></tr><tr><td align="center" valign="middle" >XS4</td><td align="center" valign="middle" >短波红外(SWIR)</td><td align="center" valign="middle" >1.58~1.75</td><td align="center" valign="middle" >20</td></tr></tbody></table></table-wrap><p>表1. SPOT-5搭载HRG的观测参数</p><p>图2. 南京市百家湖地区SPOT-5近红外影像</p><p>2) 基于SPOT-5近红外(near IR)影像的水体提取</p><p>图3(a)~(c)分别是传统的单波段阈值方法、决策树模型法 [<xref ref-type="bibr" rid="hanspub.44870-ref2">2</xref>] [<xref ref-type="bibr" rid="hanspub.44870-ref6">6</xref>] 和本文所提出的基于WBEM-BDV模型的新方法对水体提取的结果。实验中，单波段阈值法对影像进行二值化分割的上限阈值取98，下限阈值取86。由目视判读比较可看出，湖水水体也能够较准确地自动提取出来，只有少量部分的水体漏提、误提。相比较，单波段阈值法水体提取效果较差，分析原因是，岸边与水体过渡区域是由混合像元组成，单一阈值较难准确划分混淆的地物，影响细小水体提取效果。相比较，决策树模型法和WBEM-BDV新方法是较优的，这与人工目视判读分析是一致的。</p><p>图3. SPOT-5遥感百家湖水体提取结果</p><p>以靠近百家湖白龙桥(白龙桥是横跨湖心的桥，东西走向)北侧和南侧，岚湾桥(南北走向)西侧和东侧处分别设置地面测量点。根据地面实测数据的湖面宽度作为参照对比，基于相对误差RE和平均相对误差ARE指标，做客观评价，评价结果列于表2。从表中可看出，WBEM-BDV新方法的平均相对误差较小(ARE = 3.540%)，或者说遥感水体提取得到的湖面宽度与地面实测湖宽最为接近，决策树模型法的平均相对误差ARE = 3.541%，而单波段阈值法的平均相对误差最大(ARE = 4.448%)。说明WBEM-BDV新方法对水体信息精细化提取是有效的。</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> Objective evaluation for water body extraction of Baijia Lake based on SPOT-5 remote sensin</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >方法</th><th align="center" valign="middle" >位置</th><th align="center" valign="middle" >RE</th><th align="center" valign="middle" >ARE</th></tr></thead><tr><td align="center" valign="middle"  rowspan="2"  >单波段阈值</td><td align="center" valign="middle" >白龙桥北侧、南侧</td><td align="center" valign="middle" >3.386%，2.754%</td><td align="center" valign="middle"  rowspan="2"  >4.448%</td></tr><tr><td align="center" valign="middle" >岚湾桥西侧、东侧</td><td align="center" valign="middle" >7.107%，4.545%</td></tr><tr><td align="center" valign="middle"  rowspan="2"  >决策树模型</td><td align="center" valign="middle" >白龙桥北侧、南侧</td><td align="center" valign="middle" >2.550%，2.394%</td><td align="center" valign="middle"  rowspan="2"  >3.541%</td></tr><tr><td align="center" valign="middle" >岚湾桥西侧、东侧</td><td align="center" valign="middle" >5.584%，3.636%</td></tr><tr><td align="center" valign="middle"  rowspan="2"  >新方法</td><td align="center" valign="middle" >白龙桥北侧、南侧</td><td align="center" valign="middle" >2.545%，2.387%</td><td align="center" valign="middle"  rowspan="2"  >3.540%</td></tr><tr><td align="center" valign="middle" >岚湾桥西侧、东侧</td><td align="center" valign="middle" >5.585%，3.636%</td></tr></tbody></table></table-wrap><p>表2. SPOT-5遥感百家湖水体提取的客观评价</p></sec><sec id="s8_3"><title>4.3. Landsat-7与SPOT-5遥感数据融合及水体提取</title><p>1) Landsat-7数据</p><p>美国Landsat-7卫星载有增强型专题制图仪(Enhanced thematic mapper，简称ETM+)传感器。ETM+共有8个光谱波段，相比较Landsat-4、Landsat-5，增加了一个全色波谱段。ETM+的观测参数见表3所示。选用ETM+中的第2 (绿光)、第4 (近红外)、第5 (短波红外)波谱段（即ETM+542三个波谱段的百家湖地区假彩色合成影像）和第8波谱段的全色影像，经ETM+542与全色影像数据融合及合成后再进行水体提取实验。</p><table-wrap id="table3" ><label><xref ref-type="table" rid="table3">Table 3</xref></label><caption><title> ETM+ observation parameters carried by Landsat-</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >波谱段B</th><th align="center" valign="middle" >类型</th><th align="center" valign="middle" >光谱范围(μm)</th><th align="center" valign="middle" >空间分辨率(m)</th></tr></thead><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" >蓝光(blue)</td><td align="center" valign="middle" >0.45~0.515</td><td align="center" valign="middle" >30</td></tr><tr><td align="center" valign="middle" >2</td><td align="center" valign="middle" >绿光(green)</td><td align="center" valign="middle" >0.525~0.605</td><td align="center" valign="middle" >30</td></tr><tr><td align="center" valign="middle" >3</td><td align="center" valign="middle" >红光(red)</td><td align="center" valign="middle" >0.63~0.69</td><td align="center" valign="middle" >30</td></tr><tr><td align="center" valign="middle" >4</td><td align="center" valign="middle" >近红外(near IR，NIR)</td><td align="center" valign="middle" >0.775~0.90</td><td align="center" valign="middle" >30</td></tr><tr><td align="center" valign="middle" >5</td><td align="center" valign="middle" >短波红外(SWIR)</td><td align="center" valign="middle" >1.55~1.75</td><td align="center" valign="middle" >30</td></tr><tr><td align="center" valign="middle" >6</td><td align="center" valign="middle" >远红外(LWIR)</td><td align="center" valign="middle" >10.4~12.5</td><td align="center" valign="middle" >60</td></tr><tr><td align="center" valign="middle" >7</td><td align="center" valign="middle" >短波红外(SWIR)</td><td align="center" valign="middle" >2.09~2.35</td><td align="center" valign="middle" >30</td></tr><tr><td align="center" valign="middle" >8</td><td align="center" valign="middle" >全色(pan)</td><td align="center" valign="middle" >0.52~0.90</td><td align="center" valign="middle" >15</td></tr></tbody></table></table-wrap><p>表3. Landsat-7搭载ETM+的观测参数</p><p>2) 基于Landsat-7 ETM+数据融合的水体提取</p><p>通过第8波段全色波段与Landsat-7 ETM+542波谱段假彩色合成影像的数据融合处理，得到兼有全色影像的空间高分辨率和多光谱彩色信息的合成影像，在此基础上进行水体信息的提取。基于数据融合的水体信息提取流程如图4示意。</p><p>图4. 基于遥感数据融合的水体提取流程</p><p>ETM+542合成影像和全色影像的配准精度均在0.5个像素内，考虑到全色影像与ETM+542合成影像有不同的频率范围，可能造成同一场景中的同一地物会有不同的辐射响应，在融合之前还需要采用直方图匹配进行影像配准。传统的ETM+多光谱与全色影像融合方法在不同程度上存在一定的局限，考虑到均衡融合结果中的空间细节信息和光谱信息二项特征指标，实验中采用Choquet模糊积分选择小波变换系数的融合方法得到合成影像 [<xref ref-type="bibr" rid="hanspub.44870-ref24">24</xref>]。</p><p>分别采用归一化差异水体指数(normalized difference water index, NDWI)模型、改进的归一化差异水体指数(modified NDWI, MNDWI)模型、决策树模型法 [<xref ref-type="bibr" rid="hanspub.44870-ref2">2</xref>] [<xref ref-type="bibr" rid="hanspub.44870-ref6">6</xref>]、支持向量机SVM分类法 [<xref ref-type="bibr" rid="hanspub.44870-ref2">2</xref>] 和WBEM-BDV新方法的实验结果见图5。客观评价指标列于表4。</p><p>图5. 基于Landsat-7 ETM+数据融合的百家湖水体提取的实验结果</p><table-wrap id="table4" ><label><xref ref-type="table" rid="table4">Table 4</xref></label><caption><title> Objective evaluation of water body extraction based on ETM+ dat</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >方法</th><th align="center" valign="middle" >位置</th><th align="center" valign="middle" >RE</th><th align="center" valign="middle" >ARE</th></tr></thead><tr><td align="center" valign="middle"  rowspan="2"  >NDWI</td><td align="center" valign="middle" >白龙桥北侧、南侧</td><td align="center" valign="middle" >3.187%，2.754%</td><td align="center" valign="middle"  rowspan="2"  >4.323%</td></tr><tr><td align="center" valign="middle" >岚湾桥西侧、东侧</td><td align="center" valign="middle" >7.107%，4.242%</td></tr><tr><td align="center" valign="middle"  rowspan="2"  >MNDWI</td><td align="center" valign="middle" >白龙桥北侧、南侧</td><td align="center" valign="middle" >2.988%，2.582%</td><td align="center" valign="middle"  rowspan="2"  >4.230%</td></tr><tr><td align="center" valign="middle" >岚湾桥西侧、东侧</td><td align="center" valign="middle" >7.107%，4.242%</td></tr><tr><td align="center" valign="middle"  rowspan="2"  >决策树模型</td><td align="center" valign="middle" >白龙桥北侧、南侧</td><td align="center" valign="middle" >2.390%，2.410%</td><td align="center" valign="middle"  rowspan="2"  >3.505%</td></tr><tr><td align="center" valign="middle" >岚湾桥西侧、东侧</td><td align="center" valign="middle" >5.584%，3.636%</td></tr><tr><td align="center" valign="middle"  rowspan="2"  >SVM分类</td><td align="center" valign="middle" >白龙桥北侧、南侧</td><td align="center" valign="middle" >2.390%，2.028%</td><td align="center" valign="middle"  rowspan="2"  >3.448%</td></tr><tr><td align="center" valign="middle" >岚湾桥西侧、东侧</td><td align="center" valign="middle" >5.584%，3.636%</td></tr><tr><td align="center" valign="middle"  rowspan="2"  >新方法</td><td align="center" valign="middle" >白龙桥北侧、南侧</td><td align="center" valign="middle" >2.364%，1.841%</td><td align="center" valign="middle"  rowspan="2"  >3.356%</td></tr><tr><td align="center" valign="middle" >岚湾桥西侧、东侧</td><td align="center" valign="middle" >5.584%，3.435%</td></tr></tbody></table></table-wrap><p>表4. 基于ETM+数据的水体提取的客观评价</p><p>实验中NDWI、MNDWI的阈值取值大于0.3。NDWI和MNDWI模型公式分别为：</p><p>NDWI = ( G − NIR ) / ( G + NIR ) ，(G~绿光；NIR~近红外) (10)</p><p>MNDWI = ( G − SWIR ) / ( G + SWIR ) ，(G~绿光；SWIR~短波红外) (11)</p><p>从表中可看出，相比较水体指数法，决策树模型法、SVM分类法和WBEM-BDV新方法，水体提取的湖面宽与地面实际测量宽度最为接近，但决策树模型和SVM分类法的平均相对误差ARE稍劣于WBEM-BDV新方法，说明WBEM-BDV新方法具有一定的优势。</p></sec></sec><sec id="s9"><title>5. 结论</title><p>本文基于最新的昆虫生理学研究成果，在分析复眼视觉信息加工处理的神经通路基础上，建立了一种新的仿生蝇视觉“图形–背景”分辨的遥感影像水体提取模型(简称WBEM-BDV模型)，模拟了视叶神经纤维网对于杂乱背景中“图形”的分割和辨识的神经计算过程。设计了初级视觉滤波、二次视觉滤波(SVF)和光谱特征与空域特征交叉相关的多光谱遥感影像特征提取算法。经SPOT-5和Landsat-7遥感百家湖水体信息提取的实验测试，并与传统的单波段阈值法、归一化差异水体指数NDWI模型、决策树模型和支持向量机SVM分类法等比较分析，人工目视判读和与地面实测的相对误差指标客观评价结果表明了本文所提出的WBEM-BDV新方法具有优越性。</p></sec><sec id="s10"><title>基金项目</title><p>本文得到南京工程学院科研基金(项目编号：ZKJ201907)的资助。</p></sec><sec id="s11"><title>文章引用</title><p>徐梦溪,施建强,沈克永,梁玉英. 受生物视觉“图形–背景”分辨机制启发的遥感影像水体信息提取方法Water Body Information Extraction Method from Remote Sensing Images Inspired by Biological Visual Mechanism of FB Discrimination[J]. 图像与信号处理, 2021, 10(04): 155-165. https://doi.org/10.12677/JISP.2021.104017</p></sec><sec id="s12"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.44870-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">王航, 秦奋. 遥感影像水体提取研究综述[J]. 测绘科学, 2018, 43(5): 23-32.</mixed-citation></ref><ref id="hanspub.44870-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">李丹, 吴保生, 陈博伟, 薛源, 张翼. 基于卫星遥感的水体信息提取研究进展与展望[J]. 清华大学学报(自然科学版), 2020, 60(2): 147-161.</mixed-citation></ref><ref id="hanspub.44870-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Paul, A., Tripathi, D. and Dutta, D. (2018) Application and Comparison of Advanced Supervised Classifiers in Extraction of Water Bodies from Remote Sensing Images. Sustainable Water Resources Management, 4, 905-919.  
https://doi.org/10.1007/s40899-017-0184-6</mixed-citation></ref><ref id="hanspub.44870-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Crasto, N., Hopkinson, C., Forbes, D.L., Lesack, L., Marsh, P., Spooner, I. and van der Sanden, J.J. (2015) ALiDAR-Based Decision-Tree Classification of Open Water Surfaces in an Arctic Delta. Remote Sensing of Environment, 164, 90-102. https://doi.org/10.1016/j.rse.2015.04.011</mixed-citation></ref><ref id="hanspub.44870-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">陈前, 郑利娟, 李小娟, 徐崇斌, 吴俣, 谢东海, 刘亮. 基于深度学习的高分遥感影像水体提取模型研究[J]. 地理与地理信息科学, 2019, 35(4): 43-48.</mixed-citation></ref><ref id="hanspub.44870-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">饶萍, 王建力. 基于中分辨率遥感影像的水体信息精确提取[J]. 贵州大学学报(自然科学版), 2016, 33(5): 17-24.</mixed-citation></ref><ref id="hanspub.44870-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Paulk, A., Millard, S.S. and van Swinderen, B. (2013) Vision in Drosophila: Seeing the World through a Model’s Eyes. Annual Review of Entomology, 58, 313-332. https://doi.org/10.1146/annurev-ento-120811-153715</mixed-citation></ref><ref id="hanspub.44870-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">郭爱克, 彭岳清, 张柯, 奚望. 小虫春秋: 果蝇的视觉学习记忆与认知[J]. 自然杂志, 2009, 31(2): 63-68, 封2.</mixed-citation></ref><ref id="hanspub.44870-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Neriec, N. and Desplan, C. (2016) From the Eye to the Brain: Development of the Drosophila Visual System. Current Topics in Developmental Biology, 116, 247-271. https://doi.org/10.1016/bs.ctdb.2015.11.032</mixed-citation></ref><ref id="hanspub.44870-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Behnia, R. and Desplan, C. (2015) Visual Circuits in Flies: Beginning to See the Whole Picture. Current Opinion in Neurobiology, 34, 125-132. https://doi.org/10.1016/j.conb.2015.03.010</mixed-citation></ref><ref id="hanspub.44870-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Takemura, S., Bharioke, A., Lu, Z., Nern, A., Vitaladevuni, S., Rivlin, P.K., Katz, W.T., Olbris, D.J., Plaza, S.M., Winston, P., Zhao, T., Horne, J.A., Fetter, R.D., Takemura, S., Blazek, K., Chang, L., Ogundeyi, O., Saunders, M.A., Shapiro, V., Sigmund, C., Rubin, G.M., Scheffer, L.K., Meinertzhagen, I.A. and Chklovskii, D.B. (2013) A Visual Motion Detection Circuit Suggested by Drosophila Connectomics. Nature, 500, 175-181.  
https://doi.org/10.1038/nature12450</mixed-citation></ref><ref id="hanspub.44870-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Behnia, R., Clark, D.A., Carter, A.G., Clandinin, T.R. and Desplan, C. (2014) Processing Properties of ON and OFF Pathways for Drosophila Motion Detection. Nature, 512, 427-430. https://doi.org/10.1038/nature13427</mixed-citation></ref><ref id="hanspub.44870-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Haag, J., Arenz, A., Serbe, E., Gabbiani, F. and Borst, A. (2016) Complementary Mechanisms Create Direction Selectivity in the Fly. eLIFE, 5, 1-15. https://doi.org/10.7554/eLife.17421</mixed-citation></ref><ref id="hanspub.44870-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">Keles, M.F. and Frye, M.A. (2017) Object-Detecting Neurons in Drosophila. Current Biology, 27, 680-687.  
https://doi.org/10.1016/j.cub.2017.01.012</mixed-citation></ref><ref id="hanspub.44870-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">Egelhaaf, M. (1985) On the Neuronal Basis of Figure-Ground Discrimination by Relative Motion in the Visual System of the Fly. Biological Cybernetics, 52, 267-280. https://doi.org/10.1007/BF00336983</mixed-citation></ref><ref id="hanspub.44870-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">Wang, H., Peng, J. and Yue, S. (2020) A Directionally Selective Small Target Motion Detecting Visual Neural Network in Cluttered Backgrounds. IEEE Transactions on Cybernetics, 50, 1541-1555.  
https://doi.org/10.1109/TCYB.2018.2869384</mixed-citation></ref><ref id="hanspub.44870-ref17"><label>17</label><mixed-citation publication-type="other" xlink:type="simple">徐梦溪, 施建强. 仿生复眼型多源监测数据融合与专题信息提取[J]. 水利信息化, 2021(1): 71-75.</mixed-citation></ref><ref id="hanspub.44870-ref18"><label>18</label><mixed-citation publication-type="other" xlink:type="simple">Borst, A., Haag, J. and Mauss, A.S. (2020) How Fly Neurons Compute the Direction of Visual Motion. Journal of Comparative Physiology A, 206, 109-124. https://doi.org/10.1007/s00359-019-01375-9</mixed-citation></ref><ref id="hanspub.44870-ref19"><label>19</label><mixed-citation publication-type="other" xlink:type="simple">Missler, J.M. and Kamangar, F.A. (1995) A Neural Network for Pursuit Tracking Inspired by the Fly Visual System. Neural Networks, 8, 463-480. https://doi.org/10.1016/0893-6080(94)00105-U</mixed-citation></ref><ref id="hanspub.44870-ref20"><label>20</label><mixed-citation publication-type="other" xlink:type="simple">黄凤辰, 李敏, 石爱业, 汤敏, 徐立中. 受昆虫视觉启发的多光谱遥感影像小目标检测[J]. 通信学报, 2011, 32(9): 88-95.</mixed-citation></ref><ref id="hanspub.44870-ref21"><label>21</label><mixed-citation publication-type="other" xlink:type="simple">徐扬. 基于蝇视觉机制的信息特征提取方法研究[D]: [硕士学位论文]. 南京: 河海大学, 2021.</mixed-citation></ref><ref id="hanspub.44870-ref22"><label>22</label><mixed-citation publication-type="other" xlink:type="simple">Wiederman, S.D., Shoemaker, P.A. and O’Carroll, D.C. (2008) A Model for the Detection of Moving Targets in Visual Clutter Inspired by Insect Physiology. PLoS ONE, 3, e2784. https://doi.org/10.1371/journal.pone.0002784</mixed-citation></ref><ref id="hanspub.44870-ref23"><label>23</label><mixed-citation publication-type="other" xlink:type="simple">Watt, R.J. and Phillips, W.A. (2000) The Function of Dynamic Grouping Invision. Trends in Cognitive Sciences, 4, 447-454. https://doi.org/10.1016/S1364-6613(00)01553-9</mixed-citation></ref><ref id="hanspub.44870-ref24"><label>24</label><mixed-citation publication-type="other" xlink:type="simple">凌静, 徐立中, 石爱业, 黄凤辰, 汤敏. 一种基于Choquet模糊积分小波系数选择的遥感图像融合方法[J]. 遥感学报, 2009, 13(2): 263-268.</mixed-citation></ref></ref-list></back></article>