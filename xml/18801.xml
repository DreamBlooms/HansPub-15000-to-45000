<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">SEA</journal-id><journal-title-group><journal-title>Software Engineering and Applications</journal-title></journal-title-group><issn pub-type="epub">2325-2286</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/SEA.2016.55032</article-id><article-id pub-id-type="publisher-id">SEA-18801</article-id><article-categories><subj-group subj-group-type="heading"><subject>SEA20160500000_81913683.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>工程技术</subject></subj-group></article-categories><title-group><article-title>
 
 
  分块稀疏表示的人脸识别研究
  Face Recognition Research Based on Sparse Representation of Blocks
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>路</surname><given-names>杨</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>康</surname><given-names>瑞梅</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>张</surname><given-names>芳君</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>河南大学计算机与信息工程学院，河南 开封</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><author-notes><corresp id="cor1">* E-mail:<email>kangruimei24@sina.com(康瑞)</email>;</corresp></author-notes><pub-date pub-type="epub"><day>19</day><month>10</month><year>2016</year></pub-date><volume>05</volume><issue>05</issue><fpage>277</fpage><lpage>284</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   针对人脸识别中人脸被局部遮挡对识别效果带来的严重影响，提出一种对遮挡具有鲁棒性的分块稀疏表示分类的人脸识别算法。稀疏表示分类算法利用高维数据分布的稀疏性进行建模，能够很好地解决图像高维处理问题，有效地避免维数灾难。通过对该算法进行改进，提出一种分块稀疏表示的人脸识别算法。首先对人脸图像进行分割，独立地对每个子块进行稀疏表示分类，再通过所有子块的分类结果进行联合判别。改进后的算法避免了特征提取过程中所造成的图像信息丢失，也避免了人脸部分信息丢失对整体识别结果的影响。通过在AR和Yale人脸数据库上进行仿真实验，可以得出该改进算法能显著提高遮挡人脸图像的识别率，并且对光照变化也具有一定的鲁棒性。 In order to reduce the sensitivity of the face recognition algorithm to occlusion, a robust occlusion block sparse representation classification face recognition algorithm is proposed. The sparse representation algorithm uses the sparsity of high-dimensional data distribution to perform modeling, which can deal with high-dimensional image and effectively avoid dimension disaster. Block thinking is introduced in this algorithm. First of all, face image is divided into blocks which are independently sparse representation classification, and then a joint determination by all classification sub-blocks. The improved algorithm not only avoids the image feature extraction process information loss caused, but also avoids the loss of face parts information on the overall recognition results. Through simulation experiments on AR and Yale face database, it can be drawn that the improved algorithm can significantly improve the recognition rate of occluded face image, and also have some certain robustness under variable illumination.
    
  
 
</p></abstract><kwd-group><kwd>稀疏表示，人脸识别，分块，遮挡, Sparse Representation</kwd><kwd> Face Recognition</kwd><kwd> Block</kwd><kwd> Occlusion</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>分块稀疏表示的人脸识别研究<sup> </sup></title><p>路杨，康瑞梅，张芳君</p><p>河南大学计算机与信息工程学院，河南 开封</p><disp-formula id="hanspub.18801-formula104"><graphic xlink:href="http://html.hanspub.org/file/3-2690232x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>收稿日期：2016年10月7日；录用日期：2016年10月21日；发布日期：2016年10月27日</p><disp-formula id="hanspub.18801-formula105"><graphic xlink:href="http://html.hanspub.org/file/3-2690232x7_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>针对人脸识别中人脸被局部遮挡对识别效果带来的严重影响，提出一种对遮挡具有鲁棒性的分块稀疏表示分类的人脸识别算法。稀疏表示分类算法利用高维数据分布的稀疏性进行建模，能够很好地解决图像高维处理问题，有效地避免维数灾难。通过对该算法进行改进，提出一种分块稀疏表示的人脸识别算法。首先对人脸图像进行分割，独立地对每个子块进行稀疏表示分类，再通过所有子块的分类结果进行联合判别。改进后的算法避免了特征提取过程中所造成的图像信息丢失，也避免了人脸部分信息丢失对整体识别结果的影响。通过在AR和Yale人脸数据库上进行仿真实验，可以得出该改进算法能显著提高遮挡人脸图像的识别率，并且对光照变化也具有一定的鲁棒性。</p><p>关键词 :稀疏表示，人脸识别，分块，遮挡</p><disp-formula id="hanspub.18801-formula106"><graphic xlink:href="http://html.hanspub.org/file/3-2690232x8_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s3"><title>1. 引言</title><p>人脸识别因其易于使用、难仿冒、稳定性高、精确度高等特点，在越来越多的领域得到广泛使用。在理想条件的实验中，人脸识别系统已经能够得到比较令人满意的结果，但在实际的应用中，面向户外复杂场景的人脸识别技术还远未成熟，存在大量的问题亟待解决 [<xref ref-type="bibr" rid="hanspub.18801-ref1">1</xref>] ，例如表情、光照、旋转、伪装等。相对于表情、旋转等因素的影响，遮挡因素因其会造成人脸特征的局部缺失，成为人脸识别过程中急需处理的一个难题 [<xref ref-type="bibr" rid="hanspub.18801-ref2">2</xref>] 。</p><p>近年来，研究人员提出了多种解决人脸识别中处理遮挡问题的有效算法。例如遮挡区域的恢复算法，该方法首先判断出图像的遮挡类型，即遮挡区域，然后利用一定的算法对遮挡区域进行消除实现人脸重建，主要方法为主成分分析(principle component analysis, PCA)及一系列在此基础上的改进方法。Wu等人 [<xref ref-type="bibr" rid="hanspub.18801-ref3">3</xref>] 使用张量PCA重建超分辨率的人脸或被遮挡的人脸，可以在一个较小的参数空间保持较多的信息量。王志明等 [<xref ref-type="bibr" rid="hanspub.18801-ref4">4</xref>] 提出一种基于模糊PCA的人脸遮挡检测与去除方法，将遮挡人脸投影到特征脸空间并通过特征脸的线性组合得到一个重建人脸。但是当遮挡区域与训练库中的人脸图像有较大的差异时，人脸重建会造成较大的误差，影响判别结果。</p><p>随着压缩感知理论 [<xref ref-type="bibr" rid="hanspub.18801-ref5">5</xref>] 的兴起，基于稀疏编码模型的人脸识别方法得到了国内外学者的广泛关注，该算法认为一张测试人脸图像可以表示为训练样本的线性组合，它的系数是稀疏的。稀疏编码通过求解测试向量在训练向量上的最稀疏表示，得到高鲁棒性、低误差率的识别结果 [<xref ref-type="bibr" rid="hanspub.18801-ref6">6</xref>] 。Wright等 [<xref ref-type="bibr" rid="hanspub.18801-ref7">7</xref>] 提出的基于压缩感知理论的稀疏表示分类算法(sparse representation classification, SRC)，在稀疏分解字典中引入了遮挡字典，使其对遮挡图像有了较好的鲁棒性。但是，该遮挡字典是单位矩阵，维数常比训练样本字典的高，增加了稀疏分解耗时，并且由于其没有冗余度，也在一定程度上削弱了SRC算法的分类优势 [<xref ref-type="bibr" rid="hanspub.18801-ref8">8</xref>] 。</p><p>本文提出了一种基于分块稀疏表示的人脸识别方法，该方法在提高识别率的同时也解决了维数灾难问题。首先对人脸图像进行分割，独立地对每个子块进行稀疏表示分类，再通过对所有子块的分类结果进行投票确定测试人脸的类别。</p></sec><sec id="s4"><title>2. SRC算法</title><p>稀疏编码(sparse coding, SC)可以自动从没有标签的数据中发现显著基向量，然后利用基函数对输入图像进行编码表示 [<xref ref-type="bibr" rid="hanspub.18801-ref9">9</xref>] 。SRC的基本思想是首先对已知类别的训练图像经过处理后形成基底矩阵，即特征空间，再将待测样本用以该类样本为基矢量构成的过完备字典稀疏编码表示，之后计算各类训练样本预测该测试样本形成的残差，残差最小的那一类即为测试图像所属类别。</p><p>假设样本集中有M类人脸图像，每类由N幅图像组成，则共<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2690232x9_hanspub.png" xlink:type="simple"/></inline-formula>幅图像，每幅人脸图像处理后由m个像素组成，表示为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2690232x10_hanspub.png" xlink:type="simple"/></inline-formula>维列向量。设这个样本集合为D，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2690232x11_hanspub.png" xlink:type="simple"/></inline-formula>，其中D<sub>i</sub> (<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2690232x12_hanspub.png" xlink:type="simple"/></inline-formula>)表示第i个人的图像集合，又<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2690232x13_hanspub.png" xlink:type="simple"/></inline-formula>，其中D<sub>ij</sub>表示第i类人的第j张图像，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2690232x14_hanspub.png" xlink:type="simple"/></inline-formula>。当测试图像<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2690232x15_hanspub.png" xlink:type="simple"/></inline-formula>属于第i类时，则y可以由D<sub>i</sub>线性表示：</p><disp-formula id="hanspub.18801-formula107"><label>(1)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/3-2690232x16_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2690232x17_hanspub.png" xlink:type="simple"/></inline-formula>是对应于<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2690232x18_hanspub.png" xlink:type="simple"/></inline-formula>的系数。由于待测样本y的类别是未知的，所以不能用某一类图像数据作为基底，我们利用所有m类的人脸训练图像串连在一起，形成一个新的训练集矩阵A，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2690232x19_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2690232x20_hanspub.png" xlink:type="simple"/></inline-formula>。那么待测向量y就可以表示为所有训练向量的线性组合，即</p><disp-formula id="hanspub.18801-formula108"><label>(2)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/3-2690232x21_hanspub.png"  xlink:type="simple"/></disp-formula><p>理想情况下，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2690232x22_hanspub.png" xlink:type="simple"/></inline-formula>，即x为一个稀疏向量,只有测试图像所属于的那一类基底的系数不为零，其余的系数均为零。系数求出后，计算由各类训练样本预测该测试样本形成的残差，即</p><disp-formula id="hanspub.18801-formula109"><label>(3)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/3-2690232x23_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2690232x24_hanspub.png" xlink:type="simple"/></inline-formula>为提取的属于第i类样本的系数向量。最后，依据最小残差的判别准则，得出图像识别结果，即</p><disp-formula id="hanspub.18801-formula110"><label>(4)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/3-2690232x25_hanspub.png"  xlink:type="simple"/></disp-formula><p>可以看出，向量x中的非零项决定了测试样本的所属类别。因此，在y和A已知的情况下，求解向量x成为解决问题的关键。因为人脸识别处理的是小样本问题，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2690232x26_hanspub.png" xlink:type="simple"/></inline-formula>，因而式(2)通常是欠定的，x有多个解。文献 [<xref ref-type="bibr" rid="hanspub.18801-ref10">10</xref>] 表明，若x足够稀疏，则式(2)的求解可以转换为l1范数最小化问题：</p><disp-formula id="hanspub.18801-formula111"><label>(5)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/3-2690232x27_hanspub.png"  xlink:type="simple"/></disp-formula><p>对于公式(5)可以采用多种方法求解 [<xref ref-type="bibr" rid="hanspub.18801-ref11">11</xref>] ，得到待测图像的稀疏解后，就可以对测试图像进行判别归类。</p></sec><sec id="s5"><title>3. 分块SRC算法</title><p>对于遮挡的人脸图像，SRC算法的识别率并不高，但是若想应用到现实生活中，必须提高对遮挡图像的识别率。由于遮挡的连续性，遮挡部分会聚集在某一片区域，更多的部分是清晰的。我们提出一种分块的SRC算法，分块处理使用各个子模块进行联合判别来代替传统的使用整个人脸图像进行分类,减少人脸部分信息丢失对整体识别带来的不利影响。算法首先将所有样本图像按照一定的分块方式进行分块，然后分别对每一子块进行基于稀疏表示的分类，如图1所示，最终通过对所有子块的联合判别得出最终的分类结果。具体算法流程如下：</p><p>① 训练和测试人脸图像按照相同的分块方式进行均匀分块；</p><p>② 将每一子块降采样为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2690232x28_hanspub.png" xlink:type="simple"/></inline-formula>，然后将子块的所有列串联为一个列向量<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2690232x29_hanspub.png" xlink:type="simple"/></inline-formula>作为该子块的特征向量。按照这种方式处理所有训练图像，则每一子块都可以形成一个过完备词典矩阵A<sub>b</sub>；</p><p>③ 第一个子块对应的过完备词典建立后，测试图片Y的第一个子块降采样得到该子块的特征向量<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2690232x30_hanspub.png" xlink:type="simple"/></inline-formula>，然后求解Y<sub>b</sub>的稀疏表达式，比较得到的子块残差r<sub>k</sub>对子块进行判别分类，并计算最小残差r<sub>1</sub>和次最小残差r<sub>2</sub>的比值<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2690232x31_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2690232x32_hanspub.png" xlink:type="simple"/></inline-formula>。对Y的剩余子块重复该步骤；</p><p>图1. 基于分块稀疏表示的分类示例</p><p>④ 将所有子块所得类别结果和所求残差比值结果分别以向量形式保存；</p><p>⑤ 统计测试图片Y中所有子块所属类别，按照“少数服从多数”准则进行判断，即类别数量最多的为Y的识别结果；若有两个或两个以上类别数量相同或者所有子块均属于不同类时，则将具有最大残差比值的那一子块所属类别确定为测试图片所属类别。</p><p>我们之所以在有两个或两个以上类别数量相同或者所有子块均属于不同类时选用最大残差比值<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2690232x34_hanspub.png" xlink:type="simple"/></inline-formula>作为判别依据，是因为从图1可以看出，Y1和Y2子块有遮挡，人脸特征不明显时，其对应的残差值相对于特征明显的Y3和Y4子块略大，而对应的<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2690232x35_hanspub.png" xlink:type="simple"/></inline-formula>值则略小。由此可见，若<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/3-2690232x36_hanspub.png" xlink:type="simple"/></inline-formula>值大，则代表这一子块特征明显，可以在特殊情况下决定整幅图像所属类别。</p></sec><sec id="s6"><title>4. 实验结果与分析</title><p>本文选择目前比较常用的AR和Extended Yale B人脸数据库作为实验数据集，对算法的有效性进行验证。Extended Yale B人脸数据库采集了38个人在不同光照条件下的共2432张人脸图像，并经过统一裁剪，分辨率为192 168。AR人脸数据库采集了126人在不同光照、遮挡和表情变化下超过4000张正面人脸图像，每个图像已经裁剪为165 120大小，并转换为灰度图。</p><sec id="s6_1"><title>4.1. Extended Yale B人脸库实验结果</title><p>本实验主要研究在人脸上具有不同大小遮挡面积时，原始SRC方法与本文方法的识别效果对比。从Extended Yale B人脸数据库随机抽取每个人的50 张图片作为训练样本集，另外10张作为测试样本集。对测试样本进行人工模拟遮挡面积为10%、20%、30%、40%、50%，如图2所示。</p><p>人脸图在对图像进行分块时，分块数过多时，会增加算法的复杂度，但过少又会降低算法的抗遮挡能力，经过多次实验，我们验证了当分块方式为4 &#215; 3时，算法可以得到最好的识别性能。原始SRC方法与本文方法在不同遮挡面积下的识别率对比如图3所示(识别率为126人实验结果的平均值)。</p></sec><sec id="s6_2"><title>4.2. AR人脸库实验结果</title><p>本试验主要研究分块方式及分辨率大小对识别率和识别时间的影响。在试验中我们抽取了100个人共1000幅图像，每人10张图像，前8张非遮挡图像作为训练样本集，后2张主要为具有遮挡的人脸图像作为测试样本集，其中男女比例各占一半。图4为不同分辨率与分块方式对识别率(100人仿真结果平均值)的影响，图5展示了不同分辨率与分块方式对识别时间的影响。本文算法与NN [<xref ref-type="bibr" rid="hanspub.18801-ref12">12</xref>] 、SRC [<xref ref-type="bibr" rid="hanspub.18801-ref13">13</xref>] 、P + V + SRC [<xref ref-type="bibr" rid="hanspub.18801-ref14">14</xref>] 方法在AR数据库中的识别率对比结果如表1所示。可以看出，在相同分辨率下，本文算法识别率有明显提升。</p><p>图2. 不同遮挡面积</p><p>图3. SRC与本文算法在不同遮挡面积下识别率对比</p><p>图4. 不同分辨率与分块方式下算法识别率对比</p><p>图5. 不同分辨率与分块方式对算法识别时间的影响</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> The recognition rate comparison about different algorith</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >分辨率 方法</th><th align="center" valign="middle" >20*30</th><th align="center" valign="middle" >30*30</th><th align="center" valign="middle" >40*30</th></tr></thead><tr><td align="center" valign="middle" >NN</td><td align="center" valign="middle" >72.9%</td><td align="center" valign="middle" >76.2%</td><td align="center" valign="middle" >79.8%</td></tr><tr><td align="center" valign="middle" >SRC</td><td align="center" valign="middle" >81.4%</td><td align="center" valign="middle" >87.0%</td><td align="center" valign="middle" >88.3%</td></tr><tr><td align="center" valign="middle" >P + V + SRC</td><td align="center" valign="middle" >90.3%</td><td align="center" valign="middle" >89.5%</td><td align="center" valign="middle" >92.1%</td></tr><tr><td align="center" valign="middle" >本文算法</td><td align="center" valign="middle" >92.5%</td><td align="center" valign="middle" >99.0%</td><td align="center" valign="middle" >98.0%</td></tr></tbody></table></table-wrap><p>表1. 几种算法在遮挡人脸上的识别率对比</p></sec><sec id="s6_3"><title>4.3. 实验结果分析</title><p>从图3中可以看出，改进后的方法相对于原始方法，抗遮挡能力更强，在遮挡图像中的识别率有显著提高。图4和图5表明，当子块数过少时，识别率低，算法的抗遮挡能力不强，随着子块的不断增加，识别率成上升状态，但当增加到一定数目时，识别率不再上升，而识别时间却持续增长。事实上，分块过多时还会破坏图像的特征信息导致识别率的下降。同样地，当图像降采样的分辨率过小时，会丢失很多有用的图像信息，使图像的识别能力变弱。在遮挡图像中，分块方式不同时，子块像素越接近正方形，图像的识别率越高。通过对图4和图5分析，可以得出，当分块数为12块，下采样为30 &#215; 30时，识别率达到98%且识别时间较短，算法的综合性能达到最优。</p></sec></sec><sec id="s7"><title>5. 结束语</title><p>本文提出了一种遮挡鲁棒的分块稀疏表示人脸识别算法，通过对各个子模块联合判别来代替传统的使用整个人脸图像进行分类。对图像进行分块后，词典矩阵变得更扁平，系数更稀疏，识别性能更好，并详细讨论了人脸图像在不同像素和不同分块方式下识别率及识别时间问题。</p><p>在以后的工作中，可以继续探讨人脸的不同部位(如眼睛、鼻子等)对人脸识别的贡献率，根据贡献率的大小对不同的子块设置不同的权重使识别性能得到综合性提升。</p></sec><sec id="s8"><title>基金项目</title><p>河南省基础与前沿项目(No.162300410196)。</p></sec><sec id="s9"><title>文章引用</title><p>路 杨,康瑞梅,张芳君. 分块稀疏表示的人脸识别研究Face Recognition Research Based on Sparse Representation of Blocks[J]. 软件工程与应用, 2016, 05(05): 277-284. http://dx.doi.org/10.12677/SEA.2016.55032</p></sec><sec id="s10"><title>参考文献 (References)</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.18801-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Hua, G., Yang, M.H., Learnedmiller, E., et al. (2011) Introduction to the Special Section, on Real-World Face Recognition. IEEE Transactions on Pattern Analysis &amp; Machine Intelligence, 33, 1921-1924.  
&lt;br&gt;http://dx.doi.org/10.1109/TPAMI.2011.182</mixed-citation></ref><ref id="hanspub.18801-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">林玲. 基于部分遮挡人脸识别算法的研究[J]. 计算机仿真, 2012, 29(1): 231-233.</mixed-citation></ref><ref id="hanspub.18801-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Wu, J. and Trivedi, M.M. (2006) A Regression Model in Tensor PCA Subspace for Face Image Super-Resolution Reconstruction. 18th International Conference on Pattern Recognition, Hong Kong, 20-24 August 2006, 627-630.</mixed-citation></ref><ref id="hanspub.18801-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">王志明, 陶建华. 人脸遮挡区域检测与重建[J]. 計算機研究與發展,2010,47(1):16-22.</mixed-citation></ref><ref id="hanspub.18801-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Vo, N., Vo, D., Challa, S., et al. (2009) Compressed Sensing for Face Recognition. IEEE Symposium on Computational Intelligence for Image Processing, Nashville, 30 March-2 April 2009, 104-109.  
&lt;br&gt;http://dx.doi.org/10.1109/ciip.2009.4937888</mixed-citation></ref><ref id="hanspub.18801-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Wagner, A., Wright, J., Ganesh, A., et al. (2012) Toward a Practical Face Recognition System: Robust Alignment and Illumination by Sparse Representation. IEEE Transactions on Pattern Analysis &amp; Machine Intelligence, 34, 372-386.  
&lt;br&gt;http://dx.doi.org/10.1109/TPAMI.2011.112</mixed-citation></ref><ref id="hanspub.18801-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Wright, J., Yang, A.Y., Ganesh, A., et al. (2008) Robust Face Recognition via Sparse Representation. IEEE Transactions on Pattern Analysis &amp; Machine Intelligence, 31, 2368-2378. &lt;br&gt;http://dx.doi.org/10.1109/afgr.2008.4813404</mixed-citation></ref><ref id="hanspub.18801-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">朱明旱, 李树涛, 叶华. 稀疏表示分类中遮挡字典构造方法的改进[J]. 计算机辅助设计与图形学学报, 2014(11): 2064-2069.</mixed-citation></ref><ref id="hanspub.18801-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Yang, J., Yu, K., Gong, Y., et al. (2009) Linear Spatial Pyramid Matching Using Sparse Coding for Image Classification. Computer Vision and Pattern Recognition, Miami, 1794-1801.</mixed-citation></ref><ref id="hanspub.18801-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Candè, E.J. and Wakin, M.B. (2008) An Introduction to Compressive Sampling. IEEE Signal Processing Magazine, 25, 21-30. &lt;br&gt;http://dx.doi.org/10.1109/MSP.2007.914731</mixed-citation></ref><ref id="hanspub.18801-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Yang, A.Y., Zhou, Z., Balasubramanian, A.G., et al. (2013) Fast-Minimization Algorithms for Robust Face Recognition. IEEE Transactions on Image Processing, 22, 3234-3246. &lt;br&gt;http://dx.doi.org/10.1109/TIP.2013.2262292</mixed-citation></ref><ref id="hanspub.18801-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Wang, X.Z., Yan, L.I., Guo, L.H., et al. (2009) Face Recognition Algorithm Based on BD-PCA and K-NN. Journal of Wuhan University of Technology, 40-41, 130-133.</mixed-citation></ref><ref id="hanspub.18801-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Liang, S., Wang, Y. and Liu, Y. (2012) Face Recognition Algorithm Based on Compressive Sensing and SRC. Second International Conference on Instrumentation, Measurement, Computer, Communication and Control, 1460-1463.  
&lt;br&gt;http://dx.doi.org/10.1109/IMCCC.2012.342</mixed-citation></ref><ref id="hanspub.18801-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">Deng, W., Hu, J. and Guo, J. (2013) In Defense of Sparsity Based Face Recognition. IEEE Conference on Computer Vision and Pattern Recognition. 2013 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Portland, 23-28 June 2013, 399-406. &lt;br&gt;http://dx.doi.org/10.1109/CVPR.2013.58</mixed-citation></ref></ref-list></back></article>