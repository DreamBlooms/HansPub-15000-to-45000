<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2021.116185</article-id><article-id pub-id-type="publisher-id">CSA-43540</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20210600000_94225715.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  一种基于改进3D卷积的乒乓球球员动作识别算法
  A Recognition Algorithm of Player Motion of Table Tennis Based on Improved 3D Convolution
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>汪</surname><given-names>语哲</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>刘</surname><given-names>明方</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>尹</surname><given-names>真杰</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>段</surname><given-names>晓东</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>大连民族大学大数据应用技术国家民委重点实验室，辽宁 大连;大连民族大学大连市民族文化数字技术重点实验室，辽宁 大连;大连民族大学机电工程学院，辽宁 大连</addr-line></aff><aff id="aff3"><addr-line>大连民族大学大数据应用技术国家民委重点实验室，辽宁 大连;大连民族大学大连市民族文化数字技术重点实验室，辽宁 大连;大连民族大学计算机科学与工程学院，辽宁 大连</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>02</day><month>06</month><year>2021</year></pub-date><volume>11</volume><issue>06</issue><fpage>1791</fpage><lpage>1801</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   文章研究了基于视频的乒乓球球员动作识别问题。在计算机视觉领域，人体动作识别具有一定挑战性。基于专业乒乓球运动员在乒乓球发球机的接发动作视频，构建了乒乓球击球动作视频数据集，将其分为正手击球、反手击球、正手拉球、反手拉球和非击球动作5类。提出通过人体密集姿态(Dense Pose)处理数据集，将把人体形态从环境中进行提取，随后提出一种改进的C3D卷积网络，用于学习数据集上连续帧的时空特征。结果表明，文章设计的算法对于光线、环境等干扰因素具有较好的鲁棒性，泛化性能好，为基于视频的动作分类识别问题提出了一种可行解决方案。 Motion recognition of table tennis players based on video is studied in this paper. Recognition of human action is challenging in the field of computer vision. Based on videos of ball strike of professional table tennis players against table tennis ball machine, a data set of ball strike of table tennis players is constructed and divided into 5 catalogs of forehand shots, backhand shots, forehand shots, backhand shots and non-stike action. Dense pose of the human body is used to process the constructed data set and extract human body shape from the environment, and then an improved C3D convolutional network is proposed to learn the spatiotemporal features of continuous frames on the data set. Results show that the algorithm proposed in the article has good robustness to interference factors such as light and environment, and good generalization performance, demonstrating a feasible solution to the problem of video-based action classification and recognition. 
  
 
</p></abstract><kwd-group><kwd>乒乓球击球，人体动作识别，3D卷积网络，动作分类，视频跟踪, Striking of Table Tennis</kwd><kwd> Human Action Recognition</kwd><kwd> 3D Convolutional Network</kwd><kwd> Action Classification</kwd><kwd> Video Tracking</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>摘要</title><p>文章研究了基于视频的乒乓球球员动作识别问题。在计算机视觉领域，人体动作识别具有一定挑战性。基于专业乒乓球运动员在乒乓球发球机的接发动作视频，构建了乒乓球击球动作视频数据集，将其分为正手击球、反手击球、正手拉球、反手拉球和非击球动作5类。提出通过人体密集姿态(Dense Pose)处理数据集，将把人体形态从环境中进行提取，随后提出一种改进的C3D卷积网络，用于学习数据集上连续帧的时空特征。结果表明，文章设计的算法对于光线、环境等干扰因素具有较好的鲁棒性，泛化性能好，为基于视频的动作分类识别问题提出了一种可行解决方案。</p></sec><sec id="s2"><title>关键词</title><p>乒乓球击球，人体动作识别，3D卷积网络，动作分类，视频跟踪</p></sec><sec id="s3"><title>A Recognition Algorithm of Player Motion of <xref ref-type="table" rid="table">Table </xref>Tennis Based on Improved 3D Convolution<sup> </sup></title><p>Yuzhe Wang<sup>1,2,3</sup>, Mingfang Liu<sup>1,2,4</sup>, Zhenjie Yin<sup>1,2,4</sup>, Xiaodong Duan<sup>1,2,4</sup></p><p><sup>1</sup>SEAC Key Laboratory of Big Data Applied Technology, Dalian Minzu University, Dalian Liaoning</p><p><sup>2</sup>Dalian Key Lab of Digital Technology for National Culture, Dalian Minzu University, Dalian Liaoning</p><p><sup>3</sup>College of Mechanical and Electronic Engineering, Dalian Minzu University, Dalian Liaoning</p><p><sup>4</sup>College of Computer Science and Engineering, Dalian Minzu University, Dalian Liaoning</p><p><img src="//html.hanspub.org/file/20-1542196x4_hanspub.png" /></p><p>Received: May 26<sup>th</sup>, 2021; accepted: Jun. 21<sup>st</sup>, 2021; published: Jun. 28<sup>th</sup>, 2021</p><p><img src="//html.hanspub.org/file/20-1542196x5_hanspub.png" /></p></sec><sec id="s4"><title>ABSTRACT</title><p>Motion recognition of table tennis players based on video is studied in this paper. Recognition of human action is challenging in the field of computer vision. Based on videos of ball strike of professional table tennis players against table tennis ball machine, a data set of ball strike of table tennis players is constructed and divided into 5 catalogs of forehand shots, backhand shots, forehand shots, backhand shots and non-stike action. Dense pose of the human body is used to process the constructed data set and extract human body shape from the environment, and then an improved C3D convolutional network is proposed to learn the spatiotemporal features of continuous frames on the data set. Results show that the algorithm proposed in the article has good robustness to interference factors such as light and environment, and good generalization performance, demonstrating a feasible solution to the problem of video-based action classification and recognition.</p><p>Keywords:Striking of <xref ref-type="table" rid="table">Table </xref>Tennis, Human Action Recognition, 3D Convolutional Network, Action Classification, Video Tracking</p><disp-formula id="hanspub.43540-formula24"><graphic xlink:href="//html.hanspub.org/file/20-1542196x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2021 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/20-1542196x7_hanspub.png" /> <img src="//html.hanspub.org/file/20-1542196x8_hanspub.png" /></p></sec><sec id="s5"><title>1. 引言</title><p>乒乓球被誉为我国的国球，其易于开展，参与性强，普及度高，得到了国内各年龄段人员的普遍喜爱。随着科技的高速发展，计算机技术已成为提升运动竞技水平的重要工具，带有智能功能的比赛记录和分析装置已在训练和比赛中得到了初步应用。王恺凡等人基于卷积神经网络开发了一款乒乓球训练平台，将人脸识别、人体骨骼识别和心率检测功能进行了整合，提升了训练效果 [<xref ref-type="bibr" rid="hanspub.43540-ref1">1</xref>]。丁朔等人融合语音交互与自然语言处理技术，设计了一款乒乓球智能训练系统，辅助教练员制定训练计划，并对错误的动作给予视频纠正指导 [<xref ref-type="bibr" rid="hanspub.43540-ref2">2</xref>]。杨波等人将VR (Virtual Reality，虚拟现实)技术引入高等院校的乒乓球课堂教学，将其整合融入既有课程，提升了教学效果 [<xref ref-type="bibr" rid="hanspub.43540-ref3">3</xref>]。任云青等人采用ROS (Robot Operating System，机器人操作系统)、OpenCV (Open Source Computer Vision Library，开源计算机视觉库)等软件，设计并实现了一款智能乒乓球自动捡球机器人，实现了乒乓球智能识别、分拣与运输等功能 [<xref ref-type="bibr" rid="hanspub.43540-ref4">4</xref>]。</p><p>在以乒乓球运动为代表的对抗性球类项目的球员技术动作识别与分析方面，基于机器视觉的人体动作识别技术近来得到了普遍关注。孙于成等使用时空图卷积在其自建的乒乓球骨骼数据集上实现了击球动作的研究 [<xref ref-type="bibr" rid="hanspub.43540-ref5">5</xref>]。Martin等提出的双时空卷积神经网络(TSTCNN)在MediaEval 2020“运动视频分类：乒乓球的动作分类”比赛中取得了优异的成绩 [<xref ref-type="bibr" rid="hanspub.43540-ref6">6</xref>]。杨静等基于支持向量机(SVM)和光流分析，提出了一种识别体育视频中羽毛球运动员运动的方法 [<xref ref-type="bibr" rid="hanspub.43540-ref7">7</xref>]。Nur Azmina Rahmad等在其自建的羽毛球比赛数据集中对AlexNet，GoogleNet，VggNet-16和VggNet-19四种卷积神经网络的模型分类性能进行了比较 [<xref ref-type="bibr" rid="hanspub.43540-ref8">8</xref>]。Piergiovanni等构建了MLB-YouTube棒球比赛运动数据集，并用3D卷积网络的方法对数据集细粒度活动进行识别 [<xref ref-type="bibr" rid="hanspub.43540-ref9">9</xref>]。</p><p>然而上述动作识别算法研究均基于公开或非公开球员间比赛的视频数据集，在疫情常态化的新形势下，发球机已成为训练的重要组成部分，发球机发球速度、力量和旋转方式和球员回球有较大差异，而关于球员在乒乓球发球机上的回球动作识别相关研究目前比较罕见。为提升乒乓球发球机的训练质量，课题组邀请专业乒乓球队员进行标注技术动作采集，通过60 fps深度摄像机采集专业运动员接发球动作，建立了发球机接发球标准动作数据集，随后通过密集姿态(Dense Pose)技术去除环境、衣服、肤色等影响因素，最后对C3D网络 [<xref ref-type="bibr" rid="hanspub.43540-ref10">10</xref>] 改进并训练数据，完成对乒乓球击球动作的识别，整个项目的实验过程如图1所示。</p><p>图1. 乒乓球击球动作识别算法流程图</p></sec><sec id="s6"><title>2. 视频数据集构建</title><sec id="s6_1"><title>2.1. 数据采集环境搭建</title><p>选取市场上主流的乒乓球发球机(双鱼1040)进行接发球训练。该设备在出球口设置了胶皮擦球装置，能够通过胶皮摩擦发出上旋、下旋转和侧旋球；同能够调整发球速度、角度、频率，可以满足接发球技术动作训练要求。</p><p>视频采集设备为ZED双目深度像机，参数调整为：分辨率720像素、帧率60 fps。为了保证采集到的运动视频不会出现丢帧和跳帧等问题，在数据采集时对连接摄像机的电脑硬件设备进行了调整。整体采集设备硬件如图2所示。</p><p>图2. 数据采集设备</p></sec><sec id="s6_2"><title>2.2. 数据集搭建</title><p>目前乒乓球接发球主流的技术动作可分为正反手拉球、正反手攻球、正反手搓球、正反手削球等几类，目前这些技术动作尚无准确的动作集标准，然而统计分析表明，多数高水平运动员在乒乓球发球机上的接发球动作有较大相似性，因此选择邀请高水乒乓球球员动员录制接发球视频，将他们的击球动作作为标准数据集。</p><p>香港中文大学研究者于2020年构建了一个大规模体操运动人体动作数据集：FineGym [<xref ref-type="bibr" rid="hanspub.43540-ref11">11</xref>]，数据集通过层级化标注对动作的细粒度进行了区分，最细划分到一个具体的体操动作，例如平衡木体操下马动作中的团身前空翻动作。文章根据此数据所划分的细粒度动作，构建了乒乓球击球动作数据集。</p><p>乒乓球击球动握拍方式大致可以分为横拍和直拍两种，通过分析视频中的连续帧发现，直拍中有些击球动作轨迹相似，例如正手攻球和正手拉球在即将击球的瞬间的连续2~3帧动作相似，反手攻球和反手拉球在准备接球和击球的瞬间都有1~3帧的动作相似，这也是击球动作中区分的难点，击球动作相似和动作差异如图3所示。因此，在采集数据和做动作区分时，选择了对正手攻球、正手拉球、反手攻球、反手拉球的动作进行采集。采集的数据集中，击球动作之外的动作将其称为其他动作，对4类击球动作和1类其他动作进行识别，以便于模型更好区分击球动作。</p><p>图3. 击球动作中的相似动作：(a1)和(b1)为正手击球和正手拉球过程中相似动作的某一帧；(a2)和(b2)为正手击球和正手拉球过程中动作区别的某一帧；(c1)和(d1)为反手击球和反手拉球过程中的相似动作的某一帧</p></sec></sec><sec id="s7"><title>3. 数据集处理</title><sec id="s7_1"><title>3.1. 数据预处理</title><p>对所采集的乒乓球击球视频进行处理。由于在乒乓球运动中，击球是一个快速动作，直接给视频数据设置标签不仅比较困难，而且标签所在的时间段也存在其他动作的干扰。</p><p>通过将乒乓球击球视频的每一帧提出来，经过研究对比发现，每种击球动基本在16~24帧内完成击球，因此将完全包含一个击球动作的16~24帧的连续帧进行提取，形成一个击球动作的时空特征数据；非击球动作一般在48个连续帧左右之内，将提取非击球动作的48个连续帧，形成一个非击球动作的时空特征数据。经过手工提取数据后，数据集包括了824个动作，将近20,000帧图片，5类动作每类包含150左右个动作连续帧的时空特征数据。表1完整的显示了动作类别和动作数量。为了便于训练、Dense Pose处理数据和设置动作标签，设置了五个文件夹，其名字作为应五个动作类的标签，既Facade Attack (正手攻球)、Facade Pull (正手拉球)、Back Attack (反手攻球)、Facade Attack (反手拉球)和Other Action (非击球动作)五类运动标签。每个标签文件夹中的每一个子文件夹都代表一个动作，每个动作由连续帧组成。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table">Table </xref>1</label><caption><title> Data set of action category and number of action</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >击球动作</th><th align="center" valign="middle" >动作样本数量</th></tr></thead><tr><td align="center" valign="middle" >正手击球</td><td align="center" valign="middle" >179</td></tr><tr><td align="center" valign="middle" >正手拉球</td><td align="center" valign="middle" >122</td></tr><tr><td align="center" valign="middle" >反手击球</td><td align="center" valign="middle" >206</td></tr><tr><td align="center" valign="middle" >反手拉球</td><td align="center" valign="middle" >158</td></tr><tr><td align="center" valign="middle" >其他动作</td><td align="center" valign="middle" >159</td></tr></tbody></table></table-wrap><p>表1. 数据集动作类别和动作数量</p></sec><sec id="s7_2"><title>3.2. Dense Pose处理数据集</title><p>2018年Facebook [<xref ref-type="bibr" rid="hanspub.43540-ref12">12</xref>] 和Inria France [<xref ref-type="bibr" rid="hanspub.43540-ref13">13</xref>] 的研究者分别在ECCV会议和CVPR会议发表了篇有关于Dense Pose的文章，介绍了他们提出的Dense Pose系统 [<xref ref-type="bibr" rid="hanspub.43540-ref14">14</xref>]。在Dense Pose系统中的密集姿态估计(Dense Pose Estimation)功能 [<xref ref-type="bibr" rid="hanspub.43540-ref11">11</xref>] 可以将2D人体映射到3D的人体表面，在图4中展示了2D到3D的转换。这种2D映射到3D转换的过程并不会改变图像的大小，所映射的3D人体表面在图像中分成了24份，每一份的中的颜色值存在偏差，并且此功能可去除图像中的背景干扰，如图4所示。</p><p>图4. Dense Pose系统密集姿态估计处理图像</p><p>通过Dense Pose系统中的密集姿态估计功能，对手工处理后的数据集中动作帧图像进行处理，把2D人体映射到3D模型，经过此处理图片中的人体只有形态和动作，模型的泛化效果不会被人体的肤色和着装所影响。经过Dense Pose处理过的图像，动作识别中环境干扰因素都会被去除，模型泛化效果就不会受环境等因素所影响。图5介绍了未处理的数据对比经过处理后的击球部分连续动作帧。</p><p>图5. 未处理的数据对比Dense Pose处理后的击球部分连续动作帧</p></sec></sec><sec id="s8"><title>4. 网络模型搭建</title><sec id="s8_1"><title>4.1. 3D卷积网络</title><p>3D卷积也是从2D卷积的基础上发展而来的，基于2D卷积核的卷积网络 [<xref ref-type="bibr" rid="hanspub.43540-ref15">15</xref>] 可用于学习单通道或者三通道的图像的空间特征，图6中的图6(a)是2D卷积应用在三通道的图像卷积的结果，输入为w &#215; h &#215; c三个维度，表示图片的宽、高和通道数。2D卷积应用在学习单通道图像的特征时，除了输入维度少一个通道维度外，整个卷积过程与图6(a)三通道卷积过程相同。</p><p>相比于2D卷积核来说3D卷积核 [<xref ref-type="bibr" rid="hanspub.43540-ref10">10</xref>] 是多了一个维度去学习数据中的时间特征，如图6(b)输入为t &#215; w &#215; h &#215; c四个维度，其中t代表连续帧数目，t这一维度的特征就是数据时间维度上的特征。对于连续的单通道图像来说，输入的维度是t &#215; w &#215; h三个维度，整个卷积过程和图6(b)三通道图像卷积过程相同。</p><p>图6. 2D卷积过程与3D卷积过程的区别</p></sec><sec id="s8_2"><title>4.2. C3D网络结构改进</title><p>C3D网络是Du Tan (杜兰特)等人 [<xref ref-type="bibr" rid="hanspub.43540-ref10">10</xref>] 于2015年提出的一个用于学习和识别视频中信息的通用网络，其通过3D卷积网络去学习视频中的时空特征，学习所得到的模型可用于场景分类、动作识别等领域。C3D网络的训练所使用的数据集为UCF101数据集 [<xref ref-type="bibr" rid="hanspub.43540-ref16">16</xref>]，数据集由101个人类动作类别的13,320个视频组成，视频图像未经过处理，由于数据集种类多，视频图像中的特征复杂，因此C3D网络整体网络层次设计比较深，包含为8个卷积层、5个池化层、2个全连接层，整个网络的参数为6000万左右。在项目组自建的数据集中，数据经过处理后没有了环境、衣服、肤色等特征的影响，图像中只有人体形态，图像中的特征相对简单，为了防止出现过拟合现象，因此将C3D网络的整体结构缩减为5个卷积层、5个池化层、2个全连接层，并对特征图个数和神经元个数进行了缩减，最终网络参数降为500万左右。整个网络结构如图7。</p><p>图7. 改进后的C3D网络结构图</p><p>输入层(Input)：输入的数据为16个连续的视频帧，每一帧的宽高为112 &#215; 112，通道数为3，即输入维度为16 &#215; 112 &#215; 112 &#215; 3；</p><p>卷积层(Convolution)：5个卷积核的每一个卷积核维度为3 &#215; 3 &#215; 3，步长为1，并在卷积过程让其自动填充padding，保证卷积过程中输入和输出尺寸相同，在每个卷积过程结束后，使用ReLU激活函数。卷积计算公式如式(1)，其中W为帧的宽度，H为帧的高度，T为连续帧的时间维度，p为边界填充值，s为步长，为卷积核维度。</p><p>{ W o u t = W i n + 2 p − C W s + 1 H o u t = H i n + 2 p − C H s + 1 T o u t = T i n + 2 p − C T s + 1 (1)</p><p>池化层(Polling)：池化层使用的事最大值池化，为了在初始卷积池化阶段保留时间上的特征，保留了原网络的池化结构，在第一次池化时维度为1 &#215; 2 &#215; 2，步长为1 &#215; 2 &#215; 2，其他池化层的维度都为2 &#215; 2 &#215; 2，步长为2 [<xref ref-type="bibr" rid="hanspub.43540-ref6">6</xref>]；</p><p>全连接层(FC)：全连接层的神经元个数根据最后一次池化后特征图的大小设置为512个。经过前面卷积提取特征后，全连接层最终会将这些特征映射到标签空间，起到一个分类器的作用。</p><p>输出层(output)：根据数据集中5个类别的动作，网络最后的输出是判断的这五个类别的概率值。</p></sec></sec><sec id="s9"><title>5. 正文实验结果与分析</title><p>基于自建数据集训练乒乓球击球动作识别模型实验硬件环境为：处理器Intel(R) Core(TM) i7-7800X CPU @ 3.50 GHz 3.50 GHz和NVIDIA GeForce RTX 2080Ti GPU；模型泛化性能测试实验环境：硬件环境Intel(R) Xeon(R) E-2224 CPU @ 3.40 GHz 3.41 GHz和NVIDIA GeForce GTX 1650 GPU，DensePose系统不能再Windows系统上安装，所以系统环境为Ubuntu操作系统。</p><sec id="s9_1"><title>5.1. 模型训练实验结果分析</title><p>用于训练模型的训练集和验证集均来自于自建数据集，训练集和测试接的划分别为数据集的80%和20%。通过30次迭代训练，通过图8(a)可以看出在第18次迭代后训练集精准度稳定在99.5%，验证集精准度稳定在99.3%。通过图8(b)可以看出在第18次迭代后训练集损失函数值趋近于0，验证集损失函数值稳定在0.09以内。</p><p>图8. 训练集和验证集训练结果的准确率和损失函数值曲线</p></sec><sec id="s9_2"><title>5.2. 模型泛化效果预测</title><p>乒乓球击球动作识别模型泛化效果的好坏决定着这个模型是否具有实际应用价值，通过从网络上找到拍摄角度与课题组自建数据集中拍摄角度相似的乒乓球击球视频，整个视频经过Dense Pose系统处理后放入到模型中测试泛化效果。图9中的视频来源于视频网站与训练集中的数据不存在交集，并且图中为连续动作帧中提取出来图像。图9中，图9(a)预测结果为正手攻球，图9(b)预测结果为正手拉球，图9(c)预测为反手攻球，图9(d)预测为反手拉球，预测结果均与球员实际击球动作类型一致。通过泛化性能测试可以看出本文所提出的方法训练出来的动作识别模型泛化能力较强，有一定的实际应用价值。</p><p>图9. 乒乓球击球动作识别模型泛化性能测试</p></sec></sec><sec id="s10"><title>6. 结语</title><p>基于专业运动员在乒乓球发球机上的接发球视频，自建了包含五分类的乒乓球击球动作识别视频数据集，通过动作划分手工提取了连续击球动作视频帧，采用Dense Pose系统中的密集姿态估计功能对手工提取的视频帧进行了处理，最终通过改进C3D网络训练出了乒乓球击球动作识别模型。实验表明：模型训练时在第17次迭代之后训练精准度稳定在99.5%，验证集精准度稳定在99.3%，并且模型通过了泛化性能测试，证明文章提出的方法可以去除环境、衣服等因素的干扰，训练的乒乓球击球动作识别模型具有实际应用的价值。</p></sec><sec id="s11"><title>基金项目</title><p>大连市科技创新基金项目“面向足球青训的技战术分析算法及配套可穿戴设备研发”(项目编号：2020JJ26GX038)；大连民族大学学科团队项目“基于机器学习的乒乓球接发球动作识别与水平评估算法研究”。</p></sec><sec id="s12"><title>文章引用</title><p>汪语哲,刘明方,尹真杰,段晓东. 一种基于改进3D卷积的乒乓球球员动作识别算法A Recognition Algorithm of Player Motion of <xref ref-type="table" rid="table">Table </xref>Tennis Based on Improved 3D Convolution[J]. 计算机科学与应用, 2021, 11(06): 1791-1801. https://doi.org/10.12677/CSA.2021.116185</p></sec><sec id="s13"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.43540-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">王恺凡. 基于人脸识别的乒乓球智能训练平台设计[D]: [硕士学位论文]. 南京: 南京邮电大学, 2020.</mixed-citation></ref><ref id="hanspub.43540-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">丁朔. 基于智能语音交互的乒乓球训练系统的设计与实现[D]: [硕士学位论文]. 南京: 南京邮电大学, 2020.</mixed-citation></ref><ref id="hanspub.43540-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">杨波. 虚拟现实技术应用于高校乒乓球教学中的实证研究[D]: [硕士学位论文]. 兰州: 西北师范大学, 2020.</mixed-citation></ref><ref id="hanspub.43540-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">任云青. 智能乒乓球自动捡球机器人的设计与实现[D]: [硕士学位论文]. 南京: 南京邮电大学, 2020.</mixed-citation></ref><ref id="hanspub.43540-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">孙于成. 基于时空图卷积的乒乓球基础技术动作识别[D]: [硕士学位论文].安庆: 安庆师范大学, 2020.</mixed-citation></ref><ref id="hanspub.43540-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Martin, P.-E., Benois-Pineau, J., Péteri, R. and Morlier, J. (2020) 3D Attention Mechanism for Fine-Grained classification of table ten-nis strokes using a Twin Spatio-Temporal Convolutional Neural Networks. 25th International Conference on Pattern Recognition, Milano, January 2021. arXiv preprint arXiv:2012.05342.</mixed-citation></ref><ref id="hanspub.43540-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">杨静. 体育视频中羽毛球运动员的动作识别[J]. 自动化技术与应用, 2018, 37(10): 120-124.</mixed-citation></ref><ref id="hanspub.43540-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">binti Rahmad, N.A., binti Sufri, N.A. J, bin As’ari, M.A., et al. (2019) Recognition of Badminton Action Using Convolutional Neural Network. Indonesian Journal of Electrical En-gineering and Informatics (IJEEI), 7, 750-756.  
&lt;br&gt;https://doi.org/10.11591/ijeei.v7i4.968</mixed-citation></ref><ref id="hanspub.43540-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Piergiovanni, A.J. and Ryoo, M.S. (2018) Fine-Grained Activity Recognition in Baseball Videos. 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), Salt Lake City, 18-22 June 2018, 1740-1748.  
&lt;br&gt;https://doi.org/10.1109/CVPRW.2018.00226</mixed-citation></ref><ref id="hanspub.43540-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Tran, D., Bourdev, L., Fergus, R., et al. (2015) Learning Spati-otemporal Features with 3D Convolutional Networks.  2015 IEEE International Conference on Computer Vision, San-tiago, 7-13 December 2015, 4489-4497.  
&lt;br&gt;https://doi.org/10.1109/ICCV.2015.510</mixed-citation></ref><ref id="hanspub.43540-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Shao, D., Zhao, Y., Dai, B. and Liu, D. (2020) FineGym: A Hierar-chical Video Dataset for Fine-Grained Action Understanding. 2020 IEEE/CVF Conference on Computer Vision and Pat-tern Recognition (CVPR), 13-19 June 2020, Seattle, 2616-2625. &lt;br&gt;https://doi.org/10.1109/CVPR42600.2020.00269</mixed-citation></ref><ref id="hanspub.43540-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Güler, R.A., Neverova, N. and Kokkinos, I. (2018) Densepose: Dense Human Pose Estimation in the Wild. 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Salt Lake City, 18-23 June 2018, 7297-7306.  
&lt;br&gt;https://doi.org/10.1109/CVPR.2018.00762</mixed-citation></ref><ref id="hanspub.43540-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Neverova, N., Guler, R.A. and Kokkinos, I. (2018) Dense Pose Transfer. In: Ferrari, V., Hebert, M., Sminchisescu, C. and Weiss, Y., Eds., Proceedings of the European Conference on Computer Vision (ECCV), Springer, Cham, 128-143.  
&lt;br&gt;https://doi.org/10.1007/978-3-030-01219-9_8</mixed-citation></ref><ref id="hanspub.43540-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">机器之心Pro.Facebook实时人体姿态估计: Dense Pose及其应用展望[EB/OL].  
&lt;br&gt;https://baijiahao.baidu.com/s?id=1625055353488715502&amp;wfr=spider&amp;for=pc, 2019-02-01.</mixed-citation></ref><ref id="hanspub.43540-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">LeCun, Y., Bot-tou, L., Bengio, Y. and Haffner, P. (1998) Gradient-Based Learning Applied to Document Recognition. Proceedings of the IEEE, 86, 2278-2324. &lt;br&gt;https://doi.org/10.1109/5.726791</mixed-citation></ref><ref id="hanspub.43540-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">Soomro, K., Zamir, A.R. and Shah, M. (2012) UCF101: A Dataset of 101 Human Actions Classes from Videos in the Wild. CoRR, 1212, 0402.</mixed-citation></ref></ref-list></back></article>