<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2021.113076</article-id><article-id pub-id-type="publisher-id">CSA-41329</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20210300000_42933554.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  截断核范数的矩阵回归及在人脸识别中的应用
  Matrix Regression Based on Truncated Nuclear Norm and Application in Face Recognition
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>穆</surname><given-names>松</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>张</surname><given-names>治斌</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>南京信息职业技术学院 士官学院，江苏 南京</addr-line></aff><aff id="aff3"><addr-line>北京信息职业技术学院软件与信息学院，北京</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>09</day><month>03</month><year>2021</year></pub-date><volume>11</volume><issue>03</issue><fpage>741</fpage><lpage>750</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   采用回归方法进行人脸识别的过程中对误差的度量采用像素层的F范数，此方法需要假设像素之间是相互独立的，然而在具有连续遮挡的情况下该假设是不成立的。事实上，误差图像在空间上是相关的，采用矩阵的截断核范数可以更好地描述图像的结构信息。对误差图像进行分析后，提出了一种截断核范数的回归模型，并采用交替方向乘子算法(ADMM)求解。与现有的其他回归方法相比，本文的方法将误差检测和误差矫正集成到一个回归模型中，对Extend Yale B人脸数据库的实验也证明了该方法在人脸识别上的优越性。 In the process of face recognition using regression method, the error is measured by the F-norm. This method needs to assume that the pixels are independent of each other, but this assumption is not true in the case of continuous occlusion. In fact, the error images are spatially related, and the truncated nuclear norm of the matrix can describe the structural information of the image. By analyzing the error image, a regression model based on truncated nuclear norm is proposed and solved by the Alternating Direction Multiplier Algorithm (ADMM). Compared with other existing regression methods, the method of this paper integrates error detection and error correction into a regression model. The experiment on Extend Yale B and AR face database also proves the superiority of this method in face recognition.  
  
 
</p></abstract><kwd-group><kwd>稳健回归，截断核范数，交替方向乘子算法，人脸识别, Robust Regression</kwd><kwd> Truncated Nuclear Norm</kwd><kwd> ADMM</kwd><kwd> Face Recognition</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>摘要</title><p>采用回归方法进行人脸识别的过程中对误差的度量采用像素层的F范数，此方法需要假设像素之间是相互独立的，然而在具有连续遮挡的情况下该假设是不成立的。事实上，误差图像在空间上是相关的，采用矩阵的截断核范数可以更好地描述图像的结构信息。对误差图像进行分析后，提出了一种截断核范数的回归模型，并采用交替方向乘子算法(ADMM)求解。与现有的其他回归方法相比，本文的方法将误差检测和误差矫正集成到一个回归模型中，对Extend Yale B人脸数据库的实验也证明了该方法在人脸识别上的优越性。</p></sec><sec id="s2"><title>关键词</title><p>稳健回归，截断核范数，交替方向乘子算法，人脸识别</p></sec><sec id="s3"><title>Matrix Regression Based on Truncated Nuclear Norm and Application in Face Recognition</title><p>Song Mu<sup>1</sup>, Zhibin Zhang<sup>2</sup></p><p><sup>1</sup>Non-Commissioned Officer School, Nanjing Vocational College of Information Technology, Nanjing Jiangsu</p><p><sup>2</sup>Department of Software and Information, Beijing Information Technology College, Beijing</p><p><img src="//html.hanspub.org/file/30-1541189x4_hanspub.png" /></p><p>Received: Feb. 28<sup>th</sup>, 2021; accepted: Mar. 23<sup>rd</sup>, 2021; published: Mar. 30<sup>th</sup>, 2021</p><p><img src="//html.hanspub.org/file/30-1541189x5_hanspub.png" /></p></sec><sec id="s4"><title>ABSTRACT</title><p>In the process of face recognition using regression method, the error is measured by the F-norm. This method needs to assume that the pixels are independent of each other, but this assumption is not true in the case of continuous occlusion. In fact, the error images are spatially related, and the truncated nuclear norm of the matrix can describe the structural information of the image. By analyzing the error image, a regression model based on truncated nuclear norm is proposed and solved by the Alternating Direction Multiplier Algorithm (ADMM). Compared with other existing regression methods, the method of this paper integrates error detection and error correction into a regression model. The experiment on Extend Yale B and AR face database also proves the superiority of this method in face recognition.</p><p>Keywords:Robust Regression, Truncated Nuclear Norm, ADMM, Face Recognition</p><disp-formula id="hanspub.41329-formula40"><graphic xlink:href="//html.hanspub.org/file/30-1541189x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2021 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/30-1541189x7_hanspub.png" /> <img src="//html.hanspub.org/file/30-1541189x8_hanspub.png" /></p></sec><sec id="s5"><title>1. 引言</title><p>从十九世纪末法国学者提出人脸识别的概念 [<xref ref-type="bibr" rid="hanspub.41329-ref1">1</xref>]，到二十世纪末人脸识别的重大突破。人脸识别的发展经历了一个世纪。当前的人脸识别技术正处于飞速发展阶段，许多国家都开展了有关人脸识别的研究。国内多所研究机构及企业成立了人脸识别研究小组。随着人脸识别技术在网络安全、物业管理、银行、军队及计算机等诸多领域的应用。这一人工智能技术会在不断地应用中逐渐完善。然而通常的人脸识别系统都是基于正常光照且无遮挡的情况，对于特殊的情况(带遮挡、光照)未必能起到很好的识别效果。</p><p>基于线性回归分析的方法是人脸识别领域的主要方法。I. Naseem等人提出了一个线性回归分类器(LRC) [<xref ref-type="bibr" rid="hanspub.41329-ref2">2</xref>]。LRC是专门为解决小样本人脸识别问题而设计的，虽然在实验中能够取得良好的结果，但无法解决大样本人脸识别问题。</p><p>通常对线性回归模型对系数采用基于L2范数或L1范数的正则化可以避免过度拟合。J. Wright等人 [<xref ref-type="bibr" rid="hanspub.41329-ref3">3</xref>] 提出了一个基于稀疏表示的分类(SRC)方法。SRC方法假设表示系数是稀疏的并使用所有训练样本组成的字典来表示测试样本，该系数中的非零值集中在训练样本与测试样本相同的类别中。J. Yang等人对SRC进行了深入的研究，并为其有效性寻求理论的支持 [<xref ref-type="bibr" rid="hanspub.41329-ref4">4</xref>]。研究发现是L1范数决定了表示的效果，而基于L0范数的正则化只能实现稀疏性。A. Wagner等人 [<xref ref-type="bibr" rid="hanspub.41329-ref5">5</xref>] 在前人的基础上进一步扩展了SRC模型并将人脸对齐和识别统一到共同的框架之中。L. Zhang等人 [<xref ref-type="bibr" rid="hanspub.41329-ref6">6</xref>] 分析了SRC的工作原理，认为协作表示策略比基于L1范数的稀疏约束更重要。因此提出了一种基于岭回归的协作表示分类器(CRC)。CRC可以实现与SRC相似的结果，并且能够提高算法的速度。但是，大量的实践证明基于CRC模型的人脸识别方法不提供消除噪声的机制，所以它不是稳健的人脸识别方法。</p><p>目前基于回归的人脸识别方法都是将每个像素上的误差逐个地表征，而这样的做法存在两个方面缺陷。首先，这种建模需要假定误差像素是互相独立的，这一假设对于像素的随机噪声是没有问题的，但是遮挡与光照变化的情况下，这种假设就不成立。因此，使用基于像素误差模型来解决带有遮挡的图像分类在理论上是有问题的。</p><p>在回归分析的人脸识别方法中，使用一组训练图像来表示一个测试图像，在理想情况下，误差图像应当是一个低秩矩阵。在更一般的情况下，测试图像中可能存在光照的变化和部分的遮挡。而光照变化，特别是局部照明变化(如阴影)通常导致低秩误差图像。现有的回归方法，单独表征每一个误差像素，不能够有效利用这种结构信息。</p><p>本文针对带有遮挡和光照的人脸图像提出基于截断核范数的识别方法，对矩阵回归中误差图像采用截断核范数度量，通过ADMM算法求解回归系数，并采用误差矩阵的截断核范数为度量进行图像分类。</p></sec><sec id="s6"><title>2. 基于截断核范数的矩阵回归</title><p>首先给出了基于截断核范数的矩阵回归，然后利用了交替方向乘子算法进行模型求解。</p><sec id="s6_1"><title>2.1. 模型建立</title><p>给定一组n个图像矩阵 A 1 , ⋯ , A n ∈ R p &#215; q 和一个测试图像矩阵 B ∈ R p &#215; q ，测试图像B可以用矩阵 A 1 , ⋯ , A n 线性表示为</p><p>B = x 1 A 1 + x 2 A 2 + ⋯ + x n A n + E (1)</p><p>其中， x 1 , x 1 , ⋯ , x n 是表示系数， E 表示误差图像矩阵。定义</p><p>A ( x ) = x 1 A 1 + x 2 A 2 + ⋯ + x n A n (2)</p><p>则公式(1)可表示为</p><p>B = A ( x ) + E (3)</p><p>(3)式给出了线性矩阵回归模型的一般形式，误差图像 E 的最优解在许多情况下通常是低秩的，因此直观的想法可以通过秩最小化来计算回归系数</p><p>min x rank ( A ( x ) − B ) (6)</p><p>然而，采用秩函数来描述矩阵的低秩结构会使模型求解困难，cand&#233;s [<xref ref-type="bibr" rid="hanspub.41329-ref7">7</xref>] 提出采用矩阵的核范数作为矩阵秩函数的替代。</p><p>定义1 给定一个矩阵 Y ∈ R m &#215; n ，截断核范数 ‖ Y ‖ r 被定义为 min ( m , n ) − r 个最小奇异值的和，即 ‖ Y ‖ r = ∑ i = r + 1 min ( m , n ) σ i ( Y ) 。</p><p>由于截断核范数能够更准确的近似秩函数，上述秩最小化问题可转化为截断核范数最小化问题:</p><p>min x ‖ A ( x ) − B ‖ r (7)</p><p>为防止过拟合，加入正则项，得到正则化的截断核范数的矩阵回归模型</p><p>min x ‖ A ( x ) − B ‖ r + 1 2 λ ‖ x ‖ 2 2 (8)</p><p>下面求解这个模型。</p></sec><sec id="s6_2"><title>2.2. 模型求解</title><p>本文采用交替方向乘子算法(ADMM)求解截断核范数的矩阵回归问题 [<xref ref-type="bibr" rid="hanspub.41329-ref8">8</xref>] [<xref ref-type="bibr" rid="hanspub.41329-ref9">9</xref>] [<xref ref-type="bibr" rid="hanspub.41329-ref10">10</xref>]。关于ADMM的更多知识，可以参考文献 [<xref ref-type="bibr" rid="hanspub.41329-ref8">8</xref>]。根据A. Hansson等人的研究成果 [<xref ref-type="bibr" rid="hanspub.41329-ref10">10</xref>]，(8)式中的模型可以重写为</p><p>min x ‖ E ‖ r + 1 2 λ ‖ x ‖ 2 2 s .t .     A ( x ) − B = E (9)</p><p>增广拉格朗日函数定义为</p><p>L μ ( E , x , Z ) = ‖ E ‖ r + 1 2 λ ‖ x ‖ 2 2 + T r ( Z T ( A ( x ) − E − B ) ) + μ 2 ‖ A ( x ) − E − B ‖ F 2 (10)</p><p>μ &gt; 0 是惩罚参数， Z 是拉格朗日乘数法， Tr ( ⋅ ) 表示迹算子。如果 μ = 0 ，(10)表示标准的拉格朗日函数。</p><p>ADMM算法由以下迭代组成</p><p>1) 令 E = E k 且 Z = Z k ，更新 x ：</p><p>x k + 1 = arg min x L μ ( E , x , Z ) (11)</p><p>2) 令 x = x k + 1 且 Z = Z k ，更新 E ：</p><p>E k + 1 = arg min E L μ ( E , x , Z ) (12)</p><p>3) 令 x = x k + 1 且 E = E k + 1 ，更新 Z :</p><p>Z k + 1 = Z k + μ ( E k + 1 − E k + 1 ) (13)</p><p>算法的关键是解决上述步骤中的优化问题(11)和(12)。因为</p><p>T r ( Z T ( A ( x ) − E − B ) ) + μ 2 ‖ A ( x ) − E − B ‖ F 2 = μ 2 ‖ A ( x ) − ( B + E − 1 μ Z ) ‖ F 2 − 1 2 μ ‖ Z ‖ F 2 (14)</p><p>得到</p><p>L μ = ( E , x , Z ) = ‖ E ‖ r + 1 2 λ ‖ x ‖ 2 2 + μ 2 ‖ A ( x ) − ( B + E − 1 μ Z ) ‖ F 2 − 1 2 μ ‖ Z ‖ F 2 (15)</p><p>x 的解可以通过下式求：</p><p>x k + 1 = arg min x L μ ( E , x , Z ) = arg min x ( ‖ A ( x ) − ( B + E − 1 μ Z ) ‖ F 2 + λ μ ‖ x ‖ 2 2 ) (16)</p><p>令 H = { Vec ( A 1 ) , ⋯ , Vec ( A n ) } ，则 A ( x ) = ∑ i = 1 n x i A i 可以写成矩阵形式 H x .令</p><p>g = Vec ( B + E − 1 μ Z ) (17)</p><p>因此(16)等同于</p><p>x k + 1 = arg min x ( ‖ H x − g ‖ 2 2 + λ μ ‖ x ‖ 2 2 ) (18)</p><p>(18)式为标准的岭回归模型，可以得到精确解为：</p><p>x k + 1 = ( H T H + λ μ I ) − 1 H T g (19)</p><p>下面考虑问题(12)的解，由于 ‖ E ‖ r 是矩阵奇异值的非凸函数，直接求解并不容易。由文献 [<xref ref-type="bibr" rid="hanspub.41329-ref8">8</xref>]，可知</p><p>‖ E ‖ r = ∑ i = 1 min ( m , n ) σ i ( E ) − ∑ i = 1 r σ i ( E ) = ‖ E ‖ * − max A A T = I , B B T = I T r ( A E B T ) (20)</p><p>因此，求解优化问题 min E ‖ E ‖ r 可转化为：</p><p>min E ‖ E ‖ * − max A A T = I , B B T = I T r ( A E B T ) (21)</p><p>这里 A ∈ R r &#215; m , B ∈ R r &#215; n 。</p><p>定义2 关于矩阵 Y ∈ R m &#215; n ，秩为r的奇异值分解(SVD)，</p><p>Y = U ∑ V T , ∑ = diag ( { σ i } 1 ≤ i ≤ r ) (22)</p><p>定义奇异值阈值算子 D τ 如下： D τ ( Y ) = U D τ ( ∑ ) V T</p><p>D τ ( ∑ ) = diag ( { σ i − τ } + ) (23)</p><p>定理1 对于每个 τ ≥ 0 和 X ∈ R m &#215; n ，有</p><p>D τ ( X ) = arg min X 1 2 ‖ Y − X ‖ F 2 + τ ‖ Y ‖ * (24)</p><p>因此，问题(12)可转化为</p><p>E k + 1 = arg min E ‖ E ‖ * − Tr ( A l T k B l T ) + μ 2 ‖ E − T k ‖ F 2 − Tr ( Z k T ( E − T k ) ) (25)</p><p>其中 T k 为求解 E 而引进的辅助变量。</p><p>忽略常量项，可得</p><p>E k + 1 = arg min E ‖ E ‖ * + μ 2 ‖ E − ( T k + 1 μ Z k T ) ‖ F 2 (26)</p><p>由定理1可得</p><p>E k + 1 = D 1 μ ( T k + 1 μ Z k T ) (27)</p><p>计算 E k + 1 通过修正 T k 和 Z k</p><p>设置 E 1 = T 1 作为初始化，在第l次迭代中，首先基于 E l 奇异值分解确定了 E l 并计算 A l 和 B l 。</p><p>这里</p><p>A = ( u 1 , ⋯ , u r ) T , B = ( v 1 , ⋯ , v r ) T</p><p>max A A T = I , B B T = I Tr ( A E B T ) = ∑ i = 1 r σ i ( E )</p><p>T k 的更新过程为</p><p>T k + 1 = arg min T L ( E k + 1 , Z k , T k , μ ) (28)</p><p>它是T的二次函数，容易求得</p><p>T k + 1 = E k + 1 + 1 μ ( A l T B l − Z k ) (29)</p><p>最后计算 Z k + 1 ，通过修正 E k + 1 和 T k + 1</p><p>Z k + 1 = Z k + μ ( E k + 1 − T k + 1 ) (30)</p><p>S. Boyd [<xref ref-type="bibr" rid="hanspub.41329-ref9">9</xref>] 给出了ADMM算法的最优条件和停止准则。</p><p>max ( ‖ x k + 1 − x k ‖ F , ‖ E k + 1 − E k ‖ F ) ≤ ε (32)</p><p>在本算法中，由(19)式可知， ( H T H + λ μ I ) − 1 H T 在每次迭代中都是固定的，因而可以提前计算并保存。令</p><p>M = ( H T H + λ μ I ) H T (33)</p><p>然后，在每个迭代中更新 x 、 g 和矩 M g 。另一方面，更新 E 时，主要计算用于执行矩阵 Q = T k + 1 μ Z k T 的奇异值分解。</p><p>TNMR算法步骤：</p><p>1) 输入图像矩阵 Y 和训练图像 A 1 , A 2 , ⋯ , A n ，模型中的参数 λ , μ ，及终止条件 ε 。计算 H = [ Vec ( A 1 ) , ⋯ , Vec ( A n ) ] ， M = ( H T H + λ μ I ) H T</p><p>2) while not converged do</p><p>a) 更新 x k + 1 ， g = Vec ( B + E − 1 μ Z k ) ， x k + 1 = M g</p><p>b) 更新 E k + 1 ， E k + 1 = D 1 μ ( T k + 1 μ Z k )</p><p>通过对 E k + 1 的奇异值分解得到 A k + 1 ， B k + 1 ， T k + 1 = E k + 1 + 1 μ ( A k + 1 T B k + 1 − Z k )</p><p>c) 更新 Z k + 1 ， Z k + 1 = Z k + μ ( E k + 1 − T k + 1 )</p><p>d) 判断收敛条件</p><p>end while</p><p>输出：最优回归系数向量 x *</p><p>算法可以在两步迭代策略中进行解释，以获得稳健人脸识别策略。更新 x 实际上是用于确定表示系数，更新 E 实际上是一个误差检测步骤，用于确定真正损坏的部分。因此，TNMR方法提供了一个统一的框架，将误差检测和误差校正集成到一个简单的模型中。本文的算法收敛性证明类似于文献 [<xref ref-type="bibr" rid="hanspub.41329-ref11">11</xref>] 中所提供的核范数的ADMM算法收敛性证明。</p></sec><sec id="s6_3"><title>2.3. 算法的复杂度</title><p>给定n个训练样本和图像大小 p &#215; q ，令 m = p &#215; q ，由矩阵乘法决定的计算复杂度为 O ( m n ) 。更新 E 的计算复杂度是 O ( min ( p 2 q , p q 2 ) ) ，主要由 p &#215; q 矩阵 Q = T k + 1 μ Z k T 的奇异值分解决定的。因此，算法总的计算复杂度是 O ( k ( min ( m p , m q ) + m n ) ) ，其中k是迭代次数。</p></sec></sec><sec id="s7"><title>3. 分类器设计</title><p>以给定的一组图像 A 1 , A 2 , ⋯ , A n 作为训练样本，与SRC的策略类似，使用所有的训练样本来计算表示系数。对于测试图像 B ，使用所有训练样本来表示它，并通过求解下面的TNMR模型得到表示系数向量</p><p>x * = arg min x ‖ A ( x ) − B ‖ r + 1 2 λ ‖ x ‖ 2 2 (34)</p><p>在 x 的最优解基础上，得到重构图像 B ^ 和误差图像 E = B − B ^ 。定义</p><p>e i ( B ) = ‖ B − B ^ i ‖ r (35)</p><p>B ^ i 表示第i类训练样本的重构图像。</p><p>分类规则定义为：</p><p>e l ( B ) = min i e i ( B ) ，</p><p>则 B 被判定为第l类。</p></sec><sec id="s8"><title>4. 实验</title><p>本文采用Extend Yale B数据库 [<xref ref-type="bibr" rid="hanspub.41329-ref12">12</xref>] 和AR人脸数据库 [<xref ref-type="bibr" rid="hanspub.41329-ref13">13</xref>] 以验证光照变化和带遮挡情况下的人脸识别效果。TNMR方法将与下列方法比较：线性表示分类器(LRC) [<xref ref-type="bibr" rid="hanspub.41329-ref2">2</xref>]、协作表示分类器(CRC) [<xref ref-type="bibr" rid="hanspub.41329-ref6">6</xref>]、稀疏表示分类器(SRC) [<xref ref-type="bibr" rid="hanspub.41329-ref3">3</xref>]、相关熵的稀疏表示(CESR) [<xref ref-type="bibr" rid="hanspub.41329-ref14">14</xref>]、稳健稀疏编码(RSC) [<xref ref-type="bibr" rid="hanspub.41329-ref15">15</xref>]、HQ_A和HQ_M [<xref ref-type="bibr" rid="hanspub.41329-ref16">16</xref>]、核范数矩阵回归(NMR)。除了矩阵回归方法，其他向量回归的方法都采用欧氏距离为分类准则。另外，所有实验都是在原始图像进行。关于实验参数，CRC、SRC都是选择最优的参数使识别率最高。其他方法的参数设置参考原文作者的建议。</p><sec id="s8_1"><title>4.1. 带光照变化的人脸识别实验</title><p>Extend Yale B人脸数据库由耶鲁大学计算机视觉与控制中心创建，包含38人的9个姿势和64种光照条件下的人脸图像，在相机帧率为30帧/秒的情况下，获得的一个人的64张正面人脸图像，所以64张图片的头部姿势和面部表情只有微小的变化。本文的实验采用图片的大小为96 &#215; 84像素。某人的部分图像如图1所示。</p><p>图1. Extend Yale B中不同光照条件下的人脸图像</p><p>本文将分别使用子集1和子集2作为训练集，对应的子集4和子集5 (极端光照条件下的人脸图像)作为测试(如图2，图3所示)，得出的各个方法的识别率如下表1和表2。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Subset 2 as the training group and subset 4 as the test group (%</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >方法</th><th align="center" valign="middle" >LRC</th><th align="center" valign="middle" >CRC</th><th align="center" valign="middle" >SRC</th><th align="center" valign="middle" >CESR</th><th align="center" valign="middle" >RSC</th><th align="center" valign="middle" >SSEC</th><th align="center" valign="middle" >HQ_A</th><th align="center" valign="middle" >HQ_M</th><th align="center" valign="middle" >NMR</th><th align="center" valign="middle" >TNMR</th></tr></thead><tr><td align="center" valign="middle" >识别率</td><td align="center" valign="middle" >87.6</td><td align="center" valign="middle" >88.0</td><td align="center" valign="middle" >78.4</td><td align="center" valign="middle" >36.8</td><td align="center" valign="middle" >80.3</td><td align="center" valign="middle" >20.6</td><td align="center" valign="middle" >67.9</td><td align="center" valign="middle" >75.8</td><td align="center" valign="middle" >90.2</td><td align="center" valign="middle" >92.7</td></tr></tbody></table></table-wrap><p>表1. 子集2作为训练组子集4作为测试组得出的各方法识别率(%)</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> Subset 1 as the training group and subset5 as the test group (%</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >方法</th><th align="center" valign="middle" >LRC</th><th align="center" valign="middle" >CRC</th><th align="center" valign="middle" >SRC</th><th align="center" valign="middle" >CESR</th><th align="center" valign="middle" >RSC</th><th align="center" valign="middle" >SSEC</th><th align="center" valign="middle" >HQ_A</th><th align="center" valign="middle" >HQ_M</th><th align="center" valign="middle" >NMR</th><th align="center" valign="middle" >TNMR</th></tr></thead><tr><td align="center" valign="middle" >识别率</td><td align="center" valign="middle" >42.2</td><td align="center" valign="middle" >35.7</td><td align="center" valign="middle" >28.8</td><td align="center" valign="middle" >22.2</td><td align="center" valign="middle" >36.7</td><td align="center" valign="middle" >12.5</td><td align="center" valign="middle" >31.3</td><td align="center" valign="middle" >36.8</td><td align="center" valign="middle" >47.9</td><td align="center" valign="middle" >66.2</td></tr></tbody></table></table-wrap><p>表2. 子集1作为训练组子集5作为测试组得出的各方法识别率(%)</p><p>图2. 子集2和子集4的部分人脸图像</p><p>图3. 子集1和子集5的部分人脸图像</p><p>从表1实验结果来看，除了CESR，SSEC，HQ_A算法外，提出的大部分算法都得到了较好的结果。而本文所提出的TNMR算法达到了最佳效果。一些稳健的稀疏表示方法，如CESR、HQ_A、HQ_M，在极端的光照下不太可靠。SSEC作为一种专为连续遮挡而设计的方法，也不适合极端的光照条件。传统的线性回归方法LRC对光照变化的敏感性较稳健稀疏表示方法要小。而本文TNMR算法得出的结果远优于其他算法结果，并再次达到了最佳效果。上述的实验结果证明了所提出的方法(TNMR)在正常情况下与极端光照条件下的优越性能。</p></sec><sec id="s8_2"><title>4.2. 带遮挡的人脸识别实验</title><p>AR人脸数据库由巴塞罗那计算机视觉中心创建，该数据库包含126人在不同光照、表情下的4000多张人脸图像。图像在两个不同的时间段采集，由于人脸图像具有光照、表情和遮挡变化，因此该数据库是公认的人脸识别数据库。</p><p>为了验证本文方法对遮挡的人脸识别的有效性，采用AR数据中两个时间段所拍摄的不同光照和表情的图像作为训练数据(如图4所示)，分别用戴围巾和墨镜的图像作为测试数据(如图5所示)。</p><p>图4. AR中不同光照和表情下的人脸图像</p><p>图5. AR中带有不同遮挡的人脸图像</p><p>从实验结果可以看出，戴围巾遮挡的各方法识别率比较低(如表3所示)，带有墨镜遮挡的测试数据对识别的影响不是很大(如表4所示)，本文的方法相对于其他方法也没有显著性的提高。而对于带有墨镜遮挡的测试数据，LRC、CESR方法就表现的很不好，只有NMR方法能达到和我们接近的结果。所以，TNMR方法对于带有“污染”的数据仍就表现的很稳健。</p><table-wrap id="table3" ><label><xref ref-type="table" rid="table3">Table 3</xref></label><caption><title> Recognition rate of each method of wearing scarf to cover (%</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >方法</th><th align="center" valign="middle" >LRC</th><th align="center" valign="middle" >CRC</th><th align="center" valign="middle" >SRC</th><th align="center" valign="middle" >CESR</th><th align="center" valign="middle" >RSC</th><th align="center" valign="middle" >SSEC</th><th align="center" valign="middle" >HQ_A</th><th align="center" valign="middle" >HQ_M</th><th align="center" valign="middle" >NMR</th><th align="center" valign="middle" >TNMR</th></tr></thead><tr><td align="center" valign="middle" >识别率</td><td align="center" valign="middle" >30.7</td><td align="center" valign="middle" >63.6</td><td align="center" valign="middle" >57.6</td><td align="center" valign="middle" >33.8</td><td align="center" valign="middle" >66.8</td><td align="center" valign="middle" >24.6</td><td align="center" valign="middle" >48.7</td><td align="center" valign="middle" >50.1</td><td align="center" valign="middle" >73.5</td><td align="center" valign="middle" >74.1</td></tr></tbody></table></table-wrap><p>表3. 戴围巾遮挡的各方法识别率(%)</p><table-wrap id="table4" ><label><xref ref-type="table" rid="table4">Table 4</xref></label><caption><title> Recognition rate of wearing sunglasses (%</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >方法</th><th align="center" valign="middle" >LRC</th><th align="center" valign="middle" >CRC</th><th align="center" valign="middle" >SRC</th><th align="center" valign="middle" >CESR</th><th align="center" valign="middle" >RSC</th><th align="center" valign="middle" >SSEC</th><th align="center" valign="middle" >HQ_A</th><th align="center" valign="middle" >HQ_M</th><th align="center" valign="middle" >NMR</th><th align="center" valign="middle" >TNMR</th></tr></thead><tr><td align="center" valign="middle" >识别率</td><td align="center" valign="middle" >92.8</td><td align="center" valign="middle" >93.5</td><td align="center" valign="middle" >94.4</td><td align="center" valign="middle" >95.0</td><td align="center" valign="middle" >89.2</td><td align="center" valign="middle" >88.6</td><td align="center" valign="middle" >94.7</td><td align="center" valign="middle" >95.1</td><td align="center" valign="middle" >96.9</td><td align="center" valign="middle" >97.2</td></tr></tbody></table></table-wrap><p>表4. 戴墨镜的各方法识别率(%)</p></sec></sec><sec id="s9"><title>5. 结束语</title><p>本文提出了一种基于截断核范数的矩阵回归模型，并利用交替方向乘子算法计算回归系数，提出的TNMR分类器在Extend Yale B人脸图像数据库中进行的研究结果表明：</p><p>1) 与常规的基于回归的方法对光照变化和遮挡情况下的人脸识别技术相比TNMR更加稳健。</p><p>2) TNMR比结构化稀疏有着更强大的误差编码模型，并且结果对光照的变化不敏感。</p><p>3) TNMR可以在极端光照甚至部分遮挡的情况下获得重构后的满意的一般人脸图像。</p><p>尽管TNMR比许多稳健的回归方法要好，并且在实验中获得了良好的效果。但本文的模型将截断核范数作为捕获低秩结构噪声的度量，该模型是否对更复杂的噪声有效，或者如何扩展一般噪声模型需要进一步的研究。</p></sec><sec id="s10"><title>文章引用</title><p>穆 松,张治斌. 截断核范数的矩阵回归及在人脸识别中的应用Matrix Regression Based on Truncated Nuclear Norm and Application in Face Recognition[J]. 计算机科学与应用, 2021, 11(03): 741-750. https://doi.org/10.12677/CSA.2021.113076</p></sec><sec id="s11"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.41329-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">CHEN and BLEDSOE (1965) Automatic Face Recognition. Panoramic Research Inc., Palo Alto.</mixed-citation></ref><ref id="hanspub.41329-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Naseem, I., Togneri, R. and Bennamoun, M. (2010) Linear Regression for Face Recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence, 32, 2106-2112. &lt;br&gt;https://doi.org/10.1109/TPAMI.2010.128</mixed-citation></ref><ref id="hanspub.41329-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Wright, J., Yang, A.Y., Ganesh, A., et al. (2009) Robust Face Recognition via Sparse Representation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 31, 210-227. &lt;br&gt;https://doi.org/10.1109/TPAMI.2008.79</mixed-citation></ref><ref id="hanspub.41329-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Yang, J., Zhang, L., Xu, Y. and Yang, J.Y. (2012) Beyond Sparsity: The Role of L1-Optimizer in Pattern Classification. Pattern Recognition, 45, 1104-1118. &lt;br&gt;https://doi.org/10.1016/j.patcog.2011.08.022</mixed-citation></ref><ref id="hanspub.41329-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Wagner, A., Wright, J., Ganesh, A., et al. (2012) Toward a Practical Face Recognition System: Robust Registration and Illumination via Sparse Representation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 34, 372- 386. &lt;br&gt;https://doi.org/10.1109/TPAMI.2011.112</mixed-citation></ref><ref id="hanspub.41329-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Zhang, L., Yang, M. and Feng, X.C. (2011) Sparse Representation or Collaborative Representation Which Helps Face Recognition? 2011 International Conference on Computer Vision, Barcelona, 6-13 November 2011, 471-478.</mixed-citation></ref><ref id="hanspub.41329-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Candés, E.J. and Tao, T. (2010) The Power of Convex Relaxation: Near-optimal Matrix Completion. IEEE Transactions on Information Theory, 56, 2053-2080. &lt;br&gt;https://doi.org/10.1109/TIT.2010.2044061</mixed-citation></ref><ref id="hanspub.41329-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Lin, Z., Chen, M., Wu, L., et al. (2010) The Augmented Lagrange Multiplier Method for Exact Recovery of Corrupted Low-Rank Matrices. arXiv:1009.5055v2.</mixed-citation></ref><ref id="hanspub.41329-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Boyd, S., Parikh, N., Chu, E., Peleato, B. and Eckstein, J. (2011) Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers. Foundations and Trends in Machine Learning, 3, 1-122.  
&lt;br&gt;https://doi.org/10.1561/2200000016</mixed-citation></ref><ref id="hanspub.41329-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Hansson, A., Zhang, L. and Vandenberghe, L. (2012) Subspace System Identification via Weighted Nuclear Norm Optimization. 2012 IEEE 51st IEEE Conference on Decision and Control (CDC), Maui, HI, 10-13 December 2012, 3439- 3444. &lt;br&gt;https://doi.org/10.1109/CDC.2012.6426980</mixed-citation></ref><ref id="hanspub.41329-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Li, X., Ye, J., Hu, Y., et al. (2012) Matrix Completion by Truncated Nuclear Norm Regularization. 2012 IEEE Conference on Computer Vision and Pattern Recognition, Providence, 16-21 June 2012, 2192-2199.</mixed-citation></ref><ref id="hanspub.41329-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Lee, K.-C., Ho, J. and Kriegman, D.J. (2005) Acquiring Linear Subspaces for Face Recognition under Variable Lighting. IEEE Transactions on Pattern Analysis and Machine Intelligence, 27, 684-698.  
&lt;br&gt;https://doi.org/10.1109/TPAMI.2005.92</mixed-citation></ref><ref id="hanspub.41329-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Martinez, A.M. (1998) The Ar Face Database. CVC Technical Re-port No. 24.</mixed-citation></ref><ref id="hanspub.41329-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">He, R., Zheng, W.S., Hu, B.G., et al. (2011) A Regularized Correntropy Framework for Robust Pat-tern Recognition. Neural Computation, 23, 2074-2100. &lt;br&gt;https://doi.org/10.1162/NECO_a_00155</mixed-citation></ref><ref id="hanspub.41329-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">Yang, M., Zhang, L., Yang, J., et al. (2013) Regularized Robust Coding for Face Recognition. IEEE Transactions on Image Pro-cessing, 22, 1753-1766. &lt;br&gt;https://doi.org/10.1109/TIP.2012.2235849</mixed-citation></ref><ref id="hanspub.41329-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">He, R., Zheng, W.-S., Tan, T., et al. (2014) Half-Quadratic-Based Iterative Minimization for Robust Sparse Representation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 36, 261-275.  
&lt;br&gt;https://doi.org/10.1109/TPAMI.2013.102</mixed-citation></ref></ref-list></back></article>