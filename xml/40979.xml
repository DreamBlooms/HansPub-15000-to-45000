<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2021.113054</article-id><article-id pub-id-type="publisher-id">CSA-40979</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20210300000_98972489.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于背景信息优化的显著性目标检测
  Salient Object Detection Based on Background Information Optimization
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>文</surname><given-names>雅宏</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib></contrib-group><aff id="aff1"><label>1</label><addr-line>null</addr-line></aff><aff id="aff2"><label>1</label><addr-line>安康学院电子与信息工程学院电子信息技术研究中心，陕西 安康 </addr-line></aff><pub-date pub-type="epub"><day>09</day><month>03</month><year>2021</year></pub-date><volume>11</volume><issue>03</issue><fpage>534</fpage><lpage>542</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   自然图像中的背景包含了丰富的信息，在进行显著性目标检测时，如果处理不当，会影响检测结果的准确性。为了减少背景对检测的影响，本文结合背景信息特征提出了一种相邻像素优化的图像显著性目标检测方法。首先提取背景的统计信息和结构信息构建初始的显著性图；然后，利用保边平滑滤波器对初始显著图进行优化，加强目标区域的细节信息，获得轮廓较为清楚的显著图；最后，根据相邻像素之间的影响，建立相邻像素之间的关系对显著图做进一步优化，得到最终显著图。在两种公开的数据集上测试，并与四种经典的显著性检测算法对比，采用精确率–召回率曲线和F-measure图对算法进行评估，结果显示，本文提出的算法生成的显著图效果更好，检测的准确性更高。 The rich background information of natural images will affect the accuracy of the results in the pro-cess of salient object detection. In order to reduce the influence of background, we propose a salient object detection method based on adjacent pixel optimization, which exploits the feature of background information. Firstly, an initial saliency map is generated by exploiting statistical and struc-tural information of the background. Secondly, in order to enhance the detailed information of the object region and obtain a saliency map with sharp edge, the initial saliency map is optimized by using an edge-preserving filter. Finally, the relationship between adjacent pixels is established to further optimize the saliency map, according to the influence of adjacent pixels. Experiments on two public datasets and compared with four mainstream detection methods, we use the precision-recall rate curve and F-measure graph to evaluate the algorithm. The results show that the saliency map generated by the proposed method in this paper is better than other methods and more effective in highlighting the salient object uniformly.  
  
 
</p></abstract><kwd-group><kwd>显著性目标检测，背景信息，保边平滑滤波器, Salient Object Detection</kwd><kwd> Background Information</kwd><kwd> Edge-Preserving Filter</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>摘要</title><p>自然图像中的背景包含了丰富的信息，在进行显著性目标检测时，如果处理不当，会影响检测结果的准确性。为了减少背景对检测的影响，本文结合背景信息特征提出了一种相邻像素优化的图像显著性目标检测方法。首先提取背景的统计信息和结构信息构建初始的显著性图；然后，利用保边平滑滤波器对初始显著图进行优化，加强目标区域的细节信息，获得轮廓较为清楚的显著图；最后，根据相邻像素之间的影响，建立相邻像素之间的关系对显著图做进一步优化，得到最终显著图。在两种公开的数据集上测试，并与四种经典的显著性检测算法对比，采用精确率–召回率曲线和F-measure图对算法进行评估，结果显示，本文提出的算法生成的显著图效果更好，检测的准确性更高。</p></sec><sec id="s2"><title>关键词</title><p>显著性目标检测，背景信息，保边平滑滤波器</p></sec><sec id="s3"><title>Salient Object Detection Based on Background Information Optimization</title><p>Yahong Wen</p><p>Research Center of Electronic Information Technology, School of Electronic and Information Engineering, Ankang Universily, Ankang Shaanxi</p><p><img src="//html.hanspub.org/file/8-1542052x4_hanspub.png" /></p><p>Received: Feb. 16<sup>th</sup>, 2021; accepted: Mar. 10<sup>th</sup>, 2021; published: Mar. 17<sup>th</sup>, 2021</p><p><img src="//html.hanspub.org/file/8-1542052x5_hanspub.png" /></p></sec><sec id="s4"><title>ABSTRACT</title><p>The rich background information of natural images will affect the accuracy of the results in the process of salient object detection. In order to reduce the influence of background, we propose a salient object detection method based on adjacent pixel optimization, which exploits the feature of background information. Firstly, an initial saliency map is generated by exploiting statistical and structural information of the background. Secondly, in order to enhance the detailed information of the object region and obtain a saliency map with sharp edge, the initial saliency map is optimized by using an edge-preserving filter. Finally, the relationship between adjacent pixels is established to further optimize the saliency map, according to the influence of adjacent pixels. Experiments on two public datasets and compared with four mainstream detection methods, we use the precision-recall rate curve and F-measure graph to evaluate the algorithm. The results show that the saliency map generated by the proposed method in this paper is better than other methods and more effective in highlighting the salient object uniformly.</p><p>Keywords:Salient Object Detection, Background Information, Edge-Preserving Filter</p><disp-formula id="hanspub.40979-formula17"><graphic xlink:href="//html.hanspub.org/file/8-1542052x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2021 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/8-1542052x7_hanspub.png" /> <img src="//html.hanspub.org/file/8-1542052x8_hanspub.png" /></p></sec><sec id="s5"><title>1. 引言</title><p>显著性目标检测是根据人类视觉注意机制，从图像中检测并分割出最吸引人的区域 [<xref ref-type="bibr" rid="hanspub.40979-ref1">1</xref>] [<xref ref-type="bibr" rid="hanspub.40979-ref2">2</xref>]。近年来在计算机视觉领域有着广泛的应用，通常作为图像分割 [<xref ref-type="bibr" rid="hanspub.40979-ref3">3</xref>] [<xref ref-type="bibr" rid="hanspub.40979-ref4">4</xref>]、视觉跟踪 [<xref ref-type="bibr" rid="hanspub.40979-ref5">5</xref>] [<xref ref-type="bibr" rid="hanspub.40979-ref6">6</xref>] [<xref ref-type="bibr" rid="hanspub.40979-ref7">7</xref>]、视频压缩 [<xref ref-type="bibr" rid="hanspub.40979-ref8">8</xref>] [<xref ref-type="bibr" rid="hanspub.40979-ref9">9</xref>] [<xref ref-type="bibr" rid="hanspub.40979-ref10">10</xref>] 等的预处理阶段。</p><p>在显著性检测的研究过程中，研究者提出了许多显著性检测的方法，通常可以分为两类 [<xref ref-type="bibr" rid="hanspub.40979-ref11">11</xref>] [<xref ref-type="bibr" rid="hanspub.40979-ref12">12</xref>] [<xref ref-type="bibr" rid="hanspub.40979-ref13">13</xref>]：自下而上和自上而下。自下而上的方法利用先验知识和深度学习方式来完成检测，这类方法一般效果较好，能很好的突出显著性区域，但是要执行大量的训练，软硬件要求高，特别是数据收集。与自上而下的方法相比，自上而下的方法不需要数据收集和训练过程，要求低。这些优点使得自上而下方法更有效、更容易在广泛的实际计算机视觉应用中实现。本文主要对后者展开研究。</p><p>近年来，大部分自上而下的显著性检测方法中，几乎是根据颜色对比、纹理、形状等特征来实现检测，检测效果较好，能够突出显著性区域。</p><p>Achanta和Hemami等 [<xref ref-type="bibr" rid="hanspub.40979-ref14">14</xref>] 提出了一种基于频率调整的显著区域检测方法，该方法通过从原始图像中保留更多的空间频率内容，输出具有明确显著对象边界的全分辨率显著图。Wei and Wen等 [<xref ref-type="bibr" rid="hanspub.40979-ref15">15</xref>] 从不同的角度提取背景信息，利用自然图像中两种常见的背景先验，即边界先验和连通性先验，为显著目标检测提供更多的线索。Lang和Liu等 [<xref ref-type="bibr" rid="hanspub.40979-ref16">16</xref>] 提出了一种多任务稀疏追踪算法，该算法结合多种不同的特征用于图像显著性检测。根据一幅多视图特征描述的图像，通过对多视图特征矩阵进行联合低秩和稀疏分解，寻找一致稀疏的元素来推断该图像的显著性映射。Shen和Wu等 [<xref ref-type="bibr" rid="hanspub.40979-ref17">17</xref>] 提出了一种统一的显著性目标检测模型，将传统的低级别特征与更高级别的引导相结合，在一定的特征空间内将图像表示为低秩矩阵加稀疏噪声。Xie等人 [<xref ref-type="bibr" rid="hanspub.40979-ref18">18</xref>] 结合拉普拉斯稀疏子空间聚类和统一低秩表示提出一种基于超像素聚类和统一低秩表示的显著性目标检测，该方法能较好的凸显连续的显著性区域。Huang等人 [<xref ref-type="bibr" rid="hanspub.40979-ref19">19</xref>] 充分利用背景信息，结合先验知识提出一种特征聚类的检测方法。</p><p>这些方法虽然效果较好，但是当检测到分布较广的显著性区域时，产生的区域连续性较不理想。针对此问题，本文利用背景的结构特征和统计信息，生成一个以背景信息为依据的初始显著图，该显著图能较好把整个显著性区域凸显出来。为了消除初始显著性区域中的背景信息，利用保边滤波器对初始显著图进行初步优化，减弱背景信息，增强显著性区域。最后为了减弱被显著性区域包围的背景区域，利用显著性目标区域中相邻元素的相关性，对显著性图进一步的优化，得到最终的显著图。通过以上三个过程，可以有效的抑制背景信息的显示，突出显示显著性目标区域，图1为本文实验效果图。</p><p>图1. 算法效果</p></sec><sec id="s6"><title>2. 本文算法</title><p>本文首先对输入的图像进行预处理，然后通过聚类和区域分布规则来生成初始显著图，最后对初始显著图优化，得到最终的显著图，算法流程如图2所示。</p><p>图2. 算法流程</p><sec id="s6_1"><title>2.1. 初始显著图的构造</title><p>为了增加区域的连续性，减小算法的复杂度，本文采用SLIC (Simple Linear Iterative Clustering)超像素分割算法对图像进行预处理。SLIC算法是Achanta等人提出的一种性能较优的超像素分割算法，可以有效的把图像分割成轮廓清楚，区域均匀的像素块。根据人类视觉注意力特征和显著性研究发现，一般情况下，图像边界区域为显著性区域的可能性较低。也就是说，图像边界区域包含更多的背景信息。因此，本文基于此结论，提取图像的边界区域信息。将图片灰度化，选取图像边界的超像素(超像素标签)，去除边界之外的超像素，生成一副只剩下边缘的图像。但是直接把提取到的边界区域作为背景信息来生成显著图是不合理的，因为，显著性区域也有可能接触图像边界。为了得到有效的背景信息，减少显著性目标信息，利用K-means聚类算法对提取的边界信息进行处理，这样充分利用了背景的统计信息和结构信息。通过实验发现当聚类的数目为3时，检测的效果较理想。通过以上过程，可以得到3个特征聚类N(k), k ∈ { 1 , 2 , 3 } 。利用生成的三个聚类构造初始显著图。在构造显著图时，分别考虑每个超像素与3个特征聚类在颜色特征和空间分布的关系。</p><p>显著性目标区域一般更能引起人的视觉注意，与背景区域的特征分布相差较大。因此，本文利用每个像素与背景分布的差异性构造分布显著图。如果像素与N(k)分布距离较远，则该像素为显著性像素。采用欧氏距离度量像素的分布差异性。每个超像素的分布显著性图值DF<sup>k</sup>的计算如下：</p><p>D K i k = exp ( − ‖ d i − d k ‖ 2 α 2 ) ⋅ ∑ j = 1 m ( q i j − q k j ) 2 (1)</p><p>其中d<sub>i</sub>表示i个超像素的空间位置，参数α = 8，q<sub>ij</sub>表示i个超像素的向量特征，该特征是在CIELab颜色空间中由颜色和结构特征组成。q<sub>kj</sub>表示N(k)的质心， k ∈ { 1 , 2 , 3 } 。</p><p>通过上述计算可得3个基于背景信息分布的初始显著图。最后需要将三个显著性图融合成一个初始的显著图，融合方法如下：</p><p>S I S F = ∑ k = 1 3 β k &#215; D F k (2)</p><p>其中β<sub>k</sub>表示第k个分布图的权重，β<sub>k</sub>的计算方法如下：</p><p>β k = N ( k ) ∑ z = 1 3 N ( z ) (3)</p><p>每个特征聚类N(k)所包含的超像素数量是不同的，一般情况下，图像边界的超像素大部分属于背景，所以，包含超像素数量较大的N(k)更能表示背景。</p></sec><sec id="s6_2"><title>2.2. 保边滤波器对初始显著图进行初步优化</title><p>图像中显著性区域和背景区域之间有着比较明显的边缘分割，同时，如果一个区域被显著性区域包围，则这个区域为显著性区域的可能性较大。在初始的显著图中，显著性区域被加强凸显，与背景区域有着明显的区别。初始显著图中掺杂了大部分背景信息，为了抑制这些背景信息的显示，利用上述的先验知识，结合保边滤波器对初始显著图进行初步优化。在优化过程中，计算每个超像素的显著性值S<sub>po</sub>。</p><p>S p o = μ ( i ) ⋅ S I S F ( i ) + [ 1 − μ ( i ) ] ⋅ 1 n ∑ j = 1 n S I S F ( j ) (4)</p><p>其中，n是第j个超像素的相邻超像素的个数。 μ ( i ) 是一个判定第超像素是否与背景接触的因子，若与背景区域接触，值为1，否则为0。如果一个超像素与周围像素的差异性较大，则认为该超像素是显著性区域的边缘像素，否则不是。超像素与周围像素的差异性由方差来度量，方差可以显示该像素与周围像素的特征差异性，相同区域像素的特征差别小，方差小，不同区域差别较大，方差就大。</p></sec><sec id="s6_3"><title>2.3. 利用相邻像素的关系进一步优化S<sub>po</sub></title><p>虽然通过保边滤波器优化了显著性图，但是对于复杂性较高的图像来说，显著性图中还包含了较多的背景信息，为了进一步抑制背景信息的显示，本文提出了一种通过建立相邻元素之间关系进行优化的方法。一个区域一般与其周围的像素有很大的关联，可以根据一个超像素与其相邻超像素的差异性来确定其为显著性的概率，经过多次迭代计算相邻像素的关系来增强显著性区域。本文迭代次数设置为6，优化方法如下：</p><p>S δ + 1 = C ⋅ S δ + F ⋅ D ⋅ S δ (5)</p><p>其中，S<sup>1</sup> = S<sub>po</sub>，C是超像素之间的关系矩阵，D是基于最短路径的权值矩阵，F是影响因子矩阵， δ 是迭代次数。</p><p>超像素之间的关系矩阵C计算方式如下：</p><p>c i i = exp ( − s i ( 1 − s i ) θ 2 ) (6)</p><p>其中， i = 1 , ⋯ , M ， θ = 2 ，M是超像素的个数。</p><p>影响因子矩阵F计算方式如下：</p><p>f i j = { γ i j &#215; τ i j ,             i , j = 1 , ⋯ , M 0 ,                     i = j       or       otherwise (7)</p><p>其中， τ i j 是超像素i与j的位置关系， γ i j 是超像素的特征关系， γ i j = exp ( − ‖ q i − q j ‖ ρ 2 ) , ρ = 0.1 。</p><p>最短路径的权值矩阵D的计算如下：</p><p>d i j = exp ( d g e o 2 ( i , j ) 2 ε 2 ) (8)</p><p>其中， d g e o ( i , j ) = min b i = i , b 2 , ⋯ , b G = j ∑ l = 1 G − 1 d c ( b l , b l + 1 ) ，G是超像素i相邻超像素的个数， d c ( b l , b l + 1 ) 是相邻超像素的特征欧氏距离， ε = 10 。</p></sec></sec><sec id="s7"><title>3. 实验结果与分析</title><p>选用ECSSD和MSRA-1K数据集作为验证算法有效性的数据集，ECSSD和MSRA-1K数据集分别由1000张复杂的自然图像构成的数据集。实验平台为：Window 10 系统，i7-9750H CPU，Matlab 2018。实验参数设置：超像素分割数目为600。对比实验分别为wCtr_opt [<xref ref-type="bibr" rid="hanspub.40979-ref20">20</xref>]，SF [<xref ref-type="bibr" rid="hanspub.40979-ref21">21</xref>]，GS [<xref ref-type="bibr" rid="hanspub.40979-ref15">15</xref>]，MR [<xref ref-type="bibr" rid="hanspub.40979-ref22">22</xref>]。wCtr_opt是Zhu等人利用背景连通性和空间布局的特征提出地一种鲁棒性检测方法。SF是Perazzi等人基于对比度滤波提出的一种显著性区域检测方法。GS是Wei等人从背景先验出发，根据背景优先级提出的一种检测方法。MR是Yang等人利用流形排序思想，基于背景和前景的空间分布和连通性提出的一种检测方法。</p><sec id="s7_1"><title>3.1. 定性分析</title><p>图3是几种算法的实验效果图，其中Image是原图，GT是真值图，OUR是本文算法效果图。</p><p>图3. 不同算法的实验效果</p><p>第一幅图中的显著目标为树叶，背景区域中右上角和左下角区域颜色与树叶的颜色相近，容易被误检为显著性区域，可以从wCtr_opt、SF、GS算法的效果图看出，本文算法和MR算法很好地过滤了这些影响区域，但是本文算法检测出的目标轮廓比MR算法更清楚，更接近GT图。第二幅图中的显著区域为白马，第三幅显著目标为中间的大图标，从效果图可以看出，本文算法更加接近GT图。第四幅图的显著目标是两个黄色的路标，几个对比实验中，MR算法把目标区域包围的区域误检为背景区域，wCtr_opt、SF、GS算法的显著区域不清楚，或者包含背景区域，本文算法效果相比更好。第六幅图中的显著性区域包含与背景区域颜色相近的区域，四种对比算法的检测结果与GT相比，都不完整，本文算法很清楚的检测出整个目标区域，结果更加接近GT图。从实验效果图和分析得出，本文算法对细节的处理效果更好，更能完整的检测出显著性目标区域。</p></sec><sec id="s7_2"><title>3.2. 定量分析</title><p>定量分析评估指标选用精确度Precision、召回率Recall和综合评价指标F-measure。精确度是指正确分配的显著性像素的百分比，召回率是指分配的显著性像素相对于显著性像素的真实数量的比例。使用范围在[0, 255]内的不同阈值，将检测结果图与GT图二值化，并进行比较，得到精确度Precision和召回率Recall的值，绘制Precision-Recall (PR)曲线。综合评价指标F-measure由精确度Precision和召回率Recall计算得到，计算公式如下：</p><p>precision = | S T H ∩ GT | | S T H | (9)</p><p>recall = | S T H ∩ GT | | GT | (10)</p><p>F -measure = ( 1 + υ 2 ) &#215; Precisoon &#215; Recall υ 2 &#215; Precision + Recall (11)</p><p>其中， S T H 是检测结果的二值图， υ 2 = 0.3 。</p><p>图4、图5分别给出了五种算法在各数据集的PR曲线图和F-measure值条形图。从图4中可以看出，本文算法在两个数据集上的值均高于其他四种算法。图5中，本文算法的Precision、Recall和F-measure均高于其它算法，算法性能优异。</p><p>图4. 五种算法在2个数据集上的PR 曲线对比图</p><p>图5. 五种算法在2个数据集上的F-measure值对比图</p></sec><sec id="s7_3"><title>3.3. 算法时间复杂度对比</title><p>表1中给出了五种算法平均处理每幅图片需要的时间对比。由于本文算法在每次更新优化时，要不断搜索相邻元素来建立关系，更新的次数越多，花费的代价较高。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Algorithm running time comparison (unit: s</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >算法</th><th align="center" valign="middle" >wCtr_opt</th><th align="center" valign="middle" >SF</th><th align="center" valign="middle" >GS</th><th align="center" valign="middle" >MR</th><th align="center" valign="middle" >OUR</th></tr></thead><tr><td align="center" valign="middle" >时间</td><td align="center" valign="middle" >0.72</td><td align="center" valign="middle" >0.58</td><td align="center" valign="middle" >0.61</td><td align="center" valign="middle" >0.71</td><td align="center" valign="middle" >1.45</td></tr><tr><td align="center" valign="middle" >代码</td><td align="center" valign="middle" >Matlab</td><td align="center" valign="middle" >Matlab</td><td align="center" valign="middle" >Matlab</td><td align="center" valign="middle" >Matlab</td><td align="center" valign="middle" >Matlab</td></tr></tbody></table></table-wrap><p>表1. 算法运行时间对比 (单位：s)</p></sec></sec><sec id="s8"><title>4. 结束语</title><p>本文提出一种基于背景相邻关系优化的显著性检测方法，利用背景区域的统计特征信息和空间结构分布信息，建立相邻像素之间的关系，通过不断更新优化显著性区域来提高检测的准确性。在两种不同的数据集上进行测试，并与其他性能较好的算法对比，结果显示本文算法的效果更好，准确性较高。由于本文算法的时间较高，下一阶段将如何降低算法的时间，提高算法的效率作为研究。</p></sec><sec id="s9"><title>基金项目</title><p>国家自然科学基金项目(61801005)，安康学院校级项目(2019AYQJ03)，陕西省教育厅项目。</p></sec><sec id="s10"><title>文章引用</title><p>文雅宏. 基于背景信息优化的显著性目标检测Salient Object Detection Based on Background Information Optimization[J]. 计算机科学与应用, 2021, 11(03): 534-542. https://doi.org/10.12677/CSA.2021.113054</p></sec><sec id="s11"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.40979-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">张艺涵, 张朝晖, 霍丽娜, 解滨, 王秀青. 结合双流特征融合及对抗学习的图像显著性检测[J]. 计算机辅助设计与图形学学报, 2021(33): 1-10.</mixed-citation></ref><ref id="hanspub.40979-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">张荣国, 贾玉闪, 胡静, 刘小君, 李晓明. 超像素内容感知先验的多尺度贝叶斯显著性检测方法[J]. 电子学报, 2020, 48(8): 1509-1515.</mixed-citation></ref><ref id="hanspub.40979-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Qin, Y., Lu, H., Xu, Y. and Wang, H. (2015) Sa-liency Detection via Cellular Automata. 2015 IEEE Conference on Computer Vision and Pattern Recognition, Boston, 7-12 June 2015, 110-119.  
&lt;br&gt;https://doi.org/10.1109/CVPR.2015.7298606</mixed-citation></ref><ref id="hanspub.40979-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Liu, N., Han, J. and Yang, M.H. (2020) PiCANet: Pixel-Wise Contextual Attention Learning for Accurate Saliency Detection. IEEE Transactions on Image Processing, 29, 6438-6451. &lt;br&gt;https://doi.org/10.1109/TIP.2020.2988568</mixed-citation></ref><ref id="hanspub.40979-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Qiu, W., Gao, X. and Han, B. (2020) Saliency Detection using a Deep Conditional Random Field Network. Pattern Recognition, 103, Article ID: 107266. &lt;br&gt;https://doi.org/10.1016/j.patcog.2020.107266</mixed-citation></ref><ref id="hanspub.40979-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Cai, Y., Dai, L., Wang, H., Chen, L. and Li, Y. (2020) A Novel Saliency Detection Algorithm Based On Adversarial Learning Model. IEEE Transactions on Image Processing, 29, 4489-4504. &lt;br&gt;https://doi.org/10.1109/TIP.2020.2972692</mixed-citation></ref><ref id="hanspub.40979-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Zhang, J. and Sclaroff, S. (2013) Saliency Detection: A Boolean Map Approach. 2013 IEEE International Conference on Computer Vision, Sydney, 1-8 December 2013, 153-160. &lt;br&gt;https://doi.org/10.1109/ICCV.2013.26</mixed-citation></ref><ref id="hanspub.40979-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Zhang, T., Yang, Z. and Song, J. (2017) RGB-D Saliency Detection with Multi-Feature-Fused Optimization. 2017 International Conference on Image and Graphics, Shanghai, 13-15 September 2017, 15-26.  
&lt;br&gt;https://doi.org/10.1007/978-3-319-71598-8_2</mixed-citation></ref><ref id="hanspub.40979-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">崔丽群, 陈晶晶, 任茜钰, 王柏涵. 融合多特征与先验信息的显著性目标检测[J]. 中国图象图形学报, 2020, 25(2): 321-332.</mixed-citation></ref><ref id="hanspub.40979-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">李东民, 李静, 梁大川, 王超. 基于多尺度先验深度特征的多目标显著性检测方法[J]. 自动化学报, 2019, 45(11): 2058-2070.</mixed-citation></ref><ref id="hanspub.40979-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Zhang, M., Pang, Y., Wu, Y., Du, Y., Sun, H. and Zhang, K. (2018) Saliency Detection via Local Structure Propagation. Journal of Visual Com-munication and Image Representation, 52, 131-142.  
&lt;br&gt;https://doi.org/10.1016/j.jvcir.2018.01.004</mixed-citation></ref><ref id="hanspub.40979-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">庞珍珍. 显著性目标检测轮廓增强技术研究[J]. 计算机科学与应用, 2018, 8(1): 107-113.</mixed-citation></ref><ref id="hanspub.40979-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">王烨蕾, 李玲, 辛云宏. 基于分层PCA技术的显著性目标检测算法[J]. 计算机科学与应用, 2018, 8(3): 398-409.</mixed-citation></ref><ref id="hanspub.40979-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">Achanta, R., Hemami, S., Estrada, F. and Susstrunk, S. (2009) Frequen-cy-Tuned Salient Region Detection. IEEE International Conference on Computer Vision and Pattern Recognition, Miami, 20-25 June 2009, 1597-1604.  
&lt;br&gt;https://doi.org/10.1109/CVPR.2009.5206596</mixed-citation></ref><ref id="hanspub.40979-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">Wei, Y., Wen, F., Zhu, W. and Sun, J. (2012) Geodesic Sali-ency Using Background Priors. European Conference on Computer Vision, Florence, 7-13 October 2017, 29-42. &lt;br&gt;https://doi.org/10.1007/978-3-642-33712-3_3</mixed-citation></ref><ref id="hanspub.40979-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">Lang, C., Liu, G., Yu, J. and Yan, S. (2012) Saliency Detection by Multitask Sparsity Pursuit. IEEE Transactions on Image Processing A Publication of the IEEE Signal Processing So-ciety, 21, 1327-1338.  
&lt;br&gt;https://doi.org/10.1109/TIP.2011.2169274</mixed-citation></ref><ref id="hanspub.40979-ref17"><label>17</label><mixed-citation publication-type="other" xlink:type="simple">Shen, X. and Wu, Y. (2012) A Unified Approach to Salient Object Detection via Low Rank Matrix Recovery. IEEE Conference on Computer Vision &amp; Pattern Recognition, Providence, 16-21 June 2012, 853-860.</mixed-citation></ref><ref id="hanspub.40979-ref18"><label>18</label><mixed-citation publication-type="other" xlink:type="simple">Xie, Y., Lu, H. and Yang, M.H. (2013) Bayesian Saliency via Low and Mid Level Cues. IEEE Transactions on Image Processing, 22, 1689-1698. &lt;br&gt;https://doi.org/10.1109/TIP.2012.2216276</mixed-citation></ref><ref id="hanspub.40979-ref19"><label>19</label><mixed-citation publication-type="other" xlink:type="simple">Huang, K., Zhang, Y., Lv, B. and Shi, Y. (2017) Salient Object Detection Based on Background Feature Clustering. Advances in Multimedia, 2017, Article ID: 4183986. &lt;br&gt;https://doi.org/10.1155/2017/4183986</mixed-citation></ref><ref id="hanspub.40979-ref20"><label>20</label><mixed-citation publication-type="other" xlink:type="simple">Zhu, W.J., Liang, S., Wei, Y.C. and Sun, J. (2014) Saliency Optimiza-tion from Robust Background Detection. 2014 IEEE Conference on Computer Vision and Pattern Recognition, Colum-bus, 23-28 June 2014, 2814-2821.  
&lt;br&gt;https://doi.org/10.1109/CVPR.2014.360</mixed-citation></ref><ref id="hanspub.40979-ref21"><label>21</label><mixed-citation publication-type="other" xlink:type="simple">Perazzi, F., Krahenbuhl, P., Pritch, Y. and Hornung, A. (2012) Sa-liency Filters: Contrast Based Filtering for Salient Region Detection. 2012 IEEE Conference on Computer Vision and Pattern Recognition, Providence, 16-21 June 2012, 733-740. &lt;br&gt;https://doi.org/10.1109/CVPR.2012.6247743</mixed-citation></ref><ref id="hanspub.40979-ref22"><label>22</label><mixed-citation publication-type="other" xlink:type="simple">Yang, C., Zhang, L., Lu, H., Ruan, X. and Yang, M.-H. (2013) Saliency Detection via Graph-Based Manifold Ranking. 2013 IEEE Conference on Computer Vision and Pattern Recog-nition, Portland, 23-28 June 2013, 3166-3173.  
&lt;br&gt;https://doi.org/10.1109/CVPR.2013.407</mixed-citation></ref></ref-list></back></article>