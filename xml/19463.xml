<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">JISP</journal-id><journal-title-group><journal-title>Journal of Image and Signal Processing</journal-title></journal-title-group><issn pub-type="epub">2325-6753</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/JISP.2017.61005</article-id><article-id pub-id-type="publisher-id">JISP-19463</article-id><article-categories><subj-group subj-group-type="heading"><subject>JISP20170100000_84012381.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于BING和HOG-LSS特征的行人检测算法研究
  Research on Pedestrian Detection Algorithm Based on BING and HOG-LSS Feature
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>赵</surname><given-names>朝华</given-names></name><xref ref-type="aff" rid="aff1"><sub>1</sub></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib></contrib-group><aff id="aff1"><label>1</label><addr-line>四川大学计算机学院，四川 成都；视觉合成图形图像技术国家重点学科实验室，四川 成都</addr-line></aff><author-notes><corresp id="cor1">* E-mail:<email>853906141@qq.com</email></corresp></author-notes><pub-date pub-type="epub"><day>13</day><month>12</month><year>2016</year></pub-date><volume>06</volume><issue>01</issue><fpage>37</fpage><lpage>43</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   近年来，基于计算机视觉技术的行人检测方法一直是智能交通领域研究的热点问题之一。基于HOG和局部自相似(LSS)特征融合的行人检测算法在检测效果上优于传统HOG特征的行人检测算法，但是同时也存在如下挑战：1) 算法检测的速度不够快；2) 在遮挡面积过大的情况下，无法有效地进行处理。针对这些挑战问题，本文提出了一种使用BING特征、HOG-LSS特征和数据轨迹融合的行人检测优化框架，并通过对实验结果进行验证可知，检测效果优于HOG-LSS特征的行人检测方法。 In recent years, pedestrian detection, based on computer vision, has been one of the hottest topics in the field of intelligent transportation. The pedestrian detection algorithm, based on HOG and local self-similarity (LSS) feature fusion, is better than the traditional HOG detection algorithm, and also it has the following challenges: 1) low efficiency; 2) failing to effectively handle the occlusion problem. Aiming at these challenges, this paper proposes a pedestrian detection optimization framework based on BING feature, HOG-LSS feature and data trajectory fusion. It is proved that the detection result is superior to the HOG-LSS pedestrian detection method.
    
  
 
</p></abstract><kwd-group><kwd>行人检测，BING特征，HOG-LSS特征，数据轨迹融合, Pedestrian Detection</kwd><kwd> BING Feature</kwd><kwd> HOG-LSS Feature</kwd><kwd> Data Association</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>基于BING和HOG-LSS特征的行人检测 算法研究<sup> </sup></title><p>赵朝华<sup>1,2</sup></p><p><sup>1</sup>四川大学计算机学院，四川 成都</p><p><sup>2</sup>视觉合成图形图像技术国家重点学科实验室，四川 成都</p><disp-formula id="hanspub.19463-formula216"><graphic xlink:href="http://html.hanspub.org/file/5-2670098x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>收稿日期：2016年12月17日；录用日期：2016年12月31日；发布日期：2017年1月5日</p><disp-formula id="hanspub.19463-formula217"><graphic xlink:href="http://html.hanspub.org/file/5-2670098x7_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>近年来，基于计算机视觉技术的行人检测方法一直是智能交通领域研究的热点问题之一。基于HOG和局部自相似(LSS)特征融合的行人检测算法在检测效果上优于传统HOG特征的行人检测算法，但是同时也存在如下挑战：1) 算法检测的速度不够快；2) 在遮挡面积过大的情况下，无法有效地进行处理。针对这些挑战问题，本文提出了一种使用BING特征、HOG-LSS特征和数据轨迹融合的行人检测优化框架，并通过对实验结果进行验证可知，检测效果优于HOG-LSS特征的行人检测方法。</p><p>关键词 :行人检测，BING特征，HOG-LSS特征，数据轨迹融合</p><disp-formula id="hanspub.19463-formula218"><graphic xlink:href="http://html.hanspub.org/file/5-2670098x8_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s3"><title>1. 引言</title><p>行人检测，顾名思义，就是把图像或视频中出现的行人从背景中分割出来，并精确定位。近年来，基于计算机视觉技术的行人检测方法一直是智能交通领域研究的热点问题之一，除此之外，它还广泛的应用于智能监控领域，对视频监控场景区域内的可疑人物或事件进行检测、识别和报警，可以有效的阻止犯罪和异常事件的发生。另外，行人检测在人机交互、虚拟现实、医学图像、机器人视觉导航等也应用非常广泛。</p><p>目前，行人检测方法主要有背景差分和帧间差分的行人检测方法、模板匹配的行人检测方法、基于光流的行人检测方法以及基于机器学习的行人检测，由于利用机器学习的思想来解决由环境变化、行人衣着和形态变化给检测带来的影响，所以这种行人检测方法已经成为视频行人检测领域中最活跃的主流研究方向，它主要包括特征提取和机器学习两部分。2005年，Dalal [<xref ref-type="bibr" rid="hanspub.19463-ref1">1</xref>] 等提出了梯度方向直方图(histograms of oriented gradient, HOG)特征和支持向量机(support vector machine, SVM)分类器的行人检测方法，并试验中取得了很好的表现，但是对于遮挡和复杂背景下的行人检测效果差，所以随之又有一些新的论文的出现 [<xref ref-type="bibr" rid="hanspub.19463-ref2">2</xref>] [<xref ref-type="bibr" rid="hanspub.19463-ref3">3</xref>] [<xref ref-type="bibr" rid="hanspub.19463-ref4">4</xref>] ，比如局部自相似(local self-similar, LSS)特征 [<xref ref-type="bibr" rid="hanspub.19463-ref5">5</xref>] 就是通过捕捉图像颜色自相似性、边缘特征和重复模板以及复杂的纹理来计算两幅图像的相似性。在行人检测上的分类器主要有SVM和AdaBoost两种，Maji [<xref ref-type="bibr" rid="hanspub.19463-ref6">6</xref>] 等采用了一种新的核SVM方法来检测行人，叫做直方图交叉核SVM (histogram intersection kernel support vector machine, HIKSVM)，这种方法不但可以快速检测到行人，并且检测精度还有提升。朱文佳等提出了一种Gentle Adaboost的分类方法，且成功地应用到行人检测上。种衍文等 [<xref ref-type="bibr" rid="hanspub.19463-ref7">7</xref>] 提出的采用多特征结合Adaboost和SVM的两级行人检测算法，也取得了不错的效果。</p><p>但是，由于原有的算法存在速度不够快且无法有效的处理遮挡等问题，所以本文提出了基于BING (binarized normed gradients, BING)特征 [<xref ref-type="bibr" rid="hanspub.19463-ref8">8</xref>] 和HOG-LSS特征的数据轨迹融合的行人检测优化框架。实验证明，该框架不仅能改进现有的行人检测算法的检测性能，还能大大提高检测速度。</p></sec><sec id="s4"><title>2. 本文的行人检测框架与以前框架对比</title><p>如图1所示，传统的行人检测框架是直接利用行人检测算法(HOG-LSS)对输入图片进行检测，再输出结果。但是，如图2所示，对于使用BING特征和数据融合的行人检测优化框架针对HOG-LSS速度不够快的问题，可以优化成三个步骤：1) 首先，使用BING进行粗检测，在保证精度的前提之前快速过滤</p><p>掉大部分候选窗口；2) 其次，再使用HOG-LSS进行精确检测，在去掉大量候选窗口之后，能够减少窗口检测数量；3) 最后，使用轨迹融合的方法，将属于同一个目标的多个轨迹片段融合在一起，并且依据完整轨迹更新检测结果。</p></sec><sec id="s5"><title>3. 本文的行人检测特征</title><sec id="s5_1"><title>3.1. BING特征的使用</title><p>传统方法的目标检测和行人检测大都是使用滑动窗口(图3)，先学习大量的样本，以获得学习结果，然后用不同的框遍历需测试的图片，并将遍历的框中内容依次与学习结果比对，再确定框中是否存在此物体。对于一副大小为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x9_hanspub.png" xlink:type="simple"/></inline-formula>的图片来说，可能的子窗口就有<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x10_hanspub.png" xlink:type="simple"/></inline-formula>个，从算法本身来说，这就极大限制了目标检测系统的实时性。但是如果基于一种先验知识——人是一种具有封闭性特点的“物体”，就可以快速的从<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x11_hanspub.png" xlink:type="simple"/></inline-formula>个窗口中过滤掉绝大部分，然后再用特征和分类器对剩余的窗口进行行人检测，就可以在保证精度的同时，提高检测的速率。</p><p>人们观察事物都有一个习惯：先粗看，再细看。粗看是分辨视野中是否有物体，快速过滤掉视野中大部分的其他部分窗口，得到一个相对较小的窗口集合，细看则是仔细分辨物体是什么，并且在图片或视频帧中，物体对象是具有良好的封闭边界，而背景则是杂乱无章的。行人检测就是在图片或视频帧中检测哪些位置出现了人(如果把人也看作是一种“物体”)。BING检测就是这样一种“粗略检测”的方法，先将目标的大概位置检测出来，这是提速的过程。在Cheng [<xref ref-type="bibr" rid="hanspub.19463-ref8">8</xref>] 提出的BING目标检测中，将训练图像采</p><p>图1. 传统的行人检测框架</p><p>图2. 本文的行人检测框架</p><p>图3. 左图为滑动窗口方法，右图为一般普通物体检测方法</p><p>集若干个窗口并调整为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x16_hanspub.png" xlink:type="simple"/></inline-formula>的大小，提取BING特征，然后将<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x17_hanspub.png" xlink:type="simple"/></inline-formula>的矩阵向量化为64维的特征向量，用SVM分类器进行训练。</p><p>Cheng [<xref ref-type="bibr" rid="hanspub.19463-ref8">8</xref>] 的方法之所以会有如此快速的检测表现，主要是由于有以下三个特点：1) 大胆地将图像缩小为36种大小不同的图像，然后用<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x18_hanspub.png" xlink:type="simple"/></inline-formula>的模板进行匹配，使其在滑动图像匹配时少了数倍，并且物体的结构轮廓信息存在，所以不会影响检测结果；2) 特征维数低，只有64维；3) 将特征二值化，64维的特征值刚好可以使用一个64位(int64)的整型数据结构来存储，从而可以使用二进制的位处理大大加速运算。</p><p>本文的行人检测算法使用Cheng [<xref ref-type="bibr" rid="hanspub.19463-ref8">8</xref>] 的BING特征对输入图片进行粗检测，与Cheng [<xref ref-type="bibr" rid="hanspub.19463-ref8">8</xref>] 的“一般物体”的检测有所区别：1) 训练的正样本集不同，本文训练的正样本集只包含行人的图片集；2) 行人具有固定的高宽比，因此不必考虑过多的高宽比变化。</p></sec><sec id="s5_2"><title>3.2. HOG-LSS特征的使用</title><p>HOG特征是一种常用于计算机视觉与图像处理中进行物体检测的特征描述器，它的步骤是1) 首先将图像分成联通的区域(cell)；2) 然后收集cell中每个像素的梯度构成方向直方图；3) 再将直方图组合成特征描述子。</p><p>LSS特征是用来捕捉图像间的自相似性，当存在小规模的形变的时候，LSS特征通过捕捉颜色、边缘、重复图样和复杂纹理的自相似性，从而匹配图像。</p><p>利用LSS特征的这种自相似性，再结合HOG特征，来辅助区分行人和非行人目标，从而可以降低误检漏检率。本文采用串行特征组合方法，形如式子(1)所示：</p><disp-formula id="hanspub.19463-formula219"><label>(1)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-2670098x19_hanspub.png"  xlink:type="simple"/></disp-formula><p>式中，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x20_hanspub.png" xlink:type="simple"/></inline-formula>表示HOG特征，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x21_hanspub.png" xlink:type="simple"/></inline-formula>表示LSS特征。将LSS特征作为辅助检测，与HOG特征在降维后融合，从而在不增加计算量的基础上能降低传统算法的误检漏检率。</p></sec></sec><sec id="s6"><title>4. 数据融合</title><p>本文的数据融合也称为轨迹融合，它是为了解决这样的问题：对于一组轨迹片段，这组轨迹片段长度各不相同，且没有目标的外观信息，我们解决的目标是将属于同一图片目标的轨迹融合在一起。此处有三个挑战：1) 目标遮挡；2) 缺乏外观信息；3) 目标和摄像机的移动。为了解决这些挑战，我们可以将数据融合问题看成是一个广义线性分配的问题(Generalized Linear Assignment, GLA)，使用动态相似性来求解。</p><sec id="s6_1"><title>4.1. 广义线性分配(GLA)问题</title><p>假如给定N个轨迹片段<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x22_hanspub.png" xlink:type="simple"/></inline-formula>，线性分配(LA)可以看作是如下的优化问题：</p><disp-formula id="hanspub.19463-formula220"><graphic xlink:href="http://html.hanspub.org/file/5-2670098x23_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中，</p><disp-formula id="hanspub.19463-formula221"><label>(2)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-2670098x24_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x25_hanspub.png" xlink:type="simple"/></inline-formula>表示轨迹片段<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x26_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x27_hanspub.png" xlink:type="simple"/></inline-formula>之间的某种相似度(后面介绍具体的相似性计算方法)，所以P是一个前驱–后继矩阵，表明其中相邻片段之间的相似性。例如，当<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x28_hanspub.png" xlink:type="simple"/></inline-formula>不可能是<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x29_hanspub.png" xlink:type="simple"/></inline-formula>的后继片段时，P可以表示为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x30_hanspub.png" xlink:type="simple"/></inline-formula>；当<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x31_hanspub.png" xlink:type="simple"/></inline-formula>可能是<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x32_hanspub.png" xlink:type="simple"/></inline-formula>的后继片段时，P表示为大于0的数字。优化变量<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x33_hanspub.png" xlink:type="simple"/></inline-formula>表示当<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x34_hanspub.png" xlink:type="simple"/></inline-formula>时，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x35_hanspub.png" xlink:type="simple"/></inline-formula>是<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x36_hanspub.png" xlink:type="simple"/></inline-formula>的前驱轨迹，这样的轨迹将会合并在一起。</p><p>由于式子(2)中使用的条件 [<xref ref-type="bibr" rid="hanspub.19463-ref9">9</xref>] 是必须使得每个轨迹片段分配一个前驱轨迹和一个后继轨迹，为了避免这个要求，本文使用GLA的另一个式子(3)，如下：</p><disp-formula id="hanspub.19463-formula222"><graphic xlink:href="http://html.hanspub.org/file/5-2670098x37_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中，</p><disp-formula id="hanspub.19463-formula223"><label>(3)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-2670098x38_hanspub.png"  xlink:type="simple"/></disp-formula><p>GLA与LA的主要区别就是，在GLA中，并没有强制规定每个片段必须与其他轨迹片段结合起来，但是却导致了两个重要结果：1) 避免设置源节点和学习轨迹的入口和终止概率；2) GLA是一个NP完全问题，解起来比LA复杂。但是，在非常弱的约束条件下，这个问题可以用文献 [<xref ref-type="bibr" rid="hanspub.19463-ref4">4</xref>] [<xref ref-type="bibr" rid="hanspub.19463-ref10">10</xref>] 中的softassign算法来求解。</p></sec><sec id="s6_2"><title>4.2. 基于动态的相似性计算</title><p>轨迹片段<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x39_hanspub.png" xlink:type="simple"/></inline-formula>由一组有序序列<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x40_hanspub.png" xlink:type="simple"/></inline-formula>组成，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x41_hanspub.png" xlink:type="simple"/></inline-formula>。其中，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x42_hanspub.png" xlink:type="simple"/></inline-formula>表示候选行人窗口中心点的坐标s表示轨迹片段的开始时间，e表示轨迹片段的结束时间，并且轨迹片段的动态性可以用线性回归来表示：</p><disp-formula id="hanspub.19463-formula224"><label>(4)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-2670098x43_hanspub.png"  xlink:type="simple"/></disp-formula><p>在没有噪声的情况下，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x44_hanspub.png" xlink:type="simple"/></inline-formula>，其中，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x45_hanspub.png" xlink:type="simple"/></inline-formula>表示矩阵的秩，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x46_hanspub.png" xlink:type="simple"/></inline-formula>是一个<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x47_hanspub.png" xlink:type="simple"/></inline-formula>列的汉克尔(Hankel)矩阵：</p><disp-formula id="hanspub.19463-formula225"><label>(5)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-2670098x48_hanspub.png"  xlink:type="simple"/></disp-formula><p>所以轨迹片段<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x49_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x50_hanspub.png" xlink:type="simple"/></inline-formula>之间的基于动态的相似度<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x51_hanspub.png" xlink:type="simple"/></inline-formula>可以用如下的公式来表示：</p><disp-formula id="hanspub.19463-formula226"><label>(6)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-2670098x52_hanspub.png"  xlink:type="simple"/></disp-formula><p>式中，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x53_hanspub.png" xlink:type="simple"/></inline-formula>表示轨迹片段<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x54_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x55_hanspub.png" xlink:type="simple"/></inline-formula>之间的联合轨迹，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x56_hanspub.png" xlink:type="simple"/></inline-formula>表示轨迹片段<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x57_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x58_hanspub.png" xlink:type="simple"/></inline-formula>之间的间隔轨迹。式子(6)表示，如果两个轨迹片段<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x59_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x60_hanspub.png" xlink:type="simple"/></inline-formula>是属于同一个目标的轨迹，则他们的联合轨迹可以通过低秩的线性回归来表示；相反，如果两个轨迹片段属于不同目标的轨迹，则他们的联合轨迹必须使用高秩的线性回归来表示。因此，如果<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x61_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x62_hanspub.png" xlink:type="simple"/></inline-formula>，则<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x63_hanspub.png" xlink:type="simple"/></inline-formula>。相应地，如果两个轨迹片段<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x64_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x65_hanspub.png" xlink:type="simple"/></inline-formula>同属于一条轨迹，则有<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x66_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x67_hanspub.png" xlink:type="simple"/></inline-formula>；同时，相反地如果两个轨迹片段<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x68_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x69_hanspub.png" xlink:type="simple"/></inline-formula>不属于一条轨迹，则有<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x70_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x71_hanspub.png" xlink:type="simple"/></inline-formula>。</p></sec></sec><sec id="s7"><title>5. 更新结果</title><p>通过轨迹融合得到每个行人的完整轨迹之后，就可以用完整轨迹更新检测结果，这其中就包括推测行人位置以及修正检测得分两部分。</p><sec id="s7_1"><title>5.1. 推测行人位置</title><p>图4所示是某个行人的完整轨迹，由于遮挡等原因，在<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x72_hanspub.png" xlink:type="simple"/></inline-formula>期间行人检测器没有检测到该行人，</p><p>图4. t<sub>3</sub>时刻行人位置推测</p><p>但是通过轨迹融合可以得到轨迹片段<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x74_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x75_hanspub.png" xlink:type="simple"/></inline-formula>属于同一条轨迹，因此我们可以依据在<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x76_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x77_hanspub.png" xlink:type="simple"/></inline-formula>时刻该行人的位置推测出<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x78_hanspub.png" xlink:type="simple"/></inline-formula>时刻该行人的位置。</p><disp-formula id="hanspub.19463-formula227"><label>(7)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-2670098x79_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x80_hanspub.png" xlink:type="simple"/></inline-formula>表示t时刻该行人的矩形框。</p></sec><sec id="s7_2"><title>5.2. 修正检测得分</title><p>如果一条检测轨迹上的候选窗口的平均得分越高，就越有可能包含行人，因为整体上来说，包含行人目标的窗口的检测得分比背景窗口上的检测得分要高。因此，可以使用如下的公式来修正检测得分：</p><disp-formula id="hanspub.19463-formula228"><label>(8)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/5-2670098x81_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x82_hanspub.png" xlink:type="simple"/></inline-formula>表示候选行人窗口的原始检测得分，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x83_hanspub.png" xlink:type="simple"/></inline-formula>表示候选窗口中行人窗口修正后的检测得分，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x84_hanspub.png" xlink:type="simple"/></inline-formula>表示轨迹中所有候选行人窗口检测得分的平均值，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/5-2670098x85_hanspub.png" xlink:type="simple"/></inline-formula>是一个权重系数，这里取值为0.75。</p></sec></sec><sec id="s8"><title>6. 实验结果与分析</title><p>本文实验数据集采用的数据库是TUD-Brussels数据库和ETH数据库，这两个数据库都是视频中提取出来的连续帧，也是行人检测常用的数据集，吻合本文的需求。同时，本文采用评价标准是使用误检率和漏检率曲线，来衡量检测器的性能。其中，误检率表示分类结果为正例行人目标，而实际上为负例行人目标；而漏检率为测试集为正例但是判别为负例的数目/测试集中正例的数目。在误检率一定的情况下，漏检率越低检测性能越好；相反，漏检率越高检测性能越差。为简单起见，本文选取误检测率为 时的漏检率值来作为检测器性能的衡量。</p><p>表1是原始的HOG-LSS方法和本文的方法的检测性能和速度的对比。其中，“HOG-LSS”表示原始的检测器，“BING + HOGLSS + TRACK”表示本文的方法。从实验结果可以看出，对比于原始的HOG-LSS算法，本文的算法不仅可以大大提高检测速度，在提升检测性能上还有不错的表现。</p></sec><sec id="s9"><title>7. 总结</title><p>本文在HOG-LSS基础上，提出了一种基于BING和数据轨迹融合的行人检测框架优化方案。该检测框架主要针对于HOG-LSS检测速度不够快而引入一个粗检测的过程，这种粗检测可以在保证检测精度的前提之下，快速的过滤掉大部分候选行人窗口，从而有效的减少HOG-LSS算法进行检测的时间。同时，针对检测算法无法有效地解决遮挡的问题，利用数据轨迹融合的思想，将属于同一个目标的多个轨迹片段融合在一起，依据完整的轨迹更新检测结果。从结果来看，实验证明本文的方法不仅可以大大提</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Comparison of experimental results for each classifie</title></caption><table><tbody><thead><tr><th align="center" valign="middle"  rowspan="2"  >检测算法</th><th align="center" valign="middle"  colspan="2"  >TUD-Brussels数据集</th><th align="center" valign="middle"  colspan="2"  >ETH数据集</th></tr></thead><tr><td align="center" valign="middle" >速度(s)</td><td align="center" valign="middle" >漏检率(%)</td><td align="center" valign="middle" >速度(s)</td><td align="center" valign="middle" >漏检率(%)</td></tr><tr><td align="center" valign="middle" >HOG-LSS</td><td align="center" valign="middle" >2.06</td><td align="center" valign="middle" >67.71</td><td align="center" valign="middle" >2.56</td><td align="center" valign="middle" >50.16</td></tr><tr><td align="center" valign="middle" >BING + HOGLSS + TRACK</td><td align="center" valign="middle" >0.14</td><td align="center" valign="middle" >64.32</td><td align="center" valign="middle" >0.15</td><td align="center" valign="middle" >45.21</td></tr></tbody></table></table-wrap><p>表1. 各分类器实验结果对比</p><p>高检测的速度，还可以提升检测性能。在未来的研究中，将更加侧重于研究基于行人的运动轨迹建模，在进一步降低误检率和漏检率的基础上，进行行人识别跟踪和行人姿态方面等的研究。</p></sec><sec id="s10"><title>文章引用</title><p>赵朝华. 基于BING和HOG-LSS特征的行人检测算法研究 Research on Pedestrian Detection Algorithm Based on BING and HOG-LSS Feature[J]. 图像与信号处理, 2017, 06(01): 37-43. http://dx.doi.org/10.12677/JISP.2017.61005</p></sec><sec id="s11"><title>参考文献 (References)</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.19463-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Dalal, N. and Triggs, B. (2005) Histograms of Oriented Gradients for Human Detection. 2005 IEEE Conference on Computer Vision and Pattern Recognition, San Diego, 886-893. https://doi.org/10.1109/CVPR.2005.177</mixed-citation></ref><ref id="hanspub.19463-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">王孝艳, 张艳珠, 董慧颖, 等. 运动目标检测的三帧差法算法研究[J]. 沈阳理工大学学报, 2011, 30(6): 82-85, 91.</mixed-citation></ref><ref id="hanspub.19463-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Yan, J.J., Zhen, L., Dong, Y. and Li, Z.S. (2012) Multi-Pedestrian Detection in Crowded Scenes: A Global View. 2012 IEEE Conference on Computer Vision and Pattern Recognition, Rhode Island, 3124-3129.</mixed-citation></ref><ref id="hanspub.19463-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Shao, H., Chen, S., et al. (2015) Face Recognition Based on Subset Selection via Metric Learning on Manifold. Frontiers of Information Technology &amp; Electronic Engineering, 16, 1046-1058. https://doi.org/10.1631/FITEE.1500085</mixed-citation></ref><ref id="hanspub.19463-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Yao, S.H., Pan, S.M., et al. (2015) A New Pedestrian Detection Method Based on Combined HOG and LSS Features. Neurocomputing, 151, 1006-1014. https://doi.org/10.1016/j.neucom.2014.08.080</mixed-citation></ref><ref id="hanspub.19463-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Maji, S., Berg, A.C. and Malik, J. (2013) Efficient Classification for Additive Kernel SVMs. IEEE Transactions on Pattern Analysis and Machine Intelligence, 35, 66-77. https://doi.org/10.1109/TPAMI.2012.62</mixed-citation></ref><ref id="hanspub.19463-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">种衍文, 匡湖林, 李清泉. 一种基于多特征和机器学习的分级行人检测方法[J]. 自动化学报, 2012, 38(3): 375- 381.</mixed-citation></ref><ref id="hanspub.19463-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Cheng, M.M., Zhang, Z., Lin, W.Y., et al. (2014) BING: Binarized Normed Gradients for Objectness Estimation at 300 fps. 2014 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 3286-3293.  
https://doi.org/10.1109/CVPR.2014.414</mixed-citation></ref><ref id="hanspub.19463-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Zhang, L., Li, Y. and Nevatia, R. (2008) Global Data Association for Multi-Object Tracking Using Network Flows. IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Anchorage, 24-26 June 2008, 1-8.  
https://doi.org/10.1109/cvpr.2008.4587584</mixed-citation></ref><ref id="hanspub.19463-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Gold, S. and Rangarajan, A. (1996) Softmax to Softassign: Neural Network Algorithms for Combinatorial Optimization. Journal of Artificial Neural Networks, 2, 381-399.</mixed-citation></ref></ref-list></back></article>