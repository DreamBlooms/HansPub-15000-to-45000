<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">AIRR</journal-id><journal-title-group><journal-title>Artificial Intelligence and Robotics Research</journal-title></journal-title-group><issn pub-type="epub">2326-3415</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/AIRR.2015.42002</article-id><article-id pub-id-type="publisher-id">AIRR-15342</article-id><article-categories><subj-group subj-group-type="heading"><subject>AIRR20150200000_69614190.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject><subject> 工程技术</subject></subj-group></article-categories><title-group><article-title>
 
 
  狭隘环境下一种多机器人路径规划方法
  A Multi-Robot Path Planning Method under Narrow Environments
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>邵</surname><given-names>杰</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>于</surname><given-names>景茹</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib></contrib-group><aff id="aff1"><addr-line>郑州成功财经学院信息工程系，河南 郑州</addr-line></aff><aff id="aff2"><addr-line>null</addr-line></aff><author-notes><corresp id="cor1">* E-mail:<email>sj012328@163.com(邵杰)</email>;</corresp></author-notes><pub-date pub-type="epub"><day>29</day><month>05</month><year>2015</year></pub-date><volume>04</volume><issue>02</issue><fpage>9</fpage><lpage>16</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   狭隘环境下多机器人路径规划使用共享资源时，极易产生冲突，优先顺序化是解决共享资源冲突的一个重要技术。本文提出了一种基于学习分类器的动态分配优先权的方法，提高机器人团队的性能。首先机器人通过XCS优化各自的行为，然后引入和训练高水平的机器人管理者来分配优先权解决冲突。本方法适用于部分可知的Markov环境，仿真实验结果表明本文所提方法用于解决多机器人的路径规划冲突是有效的，提高了多机器人系统解决路径规划冲突的能力。 Under narrow environments, conflict easily occurs when multi-robot path planning uses shared resources, and prioritisation is an important technology to solve this problem. This paper pre- sents a dynamic allocation priority method based on learning classifier to improve the perfor-mance of the robot team. Firstly robots optimize their behaviors by XCS, and then high-level robot managers are introduced and trained to resolve conflicts by assigning priority. The novel approach is designed for partially observable Markov decision process environments. Simulation results show that the method presented is effective to solve the conflict in multi-robot path planning and improves the capacity of multi-robot path planning.
    
  
 
</p></abstract><kwd-group><kwd>路径规划，多机器人，学习分类器，遗传算法，Q学习, Path Planning</kwd><kwd> Multi-Robot</kwd><kwd> Learning Classifier System</kwd><kwd> Genetic Algorithm</kwd><kwd> Q Learning</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>狭隘环境下一种多机器人路径规划方法<sup> </sup></title><p>邵杰，于景茹</p><p>郑州成功财经学院信息工程系，河南 郑州</p><p>Email: sj012328@163.com</p><p>收稿日期：2015年5月10日；录用日期：2015年5月24日；发布日期：2015年5月29日</p><disp-formula id="scirp.15342-formula680"><graphic xlink:href="http://html.hanspub.org/file/1-2610058x5_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>狭隘环境下多机器人路径规划使用共享资源时，极易产生冲突，优先顺序化是解决共享资源冲突的一个重要技术。本文提出了一种基于学习分类器的动态分配优先权的方法，提高机器人团队的性能。首先机器人通过XCS优化各自的行为，然后引入和训练高水平的机器人管理者来分配优先权解决冲突。本方法适用于部分可知的Markov环境，仿真实验结果表明本文所提方法用于解决多机器人的路径规划冲突是有效的，提高了多机器人系统解决路径规划冲突的能力。</p><p>关键词 :路径规划，多机器人，学习分类器，遗传算法，Q学习</p><disp-formula id="scirp.15342-formula681"><graphic xlink:href="http://html.hanspub.org/file/1-2610058x6_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s3"><title>1. 引言</title><p>近年来，多机器人路径规划已成为机器人领域中的一个热点问题。根据机器人对环境的了解程度，可以分为两种类型：环境信息完全已知的全局规划和环境信息完全未知或部分未知的局部路径规划[<xref ref-type="bibr" rid="scirp.15342-ref1">1</xref>] [<xref ref-type="bibr" rid="scirp.15342-ref2">2</xref>] 。多机器人路径规划是为均处在同一个简单或复杂，静态或动态，已知或未知的工作空间中的每个机器人找到一条路径，能避开障碍物并能保证机器人之间无碰撞，最后以最小或较小的消耗完成自己的任务[<xref ref-type="bibr" rid="scirp.15342-ref3">3</xref>] [<xref ref-type="bibr" rid="scirp.15342-ref4">4</xref>] 。由于多个机器人间存在资源竞争、且共处一个工作空间，这就造成了机器人间的冲突，解决机器人间的冲突已成为多机器人系统要解决的关键问题。</p><p>解决路径规划冲突问题，已有众多学者使用众多方法做了多年的深入研究并产生了大量研究成果[<xref ref-type="bibr" rid="scirp.15342-ref5">5</xref>] -[<xref ref-type="bibr" rid="scirp.15342-ref7">7</xref>] 。已有的研究解决方法大致可以分为集中式和离散式两类。集中式方法是将所有的机器人当作一个整体进行路径优化，但在不同的环境下优化结果不可靠，特别是对于部分可知的MDP环境或者机器人太多的环境。离散式方法是分别对单个的机器人进行路径优化，并随时解决优化过程中出现的冲突。两种方法共同的缺陷是算法的计算时间太长，仅能用于较小的环境，且不能保证在较短的时间内总是获得优化或接近优化的结果。</p><p>基于上述分析，本文提出采用基于XCS的离散启发式方法用于机器人的路径规划，机器人的优先权由其XCS的预测回报值来确定，而由集中式高水平的规划机器人动态分配各机器人的优先顺序，以解决机器人间的冲突，共同完成多机器人系统的路径规划。</p></sec><sec id="s4"><title>2. 相关技术原理</title><sec id="s4_1"><title>2.1. Q学习</title><p>Q学习是由<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x7_hanspub.png" xlink:type="simple"/></inline-formula>1989年提出的基于<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x8_hanspub.png" xlink:type="simple"/></inline-formula>环境的一种学习算法(MDP) [<xref ref-type="bibr" rid="scirp.15342-ref8">8</xref>] 。其原理是通过对感知的环境状态采取各种试探动作，获得此种试探动作对此种环境状态的奖励或者惩罚信号，并能不断调整学习策略以获得较大的奖励或较小的惩罚，同时反馈给其它机器人，并能够保证学习的收敛性。</p><p>单机器人的学习环境是基于<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x9_hanspub.png" xlink:type="simple"/></inline-formula>提出的有限四元组<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x10_hanspub.png" xlink:type="simple"/></inline-formula>，其中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x11_hanspub.png" xlink:type="simple"/></inline-formula>是有限环境状态集，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x12_hanspub.png" xlink:type="simple"/></inline-formula>为机器人有限动作集，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x13_hanspub.png" xlink:type="simple"/></inline-formula>为状态转换概率函数。<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x14_hanspub.png" xlink:type="simple"/></inline-formula>为机器人的回报函数。</p><p>多机器人的学习环境是基于MR-MDP，是一个随机的四元组<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x15_hanspub.png" xlink:type="simple"/></inline-formula>。<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x16_hanspub.png" xlink:type="simple"/></inline-formula>为离散的环境状态集、<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x17_hanspub.png" xlink:type="simple"/></inline-formula>为作用于机器人的动作集，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x18_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x19_hanspub.png" xlink:type="simple"/></inline-formula>为机器人数量。<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x20_hanspub.png" xlink:type="simple"/></inline-formula>为状态转换概率函数。<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x21_hanspub.png" xlink:type="simple"/></inline-formula>为机器人的回报函数。在多机器人系统，状态转换是所有机器人联合行动的结果，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x22_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x23_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x24_hanspub.png" xlink:type="simple"/></inline-formula>。</p></sec><sec id="s4_2"><title>2.2. 学习分类器(Accuracy-Based Learning Classifier System, XCS)</title><p>XCS [<xref ref-type="bibr" rid="scirp.15342-ref9">9</xref>] 作为LCS的衍生系统是由Wilson提出的基于精度的学习分类器，集成了强化学习、遗传算法和覆盖算法。XCS是由条件、动作和预测回报三个主要的参数组成：条件指明XCS可以匹配的环境输入状态；动作表示在该XCS匹配的环境状态下XCS的建议动作；预测回报<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x25_hanspub.png" xlink:type="simple"/></inline-formula>表示该XCS被匹配且执行了该XCS所建议的动作后系统预期从环境获得的回报。预测误差<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x26_hanspub.png" xlink:type="simple"/></inline-formula>表示预测回报<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x27_hanspub.png" xlink:type="simple"/></inline-formula>的误差；适应强度<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x28_hanspub.png" xlink:type="simple"/></inline-formula>表示预测回报<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x29_hanspub.png" xlink:type="simple"/></inline-formula>的精度。</p><p>Step 1：在开始随机分类器集合选择动作概率大的动作<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x30_hanspub.png" xlink:type="simple"/></inline-formula>作用于环境，根</p><p>据环境输入，产生一个匹配环境输入的匹配规则集，然后依据每个分类器的回报预测和适应强度值，生成整个系统的预测列表和动作集。</p><p>Step 2：分类器在执行机制过程中，每选择一个动作<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x31_hanspub.png" xlink:type="simple"/></inline-formula>作用于环境，分类器从环境获得一个回报<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x32_hanspub.png" xlink:type="simple"/></inline-formula>，回报预测、分类器适应值强度更新如下：</p><disp-formula id="scirp.15342-formula682"><label>(1)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/1-2610058x33_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x34_hanspub.png" xlink:type="simple"/></inline-formula>是学习效率。</p><disp-formula id="scirp.15342-formula683"><label>(2)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/1-2610058x35_hanspub.png"  xlink:type="simple"/></disp-formula><disp-formula id="scirp.15342-formula684"><label>(3)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/1-2610058x36_hanspub.png"  xlink:type="simple"/></disp-formula><disp-formula id="scirp.15342-formula685"><label>(4)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/1-2610058x37_hanspub.png"  xlink:type="simple"/></disp-formula><disp-formula id="scirp.15342-formula686"><label>(5)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/1-2610058x38_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中参数<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x39_hanspub.png" xlink:type="simple"/></inline-formula>控制预测误差<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x40_hanspub.png" xlink:type="simple"/></inline-formula>的冗余度；参数<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x41_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x42_hanspub.png" xlink:type="simple"/></inline-formula>是常量，控制当<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x43_hanspub.png" xlink:type="simple"/></inline-formula>被超过时精确度<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x44_hanspub.png" xlink:type="simple"/></inline-formula>的下降速度。动作集中的绝对精确度值<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x45_hanspub.png" xlink:type="simple"/></inline-formula>被转换为相对精确度值<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x46_hanspub.png" xlink:type="simple"/></inline-formula>，XCS的适应度值<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x47_hanspub.png" xlink:type="simple"/></inline-formula>是依据相对精确度值进行更新：</p><disp-formula id="scirp.15342-formula687"><label>(6)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/1-2610058x48_hanspub.png"  xlink:type="simple"/></disp-formula><p>Step 3：当匹配规则集中没有分类器与环境输入信息相匹配时，启动规则发现机制的覆盖算法，随机产生一个分类器。覆盖算法产生的新规则的条件部分与环境信息匹配，该规则淘汰规则集中强度最小的规则，存入规则集中。</p><p>Step 4：未达到设定迭代次数转Step 2。</p></sec></sec><sec id="s5"><title>3. 基于XCS的多机器人路径规划冲突解决方案</title><sec id="s5_1"><title>3.1. 多机器人学习训练方法</title><p>在基于XCS的多机器人路径规划冲突解决方案中，机器人学习训练分为个体和团队训练两种方法。在个体训练阶段，XCS使机器人学会避碰，确保机器人在安全的情况下向设定目标运动。在团队训练阶段，团队训练引入的机器人管理者决定机器人的优先权，在任一时刻，所有机器人在没有考虑其他机器人位置的情况下预先感知环境，然后以机器人在管理者约束下的成功等级概率作为各机器人优先权，各机器人依优先权大小进行下一步的行动。</p></sec><sec id="s5_2"><title>3.2. 机器人优先级别设计</title><p>多机器人在未到达目标位置前，个体机器人<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x49_hanspub.png" xlink:type="simple"/></inline-formula>在区域<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x50_hanspub.png" xlink:type="simple"/></inline-formula>内移动。如果在时刻<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x51_hanspub.png" xlink:type="simple"/></inline-formula>，机器人<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x52_hanspub.png" xlink:type="simple"/></inline-formula>对目标位置<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x53_hanspub.png" xlink:type="simple"/></inline-formula>进行预测，计算出自己预接近到目标的理想速度和方位角，并将结果通过无线网络发布给其他机器人，同时自己升级为领导机器人。其他机器人根据收到的信息计算出自己的位置和运动趋势，并同时计算出目标和其他机器人与自身的相对位置，根据其他机器人的情况，提出自己预接近目标的理想速度和方位角。对于最终的等级方案，领导机器人采用成功概率加权的方法。该方法首先建立如下位置估计方程：</p><disp-formula id="scirp.15342-formula688"><label>(7)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/1-2610058x54_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中：<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x55_hanspub.png" xlink:type="simple"/></inline-formula>分别为成员机器人位置、预计速度和方位角；<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x56_hanspub.png" xlink:type="simple"/></inline-formula>为机器人目标位置、速度和方向；<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x57_hanspub.png" xlink:type="simple"/></inline-formula>为对目标机器人的移动安全半径(根据机器人大小等因素设定的经验值)；<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x58_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x59_hanspub.png" xlink:type="simple"/></inline-formula>为二维分量上的偏差。</p><p>将领导机器人<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x60_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x61_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x62_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x63_hanspub.png" xlink:type="simple"/></inline-formula>代入上式，并将求得的<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x64_hanspub.png" xlink:type="simple"/></inline-formula>代入下式，由此可得各成员机器人在机器人管理者约束下的成功等级概率。</p><disp-formula id="scirp.15342-formula689"><label>(8)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/1-2610058x65_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s5_3"><title>3.3. 解决多机器人冲突的集成适应度函数</title><p>多机器人路径规划是要求各机器人能避开动态运行的障碍物，且机器人之间不能相碰。我们把机器人是否在安全范围内，结合机器人本身预测回报值和各机器人等级概率三方面考虑来设计解决机器人冲突的集成适应度函数。</p><p>1) 是否在安全之内</p><p>我们把所有的障碍物和机器人都视为质点，每个障碍物都有一个安全半径，若机器人与障碍物的距离大于安全半径，则认为是安全的；若小于安全半径，则认为是不安全。障碍物与机器人每一个路点<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x66_hanspub.png" xlink:type="simple"/></inline-formula>之间的距离d与安全半径R之间的关系如下：</p><disp-formula id="scirp.15342-formula690"><label>(9)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/1-2610058x67_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x68_hanspub.png" xlink:type="simple"/></inline-formula>，障碍物坐标<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x69_hanspub.png" xlink:type="simple"/></inline-formula>，机器人坐标为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x70_hanspub.png" xlink:type="simple"/></inline-formula>。<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/1-2610058x71_hanspub.png" xlink:type="simple"/></inline-formula>的值表明只要机器人质点与障碍物的距离在安全半径之外，则其适应度值为0，若有一个路径点与障碍物的距离在安全半径之内，则适应度为−1。</p><p>2) 机器人的预测回报适应度函数</p><disp-formula id="scirp.15342-formula691"><label>(10)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/1-2610058x72_hanspub.png"  xlink:type="simple"/></disp-formula><p>3) 机器人的成功等级概率适应度函数</p><disp-formula id="scirp.15342-formula692"><label>(11)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/1-2610058x73_hanspub.png"  xlink:type="simple"/></disp-formula><p>综合上述因素，机器人的集成适应度函数为：</p><disp-formula id="scirp.15342-formula693"><label>(12)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/1-2610058x74_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s5_4"><title>3.4. 解决多机器人路径规划冲突的等级策略 [<xref ref-type="bibr" rid="scirp.15342-ref10">10</xref>]</title><p>本文采用离散启发式机器学习算法，结合Q学习和XCS算法共同解决多机器人路径规划中的冲突问题。LS-SVM获得的最优学习策略作为XCS的初始规则集。XCS通过与环境的交互，可以发现一组用于指导机器人避碰的学习规则，为机器人选择动作提供实时、动态的反馈，使机器人自主地学习到最优避碰规划策略。</p><p>Step 1：最小二乘支持向量机产生的最优学习策略作为XCS的初始规则集，并随机执行其中的学习策略。</p><p>Step 2：将消息列表中的消息与当前避碰规则的条件部分进行匹配，匹配的避碰规则送入匹配规则集。</p><p>Step 3：从匹配规则集中选择合适的避碰编码规则送往效应器，引导机器人产生相应的避碰动作，并依据反馈值来判断避碰效果。</p><p>Step 4：重复Step 2~Step 3过程，不断从匹配规则集中选择合适的避碰动作编码规则送往效应器，引导机器人产生相应的动作，直到匹配规则集为空或定时启动避碰规则发现机制。</p><p>Step 5：规则发现系统采用遗传算法和规则覆盖算法构造新的避碰规则。</p><p>Step 6：对产生的新的避碰规则进行规则合并，使其能概括以前的两个样本，滤除相似的个体，减少基因的单一性，加快了学习收敛速度。产生的新学习个体规则送入规则集，经过XCS发送到其公共规则集中，供其它机器人XCS产生新避碰规则时共享。</p><p>Step 7：如果机器人未达到避碰效果，则返回Step 2。</p></sec></sec><sec id="s6"><title>4. 仿真实验和分析</title><p>为了验证算法在多机器人的路径规划冲突中的有效性，以及提高多机器人系统解决路径规划冲突的能力的可行性。下面实验对所提算法进行全方位的验证比较，实验在不同的场景中进行。S和G分别为机器人初始和目标位置，O1~O3为动态障碍物，其它为一般静态障碍物。</p><p>实验场景一、U型障碍物的动态狭隘环境</p><p>图1为U型障碍物的形状，所有图中G表示机器人目标位置，S表示机器人初始位置。空心圆表示动态障碍物。</p><p>图2为多机器人系统在连续五个U型狭隘环境下的运动轨迹，动态障碍物(编号1~3)分别在所属的U型狭隘环境中作上下运动。尽管路途中有连续多个U型陷阱，机器人经过前期个体和团队训练阶段的强化学习，机器人均能摆脱U型陷阱的局部最优，四个机器人最终均顺利到达目标位置G点。</p><p>实验场景二、狭窄通道的多障碍物动态狭隘环境</p><p>图3为机器人在狭窄通道环境下的运动轨迹。由于图3左图中危险品为静态障碍物，机器人在此环境下能够顺利绕过危险品障碍物的运动轨迹。图3右图内有两个作水平运动的动态障碍物(编号1~2)，机器人在绕过危险品障碍物后，能够精确预测到第一个动态障碍物2的位置，且直线快速通过动态障碍物2的移动区域，然后绕过第二个动态障碍物1，从而完成机器人在狭窄通道环境下的整体运动规划，都能产生平滑的轨迹。</p><p>图4为多机器人在狭窄通道环境下的运动轨迹，动态障碍物(编号1~3)均在所属环境下作上下直线运动，所有参与规划的机器人均取得较满意的模拟曲线。在动态狭隘环境下，由于XCS具有较强预测回报能力和环境学习能力，所有机器人都能取得满意的运动轨迹和稳定的收敛效果。</p><p>实验场景三、凸凹多障碍物的动态狭隘环境</p><p>图5为凸凹多障碍物形状。图6为多机器人系统在有多个凸凹多障碍物狭隘环境下的运动轨迹。尽</p><p>图1. U型障碍物的形状</p><p>图2. U型环境下的多机器人运动轨迹</p><p>图3. 狭窄通道环境下的机器人运动轨迹</p><p>图4. 狭窄通道环境下的多机器人运动轨迹</p><p>图5. 凸凹多障碍物形状</p><p>图6. 凸凹多障碍物环境下多机器人运动轨迹</p><p>管有多个易于陷入局部最小的风险陷阱，但机器人(R1、R2、R3)在文献[<xref ref-type="bibr" rid="scirp.15342-ref10">10</xref>] 所述的行为控制方法follow_wall、avoid_obstacle、move_to_goal的引导下，结合本文提出的XCS集成算法，机器人R1、R2和R3均顺利躲避附近移动的动态障碍物，所有机器人能够非常稳定的到达各自的目标。在安全性方面，图6最危险的地带在凸凹障碍物周围，在30次试验中机器人R1、R2和R3分别成功29、29和30次，整个多机器人系统路径规划成功率在95%以上，表现出良好的动态避障性能。</p></sec><sec id="s7"><title>5. 结束语</title><p>本文提出采用基于XCS的离散启发式方法用于单个机器人的路径规划，机器人的优先权由其XCS的预测回报值来确定，而由集中式高水平的规划机器人动态分配各机器人的优先顺序，以解决多机器人间的冲突，共同完成多机器人系统的路径规划。很大程度上解决了遗传算法的早熟收敛、局部最优解、占据存储空间较大、收敛数度慢等问题，提高了多机器人发现安全路径的能力。</p></sec><sec id="s8"><title>基金项目</title><p>2013河南省高等学校“专业综合改革试点”项目；河南省教育厅重点基金资助项目(12B520047)。</p></sec><sec id="s9"><title>文章引用</title><p>邵 杰,于景茹, (2015) 狭隘环境下一种多机器人路径规划方法A Multi-Robot Path Planning Method under Narrow Environments. 人工智能与机器人研究,02,9-16. doi: 10.12677/AIRR.2015.42002</p></sec><sec id="s10"><title>参考文献 (References)</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.15342-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Masouri, M. and Aliyari, M. (2008) Teshnehlab. Integer GA for mobile robot path planning with using another GA as repairing function. International Conference on Automation and Logistics, Qingdao, 1-3 September 2008, 135-140.</mixed-citation></ref><ref id="hanspub.15342-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">孟伟, 黄庆成, 韩学东, 等 (2005) 一种动态未知环境中自主机器人的导航方法. 计算机研究与发展, 9, 1538- 1543.</mixed-citation></ref><ref id="hanspub.15342-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">邵杰, 杨静宇, 万鸣华, 黄传波 (2010) 基于学习分类器的多机器人路径规划收敛性研究. 计算机研究与发展, 5, 948-955.</mixed-citation></ref><ref id="hanspub.15342-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">孟偲, 王田苗 (2008) 一种移动机器人全局最优路径规划算法. 机器人, 3, 217-222.</mixed-citation></ref><ref id="hanspub.15342-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Gao, Y. and Sun, S.-D. (2009) A collision based local path planning of mobile robot. 2009 International Asia Conference on Informatics in Control, Automation and Robots, Piscataway, 2009, 185-190.</mixed-citation></ref><ref id="hanspub.15342-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">曲道奎, 杜振军, 徐殿国, 等 (2008) 移动机器人路径规划方法研究. 机器人, 2, 97-106.</mixed-citation></ref><ref id="hanspub.15342-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Holland, J.H. (1986) A mathematical frame work for studying learning in classifier systems. In: Farmer, D., Lapedes, A., Packard, N. and Wendroff, B., Eds., Evolution, Games and Learning, North-Holland, Amsterdam, 307-317.</mixed-citation></ref><ref id="hanspub.15342-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Musilek, P. (2005) Enhanced learning classifier system for robot navigatio. Intelligent Robots and Systems 2005 International Conference, Piscataway, 2005, 3390-3395.</mixed-citation></ref><ref id="hanspub.15342-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Larry, B., Mattew, S., Anthony, B., et al. (2007) Learning classifier system ensembles with rule-sharing. IEEE Transactions on Evolutionary Computation, 11, 496-502.</mixed-citation></ref><ref id="hanspub.15342-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">邵杰, 杨静宇 (2011) 基于多LCS和人工势场法的机器人行为控制. 计算机科学, 1, 948-951.</mixed-citation></ref></ref-list></back></article>