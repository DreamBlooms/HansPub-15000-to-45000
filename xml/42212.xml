<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">PM</journal-id><journal-title-group><journal-title>Pure  Mathematics</journal-title></journal-title-group><issn pub-type="epub">2160-7583</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/PM.2021.115085</article-id><article-id pub-id-type="publisher-id">PM-42212</article-id><article-categories><subj-group subj-group-type="heading"><subject>PM20210500000_63823967.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>æ•°å­¦ä¸ç‰©ç†</subject></subj-group></article-categories><title-group><article-title>
 
 
  å“ˆè¾¾ç›æµå½¢ä¸Šçš„è¿‘ç«¯æ¢¯åº¦æ³•æ”¶æ•›æ€§åˆ†æ
  Analysis of Convergence of Proximal Gradient Method on Hadamard Manifold
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>å®‹</surname><given-names>ä¹ä¹</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib></contrib-group><aff id="aff1"><label>1</label><addr-line>null</addr-line></aff><aff id="aff2"><label>1</label><addr-line>ä¸Šæµ·å¤§å­¦ï¼Œä¸Šæµ·</addr-line></aff><pub-date pub-type="epub"><day>11</day><month>05</month><year>2021</year></pub-date><volume>11</volume><issue>05</issue><fpage>701</fpage><lpage>708</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
  
    æœ¬æ–‡åœ¨å“ˆè¾¾ç›æµå½¢ä¸Šæå‡ºäº†è¿‘ç«¯æ¢¯åº¦ç®—æ³•ï¼Œå¹¶ç»™å‡ºäº†æ”¶æ•›æ€§åˆ†æã€‚å…·ä½“åœ°è¯´ï¼Œæˆ‘ä»¬å°†éå‡¸éå…‰æ»‘é—®é¢˜çš„è¿‘ç«¯æ¢¯åº¦æ³•ä»æ¬§æ°ç©ºé—´æ¨å¹¿åˆ°å“ˆè¾¾ç›æµå½¢ä¸Šã€‚åœ¨é»æ›¼æµå½¢ä¸Šå­˜åœ¨ç€éçº¿æ€§çš„å›°éš¾ï¼Œæˆ‘ä»¬æ ¹æ®å“ˆè¾¾ç›æµå½¢çš„ç‰¹æ®Šç»“æ„ï¼Œç»™å‡ºäº†ç†è®ºè¯æ˜ã€‚
    In this paper, a proximal gradient algorithm for Hadamard manifolds is presented and its conver-gence is analyzed. Specifically, we extend the proximal gradient method for Nonconvex nonsmooth problems from Euclidan space to Hadamard manifolds. The difficulty of nonlinearity on Bernhard Riemann manifolds is proved theoretically according to the special structure of Hadamard mani-folds. In this paper, a proximal gradient algorithm for Hadamard manifolds is presented and its convergence is analyzed. Specifically, we extend the proximal gradient method for nonconvex nonsmooth problems from Euclidean space to Hadamard manifolds. The difficulty of nonlinearity on Bernhard Riemann manifolds is proved theoretically according to the special structure of Hadamard manifolds. 
  
 
</p></abstract><kwd-group><kwd>è¿‘ç«¯æ¢¯åº¦æ³•ï¼Œå“ˆè¾¾ç›æµå½¢ï¼Œå†…è•´ç®—æ³•, Near-End Gradient Method</kwd><kwd> Hadamard Manifold</kwd><kwd> Intrinsic Algorithm</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>æ‘˜è¦</title><p>æœ¬æ–‡åœ¨å“ˆè¾¾ç›æµå½¢ä¸Šæå‡ºäº†è¿‘ç«¯æ¢¯åº¦ç®—æ³•ï¼Œå¹¶ç»™å‡ºäº†æ”¶æ•›æ€§åˆ†æã€‚å…·ä½“åœ°è¯´ï¼Œæˆ‘ä»¬å°†éå‡¸éå…‰æ»‘é—®é¢˜çš„è¿‘ç«¯æ¢¯åº¦æ³•ä»æ¬§æ°ç©ºé—´æ¨å¹¿åˆ°å“ˆè¾¾ç›æµå½¢ä¸Šã€‚åœ¨é»æ›¼æµå½¢ä¸Šå­˜åœ¨ç€éçº¿æ€§çš„å›°éš¾ï¼Œæˆ‘ä»¬æ ¹æ®å“ˆè¾¾ç›æµå½¢çš„ç‰¹æ®Šç»“æ„ï¼Œç»™å‡ºäº†ç†è®ºè¯æ˜ã€‚</p></sec><sec id="s2"><title>å…³é”®è¯</title><p>è¿‘ç«¯æ¢¯åº¦æ³•ï¼Œå“ˆè¾¾ç›æµå½¢ï¼Œå†…è•´ç®—æ³•</p></sec><sec id="s3"><title>Analysis of Convergence of Proximal Gradient Method on Hadamard Manifold</title><p>Lele Song</p><p>Shanghai University, Shanghai</p><p><img src="//html.hanspub.org/file/1-1251286x4_hanspub.png" /></p><p>Received: Apr. 2<sup>nd</sup>, 2021; accepted: May 3<sup>rd</sup>, 2021; published: May 11<sup>th</sup>, 2021</p><p><img src="//html.hanspub.org/file/1-1251286x5_hanspub.png" /></p></sec><sec id="s4"><title>ABSTRACT</title><p>In this paper, a proximal gradient algorithm for Hadamard manifolds is presented and its convergence is analyzed. Specifically, we extend the proximal gradient method for Nonconvex nonsmooth problems from Euclidan space to Hadamard manifolds. The difficulty of nonlinearity on Bernhard Riemann manifolds is proved theoretically according to the special structure of Hadamard manifolds. In this paper, a proximal gradient algorithm for Hadamard manifolds is presented and its convergence is analyzed. Specifically, we extend the proximal gradient method for nonconvex nonsmooth problems from Euclidean space to Hadamard manifolds. The difficulty of nonlinearity on Bernhard Riemann manifolds is proved theoretically according to the special structure of Hadamard manifolds.</p><p>Keywords:Near-End Gradient Method, Hadamard Manifold, Intrinsic Algorithm</p><disp-formula id="hanspub.42212-formula2"><graphic xlink:href="//html.hanspub.org/file/1-1251286x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2021 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/1-1251286x7_hanspub.png" /> <img src="//html.hanspub.org/file/1-1251286x8_hanspub.png" /></p></sec><sec id="s5"><title>1. å¼•è¨€</title><p>æµå½¢æ˜¯ä¸€èˆ¬å‡ ä½•å¯¹è±¡çš„æ€»ç§°ï¼Œæ˜¯æ¬§å¼ç©ºé—´ä¸­çš„æ›²çº¿ï¼Œæ›²é¢ç­‰æ¦‚å¿µçš„æ¨å¹¿ã€‚æµå½¢ä¸Šçš„ä¼˜åŒ–ä¸ä»…æ˜¯è¿‘å¹´æ¥ä¿¡æ¯ç§‘å­¦é¢†åŸŸå‘å±•èµ·æ¥çš„ä¸€é—¨æ–°å…´å­¦ç§‘ï¼ŒåŒæ—¶ä¹Ÿæ˜¯ä¼˜åŒ–ç†è®ºä¸æ–¹æ³•çš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚åœ¨ä¼˜åŒ–é¢†åŸŸä¸­ï¼Œé€šè¿‡åˆ©ç”¨æµå½¢çš„å‡ ä½•ç»“æ„ï¼Œä¸€äº›æ¬§å¼ç©ºé—´çš„éå‡¸é—®é¢˜å¯ä»¥è½¬åŒ–ä¸ºæµå½¢ä¸Šçš„å‡¸ä¼˜åŒ–é—®é¢˜ï¼Œä¸€äº›çº¦æŸä¼˜åŒ–é—®é¢˜å¯ä»¥è§†ä¸ºæµå½¢ä¸Šçš„æ— çº¦æŸä¼˜åŒ–é—®é¢˜ã€‚å› æ­¤ï¼Œè¿‘å¹´æ¥è¿™ä¸ªé¢†åŸŸçš„ç ”ç©¶å—åˆ°è¶Šæ¥è¶Šå¤šçš„å…³æ³¨ã€‚</p><p>å“ˆè¾¾ç›æµå½¢æ˜¯ä¸€ä¸ªå®Œå¤‡çš„å…·æœ‰éæ­£æ›²ç‡ [<xref ref-type="bibr" rid="hanspub.42212-ref1">1</xref>] [<xref ref-type="bibr" rid="hanspub.42212-ref2">2</xref>] çš„ç®€å•è¿é€šæœ‰é™ç»´é»æ›¼æµå½¢ï¼ŒåŒ…æ‹¬å¤§é‡é‡è¦çš„çŸ©é˜µæµå½¢å’Œæ¨¡å‹ã€‚åœ¨æœºå™¨å­¦ä¹  [<xref ref-type="bibr" rid="hanspub.42212-ref3">3</xref>]ï¼Œå›¾åƒå¤„ç† [<xref ref-type="bibr" rid="hanspub.42212-ref4">4</xref>] ä¸­éƒ½æœ‰ç€å¹¿æ³›çš„åº”ç”¨ã€‚ç”±äºå…¶ä¼˜è‰¯çš„å‡ ä½•ç»“æ„ï¼Œå“ˆè¾¾ç›æµå½¢ä¸Šä»»æ„ä¸¤ç‚¹é—´æµ‹åœ°çº¿çš„å”¯ä¸€æ€§å‡è®¾ï¼Œé¿å…äº†ç®—æ³•è®¾è®¡çš„å¥‡å¼‚æ€§ã€‚è¿‘å¹´æ¥ï¼Œå›½å†…å¤–ç ”ç©¶äº†å„ç§éæ­£æ›²ç‡æµå½¢ï¼Œå¦‚å¯¹ç§°æ­£å®šæµå½¢å’Œné˜¶æ—‹è½¬ç¾¤ï¼Œå·²ç»å‡ºç°åœ¨æœºå™¨å­¦ä¹ å’Œè®¡ç®—æœºè§†è§‰ä¸­ [<xref ref-type="bibr" rid="hanspub.42212-ref5">5</xref>] [<xref ref-type="bibr" rid="hanspub.42212-ref6">6</xref>] [<xref ref-type="bibr" rid="hanspub.42212-ref7">7</xref>]ã€‚è€ƒè™‘æµå½¢çš„å‡ ä½•ç»“æ„ï¼Œè®¾è®¡å†…åœ¨çš„è¿­ä»£ç»“æ„ä¿æŒç®—æ³• [<xref ref-type="bibr" rid="hanspub.42212-ref8">8</xref>] [<xref ref-type="bibr" rid="hanspub.42212-ref9">9</xref>]ï¼Œä¸ºä¸€äº›ä»»åŠ¡çš„ç ”ç©¶æä¾›äº†æ›´å‡†ç¡®ï¼Œæ›´æœ‰æ•ˆçš„é€”å¾„ã€‚</p><p>ä½œä¸ºéæ­£æ›²ç‡æµå½¢ï¼Œå“ˆè¾¾ç›æµå½¢å…·æœ‰æ— å…±è½­ç‚¹çš„ä¼˜è‰¯æ€§è´¨ï¼Œå› æ­¤å…¶ä¸Šä»»æ„ä¸¤ç‚¹ä¹‹é—´å­˜åœ¨å”¯ä¸€çš„æµ‹åœ°çº¿ã€‚å®ƒä½¿ç®—æ³•çš„è¿­ä»£åœ¨æ•´ä¸ªæµå½¢ä¸Šæœ‰äº†å¾ˆå¥½çš„å®šä¹‰ï¼Œå¹¶åœ¨è¿™æ ·çš„æµå½¢ä¸Šå‘å±•äº†è®¸å¤šä¿æŒç»“æ„çš„ç®—æ³•ã€‚ä¾‹å¦‚ï¼ŒColaoç­‰äººè€ƒè™‘äº†éçº¿æ€§å“ˆè¾¾ç›æµå½¢ä¸Šçš„å¹³è¡¡é—®é¢˜ï¼Œè¯æ˜äº†ä¸€ç±»åŒå‡½æ•°å¹³è¡¡ç‚¹çš„å­˜åœ¨æ€§ [<xref ref-type="bibr" rid="hanspub.42212-ref1">1</xref>] å’Œå®šä¹‰åœ¨å“ˆè¾¾ç›æµå½¢ä¸Šçš„é›†å€¼æ˜ å°„çš„ä¸åŠ¨ç‚¹å®šç†ï¼Œå¹¶è®¨è®ºäº†å¹³è¡¡ç‚¹çš„è¿‘ä¼¼é—®é¢˜ã€‚è¿‘å‡ å¹´ï¼ŒRuizgarzonç­‰äººæå‡ºäº†å“ˆè¾¾ç›æµå½¢çš„çº¦æŸå‘é‡ä¼˜åŒ–é—®é¢˜å¼±æœ‰æ•ˆParetoç‚¹çš„ç»å…¸å……è¦æ¡ä»¶ [<xref ref-type="bibr" rid="hanspub.42212-ref10">10</xref>]ï¼ŒFerreiaå’ŒLouzeiroå°†æ¢¯åº¦æ–¹æ³•æ¨å¹¿åˆ°æˆªé¢æ›²ç‡æœ‰ç•Œçš„æµå½¢ä¸Šï¼Œå¹¶è¯æ˜äº†ä¸€é˜¶æ”¶æ•›é€Ÿåº¦ [<xref ref-type="bibr" rid="hanspub.42212-ref11">11</xref>]ã€‚å¦ä¸€æ–¹é¢ï¼ŒFerreiraå’ŒOliveiraæå‡ºäº†ä¸€ç§æ±‚è§£å“ˆè¾¾ç›å½¢ä¸Šå…‰æ»‘å‡¸å‡½æ•°çš„é‚»è¿‘ç‚¹æ–¹æ³• [<xref ref-type="bibr" rid="hanspub.42212-ref12">12</xref>]ï¼Œå¹¶è¯´æ˜äº†Riemannæµå½¢ä¸­çš„å‡¸åˆ†æï¼Œå¯ä»¥ç”¨æ¥è§£å†³æ¬§å¼ç©ºé—´ä¸­çš„éå‡¸çº¦æŸé—®é¢˜ï¼Œå¹¶ä¼°è®¡äº†ğ‘ƒ (1/l)çš„æ”¶æ•›é€Ÿåº¦ [<xref ref-type="bibr" rid="hanspub.42212-ref9">9</xref>] [<xref ref-type="bibr" rid="hanspub.42212-ref13">13</xref>]ã€‚Wangç­‰äººå°†æ±‚è§£å¤šå€¼å‘é‡åœºå¥‡å¼‚ç‚¹çš„éç²¾ç¡®è¿‘ç‚¹æ–¹æ³•æ¨å¹¿åˆ°å“ˆè¾¾ç›æµå½¢ä¸Š [<xref ref-type="bibr" rid="hanspub.42212-ref14">14</xref>]ã€‚Bentoç­‰äººè¿˜å°†ä¸€ç§è¿‘ä¼¼ç‚¹æ³•æ¨å¹¿åˆ°ä¸€èˆ¬Riemannæµå½¢ï¼Œå¹¶è¿›è¡Œäº†æ”¶æ•›æ€§åˆ†æ [<xref ref-type="bibr" rid="hanspub.42212-ref15">15</xref>] ä»¥åŠè¿›ä¸€æ­¥çš„çŸ¢é‡ä¼˜åŒ– [<xref ref-type="bibr" rid="hanspub.42212-ref16">16</xref>]ã€‚Ansariç­‰äººæå‡ºäº†ä¸€ç§æ­£åˆ™åŒ–çš„éç²¾ç¡®é‚»è¿‘ç‚¹ç®—æ³•ï¼Œç”¨äºå¯»æ‰¾å“ˆè¾¾ç›æµå½¢ä¸Šæœ€å¤§å•è°ƒé›†å€¼å‘é‡åœºçš„å¥‡ç‚¹ [<xref ref-type="bibr" rid="hanspub.42212-ref17">17</xref>]ã€‚Baygorreaç­‰äººå»ºç«‹äº†å“ˆè¾¾ç›æµå½¢ä¸Šæ‹Ÿå‡¸æå°åŒ–çš„éç²¾ç¡®é‚»è¿‘ç‚¹æ–¹æ³• [<xref ref-type="bibr" rid="hanspub.42212-ref18">18</xref>] å¹¶ä¼°è®¡å…¶æ”¶æ•›é€Ÿåº¦ [<xref ref-type="bibr" rid="hanspub.42212-ref19">19</xref>]ã€‚Tangå’ŒHuangè¿˜ä¼°è®¡äº†å‘é‡å‡½æ•°åœ¨å“ˆè¾¾ç›æµå½¢ä¸Šçš„é‚»è¿‘ç‚¹ç®—æ³•çš„æ”¶æ•›é€Ÿåº¦ [<xref ref-type="bibr" rid="hanspub.42212-ref20">20</xref>]ã€‚è¿‘å‡ å¹´ï¼ŒChenç­‰äººæå‡ºäº†Stiefelæµå½¢ä¸Šçš„é»æ›¼è¿‘ä¼¼æ¢¯åº¦(RPG)æ–¹æ³• [<xref ref-type="bibr" rid="hanspub.42212-ref21">21</xref>]ï¼Œè€ŒTorres Almeidaç­‰äººåˆ™ä¿®æ”¹äº†é‚»è¿‘ç‚¹ç®—æ³•æ¥ä¼˜åŒ–å“ˆè¾¾ç›æµå½¢ä¸Šçš„DCå‡½æ•° [<xref ref-type="bibr" rid="hanspub.42212-ref22">22</xref>]ã€‚ç»“æœè¡¨æ˜ï¼ŒåŸºäºæ¢¯åº¦çš„æ–¹æ³•å’Œå“ˆè¾¾ç›æµå½¢ä¸Šçš„é‚»è¿‘ç‚¹ç®—æ³•æå¤§åœ°ä¸°å¯Œäº†æµå½¢ä¼˜åŒ–çš„ç ”ç©¶ã€‚</p><p>åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†ä»¥å¦ä¸€ç§æ–¹å¼åŠ é€Ÿæ±‚è§£å“ˆè¾¾ç›æµå½¢ä¸Šä¸€ç±»éå‡¸éå…‰æ»‘é—®é¢˜çš„å†…è•´è¿‘ç«¯æ¢¯åº¦ç®—æ³•ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬è€ƒè™‘ä¸‹é¢çš„æœ€å°åŒ–é—®é¢˜ï¼š</p><p>min x âˆˆ M F ( x ) = f ( x ) + g ( x ) (1)</p><p>å…¶ä¸­ M æ˜¯æœ‰é™ç»´å“ˆè¾¾ç›æµå½¢(å…·æœ‰éæ­£æˆªé¢æ›²ç‡çš„æµå½¢)ï¼Œ f æ˜¯æµ‹åœ°å…‰æ»‘å‡½æ•°ï¼Œ g æ˜¯ä¸‹åŠè¿ç»­å‡½æ•°ï¼Œå¯ä»¥ä¸è¿ç»­ã€‚</p></sec><sec id="s6"><title>2. é¢„å¤‡çŸ¥è¯†</title><p>æˆ‘ä»¬åœ¨æœ¬èŠ‚æå‡ºäº†ä¸€äº›å…³äºå“ˆè¾¾ç›æµå½¢çš„æ¦‚å¿µã€‚æ›´è¯¦ç»†çš„å†…å®¹ï¼Œè¯·å‚é˜… [<xref ref-type="bibr" rid="hanspub.42212-ref2">2</xref>] [<xref ref-type="bibr" rid="hanspub.42212-ref13">13</xref>] [<xref ref-type="bibr" rid="hanspub.42212-ref18">18</xref>]ã€‚</p><p>å“ˆè¾¾ç›æµå½¢æ˜¯ä¸€ä¸ªå…·æœ‰éæ­£æˆªé¢æ›²ç‡çš„å®Œå…¨å•è¿é€šé»æ›¼æµå½¢ã€‚åœ¨å“ˆè¾¾ç›æµå½¢ä¸Šä»»æ„ä¸¤ç‚¹ä¹‹é—´å­˜åœ¨å”¯ä¸€çš„æµ‹åœ°çº¿ã€‚è®¾ M æ˜¯å“ˆè¾¾ç›æµå½¢ï¼Œç»™å®š x âˆˆ M ï¼Œ T x M è¡¨ç¤º M ä¸Šåœ¨ x ç‚¹çš„åˆ‡ç©ºé—´ã€‚å¯¹ä»»æ„ y âˆˆ M ï¼ŒæŒ‡æ•°æ˜ å°„å®šä¹‰ä¸ºï¼š exp x k : T x M â†’ M ï¼ŒæŒ‡æ•°æ˜ å°„å®šä¹‰ä¸º exp x k âˆ’ 1 : M â†’ T x M æ»¡è¶³ â€– exp x âˆ’ 1 y â€– = â€– exp y âˆ’ 1 x â€– = d ( x , y ) ï¼Œå…¶ä¸­ï¼Œ â€– &#183; â€– ä¸ºåˆ‡å‘é‡åœ¨å¯¹åº”é»æ›¼åº¦é‡ âŒ© , âŒª ä¸‹çš„èŒƒæ•°ã€‚ d ( x , y ) æ˜¯ x å’Œ y ä¸¤ç‚¹é—´çš„æµ‹åœ°è·ç¦»ã€‚åœ¨å“ˆè¾¾ç›æµå½¢ä¸Šï¼Œå¯¹äºä»»æ„ä¸¤ç‚¹ x , y âˆˆ M ï¼Œæˆ‘ä»¬æœ‰ grad 1 2 d 2 ( x , y ) = âˆ’ exp x âˆ’ 1 y ã€‚è®¾ Î³ : [ a , b ] â†’ M ä¸ºä¸€æ¡æ›²çº¿ï¼Œ âˆ‡ è¡¨ç¤º M ä¸Šçš„Levi-Civitaè”ç»œã€‚ä¸€ä¸ªæ²¿ç€æ›²çº¿ Î³ çš„å‘é‡åœº V æ˜¯å¹³è¡Œå‘é‡åœºï¼Œå½“ä¸”ä»…å½“ âˆ‡ Î³ â€² V = 0 ï¼Œå½“ âˆ‡ Î³ â€² Î³ â€² = 0 æ—¶ï¼Œ Î³ æ˜¯ä¸€æ¡æµ‹åœ°çº¿ã€‚æµ‹åœ°çº¿ Î³ ( &#183; ) = Î³ v ( &#183; , x ) è¡¨ç¤º Î³ ( 0 ) = x ï¼Œ Î³ â€² ( 0 ) = v ä»¥åŠ Î³ ( 1 ) = exp x v ã€‚ P ( x , y ) : T x M â†’ T x M å°†å‘é‡ v âˆˆ T x M æ˜ å°„åˆ° P ( x , y ) v âˆˆ T x M å¹¶ä¿æŒå‘é‡å†…ç§¯ä¸å˜ï¼Œç§° P ( x , y ) ä¸ºMä¸Šçš„å¹³è¡Œç§»åŠ¨ï¼Œå³ âŒ© v , w âŒª x = âŒ© P ( x , y ) v , P ( x , y ) w âŒª y ï¼Œç‰¹åˆ«åœ°ï¼Œ â€– v â€– x = â€– P ( x , y ) v â€– y ã€‚æµå½¢ä¸Šçš„ä¸€ä¸ªæµ‹åœ°ä¸‰è§’ Î” ( x y z ) æ˜¯ç”± x , y , z åŠè¿æ¥è¿™äº›ç‚¹çš„ä¸‰æ¡æœ€å°æµ‹åœ°çº¿ç»„æˆçš„é›†åˆã€‚ä½™å¼¦å®šç†æ˜¯å“ˆè¾¾ç›æµå½¢ä¸Šä¸€ä¸ªé‡è¦çš„æ€§è´¨ï¼Œä»»æ„ç»™å®š M ä¸Šçš„æµ‹åœ°ä¸‰è§’ Î” ( x y z ) ï¼Œæœ‰ d 2 ( x , z ) + d 2 ( z , y ) â‰¤ d 2 ( x , y ) + 2 âŒ© exp z âˆ’ 1 x , exp z âˆ’ 1 y âŒª ã€‚</p><p>å®šä¹‰2.1 M ä¸Šçš„å¯å¾®å‡½æ•° f çš„æ¢¯åº¦æ˜¯L-Lipschitzè¿ç»­çš„ï¼Œé‚£ä¹ˆç§° f æ˜¯æµ‹åœ°L-å…‰æ»‘(G-Lå…‰æ»‘)å‡½æ•°ã€‚å³ â€– P ( x , y ) grad f ( x ) âˆ’ grad f ( y ) â€– â‰¤ L d ( x , y ) ã€‚</p><p>æ³¨ï¼šå®šä¹‰2.1ç­‰ä»·äº</p><p>â€– f ( y ) âˆ’ f ( x ) âˆ’ âŒ© grad f ( x ) , exp x âˆ’ 1 y âŒª â€– â‰¤ L 2 â€– exp x âˆ’ 1 y â€– 2 (2)</p><p>å®šä¹‰2.2 å¦‚æœå‡½æ•° F : M â†’ R åœ¨ x âˆˆ M æ»¡è¶³</p><p>lim d ( x , y ) â†’ âˆ F ( y ) d ( x , y ) = + âˆ</p><p>åˆ™ç§° F åœ¨ x ç‚¹ä¸Šæ˜¯1-å¼ºåˆ¶çš„ã€‚</p><p>å®šä¹‰2.3 ä»¤ g : M â†’ R âˆª { + âˆ } æ˜¯ä¸€ä¸ªä¸‹åŠè¿ç»­çš„æ°å½“å‡½æ•°ï¼Œ g åœ¨ x âˆˆ M ä¸Šçš„Fr&#233;chetæ¬¡å¾®åˆ†å®šä¹‰ä¸º</p><p>âˆ‚ F g ( x ) : = { v âˆˆ T x M | âˆƒ ( x m , v m ) â†’ ( x , v ) , s . t . g ( x m ) â†’ g ( x ) , v m âˆˆ âˆ‚ F g ( x m ) }</p></sec><sec id="s7"><title>3. å“ˆè¾¾ç›æµå½¢ä¸Šçš„è¿‘ç«¯æ¢¯åº¦æ³•</title><p>åœ¨æ¬§å¼ç©ºé—´ä¸­è¿‘ç«¯ç®—æ³•å¯ä»¥çœ‹ä½œæ˜¯è§£å†³ä¸€äº›éå…‰æ»‘ã€æœ‰çº¦æŸã€å¤§è§„æ¨¡é—®é¢˜çš„å¸¸è§„æ–¹æ³•ã€‚æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»å“ˆè¾¾ç›æµå½¢ä¸Šçš„è¿‘ç«¯æ¢¯åº¦æ³•ã€‚</p><p>å®šä¹‰3.1 é»æ›¼æµå½¢ä¸Šçš„è¿‘ç«¯ç®—å­å®šä¹‰ä¸ºï¼š</p><p>x k + 1 : = p r o x Î» k g ( x â€² k ) = arg min x âˆˆ M ( g ( x ) + 1 2 Î» k d 2 ( x , x â€² k ) ) ,</p><p>å…¶ä¸­ï¼Œ x â€² k = exp x k ( âˆ’ Î» k grad f ( x k ) ) ã€‚</p><p>æˆ‘ä»¬æ¥ä¸‹æ¥ç»™å‡ºä¸‹åˆ—å‡è®¾ï¼š</p><p>å‡è®¾3.1 f æ˜¯ä¸€ä¸ªæ°å½“çš„ï¼Œå¹¶ä¸”åœ¨Mä¸Šæ˜¯G-Lå…‰æ»‘å‡½æ•°ï¼Œ g æ˜¯ä¸€ä¸ªæ°å½“çš„ï¼Œåœ¨Mä¸Šæ˜¯ä¸‹åŠè¿ç»­å‡½æ•°ã€‚</p><p>å‡è®¾3.2 å‡½æ•° F = f + g æ˜¯1-å¼ºåˆ¶çš„ï¼Œå¹¶ä¸”åœ¨Mä¸Šæœ‰ä¸‹ç•Œã€‚</p><p>å¼•ç†3.1 è®¾ Î© åœ¨ M ä¸Šæ˜¯ä¸€ä¸ªç´§é›†ï¼Œåˆ™å­˜åœ¨ä¸€ä¸ªå¸¸æ•° C ( 0 &lt; C &lt; + âˆ ) ä½¿å¾—ä»»æ„ x , y å’Œ z âˆˆ M ï¼Œéƒ½æœ‰</p><p>â€– exp x âˆ’ 1 z âˆ’ P ( x , y ) exp y âˆ’ 1 z â€– â‰¤ C d ( x , y ) (3)</p><p>è¯æ˜ï¼šç”±äº M æ˜¯ä¸€ä¸ªæœ‰é™ç»´å“ˆè¾¾ç›æµå½¢ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠ exp x âˆ’ 1 z çœ‹ä½œ x ç‚¹å¤„çš„å…‰æ»‘å‡½æ•°ï¼Œæ­¤æ—¶ï¼Œç»“è®ºå¾—è¯ã€‚</p><p>æ³¨ å®é™…ä¸Šï¼Œç”±å¼•ç†3.1æˆ‘ä»¬å¯ä»¥å¾—å‡º C â‰¥ 1 ã€‚æ¢¯åº¦å‘é‡åœºåœ¨ M ä¸Šï¼Œå½“ Î» = 1 æ—¶ï¼Œæ¢¯åº¦å‘é‡åœº grad 1 2 d 2 ( â‹… , z ) æ˜¯ä¸¥æ ¼å•è°ƒçš„ã€‚å› æ­¤ï¼Œå¯¹ä»»æ„ x , y å’Œ z âˆˆ M ï¼Œæˆ‘ä»¬æœ‰</p><p>âŒ© P ( x , y ) grad 1 2 d 2 ( â‹… , z ) âˆ’ grad 1 2 d 2 ( â‹… , z ) , exp x âˆ’ 1 y âŒª â‰¥ d 2 ( x , y )</p><p>å³ï¼Œ</p><p>âŒ© P ( x , y ) ( âˆ’ exp y âˆ’ 1 z ) âˆ’ exp x âˆ’ 1 z , exp x âˆ’ 1 y âŒª â‰¥ d 2 ( x , y )</p><p>å› æ­¤ï¼Œ</p><p>â€– exp x âˆ’ 1 z âˆ’ P ( x , y ) exp y âˆ’ 1 z â€– â‰¥ d ( x , y )</p><p>æ­¤æ—¶ï¼Œåœ¨å¼•ç†3.2ä¸­ C â‰¥ 1 ã€‚</p><p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ç»™å‡ºå“ˆè¾¾ç›æµå½¢ä¸Šæ»¡è¶³ä¸Šè¿°å‡è®¾çš„å®šæ­¥é•¿è¿‘ç«¯æ¢¯åº¦ç®—æ³•(å¦‚ä¸‹ç®—æ³•1)ã€‚</p><p>Algorithm 1. Upper proximal gradient method</p><p>ç®—æ³•1. Mä¸Šè¿‘ç«¯æ¢¯åº¦æ³•</p>æ”¶æ•›æ€§åˆ†æ<p>å®šç†3.1 å½“å‡è®¾3.1ï¼Œ3.2æˆç«‹æ—¶ï¼Œç®—æ³•1ç”Ÿæˆçš„è¿­ä»£åºåˆ— { x k } åœ¨ä¸€ä¸ªæœ‰ç•ŒåŒºåŸŸä¸­ï¼Œè®¾ x * æ˜¯ { x k } çš„ä»»æ„èšç‚¹ï¼Œåˆ™ 0 âˆˆ âˆ‚ F ( x * ) ã€‚</p><p>è¯æ˜ï¼š</p><p>x k + 1 = prox Î± g ( exp x k ( âˆ’ Î± grad f ( x k ) ) ) = arg min x âˆˆ M 1 2 Î± d 2 ( x , exp x k ( âˆ’ Î± grad f ( x k ) ) ) + g ( x ) (5)</p><p>ä»¤ Ï‰ k = exp x k ( âˆ’ Î± grad f ( x k ) ) ï¼Œåˆ™</p><p>g ( x k + 1 ) + 1 2 Î± d 2 ( x k + 1 , Ï‰ k ) â‰¤ g ( x k ) + 1 2 Î± d 2 ( x k , Ï‰ k )</p><p>ç”± f çš„G-Lå…‰æ»‘æ€§è´¨ï¼Œæˆ‘ä»¬æœ‰ï¼Œ</p><p>F ( x k + 1 ) = f ( x k + 1 ) + g ( x k + 1 ) â‰¤ f ( x k ) + âŒ© grad f ( x k ) , exp x k âˆ’ 1 x k + 1 âŒª + L 2 â€– exp x k âˆ’ 1 x k + 1 â€– 2 â€‰ â€‰ + g ( x k ) + 1 2 Î± ( d 2 ( x k , Ï‰ k ) âˆ’ d 2 ( x k + 1 , Ï‰ k ) ) (8)</p><p>ç”±ä½™å¼¦å®šç†ï¼Œæˆ‘ä»¬æœ‰ï¼Œ</p><p>d 2 ( x k , Ï‰ k ) âˆ’ d 2 ( x k + 1 , Ï‰ k ) â‰¤ âˆ’ d 2 ( x k + 1 , x k ) + 2 âŒ© grad f ( x k ) , exp x k âˆ’ 1 x k + 1 âŒª = âˆ’ â€– exp x k âˆ’ 1 x k + 1 â€– 2 âˆ’ 2 Î± âŒ© grad f ( x k ) , exp x k âˆ’ 1 x k + 1 âŒª (9)</p><p>ç”±(8)ï¼Œ(9)æˆ‘ä»¬å¯å¾—ï¼Œ</p><p>F ( x k + 1 ) â‰¤ F ( x k ) + 1 2 Î± ( âˆ’ â€– exp x k âˆ’ 1 x k + 1 â€– 2 âˆ’ 2 Î± âŒ© grad f ( x k ) , exp x k âˆ’ 1 x k + 1 âŒª ) â€‰ â€‰ + âŒ© grad f ( x k ) , exp x k âˆ’ 1 x k + 1 âŒª + L 2 â€– exp x k âˆ’ 1 x k + 1 â€– 2 = F ( x k ) âˆ’ ( 1 2 Î± âˆ’ L 2 ) â€– exp x k âˆ’ 1 x k + 1 â€– 2 . (10)</p><p>å› ä¸º Î± â‰¤ 1 L ï¼Œæ‰€ä»¥ï¼Œ F ( x k + 1 ) â‰¤ F ( x k ) ã€‚ä»è€Œå¯å¾— F ( x k ) æ˜¯éå¢çš„ï¼Œå› æ­¤ï¼Œæˆ‘ä»¬æœ‰</p><p>F ( x k ) â‰¤ F ( x 1 ) , âˆ€ k &gt; 0.</p><p>ç”±äº f æ˜¯1-å¼ºåˆ¶çš„ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ° { x k } æ˜¯æœ‰ç•Œçš„ï¼Œå› æ­¤ï¼Œ { x k } æœ‰èšç‚¹ã€‚å› ä¸º F ( x k ) æ˜¯éå¢çš„ä¸”æœ‰ç•Œï¼Œå› æ­¤ï¼Œ F åœ¨ { x k } æ‰€æœ‰çš„èšç‚¹ä¸Šéƒ½æœ‰ç›¸åŒçš„å€¼ï¼Œè®°ä¸º F * ã€‚</p><p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†è¯æ˜ { x k } åœ¨ä¸€ä¸ªæœ‰ç•ŒåŸŸä¸­ã€‚ç”±(10)ï¼Œæˆ‘ä»¬å¯å¾—</p><p>( 1 2 Î± âˆ’ L 2 ) â€– exp x k âˆ’ 1 x k + 1 â€– 2 â‰¤ F ( x k ) âˆ’ F ( x k + 1 )</p><p>å› æ­¤ï¼Œ</p><p>( 1 2 Î± âˆ’ L 2 ) âˆ‘ k = 1 âˆ â€– exp x k âˆ’ 1 x k + 1 â€– 2 â‰¤ F ( x 1 ) âˆ’ F * &lt; âˆ .</p><p>è¿›è€Œï¼Œ</p><p>â€– exp x k âˆ’ 1 x k + 1 â€– 2 â†’ 0 k â†’ âˆ</p><p>ç”±(5)çš„æœ€ä¼˜æ€§å¯å¾—ï¼Œ</p><p>0 âˆˆ âˆ‚ g ( x k + 1 ) + 1 2 Î± gradd 2 ( &#183; , Ï‰ k ) = grad f ( x k + 1 ) + âˆ‚ g ( x k + 1 ) âˆ’ grad f ( x k + 1 ) + 1 2 Î± gradd 2 ( &#183; , Ï‰ k ) ,</p><p>ä¹‹åï¼Œæˆ‘ä»¬æœ‰ï¼Œ</p><p>grad f ( x k + 1 ) âˆ’ 1 2 Î± gradd 2 ( &#183; , Ï‰ k ) âˆˆ âˆ‚ F ( x k + 1 )</p><p>å› æ­¤ï¼Œ</p><p>â€– grad f ( x k + 1 ) âˆ’ 1 2 Î± gradd 2 ( &#183; , Ï‰ k ) â€– = â€– grad f ( x k + 1 ) âˆ’ 1 Î± ( âˆ’ exp x k + 1 âˆ’ 1 Ï‰ k ) â€– = â€– grad f ( x k + 1 ) âˆ’ P ( x k , x k + 1 ) grad f ( x k ) + P ( x k , x k + 1 ) grad f ( x k ) + 1 Î± exp x k + 1 âˆ’ 1 Ï‰ k â€– â‰¤ L â€– exp x k âˆ’ 1 x k + 1 â€– + 1 Î± â€– P ( x k , x k + 1 ) Î± grad f ( x k ) + exp x k + 1 âˆ’ 1 Ï‰ k â€– .</p><p>å› ä¸º f æ˜¯G-Lå…‰æ»‘çš„ï¼Œä¸” { x k } åœ¨ä¸€ä¸ªæœ‰ç•ŒåŸŸä¸Šï¼Œå­˜åœ¨ä¸€ä¸ªç´§é›† Î© 1 âŠƒ { x k } ä½¿å¾— grad f ( x ) çš„èŒƒæ•°å¯¹äºä»»æ„ x âˆˆ Î© 1 æ˜¯æœ‰é™çš„ï¼Œé‚£ä¹ˆï¼Œ { Ï‰ k } è‡ªç„¶åœ¨ä¸€ä¸ªæœ‰ç•ŒåŒºåŸŸ Î© 2 ä¸­ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜å¯å¾—åˆ° { x k } ï¼Œ { Ï‰ k } éƒ½åœ¨ä¸€ä¸ªç´§é›† Î© ä¸­ã€‚å› æ­¤ï¼Œç”±å¼•ç†å¯å¾—ï¼Œå­˜åœ¨ä¸€ä¸ªå¸¸æ•° C ï¼Œä½¿å¾—ï¼Œ</p><p>â€– P ( x k , x k + 1 ) Î± grad f ( x k ) + exp x k + 1 âˆ’ 1 Ï‰ k â€– = â€– P ( x k , x k + 1 ) ( exp x k âˆ’ 1 Ï‰ k ) + exp x k + 1 âˆ’ 1 Ï‰ k â€– â‰¤ C â€– exp x k âˆ’ 1 x k + 1 â€– . (16)</p><p>ç”±(14)ï¼Œ(15)ï¼Œ(16)æˆ‘ä»¬å¯ä»¥å¾—å‡º</p><p>â€– grad f ( x k + 1 ) âˆ’ 1 2 Î± gradd 2 ( &#183; , Ï‰ k ) â€– â‰¤ ( L + C Î± ) â€– exp x k âˆ’ 1 x k + 1 â€– â†’ 0 , k â†’ âˆ . (17)</p><p>è®¾ x * æ˜¯ { x k } çš„ä»»æ„èšç‚¹ï¼Œå½“ j â†’ âˆ æ—¶ï¼Œ { x k } çš„å­åˆ— x k j â†’ x * ã€‚æˆ‘ä»¬ç°åœ¨è¯æ˜ 0 âˆˆ âˆ‚ F ( x * ) ã€‚ç”±(5)æˆ‘ä»¬çŸ¥é“</p><p>g ( x k j + 1 ) + 1 2 Î± gradd 2 ( x k j + 1 , Ï‰ k j ) â‰¤ g ( x * ) + 1 2 Î± gradd 2 ( x * , Ï‰ k j ) ,</p><p>é‚£ä¹ˆï¼Œ</p><p>g ( x k j + 1 ) â‰¤ g ( x * ) + 1 2 Î± ( gradd 2 ( x * , Ï‰ k j ) âˆ’ gradd 2 ( x k j + 1 , Ï‰ k j ) ) .</p><p>æœ‰ä½™å¼¦å®šç†ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°</p><p>g ( x k j + 1 ) â‰¤ g ( x * ) âˆ’ 1 2 Î± gradd 2 ( x k j + 1 , x * ) + 1 Î± âŒ© exp x * âˆ’ 1 x k j + 1 , exp x * âˆ’ 1 Ï‰ k j âŒª .</p><p>ç”±äº { Ï‰ k } åœ¨ä¸€ä¸ªæœ‰ç•ŒåŒºåŸŸä¸­ï¼Œå¯¹äºä»»æ„ j &gt; 0 ï¼Œ exp x * âˆ’ 1 x k j + 1 è‡ªç„¶ä¹Ÿæ˜¯æœ‰ç•Œçš„ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æœ‰</p><p>lim sup j â†’ âˆ g ( x k j + 1 ) â‰¤ g ( x * ) .</p><p>æ­¤å¤–ï¼Œç”± g ( x ) ä¸‹åŠè¿ç»­ï¼Œæˆ‘ä»¬æœ‰</p><p>lim inf j â†’ âˆ g ( x k j + 1 ) â‰¥ g ( x * ) .</p><p>æ‰€ä»¥ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°</p><p>lim j â†’ âˆ g ( x k j + 1 ) = g ( x * ) . (18)</p><p>ç”± f ( x ) çš„è¿ç»­æ€§å’Œ(18)ï¼Œå¯çŸ¥å½“ j â†’ âˆ ï¼Œ</p><p>F ( x k j + 1 ) â†’ F ( x * ) .</p><p>ç”±(14)ï¼Œ(17)â€”(19)ï¼Œä»¥åŠæ¬¡å¾®åˆ†çš„å®šä¹‰å¯å¾—</p><p>0 âˆˆ âˆ‚ F ( x * ) .</p></sec><sec id="s8"><title>4. ç»“è®º</title><p>æœ¬æ–‡é’ˆå¯¹äºæå°åŒ–éå‡¸éå…‰æ»‘å‡½æ•°é—®é¢˜ï¼Œä¸»è¦ç ”ç©¶äº†å“ˆè¾¾ç›æµå½¢ä¸Šçš„è¿‘ç«¯æ¢¯åº¦ç®—æ³•ï¼Œæˆ‘ä»¬é¦–å…ˆå°†æ¬§å¼ç©ºé—´çš„è¿‘ç«¯æ¢¯åº¦ç®—æ³•æ¨å¹¿åˆ°å“ˆè¾¾ç›æµå½¢ä¸Šï¼Œå†æ ¹æ®è¯¥æµå½¢çš„ä¼˜è‰¯ç»“æ„ï¼Œç»™å‡ºæµå½¢ä¸Šè¿‘ç«¯æ¢¯åº¦æ³•çš„æ”¶æ•›æ€§è¯æ˜ã€‚ç†è®ºä¸Šï¼Œæˆ‘ä»¬å¯ä»¥å¾—å‡ºæˆ‘ä»¬æå‡ºçš„å“ˆè¾¾ç›æµå½¢ä¸Šçš„è¿‘ç«¯æ¢¯åº¦ç®—æ³•æ˜¯æ”¶æ•›çš„ã€‚ç”±äºæµå½¢ä¸Šéçº¿æ€§æ€§è´¨ï¼Œæ”¶æ•›é€Ÿåº¦çš„ç†è®ºç ”ç©¶å­˜åœ¨ä¸€å®šçš„å›°éš¾ï¼Œè¿˜éœ€è¦è¿›ä¸€æ­¥ç ”ç©¶ã€‚</p></sec><sec id="s9"><title>æ–‡ç« å¼•ç”¨</title><p>å®‹ä¹ä¹. å“ˆè¾¾ç›æµå½¢ä¸Šçš„è¿‘ç«¯æ¢¯åº¦æ³•æ”¶æ•›æ€§åˆ†æAnalysis of Convergence of Proximal Gradient Method on Hadamard Manifold[J]. ç†è®ºæ•°å­¦, 2021, 11(05): 701-708. https://doi.org/10.12677/PM.2021.115085</p></sec><sec id="s10"><title>å‚è€ƒæ–‡çŒ®</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.42212-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Colao, V., LÃ³pez, G., Marino, G. and MartÃ­n-MÃ¡rquez, V. (2012) Equilibrium Problems in Hadamard Manifolds. Journal of Mathematical Analysis and Applications, 388, 61-77. &lt;br&gt;https://doi.org/10.1016/j.jmaa.2011.11.001</mixed-citation></ref><ref id="hanspub.42212-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Sakai, T. (1996) Riemannian Geometry (Translations of Mathematical Monographs). American Mathematical Society, Providence, 262-272. &lt;br&gt;https://doi.org/10.1090/mmono/149</mixed-citation></ref><ref id="hanspub.42212-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Zhang, H.C. and Hager, W.W. (2004) A Nonmonotone Line Search Technique and Its Application to Unconstrained Optimization. SIAM Journal on Imaging Sciences, 14, 1043-1056. &lt;br&gt;https://doi.org/10.1137/S1052623403428208</mixed-citation></ref><ref id="hanspub.42212-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Beck, A. and Teboulle, M. (2009) A Fast Iterative Shrinkage-Thresholding Algorithm for Linear Inverse Problems. SIAM Journal on Imaging Sciences, 2, 183-202. &lt;br&gt;https://doi.org/10.1137/080716542</mixed-citation></ref><ref id="hanspub.42212-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Ying, S., Wen, Z., Shi, J., Peng, Y., Peng, J. and Qiao, H. (2018) Manifold Preserving: An Intrinsic Approach for Semisupervised Distance Metric Learning. IEEE Transactions on Neural Networks and Learning Systems, 29, 2731-2742.</mixed-citation></ref><ref id="hanspub.42212-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Li, H., Fang, C. and Lin, Z. (2020) Accelerated First-Order Optimization Algorithms for Machine Learning. Proceedings of the IEEE, 108, 2067-2082. &lt;br&gt;https://doi.org/10.1109/JPROC.2020.3007634</mixed-citation></ref><ref id="hanspub.42212-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Wang, Q., Yuen, P.C. and Feng, G. (2013) Semi-Supervised Metric Learning via Topology Preserving Multiple Semi-Su- pervised Assumptions. Pattern Recognition, 46, 2576-2587. &lt;br&gt;https://doi.org/10.1016/j.patcog.2013.02.015</mixed-citation></ref><ref id="hanspub.42212-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Absil, P.A., Mahony, R. and Sepulchre, R. (2009) Optimization Algorithms on Matrix Manifolds. Princeton University Press, Princeton. &lt;br&gt;https://doi.org/10.1515/9781400830244</mixed-citation></ref><ref id="hanspub.42212-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">BacÃ¡k, M. (2014) Convex Analysis and Optimization in Hdamard Spaces, Vol. 22. Walter de Gruyter GmbH &amp; Co KG.  
&lt;br&gt;https://doi.org/10.1515/9783110361629</mixed-citation></ref><ref id="hanspub.42212-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Ruizgarzon, G., Osunagomez, R. and Ruizzapatero, J. (2019) Nec-essary and Sufficient Optimality Conditions for Vector Equilibrium Problems on Hadamard Manifolds. Symmetry, 11, 1037. &lt;br&gt;https://doi.org/10.3390/sym11081037</mixed-citation></ref><ref id="hanspub.42212-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Ferreira, O.P., Louzeiro, M.S. and Prudente, L.F. (2019) Gra-dient Method for Optimization on Riemannian Manifolds with Lower Bounded Curvature. SIAM Journal on Optimiza-tion, 29, 2517-2541. &lt;br&gt;https://doi.org/10.1137/18M1180633</mixed-citation></ref><ref id="hanspub.42212-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Ferreira, O.P. and Oliveira, P.R. (2002) Proximal Point Algorithm on Riemannian Manifolds. Optimization, 51, 257-270.  
&lt;br&gt;https://doi.org/10.1080/02331930290019413</mixed-citation></ref><ref id="hanspub.42212-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Bento, G.C., Ferreira, O.P. and Melo, J.G. (2017) Itera-tion-Complexity of Gradient, Subgradient and Proximal Point Methods on Riemannian Manifolds. Journal of Optimi-zation Theory and Applications, 173, 548-562.  
&lt;br&gt;https://doi.org/10.1007/s10957-017-1093-4</mixed-citation></ref><ref id="hanspub.42212-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">Wang, J., Li, C., Lopez, G. and Yao, J.-C. (2015) Convergence Analysis of Inexact Proximal Point Algorithms on Hadamard Manifolds. Journal of Global Optimization, 61, 553-573. &lt;br&gt;https://doi.org/10.1007/s10898-014-0182-2</mixed-citation></ref><ref id="hanspub.42212-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">Bento, G.C., Cruz Neto, J.X. and Oliveira, P.R. (2016) A New Approach to the Proximal Point Method: Convergence on General Riemannian Manifolds. Journal of Optimization Theory and Applications, 168, 743-755.  
&lt;br&gt;https://doi.org/10.1007/s10957-015-0861-2</mixed-citation></ref><ref id="hanspub.42212-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">Bento, G.C., Ferreira, O.P. and Oliveira, P.R. (2018) Proximal Point Method for Vector Optimization on Hadamard Manifolds. Operations Research Letters, 46, 13-18. &lt;br&gt;https://doi.org/10.1016/j.orl.2017.10.017</mixed-citation></ref><ref id="hanspub.42212-ref17"><label>17</label><mixed-citation publication-type="other" xlink:type="simple">Ansari, Q.H., Babu, F. and Yao, J.-C. (2019) Regularization of Proximal Point Algorithms in Hadamard Manifolds. Journal of Fixed Point Theory and Applications, 21, Article No. 25. &lt;br&gt;https://doi.org/10.1007/s11784-019-0658-2</mixed-citation></ref><ref id="hanspub.42212-ref18"><label>18</label><mixed-citation publication-type="other" xlink:type="simple">Baygorrea, N., Papa Quiroz, E.A. and Maculan, N. (2016) Inexact Proximal Point Methods for Quasiconvex Minimization on Hadamard Manifolds. Journal of the Operations Research Society of China, 4, 397-424.  
&lt;br&gt;https://doi.org/10.1007/s40305-016-0133-3</mixed-citation></ref><ref id="hanspub.42212-ref19"><label>19</label><mixed-citation publication-type="other" xlink:type="simple">Baygorrea, N., Papa Quiroz, E.A. and Maculan, N. (2017) On the Convergence Rate of an Inexact Proximal Point Algorithm for Quasiconvex Minimization on Hadamard Manifolds. Journal of the Operations Research Society of China, 5, 457-467. &lt;br&gt;https://doi.org/10.1007/s40305-016-0129-z</mixed-citation></ref><ref id="hanspub.42212-ref20"><label>20</label><mixed-citation publication-type="other" xlink:type="simple">Tang, F.M. and Huang, P.L. (2017) On the Convergence Rate of a Proximal Point Algorithm for Vector Function on Hadamard Manifolds. Journal of the Operations Research Society of China, 5, 405-417.  
&lt;br&gt;https://doi.org/10.1007/s40305-016-0146-y</mixed-citation></ref><ref id="hanspub.42212-ref21"><label>21</label><mixed-citation publication-type="other" xlink:type="simple">Chen, S., Ma, S., Man-Cho So, A. and Zhang, T. (2020) Proximal Gradient Method for Nonsmooth Optimization over the Stiefel Manifold. SIAM Journal on Optimization, 30, 210-239. &lt;br&gt;https://doi.org/10.1137/18M122457X</mixed-citation></ref><ref id="hanspub.42212-ref22"><label>22</label><mixed-citation publication-type="other" xlink:type="simple">Torres Almeida, Y., Cruz Neto, J.X., Oliveira, P.R. and Oliveira Souza, J.C. (2020) A Modified Proximal Point Method for DC Functions on Hadamard Manifolds. Computational Optimization and Applications, 76, 649-673.  
&lt;br&gt;https://doi.org/10.1007/s10589-020-00173-3</mixed-citation></ref></ref-list></back></article>