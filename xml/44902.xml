<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2021.118223</article-id><article-id pub-id-type="publisher-id">CSA-44902</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20210800000_49319859.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于改进的近似
  l
  <sub>0</sub>范数的稀疏信号重构算法
  A Sparse Signal Reconstruction Algorithm Based on Improved Approximate 
  l
  <sub>0</sub> Norm
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>张</surname><given-names>慧萍</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>张</surname><given-names>连娜</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>李</surname><given-names>荣鹏</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>宋</surname><given-names>学力</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>长安大学理学院，陕西 西安</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>02</day><month>08</month><year>2021</year></pub-date><volume>11</volume><issue>08</issue><fpage>2179</fpage><lpage>2189</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   稀疏信号重构算法是压缩感知的关键。基于近似l<sub>0</sub>范数的稀疏信号重构可以通过选取一个光滑函数近似l<sub>0</sub>范数，从而将l<sub>0</sub>范数最小化问题转化为光滑函数的优化问题。为了提高压缩感知中稀疏信号重构的精度，本文提出了一种基于改进的近似l<sub>0</sub>范数的稀疏信号重构算法。该算法首先利用一种改进的光滑函数来近似l<sub>0</sub>范数；其次利用外点罚函数法和共轭梯度法求解基于该光滑函数的优化问题的稀疏解；最后进行了多项实验来验证所提出算法的有效性。实验结果表明：相比于光滑l0算法、基追踪算法和非凸复合稀疏基算法，本文所提算法在重构误差、信噪比和恢复成功率等方面更具优越性。 The sparse signal reconstruction algorithm is the key to compressive sensing. The sparse signal reconstruction based on approximate l<sub>0</sub> norm can be achieved by choosing a smooth function to approximate l<sub>0</sub> norm, thus the minimization problem of l<sub>0</sub> norm is transformed into an optimization problem of a smooth function. To improve the accuracy of the sparse signal reconstruction in compressive sensing, a sparse signal reconstruction algorithm based on an improved approximate l<sub>0</sub> norm is proposed in this paper. Firstly, a smooth function is proposed to approximate l<sub>0</sub> norm. Then, the sparse solution of this optimization problem that based on the smooth function is solved by exterior point penalty function method and conjugate gradient method. Finally, a number of experiments are carried out to verify the performance of the proposed algorithm. The experimental results show that the proposed algorithm is more superior in reconstruction error, signal-to-noise ratio and recovery success rate compared with smoothed l0 algorithm, the basis pursuit algorithm and the non-convex composite sparse bases algorithm. 
  
 
</p></abstract><kwd-group><kwd>压缩感知，信号重构，近似l<sub>0</sub>范数，共轭梯度法, Compressive Sensing</kwd><kwd> Signal Reconstruction</kwd><kwd> Approximate l<sub>0</sub> Norm</kwd><kwd> Conjugate Gradient Method</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>摘要</title><p>稀疏信号重构算法是压缩感知的关键。基于近似l<sub>0</sub>范数的稀疏信号重构可以通过选取一个光滑函数近似l<sub>0</sub>范数，从而将l<sub>0</sub>范数最小化问题转化为光滑函数的优化问题。为了提高压缩感知中稀疏信号重构的精度，本文提出了一种基于改进的近似l<sub>0</sub>范数的稀疏信号重构算法。该算法首先利用一种改进的光滑函数来近似l<sub>0</sub>范数；其次利用外点罚函数法和共轭梯度法求解基于该光滑函数的优化问题的稀疏解；最后进行了多项实验来验证所提出算法的有效性。实验结果表明：相比于光滑l<sub>0</sub>算法、基追踪算法和非凸复合稀疏基算法，本文所提算法在重构误差、信噪比和恢复成功率等方面更具优越性。</p></sec><sec id="s2"><title>关键词</title><p>压缩感知，信号重构，近似l<sub>0</sub>范数，共轭梯度法</p></sec><sec id="s3"><title>A Sparse Signal Reconstruction Algorithm Based on Improved Approximate l<sub>0</sub> Norm<sup> </sup></title><p>Huiping Zhang, Lianna Zhang, Rongpeng Li, Xueli Song<sup>*</sup></p><p>School of Science, Chang’an University, Xi’an Shaanxi</p><p><img src="//html.hanspub.org/file/17-1542252x5_hanspub.png?20210902075851635" /></p><p>Received: Jul. 28<sup>th</sup>, 2021; accepted: Aug. 24<sup>th</sup>, 2021; published: Aug. 31<sup>st</sup>, 2021</p><p><img src="//html.hanspub.org/file/17-1542252x6_hanspub.png?20210902075851635" /></p></sec><sec id="s4"><title>ABSTRACT</title><p>The sparse signal reconstruction algorithm is the key to compressive sensing. The sparse signal reconstruction based on approximate l<sub>0</sub> norm can be achieved by choosing a smooth function to approximate l<sub>0</sub> norm, thus the minimization problem of l<sub>0</sub> norm is transformed into an optimization problem of a smooth function. To improve the accuracy of the sparse signal reconstruction in compressive sensing, a sparse signal reconstruction algorithm based on an improved approximate l<sub>0</sub> norm is proposed in this paper. Firstly, a smooth function is proposed to approximate l<sub>0</sub> norm. Then, the sparse solution of this optimization problem that based on the smooth function is solved by exterior point penalty function method and conjugate gradient method. Finally, a number of experiments are carried out to verify the performance of the proposed algorithm. The experimental results show that the proposed algorithm is more superior in reconstruction error, signal-to-noise ratio and recovery success rate compared with smoothed l<sub>0</sub> algorithm, the basis pursuit algorithm and the non-convex composite sparse bases algorithm.</p><p>Keywords:Compressive Sensing, Signal Reconstruction, Approximate l<sub>0</sub> Norm, Conjugate Gradient Method</p><disp-formula id="hanspub.44902-formula11"><graphic xlink:href="//html.hanspub.org/file/17-1542252x7_hanspub.png?20210902075851635"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2021 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/17-1542252x8_hanspub.png?20210902075851635" /> <img src="//html.hanspub.org/file/17-1542252x9_hanspub.png?20210902075851635" /></p></sec><sec id="s5"><title>1. 引言</title><p>传统的数据采集需要满足奈奎斯特采样定理，即为了不失真的恢复信号，采样频率必须大于信号最高带宽的两倍。但在这一理论指导下所获得的信息是冗余的，极大的影响了信息领域的发展。压缩感知(Compressive Sensing, CS) [<xref ref-type="bibr" rid="hanspub.44902-ref1">1</xref>] 是一种新型的信号采集与重构理论，它可通过远低于奈奎斯特标准的方式进行数据采样，并仍能够精确地恢复稀疏信号。该理论提出后，在阵列信号处理 [<xref ref-type="bibr" rid="hanspub.44902-ref2">2</xref>]、医学影像 [<xref ref-type="bibr" rid="hanspub.44902-ref3">3</xref>] 和雷达探测 [<xref ref-type="bibr" rid="hanspub.44902-ref4">4</xref>] 等领域受到高度关注，展现出了巨大的应用价值。压缩感知理论主要包括三部分：信号的稀疏表示、测量矩阵的设计和稀疏信号重构。其中，稀疏信号重构是指从较少的测量值中精确地恢复原始信号，是CS理论中最重要的一部分。信号的重构精度主要取决于重构算法的性能，设计高效的重构算法是提高稀疏信号重构精度的关键。因此，稀疏信号重构算法具有重要的研究意义。</p><p>从数学的角度来看，通常使用以下最小化方法对稀疏信号重构问题进行建模 [<xref ref-type="bibr" rid="hanspub.44902-ref5">5</xref>]：</p><p>min x ∈ R n ‖ x ‖ 0         s .t .     A x = b (1)</p><p>其中 A ∈ R m &#215; n ( m &lt; n ) 是感知矩阵， b ∈ R m 是测量向量， x ∈ R n 是未知的稀疏向量， ‖ x ‖ 0 是实向量x的零范数。</p><p>然而，由于l<sub>0</sub>范数的不连续性，使得基于l<sub>0</sub>范数的重构模型的直接求解是NP (Non-deterministic Polynomial)难的 [<xref ref-type="bibr" rid="hanspub.44902-ref6">6</xref>]，其计算量会随稀疏向量维数的增加而增大，且模型的抗噪能力较差。为此学者们提出了很多方法对最小化l<sub>0</sub>范数进行近似求解，如贪婪方法、凸松弛方法和非凸松弛方法等。贪婪算法通过选择与信号重构残差最匹配的原子进行信号重构，传统的贪婪算法有正交匹配追踪算法 [<xref ref-type="bibr" rid="hanspub.44902-ref7">7</xref>]、广义正交匹配追踪算法 [<xref ref-type="bibr" rid="hanspub.44902-ref8">8</xref>] 和子空间追踪算法 [<xref ref-type="bibr" rid="hanspub.44902-ref9">9</xref>] 等，这类算法重构理论简单、计算速度较快，但重构精度较低，需要更多观测值。凸松弛方法将最小化l<sub>0</sub>范数转化为最小化l<sub>1</sub>范数，其中典型的算法有基追踪算法 [<xref ref-type="bibr" rid="hanspub.44902-ref10">10</xref>]、迭代阈值算法 [<xref ref-type="bibr" rid="hanspub.44902-ref11">11</xref>] 和梯度投影法 [<xref ref-type="bibr" rid="hanspub.44902-ref12">12</xref>] 等，这类算法重构精度较高、所需测量值较少，但计算复杂度较高，不适合求解大规模问题。因此这两类算法应用范围有限。</p><p>近年来，利用非凸松弛方法近似求解l<sub>0</sub>范数受到了广泛关注。常见的非凸松弛方法使用l<sub>p</sub>范数、高斯类函数或分式类函数近似l<sub>0</sub>范数，其中高斯类函数是一种最常见的近似函数。最早Mohimani等人提出了光滑l<sub>0</sub> (Smoothed l<sub>0 </sub>norm, SL0)算法 [<xref ref-type="bibr" rid="hanspub.44902-ref13">13</xref>]，该算法利用标准高斯函数近似l<sub>0</sub>范数，并结合最速下降法寻求最优解；随后林婉娟等人提出了利用双曲正切函数和修正牛顿法的牛顿光滑l<sub>0</sub> (Newton Smoothed l<sub>0 </sub>norm, NSL0)算法 [<xref ref-type="bibr" rid="hanspub.44902-ref14">14</xref>]；张巍等人通过引入近似双曲正切函数和混合优化方法提出了近似阻尼牛顿光滑l<sub>0</sub> (Almost- Hybird Newton Smoothed l<sub>0 </sub>norm, A-HNSL0)算法 [<xref ref-type="bibr" rid="hanspub.44902-ref15">15</xref>]；2020年，周洁容等人提出的非凸复合稀疏基(Non-convex Composite Sparse bases, NCCS)算法 [<xref ref-type="bibr" rid="hanspub.44902-ref16">16</xref>] 中采用复合指数函数近似l<sub>0</sub>范数，并结合外点罚函数法和共轭梯度法求得最优解。这类方法对稀疏信号的恢复性能由所使用的函数对l<sub>0</sub>范数的逼近程度以及对该函数的求解方法所决定。</p><p>SL0算法具有重构速度快，算法简单等优点，但该算法采用的高斯函数的陡峭性不大，不能更好地逼近l<sub>0</sub>范数，且利用最速下降法进行求解会产生“锯齿现象”，不能求得全局最优解，从而导致算法重构精度不高。针对以上不足，本文利用一种陡峭性更强的非凸光滑函数逼近l<sub>0</sub>范数，并通过外点罚函数法和共轭梯度法求得稀疏解，提出了一种改进的近似l<sub>0</sub>范数的稀疏信号重构算法，即INCS (Improved non-convex sparse bases)算法。最后通过仿真实验验证了本文算法在重构误差、信噪比和恢复成功率等方面较于SL0算法、基追踪算法和NCCS算法的优越性。</p></sec><sec id="s6"><title>2. SL0算法</title><p>压缩感知中稀疏信号重构算法是求解最优化问题(1)，对任意的 x ∈ R n ， ‖ x ‖ 0 可表示为 ‖ x ‖ 0 = ∑ i = 1 n δ ( x i ) ，其中 δ ( x i ) = { 0 x i = 0 1 x i ≠ 0 。</p><p>由于l<sub>0</sub>范数是不连续的，SL0算法中Mohimani等人首次提出利用连续函数 f σ ( x i ) = 1 − e − x i 2 2 σ 2 来逼近 δ ( x i ) ，其中 σ ( 0 &lt; σ &lt; 1 ) 为控制参数，显然有：</p><p>lim σ → 0 f σ ( x i ) = { 0 x i = 0 1 x i ≠ 0 (2)</p><p>令 F σ ( x ) = ∑ i = 1 n f σ ( x i ) ，对任意的 x ∈ R n ，可得到 lim σ → 0 F σ ( x ) = ‖ x ‖ 0 。故最小化l<sub>0</sub>范数问题(1)可转化为</p><p>以下优化问题：</p><p>min x F σ ( x )         s .t .       A x = b (3)</p><p>SL0算法利用最速下降法和梯度投影原理求解该优化问题。该算法具有重构速度快，算法简单等优点，但采用的连续函数的陡峭性不大，使得近似l<sub>0</sub>范数的估计不准确；且最速下降法会出现“锯齿现象”，不能求得全局最优解，从而导致算法的重构精度不高。</p></sec><sec id="s7"><title>3. 基于改进的近似l<sub>0</sub>范数的稀疏信号重构算法</title><sec id="s7_1"><title>3.1. 改进的近似l<sub>0</sub>范数</title><p>为了提高近似函数对l<sub>0</sub>范数的逼近程度，本文采用一种改进的非凸光滑函数近似l<sub>0</sub>范数：</p><p>f σ ( x ) = 1 − e − c | x | σ 2 (4)</p><p>其中c为大于等于1的常数， σ ( 0 &lt; σ &lt; 1 ) 为控制参数。</p><p>文献 [<xref ref-type="bibr" rid="hanspub.44902-ref13">13</xref>] 和 [<xref ref-type="bibr" rid="hanspub.44902-ref16">16</xref>] 中分别采用了以下两种函数来近似l<sub>0</sub>范数：</p><p>p σ ( x ) = 1 − e − x 2 2 σ 2 、 h σ ( x ) = 1 − e − | x | σ ( | x | + σ )</p><p>下面从几何图像和理论分析上说明本文提出的函数 f σ ( x ) 比函数 p σ ( x ) 和 h σ ( x ) 更逼近l<sub>0</sub>范数。</p><p>1) 几何图像分析</p><p>函数 f σ ( x ) 、 p σ ( x ) 和 h σ ( x ) 的几何图像如图1所示，可以看出，函数 f σ ( x ) 的图像曲线相比于其他两种函数更陡峭，即函数 f σ ( x ) 对l<sub>0</sub>范数的逼近效果更好。</p><p>图1. σ = 0.1 , c = 1 时三种函数的对比图</p><p>2) 理论分析</p><p>假定 x ≥ 0 ，则对区间内任意 σ ( σ ≠ 0 ) 有 p σ ( x ) = 1 − e − x 2 2 σ 2 、 h σ ( x ) = 1 − e − x σ ( x + σ ) 、 f σ ( x ) = 1 − e − c x σ 2 ，</p><p>因为</p><p>h σ ( x ) − p σ ( x ) = e − x 2 2 σ 2 − e − x σ ( x + σ ) (5)</p><p>所以比较函数 p σ ( x ) 和 h σ ( x ) 的大小只需要比较他们的指数大小，易得：</p><p>− x 2 2 σ 2 − ( − x σ ( x + σ ) ) = x σ ( 1 x + σ − x 2 σ ) ≥ 0 (6)</p><p>因此 h σ ( x ) ≥ p σ ( x ) ；</p><p>同理</p><p>f σ ( x ) − h σ ( x ) = e − x σ ( x + σ ) − e − c x σ 2 (7)</p><p>因为</p><p>− x σ ( x + σ ) − ( − c x σ 2 ) = x σ ( c σ − 1 x + σ ) ≥ 0 (8)</p><p>所以 f σ ( x ) ≥ h σ ( x ) 。</p><p>利用函数对称性， x &lt; 0 时也可类似讨论。因此可以得到 p σ ( x ) ≤ h σ ( x ) ≤ f σ ( x ) ，即当 x ≠ 0 时，函数 f σ ( x ) 对应的函数值比其他两种函数对应的函数值更加接近于1，这意味着函数 f σ ( x ) 比其他两种函数更逼近l<sub>0</sub>范数。</p></sec><sec id="s7_2"><title>3.2. 算法实现</title><p>下面基于所改进的函数 f σ ( x ) 对(3)式进行求解。令 x = u − v ，其中 u , v ∈ R n ，u为x中所有的正元，其余元素为零；v为x中所有负元的绝对值，其余元素也为零，利用 z = [ u T , v T ] T ∈ R 2 n 表示拼接向量。</p><p>经过替换，可得：</p><p>F σ ( z ) = F σ ( x ) = ∑ i = 1 2 n ( 1 − e − c z i σ 2 ) (9)</p><p>此时约束条件 A x = b 转化为 [ A , − A ] z = b ，所以(3)式转化为：</p><p>min z F σ ( z )         s .t .     [ A , − A ] z = b , z ≥ 0 (10)</p><p>为了方便求解(10)式，利用非凸函数 F σ ( z ) 的一阶判别条件及优化最小化(Majorize-Minorize, MM)方法 [<xref ref-type="bibr" rid="hanspub.44902-ref17">17</xref>] 对目标函数 F σ ( z ) 进行放缩，可得：</p><p>F σ ( z ) ≤ F σ ( z ˜ ) + 〈 z − z ˜ , ∇ F σ ( z ˜ ) 〉 ≤ F σ ( z ˜ ) + 〈 z − z ˜ , ∇ F σ ( z ˜ ) 〉 + λ ( ‖ z − z ˜ ‖ 2 2 + ‖ z − z ˜ ‖ 1 ) (11)</p><p>记</p><p>H σ ( z , z ˜ ) = F σ ( z ˜ ) + 〈 z − z ˜ , ∇ F σ ( z ˜ ) 〉 + λ ( ‖ z − z ˜ ‖ 2 2 + ‖ z − z ˜ ‖ 1 ) (12)</p><p>其中 z , z ˜ 为可行域中的点， λ ( λ &gt; 1 / σ 2 ) 为常值，则 H σ ( z , z ˜ ) 为 F σ ( z ) 的一个上界函数。</p><p>忽略常值后，则(10)式的解由下式迭代求得：</p><p>z k + 1 σ = arg min z { 〈 ∇ F σ ( z k σ ) , z 〉 + λ ( ‖ z − z k σ ‖ 2 2 + ‖ z − z k σ ‖ 1 ) | [ A , − A ] z = b , z ≥ 0 } (13)</p><p>其中 z k σ ( k = 1 , 2 , 3 , ⋯ ) 为可行域中的点，取值与 σ 有关。</p><p>令</p><p>{ 〈 ∇ F σ ( z ˜ σ ) , z 〉 + λ ( ‖ z − z ˜ ‖ 2 2 + ‖ z − z ˜ ‖ 1 ) = G ( z ) [ A , − A ] z − b = H ( z ) = ( h 1 ( z ) , ⋯ , h m ( z ) ) T z = W ( z ) = ( w 1 ( z ) , ⋯ , w 2 n ( z ) ) T</p><p>则(13)可简记为：</p><p>min z G ( z )         s .t .     H ( z ) = 0 , W ( z ) ≥ 0 (14)</p><p>因此，(3)式的优化问题转化为(14)式的优化问题。</p><p>本文利用外点罚函数法 [<xref ref-type="bibr" rid="hanspub.44902-ref18">18</xref>] 和共轭梯度法迭代求解(14)式，具体步骤如下：</p><p>利用外点罚函数法引入正数M，本文取 M = 1 ，放大倍数为5，将(14)式转化为以下无约束问题：</p><p>z k + 1 σ = arg min z L z k σ ( z , M ) (15)</p><p>其中</p><p>L z k σ ( z , M ) = 〈 ∇ F σ ( z k σ ) , z 〉 + λ ( ‖ z − z k σ ‖ 2 2 + ‖ z − z k σ ‖ 1 ) + M ( I T ⋅ U ( z ) + I T ⋅ H ( z ) ) (16)</p><p>式中I为 2 n &#215; 1 的单位向量， U ( z ) = ( min ( 0 , z 1 2 ) , ⋯ , min ( 0 , z 2 n 2 ) ) T ， H ( z ) = d i a g ( [ A , − A ] z − b ) ⋅ ( [ A , − A ] z − b ) ，则函数 L z k σ ( z , M ) 有关z的一阶、二阶次梯度 [<xref ref-type="bibr" rid="hanspub.44902-ref19">19</xref>] 分别为：</p><p>∇ L z k σ ( z , M ) = ∇ F σ ( z k σ ) + λ ( 2 ( z − z k σ ) + sgn ( z − z k σ ) ) + 2 M { V ( z ) + [ A , − A ] T ⋅ ( [ A , − A ] z − b ) } (17)</p><p>∇ 2 L z k σ ( z , M ) = 2 λ I + 2 M ⋅ [ A , − A ] T [ A , − A ] I (18)</p><p>其中 V ( z ) = ( min ( 0 , z 1 ) , ⋯ , min ( 0 , z 2 n ) ) T 。</p><p>再利用共轭梯度法迭代求解(15)式的 z k + 1 σ ，其迭代更新格式为：</p><p>z t + 1 = z t + α t ⋅ p t (19)</p><p>其中步长因子为：</p><p>α t = ‖ ∇ L z k σ ( z t , M ) ‖ 2 2 p t T ⋅ ∇ 2 L z k σ ( z t , M ) ⋅ p t (20)</p><p>下降方向为：</p><p>p t = − ∇ L z k σ ( z t , M ) + p t − 1 ⋅ ρ t − 1 (21)</p><p>其中令 z k σ = z 0 ， p 0 = − ∇ L z k σ ( z 0 , M ) ， ρ t − 1 = ‖ ∇ L z k σ ( z t , M ) ‖ 2 2 ‖ ∇ L z k σ ( z t − 1 , M ) ‖ 2 2 。</p><p>综上所述，本文所提出的INCS算法的流程如下：</p><p>Step 1输入：矩阵A、测量向量b， ε 1 , ε 2 , ε 3 &gt; 0 ；</p><p>Step 2初始化：</p><p>1) 设置递减序列 σ ， σ k + 1 = β σ k ，其中 0 &lt; β &lt; 1 ， β 为 σ 的递减因子，本文设置 β = 0.5 ， σ 0 = 2 max ( | x 0 | ) ；</p><p>2) 设置初始值： x 0 = arg min x { ‖ x ‖ 1 | A x = b } ， z 0 = [ ( x 0 + ) T , ( x 0 − ) T ] T ；</p><p>Step 3算法迭代：</p><p>1) k = 0 ， σ = σ 0 ；</p><p>2) while d 1 &gt; ε 1 do</p><p>1：{ z ^ 0 = z k , l = 0 , k = k + 1 ，</p><p>2：while d 2 &gt; ε 2 do</p><p>3：{ l = l + 1 ，</p><p>4： z ^ l = arg min z { G l − 1 ( z ) | [ A , − A ] z = b , z ≥ 0 } ，</p><p>5： d 2 = ‖ z ^ l − z ^ l − 1 ‖ 2 ‖ z ^ l − 1 ‖ 2 }</p><p>6： z k = z ^ l ，</p><p>7： d 1 = ‖ z ^ k − z ^ k − 1 ‖ 2 ‖ z ^ k − 1 ‖ 2 ，</p><p>8： σ = β σ }，</p><p>9： x k = z k ( 1 : n ) − z k ( n + 1 : e n d ) ，</p><p>10： W = 1 | x k − 1 | + ε 3 ，</p><p>11： x k = arg min x { ‖ W x ‖ 1 | A x = b } ；</p><p>Step 4输出稀疏向量： x = x k 。</p><p>其中Step 3由内、外两部分循环构成。外循环由步骤1~2及6~8组成，通过参数 σ 实现函数 f σ ( x ) 对 l 0 范数的逐次逼近；内循环为步骤3~5，利用外点罚函数法和共轭梯度法迭代求解步骤4；并将求得的解利用加权 l 1 范数最小化 [<xref ref-type="bibr" rid="hanspub.44902-ref20">20</xref>] 进行稀疏化处理。 d 1 和 d 2 分别表示外、内循环连续迭代的解之间的相对误差，并用于判断循环是否停止。</p></sec></sec><sec id="s8"><title>4. 仿真实验与结果分析</title><p>为验证本文所提出的INCS算法在重构性能上的优越性，本节设计了几组有关SL0算法、基追踪(Basis Pursuit, BP)算法、NCCS算法和INCS算法的对比实验。对于每个实验，我们重复进行100次测试，给出平均结果，并取 c = 10 。仿真实验结果是在MatlabR2014a的条件下获得的。</p><p>在仿真实验中，矩阵A的大小为 128 &#215; 256 ，其中矩阵元素服从零均值、单位方差的高斯分布，矩阵的列具有单位l<sub>2</sub>范数；稀疏原信号x的维数为256，非零项服从正态分布；信号稀疏度k取值区间为 [ 10 , 80 ] 。</p><p>实验中所涉及到的性能指标包括：</p><p>1) 重构误差(mean squared error)：</p><p>M S E = ‖ x ˜ − x ^ ‖ 2 2</p><p>2) 信噪比(signal noise ratio)：</p><p>S N R = 10 ⋅ log 10 ( ‖ x ˜ ‖ 2 2 ‖ x ˜ − x ^ ‖ 2 2 )</p><p>3) 算法运行时间</p><p>4) 恢复成功率(recovery success rate)：当 x ˜ i ≠ 0 时， | x ˜ − x ^ | ≤ 10 − 4 说明算法在该点处重构成功，</p><p>R S S = x ^ 重 构 成 功 的 点 个 数 x ˜ 中 非 零 点 个 数</p><p>其中 x ˜ 表示稀疏原信号， x ^ 表示算法的恢复信号；</p><p>图2为各算法的重构误差MSE和稀疏度的变化关系，实验结果如图2及表1所示。由图2和表1可见，BP算法、NCCS算法和INCS算法都存在随着稀疏度的增加重构误差增大的趋势。在同一稀疏度下，相比于其他三种算法，INCS算法的重构误差略小。</p><p>图2. SL0算法、BP算法、NCCS算法、INCS算法的重构误差和稀疏度的变化关系</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> The numerical record of the reconstruction error of each algorithm changing with the sparsity </title></caption><table><tbody><thead><tr><th align="center" valign="middle" >算法</th><th align="center" valign="middle" >k = 10</th><th align="center" valign="middle" >k = 20</th><th align="center" valign="middle" >k = 30</th><th align="center" valign="middle" >k = 40</th><th align="center" valign="middle" >k = 50</th><th align="center" valign="middle" >k = 60</th><th align="center" valign="middle" >k = 70</th><th align="center" valign="middle" >k = 80</th></tr></thead><tr><td align="center" valign="middle" >BP</td><td align="center" valign="middle" >1.12E−18</td><td align="center" valign="middle" >5.48E−18</td><td align="center" valign="middle" >5.81E−17</td><td align="center" valign="middle" >3.06E−16</td><td align="center" valign="middle" >0.45357</td><td align="center" valign="middle" >3.57556</td><td align="center" valign="middle" >10.01417</td><td align="center" valign="middle" >18.29708</td></tr><tr><td align="center" valign="middle" >SL0</td><td align="center" valign="middle" >2.47E−08</td><td align="center" valign="middle" >2.29E−08</td><td align="center" valign="middle" >2.09E−08</td><td align="center" valign="middle" >1.94E−08</td><td align="center" valign="middle" >1.70E−08</td><td align="center" valign="middle" >1.24461</td><td align="center" valign="middle" >14.78881</td><td align="center" valign="middle" >23.99578</td></tr><tr><td align="center" valign="middle" >NCCS</td><td align="center" valign="middle" >5.54E−20</td><td align="center" valign="middle" >5.79E−19</td><td align="center" valign="middle" >1.93E−18</td><td align="center" valign="middle" >7.17E−18</td><td align="center" valign="middle" >9.38E−18</td><td align="center" valign="middle" >0.79264</td><td align="center" valign="middle" >7.34229</td><td align="center" valign="middle" >17.68958</td></tr><tr><td align="center" valign="middle" >INCS</td><td align="center" valign="middle" >2.83E−20</td><td align="center" valign="middle" >1.31E−19</td><td align="center" valign="middle" >2.45E−19</td><td align="center" valign="middle" >9.53E−19</td><td align="center" valign="middle" >2.45E−18</td><td align="center" valign="middle" >7.60E−17</td><td align="center" valign="middle" >3.04638</td><td align="center" valign="middle" >14.10025</td></tr></tbody></table></table-wrap><p>表1. 各算法的重构误差随着稀疏度k变化的数值记录</p><p>图3为各算法的重构信噪比SNR和稀疏度的变化关系，实验结果如图3及表2所示。可以看出，在稀疏度区间 [ 10 , 50 ] 上，INCS算法和NCCS算法的信噪比变化不大且相差很小，但明显高于SL0算法和BP算法的信噪比；在稀疏度区间 [ 50 , 80 ] 上，各算法的信噪比随着稀疏度的增加而减小，但INCS算法的信噪比仍高于其他三种算法。</p><p>图3. SL0算法、BP算法、NCCS算法、INCS算法的重构信噪比和稀疏度的变化关系</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> The numerical record of the signal-to-noise ratio of each algorithm changing with the sparsity </title></caption><table><tbody><thead><tr><th align="center" valign="middle" >算法</th><th align="center" valign="middle" >k = 10</th><th align="center" valign="middle" >k = 20</th><th align="center" valign="middle" >k = 30</th><th align="center" valign="middle" >k = 40</th><th align="center" valign="middle" >k = 50</th><th align="center" valign="middle" >k = 60</th><th align="center" valign="middle" >k = 70</th><th align="center" valign="middle" >k = 80</th></tr></thead><tr><td align="center" valign="middle" >BP</td><td align="center" valign="middle" >2.11E+02</td><td align="center" valign="middle" >2.05E+02</td><td align="center" valign="middle" >2.05E+02</td><td align="center" valign="middle" >1.94E+02</td><td align="center" valign="middle" >1.12E+02</td><td align="center" valign="middle" >19.71136</td><td align="center" valign="middle" >6.68644</td><td align="center" valign="middle" >4.47774</td></tr><tr><td align="center" valign="middle" >SL0</td><td align="center" valign="middle" >70.98122</td><td align="center" valign="middle" >77.35896</td><td align="center" valign="middle" >81.58295</td><td align="center" valign="middle" >84.80094</td><td align="center" valign="middle" >87.50702</td><td align="center" valign="middle" >83.92584</td><td align="center" valign="middle" >26.56156</td><td align="center" valign="middle" >6.28709</td></tr><tr><td align="center" valign="middle" >NCCS</td><td align="center" valign="middle" >2.32E+02</td><td align="center" valign="middle" >2.26E+02</td><td align="center" valign="middle" >2.23E+02</td><td align="center" valign="middle" >2.21E+02</td><td align="center" valign="middle" >2.16E+02</td><td align="center" valign="middle" >1.94E+02</td><td align="center" valign="middle" >1.16E+02</td><td align="center" valign="middle" >18.32044</td></tr><tr><td align="center" valign="middle" >INCS</td><td align="center" valign="middle" >2.32E+02</td><td align="center" valign="middle" >2.23E+02</td><td align="center" valign="middle" >2.22E+02</td><td align="center" valign="middle" >2.18E+02</td><td align="center" valign="middle" >2.12E+02</td><td align="center" valign="middle" >2.11E+02</td><td align="center" valign="middle" >1.57E+02</td><td align="center" valign="middle" >35.03469</td></tr></tbody></table></table-wrap><p>表2. 各算法的重构信噪比随着稀疏度k变化的数值记录</p><p>图4为各算法的运行时间和稀疏度的变化关系，实验结果如图4及表3所示。可以看出，SL0算法和BP算法的运行时间较短并能够保持在0.5秒以内。在稀疏度区间 [ 10 , 50 ] 上，INCS算法和NCCS算法的运行时间能保持在1秒以内，在稀疏度区间 [ 50 , 80 ] 上这两种算法的运行时间都有所增加，但对比NCCS算法，INCS算法的运行时间始终略短。</p><p>图4. SL0算法、BP算法、NCCS算法、INCS算法的运行时间和稀疏度的变化关系</p><table-wrap id="table3" ><label><xref ref-type="table" rid="table3">Table 3</xref></label><caption><title> The numerical record of the running time of each algorithm changing with the sparsity </title></caption><table><tbody><thead><tr><th align="center" valign="middle" >算法</th><th align="center" valign="middle" >k = 10</th><th align="center" valign="middle" >k = 20</th><th align="center" valign="middle" >k = 30</th><th align="center" valign="middle" >k = 40</th><th align="center" valign="middle" >k = 50</th><th align="center" valign="middle" >k = 60</th><th align="center" valign="middle" >k = 70</th><th align="center" valign="middle" >k = 80</th></tr></thead><tr><td align="center" valign="middle" >BP</td><td align="center" valign="middle" >0.11539</td><td align="center" valign="middle" >0.12327</td><td align="center" valign="middle" >0.13205</td><td align="center" valign="middle" >0.15259</td><td align="center" valign="middle" >0.16604</td><td align="center" valign="middle" >0.16831</td><td align="center" valign="middle" >0.18520</td><td align="center" valign="middle" >0.18352</td></tr><tr><td align="center" valign="middle" >SL0</td><td align="center" valign="middle" >0.00010</td><td align="center" valign="middle" >0.00009</td><td align="center" valign="middle" >0.00011</td><td align="center" valign="middle" >0.00009</td><td align="center" valign="middle" >0.00012</td><td align="center" valign="middle" >0.00012</td><td align="center" valign="middle" >0.00010</td><td align="center" valign="middle" >0.00009</td></tr><tr><td align="center" valign="middle" >NCCS</td><td align="center" valign="middle" >0.58932</td><td align="center" valign="middle" >0.58826</td><td align="center" valign="middle" >0.60202</td><td align="center" valign="middle" >0.57496</td><td align="center" valign="middle" >0.66814</td><td align="center" valign="middle" >1.07208</td><td align="center" valign="middle" >2.03705</td><td align="center" valign="middle" >2.41634</td></tr><tr><td align="center" valign="middle" >INCS</td><td align="center" valign="middle" >0.46711</td><td align="center" valign="middle" >0.48871</td><td align="center" valign="middle" >0.48493</td><td align="center" valign="middle" >0.50970</td><td align="center" valign="middle" >0.60926</td><td align="center" valign="middle" >0.71415</td><td align="center" valign="middle" >1.40504</td><td align="center" valign="middle" >2.34221</td></tr></tbody></table></table-wrap><p>表3. 各算法的运行时间随着稀疏度k变化的数值记录</p><p>图5为各算法的恢复成功率RSS和稀疏度的变化关系，实验结果如图5及表4所示。可以看出，当稀疏度增加到一定程度时这四种算法的恢复成功率均开始降低。INCS算法的恢复成功率在稀疏度区间 [ 10 , 60 ] 上都能保持为1，也就是说在这个区间内该算法都能够实现信号的完全恢复。在稀疏度区间 [ 60 , 80 ] 上，INCS算法的恢复成功率始终略高于其他三种算法，所以利用INCS算法恢复信号时精确度有一定的提高。</p><p>图5. SL0算法、BP算法、NCCS算法、INCS算法的恢复成功率和稀疏度的变化关系</p><table-wrap id="table4" ><label><xref ref-type="table" rid="table4">Table 4</xref></label><caption><title> The numerical record of the recovery success rate of each algorithm changing with the sparsity </title></caption><table><tbody><thead><tr><th align="center" valign="middle" >算法</th><th align="center" valign="middle" >k = 10</th><th align="center" valign="middle" >k = 20</th><th align="center" valign="middle" >k = 30</th><th align="center" valign="middle" >k = 40</th><th align="center" valign="middle" >k = 50</th><th align="center" valign="middle" >k = 60</th><th align="center" valign="middle" >k = 70</th><th align="center" valign="middle" >k = 80</th></tr></thead><tr><td align="center" valign="middle" >BP</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >0.79640</td><td align="center" valign="middle" >0.54050</td><td align="center" valign="middle" >0.50729</td><td align="center" valign="middle" >0.50075</td></tr><tr><td align="center" valign="middle" >SL0</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >0.96700</td><td align="center" valign="middle" >0.62271</td><td align="center" valign="middle" >0.52200</td></tr><tr><td align="center" valign="middle" >NCCS</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >0.97750</td><td align="center" valign="middle" >0.77829</td><td align="center" valign="middle" >0.53650</td></tr><tr><td align="center" valign="middle" >INCS</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >0.87512</td><td align="center" valign="middle" >0.57163</td></tr></tbody></table></table-wrap><p>表4. 各算法的恢复成功率随着稀疏度k变化的数值记录</p><p>综上所述，本文提出的INCS算法的综合重构性能优于实验中的对比算法，说明利用该算法能够更好的恢复稀疏信号。</p></sec><sec id="s9"><title>5. 结论</title><p>本文提出了一种基于改进的近似l<sub>0</sub>范数的稀疏信号重构算法，即INCS算法。该算法利用一种逼近性能更优的非凸光滑函数实现对l<sub>0</sub>范数的逼近，并通过外点罚函数法和共轭梯度法求解基于该函数的稀疏解。实验结果表明：对比SL0算法、BP算法和NCCS算法，INCS算法在重构误差、信噪比和恢复成功率等方面表现出更优越的重构性能。</p></sec><sec id="s10"><title>基金项目</title><p>长安大学中央高校基本科研业务费专项资金资助项目(编号：310812163504)。</p></sec><sec id="s11"><title>文章引用</title><p>张慧萍,张连娜,李荣鹏,宋学力. 基于改进的近似l<sub>0</sub>范数的稀疏信号重构算法A Sparse Signal Reconstruction Algorithm Based on Improved Approximate l<sub>0</sub> Norm[J]. 计算机科学与应用, 2021, 11(08): 2179-2189. https://doi.org/10.12677/CSA.2021.118223</p></sec><sec id="s12"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.44902-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Donoho, D.L. (2006) Compressed Sensing. IEEE Transactions on Information Theory, 52, 1289-1306.  
&lt;br&gt;https://doi.org/10.1109/TIT.2006.871582</mixed-citation></ref><ref id="hanspub.44902-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Salari, S., Chan, F., Chan, Y.T. and Guay, R. (2020) DOA Estima-tion Using Compressive Sampling-Based Sensors in the Presence of Interference. IEEE Transactions on Aerospace and Electronic Systems, 56, 4395-4405.  
&lt;br&gt;https://doi.org/10.1109/TAES.2020.2990818</mixed-citation></ref><ref id="hanspub.44902-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">张国平, 牟忠德. 基于压缩感知的医学图像重建方法[J]. 生物医学工程学进展, 2019, 40(4): 187-195.</mixed-citation></ref><ref id="hanspub.44902-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Herman, M.A. and Strohmer, T. (2009) High-Resolution Radar via Compressed Sensing. IEEE Transactions on Signal Processing, 57, 2275-2284. &lt;br&gt;https://doi.org/10.1109/TSP.2009.2014277</mixed-citation></ref><ref id="hanspub.44902-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Li, H., Zhang, Q., Cui, A. and Peng, J. (2020) Minimization of Fraction Function Penalty in Compressed Sensing. IEEE Transactions on Neural Networks and Learning Systems, 31, 1626-1637.  
&lt;br&gt;https://doi.org/10.1109/TNNLS.2019.2921404</mixed-citation></ref><ref id="hanspub.44902-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Peng, J., Yue, S. and Li, H. (2015) NP/CMP Equivalence: A Phenomenon Hidden among Sparsity Models l0 Minimization and lp Minimization for Information Processing. IEEE Transactions on Information Theory, 61, 4028-4033.  
&lt;br&gt;https://doi.org/10.1109/TIT.2015.2429611</mixed-citation></ref><ref id="hanspub.44902-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Tropp, J.A. and Gilbert, A.C. (2007) Signal Recovery from Ran-dom Measurements via Orthogonal Matching Pursuit. IEEE Transactions on Information Theory, 53, 4655-4666. &lt;br&gt;https://doi.org/10.1109/TIT.2007.909108</mixed-citation></ref><ref id="hanspub.44902-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Wang, J., Kwon, S. and Shim, B. (2012) Generalized Orthogonal Matching Pursuit. IEEE Transactions on Signal Processing, 60, 6202-6216. &lt;br&gt;https://doi.org/10.1109/TSP.2012.2218810</mixed-citation></ref><ref id="hanspub.44902-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Dai, W. and Milenkovic, O. (2009) Subspace Pursuit for Com-pressive Sensing Signal Reconstruction. IEEE Transactions on Information Theory, 55, 2230-2249. &lt;br&gt;https://doi.org/10.1109/TIT.2009.2016006</mixed-citation></ref><ref id="hanspub.44902-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Chen, S.S., Donoho, D.L. and Saunders, M.A. (2001) Atomic Decomposition by Basis Pursuit. Siam Review, 43, 129-159. &lt;br&gt;https://doi.org/10.1137/S003614450037906X</mixed-citation></ref><ref id="hanspub.44902-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Bayram, I. (2016) On the Convergence of the Iterative Shrink-age/Thresholding Algorithm with a Weakly Convex Penalty. IEEE Transactions on Signal Processing, 64, 1597-1608. &lt;br&gt;https://doi.org/10.1109/TSP.2015.2502551</mixed-citation></ref><ref id="hanspub.44902-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Figueiredo, M., Nowak, R.D. and Wright, S.J. (2007) Gradient Projection for Sparse Reconstruction: Application to Compressed Sensing and Other Inverse Problems. IEEE Journal of Selected Topics in Signal Processing, 1, 586-597.  
&lt;br&gt;https://doi.org/10.1109/JSTSP.2007.910281</mixed-citation></ref><ref id="hanspub.44902-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Mohimani, H., Babaie-Zadeh, M. and Jutten, C. (2009) A Fast Approach for Overcomplete Sparse Decomposition Based on Smoothed l0 Norm. IEEE Transactions on Signal Pro-cessing, 57, 289-301.  
&lt;br&gt;https://doi.org/10.1109/TSP.2008.2007606</mixed-citation></ref><ref id="hanspub.44902-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">林婉娟, 赵瑞珍, 李浩. 用于压缩感知信号重建的NSL0算法[J]. 新型工业化, 2011(17): 78-84.</mixed-citation></ref><ref id="hanspub.44902-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">张巍, 朱正为, 汪亮, 王学渊. 一种A-HNSL0压缩感知SAR图像重建方法[J]. 电光与控制, 2020, 27(8): 28-32.</mixed-citation></ref><ref id="hanspub.44902-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">周洁容, 李海洋, 凌军, 等. 基于非凸复合函数的稀疏信号恢复算法[J]. 自动化学报, 2021, 47(x): 1-12.</mixed-citation></ref><ref id="hanspub.44902-ref17"><label>17</label><mixed-citation publication-type="other" xlink:type="simple">Hunter, D.R. and Lange, K. (2004) A Tutorial on MM algorithms. The American Statistician, 58, 30-37.  
&lt;br&gt;https://doi.org/10.1198/0003130042836</mixed-citation></ref><ref id="hanspub.44902-ref18"><label>18</label><mixed-citation publication-type="other" xlink:type="simple">袁亚湘, 孙文瑜. 最优化理论与方法[M]. 北京: 科学出版社, 1997: 455-482.</mixed-citation></ref><ref id="hanspub.44902-ref19"><label>19</label><mixed-citation publication-type="other" xlink:type="simple">Clarke, F. (1983) Optimization and Non-Smooth Analysis. Society for Industrial and Applied Mathematics, New York, 37-187. &lt;br&gt;https://doi.org/10.1137/1.9781611971309</mixed-citation></ref><ref id="hanspub.44902-ref20"><label>20</label><mixed-citation publication-type="other" xlink:type="simple">Candes, E.J., Wakin, M.B. and Boyd, S.P. (2008) Enhancing Sparsity by Reweighted l1 Minimization. Journal of Fourier Analysis and Applications, 14, 877-905. &lt;br&gt;https://doi.org/10.1007/s00041-008-9045-x</mixed-citation></ref></ref-list></back></article>