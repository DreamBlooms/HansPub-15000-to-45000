<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">SEA</journal-id><journal-title-group><journal-title>Software Engineering and Applications</journal-title></journal-title-group><issn pub-type="epub">2325-2286</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/SEA.2016.52016</article-id><article-id pub-id-type="publisher-id">SEA-17368</article-id><article-categories><subj-group subj-group-type="heading"><subject>SEA20160200000_92510407.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>工程技术</subject></subj-group></article-categories><title-group><article-title>
 
 
  快速行人越界检测算法研究
  Fast Pedestrian Crossing Boundary Detection Method
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>高</surname><given-names>志辉</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>盘</surname><given-names>先跃</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib></contrib-group><aff id="aff1"><addr-line>国防科学技术大学，湖南 长沙</addr-line></aff><aff id="aff2"><addr-line>null</addr-line></aff><author-notes><corresp id="cor1">* E-mail:<email>946361596@qq.com(高志)</email>;</corresp></author-notes><pub-date pub-type="epub"><day>29</day><month>03</month><year>2016</year></pub-date><volume>05</volume><issue>02</issue><fpage>146</fpage><lpage>153</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   本文提出了一种综合运用混合高斯模型前景检测方法、Canny边缘检测、霍夫直线检测、颜色识别与重心检测方法，能较好的解决视频监控系统中行人越界检测的工程类问题。实验结果表明，此综合运用检测方法简单有效、易于实现，且检测准确率高、运行速度快。 This paper presents a comprehensive method which combines Gaussian mixture model based on the foreground detection method with Hough line detection, color recognition and centroid detection methods to detect whether the pedestrian crosses the specific boundary in the video surveillance system. Experiments show that the proposed integrated method is simple yet efficient and easy to implement, and has characteristics of high accuracy, fast running speed.
    
  
 
</p></abstract><kwd-group><kwd>混合高斯模型，霍夫直线检测，颜色识别，重心检测, Gaussian Mixture Model</kwd><kwd> Hough Line Detection</kwd><kwd> Color Recognition</kwd><kwd> Centroid Detection</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>快速行人越界检测算法研究<sup> </sup></title><p>高志辉，盘先跃</p><p>国防科学技术大学，湖南 长沙</p><disp-formula id="hanspub.17368-formula296"><graphic xlink:href="http://html.hanspub.org/file/6-2690206x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>收稿日期：2016年3月30日；录用日期：2016年4月16日；发布日期：2016年4月19日</p><disp-formula id="hanspub.17368-formula297"><graphic xlink:href="http://html.hanspub.org/file/6-2690206x7_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>本文提出了一种综合运用混合高斯模型前景检测方法、Canny边缘检测、霍夫直线检测、颜色识别与重心检测方法，能较好的解决视频监控系统中行人越界检测的工程类问题。实验结果表明，此综合运用检测方法简单有效、易于实现，且检测准确率高、运行速度快。</p><p>关键词 :混合高斯模型，霍夫直线检测，颜色识别，重心检测</p><disp-formula id="hanspub.17368-formula298"><graphic xlink:href="http://html.hanspub.org/file/6-2690206x8_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s3"><title>1. 引言</title><p>运动检测与物体识别技术是计算机视觉的热点研究领域，其中，基于运动目标检测的识别技术已广泛应用于各个领域。目前，运动目标检测识别领域的算法较多，简单的有基于特征的识别，如轮廓、颜色、边缘等特征识别；中等的特征有局部二值统计LBP [<xref ref-type="bibr" rid="hanspub.17368-ref1">1</xref>] ，SIFT [<xref ref-type="bibr" rid="hanspub.17368-ref2">2</xref>] 、SURF [<xref ref-type="bibr" rid="hanspub.17368-ref3">3</xref>] 等特征识别；高等的有采用分类器对提取的特征进行分类，如人脸Haar检测 [<xref ref-type="bibr" rid="hanspub.17368-ref4">4</xref>] ，行人检测(HOG) [<xref ref-type="bibr" rid="hanspub.17368-ref5">5</xref>] 等。常见的运动目标检测方法有帧差法、背景减除法、光流法等 [<xref ref-type="bibr" rid="hanspub.17368-ref6">6</xref>] 、自适应背景检测法、独立多峰模型法 [<xref ref-type="bibr" rid="hanspub.17368-ref7">7</xref>] ，传统的运动目标检测方法在背景比较单一的情况下能取得较好的效果，识别的速度较快，但不能较好应用于复杂背景当中。一些比较复杂的算法，如行人检测、光流跟踪往往比较耗时，无法满足实时性需求。</p></sec><sec id="s4"><title>2. 相关工作</title><p>本文提出的综合运用检测方法，克服以上传统方法的不足，较好解决行人越界检测问题。首先，采用Canny边缘检测 [<xref ref-type="bibr" rid="hanspub.17368-ref8">8</xref>] 监控系统中的白色边界线，然后使用霍夫变换 [<xref ref-type="bibr" rid="hanspub.17368-ref9">9</xref>] 检测直线，记录直线的两个端点，从而计算出边界线的位置，而后采用混合高斯模型 [<xref ref-type="bibr" rid="hanspub.17368-ref10">10</xref>] 检测算法检测出运动物体，排除背景干扰，紧接着采用颜色统计法，监控两种特定行人(特定行人甲和特定行人乙)，由着色衣服进行区分允许或静止通行。通过分析着装衣服的RGB颜色属性，统计每帧图片中的衣服区域的颜色像素总和，估算出行人衣服轮廓的质心，最后，通过判断质心和边界线的位置关系来判定特定行人是否越界。整个算法流程如图1所示。</p><sec id="s4_1"><title>2.1. Canny边缘检测</title><p>Canny边缘检测算法是一种优秀的边缘检测算法，能精确地检测出边缘来。边界线一般呈现白色，通过颜色过滤，通过统计边界线的R、G、B的范围，可将边界线的大致位置求出，再进行边缘检测，能减少算法运行时间。Canny边缘检测的主要步骤是：1) 去噪；2) 用一阶偏导的有限差分来计算梯度的幅值和方向；3) 对梯度幅值进行非极大值抑制；4) 用双阈值算法检测和连接边缘。图2(b)显示经过颜色过滤，再使用Canny边缘检测求出图2(a)中的边界线。</p></sec><sec id="s4_2"><title>2.2. 边界线检测</title><p>在监控视频中，特定行人乙越过边界线则进行报警。为了检测行人是否越界，首先要将边界线的具体位置计算出来。边界线的定位直接决定了检测行人越界的正确率。常见的边界线寻找方法有颜色标定法、直线检测法等。其中，颜色标定法对光照鲁棒性不好，各种噪声也会影响边界线的检测结果。边界线一般由白色的横条组，最好的检测方法是采用霍夫直线检测。</p><p>霍夫变换是图像变换中的一种重要的方法，主要是从图像中分离出具有相同属性的形状。霍夫变换寻找直线的方法比其他方法更好的减少噪声的干扰。霍夫变换检测直线的原理是：直角系坐标跟极坐标是在直角坐标系和极坐标系的对应关系，点、直线在两个坐标系中是对偶关系。即直角坐标系中的点是极坐标系中的线，直角坐标系中的线是极坐标系中的点。反过来也成立。检测图像中的直线，可以转化</p><p>图1. 行人越界检测算法流程</p><p>图2. 颜色过滤以及边缘检测后的结果</p><p>为统计检测极坐标系中的点<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-2690206x12_hanspub.png" xlink:type="simple"/></inline-formula>。图像中直线的表示，可由斜率和截距表示，而极坐标中用<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-2690206x13_hanspub.png" xlink:type="simple"/></inline-formula>表示。</p><disp-formula id="hanspub.17368-formula299"><label>(1)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/6-2690206x14_hanspub.png"  xlink:type="simple"/></disp-formula><p>对应于<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-2690206x15_hanspub.png" xlink:type="simple"/></inline-formula>空间的一条正弦曲线：多个点在<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-2690206x16_hanspub.png" xlink:type="simple"/></inline-formula>平面上就是多条正弦曲线，而多条正弦曲线会相交，交点就是直角坐标系中的直线。直角坐标系中的一条直线上的三个点对应于<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-2690206x17_hanspub.png" xlink:type="simple"/></inline-formula>空间中三条曲线，并交于一点。统计一个矩阵中多条线相交的点作为检测直线的极坐标表现形式，这样就能求出图像中存在的直线。在寻找边界线的时候，会有很多直线被检测出，在同一水平线上，去顶部和底部直线的中点，作为检测的边界线。</p></sec><sec id="s4_3"><title>2.3. 混合高斯模型前景运动检测算法</title><p>混合高斯模型是目前背景建模最成功的方法之一，运用混合高斯模型对样本的概率密度分布进行估计，而估计采用的模型(训练模型)是几个高斯模型的加权和。每个高斯模型就代表了一个类。对样本中的数据分别在几个高斯模型上投影，就会分别得到在各个类上的概率。然后我们可以选取概率最大的类作为判决结果，使用K (基本为3到5个)个高斯模型来表征图像中各个像素点的特征，在新一帧图像获得后更新混合高斯模型，用当前图像中的每个像素点与混合高斯模型匹配，如果成功则判定该点为背景点，否则为前景点。</p><p>混合高斯模型前景运动检测算法的流程是：</p><p>1) 每个新像素值<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-2690206x18_hanspub.png" xlink:type="simple"/></inline-formula>同当前K个模型按照下式进行比较，直到找到匹配新像素值的分布模型，即同该模型的均值偏差在<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-2690206x19_hanspub.png" xlink:type="simple"/></inline-formula>内</p><disp-formula id="hanspub.17368-formula300"><label>(2)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/6-2690206x20_hanspub.png"  xlink:type="simple"/></disp-formula><p>2) 如果所匹配的模式符合背景要求，则该像素属于背景，否则属于前景。</p><p>3) 各模式权值按如下公式更新，其中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-2690206x21_hanspub.png" xlink:type="simple"/></inline-formula>是学习速率，对于匹配的模式<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-2690206x22_hanspub.png" xlink:type="simple"/></inline-formula>，否则<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-2690206x23_hanspub.png" xlink:type="simple"/></inline-formula>，然后各模式的权重进行归一化：</p><disp-formula id="hanspub.17368-formula301"><label>(3)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/6-2690206x24_hanspub.png"  xlink:type="simple"/></disp-formula><p>4) 未匹配模式的均值<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-2690206x25_hanspub.png" xlink:type="simple"/></inline-formula>与标准差不变，匹配模式的参数按照如下公式更新：</p><disp-formula id="hanspub.17368-formula302"><label>(4)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/6-2690206x26_hanspub.png"  xlink:type="simple"/></disp-formula><disp-formula id="hanspub.17368-formula303"><label>(5)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/6-2690206x27_hanspub.png"  xlink:type="simple"/></disp-formula><disp-formula id="hanspub.17368-formula304"><label>(6)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/6-2690206x28_hanspub.png"  xlink:type="simple"/></disp-formula><p>5) 如果第1步中没有任何模式匹配，则权重最小的模式被替换，即该模式的均值为当前像素值，标准差为初始较大值，权重为较小值。</p><p>6) 各模式根据<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-2690206x29_hanspub.png" xlink:type="simple"/></inline-formula>按降序排列，权重大、标准差小的模式排列靠前。</p><p>7) 选前B个模式作为背景，B满足下式，参数T表示背景所占比例</p><disp-formula id="hanspub.17368-formula305"><label>(7)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/6-2690206x30_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s4_4"><title>2.4. 行人衣服颜色识别</title><p>该步骤的详细算法是：</p><p>1) 设置三个标记矩阵，大小跟每帧图像的大小相同，分别用来标记特定行人甲、特定行人乙以及无人时的图像；</p><p>2) 依次遍历图像中的每个像素点，判断每个像素点的范围，当符合一定的范围，则在相应的标记矩阵中进行标记；其中，掩模M1的获取方法是通过统计特别行人甲的衣服像素范围得到，掩模M2的获取方法是通过统计特别行人乙的衣服像素范围得到，掩模M3是统计其他行人衣服的像素范围得到。这些不同人所穿的衣服颜色各不相同，通过统计衣服的颜色，就能获得相应的掩模。</p><p>3) 分别依次计算三个标记矩阵的像素总和以及重心，判断是否是M2 (特定行人乙)标记，如判定是，同时</p><p>标记矩阵过线，则进行报警。</p><p>如图3所示。</p><p>在行人越界监控系统中，平常行人跟特定行人的衣服着装是区分开来的，并且衣服颜色均是固定的。识别平常行人和特定行人最好的方法就是分辨其所穿着衣服的颜色。平常人衣服的颜色RGB值会呈现在一定的范围内，其着装衣服的颜色范围为</p><disp-formula id="hanspub.17368-formula306"><label>(8)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/6-2690206x31_hanspub.png"  xlink:type="simple"/></disp-formula><p>特定的行人的衣服颜色范围为</p><disp-formula id="hanspub.17368-formula307"><label>(9)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/6-2690206x32_hanspub.png"  xlink:type="simple"/></disp-formula><p>图3. 特定行人越界检测流程图</p><p>通过统计每帧图像中颜色的范围以及高斯混合模型前景运动检测算法检测出来的掩模，可以得到行人属性的二值图像，然后统计图像中标记像素的重心以及像素的个数，从而确定该行人属于正常人还是属于特定行人。重心计算的公式为：</p><disp-formula id="hanspub.17368-formula308"><label>(10)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/6-2690206x34_hanspub.png"  xlink:type="simple"/></disp-formula><disp-formula id="hanspub.17368-formula309"><label>(11)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/6-2690206x35_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中，x%，y%，为计算后的重心横、纵坐标值，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-2690206x36_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/6-2690206x37_hanspub.png" xlink:type="simple"/></inline-formula>为离散的横、纵坐标值。</p><p>在计算出重心坐标值后，需要辨别当前帧重心和前一帧重心以及边界线的位置的关系，判断重心是否超过了边界线。当边界线的位置，处于前一帧重心和当前帧重心中间时，并且通过颜色统计法检测出的运动行人是特定行人乙时，则报警。特定行人乙越界的关系示意图如图4所示。</p></sec></sec><sec id="s5"><title>3. 算法测试</title><p>为了验证本文的算法的可行有效性，采用VC++2010与OpenCV2.4.3进行试验实验。电脑配置为双核CPU主频2.0 GHz，图像大小1980 &#215; 1020。实验视频采用自己拍摄的监控行人越界视频。其中，模拟正常人越界的视频100个，每个视频中正常人越界10次；模拟特定行人越界的视频100个，每个视频中特定行人越界10次。通过观察视频的处理效果以及正确识别率和识别时间，来验证本文算法相对于其他算法更具优越性。</p><p>如图5所示，对视频中的第一帧中的边界线进行检测。白线中的黑色细线则为检测到的边界线。通过确定边界线的位置，才能在以后的每帧中进行检测，判断特定行人是否越界。</p><p>图6是各种运动检测算法的检测效果图，分别为本文算法、基于自适应背景学习的运动检测算法、</p><p>图4. 特定行人乙越界示意图</p><p>图5. 边界线检测效果图</p><p>图6. 各种前景运动检测算法效果图</p><p>独立多模BGS [<xref ref-type="bibr" rid="hanspub.17368-ref11">11</xref>] 运动检测算法。</p><p>从图6可以看出，本文所使用的运动检测算法能够有效的检测出运动的物体，并且得到非常干净的背景。其他算法都会产生一些噪声干扰，或者产生运动“鬼影”的现象。运动检测算法性能越好，以后的行人定位越精确。</p><p>表1是各种前景运动检测算法跟颜色、重心相结合检测特定行人所用的时间，统计的依据是对检测</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Comparation with other foreground detection algorithms on tim</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >算法</th><th align="center" valign="middle" >本文</th><th align="center" valign="middle" >基于自适应背景学习的运动检测算法</th><th align="center" valign="middle" >独立多模</th></tr></thead><tr><td align="center" valign="middle" >用时(毫秒)</td><td align="center" valign="middle" >19</td><td align="center" valign="middle" >24</td><td align="center" valign="middle" >24.3</td></tr></tbody></table></table-wrap><p>表1. 本文算法与其他前景检测算法用时对比</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> Comparation with other similar algorithms on accuracy and tim</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >算法</th><th align="center" valign="middle" >本文</th><th align="center" valign="middle" >文献 [<xref ref-type="bibr" rid="hanspub.17368-ref12">12</xref>]</th><th align="center" valign="middle" >文献 [<xref ref-type="bibr" rid="hanspub.17368-ref13">13</xref>]</th><th align="center" valign="middle" >文献 [<xref ref-type="bibr" rid="hanspub.17368-ref14">14</xref>]</th><th align="center" valign="middle" >文献 [<xref ref-type="bibr" rid="hanspub.17368-ref15">15</xref>]</th></tr></thead><tr><td align="center" valign="middle" >正确率(%)</td><td align="center" valign="middle" >100</td><td align="center" valign="middle" >94.6</td><td align="center" valign="middle" >98.1</td><td align="center" valign="middle" >96.2</td><td align="center" valign="middle" >93.3</td></tr><tr><td align="center" valign="middle" >用时(毫秒)</td><td align="center" valign="middle" >19</td><td align="center" valign="middle" >29</td><td align="center" valign="middle" >356</td><td align="center" valign="middle" >298</td><td align="center" valign="middle" >96</td></tr></tbody></table></table-wrap><p>表2. 本文算法与其他相似算法用时和正确率对比</p><p>图7. 越界报警示意图</p><p>到的每一帧处理的时间进行统计，然后取这些帧的平均时间。从表1可以看出，本文算法的前景检测性能最好。</p><p>表2是本文算法跟其他相似算法在相同条件下正确率和使用时间对比，统计的依据是每次正常行人或者特定行人越界时，能依据衣服着装颜色，正确区分特定行人，特定行人乙越界则报警则，检测正确，否则错误。从表中可以看出，在高清摄像头拍摄的大图片中，本文算法性能优越，并且正确率非常高。</p><p>图7是特定行人甲和特定行人乙越界时的情景。当特定行人乙越过边界线后，则系统会发出报警确定为错误行人；特定行人甲越过边界线后，则系统不报警确定为正确行人。</p></sec><sec id="s6"><title>4. 结束语</title><p>本文提出了综合运用混合高斯模型前景检测方法、霍夫直线检测、颜色识别与质心检测方法，较好地解决了行人越界检测的工程类问题，通过一系列实验证明本方法能在高清摄像头与比较低端的电脑上达到良好的检测效果，具有检测正确率高、运行速度快、算法简单、易于实现等特点。但是，这种综合行人越界检测方法是基于检测行人底层特征进行的越界判定，受光照等因素的影响较大，需待进一步研究。</p></sec><sec id="s7"><title>文章引用</title><p>高志辉,盘先跃. 快速行人越界检测算法研究Fast Pedestrian Crossing Boundary Detection Method[J]. 软件工程与应用, 2016, 05(02): 146-153. http://dx.doi.org/10.12677/SEA.2016.52016</p></sec><sec id="s8"><title>参考文献 (References)</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.17368-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Wang, L. and He, D.C. (1990) Texture Classification Using Texture Spectrum. Pattern Recognition, 23, 905-910.  
&lt;br&gt;http://dx.doi.org/10.1016/0031-3203(90)90135-8</mixed-citation></ref><ref id="hanspub.17368-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Lowe, D.G. (1999) Object Recognition from Local Scale-Invariant Features. Proceedings of the International Conference on Computer Vision, 1150-1157. &lt;br&gt;http://dx.doi.org/10.1109/iccv.1999.790410</mixed-citation></ref><ref id="hanspub.17368-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Baya, H., Essa, A., Tuytelaarsb, T. and Van Goola, L. (2008) Speeded-Up Robust Features (SURF). Computer Vision and Image Understanding, 110, 346-359.</mixed-citation></ref><ref id="hanspub.17368-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Ghafouri, S. and Seyedarabi, H. (2013) Hybrid Method for Hand Gesture Recognition Based on Combination of Haar-Like and Hog Features. The 21st Iranian Conference on Electrical Engineering (ICEE), 14-16 May 2013, 1-4.  
&lt;br&gt;http://dx.doi.org/10.1109/iraniancee.2013.6599529</mixed-citation></ref><ref id="hanspub.17368-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Dalal, N. and Triggs, B. (2005) Histograms of Oriented Gradients for Human Detection. IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 1, 886-893.</mixed-citation></ref><ref id="hanspub.17368-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Canny, J. (1986) A Computational Approach to Edge Detection. IEEE Transactions Ransactions on Pattern Analysis and Maintellgence, pami-8.</mixed-citation></ref><ref id="hanspub.17368-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">(1962) P.V.C. Method and Means for Recognizing Complex Patterns. US Patent 3069654.</mixed-citation></ref><ref id="hanspub.17368-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Stauffer, C. and Grimson, W.E.L. (2007) Adaptive Background Mixture Models for Real-Time Tracking. The Artificial Intellgence Laboratory, Massachusetts Institute of Technology, Cambridge.</mixed-citation></ref><ref id="hanspub.17368-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">El Harrouss, O., Moujahid, D. and Tairi, H. (2015) Motion Detection Based on the Combining of the Background Subtraction and Spatial Color Information. Intelligent Systems and Computer Vision (ISCV), 25-26 March 2015, 1-4.  
&lt;br&gt;http://dx.doi.org/10.1109/isacv.2015.7105548</mixed-citation></ref><ref id="hanspub.17368-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Bloisi, D. and Iocchi, L. (2012) Independent Multimodal Back-ground Subtraction. Computational Modelling of Objects Represented in Images Fundamentals Methods &amp; Applications III, 413, 39-44.</mixed-citation></ref><ref id="hanspub.17368-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Duan, D.G., Xie, M., Mo, Q., Han, Z.M. and Wan, Y.L. (2010) An Improved Hough Transform for Line Detection. International Conference on Computer Application and System Modeling (ICCASM), 2, V2-354-V2-357.</mixed-citation></ref><ref id="hanspub.17368-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">许静, 张冬宁, 张学军. 一种判定运动目标越界的算法[J]. 无线电工程, 2009(11): 32-34.</mixed-citation></ref><ref id="hanspub.17368-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Hariyono, J. and Jo, K.-H. (2015) Detection of Pedestrian Crossing Road. IEEE International Conference on Image Processing (ICIP), 27-30 September 2015, 4585-4588.</mixed-citation></ref><ref id="hanspub.17368-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">Bonnin, S., Weisswange, T.H., Kummert, F. and Schmuedderich, J. (2014) Pedestrian Crossing Prediction Using Multiple Context-Based Models. IEEE 17th International Conference on Intelligent Transportation Systems (ITSC), 8-11 October 2014, 378-385.</mixed-citation></ref><ref id="hanspub.17368-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">Fascioli, A., Fedriga, R.I. and Ghidoni, S. (2007) Vision-Based Monitoring of Pedestrian Crossings. 14th International Conference on Image Analysis and Processing, 10-14 September 2007, 566-574.  
&lt;br&gt;http://dx.doi.org/10.1109/iciap.2007.4362838</mixed-citation></ref></ref-list></back></article>