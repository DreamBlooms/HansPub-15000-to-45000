<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">AAM</journal-id><journal-title-group><journal-title>Advances in Applied Mathematics</journal-title></journal-title-group><issn pub-type="epub">2324-7991</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/AAM.2021.102049</article-id><article-id pub-id-type="publisher-id">AAM-40452</article-id><article-categories><subj-group subj-group-type="heading"><subject>AAM20210200000_30413179.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>数学与物理</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于拉普拉斯约束的半监督模糊C均值算法
  Semi-Supervised Fuzzy C-Means Algorithm Based on Laplace Constraint
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>张</surname><given-names>宁</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>马</surname><given-names>盈仓</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>朱</surname><given-names>恒东</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>西安工程大学理学院，陕西 西安</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>08</day><month>02</month><year>2021</year></pub-date><volume>10</volume><issue>02</issue><fpage>433</fpage><lpage>443</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
  
    模糊聚类算法作为经典的无监督算法之一，在未提供先验信息的基础上容易陷入局部最优。为了能够将监督学习与无监督学习相结合，同时利用已标签数据和未标签数据共同进行训练学习，本文通过对目标函数进行拉普拉斯约束，通过验证隶属度的范围始终大于等于零，能够证明该算法是有效的。在其基础上加入先验信息来挖掘大量有用的信息，使之在未提供先验信息的基础上，算法能够合理、有效地利用部分已标识样本的类别信息对未标识样本产生影响，从而提高半聚类算法的聚类性能；最后，将文章中提出的两类改进算法与原始模糊c均值(FCM)进行聚类指标对比，能够显示其具有良好的聚类效果。
    As one of the classical unsupervised algorithms, fuzzy clustering algorithm is easy to fall into local optimum without providing prior information. In order to combine supervised learning with unsupervised learning and use both labeled and unlabeled data for training learning, this paper proved the effectiveness of the algorithm through Laplace constraint on the objective function and verification that the range of membership is always greater than or equal to zero. On this basis, prior information is added to mine a lot of useful information, so that the algorithm can reasonably and effectively use the category information of part of the identified samples to affect the unidentified samples, so as to improve the clustering performance of the semi-clustering algorithm. Finally, the two improved algorithms proposed in this paper are compared with the original Fuzzy C-means (FCM) for clustering index, and the results show that the proposed algorithm has good clustering effect. 
  
 
</p></abstract><kwd-group><kwd>拉普拉斯约束，先验信息，隶属度，聚类, Laplacian Constraint Sparse</kwd><kwd> Prior Information</kwd><kwd> Membership</kwd><kwd> Clustering</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>摘要</title><p>模糊聚类算法作为经典的无监督算法之一，在未提供先验信息的基础上容易陷入局部最优。为了能够将监督学习与无监督学习相结合，同时利用已标签数据和未标签数据共同进行训练学习，本文通过对目标函数进行拉普拉斯约束，通过验证隶属度的范围始终大于等于零，能够证明该算法是有效的。在其基础上加入先验信息来挖掘大量有用的信息，使之在未提供先验信息的基础上，算法能够合理、有效地利用部分已标识样本的类别信息对未标识样本产生影响，从而提高半聚类算法的聚类性能；最后，将文章中提出的两类改进算法与原始模糊c均值(FCM)进行聚类指标对比，能够显示其具有良好的聚类效果。</p></sec><sec id="s2"><title>关键词</title><p>拉普拉斯约束，先验信息，隶属度，聚类</p></sec><sec id="s3"><title>Semi-Supervised Fuzzy C-Means Algorithm Based on Laplace Constraint<sup> </sup></title><p>Ning Zhang, Yingcang Ma, Hengdong Zhu</p><p>School of Science, Xi’an Polytechnic University, Xi’an Shaanxi</p><p><img src="//html.hanspub.org/file/8-2621489x4_hanspub.png" /></p><p>Received: Jan. 7<sup>th</sup>, 2021; accepted: Feb. 11<sup>th</sup>, 2021; published: Feb. 20<sup>th</sup>, 2021</p><p><img src="//html.hanspub.org/file/8-2621489x5_hanspub.png" /></p></sec><sec id="s4"><title>ABSTRACT</title><p>As one of the classical unsupervised algorithms, fuzzy clustering algorithm is easy to fall into local optimum without providing prior information. In order to combine supervised learning with unsupervised learning and use both labeled and unlabeled data for training learning, this paper proved the effectiveness of the algorithm through Laplace constraint on the objective function and verification that the range of membership is always greater than or equal to zero. On this basis, prior information is added to mine a lot of useful information, so that the algorithm can reasonably and effectively use the category information of part of the identified samples to affect the unidentified samples, so as to improve the clustering performance of the semi-clustering algorithm. Finally, the two improved algorithms proposed in this paper are compared with the original Fuzzy C-means (FCM) for clustering index, and the results show that the proposed algorithm has good clustering effect.</p><p>Keywords:Laplacian Constraint Sparse, Prior Information, Membership, Clustering</p><disp-formula id="hanspub.40452-formula60"><graphic xlink:href="//html.hanspub.org/file/8-2621489x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2021 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/8-2621489x7_hanspub.png" /> <img src="//html.hanspub.org/file/8-2621489x8_hanspub.png" /></p></sec><sec id="s5"><title>1. 引言</title><p>近年来，聚类分析在模式识别、图像处理和数据挖掘中得到了广泛的应用。它试图将数据集划分为不同的组，使得同一集群中的数据点(模式、样本和主题)具有较高的相似性，而不同集群中的数据点具有较低的相似性。到目前为止，已经开发了许多聚类算法，包括层次聚类 [<xref ref-type="bibr" rid="hanspub.40452-ref1">1</xref>]、谱聚类 [<xref ref-type="bibr" rid="hanspub.40452-ref2">2</xref>] 和模糊c均值聚类(FCM) [<xref ref-type="bibr" rid="hanspub.40452-ref3">3</xref>] 等。</p><p>作为半监督聚类，可以采用不同的方法来控制聚类过程。传统的模糊聚类算法对未知样本的使用率较低，针对于该问题，相关领域学者经过不断研究提出了半监督模糊聚类。2000年，Wagstaff引入了一个具有成对约束集群的修改版本，即“必须连接”和“不能连接”，以提高聚类性能 [<xref ref-type="bibr" rid="hanspub.40452-ref4">4</xref>]。由于模糊c均值(FCM)是最经典的算法之一，一些相关的工作已经被提出，来约束半监督模糊c均值，例如在隶属度中加入半监督项 [<xref ref-type="bibr" rid="hanspub.40452-ref6">6</xref>]。半监督模糊聚类算法通过将少量的数据类别标签作为监督信息 [<xref ref-type="bibr" rid="hanspub.40452-ref5">5</xref>] 来加入到模糊聚类算法中，使其在整个聚类迭代优化过程中发挥一定的监督作用。SFCM算法 [<xref ref-type="bibr" rid="hanspub.40452-ref7">7</xref>] 是一种经典的半监督聚类算法，它以标签信息作为先验知识。该算法将已知的类别标签集成到隶属度矩阵中，指导隶属度矩阵的优化，约束项中所含的先验信息则会对隶属度矩阵的优化起监督作用，并创建最合理的模糊划分，以此提高聚类效果。Pedrycz和Waletzky [<xref ref-type="bibr" rid="hanspub.40452-ref8">8</xref>] 接受了改进的FCM算法，并将聚类问题的标记数据和未标记数据作为改进目标函数的途径。Luis等人 [<xref ref-type="bibr" rid="hanspub.40452-ref9">9</xref>] 提出了一种新的半监督模糊c均值算法，该算法利用基因本体注释作为先验知识来指导基因分组过程。同时，引入基于核的FCM方法(SSKFCM) [<xref ref-type="bibr" rid="hanspub.40452-ref10">10</xref>] [<xref ref-type="bibr" rid="hanspub.40452-ref11">11</xref>] 将半监督学习技术与核方法相结合，提高了模糊划分的质量。该方法将半监督聚类扩展到核空间，使聚类在输入空间中划分成具有非线性边界的群。</p><p>半监督聚类方法分为基于相似度的聚类方法和基于搜索的聚类方法，Zhang等人 [<xref ref-type="bibr" rid="hanspub.40452-ref12">12</xref>] 提出了一个框架，对由边缘信息构造的加权拉普拉斯矩阵进行优化更新。在文献 [<xref ref-type="bibr" rid="hanspub.40452-ref13">13</xref>] 的基础上，提出了一种鲁棒稀疏模糊k均值聚类算法，该算法是对标准模糊k均值算法的一种改进，它采用了一个鲁棒函数而不是平方数据拟合项来处理离群点。该文章中提出了一种新的方法(FSCM)来实现谱聚类结构和数据的模糊相似矩阵的联合学习。更为重要的是，结合稀疏性的概念，进一步引入惩罚项，使每个样本的对象簇成员具有适当的稀疏性。该算法不仅保证了软聚类算法在实际应用中的鲁棒性，而且考虑到隶属度数量较少，避免了性能下降 [<xref ref-type="bibr" rid="hanspub.40452-ref14">14</xref>]。根据不同聚类评价算法的适用范围，提出了一种特征加权模糊半监督聚类算法(SFFD) [<xref ref-type="bibr" rid="hanspub.40452-ref15">15</xref>] [<xref ref-type="bibr" rid="hanspub.40452-ref16">16</xref>]。该算法基于完全自适应的距离函数、特征权重和两两约束构造一个统一的目标函数，用于在两两约束下搜索最优原型参数和最优特征权重。同时，给出了四种不同的模糊聚类有效性评价算法，采用不同的算法来评估SFFD算法的有效性，得到不同输入数据集的最优聚类数，从而确定聚类形成过程中的聚类数。文章 [<xref ref-type="bibr" rid="hanspub.40452-ref17">17</xref>] 中提出的半监督模糊聚类算法充分利用了已知的信息样本，以最小信息熵对应的聚类数作为整个样本的最优聚类数，以此得到的聚类中心是模糊聚类的原始聚类中心。</p><p>本文在研究模糊c均值聚类(FCM)算法的基础上，通过加入正则项来约束FCM，提出了一种基于拉普拉斯约束的模糊c均值(FCML)算法，给出了FCML算法的迭代结果，并对其进行非负证明，即u<sub>ij</sub>经过多次迭代后，其最终结果仍为非负数，以此来证明该算法的有效性。</p><p>文章第三节在研究基于拉普拉斯约束的模糊c均值(FCML)算法的基础上，提出了基于拉普拉斯约束的半监督模糊c均值(SFCML)算法，该算法通过引入一些监督信息来改进FCML算法，可以在不提供先验信息的情况下充分利用先验信息来对未标记样本进行部分标记，合理有效地利用部分已识别样本的类别信息，从而提高半聚类算法的聚类性能，其最终结果具有和FCM算法一样简洁的隶属度与聚类中心的迭代公式。</p><p>最后，将文章中提出的基于拉普拉斯约束的模糊c均值(FCML)算法及基于拉普拉斯约束的半监督模糊c均值(SFCML)算法与原始模糊c均值(FCM)的聚类性能进行了检验和评价。</p></sec><sec id="s6"><title>2. 基于拉普拉斯约束的模糊c均值(FCML)</title><sec id="s6_1"><title>2.1. 目标函数设计</title><p>为了将数据点按一定的隶属度分组到每个聚类中，模糊c均值聚类的目标函数为：</p><p>min ∑ i = 1 n ∑ j = 1 c ‖ x i − v j ‖ 2 2 u i j 2</p><p>st .   ∑ i = 1 c u i j = 1 (1)</p><p>其中X为原始样本数据集， V = { v 1 , v 2 , ⋯ , v c } 为C个聚类中心， U = ( u i j ) c &#215; n 为隶属度矩阵， ‖ ⋅ ‖ 为欧式距离。</p><p>通过稀疏化模糊c均值去除大量的冗余变量，只保留与相应变量最相关的解释变量，简化了模型的同时却保留了数据集中最重要的信息，能够有效地解决高维数据集建模中的诸多问题，因此，本文在模糊c均值聚类的基础上引入了拉普拉斯约束：</p><p>min ∑ i = 1 n ∑ j = 1 c ‖ x i − v j ‖ 2 2 u i j 2 + 2 λ T r ( U T L S U ) 2)</p><p>式中n表示元素个数，c表示聚类个数，d为维数，S为数据X的相似矩阵， L S = D − S T + S 2 为S的Laplace矩阵， D = ∑ j = 1 n ( s i j + s j i ) 2 为对角矩阵。</p></sec><sec id="s6_2"><title>2.2. 理论分析</title><p>当U和S固定时，更新V可得到</p><p>V j = ∑ i = 1 n u i j 2 x i ∑ i = 1 n u i j 2 (3)</p><p>当V和S固定时，更新U，由目标函数可知与U有关的函数为：</p><p>min ∑ i = 1 c ∑ j = 1 n u i j 2 d i j 2 + 2 λ T r ( U L S U T ) (4)</p><p>在聚类算法中，有一个经典的等式：</p><p>2 T r ( U L S U T ) = ∑ i = 1 n ∑ j = 1 n ‖ u i − u j ‖ F 2 s i j (5)</p><p>关于(5)式是否成立，给出了如下证明：</p><p>U T L S U = U T ( D − S ) U = U T D U − U T S U</p><p>2 T r ( U T L S U ) = ∑ i = 1 n u i 2 d i − ∑ i , j = 1 n u i u j s i j = 1 2 ( ∑ i = 1 n u i 2 d i − 2 ∑ i , j = 1 n u i u j s i j + ∑ i = 1 n u j 2 d j ) = ∑ i , j = 1 n ‖ u i − u j ‖ F 2 s i j</p><p>因此，目标函数(4)可以改写成：</p><p>J = min ∑ i = 1 n ∑ j = 1 c ‖ x i − v j ‖ 2 2 u i j 2 + λ ∑ i = 1 n ∑ j = 1 c ‖ u i − u j ‖ F 2 s i j + μ ∑ i = 1 n ∑ j = 1 c ‖ x i − x j ‖ 2 2 s i j 2 (6)</p><p>即(6)式为</p><p>J u = min ∑ i = 1 c ∑ j = 1 n u i j 2 d i j 2 + λ ∑ i = 1 n ∑ j = 1 n ‖ u i − u j ‖ F 2 s i j (7)</p><p>其中含 u i j 的项为：</p><p>u i j 2 d i j 2 + 2 λ ∑ l ≠ j ‖ u l − u j ‖ F 2 s l j = u i j 2 d i j 2 + 2 λ ( ‖ u 1 − u j ‖ F 2 s 1 j + ⋯ + ‖ u j − 1 − u j ‖ F 2 s j − 1 , j + ‖ u j + 1 − u j ‖ F 2 s j + 1 , j + ⋯ + ‖ u n − u j ‖ F 2 s n j ) (8)</p><p>同理， ‖ u 1 − u j ‖ F 2 = ( u 11 − u 1 j ) 2 + ( u 21 − u 2 j ) 2 + ⋯ + ( u c 1 − u c j ) 2 ，其中只有 ( u i 1 − u i j ) 2 中 u i j ，所以(8)式中含 u i j 的值为：</p><p>u i j 2 d i j 2 + 2 λ ∑ l ≠ j ( u i j − u i l ) 2 s l j (9)</p><p>对其进行拉格朗日求导可得</p><p>2 u i j d i j 2 + 4 λ ∑ l ≠ j u i j s l j − 4 λ ∑ l ≠ j u i l s l j − ξ j = 0</p><p>其中 ξ i 为Lagrange乘子，所以</p><p>u i j = 4 λ ∑ l ≠ j u i l s l j + ξ j 2 d i j 2 + 4 λ ∑ l ≠ j s l j (10)</p><p>由约束条件 ∑ k = 1 c u k j = 1 可知(10)式为</p><p>∑ k = 1 c u k j = ∑ k = 1 c 4 λ ∑ l ≠ j u k l s l j + ξ j 2 d k j 2 + 4 λ ∑ l ≠ j s l j = 1 (11)</p><p>即</p><p>ξ j = 1 − ∑ k = 1 c 4 λ ∑ l ≠ j u k l s l j 2 d k j 2 + 4 λ ∑ l ≠ j s l j ∑ k = 1 c 1 2 d k j 2 + 4 λ ∑ l ≠ j s l j (12)</p><p>将(12)式代入(10)式中可得</p><p>u i j = 4 λ ∑ l ≠ j u i l s l j + 1 − ∑ k = 1 c 4 λ ∑ l ≠ j u k l s l j 2 d k j 2 + 4 λ ∑ l ≠ j s l j ∑ k = 1 c 1 2 d k j 2 + 4 λ ∑ l ≠ j s l j 2 d i j 2 + 4 λ ∑ l ≠ j s l j (13)</p><p>本文中，我们对迭代后(13)式中 u i j ≥ 0 是否成立进行了证明：</p><p>证明： u i j = 4 λ ∑ l ≠ j u i l s l j + 1 − ∑ k = 1 c 4 λ ∑ l ≠ j u k l s l j 2 d k j 2 + 4 λ ∑ l ≠ j s l j ∑ k = 1 c 1 2 d k j 2 + 4 λ ∑ l ≠ j s l j 2 d i j 2 + 4 λ ∑ l ≠ j s l j ≥ 0</p><p>由于 2 d i j 2 + 4 λ ∑ l ≠ j s l j ≥ 0 , 2 d k j 2 + 4 λ ∑ l ≠ j s l j ≥ 0 , 4 λ ∑ l ≠ j u i l s l j ≥ 0 ，因此在这里只需证： 1 − ∑ k = 1 c 4 λ ∑ l ≠ j u k l s l j 2 d k j 2 + 4 λ ∑ l ≠ j s l j ≥ 0 即</p><p>∑ k = 1 c 4 λ ∑ l ≠ j u k l s l j 2 d k j 2 + 4 λ ∑ l ≠ j s l j ≤ 1</p><p>因为</p><p>4 λ ∑ l ≠ j u k l s l j 2 d k j 2 + 4 λ ∑ l ≠ j s l j ≤ 4 λ ∑ l ≠ j u k l s l j 4 λ ∑ l ≠ j s l j = ∑ l ≠ j u k l s l j ∑ l ≠ j s l j</p><p>可得</p><p>∑ k = 1 c 4 λ ∑ l ≠ j u k l s l j 2 d k j 2 + 4 λ ∑ l ≠ j s l j ≤ ∑ k = 1 c ∑ l ≠ j u k l s l j ∑ l ≠ j s l j</p><p>因为</p><p>∑ k = 1 c ∑ l ≠ j u k l s l j ∑ l ≠ j s l j = ∑ k = 1 c u k 1 s 1 j + u k 2 s 2 j + ⋯ + u k , j − 1 s j − 1 , j + u k , j + 1 s j + 1 , j + ⋯ + u k n s n j s 1 j + s 2 j + ⋯ + s j − 1 , j + s j + 1 , j + ⋯ + s n j = s 1 j ∑ k = 1 c u k 1 + s 2 j ∑ k = 1 c u k 2 + ⋯ + s j − 1 , j ∑ k = 1 c u k , j − 1 + s j + 1 , j ∑ k = 1 c u k , j + 1 + ⋯ + s n j ∑ k = 1 c u k n s 1 j + s 2 j + ⋯ + s j − 1 , j + s j + 1 , j + ⋯ + s n j (14)</p><p>由约束条件可得 ∑ k = 1 c u k 1 = 1 , ⋯ , ∑ k = 1 c u k n = 1 ，从而 ∑ k = 1 c ∑ l ≠ j u k l s l j ∑ l ≠ j s l j = 1 ，因此 u i j ≥ 0 得证。</p><p>固定U和V，更新S，(4)式可以看作：</p><p>λ T r ( U T L S U ) + μ ∑ i = 1 n ∑ j = 1 c ‖ x i − x j ‖ 2 2 s i j 2 = λ ∑ i = 1 n ∑ j = 1 c ‖ u i − u j ‖ 2 2 s i j + μ ∑ i = 1 n ∑ j = 1 c ‖ x i − x j ‖ 2 2 s i j 2 (15)</p><p>由于i独立，因此对(5)式求解，可以得到</p><p>s i T D s i + λ μ s i T V i (16)</p></sec><sec id="s6_3"><title>2.3. 算法流程</title><p>基于拉普拉斯约束的模糊c均值(FCML)与其他聚类算法具有类似的框架，其流程可以总结为：</p><p>输入：原始样本数据集X，聚类簇数c以及相似矩阵S。</p><p>输出：聚类中心V，迭代后的隶属度矩阵U。</p><p>步骤1：按照约束条件初始化U并设置聚类簇数c，迭代次数设置为100次。</p><p>步骤2：计算实际数据集的样本点与聚类中心的距离d；</p><p>步骤3：利用公式(4)计算迭代后的隶属度矩阵U；</p><p>步骤4：利用公式(3)计算V；</p><p>步骤5：本次计算得出的聚类中心与上次相比，不发生变化或者满足迭代次数超出最大次数，则算法停止；否则，返回步骤2。</p></sec></sec><sec id="s7"><title>3. 基于拉普拉斯约束的半监督模糊c均值算法(SFCML)</title><sec id="s7_1"><title>3.1. 目标函数设计</title><p>半监督聚类是一种监督聚类和无监督聚类相结合的聚类方法，既可以使用有标记的数据，也可以使用无标记的数据。在上一节中，我们通过对FCM算法进行拉普拉斯约束，得到了FCML算法，该过程是简单的，它通常可以达到预期的性能。然而，FCML算法没有嵌入可在某些应用中收集和有用的先验知识，因此算法容易陷入局部最优。本节中，我们在数据集X上运行FCML算法，给定原始数据集X，第l个样本与它们的集群标签y构成一个标记子集Y，其余的 n − l 个样本构成一个未标记子集，通过将先验知识引入到FCML中，此时SFCML算法的目标函数为：</p><p>J = min ∑ i = 1 n ∑ j = 1 c ‖ x i − v j ‖ 2 2 u i j 2 + λ ∑ i = 1 n ∑ j = 1 c ‖ u i − u j ‖ F 2 s i j + α ∑ i = 1 n ∑ j = 1 c ( u i j − f i j b i ) 2 d i j 2 st .   ∑ i = 1 n u i j = 1 , u i j ≥ 0 (17)</p><p>式中， α ( α ≥ 0 ) 是反映保真度项重要性的参数， α 的具体值和 总 样 本 数 L 标 记 样 本 数 L 1 成正比例关系； f i j 为标签样本的隶属度矩阵，其值具体表示为 x i 归于 c j 的程度大小； b i 为一个布尔型的二值向量，根据其实际值可以判断 x i 是否是已经标记的数据。 b i 需要满足的条件如下：</p><p>{ b i = 1 , x i 被 标 记 b i = 0 , 其 他 (18)</p></sec><sec id="s7_2"><title>3.2. 理论分析</title><p>当U和S固定时，更新V可得到</p><p>v j = ∑ i = 1 n u i j 2 x i ∑ i = 1 n u i j 2 (19)</p><p>当V和S固定时，更新U，由目标函数可知与U有关的函数为：</p><p>其中含 u i j 的项为：</p><p>J = min ∑ i = 1 n ∑ j = 1 c ‖ x i − v j ‖ 2 2 u i j 2 + λ ∑ i = 1 n ∑ j = 1 c ‖ u i − u j ‖ F 2 s i j + α ∑ i = 1 n ∑ j = 1 c ( u i j − f i j b i ) 2 d i j 2 (20)</p><p>u i j 2 d i j 2 + 2 λ ∑ l ≠ j ‖ u l − u j ‖ F 2 s l j + α ∑ i = 1 n ∑ j = 1 c ( u i j − f i j b i ) 2 d i j 2 = u i j 2 d i j 2 + 2 λ ( ‖ u 1 − u j ‖ F 2 s 1 j + ⋯ + ‖ u j − 1 − u j ‖ F 2 s j − 1 , j + ‖ u j + 1 − u j ‖ F 2 s j + 1 , j + ⋯ + ‖ u n − u j ‖ F 2 s n j ) + α ( ( u 11 − f 11 b 1 ) 2 d 11 2 + ⋯ + ( u 1 j − f 1 j b 1 ) 2 d 1 j 2 + ⋯ + ( u i j − f i j b i ) 2 d i j 2 + ⋯ + ( u n c − f n c b n ) 2 d n c 2 ) (21)</p><p>由于只有 ( u i 1 − u i j ) 2 及 α ( u i j − f i j b i ) d i j 2 中有 u i j ，所以(21)式中含 u i j 的值为：</p><p>u i j 2 d i j 2 + 2 λ ∑ l ≠ j ( u i j − u i l ) 2 s l j + α ∑ i = 1 n ∑ j = 1 c ( u i j − f i j b i ) 2 d i j 2 (22)</p><p>将(22)式改写为</p><p>L ( u i j , η , β i j ) = u i j 2 d i j 2 + 2 λ ∑ l ≠ j ( u i j − u i l ) 2 s l j + α ∑ i = 1 n ∑ j = 1 c ( u i j − f i j b i ) 2 d i j 2 − η ( ∑ i = 1 n u i j − 1 ) − β i j u i j (23)</p><p>对(23)式中 u i j 求偏导数可得：</p><p>∂ J u ∂ u = 2 u i j d i j 2 + 4 λ ∑ l ≠ j ( u i j − u i l ) s l j + 2 α ( u i j − f i j b i ) d i j 2 − η − β i j</p><p>对其进行拉格朗日求导可得</p><p>2 u i j d i j 2 + 4 λ ∑ l ≠ j u i j s l j − 4 λ ∑ l ≠ j u i l s l j − 2 α ( u i j − f i j b i ) d i j 2 − η − β i j = 0</p><p>其中 η 和 β i j ≥ 0 为Lagrange乘子，所以</p><p>u i j = ( 4 λ ∑ l ≠ j u i l s l j − 2 α f i j b i d i j 2 + η + β i j 2 d i j 2 − 2 α d i j 2 + 4 λ ∑ l ≠ j s l j ) + (24)</p><p>由约束条件 ∑ k = 1 c u k j = 1 可知(24)式为</p><p>∑ k = 1 c u k j = ∑ k = 1 c 4 λ ∑ l ≠ j u k l s l j − 2 α f k j b k d k j 2 + ξ j 2 d k j 2 − 2 α d k j 2 + 4 λ ∑ l ≠ j s l j = 1 (25)</p><p>因此</p><p>ξ j = 1 − ∑ k = 1 c 4 λ ∑ l ≠ j u k l s l j 2 d k j 2 − 2 α d k j 2 + 4 λ ∑ l ≠ j s l j + ∑ k = 1 c 2 α f k j b k d k j 2 2 d k j 2 − 2 α d k j 2 + 4 λ ∑ l ≠ j s l j ∑ k = 1 c 1 2 d k j 2 − 2 α d k j 2 + 4 λ ∑ l ≠ j s l j (26)</p><p>将(25)式代入(24)式中可得</p><p>u i j = 4 λ ∑ l ≠ j u i l s l j − 2 α f i j b i d i j 2 + 1 − ∑ k = 1 c 4 λ ∑ l ≠ j u k l s l j 2 d k j 2 − 2 α d k j 2 + 4 λ ∑ l ≠ j s l j + ∑ k = 1 c 2 α f k j b k d k j 2 2 d k j 2 − 2 α d k j 2 + 4 λ ∑ l ≠ j s l j ∑ k = 1 c 1 2 d k j 2 − 2 α d k j 2 + 4 λ ∑ l ≠ j s l j 2 d i j 2 − 2 α d i j 2 + 4 λ ∑ l ≠ j s l j (27)</p></sec><sec id="s7_3"><title>3.3. 算法2</title><p>基于拉普拉斯约束的半监督模糊c均值(SFCML)与其他半监督聚类算法具有类似的框架，其流程为：</p><p>输入：需要聚类的数据对象集合X，聚类的类别数c以及带有标签信息的约束集Y。</p><p>输出：更新后的聚类中心V及隶属度矩阵U。</p><p>步骤1：通过计算每个集群中标记样本的平均值来初始化集群中心V<sub>0</sub>，按照约束条件随机初始化U，设置聚类个数c，由标记信息计算标记信息的初始隶属度矩阵F<sub>0</sub>；</p><p>步骤2：计算实际数据集X的样本点与聚类中心的距离d，标签样本集Y与聚类中心的距离d<sub>y</sub>；</p><p>步骤3：利用公式(27)计算迭代后的隶属度矩阵U；</p><p>步骤4：利用公式(19)计算聚类中心V；</p><p>步骤5：本次计算得出的聚类中心与上次相比，不发生变化或者满足迭代次数超出最大次数，则算法停止；否则，返回步骤2。</p></sec></sec><sec id="s8"><title>4. 实验结果分析</title><sec id="s8_1"><title>4.1. 实验设计</title><p>为评估聚类结果，采用聚类准确率(ACC)、NMI指标及兰德指数(简称RI)这三种被广泛使用的聚类性能指标。ACC指标可以发现聚类结果和真实类标签之间的一对一关系，且测量每个聚类所包含的来自对应类别的数据点的多少，其计算式为</p><p>A C C = ∑ i = 1 n δ ( m a p ( r i ) , q i ) n</p><p>NMI指标用于确定聚类的质量，给定一个聚类结果，则</p><p>N M I = ∑ i = 1 n ∑ j = 1 n n i j lg n i j n i n ^ j ( ∑ i = 1 n n i lg n i n ) ( ∑ j = 1 n n ^ j lg n ^ j n )</p><p>兰德指数(简称RI)算法的性能根据该算法获得的决策数量的正确率来评估。它需提供定实际类别信息C，假设K是聚类结果，a表示在C和k中都是同类别的元素对数，d表示在C与k中都是不同类别的元素对数，则RI参数为： R I = a + d C 2 n samples ，其中 C 2 n samples 数据集中可以组成的总元素对数。</p></sec><sec id="s8_2"><title>4.2. 真实数据集实验结果</title><p>我们在真实数据集中选取iris数据集进行实验。实验采用FCM、FCML和SFCML进行测试和比较。为了验证测试结果的可靠性，在FCM、FCML和SFCML实验中均使用欧氏距离。此外，算法的标签样本点个数为10个，标签样本点的初始隶属度相同。采用三种算法对真实数据集进行依次测试，每种算法测试10次。最终实验结果见表1。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Accuracy of FCM, FCML and SFCML algorithms on Iris data se</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >迭代次数</th><th align="center" valign="middle" >FCM</th><th align="center" valign="middle" >FCML</th><th align="center" valign="middle" >SFCML</th></tr></thead><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" >0.8933</td><td align="center" valign="middle" >0.9067</td><td align="center" valign="middle" >0.9133</td></tr><tr><td align="center" valign="middle" >2</td><td align="center" valign="middle" >0.8797</td><td align="center" valign="middle" >0.8933</td><td align="center" valign="middle" >0.9067</td></tr><tr><td align="center" valign="middle" >3</td><td align="center" valign="middle" >0.9067</td><td align="center" valign="middle" >0.9184</td><td align="center" valign="middle" >0.9600</td></tr><tr><td align="center" valign="middle" >4</td><td align="center" valign="middle" >0.8900</td><td align="center" valign="middle" >0.9034</td><td align="center" valign="middle" >0.9307</td></tr><tr><td align="center" valign="middle" >5</td><td align="center" valign="middle" >0.7400</td><td align="center" valign="middle" >0.9700</td><td align="center" valign="middle" >0.9900</td></tr><tr><td align="center" valign="middle" >6</td><td align="center" valign="middle" >0.9700</td><td align="center" valign="middle" >0.9800</td><td align="center" valign="middle" >0.9900</td></tr><tr><td align="center" valign="middle" >7</td><td align="center" valign="middle" >0.9015</td><td align="center" valign="middle" >0.9184</td><td align="center" valign="middle" >0.9600</td></tr><tr><td align="center" valign="middle" >8</td><td align="center" valign="middle" >0.8400</td><td align="center" valign="middle" >0.9700</td><td align="center" valign="middle" >1</td></tr><tr><td align="center" valign="middle" >9</td><td align="center" valign="middle" >0.9700</td><td align="center" valign="middle" >0.9900</td><td align="center" valign="middle" >1</td></tr><tr><td align="center" valign="middle" >10</td><td align="center" valign="middle" >0.9700</td><td align="center" valign="middle" >0.9800</td><td align="center" valign="middle" >1</td></tr></tbody></table></table-wrap><p>表1. Iris数据集上FCM、FCML、SFCML算法准确率</p><p>由表1可以清楚看出，FCM算法、FCML算法和SFCML算法的准确率大小依次为：SFCML算法最大，FCML算法其次，最后是FCM算法，与理论分析结果一致。和FCM算法相比，FCML算法能够有效提取有用信息进行聚类，而SFCML算法在FCML算法的基础上加入监督信息，使得算法准确率进一步提升。</p><p>表2分别对FCM、FCML和SFCML算法进行聚类质量NMI及聚类效果RI对比。</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> Clustering effect comparison of FCM, FCML and SFCML on Iris data se</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >评估标准</th><th align="center" valign="middle" >FCM</th><th align="center" valign="middle" >FCML</th><th align="center" valign="middle" >SFCML</th></tr></thead><tr><td align="center" valign="middle" >NMI</td><td align="center" valign="middle" >0.9067</td><td align="center" valign="middle" >0.9184</td><td align="center" valign="middle" >0.9390</td></tr><tr><td align="center" valign="middle" >RI</td><td align="center" valign="middle" >0.9600</td><td align="center" valign="middle" >0.9703</td><td align="center" valign="middle" >0.9800</td></tr></tbody></table></table-wrap><p>表2. Iris数据集上FCM、FCML、SFCML聚类效果对比</p><p>从聚类准确度方面分析，SFCML算法达到最大值，为0.9800；而FCM算法因为没有监督信息集拉普拉斯约束项做指导，聚类的准确率是3种算法中最小的，为0.9600；FCML算法居中，为0.9703。综合来看，无论用3个方面的哪一个评价，SFCML算法的聚类性能都要优于其他2种聚类算法。</p></sec></sec><sec id="s9"><title>5. 总结与展望</title><p>本文在经典FCM算法的基础上引入了拉普拉斯算法进行约束，提高聚类的抗噪性能以及提取重要的属性特征，并将最终迭代结果进行非负验证。其次，利用少量标记信息进行数据预处理，构造半监督聚类算法SFCML来对FCML算法进行改进。此外，由于SFCML的目标函数是基于FCM的，它继承了聚类算法FCM的大部分优点。本文在真实数据集上进行算法对比实验，实验结果进一步验证了本文提出的SFCML算法的有效性。之后对半监督的研究将从对相似矩阵S进行半监督学习，并验证是否能达到改进已有算法的效果。与多个领域进行融合，在不同领域内运用半监督聚类算法的思想，加入不同领域的知识，可以得到更加优化的效果。</p></sec><sec id="s10"><title>致谢</title><p>首先要感谢我的论文指导老师、西安工程大学理学院研究生院的马盈仓老师。马老师对我论文的研究方向做出了指导性的意见和建议，在写这篇论文的过程中，他对我遇到的困难和疑惑及时给予了认真的指导，提出了许多有益的改进建议，投入了大量的心血和精力。衷心感谢马老师对我的帮助和关心！同时，我也要感谢西安工程大学理学院研究生院计算数学专业的老师们和全体同学们，我们互相学习，互相帮助，度过了一段美好而难忘的时光。此外，我还要感谢我的朋友和同学们在论文的准备过程中给予我的大力支持和帮助，给我带来了很大的启发。也要感谢参考文献中的作者，他们的研究文章对我的研究课题有了一个很好的起点。最后，谢谢论文评阅老师们的辛苦工作。衷心感谢我的家人、朋友和同学对我的鼓励和支持，让我顺利完成了这篇论文。</p></sec><sec id="s11"><title>基金项目</title><p>国家自然科学基金项目(61976130)；陕西省重点研发计划项目(2018KW-021)；陕西省自然科学基金项目(2020JQ-923)。</p></sec><sec id="s12"><title>文章引用</title><p>张 宁,马盈仓,朱恒东. 基于拉普拉斯约束的半监督模糊C均值算法Semi-Supervised Fuzzy C-Means Algorithm Based on Laplace Constraint[J]. 应用数学进展, 2021, 10(02): 433-443. https://doi.org/10.12677/AAM.2021.102049</p></sec><sec id="s13"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.40452-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Johnson, S.C. (1967) Hierarchical Clustering Schemes. Psychometrika, 32, 241-254.  
&lt;br&gt;https://doi.org/10.1007/BF02289588</mixed-citation></ref><ref id="hanspub.40452-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Ng, A.Y., Jordan, M.I. and Weiss, Y. (2002) On Spectral Clustering: Analysis and an Algorithm. The Conference and Workshop on Neural Information Processing Systems, Vol. 14, 849-856.</mixed-citation></ref><ref id="hanspub.40452-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Bezdek, J.C. (1981) Pattern Recognition with Fuzzy Objective Function Algorithms. Plenum, New York.  
&lt;br&gt;https://doi.org/10.1007/978-1-4757-0450-1</mixed-citation></ref><ref id="hanspub.40452-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Wu, L., Hoi, S., Jin, R., et al. (2010) Learning Bregman Distance Functions for Semi-Supervised Clustering. IEEE Transactions on Knowledge &amp; Data Engineering, 24, 478-491. &lt;br&gt;https://doi.org/10.1109/TKDE.2010.215</mixed-citation></ref><ref id="hanspub.40452-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">白福均, 高建瓴, 宋文慧, 等. 半监督模糊聚类算法的研究与改进[J]. 通信技术, 2018, 317(5): 71-75.</mixed-citation></ref><ref id="hanspub.40452-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Brodinova, S., Filzmoser, P., Ortner, T., et al. (2019) Robust and Sparse K-Means Clustering for High-Dimensional Data. Advances in Data Analysis &amp; Classification, 13, 905-932. &lt;br&gt;https://doi.org/10.1007/s11634-019-00356-9</mixed-citation></ref><ref id="hanspub.40452-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">朱乐为. 模糊C-means聚类算法的拓展研究[J]. 云南民族大学学报(自然科学版), 2019, 28(3): 64-70.</mixed-citation></ref><ref id="hanspub.40452-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Pedrycz, W. and Waletzky, J. (1997) Fuzzy Clustering with Partial Supervision. IEEE Transactions on Systems Man and Cybernetics Part B—Cybernetics, 27, 787-795. &lt;br&gt;https://doi.org/10.1109/3477.623232</mixed-citation></ref><ref id="hanspub.40452-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Tari, L., Baral, C. and Kim, S. (2009) Fuzzy c-Means Clustering with Prior Biological Knowledge. Journal of Biomedical Informatics, 42, 74-81. &lt;br&gt;https://doi.org/10.1016/j.jbi.2008.05.009</mixed-citation></ref><ref id="hanspub.40452-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Zhang, H.X. and Lu, J. (2009) Semi-Supervised Fuzzy Clustering: A Kernel-Based Approach. Knowledge-Based Systems, 22, 477-481. &lt;br&gt;https://doi.org/10.1016/j.knosys.2009.06.009</mixed-citation></ref><ref id="hanspub.40452-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Zhang, D.Q., Zhou, Z.H. and Chen, S.C. (2007) Semi-Supervised Dimensionality Reduction. Proceedings of the Seventh Siam International Conference on Data Mining, Minneapolis, 26-28 April 2007, 629-634.  
&lt;br&gt;https://doi.org/10.1137/1.9781611972771.73</mixed-citation></ref><ref id="hanspub.40452-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Zhang, R., Nie, F. and Li, X. (2017) Self-Weighted Spectral Clustering with Parameter-Free Constraint. Neurocomputing, 241, 164-170. &lt;br&gt;https://doi.org/10.1016/j.neucom.2017.01.085</mixed-citation></ref><ref id="hanspub.40452-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Zhang, R., Nie, F., Guo, M., et al. (2019) Joint Learning of Fuzzy k-Means and Nonnegative Spectral Clustering with Side Information. IEEE Transactions on Image Processing, 28, 2152-2162. &lt;br&gt;https://doi.org/10.1109/TIP.2018.2882925</mixed-citation></ref><ref id="hanspub.40452-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">Wang, D., Nie, F. and Huang, H. (2015) Feature Selection via Global Redundancy Minimization. IEEE Transactions on Knowledge &amp; Data Engineering, 27, 2743-2755. &lt;br&gt;https://doi.org/10.1109/TKDE.2015.2426703</mixed-citation></ref><ref id="hanspub.40452-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">李龙龙, 何东健, 王美丽. 模糊半监督加权聚类算法的有效性评价研究[J]. 计算机技术与发展, 2016, 26(6): 65-68.</mixed-citation></ref><ref id="hanspub.40452-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">Li, L.L., Jonathan, G., He, D.J., et al. (2015) Semi-Supervised Fuzzy Clustering with Feature Discrimination. PLoS ONE, 10, 131-160. &lt;br&gt;https://doi.org/10.1371/journal.pone.0131160</mixed-citation></ref><ref id="hanspub.40452-ref17"><label>17</label><mixed-citation publication-type="other" xlink:type="simple">郭新辰, 郗仙田, 樊秀玲, 等. 基于半监督的模糊C-均值聚类算法[J]. 吉林大学学报: 理学版, 2015, 53(4): 705-709.</mixed-citation></ref></ref-list></back></article>