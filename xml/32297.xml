<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2019.99198</article-id><article-id pub-id-type="publisher-id">CSA-32297</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20190900000_38913356.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于迁移深度学习的雷达信号分选识别
  Radar Signal Sorting and Recognition Based on Transferred Deep Learning
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>王</surname><given-names>功明</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>陈</surname><given-names>世文</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff3"><sup>3</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>黄</surname><given-names>洁</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff3"><sup>3</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>黄</surname><given-names>东华</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff3"><sup>3</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>战略支援部队信息工程大学，河南 郑州;中国人民解放军93986部队，新疆 和田</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><aff id="aff3"><addr-line>战略支援部队信息工程大学，河南 郑州</addr-line></aff><pub-date pub-type="epub"><day>03</day><month>09</month><year>2019</year></pub-date><volume>09</volume><issue>09</issue><fpage>1761</fpage><lpage>1778</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   针对当前雷达信号分选识别算法普遍存在的低信噪比下识别能力差、特征参数提取困难、分类器模型参数复杂等问题，提出了一种基于时频分析、深度学习和迁移学习融合模型的雷达信号自动分选识别算法。首先通过引入的多重同步压缩变换得到雷达信号的时频图像，然后利用灰度化、维纳滤波、双三次插值法和归一化等手段对时频图像进行预处理，最后基于迁移学习的方法，以GoogLeNet和ResNet模型为基础完成了对雷达信号的离线训练和在线识别。仿真结果表明，在信噪比为−6 dB时，该算法对9种雷达信号(CW, LFM, NLFM, BPSK, MPSK, Costas, LFM/BPSK, LFM/FSK, BPSK/FSK)的整体平均识别率可达93.4%，较常规人工提取算法具有更好的抗噪性和泛化能力。 Aiming at the problems of poor recognition ability under low signal-to-noise ratio (SNR), difficulty in extracting feature parameters and complexity of classifier model parameters commonly existing in current radar signal sorting and recognition algorithms, an automatic radar signal sorting and recognition algorithm based on time-frequency analysis, deep learning and transfer learning fusion model is proposed. Firstly, the time-frequency image of radar signal is obtained by introducing Mul-tisynchrosqueezing Transform. Then, the time-frequency image is preprocessed by gray scale, Wiener filtering, bicubic interpolation and normalization. Finally, based on the migration learning method, the off-line training and on-line recognition of radar signals are completed on the basis of Goog-LeNet and ResNet models. Simulation results show that when SNR is −6 dB, the overall average recognition rate of the algorithm for nine radar signals (CW, LFM, NLFM, BPSK, MPSK, Costas, LFM/BPSK, LFM/FSK, BPSK/FSK) can reach 93.4%, which is better than the conventionally artificial extraction algorithm in noise resistance and generalization. 
  
 
</p></abstract><kwd-group><kwd>雷达信号，分选识别，时频分析，深度学习，迁移学习, Radar Signal</kwd><kwd> Sorting and Recognition</kwd><kwd> Time-Frequency Analysis</kwd><kwd> Deep Learning</kwd><kwd> Transfer Learning</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>基于迁移深度学习的雷达信号分选识别<sup> </sup></title><p>王功明<sup>1,2</sup>，陈世文<sup>1*</sup>，黄洁<sup>1</sup>，黄东华<sup>1</sup></p><p><sup>1</sup>战略支援部队信息工程大学，河南 郑州</p><p><sup>2</sup>中国人民解放军93986部队，新疆 和田</p><p><img src="//html.hanspub.org/file/17-1541521x1_hanspub.png" /></p><p>收稿日期：2019年9月2日；录用日期：2019年9月17日；发布日期：2019年9月24日</p><disp-formula id="hanspub.32297-formula11"><graphic xlink:href="//html.hanspub.org/file/17-1541521x6_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>针对当前雷达信号分选识别算法普遍存在的低信噪比下识别能力差、特征参数提取困难、分类器模型参数复杂等问题，提出了一种基于时频分析、深度学习和迁移学习融合模型的雷达信号自动分选识别算法。首先通过引入的多重同步压缩变换得到雷达信号的时频图像，然后利用灰度化、维纳滤波、双三次插值法和归一化等手段对时频图像进行预处理，最后基于迁移学习的方法，以GoogLeNet和ResNet模型为基础完成了对雷达信号的离线训练和在线识别。仿真结果表明，在信噪比为−6 dB时，该算法对9种雷达信号(CW, LFM, NLFM, BPSK, MPSK, Costas, LFM/BPSK, LFM/FSK, BPSK/FSK)的整体平均识别率可达93.4%，较常规人工提取算法具有更好的抗噪性和泛化能力。</p><p>关键词 :雷达信号，分选识别，时频分析，深度学习，迁移学习</p><disp-formula id="hanspub.32297-formula12"><graphic xlink:href="//html.hanspub.org/file/17-1541521x7_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2019 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/17-1541521x8_hanspub.png" /> <img src="//html.hanspub.org/file/17-1541521x9_hanspub.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>近年来，随着雷达技术的快速发展，以低截获概率(Low Probability Interception, LPI)雷达为代表的各种新体制雷达在战场上得到了广泛的应用。战场电磁环境变得日益复杂、信号类型变化多样，使得传统依靠五大常规参数：载频(Carrier Frequency, CF)、脉冲宽度(Pulse Width, PW)、脉冲幅度(Pulse Amplitude, PA)、到达时间(Time of Arrival, TOA)和到达角(Direction of Arrival, DOA)组成的脉冲描述字(Pulse Description Word, PDW)已经难以满足雷达信号分选识别的实际需要 [<xref ref-type="bibr" rid="hanspub.32297-ref1">1</xref>] [<xref ref-type="bibr" rid="hanspub.32297-ref2">2</xref>] 。考虑到新体制雷达信号往往包含丰富的脉内信息，基于脉内信息的雷达信号分选识别算法逐步成为了研究热点。</p><p>基于脉内信息的雷达信号分选识别的关键在于特征提取和分类器设计。经过多年的不断研究，学者们陆续提出了时频分析、模糊函数、高阶统计量及变换域分析等方法。文献 [<xref ref-type="bibr" rid="hanspub.32297-ref3">3</xref>] 通过Choi-Williams分布得到信号的时频图像，进一步提取出时频图像的奇异值熵和信号频谱的分形维数特征，最后使用基于支持向量机(Support Vector Machine, SVM)的分类器完成了对8种雷达信号的识别，在信噪比大于等于1 dB时，整体平均识别率达到95%；文献 [<xref ref-type="bibr" rid="hanspub.32297-ref4">4</xref>] 提出一种基于模糊函数主脊切面特征的方法，构建出由主脊方向、切面重心和惯性半径组成的特征向量，所提取特征较好地反映了不同信号波形的差异，同时具备较好的抗噪性；文献 [<xref ref-type="bibr" rid="hanspub.32297-ref5">5</xref>] 采用直接法得到雷达信号的双谱估计，基于广义维数(Generalized Dimension, GD)方法从双谱对角切片(Bispectra Diagonal Slice, BDS)中提取出3个区分度大的特征q值作为特征参数用于信号的识别，在信噪比为0 dB时对4种雷达信号的整体识别率为92.2%。这些都可以归纳为人工特征提取结合机器学习的方法，人工特征虽然具有计算简单、设计灵活、意义明确等优点，但也存在以下几个问题：一是表述能力有限。人工设计的特征往往比较简单固定，只能描述某一部分的信息，在处理复杂问题时容易遇到精度上的瓶颈；二是特征通用性不足。针对不同问题往往需要设计不同的特征，在处理新问题时某些特征的效果会大打折扣，需要反复验证其有效性；三是维数灾难。为了提升算法的精度，会提取各种各样的特征，当维数增加到一定程度后，增加特征维度反而会引起精度的下降。</p><p>随着深度学习理论的不断发展，鉴于它在计算机视觉中优异的模型泛化能力，学者们将深度学习引入到了雷达信号分选识别领域，利用各种成熟的深度学习网络模型自动提取信号的潜在特征，并取得了良好的应用效果 [<xref ref-type="bibr" rid="hanspub.32297-ref6">6</xref>] - [<xref ref-type="bibr" rid="hanspub.32297-ref11">11</xref>] 。文献 [<xref ref-type="bibr" rid="hanspub.32297-ref12">12</xref>] 引入一种新的核函数构建Cohen类时频分布得到雷达信号的时频图，经过维纳滤波、双线性插值、灰度化等处理后送入CNN网络实现了对12种雷达信号(LFM, SFM, 2FSK, 4FSK, DLFM, EQFM, MLFM, BPSK, Frank, MP, LFM-BPSK, 2FSK-BPSK)的自动识别，在信噪比为−6 dB时，整体平均识别率达到96.1%；文献 [<xref ref-type="bibr" rid="hanspub.32297-ref13">13</xref>] 提出了一种包含两个独立的卷积神经网络(Convolutional Neural Network, CNN)和赫尔曼网络(Herman Neural Network, ENN)的混合分类器模型，该算法信噪比大于等于−2 dB时对12种雷达信号(BPSK, LFM, Costas, Frank, P1-P4, T1-T4)的整体识别率达到94.5%。但与传统机器学习相比，深度学习对数据有非常严重的依赖，需要大量的样本数据学习潜在的特征，而且不能有效地应用于新的任务。在雷达信号分选识别等特殊领域，往往难以获得大量、高质量的训练样本。迁移学习通过使用现有的知识或模型来解决不同但相关领域的问题，为机器学习和深度学习提供了一个新的思路 [<xref ref-type="bibr" rid="hanspub.32297-ref14">14</xref>] 。基于迁移学习的深度神经网络模型不用从零开始训练，而只需要在预训练网络模型的基础上对新的样本进行训练，然后进行网络参数微调，就可以方便快捷地达到满意的识别效果。文献 [<xref ref-type="bibr" rid="hanspub.32297-ref15">15</xref>] 基于改进核函数的Cohen类分布得到雷达信号的时频图像，使用预训练自编码器(Stacked Auto Encoder, SAE)和AlexNet结构的卷积神经网络(Convolutional Neural Network, CNN)混合模型，通过迁移学习的方法完成了对12种雷达信号(Costas, LFM, NLFM, BPSK, P1-P4和T1-T4)的识别，在信噪比大于等于−6 dB时，平均识别率达到95.5%，尽管这些算法取得了良好的识别效果，但仍然存在一些问题：1) 模型复杂、训练时间长；2) 低信噪比下识别效果不佳；3) 对复合调制类型雷达信号关注较少等。</p><p>因此，本文结合时频分析、深度学习和迁移学习理论，提出了一种基于迁移深度学习的雷达信号分选识别算法。该算法先通过引入多重同步压缩变换(Multi-synchrosqueezing Transform, MSST)得到雷达信号的时频图像，然后对时频图像进行灰度化、维纳滤波、双三次插值法和归一化预处理，运用迁移学习的思想，分别基于GoogLeNet和ResNet两种预训练神经网络模型对时频图像进行离线训练，最后实现了对9种雷达信号的在线识别。</p></sec><sec id="s4"><title>2. 基于时频分析的信号预处理</title><sec id="s4_1"><title>2.1. 雷达脉内调制信号模型</title><p>雷达信号的脉内特征包括脉内有意调制特征和脉内无意调制特征。无意调制特征又称为指纹特征，一般是人为误差产生或者雷达发射机硬件固有的非理想特性产生的固有特征，可用于辐射源个体识别(Specific Emitter Identification, SEI)。有意调制特征雷达波形设计者为了实现某种特定的功能，人为地加入了一些调制特征，包括幅度调制、频率调制、相位调制以及两种或两种以上的混合调制特征等 [<xref ref-type="bibr" rid="hanspub.32297-ref16">16</xref>] [<xref ref-type="bibr" rid="hanspub.32297-ref17">17</xref>] 。本文主要针对脉内有意调制特征展开研究，对指纹特征暂不做分析。</p><p>宽带接收机侦收到的雷达信号一般由信号和高斯白噪声两部分组成，其信号模型可描述为</p><p>y ( t ) = s ( t ) + n ( t ) = A e j ϕ ( t ) + n ( t ) (1)</p><p>式中， s ( t ) 表示雷达信号， n ( t ) 表示高斯白噪声。A表示信号的幅值，假设为1。 ϕ ( t ) 表示信号的瞬时相位。9种雷达信号的调制类型分别为：常规信号(Conventional Wareform, CW)、线性调频信号(Linear Frequency Modulation, LFM)、非线性调频信号(Nonlinear Frequency Modulation, NLFM)、二相编码信号(Binary Phase Shift Keying, BPSK)、多相编码信号(Multi-Phase Shift Keying, MPSK)、Costas编码信号以及LFM/BPSK、LFM/FSK和BPSK/FSK复合调制信号。</p></sec><sec id="s4_2"><title>2.2. 多重同步压缩变换(MSST)</title><p>雷达信号作为一种非平稳信号，包含丰富的时频域信息。典型的时频分析方法有：短时傅里叶变换(Short-time Fourier Transform, STFT)、小波变换(Wavelet Transform, WT)、魏格纳-威利分布(Wigner-Vill Distribution, WVD)以及Cohen类时频分布等。其中STFT属于线性变换，在实际应用中存在窗函数选择困难的缺陷；WVD属于二次型变换，在处理多分量复杂信号时不可避免地会产生交叉项干扰；而Choi-Williams分布属于Cohen类的一种，可以较好的抑制交叉项的干扰，但也无法完全消除交叉项。</p><p>MSST是一种对STFT多次执行同步压缩后处理的改进算法，由Yu Gang等人于2018年首次提出 [<xref ref-type="bibr" rid="hanspub.32297-ref18">18</xref>] ，具有较高的时频聚集性，并且不会产生交叉项干扰，较CWD具有一定优越性。</p><p>信号 的短时傅里叶变换(Short-time Fourier Transform，STFT)定义为</p><p>G ( t , w ) = ∫ − ∞ + ∞ g ( u − t ) s ( u ) e − j w ( u − t ) d u (2)</p><p>式中 g ( u ) 为窗函数。</p><p>选取信号模型为</p><p>s ( u ) = A ( u ) e j φ ( u ) (3)</p><p>其中 A ( u ) 、 φ ( u ) 分别表示信号的幅度和相位。</p><p>幅度和相位的一阶泰勒级数展开式分别为</p><p>{ A ( u ) = A ( t ) φ ( u ) = φ ( t ) + φ ′ ( t ) ( u − t ) (4)</p><p>信号 s ( u ) 可以表示为</p><p>s ( u ) = A ( t ) e j ( φ ( t ) + φ ′ ( t ) ( u − t ) ) (5)</p><p>于是，信号 s ( u ) 的短时傅里叶变换(STFT)时频谱可表示为</p><p>G ( t , w ) = ∫ − ∞ + ∞ g ( u − t ) A ( t ) e j ( φ ( t ) + φ ′ ( t ) ( u − t ) ) e − j w ( u − t ) d u = A ( t ) e j φ ( t ) ∫ − ∞ + ∞ g ( u − t ) e j ( φ ′ ( t ) ( u − t ) ) − j w ( u − t ) d ( u − t ) = A ( t ) e j φ ( t ) g ^ ( w − φ ′ ( t ) ) (6)</p><p>对上式求偏导，有</p><p>∂ t G ( t , w ) = ∂ t ( A ( t ) e j φ ( t ) g ^ ( w − φ ′ ( t ) ) ) = A ( t ) e j φ ( t ) g ^ ( w − φ ′ ( t ) ) j φ ′ ( t ) = G ( t , w ) j φ ′ ( t ) (7)</p><p>当 G ( t , w ) ≠ 0 时，瞬时频率估计 w ^ ( t , w ) 可表示为</p><p>w ^ ( t , w ) = ∂ t G ( t , w ) j G ( t , w ) (8)</p><p>再对时频谱执行同步压缩处理(Synchrosqueezing Transformation, SST)，可表示为</p><p>T s ( t , η ) = ∫ − ∞ + ∞ G ( t , w ) δ ( η − w ^ ( t , w ) ) d w (9)</p><p>通过执行SST，可以从频率方向压缩STFT的结果，进而提高时频谱的能量聚集程度。</p><p>对得到的时频谱继续执行SST，有</p><p>T s [ 2 ] ( t , η ) = ∫ − ∞ + ∞ T s [ 1 ] ( t , w ) δ ( η − w ^ ( t , w ) ) d w T s [ 3 ] ( t , η ) = ∫ − ∞ + ∞ T s [ 2 ] ( t , w ) δ ( η − w ^ ( t , w ) ) d w                                                       ⋮ T s [ N ] ( t , η ) = ∫ − ∞ + ∞ T s [ N − 1 ] ( t , w ) δ ( η − w ^ ( t , w ) ) d w (10)</p><p>图1给出了6种典型雷达信号和3种复合调制信号在信噪比为8 dB时的MSST时频图像。</p></sec><sec id="s4_3"><title>2.3. 时频图像预处理</title><p>为了减少噪声对时频图像的不利影响，以及得到满足分类器输入要求的时频图像，需要首先对原始时频图像进行预处理，具体的预处理流程如下。</p><p>Step1：将时频分布原始图像转换为灰度图像；</p><p>Step2：采用维纳自适应滤波器去除灰度图像的噪声点，对图像进行增强处理；</p><p>图1. 信噪比为8 dB时9种雷达信号的MSST时频图像</p><p>Step3：运用双三次插值法将时频图像大小调整为224 &#215; 224，使所有信号的时频图像尺寸大小保持一致并减小数据量；</p><p>Step4：最后利用最大最小值法对图像进行归一化处理。</p><p>图2是Costas信号在信噪比为0 dB下的时频图像预处理流程。经过上述图像处理以后，在最大程度地保留信号完整信息的同时基本去除了噪声和冗余信息。</p><p>图2. 时频图像预处理</p></sec></sec><sec id="s5"><title>3. 迁移深度学习</title><sec id="s5_1"><title>3.1. 典型预训练深度神经网络模型</title><sec id="s5_1_1"><title>3.1.1. GoogLeNet网络</title><p>GoogLeNet是由Google公司提出一种卷积神经网络模型，曾在2014年的ILSVRC分类任务比赛中荣获冠军。其参数数量仅为AlexNet的1/12，但精度却远远超过AlexNet。GoogLeNet的主要创新主要有两点：一是用全局平均池化层替换掉了最后的全连接层，从而减轻了过拟合并且模型训练的速度更快；二是借鉴Networkin Network (NIN)的思想设计了Inception结构，该结构能够在不显著加大计算负担的前提下，更好地利用网络中的计算资源，增加网络的深度和宽度。</p><p>一个简单的Inception结构如图3(a)所示。它由3组尺寸不同的卷积核及一个最大池化单元构成，通过并行地处理来自上一层的输入图像，然后对结果依据通道进行融合拼接。</p><p>在执行卷积运算中，假如输入图像的通道数过多，就会耗费大量的运算资源，卷积核的参数数量也会过多，此时就需要对数据进行降维处理。图3(b)为加上降维功能的Inception模块。该模块对除1 &#215; 1卷积之外的所有卷积和池化操作均使用了1 &#215; 1卷积运算进行降维，从而减少了图像的通道数。</p><p>采用了Inception的GoogLeNet模型深度共有22层，其网络结构如表1所示。</p><p>其中，“#3 &#215; 3 reduce”，“#5 &#215; 5 reduce”表示在3 &#215; 3、5 &#215; 5卷积操作前使用1 &#215; 1卷积的数量。输入图像为224 &#215; 224 &#215; 3，并且经过了零均值化的预处理操作，所有降维层都采用了ReLU非线性激活函数。</p></sec><sec id="s5_1_2"><title>3.1.2. ResNet网络</title><p>从经验来看，网络的深度对模型的性能尤为重要，更深层次的网络有助于提取更加复杂的特征，当模型更深时取得的效果也就越好。但研究表明，深度网络出现了退化问题：随着网络深度的不断增加，训练的准确率趋于饱和，甚至出现了下降趋势。为了解决该退化问题，一种称为ResNet的新型卷积神经网络模型由微软亚洲研究院何凯明团队提出，它以3.6%的错误率赢得了2015年的ILSVRC分类比赛。其主要创新是提出了残差模块(Residual Block)，有效解决了网络深度增加所引起的梯度消失和退化问题，残差模块的结构如图4所示。</p><p>图3. Inception模块</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Thestructure of GoogLeNe</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >Type</th><th align="center" valign="middle" >Patchsize/Stride</th><th align="center" valign="middle" >Outputsize</th><th align="center" valign="middle" >Depth</th><th align="center" valign="middle" >#1 &#215; 1</th><th align="center" valign="middle" >#3 &#215; 3 reduce</th><th align="center" valign="middle" >#3 &#215; 3</th><th align="center" valign="middle" >#5 &#215; 5 reduce</th><th align="center" valign="middle" >#5 &#215; 5</th><th align="center" valign="middle" >Poolproj</th><th align="center" valign="middle" >Params</th></tr></thead><tr><td align="center" valign="middle" >Input</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >224 &#215; 224 &#215; 3</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td></tr><tr><td align="center" valign="middle" >Convolution</td><td align="center" valign="middle" >7 &#215; 7/2</td><td align="center" valign="middle" >112 &#215; 112 &#215; 64</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" >2.7 K</td></tr><tr><td align="center" valign="middle" >Max pool</td><td align="center" valign="middle" >3 &#215; 3/2</td><td align="center" valign="middle" >56 &#215; 56 &#215; 64</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td></tr><tr><td align="center" valign="middle" >Convolution</td><td align="center" valign="middle" >3 &#215; 3/1</td><td align="center" valign="middle" >56 &#215; 56 &#215; 192</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >64</td><td align="center" valign="middle" >192</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" >112 K</td></tr><tr><td align="center" valign="middle" >Max pool</td><td align="center" valign="middle" >3 &#215; 3/2</td><td align="center" valign="middle" >28 &#215; 28 &#215; 192</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td></tr><tr><td align="center" valign="middle" >Inception (3a)</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >28 &#215; 28 &#215; 256</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >64</td><td align="center" valign="middle" >96</td><td align="center" valign="middle" >128</td><td align="center" valign="middle" >16</td><td align="center" valign="middle" >32</td><td align="center" valign="middle" >32</td><td align="center" valign="middle" >159 K</td></tr><tr><td align="center" valign="middle" >Inception (3b)</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >28 &#215; 28 &#215; 480</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >128</td><td align="center" valign="middle" >128</td><td align="center" valign="middle" >192</td><td align="center" valign="middle" >32</td><td align="center" valign="middle" >96</td><td align="center" valign="middle" >64</td><td align="center" valign="middle" >380 K</td></tr><tr><td align="center" valign="middle" >Max pool</td><td align="center" valign="middle" >3 &#215; 3/2</td><td align="center" valign="middle" >14 &#215; 14 &#215; 480</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td></tr><tr><td align="center" valign="middle" >Inception (4a)</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >14 &#215; 14 &#215; 512</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >192</td><td align="center" valign="middle" >96</td><td align="center" valign="middle" >208</td><td align="center" valign="middle" >16</td><td align="center" valign="middle" >48</td><td align="center" valign="middle" >64</td><td align="center" valign="middle" >364 K</td></tr><tr><td align="center" valign="middle" >Inception (4b)</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >14 &#215; 14 &#215; 512</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >160</td><td align="center" valign="middle" >112</td><td align="center" valign="middle" >224</td><td align="center" valign="middle" >24</td><td align="center" valign="middle" >64</td><td align="center" valign="middle" >64</td><td align="center" valign="middle" >437 K</td></tr><tr><td align="center" valign="middle" >Inception (4c)</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >14 &#215; 14 &#215; 512</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >128</td><td align="center" valign="middle" >128</td><td align="center" valign="middle" >256</td><td align="center" valign="middle" >24</td><td align="center" valign="middle" >64</td><td align="center" valign="middle" >64</td><td align="center" valign="middle" >463 K</td></tr><tr><td align="center" valign="middle" >Inception (4d)</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >14 &#215; 14 &#215; 528</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >112</td><td align="center" valign="middle" >114</td><td align="center" valign="middle" >288</td><td align="center" valign="middle" >32</td><td align="center" valign="middle" >64</td><td align="center" valign="middle" >64</td><td align="center" valign="middle" >580 K</td></tr><tr><td align="center" valign="middle" >Inception (4e)</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >14 &#215; 14 &#215; 832</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >256</td><td align="center" valign="middle" >160</td><td align="center" valign="middle" >320</td><td align="center" valign="middle" >32</td><td align="center" valign="middle" >128</td><td align="center" valign="middle" >128</td><td align="center" valign="middle" >840 K</td></tr><tr><td align="center" valign="middle" >Max pool</td><td align="center" valign="middle" >3 &#215; 3/2</td><td align="center" valign="middle" >7 &#215; 7 &#215; 832</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td></tr><tr><td align="center" valign="middle" >Inception (5a)</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >7 &#215; 7 &#215; 832</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >256</td><td align="center" valign="middle" >160</td><td align="center" valign="middle" >320</td><td align="center" valign="middle" >32</td><td align="center" valign="middle" >128</td><td align="center" valign="middle" >128</td><td align="center" valign="middle" >1072 K</td></tr><tr><td align="center" valign="middle" >Inception (5a)</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >7 &#215; 7 &#215; 1024</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >384</td><td align="center" valign="middle" >192</td><td align="center" valign="middle" >384</td><td align="center" valign="middle" >48</td><td align="center" valign="middle" >128</td><td align="center" valign="middle" >128</td><td align="center" valign="middle" >1388 K</td></tr><tr><td align="center" valign="middle" >Avg pool</td><td align="center" valign="middle" >7 &#215; 7/1</td><td align="center" valign="middle" >1 &#215; 1 &#215; 1024</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td></tr><tr><td align="center" valign="middle" >Dropout (40%)</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >1 &#215; 1 &#215; 1024</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td></tr><tr><td align="center" valign="middle" >Linear</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >1 &#215; 1 &#215; 1000</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" >1000 K</td></tr><tr><td align="center" valign="middle" >Softmax</td><td align="center" valign="middle" ></td><td align="center" valign="middle" >1 &#215; 1 &#215; 1000</td><td align="center" valign="middle" >0</td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td><td align="center" valign="middle" ></td></tr></tbody></table></table-wrap><p>表1. GoogLeNet网络结构</p><p>图4. 残差模块</p><p>一个残差模块可以表示为</p><p>y i = F ( x i , W i ) + h ( x i ) x i + 1 = f ( y i ) (11)</p><p>其中 x i 和 x i + 1 分别表示第i个残差块的输入和输出， F ( x , W i ) 表示学习到的残差， h ( x i ) = x i 表示恒等映射，f为ReLU激活函数。采用残差模块的ResNet网络共有5种不同的深度，其网络结构如表2所示。</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> The structure of ResNe</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >类型</th><th align="center" valign="middle" >输出维度</th><th align="center" valign="middle" >18-层</th><th align="center" valign="middle" >34-层</th><th align="center" valign="middle" >50-层</th><th align="center" valign="middle" >101-层</th><th align="center" valign="middle" >152-层</th></tr></thead><tr><td align="center" valign="middle" >conv1</td><td align="center" valign="middle" >112 &#215; 112</td><td align="center" valign="middle"  colspan="5"  >7 &#215; 7 , 64, stride 2</td></tr><tr><td align="center" valign="middle"  rowspan="2"  >Conv2_x</td><td align="center" valign="middle"  rowspan="2"  >56 &#215; 56</td><td align="center" valign="middle"  colspan="5"  >3 &#215; 3 , max pool, stride 2</td></tr><tr><td align="center" valign="middle" >[ 3 &#215; 3 , 64 3 &#215; 3 , 64 ] &#215; 2</td><td align="center" valign="middle" >[ 3 &#215; 3 , 64 3 &#215; 3 , 64 ] &#215; 3</td><td align="center" valign="middle" >[ 1 &#215; 1 , 64 3 &#215; 3 , 64 1 &#215; 1 , 256 ] &#215; 3</td><td align="center" valign="middle" >[ 1 &#215; 1 , 64 3 &#215; 3 , 64 1 &#215; 1 , 256 ] &#215; 3</td><td align="center" valign="middle" >[ 1 &#215; 1 , 64 3 &#215; 3 , 64 1 &#215; 1 , 256 ] &#215; 3</td></tr><tr><td align="center" valign="middle" >Conv3_x</td><td align="center" valign="middle" >28 &#215; 28</td><td align="center" valign="middle" >[ 3 &#215; 3 , 128 3 &#215; 3 , 128 ] &#215; 2</td><td align="center" valign="middle" >[ 3 &#215; 3 , 128 3 &#215; 3 , 128 ] &#215; 4</td><td align="center" valign="middle" >[ 1 &#215; 1 , 128 3 &#215; 3 , 128 1 &#215; 1 , 512 ] &#215; 4</td><td align="center" valign="middle" >[ 1 &#215; 1 , 128 3 &#215; 3 , 128 1 &#215; 1 , 512 ] &#215; 4</td><td align="center" valign="middle" >[ 1 &#215; 1 , 128 3 &#215; 3 , 128 1 &#215; 1 , 512 ] &#215; 8</td></tr><tr><td align="center" valign="middle" >Conv4_x</td><td align="center" valign="middle" >14 &#215; 14</td><td align="center" valign="middle" >[ 3 &#215; 3 , 256 3 &#215; 3 , 256 ] &#215; 2</td><td align="center" valign="middle" >[ 3 &#215; 3 , 256 3 &#215; 3 , 256 ] &#215; 6</td><td align="center" valign="middle" >[ 1 &#215; 1 , 256 3 &#215; 3 , 256 1 &#215; 1 , 1024 ] &#215; 6</td><td align="center" valign="middle" >[ 1 &#215; 1 , 256 3 &#215; 3 , 256 1 &#215; 1 , 1024 ] &#215; 23</td><td align="center" valign="middle" >[ 1 &#215; 1 , 256 3 &#215; 3 , 256 1 &#215; 1 , 1024 ] &#215; 36</td></tr><tr><td align="center" valign="middle" >Conv5_x</td><td align="center" valign="middle" >7 &#215; 7</td><td align="center" valign="middle" >[ 3 &#215; 3 , 512 3 &#215; 3 , 512 ] &#215; 2</td><td align="center" valign="middle" >[ 3 &#215; 3 , 512 3 &#215; 3 , 512 ] &#215; 3</td><td align="center" valign="middle" >[ 1 &#215; 1 , 512 3 &#215; 3 , 512 1 &#215; 1 , 2048 ] &#215; 3</td><td align="center" valign="middle" >[ 1 &#215; 1 , 512 3 &#215; 3 , 512 1 &#215; 1 , 2048 ] &#215; 3</td><td align="center" valign="middle" >[ 1 &#215; 1 , 512 3 &#215; 3 , 512 1 &#215; 1 , 2048 ] &#215; 3</td></tr><tr><td align="center" valign="middle" ></td><td align="center" valign="middle" >1 &#215; 1</td><td align="center" valign="middle"  colspan="5"  >average pool, 1000-d fc, softmax</td></tr><tr><td align="center" valign="middle"  colspan="2"  >FLOPs</td><td align="center" valign="middle" >1.8 &#215; 10 9</td><td align="center" valign="middle" >3.6 &#215; 10 9</td><td align="center" valign="middle" >3.8 &#215; 10 9</td><td align="center" valign="middle" >7.6 &#215; 10 9</td><td align="center" valign="middle" >11.3 &#215; 10 9</td></tr></tbody></table></table-wrap><p>表2. ResNet网络结构</p><p>其中网络的深度分别为18，34，50，101，152，它们都是先经过一个7 &#215; 7的卷积层，再连接一个最大池化操作，然后进行堆叠残差块，各网络中残差模块的数量依次为8，16，33，50。最后通常在网络的后端连接一个全局平均池化，从而有效防止过拟合，使输入输出的空间变换更具有鲁棒性。</p></sec></sec><sec id="s5_2"><title>3.2. 迁移深度学习</title><p>2005年，美国国防高级研究计划局(DARPA)信息处理技术办公室(IPTO)给迁移学习确定了一个新的定义：一个系统能够将从先前的任务中学到的知识和能力应用到新任务中解决问题。在这个定义中，迁移学习旨在从一个或多个源任务中提取知识，从而运用到目标任务 [<xref ref-type="bibr" rid="hanspub.32297-ref19">19</xref>] 。</p><p>具体的讲：给定源域 D S 和学习任务 T S ，一个目标域 D T 和学习任务 T T 。迁移学习旨在将从 D S 和 T S 中学习到的知识帮助提升 D T 中目标预测函数 f T ( . ) 的学习，其中 D S ≠ D T 或 T S ≠ T T ，多数情况下 D S 要大于 D T 的尺寸， N S ≫ N T 。</p><p>GoogLeNet和ResNet作为成熟的预训练网络，已经对超过一百万个图像进行了训练，学习到了丰富的特征，借助于迁移学习，将预训练好的成熟网络作为训练的初始值，基于它学习新的任务，通过网络微调(Fine-Tune)的方式就可以较少的训练样本快速地将已学习的特征迁移到新的任务中，从而有效解决了雷达信号样本构建难和训练耗时长的问题。</p></sec><sec id="s5_3"><title>3.3. 基于迁移深度学习的雷达信号分选识别算法流程</title><p>本文构建的基于迁移深度学习的雷达信号分选识别算法的系统结构框图如图5所示。</p><p>图5. 迁移深度学习系统结构框图</p><p>具体步骤如下：</p><p>Step1：利用MATLAB软件产生雷达信号数据集；</p><p>Step2：基于MSST得到雷达信号的时频图像矩阵，并对时频图像进行灰度化、自适应维纳滤波、双三次插值缩放、归一化等预处理操作，生成尺寸为224 &#215; 224的图像数据集；</p><p>Step3：加载预训练网络(GoogLeNet或ResNet)，利用迁移学习的方法，保持预训练网络的参数不变，替换掉最后一个可学习层和分类层，构建特征迁移模块；</p><p>Step4：通过图层复制将图像数据集转换为224 &#215; 224 &#215; 3的RGB图像，经过数据增强处理后构建样本集，其中80%用于训练，10%用于测试，10%用于验证；</p><p>Step5：将训练集和验证集送入网络进行迁移学习训练，迭代6次，得到最终训练模型TraindedNet；</p><p>Step6：利用训练后的模型TrainedNet对测试集进行识别，得到识别结果。</p></sec></sec><sec id="s6"><title>4. 仿真与分析</title><sec id="s6_1"><title>4.1. 仿真条件</title><p>本文对9种雷达信号进行分选识别，由于不同雷达信号具有不同的参数，为方便描述，采用基于采样频率 f s 的均匀分布 U ( . ) 统一表示，例如 U ( 1 / 8 , 1 / 4 ) 表示参数范围 [ f s / 8 , f s / 8 ] 在之间的随机数。详细的参数设置如表3所示，统一取采样频率 f s = 64   MHz ，脉冲宽度 T = 16   μ s 。</p><table-wrap id="table3" ><label><xref ref-type="table" rid="table3">Table 3</xref></label><caption><title> Parameter settin</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >雷达信号</th><th align="center" valign="middle" >仿真参数</th><th align="center" valign="middle" >取值范围</th></tr></thead><tr><td align="center" valign="middle" >CW</td><td align="center" valign="middle" >载波频率 f c</td><td align="center" valign="middle" >U ( 1 / 8 , 1 / 4 )</td></tr><tr><td align="center" valign="middle"  rowspan="2"  >LFM,NLFM</td><td align="center" valign="middle" >初始频率 f 0</td><td align="center" valign="middle" >U ( 1 / 16 , 1 / 8 )</td></tr><tr><td align="center" valign="middle" >带宽B</td><td align="center" valign="middle" >U ( 1 / 16 , 1 / 8 )</td></tr><tr><td align="center" valign="middle"  rowspan="2"  >BPSK</td><td align="center" valign="middle" >Barker码长度L</td><td align="center" valign="middle" >{ 5 , 7 , 11 , 13 }</td></tr><tr><td align="center" valign="middle" >载波频率 f c</td><td align="center" valign="middle" >U ( 1 / 8 , 1 / 4 )</td></tr><tr><td align="center" valign="middle"  rowspan="2"  >MPSK</td><td align="center" valign="middle" >Frank码 步进频率M</td><td align="center" valign="middle" >{ 4 , 8 }</td></tr><tr><td align="center" valign="middle" >载波频率 f c</td><td align="center" valign="middle" >U ( 1 / 8 , 1 / 4 )</td></tr><tr><td align="center" valign="middle"  rowspan="2"  >Costas</td><td align="center" valign="middle" >跳频序列</td><td align="center" valign="middle" >[ 3 , 2 , 6 , 4 , 5 , 1 ] [ 5 , 4 , 6 , 2 , 3 , 1 ] [ 2 , 4 , 8 , 5 , 10 , 9 , 7 , 3 , 6 , 1 ]</td></tr><tr><td align="center" valign="middle" >基准频率 f min</td><td align="center" valign="middle" >U ( 1 / 24 , 1 / 20 )</td></tr><tr><td align="center" valign="middle"  rowspan="3"  >LFM/BPSK</td><td align="center" valign="middle" >基准频率 f min</td><td align="center" valign="middle" >U ( 1 / 24 , 1 / 20 )</td></tr><tr><td align="center" valign="middle" >带宽</td><td align="center" valign="middle" >U ( 1 / 16 , 1 / 8 )</td></tr><tr><td align="center" valign="middle" >Barker码长L</td><td align="center" valign="middle" >{ 5 , 7 , 11 , 13 }</td></tr><tr><td align="center" valign="middle"  rowspan="2"  >LFM/4FSK</td><td align="center" valign="middle" >基准频率 f min</td><td align="center" valign="middle" >U ( 1 / 24 , 1 / 20 )</td></tr><tr><td align="center" valign="middle" >子码带宽 B c</td><td align="center" valign="middle" >U ( 1 / 20 , 1 / 10 )</td></tr><tr><td align="center" valign="middle"  rowspan="2"  >BPSK/4FSK</td><td align="center" valign="middle" >Barker码长度L</td><td align="center" valign="middle" >{ 5 , 7 , 11 , 13 }</td></tr><tr><td align="center" valign="middle" >基准频率 f min</td><td align="center" valign="middle" >U ( 1 / 24 , 1 / 20 )</td></tr></tbody></table></table-wrap><p>表3. 参数设置</p></sec><sec id="s6_2"><title>4.2. 不同信噪比识别准确率实验</title><p>考虑雷达信号受高斯白噪声的影响，信噪比取−6~+14 dB，步长为2 dB。每个信噪比下每种信号各产生100组数据，基于多重同步压缩变换(MSST)得到信号的时频图像，并经预处理后生成224 &#215; 224的灰度图像，最后转换为224 &#215; 224 &#215; 3的RGB图像(其中3是颜色通道数，可通过复制图层解决)用于构建样本集。其中80%用于训练，10%用于测试，10%用于验证。</p><p>加载新的训练样本集，分别基于GoogLeNet和ResNet重新进行训练，对部分网络参数进行微调，利用迁移学习训练后的网络模型对9种雷达信号进行分选识别，得到不同信噪比下基于两种CNN模型迁移深度学习的识别准确率结果如图6所示。</p><p>从图6仿真结果可知，两种模型下基于迁移深度学习的识别算法在信噪比大于−4 dB时，对9种雷达信号的识别准确率均达到90%以上；在信噪比大于0 dB时，9种雷达信号的识别准确率均达到了100%，证明了基于迁移深度学习实现对雷达信号自动分选识别的算法具有较高的抗噪声性能和泛化能力。</p><p>图6. 不同信噪比下9种雷达信号的识别准确率</p></sec><sec id="s6_3"><title>4.3. 抗混淆性能分析</title><p>为了进一步验证模型识别的准确性，分别基于GoogLeNet和ResNet迁移学习得到测试样本的混淆矩阵结果，如图7所示。</p><p>从混淆矩阵可以看出，ResNet模型的平均识别准确率更高，对9种雷达信号的平均识别率达到了99.51%，高于GoogLeNet模型约0.14%。结果表明经过图像预处理后得到的MSST时频图像能够较完整地反映雷达信号的有效信息，基于迁移深度学习模型自动提取的特征信息更加地精细，识别的准确性更高。</p><p>图7. 测试样本混淆矩阵</p></sec><sec id="s6_4"><title>4.4. 算法对比</title><p>为进一步分析基于迁移深度学习算法的性能，下面将本文算法与文献 [<xref ref-type="bibr" rid="hanspub.32297-ref12">12</xref>] 和 [<xref ref-type="bibr" rid="hanspub.32297-ref13">13</xref>] 算法进行比较。两种算法对9种雷达信号的识别率曲线如图8所示。</p><p>由图8可以看出，本文提出的算法整体平均识别率明显优于文献 [<xref ref-type="bibr" rid="hanspub.32297-ref12">12</xref>] 和 [<xref ref-type="bibr" rid="hanspub.32297-ref13">13</xref>] 算法。在信噪比为时−6 dB时，采用改进Cohen类分布和CNN模型的文献 [<xref ref-type="bibr" rid="hanspub.32297-ref12">12</xref>] 算法识别率为82.5%，这是由于该算法使用了过多的去噪图像预处理，损失了大量细节信息，并且所用的改进Cohen类时频分布对复合调制信号的处理能力</p><p>图8. 算法性能对比</p><p>较差；采用人工提取特征的文献 [<xref ref-type="bibr" rid="hanspub.32297-ref13">13</xref>] 算法的整体平均识别率仅能达到65.1%，这是由于该算法采用人工提取的特征容易受到噪声的影响，同时该算法未对复合调制信号进行研究；而本文基于GoogLeNet和ResNet迁移深度学习的算法在信噪比低于−6 dB时整体平均识别率仍然可以达到93.4%。在更高信噪比下，对9种雷达信号的识别率普遍优于其他两种算法。这是因为，该算法基于MSST时频分布和迁移深度学习自动挖掘的时频域高维特征表征能力更强，模型的抗噪性和泛化能力更为优秀，同时较常规的深度学习模型算法计算量更小，有助于工程上的实现。</p></sec></sec><sec id="s7"><title>5. 结论</title><p>本文提出了一种基于时频分析、深度学习和迁移学习的融合模型，并应用于雷达信号的自动分选识别中。该算法引入了多重同步压缩变换(MSST)得到信号的时频图像，然后利用灰度化、维纳滤波、双三次插值法和归一化等手段对时频图像进行预处理操作，最后基于迁移深度学习的方法，以两种预训练模型(GoogLeNet和ResNet)对时频图像样本进行重新离线训练，通过网络参数微调得到了新的融合模型，可以实现对9种雷达信号的自动识别。仿真结果表明，该算法模型简单、计算量小，在信噪比为−6 dB时，对9种雷达信号的识别率可达93.4%，具有较高的抗噪声性能和泛化能力。</p></sec><sec id="s8"><title>基金项目</title><p>国家自然科学基金资助项目(61703433)，军队科研资助项目。</p></sec><sec id="s9"><title>文章引用</title><p>王功明,陈世文,黄 洁,黄东华. 基于迁移深度学习的雷达信号分选识别 Radar Signal Sorting and Recognition Based on Transferred Deep Learning[J]. 计算机科学与应用, 2019, 09(09): 1761-1778. https://doi.org/10.12677/CSA.2019.99198</p></sec><sec id="s10"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.32297-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">毛校洁. 雷达信号脉内调制类型识别方法研究[D]: [硕士学位论文]. 哈尔滨: 哈尔滨工程大学, 2019.</mixed-citation></ref><ref id="hanspub.32297-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">周志文, 黄高明, 陈海洋, 等. 雷达辐射源识别算法综述[J]. 电讯技术, 2017, 57(8): 973-980.</mixed-citation></ref><ref id="hanspub.32297-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">曲志昱, 毛校洁, 侯长波. 基于奇异值熵和分形维数的雷达信号识别[J]. 系统工程与电子技术, 2018, 40(2): 303-307.</mixed-citation></ref><ref id="hanspub.32297-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">普运伟, 金炜东, 朱明, 等. 雷达辐射源信号模糊函数主脊切面特征提取方法[J]. 红外与毫米波学报, 2008, 27(2): 133-137.</mixed-citation></ref><ref id="hanspub.32297-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">王星, 呙鹏程, 田元荣, 等. 基于BDS-GD的低截获概率雷达信号识别[J]. 北京航空航天大学学报, 2018, 44(3): 583-592.</mixed-citation></ref><ref id="hanspub.32297-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">Dong, X., Cheng, S., Yang, J., et al. (2019) Radar Specific Emitter Recognition Based on DBN Feature Extraction. Journal of Physics: Conference Series, 1176, Article ID: 032025. &lt;br&gt;https://doi.org/10.1088/1742-6596/1176/3/032025</mixed-citation></ref><ref id="hanspub.32297-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Kong, S.-H., Kim, M., Hoang, L.M., et al. (2018) Automatic LPI Radar Waveform Recognition Using CNN. IEEE Access, 6, 4207-4219. &lt;br&gt;https://doi.org/10.1109/ACCESS.2017.2788942</mixed-citation></ref><ref id="hanspub.32297-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Wan, J., Yu, X. and Guo, Q. (2019) LPI Radar Waveform Recognition Based on CNN and TPOT. Symmetry, 11, 725.  
&lt;br&gt;https://doi.org/10.3390/sym11050725</mixed-citation></ref><ref id="hanspub.32297-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Zhou, Z., Huang, G., Chen, H., et al. (2018) Automatic Radar Waveform Recognition Based on Deep Convolutional Denoising Auto-Encoders. Circuits Systems &amp; Signal Processing, No. 5, 1-15.</mixed-citation></ref><ref id="hanspub.32297-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">张穆清, 王华力, 倪雪. 基于深度学习与支持向量机的低截获概率雷达信号识别[J]. 科技导报, 2019, 37(4): 69-75.</mixed-citation></ref><ref id="hanspub.32297-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">周东青, 王玉冰, 王星, 等. 基于深度限制波尔兹曼机的辐射源信号识别[J]. 国防科技大学学报, 2016, 38(6): 136-141.</mixed-citation></ref><ref id="hanspub.32297-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Qu, Z., Mao, X. and Deng, Z. (2018) Radar Signal Intra-Pulse Modulation Recognition Based on Convolutional Neural Network. IEEE Access, 6, 43874-43884. &lt;br&gt;https://doi.org/10.1109/ACCESS.2018.2864347</mixed-citation></ref><ref id="hanspub.32297-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Zhang, M., Diao, M., Gao, L., et al. (2017) Neural Networks for Radar Waveform Recognition. Symmetry, 9, 75.  
&lt;br&gt;https://doi.org/10.3390/sym9050075</mixed-citation></ref><ref id="hanspub.32297-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">Pan, S.J. and Yang, Q. (2010) A Survey on Transfer Learning. IEEE Transactions on Knowledge &amp; Data Engineering, 22, 1345-1359. &lt;br&gt;https://doi.org/10.1109/TKDE.2009.191</mixed-citation></ref><ref id="hanspub.32297-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">Gao, L., Zhang, X., Gao, J., et al. (2019) Fusion Image Based Radar Signal Feature Extraction and Modulation Recognition. IEEE Access, 7, 13135-13148. &lt;br&gt;https://doi.org/10.1109/ACCESS.2019.2892526</mixed-citation></ref><ref id="hanspub.32297-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">刘延姣. 雷达信号的特征信息提取与识别技术研究[D]: [硕士学位论文]. 西安: 西安电子科技大学, 2018.</mixed-citation></ref><ref id="hanspub.32297-ref17"><label>17</label><mixed-citation publication-type="other" xlink:type="simple">王爽. 基于时频分析和模糊函数的LPI雷达波形识别算法研究[D]: [硕士学位论文]. 哈尔滨: 哈尔滨工程大学, 2019.</mixed-citation></ref><ref id="hanspub.32297-ref18"><label>18</label><mixed-citation publication-type="other" xlink:type="simple">Yu, G., Wang, Z. and Zhao, P. (2019) Multisynchrosqueezing Transform. IEEE Transactions on Industrial Electronics, 66, 5441-5455. &lt;br&gt;https://doi.org/10.1109/TIE.2018.2868296</mixed-citation></ref><ref id="hanspub.32297-ref19"><label>19</label><mixed-citation publication-type="other" xlink:type="simple">Tan, C., Sun, F., Kong, T., et al. (2018) A Survey on Deep Transfer Learning. 27th International Conference on Artificial Neural Networks, Rhodes, 4-7 October 2018, 270-279. &lt;br&gt;https://doi.org/10.1007/978-3-030-01424-7_27</mixed-citation></ref></ref-list></back></article>