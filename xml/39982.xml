<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2021.111013</article-id><article-id pub-id-type="publisher-id">CSA-39982</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20210100000_57521207.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  序决策系统下近似约简的启发式算法
  Heuristic Algorithm to Attribute Reduction for Lower Approximation Preservation in Ordered Decision Systems
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>孙</surname><given-names>祖文</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>唐</surname><given-names>玉凯</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>烟台大学计算机与控制工程学院，山东 烟台</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>08</day><month>01</month><year>2021</year></pub-date><volume>11</volume><issue>01</issue><fpage>113</fpage><lpage>120</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   随着网络的进步，社会中产生了大量的高维数据，但很多统计方法难以直接应用到高维数据上。如何获得去噪简化且保存关键信息的低维度数据是一项急需解决的问题。粗糙集理论提供了一种数据降维的方法，被称为属性约简。属性约简的目标是保证原数据集的一种分类特征不变，获得其最小的属性子集。目前，基于不同的分类特征，已提出了许多不同的属性约简算法，如下近似保持、分布保持等。在序决策系统中，传统的下近似约简算法是基于差别矩阵的，计算复杂度高。为了解决这一问题，本文使用依赖度，设计了一个后向贪婪的启发式算法来计算下近似约简。实验使用6组UCI数据集。实验结果表明本文设计的算法可以得到正确的下近似约简，并在时间效率上优于传统的差别矩阵算法。 With the development of network, a large number of high-dimensional data are generated in the society, but many statistical methods are difficult to be directly applied to high-dimensional data. How to obtain the denoising simplified data with low dimensions and key information is an urgent problem. Rough set theory provides a method for reducing data dimensions, called attribute reduction. The purpose of attribute reduction is to obtain a minimal subset of attributes without changing a classification property of the original data. Until now, different attribute reduction methods are proposed for different classification properties, such as lower approximation preservation and distribution preservation. In an ordered decision system, the traditional attribute reduction algorithm is based on discernibility matrices, and the computation complexity is high. To solve this problem, we design a backward greedy heuristic algorithm to compute a reduct for lower approximation preservation. The experiments are conducted in six UCI data sets. The experimental results show that the algorithm gets a correct reduct and is better than the traditional discernibility matrix algorithm in time efficiency. 
  
 
</p></abstract><kwd-group><kwd>属性约简，启发式算法，粗糙集，序决策系统, Attribute Reduction</kwd><kwd> Heuristic Algorithm</kwd><kwd> Rough Set Theory</kwd><kwd> Ordered Decision Systems</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>摘要</title><p>随着网络的进步，社会中产生了大量的高维数据，但很多统计方法难以直接应用到高维数据上。如何获得去噪简化且保存关键信息的低维度数据是一项急需解决的问题。粗糙集理论提供了一种数据降维的方法，被称为属性约简。属性约简的目标是保证原数据集的一种分类特征不变，获得其最小的属性子集。目前，基于不同的分类特征，已提出了许多不同的属性约简算法，如下近似保持、分布保持等。在序决策系统中，传统的下近似约简算法是基于差别矩阵的，计算复杂度高。为了解决这一问题，本文使用依赖度，设计了一个后向贪婪的启发式算法来计算下近似约简。实验使用6组UCI数据集。实验结果表明本文设计的算法可以得到正确的下近似约简，并在时间效率上优于传统的差别矩阵算法。</p></sec><sec id="s2"><title>关键词</title><p>属性约简，启发式算法，粗糙集，序决策系统</p></sec><sec id="s3"><title>Heuristic Algorithm to Attribute Reduction for Lower Approximation Preservation in Ordered Decision Systems<sup> </sup></title><p>Zuwen Sun, Yukai Tang</p><p>School of Computer and Control Engineering, Yantai University, Yantai Shandong</p><p><img src="//html.hanspub.org/file/13-1541992x4_hanspub.png" /></p><p>Received: Dec. 25<sup>th</sup>, 2020; accepted: Jan. 19<sup>th</sup>, 2021; published: Jan. 26<sup>th</sup>, 2021</p><p><img src="//html.hanspub.org/file/13-1541992x5_hanspub.png" /></p></sec><sec id="s4"><title>ABSTRACT</title><p>With the development of network, a large number of high-dimensional data are generated in the society, but many statistical methods are difficult to be directly applied to high-dimensional data. How to obtain the denoising simplified data with low dimensions and key information is an urgent problem. Rough set theory provides a method for reducing data dimensions, called attribute reduction. The purpose of attribute reduction is to obtain a minimal subset of attributes without changing a classification property of the original data. Until now, different attribute reduction methods are proposed for different classification properties, such as lower approximation preservation and distribution preservation. In an ordered decision system, the traditional attribute reduction algorithm is based on discernibility matrices, and the computation complexity is high. To solve this problem, we design a backward greedy heuristic algorithm to compute a reduct for lower approximation preservation. The experiments are conducted in six UCI data sets. The experimental results show that the algorithm gets a correct reduct and is better than the traditional discernibility matrix algorithm in time efficiency.</p><p>Keywords:Attribute Reduction, Heuristic Algorithm, Rough Set Theory, Ordered Decision Systems</p><disp-formula id="hanspub.39982-formula9"><graphic xlink:href="//html.hanspub.org/file/13-1541992x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2021 by author(s) and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY 4.0).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/13-1541992x7_hanspub.png" /> <img src="//html.hanspub.org/file/13-1541992x8_hanspub.png" /></p></sec><sec id="s5"><title>1. 引言</title><p>粗糙集理论 [<xref ref-type="bibr" rid="hanspub.39982-ref1">1</xref>] 是Pawlak提出的处理模糊数据分类的有效方法，已被使用在数据挖掘 [<xref ref-type="bibr" rid="hanspub.39982-ref2">2</xref>] [<xref ref-type="bibr" rid="hanspub.39982-ref3">3</xref>]、数据分析 [<xref ref-type="bibr" rid="hanspub.39982-ref4">4</xref>] 和机器学习 [<xref ref-type="bibr" rid="hanspub.39982-ref5">5</xref>] 等领域。属性约简 [<xref ref-type="bibr" rid="hanspub.39982-ref6">6</xref>] [<xref ref-type="bibr" rid="hanspub.39982-ref7">7</xref>] [<xref ref-type="bibr" rid="hanspub.39982-ref8">8</xref>] 是粗糙集理论中的一种数据降维方法。属性约简可以保证原数据集的一种分类特征不变，然后获得最小的特征子集。Pawlak粗糙集使用等价关系来划分样本，但在现实生活中，样本往往需要使用序关系来进行描述，例如学生的成绩、产品的市场占有率等。序决策系统是经典决策系统的一种拓展。在序决策系统中，属性的值域是有序的，在样本间能建立偏序(优势)关系。为了从序决策系统中提取有效信息，Greco等 [<xref ref-type="bibr" rid="hanspub.39982-ref9">9</xref>] 提出了优势粗糙集方法(Dominance-based rough set approach, DRSA)。</p><p>如今，对于DRSA的研究已经较为深入。对于序决策系统中不同的分类特征，专家学者们设计了许多不同的属性约简算法。Yuan等 [<xref ref-type="bibr" rid="hanspub.39982-ref10">10</xref>] 提出了上近似保持约简和广义决策保持约简的算法，并证明了两种算法结果的等价性。Xu等 [<xref ref-type="bibr" rid="hanspub.39982-ref11">11</xref>] 提出了下近似保持约简算法。Qian等 [<xref ref-type="bibr" rid="hanspub.39982-ref12">12</xref>] [<xref ref-type="bibr" rid="hanspub.39982-ref13">13</xref>] 将DRSA应用于集值数据和区间值数据，提出了优势关系保持的约简算法。</p><p>以上提及的算法是基于差别矩阵 [<xref ref-type="bibr" rid="hanspub.39982-ref14">14</xref>]、利用布尔运算法则来进行计算的。尽管这种方法能够得到所有的约简结果，但计算的时间复杂度高。为了提升属性约简的效率，专家学者们在序决策系统中研究设计了启发式算法 [<xref ref-type="bibr" rid="hanspub.39982-ref15">15</xref>] [<xref ref-type="bibr" rid="hanspub.39982-ref16">16</xref>] [<xref ref-type="bibr" rid="hanspub.39982-ref17">17</xref>]。启发式算法能够根据不同的分类特征得到一个约简结果，计算效率高。本文基于后向贪婪策略，在序决策系统中提出了下近似约简的启发式算法。实验表明，本文所提的算法能计算出一个正确的下近似约简，且在时间效率上优于Xu等 [<xref ref-type="bibr" rid="hanspub.39982-ref11">11</xref>] 提出的差别矩阵算法。</p></sec><sec id="s6"><title>2. 基本概念</title><p>给定一个序决策系统 S = ( O , A = M ∪ N ) ，O是样本集合，也被称为论域。A是属性集合，其中M是条件属性集合，N是决策属性集合。对于 ∀ a ∈ A ， ∀ x ∈ O ， a ( x ) 表示样本x在某个属性a下的取值。表1为一个序信息系统，论域 O = { x 1 , x 2 , x 3 , x 4 } ，条件属性集 M = { a , b , c } ，决策属性集 N = { d } 。</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> An ordered decision syste</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >O</th><th align="center" valign="middle" >a</th><th align="center" valign="middle" >b</th><th align="center" valign="middle" >c</th><th align="center" valign="middle" >d</th></tr></thead><tr><td align="center" valign="middle" >x<sub>1</sub></td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >1</td></tr><tr><td align="center" valign="middle" >x<sub>2</sub></td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >2</td></tr><tr><td align="center" valign="middle" >x<sub>3</sub></td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >3</td><td align="center" valign="middle" >2</td><td align="center" valign="middle" >2</td></tr><tr><td align="center" valign="middle" >x<sub>4</sub></td><td align="center" valign="middle" >1</td><td align="center" valign="middle" >4</td><td align="center" valign="middle" >5</td><td align="center" valign="middle" >3</td></tr></tbody></table></table-wrap><p>表1. 序决策系统</p><p>定义1 [<xref ref-type="bibr" rid="hanspub.39982-ref9">9</xref>] 给定一个序信息系统 S = ( O , A = M ∪ N ) ，对于 B ⊆ A ，记</p><p>R B ≥ = { ( x , y ) ∈ O &#215; O | ∀ a ∈ B , a ( x ) ≥ a ( y ) } .</p><p>则 R B ≥ 为属性集B下的优势关系。 ( x , y ) ∈ R B ≥ 表示x在属性集B下优于y，且 R B ≥ = ∩ a ∈ B R a ≥ 。</p><p>优势关系是一个自反、传递、反对称的偏序关系，由优势关系可以导出论域上的一个覆盖。对于 B ⊆ M ， [ x ] B ≥ = { y ∈ O | ( y , x ) ∈ R B ≥ } 和 [ x ] B ≤ = { y ∈ O | ( x , y ) ∈ R B ≥ } 为样本x关于属性集B的条件优势类和条件劣势类。对于决策属性集N， [ x ] N ≥ = { y ∈ O | ( y , x ) ∈ R N ≥ } ，称 [ x ] N ≥ 为样本x关于优势关系 R N ≥ 的决策优势类，关于 R N ≥ 的决策优势类的全体记为 O / R N ≥ = { N 1 , N 2 , ⋯ , N t } = { [ x ] N ≥ | x ∈ O } 。</p><p>定义2 [<xref ref-type="bibr" rid="hanspub.39982-ref9">9</xref>] 给定一个序决策系统 S = ( O , A = M ∪ N ) ，对于 B ⊆ M ， N i ∈ O / R N ≥ ，记</p><p>R B ≥ _ ( N i ) = { x ∈ O | [ x ] B ≥ ⊆ N i } ;</p><p>R B ≥ &#175; ( N i ) = { x ∈ O | [ x ] B ≤ ∩ N i ≠ ∅ } ,</p><p>R B ≥ _ ( N i ) 和 R B ≥ &#175; ( N i ) 分别为 N i 关于属性集B的下近似和上近似。</p></sec><sec id="s7"><title>3. 下近似保持约简以及差别矩阵算法</title><p>在下近似集合中，每一个样本对应着数据集中的一条确定性规则，保证约简前后下近似不变，即保证了确定性规则不变。Xu等 [<xref ref-type="bibr" rid="hanspub.39982-ref11">11</xref>] 在序决策系统S中定义了下近似约简。</p><p>定义3 [<xref ref-type="bibr" rid="hanspub.39982-ref11">11</xref>] 给定一个序决策系统 S = ( O , A = M ∪ N ) ，对于 B ⊆ M ， O / R N ≥ = { N 1 , N 2 , ⋯ , N t } ，B是序决策系统S的一个下近似约简需满足以下两点：</p><p>1) ∀ N i ∈ O / R N ≥ , R B ≥ _ ( N i ) = R M ≥ _ ( N i ) ，</p><p>2) ∀ P ⊂ B , ∃ N i ∈ O / R N ≥ , R P ≥ _ ( N i ) ≠ R B ≥ _ ( N i ) 。</p><p>条件1)保证了约简前后S的下近似保持不变，条件2)则保证获得的约简B是能够满足1)的最小属性子集。为了计算下近似约简，Xu等 [<xref ref-type="bibr" rid="hanspub.39982-ref11">11</xref>] 设计了一个差别矩阵算法，如表2所示。</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> A discernibility matrix algorithm for lower approximation preservation (DMALA) [11</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >输入：序决策系统 S = ( O , A = M ∪ N ) 。 输出：S的所有下近似约简。</th></tr></thead><tr><td align="center" valign="middle" >1.在条件属性集M下，计算每个样本的条件优势类 [ x ] M ≥ 。 2.对 O / R N ≥ 的每一个 N i 计算下近似 R M ≥ _ ( N i ) 。 3.构造差别矩阵。 4.根据差别矩阵得到差别函数。 5.使用分配律和吸收律对差别函数进行范式转换，将其变为极小析取式。 6.输出极小析取式中的合取项，每一个合取项就是一个下近似约简。</td></tr></tbody></table></table-wrap><p>表2. 基于下近似保持的差别矩阵算法 [<xref ref-type="bibr" rid="hanspub.39982-ref11">11</xref>]</p></sec><sec id="s8"><title>4. 基于依赖度的启发式算法</title><p>上一节介绍的差别矩阵算法是基于范式转换来计算约简的。研究已表明，范式的转换是一个NP-Hard问题，因此Xu等 [<xref ref-type="bibr" rid="hanspub.39982-ref11">11</xref>] 设计的差别矩阵算法计算复杂度高，难以应用在多样本的高维数据集上。为了提升计算效率，本节基于依赖度，提出了一个下近似约简的启发式算法。</p><p>定义4 [<xref ref-type="bibr" rid="hanspub.39982-ref18">18</xref>] 给定一个序决策系统 S = ( O , A = M ∪ N ) ，对于 B ⊆ M ， O / R N ≥ = { N 1 , N 2 , ⋯ , N t } ，记</p><p>γ B ≥ = 1 | O | ∑ i = 1 t | R B ≥ _ ( N i ) | ,</p><p>则 γ B ≥ 为属性集B关于决策属性N的依赖度，其中 |   ⋅   | 表示集合中元素的个数。</p><p>基于依赖度，给出下近似约简的等价定义如下。</p><p>定义5 [<xref ref-type="bibr" rid="hanspub.39982-ref18">18</xref>] 给定一个序决策系统 S = ( O , A = M ∪ N ) ，对于 B ⊆ M ，B是序决策系统S的一个下近似约简需满足以下两点：</p><p>1) γ B ≥ = γ M ≥ ，</p><p>2) ∀ P ⊂ B , γ P ≥ ≠ γ B ≥ 。</p><p>基于定义5，本文将依赖度作为搜索条件，设计了一个后向贪婪的算法，在每次迭代过程中逐步搜索删除冗余属性。算法具体步骤如表3所示。</p><table-wrap id="table3" ><label><xref ref-type="table" rid="table3">Table 3</xref></label><caption><title> A backward greedy algorithm for lower approximation preservation (BGALA</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >输入：序决策系统 S = ( O , A = M ∪ N ) 。 输出：S的下近似约简B。</th></tr></thead><tr><td align="center" valign="middle" >1.在条件属性集M下，对 O / R N ≥ 的每一个 N i 计算下近似 R M ≥ _ ( N i ) 。 2.计算 γ M ≥ 。 3.令 B ← M 。 4.对M中的每个条件属性a，重复： 计算 γ B − { a } ≥ ； 若 γ B − { a } ≥ = γ B ≥ ，那么 B = B − { a } 。 5.输出B。</td></tr></tbody></table></table-wrap><p>表3. 基于下近似保持的后向贪婪算法</p><p>令m表示样本个数，n表示条件属性数目。算法BGALA第1步和第2步是为了计算原始属性集的依赖度，时间复杂度为 O ( m 2 n 2 ) 。第4步是一个迭代的过程，在每次迭代中删除一个对依赖度无影响(冗余)的属性，其时间复杂度为 O ( m 3 n 2 ) 。当所有冗余属性被删除，输出约简结果B。算法的整体时间复杂度是 O ( m 3 n 2 ) 。</p></sec><sec id="s9"><title>5. 实验分析</title><p>本节通过实验对比Xu等 [<xref ref-type="bibr" rid="hanspub.39982-ref11">11</xref>] 的算法DMALA和本文所提算法BGALA。实验对比主要有两个方面。首先对比两种算法(DMALA, BGALA)的约简结果，验证BGALA可以获得和DMALA相同的约简。然后对DMALA和BGALA的运行效率进行对比。本节实验所用的硬件配置为：Windows 10 64位操作系统，Inter(R) Core(TM) i5-8400处理器，16G运行内存。实验使用的编程语言为Python3.6.5，编译器为Pycharm Community Edition 2018.3.6。实验使用的6组UCI数据集如表4所示。</p><table-wrap-group id="4"><label><xref ref-type="table" rid="table4">Table 4</xref></label><caption><title> Data sets descriptio</title></caption><table-wrap id="4_1"><table><tbody><thead><tr><th align="center" valign="middle" >序号</th><th align="center" valign="middle" >数据集</th><th align="center" valign="middle" >样本数</th><th align="center" valign="middle" >属性数</th></tr></thead><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" >Absenteeism at work</td><td align="center" valign="middle" >740</td><td align="center" valign="middle" >19</td></tr></tbody></table></table-wrap><table-wrap id="4_2"><table><tbody><thead><tr><th align="center" valign="middle" >2</th><th align="center" valign="middle" >Chronic kidney disease</th><th align="center" valign="middle" >400</th><th align="center" valign="middle" >24</th></tr></thead><tr><td align="center" valign="middle" >3</td><td align="center" valign="middle" >Dermatology</td><td align="center" valign="middle" >366</td><td align="center" valign="middle" >34</td></tr><tr><td align="center" valign="middle" >4</td><td align="center" valign="middle" >Flags</td><td align="center" valign="middle" >194</td><td align="center" valign="middle" >28</td></tr><tr><td align="center" valign="middle" >5</td><td align="center" valign="middle" >Lymphography</td><td align="center" valign="middle" >148</td><td align="center" valign="middle" >18</td></tr><tr><td align="center" valign="middle" >6</td><td align="center" valign="middle" >Stalog (vehicle)</td><td align="center" valign="middle" >846</td><td align="center" valign="middle" >18</td></tr></tbody></table></table-wrap></table-wrap-group><p>表4. 数据集描述</p><sec id="s9_1"><title>5.1. 约简结果对比</title><p>表5为DMALA和BGALA两种算法的约简结果对比。属性按照从左到右的顺序使用从1开始的正整数来命名。从表中可以看出，DMALA可以得到多个下近似约简，BGALA只能得到一个下近似约简。而且，在DMALA计算出的所有下近似约简中，有一个约简和BGALA计算出的约简是相同的。这个实验结果说明BGALA的计算结果是DMALA的计算结果之一，是一个正确的下近似约简。</p><table-wrap id="table5" ><label><xref ref-type="table" rid="table5">Table 5</xref></label><caption><title> The comparison of the reduction result</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >序号</th><th align="center" valign="middle" >数据集</th><th align="center" valign="middle" >DMALA</th><th align="center" valign="middle" >BGALA</th></tr></thead><tr><td align="center" valign="middle" >1</td><td align="center" valign="middle" >Absenteeism at work</td><td align="center" valign="middle" >{1,2,3,4,5,6,7,11,12,13,14,15,16,17,19} {1,2,3,5,6,7,11,13,14,15,16,17,18,19}</td><td align="center" valign="middle" >{1,2,3,5,6,7,11,13,14,15,16,17,18,19}</td></tr><tr><td align="center" valign="middle" >2</td><td align="center" valign="middle" >Chronic kidney disease</td><td align="center" valign="middle" >{1,2,3,7,9,10,13,14,15,17} {1,3,5,7,8,10,11,14,15,16,18,24}</td><td align="center" valign="middle" >{1,3,5,7,8,10,11,14,15,16,18,24}</td></tr><tr><td align="center" valign="middle" >3</td><td align="center" valign="middle" >Dermatology</td><td align="center" valign="middle" >{3,5,6,9,10,12,16,18,19,20,21,23, 24,26,31,33,34}</td><td align="center" valign="middle" >{3,5,6,9,10,12,16,18,19,20,21,23, 24,26,31,33,34}</td></tr><tr><td align="center" valign="middle" >4</td><td align="center" valign="middle" >Flags</td><td align="center" valign="middle" >{1,2,3,4,5,6,7,8,12,13,15,16,17,19,21, 22,23,24,25,27,28} {1,2,3,4,5,6,7,8,11,12,13,15,16,17,18, 19,21,22,24,25,27} {1,2,3,4,5,6,7,8,11,12,13,15,16,17,19, 21,22,23,24,25,27} {1,2,3,4,5,6,7,8,12,13,15,16,17,18,19, 21,22,24,25,27,28}</td><td align="center" valign="middle" >{1,2,3,4,5,6,7,8,12,13,15,16,17,19,21, 22,23,24,25,27,28}</td></tr><tr><td align="center" valign="middle" >5</td><td align="center" valign="middle" >Lymphography</td><td align="center" valign="middle" >{1,2,3,4,5,6,7,8,11,12,13,14,16,17,18} {2,3,4,5,6,7,8,10,11,12,13,14,16,17,18}</td><td align="center" valign="middle" >{2,3,4,5,6,7,8,10,11,12,13,14,16,17,18}</td></tr><tr><td align="center" valign="middle" >6</td><td align="center" valign="middle" >Stalog(vehicle)</td><td align="center" valign="middle" >{1,4,5,6,7,8,9,10,12,14,16,17} {1,4,5,6,7,8,9,10,11,13,14,16,17}</td><td align="center" valign="middle" >{1,4,5,6,7,8,9,10,12,14,16,17}</td></tr></tbody></table></table-wrap><p>表5. 约简结果对比</p></sec><sec id="s9_2"><title>5.2. 时间效率对比</title><p>图1~6展示了DMALA、BGALA在6组数据集上的效率对比。其中横轴代表属性的个数，纵轴代表运行时间。从图中可以看出，随着属性数的增加，BGALA的运行时间曲线较为平稳，而DMALA的运行时间曲线则波动较大。属性数目较少时，BGALA的运行时间略长于DMALA的运行时间，但当属性数目较大时，BGALA的运行时间要远远短于DMALA的运行时间。这个实验结果表明，在处理高维数据时，BGALA的时间性能要优于DMALA。</p></sec></sec><sec id="s10"><title>6. 总结</title><p>在序决策系统中，下近似约简的差别矩阵算法时间复杂高，不利于应用在高维数据当中。本文通过引入依赖度的概念，设计了一个后向贪婪的启发式算法来获得下近似约简。实验证明本文所提的算法能计算出一个正确的约简，并在时间性能上优于传统的差别矩阵算法。下一步将继续研究其它约简目标的启发式算法。</p><p>图1. Absenteeism at work</p><p>图2. Chronic kidney disease</p><p>图3. Dermatology</p><p>图4. Flags</p><p>图5. Lymphography</p><p>图6. Stalog (vehicle)</p></sec><sec id="s11"><title>基金项目</title><p>烟台大学研究生科技创新基金(YDYB2023)资助。</p></sec><sec id="s12"><title>文章引用</title><p>孙祖文,唐玉凯. 序决策系统下近似约简的启发式算法Heuristic Algorithm to Attribute Reduction for Lower Approximation Preservation in Ordered Decision Systems[J]. 计算机科学与应用, 2021, 11(01): 113-120. https://doi.org/10.12677/CSA.2021.111013</p></sec><sec id="s13"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.39982-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Pawlak, Z. (1982) Rough Sets. International Journal of Computer &amp; Information Sciences, 11, 341-356. 
&lt;br&gt;https://doi.org/10.1007/BF01001956</mixed-citation></ref><ref id="hanspub.39982-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Zhang, J.B., Li, T.R., Ruan, D. and Liu, D. (2012) Neighborhood Rough Sets for Dynamic Data Mining. International Journal of Intelligent Systems, 27, 317-342. &lt;br&gt;https://doi.org/10.1002/int.21523</mixed-citation></ref><ref id="hanspub.39982-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Huang, H., Meng, F.Z., Zhou, S.H., Jiang, F. and Manogaran, G. (2019) Brain Image Segmentation Based on FCM Clustering Algorithm and Rough Set. IEEE Access, 7, 12386-12396. 
&lt;br&gt;https://doi.org/10.1109/ACCESS.2019.2893063</mixed-citation></ref><ref id="hanspub.39982-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Sai, Y., Yao, Y.Y. and Zhong, N. (2001) Data Analysis and Mining in Ordered Information Tables. 2001 IEEE International Conference of Data Mining, San Jose, 29 November-2 December 2001, 497-504.  
&lt;br&gt;https://doi.org/10.1109/ICDM.2001.989557</mixed-citation></ref><ref id="hanspub.39982-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Swiniarski, R.W. and Skowron, A. (2003) Rough Set Method in Feature Selection and Recognition. Pattern Recognition Letters, 24, 833-849. &lt;br&gt;https://doi.org/10.1016/S0167-8655(02)00196-4</mixed-citation></ref><ref id="hanspub.39982-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">唐玉凯, 张楠, 童向荣, 张小峰. 不完备决策系统下的多特定类广义决策约简[J]. 智能系统学报, 2019, 14(6): 1199-1208. http://dx.doi.org/10.11992/tis.201905059</mixed-citation></ref><ref id="hanspub.39982-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">许鑫. 连续值信息系统的不确定性度量[J]. 计算机科学与应用, 2017, 7(4): 388-397. 
&lt;br&gt;https://doi.org/10.12677/CSA.2017.74047</mixed-citation></ref><ref id="hanspub.39982-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">苗夺谦, 胡桂荣. 知识约简的一种启发式算法[J]. 计算机研究与发展, 1999, 36(6): 681-684.</mixed-citation></ref><ref id="hanspub.39982-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Greco, S., Matarazzo, B. and Slowinski, R. (1998) A New Rough Set Approach to Multicriteria and Multiattribute Classification. 1998 International Conference on Rough Sets and Current Trends in Computing, Warsaw, 22-26 June 1998, 60-67. &lt;br&gt;https://doi.org/10.1007/3-540-69115-4_9</mixed-citation></ref><ref id="hanspub.39982-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">袁修久, 何华灿. 优势关系下广义决策约简和上近似约简[J]. 计算机工程与应用, 2006, 42(5): 4-7. 
http://dx.chinadoi.cn/10.3321/j.issn:1002-8331.2006.05.002</mixed-citation></ref><ref id="hanspub.39982-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">徐伟华, 张晓燕, 张文修. 优势关系下不协调目标信息系统的下近似约简[J]. 计算机工程与应用, 2009, 45(16): 66-69, 76. http://dx.chinadoi.cn/10.3778/j.issn.1002-8331.2009.16.018</mixed-citation></ref><ref id="hanspub.39982-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Qian, Y.H., Dang C.Y., Liang, J.Y. and Tang, D.W. (2009) Set-Valued Ordered Information Systems. Information Sciences, 179, 2809-2832. &lt;br&gt;https://doi.org/10.1016/j.ins.2009.04.007</mixed-citation></ref><ref id="hanspub.39982-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Qian, Y.H., Liang, J.Y. and Dang C.Y. (2008) Interval Ordered In-formation Systems. Computers &amp; Mathematics with Applications, 56, 1994-2009. &lt;br&gt;https://doi.org/10.1016/j.camwa.2008.04.021</mixed-citation></ref><ref id="hanspub.39982-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">Skowron, A. and Rauszer, C. (1992) The Discernibility Matri-ces and Functions in Information Systems. In: Słowiński, R., Ed., Intelligent Decision Support, Springer, Dordrecht, 331-362. &lt;br&gt;https://doi.org/10.1007/978-94-015-7975-9_21</mixed-citation></ref><ref id="hanspub.39982-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">Hu, Q.H., Yu, D.R. and Guo, M.Z. (2010) Fuzzy Preference Based Rough Sets. Information Sciences, 180, 2003-2022. 
&lt;br&gt;https://doi.org/10.1016/j.ins.2010.01.015</mixed-citation></ref><ref id="hanspub.39982-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">Du, W.S. and Hu, B.Q. (2018) A Fast Heuristic Attribute Reduction Approach to Ordered Decision Systems. European Journal of Operational Research, 264, 440-452. &lt;br&gt;https://doi.org/10.1016/j.ejor.2017.03.029</mixed-citation></ref><ref id="hanspub.39982-ref17"><label>17</label><mixed-citation publication-type="other" xlink:type="simple">赵立威, 张楠, 张中喜. 基于特征粒的序决策系统快速约简研究[J]. 山西大学学报(自然科学版), 2020, 43(4): 897-905.</mixed-citation></ref><ref id="hanspub.39982-ref18"><label>18</label><mixed-citation publication-type="other" xlink:type="simple">Du, W.S. and Hu, B.Q. (2014) Approximate Distri-bution Reducts in Inconsistent Interval-Valued Information Systems. Information Sciences, 271, 93-114. &lt;br&gt;https://doi.org/10.1016/j.ins.2014.02.070</mixed-citation></ref></ref-list></back></article>