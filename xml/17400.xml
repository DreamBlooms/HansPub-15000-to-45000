<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2016.64027</article-id><article-id pub-id-type="publisher-id">CSA-17400</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20160400000_31245946.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  融合Gabor纹理特征的观测场彩色图像均值偏移分割方法研究
  A Method of Meteorological Observation Field Color Image Segmentation Using Mean Shift Combined with Gabor Texture Feature
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>王</surname><given-names>瑾</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>张</surname><given-names>国英</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>中国矿业大学(北京)机电与信息工程学院，北京</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>22</day><month>04</month><year>2016</year></pub-date><volume>06</volume><issue>04</issue><fpage>216</fpage><lpage>222</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
  针对传统分割方法处理具有复杂性、多样性的室外彩色图像存在明显不足，本文提出一种融合Gabor纹理特征的室外彩色图像均值偏移分割方法。首先，采用Gabor滤波器组对图像进行纹理特征提取，将特征进行多方向融合降低特征维度。然后将纹理特征与图像像素的位置、颜色特征融合到均值偏移分割算法中，实现图像的区域分割。对比分水岭分割、传统均值偏移分割方法等，本方法能有效的控制过分割和欠分割的产生，能得到较好的分割效果。
   Due to shortage of traditional image segmentation methods dealing with complex and diverse outdoor color image, this paper puts forward to a Mean Shift segmentation method combined with Gabor texture feature. First of all, the paper extracts texture feature using Gabor filter and reduces the feature dimension by fusing multiple direction features. Then, mean space distance, color dis-tance and texture distance are calculated for region segmentation in images using Mean Shift clustering algorithm. Compared to watershed segmentation and classical Mean Shift clustering algorithm, this method can effectively control the generation of over-segmentation and owe seg-mentation and can get better segmentation effect.
 
</p></abstract><kwd-group><kwd>彩色图像分割，均值偏移，Gabor纹理特征提取, Color Image Segmentation</kwd><kwd> Mean Shift</kwd><kwd> Gabor Texture Feature Extraction</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>融合Gabor纹理特征的观测场彩色图像均值偏移分割方法研究<sup> </sup></title><p>王瑾，张国英</p><p>中国矿业大学(北京)机电与信息工程学院，北京</p><disp-formula id="hanspub.17400-formula96"><graphic xlink:href="http://html.hanspub.org/file/2-1540571x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>收稿日期：2016年3月28日；录用日期：2016年4月18日；发布日期：2016年4月22日</p><disp-formula id="hanspub.17400-formula97"><graphic xlink:href="http://html.hanspub.org/file/2-1540571x7_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>针对传统分割方法处理具有复杂性、多样性的室外彩色图像存在明显不足，本文提出一种融合Gabor纹理特征的室外彩色图像均值偏移分割方法。首先，采用Gabor滤波器组对图像进行纹理特征提取，将特征进行多方向融合降低特征维度。然后将纹理特征与图像像素的位置、颜色特征融合到均值偏移分割算法中，实现图像的区域分割。对比分水岭分割、传统均值偏移分割方法等，本方法能有效的控制过分割和欠分割的产生，能得到较好的分割效果。</p><p>关键词 :彩色图像分割，均值偏移，Gabor纹理特征提取</p><disp-formula id="hanspub.17400-formula98"><graphic xlink:href="http://html.hanspub.org/file/2-1540571x8_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s3"><title>1. 引言</title><p>彩色图像分割是目前数字图像处理的一个重要研究方向，作为目标检测的基础将图像根据同性特征进行分割，过细的分割会增加检测的难度和复杂度，过粗的分割会导致错误的检测结果。常用的彩色图像分割方法主要分为基于边缘、基于区域、和基于像素的分割。基于边缘分割方法使用边缘检测算子求梯度等方法获得图像边缘，将边缘连接起来构成闭合边界，该方法对灰度平滑的对象可以获得较为精确的边界，但对图像纹理边界检测效果较差，不易获得完整的边界。基于区域的分割方法主要有区域生长、区域分裂与合并以及分水岭分割等，其中区域生长和区域分裂与合并依赖于种子点位置的选取以及合并的终止条件难以针对不同尺度区域进行自动化分割，分水岭分割算法受制于噪声和梯度的局部不规则形，易导致欠分割或过分割。基于像素分割方法主要有k均值等特征聚类分割方法，k均值分割结果完全依赖于设定的初始聚类种数，不适宜用于具有目标多样性、不确定性的室外场景分割。</p><p>室外场景彩色图像的特征空间分布随机且变化连续，数字图像的采样噪声和光照变化增加了图像的无规律性、复杂性，所以采用融合颜色、空间、纹理多维特征有利于取得更好的分割效果。Fukunaga [<xref ref-type="bibr" rid="hanspub.17400-ref1">1</xref>] [<xref ref-type="bibr" rid="hanspub.17400-ref2">2</xref>] 等人提出的均值偏移(Mean Shift)分割算法近年来在自然场景图像分割中得到了广泛的关注，该算法使用非参数概率密度估计方法，融合空间、色度信息，通过迭代过程对图像进行滤波，根据滤波结果的区域增长实现图像分割。文献 [<xref ref-type="bibr" rid="hanspub.17400-ref3">3</xref>] 中使用快速MS以及自适应MS [<xref ref-type="bibr" rid="hanspub.17400-ref4">4</xref>] 分割方法对自然场景图像都获得了较好效果。然而传统的Mean Shift分割方法只考虑图像的颜色和空间信息，导致图像分割精度提高有限，易产生过分割现象。根据纹理不依赖颜色、亮度，能较好反映物体同质现象的重要特征，使用纹理特征进行分割可以将具有相同或相似纹理的景物独立完整的分割出来，有助于避免产生过分割、提高分割结果的准确性和完整性。在纹理特征提取方法中Gabor纹理特征提取方法与人类视觉系统对于频率和方向的表示较为一致，并且具有较强的容噪能力，因此本文考虑结合Gabor提取图像的纹理特征改进一般Mean Shift图像分割算法，使之对具有较强纹理特征的室外场景彩色图像进行分割获得良好的分割结果。</p></sec><sec id="s4"><title>2. Mean Shift分割算法</title><p>Mean Shift算法在解决任何问题都是将其转化成连续非参数化的概率密度估计问题。即将与每个像素关联的特征向量(例如位置和颜色)模型化为来自某个位置概率密度函数的样本，然后使用梯度求导、迭代漂移的方法寻找在此分布中的峰值(模态)，将输入空间中能够攀登到同一峰值的区域部分标记归并为同一个类中，最终完成图像的分割。Mean Shift方法主要步骤为进行概率密度估计、求密度梯度、中心点迁移及区域中心提取。</p><sec id="s4_1"><title>2.1. Mean Shift基本思想</title><p>集合S<sub>h</sub>是一个距离中心像素点x<sub>0</sub>距离小于h的d维空间n个样本点的集合。在x<sub>0</sub>处的概率密度估函数表达式 [<xref ref-type="bibr" rid="hanspub.17400-ref1">1</xref>] 如下：</p><disp-formula id="hanspub.17400-formula99"><label>(1)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/2-1540571x9_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中K(x)为核函数，h为窗宽。根据概率密度函数<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x10_hanspub.png" xlink:type="simple"/></inline-formula>在局部最大值或最小值处<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x11_hanspub.png" xlink:type="simple"/></inline-formula>，可以利用核函数密度梯度计算获取聚类中心，对(1)式求梯度计算得：</p><disp-formula id="hanspub.17400-formula100"><label>(2)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/2-1540571x12_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x13_hanspub.png" xlink:type="simple"/></inline-formula>为归一化常数，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x14_hanspub.png" xlink:type="simple"/></inline-formula>是核函数<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x15_hanspub.png" xlink:type="simple"/></inline-formula>的轮廓函数，且<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x16_hanspub.png" xlink:type="simple"/></inline-formula>。由密度梯度推导可以得到沿梯度方向的偏移向量 [<xref ref-type="bibr" rid="hanspub.17400-ref1">1</xref>] [<xref ref-type="bibr" rid="hanspub.17400-ref2">2</xref>] ：</p><disp-formula id="hanspub.17400-formula101"><label>(3)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/2-1540571x17_hanspub.png"  xlink:type="simple"/></disp-formula><p>式中，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x18_hanspub.png" xlink:type="simple"/></inline-formula>。均值位移向量即为<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x19_hanspub.png" xlink:type="simple"/></inline-formula>周围邻居<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x20_hanspub.png" xlink:type="simple"/></inline-formula>的加权平均与<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x21_hanspub.png" xlink:type="simple"/></inline-formula>当前值的差异，其在多维空间中均值位移向量指向与函数梯度<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x22_hanspub.png" xlink:type="simple"/></inline-formula>相同的方向。由公式(3)可以看出Mean Shift算法是一个迭代过程，均值偏移向量沿着该概率密度的梯度方向移动，根据当前位置的概率密度大小而不断调整步长，最终，多次迭代迁移后收敛到聚类中心，文献 [<xref ref-type="bibr" rid="hanspub.17400-ref5">5</xref>] 证明了Mean Shift算法的收敛性。</p></sec><sec id="s4_2"><title>2.2. Mean Shift图像聚类分割</title><p>Mean Shift方法应用到图像分割中即将图像中的像素点映射到空间和颜色构成的高维空间中使用概率密度估计表示，根据梯度下降原则求出延梯度下降方向每次迭代的偏移量即均值位移向量，进行多次迭代找到同一类别的聚集中心点——模态。在均值位移过程中，模态(即聚类中心)<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x23_hanspub.png" xlink:type="simple"/></inline-formula>的当前估计在第k次迭代中被其局部加权平均所取代，迭代公式如下：</p><disp-formula id="hanspub.17400-formula102"><label>(4)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/2-1540571x24_hanspub.png"  xlink:type="simple"/></disp-formula><p>式中，x<sub>0</sub>表示聚类中心点，k表示迭代次数，G是上一节提到的核函数的轮廓函数的导数函数也是一种核函数。</p><p>由于图像中的点包含空间和颜色两种信息，因为两种信息尺度标准并不一致，因此作为权重的核函数使用多元核函数，表如下式：</p><disp-formula id="hanspub.17400-formula103"><label>(5)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/2-1540571x25_hanspub.png"  xlink:type="simple"/></disp-formula><p>得到聚类中心后计算外围样本点计算其到中心的距离可以判别所归属的类别并进行标记，根据标记结果可以得到分割结果。</p></sec></sec><sec id="s5"><title>3. 融合Gabor纹理特征的彩色图像分割算法</title><p>室外自然场景图像中通常具有区域性纹理特征，仅使用颜色进行分割易造成过分割等问题，因此在分割过程中考虑融合纹理特征 [<xref ref-type="bibr" rid="hanspub.17400-ref6">6</xref>] 。目前常用的纹理特征提取方法主要有灰度共生矩阵和Gabor滤波器等，由于Gabor函数可以在频域不同尺度、不同方向上提取相关特征，并且Gabor滤波器的频率和方向与人类视觉系统对于频率和方向的表示较为一致，因此本文使用Gabor小波进行纹理提取。</p><sec id="s5_1"><title>3.1. Gabor纹理特征提取</title><p>Gabor提取纹理特征主要分三个步骤，首先设计一组Gabor滤波器，构建Gabor滤波器组；其次在多方向和多尺度上对图像进行Gabor滤波卷积，最后对每一个方向和尺度的滤波器图像进行纹理特征的描述，提取所需要的纹理特征数值。</p><p>针对二维图像本文所使用的二维Gabor滤波器函数如下：</p><disp-formula id="hanspub.17400-formula104"><label>(6)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/2-1540571x26_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x27_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x28_hanspub.png" xlink:type="simple"/></inline-formula>是其在<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x29_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x30_hanspub.png" xlink:type="simple"/></inline-formula>坐标轴上的标准方差，表征空间域中高斯函数的带宽，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x31_hanspub.png" xlink:type="simple"/></inline-formula>是高斯函数的复调制频率。</p><p>使用不同尺度和方向的一组Gabor滤波器可以很好的提取出图像的纹理特征。将<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x32_hanspub.png" xlink:type="simple"/></inline-formula>作为一个基函数，对其进行尺度扩张和旋转变换，得到一组Gabor小波滤波器组，其公式如下：</p><disp-formula id="hanspub.17400-formula105"><label>(7)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/2-1540571x33_hanspub.png"  xlink:type="simple"/></disp-formula><disp-formula id="hanspub.17400-formula106"><label>(8)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/2-1540571x34_hanspub.png"  xlink:type="simple"/></disp-formula><p><inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x35_hanspub.png" xlink:type="simple"/></inline-formula>为尺度因子，m，n为整数，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x36_hanspub.png" xlink:type="simple"/></inline-formula>，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x37_hanspub.png" xlink:type="simple"/></inline-formula>是Gabor滤波器组的方向数，m为尺度参数，n为方向参数。</p><p>假设<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x38_hanspub.png" xlink:type="simple"/></inline-formula>是一幅图像，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x39_hanspub.png" xlink:type="simple"/></inline-formula>是Gabor小波函数，针对不同的<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x40_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x41_hanspub.png" xlink:type="simple"/></inline-formula>有不同<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x42_hanspub.png" xlink:type="simple"/></inline-formula>函数，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x43_hanspub.png" xlink:type="simple"/></inline-formula>的二维Gabor变换可以定义为如下式子：</p><disp-formula id="hanspub.17400-formula107"><label>(9)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/2-1540571x44_hanspub.png"  xlink:type="simple"/></disp-formula><p>使用上述公式对图像进行Gabor卷积可以得到m个尺度n个方向下的纹理图</p><p>考虑到使用<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x45_hanspub.png" xlink:type="simple"/></inline-formula>维特征进行聚类会导致时间效率大大降低，因此参考文献 [<xref ref-type="bibr" rid="hanspub.17400-ref7">7</xref>] ，针对每一尺度各个方向，按照融合规则将每个像素点各个尺度上4个Gabor方向特征转化为二进制编码</p><disp-formula id="hanspub.17400-formula108"><label>(10)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/2-1540571x46_hanspub.png"  xlink:type="simple"/></disp-formula><disp-formula id="hanspub.17400-formula109"><label>(11)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/2-1540571x47_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x48_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x49_hanspub.png" xlink:type="simple"/></inline-formula>是像素点<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x50_hanspub.png" xlink:type="simple"/></inline-formula>在不同方向上的Gabor特征的实部和虚部，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x51_hanspub.png" xlink:type="simple"/></inline-formula>和<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x52_hanspub.png" xlink:type="simple"/></inline-formula>是每一方向所对应的二进制代码。将这些二进制代码按照顺序排列起来形融合成一个十进制的数字，每一个数字可以代表一个方向的融合特征。</p><disp-formula id="hanspub.17400-formula110"><label>(12)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/2-1540571x53_hanspub.png"  xlink:type="simple"/></disp-formula><disp-formula id="hanspub.17400-formula111"><label>(13)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/2-1540571x54_hanspub.png"  xlink:type="simple"/></disp-formula><p>最终每个像素得到3个尺度上的多方向Gabor特征，<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x55_hanspub.png" xlink:type="simple"/></inline-formula>。</p></sec><sec id="s5_2"><title>3.2. 多维特征均值偏移</title><p>在图像处理过程中每一像素点<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x56_hanspub.png" xlink:type="simple"/></inline-formula>包含三类信息：坐标空间(spatial, <inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x57_hanspub.png" xlink:type="simple"/></inline-formula>,<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x58_hanspub.png" xlink:type="simple"/></inline-formula>)，颜色空间(本文针对彩色图像)(range, <inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x59_hanspub.png" xlink:type="simple"/></inline-formula>,<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x60_hanspub.png" xlink:type="simple"/></inline-formula>或<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x61_hanspub.png" xlink:type="simple"/></inline-formula>)，纹理特征(Texture,<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x62_hanspub.png" xlink:type="simple"/></inline-formula>)构成其特征空间，因为三者属性截然不同因此考虑使用多元核密度估计方法。</p><p>根据上述纹理特征提取方法得到图像像素的纹理空间特征(<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x63_hanspub.png" xlink:type="simple"/></inline-formula>)，将纹理信息与像素的空间位置及颜色信息融合，得到图像中任意像素点处的融合后N维特征向量：<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x64_hanspub.png" xlink:type="simple"/></inline-formula>。</p><p>综合空间、颜色与纹理属性信息的多元核函数公式如下：</p><disp-formula id="hanspub.17400-formula112"><label>(14)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/2-1540571x65_hanspub.png"  xlink:type="simple"/></disp-formula><p>其中，2是空间维数，p是色度向量的维数，q是纹理向量的维数。<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x66_hanspub.png" xlink:type="simple"/></inline-formula>分别是位置、色度和纹理向量；<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x67_hanspub.png" xlink:type="simple"/></inline-formula>分别是空间带宽、色度值域带宽和纹理特征带宽。</p><p>核函数用于度量集合中每一个样本与中心样本之间的相似度。通常采用的核函数由Gauss核函数和Epanechnikov核函数，较Epanechnikov核函数而言高斯核函数具有更平滑的轨迹，在模态附近步长大小控制能力更强，因此本文采用Gauss核函数：</p><disp-formula id="hanspub.17400-formula113"><label>(15)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/2-1540571x68_hanspub.png"  xlink:type="simple"/></disp-formula><p>基于N维融合特征的Mean Shift迁移向量如下式：</p><disp-formula id="hanspub.17400-formula114"><label>(16)</label><graphic position="anchor" xlink:href="http://html.hanspub.org/file/2-1540571x69_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s5_3"><title>3.3. 彩色图像分割</title><p>使用多维特征核函数法对整幅图像进行偏移迭代直至满足停止准则(偏移距离小于设定值或迭代次数达到最大值)，该过程将空间位置近似的、颜色性质差异小的像素收敛到近似的模态，得到聚类的中心<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x70_hanspub.png" xlink:type="simple"/></inline-formula>，将图像中与中心点Y所有空间距离小于<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x71_hanspub.png" xlink:type="simple"/></inline-formula>，颜色距离小于<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x72_hanspub.png" xlink:type="simple"/></inline-formula>，纹理距离小于<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x73_hanspub.png" xlink:type="simple"/></inline-formula>的</p><p>像素点划分到对应类别<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x74_hanspub.png" xlink:type="simple"/></inline-formula>中去，并设置其类别标识<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x75_hanspub.png" xlink:type="simple"/></inline-formula>将聚类结果分为不连通的小块。设定阈值M，将面积小于阈值的区域合并到周围区域中，得到最终分割结果。</p></sec></sec><sec id="s6"><title>4. 实验结果及分析</title><p>实验数据来自气象台观测场提供的摄像头拍摄周围环境图像，包含80幅大小为800 &#215; 600的观测场图像。通过前人大量实验表明一般纹理方向的识别使用4到6个方向就可以满足分类的要求，本文选取使用4 &#215; 3的Gabor滤波级基如图1，即4个方向分别是0、30、60、90度，3个尺度<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x76_hanspub.png" xlink:type="simple"/></inline-formula>，共12个滤波器。每一个滤波器对图像进行卷积滤波得到12个不同尺度不同方向的Gabor滤波结果，使用二进制编码降维后得到3个尺度下的纹理特征。</p><p>为验证提出方法的有效性，从中选取20幅彩色图像进行分割试验，设计了对比试验。实验根据经验调整<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x77_hanspub.png" xlink:type="simple"/></inline-formula>参数，对比了传统分水岭分割算法、以及Rutgers大学Robust Image Understanding实验室开发的基于固定带宽Mean Shift算法以及本文提出的方法。</p><p>图1. 一组Gabor基样例</p><p>图2. 不同算法分割结果对比</p><disp-formula id="hanspub.17400-formula115"><graphic xlink:href="http://html.hanspub.org/file/2-1540571x86_hanspub.png"  xlink:type="simple"/></disp-formula><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> OCE value of segmentation between EDISON and our metho</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >方法名称</th><th align="center" valign="middle" >房屋</th><th align="center" valign="middle" >树木</th><th align="center" valign="middle" >绿地</th><th align="center" valign="middle" >天空</th><th align="center" valign="middle" >道路</th></tr></thead><tr><td align="center" valign="middle" >EDISON</td><td align="center" valign="middle" >0.282</td><td align="center" valign="middle" >0.334</td><td align="center" valign="middle" >0.054</td><td align="center" valign="middle" >0.010</td><td align="center" valign="middle" >0.126</td></tr><tr><td align="center" valign="middle" >本文</td><td align="center" valign="middle" >0.274</td><td align="center" valign="middle" >0.326</td><td align="center" valign="middle" >0.045</td><td align="center" valign="middle" >0.010</td><td align="center" valign="middle" >0.123</td></tr></tbody></table></table-wrap><p>表1. 本文分割方法与EDISON分割方法OCE值比较</p><p>由实验结果可以看出使用分水岭分割方法结果不够准确，使用传统Mean Shift分割方法获得较为细碎的分割结果(如2中的栅栏、树丛部分)，本文方法对于具有纹理同质区域有较好的保护作用，在一定程度上抑制纹理区域内部变换所造成的过分割问题，能获得较好的对象边界信息。</p><p>为了评价分割结果，本文选用了图2中图像进行定量对比分析。对彩色图像分割结果进行评价的标准有很多 [<xref ref-type="bibr" rid="hanspub.17400-ref8">8</xref>] [<xref ref-type="bibr" rid="hanspub.17400-ref9">9</xref>] ，本文选择根据Mark [<xref ref-type="bibr" rid="hanspub.17400-ref10">10</xref>] 等人提出的基于对象一致性误差(OCE)的图像分割评价标准，其具有客观性，对过分割和欠分割都较为敏感。OCE比较参考对象(O)与实际分割对象(R)的差别满足<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x87_hanspub.png" xlink:type="simple"/></inline-formula>，当<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x88_hanspub.png" xlink:type="simple"/></inline-formula>时，表示分割结果与实际完全相符，因此OCE值越小说明分割结果与实际越吻合，分割方法越好。因此将图2分割结果根据房屋、树木、绿地、天空、道路进行分类，计算相应OCE值，得到如表1所示结果。</p></sec><sec id="s7"><title>5. 结论</title><p>本文融合Gabor纹理特征于Mean Shift分割算法中，充分利用室外图像的复杂性、多样性以及具有丰富纹理的特点，使用融合纹理特征、位置特征和颜色特征形成的多维特征Gauss核函数进行Mean Shift聚类，实现了室外场景彩色图像的自动化分割，分割结果更符合人的视觉感知。对于本文的融合纹理信息的Mean Shift算法中<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x89_hanspub.png" xlink:type="simple"/></inline-formula>参数的选择对分割结果会产生较大影响，因此对<inline-formula><inline-graphic xlink:href="http://html.hanspub.org/file/2-1540571x90_hanspub.png" xlink:type="simple"/></inline-formula>参数的选择是今后有待进一步研究的方向。</p></sec><sec id="s8"><title>文章引用</title><p>王瑾,张国英. 融合Gabor纹理特征的观测场彩色图像均值偏移分割方法研究 A Method of Meteorological Observation Field Color Image Segmentation Using Mean Shift Combined with Gabor Texture Feature[J]. 计算机科学与应用, 2016, 06(04): 216-222. http://dx.doi.org/10.12677/CSA.2016.64027</p></sec><sec id="s9"><title>参考文献 (References)</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.17400-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Fukunaga, K. and Hostetler, L.D. (1975) The Estimation of the Gradient of a Density Function, with Applications in Pattern Recognition. IEEE Transactions on Information Theory, 21, 32-10.  
&lt;br&gt;http://dx.doi.org/10.1109/TIT.1975.1055330</mixed-citation></ref><ref id="hanspub.17400-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Cheng, Y.Z. (1995) Mean Shift, Mode Seeking, and Clustering. IEEE Transactions Analysis and Machine Intelligence, 17.</mixed-citation></ref><ref id="hanspub.17400-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Freedman, D. and Kisilev, P. (2009) Hewlett-Packard Laboratories, Haifa, Isreal. Fast Mean Shift by Compact Density Representation. IEEE Conference on Computer Vision and Pattern Recognition, 20-25 June 2009, 1818-1925.</mixed-citation></ref><ref id="hanspub.17400-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">王晏, 孙怡. 自适应Mean Shift算法的彩色图像平滑与分割算法[J]. 自动化学报, 2010(12):1637-1644.</mixed-citation></ref><ref id="hanspub.17400-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">文志强, 蔡自兴. Mean Shift算法的收敛性分析[J]. 软件学报, 2007, 18(2): 205-212.</mixed-citation></ref><ref id="hanspub.17400-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">周家香, 朱建军, 梅小明, 马慧云. 多维特征自适应Mean Shift遥感图像分割方法[J]. 武汉大学学报: 信息科学版, 2012, 37(4): 419-422.</mixed-citation></ref><ref id="hanspub.17400-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">刘帅师, 田彦涛, 万川. 基于Gabor多方向特征融合与分块直方图的人脸表情识别方法[J]. 自动化学报, 2011(12): 1455-1463.</mixed-citation></ref><ref id="hanspub.17400-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Martin, D., Fowlkes, C., Tal, D., et al. (2001) A Database of Human Segmented Natural Images and Its Application to Evaluating Segmentation Algorithms and Measuring Ecological Statistics. IEEE International Conference on Computer Vision, 2, 416-423. &lt;br&gt;http://dx.doi.org/10.1109/iccv.2001.937655</mixed-citation></ref><ref id="hanspub.17400-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Borsotti, M., Campadelli, P., Schettini, R., et al. (1998) Quan-titative Evaluation of Color Image Segmentation Results. Pattern Recognition Letters, 19, 741-747. &lt;br&gt;http://dx.doi.org/10.1016/S0167-8655(98)00052-X</mixed-citation></ref><ref id="hanspub.17400-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Mark, P., Zhang, H. and Pi, M.H. (2009) An Evaluation Metric for Image Segmentation of Multiple Objects. Image and Vision Computing, 27, 1223-1227. &lt;br&gt;http://dx.doi.org/10.1016/j.imavis.2008.09.008</mixed-citation></ref></ref-list></back></article>