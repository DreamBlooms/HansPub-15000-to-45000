<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">AIRR</journal-id><journal-title-group><journal-title>Artificial Intelligence and Robotics Research</journal-title></journal-title-group><issn pub-type="epub">2326-3415</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/AIRR.2018.73016</article-id><article-id pub-id-type="publisher-id">AIRR-26651</article-id><article-categories><subj-group subj-group-type="heading"><subject>AIRR20180300000_75960552.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject><subject> 工程技术</subject></subj-group></article-categories><title-group><article-title>
 
 
  一种基于卷积神经网络的草地植物识别方法
  Grassland Plant Identification Method Based on Convolutional Neural Network
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>曹</surname><given-names>中奇</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>刘</surname><given-names>路路</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>康</surname><given-names>孝岩</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>张</surname><given-names>爱武</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>柴</surname><given-names>沙驼</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="aff2"><addr-line>首都师范大学资源环境与旅游学院，北京</addr-line></aff><aff id="aff3"><addr-line>青海大学畜牧兽医院，青海 西宁</addr-line></aff><aff id="aff1"><addr-line>null</addr-line></aff><pub-date pub-type="epub"><day>27</day><month>06</month><year>2018</year></pub-date><volume>07</volume><issue>03</issue><fpage>135</fpage><lpage>146</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   现有对草地植物的图像识别主要集中于对叶片或大面积种群的识别，很少有从单株植物或小片群落的角度进行识别。本文针对上述问题，总结出三种适用于解决该问题的识别方法，改进和微调了现有基于卷积神经网络方法的预处理流程和网络模型来进行植物图像识别方法。本文采用近距离拍摄的高空间分辨率草地植物图片，设计实验对比分析了上述三种方法在识别标注样本数据集上的表现。实验结果表明，基于预训练模型的深度卷积神经网络方法同其他方法相比，在准确性上，具有显著的优越性。 The existing image recognition of grassland plants is mainly focused on the identification of leaves or large area populations, and few of them are identified from the angle of single plant or small community. In this paper, three identification methods for solving the problem are summarized, and the process of preprocessing and network model based on the existing convolution neural network methods are improved and adjusted to carry out the method of plant image recognition. In this paper, the high spatial resolution grassland plant pictures are taken near the distance, and the performance of the above three methods on the identified annotation sample data sets is compared and analyzed. The experimental results show that the method of deep convolution neural network based on pre-training model is superior to other methods in identifying the accuracy of the data set of the labeled sample. 
 
</p></abstract><kwd-group><kwd>草地图像识别，全局特征，主成分分析，卷积神经网络, Grass Image Classification</kwd><kwd> Global Features</kwd><kwd> PCA</kwd><kwd> CNN</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>一种基于卷积神经网络的草地植物 识别方法<sup> </sup></title><p>曹中奇<sup>1</sup>，刘路路<sup>1*</sup>，康孝岩<sup>1</sup>，张爱武<sup>1</sup>，柴沙驼<sup>2</sup></p><p><sup>1</sup>首都师范大学资源环境与旅游学院，北京</p><p><sup>2</sup>青海大学畜牧兽医院，青海 西宁</p><disp-formula id="hanspub.26651-formula52"><graphic xlink:href="//html.hanspub.org/file/7-2610124x5_hanspub.png"  xlink:type="simple"/></disp-formula><p>收稿日期：2018年8月7日；录用日期：2018年8月23日；发布日期：2018年8月30日</p><disp-formula id="hanspub.26651-formula53"><graphic xlink:href="//html.hanspub.org/file/7-2610124x6_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>现有对草地植物的图像识别主要集中于对叶片或大面积种群的识别，很少有从单株植物或小片群落的角度进行识别。本文针对上述问题，总结出三种适用于解决该问题的识别方法，改进和微调了现有基于卷积神经网络方法的预处理流程和网络模型来进行植物图像识别方法。本文采用近距离拍摄的高空间分辨率草地植物图片，设计实验对比分析了上述三种方法在识别标注样本数据集上的表现。实验结果表明，基于预训练模型的深度卷积神经网络方法同其他方法相比，在准确性上，具有显著的优越性。</p><p>关键词 :草地图像识别，全局特征，主成分分析，卷积神经网络</p><disp-formula id="hanspub.26651-formula54"><graphic xlink:href="//html.hanspub.org/file/7-2610124x7_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2018 by authors and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/7-2610124x8_hanspub.png" /> <img src="//html.hanspub.org/file/7-2610124x9_hanspub.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>关于青海省的植物种类及其特征 [<xref ref-type="bibr" rid="hanspub.26651-ref1">1</xref>] - [<xref ref-type="bibr" rid="hanspub.26651-ref6">6</xref>] 、植物识别 [<xref ref-type="bibr" rid="hanspub.26651-ref7">7</xref>] [<xref ref-type="bibr" rid="hanspub.26651-ref8">8</xref>] [<xref ref-type="bibr" rid="hanspub.26651-ref9">9</xref>] 等方面的研究都取得了突破性的研究成果。但传统的遥感图像分类方法在进行植物识别时，由于图像具有较高的空间分辨率，会出现同物异谱等问题。植物的识别是复杂度高且数据量大的一项研究，因此深度学习在植物识别方面具有技术优势和广阔的发展前景。卷积神经网络 [<xref ref-type="bibr" rid="hanspub.26651-ref10">10</xref>] [<xref ref-type="bibr" rid="hanspub.26651-ref11">11</xref>] [<xref ref-type="bibr" rid="hanspub.26651-ref12">12</xref>] [<xref ref-type="bibr" rid="hanspub.26651-ref13">13</xref>] [<xref ref-type="bibr" rid="hanspub.26651-ref14">14</xref>] (Convolutional Neural Network, CNN)是深度学习研究中具有代表性并且十分高效的方法之一。最早的卷积神经网络模型是由纽约大学的Yann LeCun教授提出来的 [<xref ref-type="bibr" rid="hanspub.26651-ref15">15</xref>] 。经过了整整20年的发展，至今卷积神经网络技术已在计算机视觉领域确立了统治地位。</p><p>Lopatin等 [<xref ref-type="bibr" rid="hanspub.26651-ref16">16</xref>] 使用地面高光谱仪器距地面2.5米的高度采集草地植物影像，证明在低结构异质性环境下，高空间分辨率的高光谱遥感适用于基于个体的草地植物物种分类。Shang等 [<xref ref-type="bibr" rid="hanspub.26651-ref17">17</xref>] 分析了不同种类草地植被叶片高光谱数据的原始特征和灰度共生矩阵的纹理特征，设计了一种基于植被特征库的植物精细分类算法。Meyer等 [<xref ref-type="bibr" rid="hanspub.26651-ref18">18</xref>] 用机器学习技术测试了高光谱和多光谱在现场测定的适用性，成果映射出在区域范围内的植被覆盖和地上生物量。</p><p>现有的针对草地的精细分类通常采用混合像元分解、端元提取的方式，处理航天航空遥感获得的地面光谱数据，空间分辨率很有限，限制了草地植物的识别，而前人对草地植物的识别多集中于大面积的种群识别。本文从全局特征、PCA + SVM (主成分分析法+支持向量机)、深度卷积神经网络三种方法出发，通过对比试验，对数据集中的草地植物进行分类检测，提高检测精度，为草地植物分类检测提供便利。本文采用地面采集的数据，空间分辨率较高，可以做到单株植物的识别。</p></sec><sec id="s4"><title>2. 基于深度卷积神经网络的草地植物识别方法</title><p>本文使用的算法流程如图1所示。实验室实地采集获得青海地区6000余幅多光谱草地影像数据。有别于一般在划分数据集之前就进行图像预处理的做法，本文选择将预处理步骤放在训练前。这样做的好处一是保留测试集本身的客观性(没有经过人为处理)，二是可以通过程序随机生成预处理所用方法的参数，使得进入网络的每一批次的数据都不尽相同，变相的丰富了数据量，防止网络过拟合。</p><sec id="s4_1"><title>2.1. 图像预处理增强</title><p>当拍摄者从俯视角度获取植物照片时，植物影像势必会由于拍摄者位置方位不同产生不固定的旋转偏移。此外，受拍照时的光照强度、遮盖、阴影等影响也会引起数据集影像信息的波动。本文通过多种图像增强手段对植物图像进行预处理以消除这些影响(图2)。具体步骤为随机加窗、图像大小调整、随机翻转、灰度调整。</p></sec><sec id="s4_2"><title>2.2. 基于自选网络的识别方法</title><p>本文首先尝试使用表1所示的网络结构进行图像识别。该网络基于经典的Lenet-5 [<xref ref-type="bibr" rid="hanspub.26651-ref19">19</xref>] 模型，在其基础上进行了一些改进。</p><p>1) 将原本5 &#215; 5的卷积核替换成两个级联的3 &#215; 3卷积核。</p><p>2) 参考AlexNet [<xref ref-type="bibr" rid="hanspub.26651-ref11">11</xref>] ，在CNN中使用重叠的最大池化，让池化层的步长比池化核的尺寸小。</p><p>3) 学习AlexNet [<xref ref-type="bibr" rid="hanspub.26651-ref11">11</xref>] ，使用修正线性单元(Rectified linear unit, ReLU)作为激活函数。</p><p>4) 增加局部相应归一化层(LRN)，对局部神经元的活动创建竞争机制。</p><p>图1. 基于卷积神经网络的草地植物图像识别方法流程图</p><p>图2. 植物图像预处理过程示意图。(a) 初始输入影像；(b) 随机加框效果；(c) 将图像按框裁切，并调整大小；(d) 图像随机翻转</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> A modified convolutional neural network model based on Lenet-5 mode</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >层名</th><th align="center" valign="middle" >层级结构</th><th align="center" valign="middle" >属性</th></tr></thead><tr><td align="center" valign="middle" >层1</td><td align="center" valign="middle" >Conv1 + ReLU1 Pool1 LRN1</td><td align="center" valign="middle" >卷积核数量：16 卷积核尺寸：3 步长：1 核尺寸：3 步长：2 局部尺寸：4</td></tr><tr><td align="center" valign="middle" >层2</td><td align="center" valign="middle" >Conv2 + ReLU2 Pool1 LRN1</td><td align="center" valign="middle" >卷积核数量：16 卷积核尺寸：3 步长：1 核尺寸：3 步长：2 局部尺寸：4</td></tr><tr><td align="center" valign="middle" >层3</td><td align="center" valign="middle" >FC3 + ReLU3</td><td align="center" valign="middle" >神经元数量：128</td></tr><tr><td align="center" valign="middle" >层4</td><td align="center" valign="middle" >FC4 + ReLU4</td><td align="center" valign="middle" >神经元数量：128</td></tr><tr><td align="center" valign="middle" >层5</td><td align="center" valign="middle" >SOFTMAX</td><td align="center" valign="middle" >输出N_CLASSES维度的值</td></tr></tbody></table></table-wrap><p>表1. 基于Lenet-5模型改进的卷积神经网络模型各层属性表</p></sec><sec id="s4_3"><title>2.3. 基于fine tuning技术的识别方法</title><p>有时难以获得大量的训练数据，数据量过小时，超参数难以调整，学习权重不充分，容易出现过拟合。这时采用迁移学习的策略，在一个已经被海量数据训练好的模型的基础上微调(fine tuning)就是一个理想的策略。基于fine tuning技术的图像识别算法可以概括为以下步骤图3。</p><p>针对植物图片数据量过少的问题，本文尝试使用经过海量数据集预先训练好的模型作为网络的超参数，并在其基础上用少量植物样本数据进行微调，获得适合与解决本文研究任务的分类模型。具体本文选择Google提出的Inception_v4模型 [<xref ref-type="bibr" rid="hanspub.26651-ref20">20</xref>] 作为我们的预训练网络，将该模型学习好的参数输送到网络中作为初始参数，修改最后分类层的输出个数对应本文研究对象的类别数目。固定前面几层的参数，只学习最后的Logis层和Aux_logits层。最后用实验室的带标签的草类数据集微调模型。</p></sec></sec><sec id="s5"><title>3. 青海地区草地植物图片识别方法实验</title><sec id="s5_1"><title>3.1. 图片采集和样本库构建</title><sec id="s5_1_1"><title>3.1.1. 图片采集</title><p>实验室通过自主集成的手持多光谱图像采集设备，于2017年8月11日至8月18日在青海省海北州海晏县西海镇附近采集了6000余张草地的多光谱影像数据，原始数据参数如表2，图4所示。</p><p>图3. 基于fine tuning技术的图像识别算法</p><p>图4. 拼接后的原始影像数据示例。(a)：真彩色合成的原始影像；(b)：a的局部放大效果</p><table-wrap id="table2" ><label><xref ref-type="table" rid="table2">Table 2</xref></label><caption><title> Original data parameters of each multispectral imag</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >波段数</th><th align="center" valign="middle" >测区面积</th><th align="center" valign="middle" >单位像素面积</th></tr></thead><tr><td align="center" valign="middle" >6</td><td align="center" valign="middle" >1.6827平方米</td><td align="center" valign="middle" >0.85254平方毫米</td></tr></tbody></table></table-wrap><p>表2. 每幅多光谱图像原始数据参数</p><p>由表2和图4可以看出，原始图像数据具有空间分辨率达毫米级、图像局部过曝，配准不精确、图像边缘存在光谱畸变等问题。</p><p>如此高的空间分辨率和光谱畸变使得传统的遥感影像分类方法在应用中，将面临严重的同物异谱现象。且研究对象大都是绿色植物，不同种类的草在光谱信息上的差异并不明显，即存在异物同谱现象。使用光谱信息进行草种的分类识别难度大，因而需借鉴目前主流的图像识别算法的思路。</p></sec><sec id="s5_1_2"><title>3.1.2. 植物标注样本数据库构建</title><p>预处理流程图见图5(a)。实验室先将原始6个波段的数据对齐拼接，再使用真彩色合成获得彩色图像。通过人工裁剪(图5(b))，从合成的6000多张彩色图片中找出三种典型的青海湖地区草场的代表草种，分别是马蔺草、狼毒草和香青草。每种100张，共300张。样本库示例见图6。</p></sec></sec><sec id="s5_2"><title>3.2. 基于全局特征的图像识别实验</title><p>实验通过三种特征算子获取组合特征向量之后，经过归一化处理得到归一化的特征向量，每个特征向量长度为532。归一化的特征向量按9:1的比例随机划分成训练数据集和验证数据集。本文选取逻辑回归(LR)、线性判别分析(LDA)、k近邻(KNN)、决策树(CART)、随机森林(RF)、朴素贝叶斯(NB)和支持向量机(SVM)七种分类器模型训练。使用训练数据集训练好的模型采用k折交叉验证(k = 10)，最后得分如表3所示。</p><p>本文通过k折交叉验证选取准确率最高的随机森林模型用于测试数据集的分类。实验测试了决策树数目取不同值时对分类结果的影响，当决策树取值在[1, 30]之间时，分类结果的各项指标会上下波段，当决策树数目取5时整体效果最好(平均召回率 = 0.7，平均精度 = 0.8，平均f1得分 = 0.64)。</p><p>表4所示是使用全局特征+随机森林分类法，在决策树数目 = 5时的各项分类结果统计表。该方法对狼毒草的识别能力很差，虽然精度很高，但召回率只有0.2，即10张狼毒草照片里只有2张被识别出来。马蔺草的召回率是1.0，表明所有马蔺草均被识别出来，但是精度只有0.59。这说明该分类模型倾向于把马蔺草和狼毒草都识别成马蔺草，显然也是不合理的。香青的召回率和精度都挺高，说明该分类模型能够较准确的识别出香青。</p></sec><sec id="s5_3"><title>3.3. 基于PCA和SVM的图像识别实验</title><p>在使用主成分分析法对带标签植物样本数据集进行抽象降维时，主成分向量的个数N是重要的超参数。实验测试了五种取值下的评分表现，结果表明N取30时的识别性能最佳。表5展示出N = 30时该方法的分类结果评价。统计结果表明，该方法对三种草的识别精度和召回率比较平衡，而且都比较高(平均 &gt; 0.80)。</p><p>使用支持向量机模型作为分类器时，需要注意超参数的选择，包括惩罚参数C、核函数模型kernel、核函数的参数gamma等。本文采用交叉验证的方法选取最优化的结果和参数。实验结果表明，kernel选择径向基核函数(Radial Basis Function, RBF)，C = 10，gamma = 0.01时可以取得最优结果。</p></sec><sec id="s5_4"><title>3.4. 基于卷积神经网络图像识别实验</title><p>本文首先尝试使用在Lenet-5的基础上改进的卷积神经网络做分类实验。网络结构和数据流动情况如</p><p>图5. 带标注植物样本数据库的构建方法。(a)：带标注植物样本数据库构建流程图；(b)：实验室开发的图像采集标注软件</p><p>图7所示。输入数据的batch_size设置为12，图像大小为208 &#215; 208 &#215; 3。conv1和conv2使用16个3 &#215; 3的卷积核，采用零填充方式，输出的feature map大小与输入图片的大小相同；pooling1和pooling2使用3 &#215; 3的池化核，采用重叠池化方式，步长为2；全连接层的神经元数目是128；分类器选择的是SoftMax。分类结果评价表见表6。可以看出，分类的结果并不理想。狼毒草的召回率为1，精度只有0.59，说明模型倾向于把所有草都识别为狼毒草；马蔺草的召回率只有0.3，精度只有0.43，说明模型不能有效识别马蔺草；香青的召回率为0.60，精度为1，说明模型一定程度上可以识别出香青。使用Tensorflow提供的可视化工具考察模型的训练过程，见图8。考察损失函数的下降曲线(图8(a))和精度的上升曲线(图8(b))，可以看出，损失函数/准确率的下降/上升非常快，曲线的变化非常陡峭。在大约1000步时，损失函数已经下降到0，准确率已经上升至1.00。发生这种情况的原因一般是训练样本过少，网络深度过浅，优化器选择不当等导致的过拟合。</p><p>基于fine tuning技术的分类结果评价表见表7。可以看出，模型的分类效果非常好，各项指标均为1。表明该模型在测试数据集上能够完全识别出三种草，准确率为100%。考察模型训练过程中损失函数的下降情况如图9。在训练到1000步时，损失函数下降到0.48，之后一直在0.5左右上下波动。这种情况符合正常的训练过程。</p></sec></sec><sec id="s6"><title>4. 结论与展望</title><p>本文针对单株植物或小片群落的植物图像识别问题，总结出三种识别方法适用于解决该问题。基于预训练模型的深度卷积神经网络方法同其他方法相比，在识别带标注样本数据集的准确性上，具有显著的优越性。</p><p>虽然本文最后实验可以完全识别现有的带标注样本数据集，但仍有很多不足之处需要改进：</p><p>1) 带标注植物样本数据库数据量太小，且无季节性变化。这些有赖于实验室之后的建库工作持续进行。</p><p>图6. 带标注植物样本图片库部分展示。(a)：狼毒草库；(b)：马蔺草库；(c)：香青库</p><p>图7. 本文使用的卷积神经网络结构图</p><p>图8. 使用自选网络模型训练过程可视化。(a)：损失函数下降曲线；(b)：精度上升曲线</p><p>图9. 基于fine-tuning技术的卷积神经网络模型训练过程损失函数下降曲线</p><table-wrap id="table3" ><label><xref ref-type="table" rid="table3">Table 3</xref></label><caption><title> Seven classifier’s K fold cross validation score statistics tabl</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >分类器</th><th align="center" valign="middle" >准确率</th></tr></thead><tr><td align="center" valign="middle" >LR</td><td align="center" valign="middle" >0.944444 (0.044598)</td></tr><tr><td align="center" valign="middle" >LDA</td><td align="center" valign="middle" >0.837037 (0.060178)</td></tr><tr><td align="center" valign="middle" >KNN</td><td align="center" valign="middle" >0.925926 (0.043823)</td></tr><tr><td align="center" valign="middle" >CART</td><td align="center" valign="middle" >0.837037 (0.060178)</td></tr><tr><td align="center" valign="middle" >RF</td><td align="center" valign="middle" >0.948148 (0.066667)</td></tr><tr><td align="center" valign="middle" >NB</td><td align="center" valign="middle" >0.844444 (0.093404)</td></tr><tr><td align="center" valign="middle" >SVM</td><td align="center" valign="middle" >0.818519 (0.048148)</td></tr></tbody></table></table-wrap><p>表3. 七种分类器的K折交叉验证得分统计表</p><table-wrap id="table4" ><label><xref ref-type="table" rid="table4">Table 4</xref></label><caption><title> Global characteristic + random forest classification result evaluation table, number of decision trees = </title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" >Precision</th><th align="center" valign="middle" >Recall</th><th align="center" valign="middle" >f1-score</th><th align="center" valign="middle" >Support</th></tr></thead><tr><td align="center" valign="middle" >Langdu</td><td align="center" valign="middle" >1.00</td><td align="center" valign="middle" >0.20</td><td align="center" valign="middle" >0.33</td><td align="center" valign="middle" >10</td></tr><tr><td align="center" valign="middle" >Malin</td><td align="center" valign="middle" >0.59</td><td align="center" valign="middle" >1.00</td><td align="center" valign="middle" >0.74</td><td align="center" valign="middle" >10</td></tr><tr><td align="center" valign="middle" >Xiangqing</td><td align="center" valign="middle" >0.82</td><td align="center" valign="middle" >0.90</td><td align="center" valign="middle" >0.86</td><td align="center" valign="middle" >10</td></tr><tr><td align="center" valign="middle" >Avg/total</td><td align="center" valign="middle" >0.80</td><td align="center" valign="middle" >0.70</td><td align="center" valign="middle" >0.64</td><td align="center" valign="middle" >30</td></tr></tbody></table></table-wrap><p>表4. 全局特征 + 随机森林法分类结果评价表，决策树数目 = 5</p><table-wrap id="table5" ><label><xref ref-type="table" rid="table5">Table 5</xref></label><caption><title> PCA + SVM method classification result evaluation table, extracting principal component vector number N = 3</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" >Precision</th><th align="center" valign="middle" >Recall</th><th align="center" valign="middle" >f1-score</th><th align="center" valign="middle" >Support</th></tr></thead><tr><td align="center" valign="middle" >Langdu</td><td align="center" valign="middle" >0.78</td><td align="center" valign="middle" >0.78</td><td align="center" valign="middle" >0.78</td><td align="center" valign="middle" >9</td></tr><tr><td align="center" valign="middle" >Malin</td><td align="center" valign="middle" >1.00</td><td align="center" valign="middle" >0.80</td><td align="center" valign="middle" >0.89</td><td align="center" valign="middle" >10</td></tr><tr><td align="center" valign="middle" >Xiangqing</td><td align="center" valign="middle" >0.77</td><td align="center" valign="middle" >0.91</td><td align="center" valign="middle" >0.83</td><td align="center" valign="middle" >11</td></tr><tr><td align="center" valign="middle" >Avg/total</td><td align="center" valign="middle" >0.85</td><td align="center" valign="middle" >0.83</td><td align="center" valign="middle" >0.84</td><td align="center" valign="middle" >30</td></tr></tbody></table></table-wrap><p>表5. PCA + SVM方法分类结果评价表提取主成分向量数N = 30</p><table-wrap id="table6" ><label><xref ref-type="table" rid="table6">Table 6</xref></label><caption><title> Use of self-selected network classification results evaluation tabl</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" >Precision</th><th align="center" valign="middle" >Recall</th><th align="center" valign="middle" >f1-score</th><th align="center" valign="middle" >Support</th></tr></thead><tr><td align="center" valign="middle" >Langdu</td><td align="center" valign="middle" >0.59</td><td align="center" valign="middle" >1.00</td><td align="center" valign="middle" >0.74</td><td align="center" valign="middle" >10</td></tr><tr><td align="center" valign="middle" >Malin</td><td align="center" valign="middle" >0.43</td><td align="center" valign="middle" >0.30</td><td align="center" valign="middle" >0.35</td><td align="center" valign="middle" >10</td></tr><tr><td align="center" valign="middle" >Xiangqing</td><td align="center" valign="middle" >1.00</td><td align="center" valign="middle" >0.60</td><td align="center" valign="middle" >0.75</td><td align="center" valign="middle" >10</td></tr><tr><td align="center" valign="middle" >Avg/total</td><td align="center" valign="middle" >0.67</td><td align="center" valign="middle" >0.60</td><td align="center" valign="middle" >0.75</td><td align="center" valign="middle" >30</td></tr></tbody></table></table-wrap><p>表6. 使用自选网络分类结果评价表</p><table-wrap id="table7" ><label><xref ref-type="table" rid="table7">Table 7</xref></label><caption><title> Classification result evaluation table based on fine tuning technolog</title></caption><table><tbody><thead><tr><th align="center" valign="middle" ></th><th align="center" valign="middle" >Precision</th><th align="center" valign="middle" >Recall</th><th align="center" valign="middle" >f1-score</th><th align="center" valign="middle" >Support</th></tr></thead><tr><td align="center" valign="middle" >Langdu</td><td align="center" valign="middle" >1.00</td><td align="center" valign="middle" >1.00</td><td align="center" valign="middle" >1.00</td><td align="center" valign="middle" >10</td></tr><tr><td align="center" valign="middle" >Malin</td><td align="center" valign="middle" >1.00</td><td align="center" valign="middle" >1.00</td><td align="center" valign="middle" >1.00</td><td align="center" valign="middle" >10</td></tr><tr><td align="center" valign="middle" >Xiangqing</td><td align="center" valign="middle" >1.00</td><td align="center" valign="middle" >1.00</td><td align="center" valign="middle" >1.00</td><td align="center" valign="middle" >10</td></tr><tr><td align="center" valign="middle" >Avg/total</td><td align="center" valign="middle" >1.00</td><td align="center" valign="middle" >1.00</td><td align="center" valign="middle" >1.00</td><td align="center" valign="middle" >30</td></tr></tbody></table></table-wrap><p>表7. 基于fine tuning技术的分类结果评价表</p><p>2) 选择的网络深度较浅，没有选择合适的优化器。关于CNN的理论知识还要加强学习受硬件条件制约，没有使用更新的RCNN，fast-RCNN技术，只能识别分割好的数据。</p></sec><sec id="s7"><title>基金项目</title><p>国家自然科学基金(编号：41571369)；青海省科技计划项目(编号：2016-NK-138)；科技创新服务能力建设基本科研业务费(科研类) (编号：025185305000/143)。</p></sec><sec id="s8"><title>文章引用</title><p>曹中奇,刘路路,康孝岩,张爱武,柴沙驼. 一种基于卷积神经网络的草地植物识别方法 Grassland Plant Identification Method Based on Convolutional Neural Network[J]. 人工智能与机器人研究, 2018, 07(03): 135-146. https://doi.org/10.12677/AIRR.2018.73016</p></sec><sec id="s9"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.26651-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Wang, L., Abbott, R.J., Zheng, W., et al. (2009) History and Evolution of Alpine Plants Endemic to the Qinghai-Tibetan Plateau: Aco-nitum gymnandrum (Ranunculaceae). Molecular Ecology, 18, 709. 
&lt;br&gt;https://doi.org/10.1111/j.1365-294X.2008.04055.x</mixed-citation></ref><ref id="hanspub.26651-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">李红梅, 马玉寿. 基于GIS技术的青海省草地类型分类研究[J]. 草业科学, 2009, 26(12): 24-29.</mixed-citation></ref><ref id="hanspub.26651-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">马松江. 青海海西草原有毒植物及其经济价值[J]. 草业科学, 2008, 25(5): 98-103.</mixed-citation></ref><ref id="hanspub.26651-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">孙菁, 彭敏, 陈桂琛, 等. 青海湖区针茅草原植物群落特征及群落多样性研究[J]. 西北植物学报, 2003, 23(11): 1963-1968.</mixed-citation></ref><ref id="hanspub.26651-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">魏卫东, 马欣. 青海资源植物黄花铁线莲种子萌发特性研究[J]. 种子, 2008, 27(3): 49-51.</mixed-citation></ref><ref id="hanspub.26651-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">吴玉虎. 青海种子植物特有种及其生态地理分布[J]. 植物分类与资源学报, 2006, 28(4): 327-336.</mixed-citation></ref><ref id="hanspub.26651-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Meyer, G.E. (1998) Machine Vision Detection Parameters for Plant Species Identification. Precision Agriculture and Biological Quality, 3543.</mixed-citation></ref><ref id="hanspub.26651-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Weiss, U. and Biber, P. (2011) Plant Detection and Mapping for Agricultural Robots Using a 3D LIDAR Sensor. Robotics &amp; Autonomous Systems, 59, 265-273. &lt;br&gt;https://doi.org/10.1016/j.robot.2011.02.011</mixed-citation></ref><ref id="hanspub.26651-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Zhao, Z.L., Dorje, G. and Wang, Z.T. (2010) Identification of Medicinal Plants Used as Tibetan Traditional Medicine Jie-Ji. Journal of Ethnopharmacology, 132, 122. &lt;br&gt;https://doi.org/10.1016/j.jep.2010.07.051</mixed-citation></ref><ref id="hanspub.26651-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Reyes, A.K., Caicedo, J.C. and Camargo, J.E. (2015) Fine-Tuning Deep Con-volutional Networks for Plant Recognition. Working Notes of Conference and Labs of the Evaluation Forum (CLEF), 1-9.</mixed-citation></ref><ref id="hanspub.26651-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Krizhevsky, A., Sutskever, I. and Hinton, G.E. (2012) ImageNet Classification with Deep Convolutional Neural Networks. Advances in Neural Information Processing Systems, 1097-1105.</mixed-citation></ref><ref id="hanspub.26651-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Lawrence, S., Giles, C.L., Tsoi, A.C., et al. (1997) Face Recognition: A Convolutional Neural-Network Approach. IEEE Transactions on Neural Networks, 8, 98-113. &lt;br&gt;https://doi.org/10.1109/72.554195</mixed-citation></ref><ref id="hanspub.26651-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">杨心. 基于卷积神经网络的交通标识识别研究与应用[D]: [硕士学位论文]. 大连: 大连理工大学, 2014.</mixed-citation></ref><ref id="hanspub.26651-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">贾世杰, 杨东坡, 刘金环. 基于卷积神经网络的商品图像精细分类[J]. 山东科技大学学报(自然科学版), 2014, 33(6): 91-96.</mixed-citation></ref><ref id="hanspub.26651-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">程嘉晖. 基于深度卷积神经网络的飞行器图像识别算法研究[D]: [硕士学位论文]. 杭州: 浙江大学, 2017.</mixed-citation></ref><ref id="hanspub.26651-ref16"><label>16</label><mixed-citation publication-type="other" xlink:type="simple">Lopatin, J., Fassnacht, F.E., Kattenborn, T., et al. (2017) Mapping Plant Species in Mixed Grassland Communities Using Close Range Imaging Spectroscopy. Remote Sensing of Environment, 201, 12-23.</mixed-citation></ref><ref id="hanspub.26651-ref17"><label>17</label><mixed-citation publication-type="other" xlink:type="simple">Shang, K., Zhang, X., Sun, Y.L., Zhang, L.F., Wang, S.D. and Zhuang, Z. (2015) Sophisticated Vegetation Classification Based on Feature Band Set Using Hyperspectral Image. Spectroscopy and Spectral Analysis, 35, 1669-1676.</mixed-citation></ref><ref id="hanspub.26651-ref18"><label>18</label><mixed-citation publication-type="other" xlink:type="simple">Meyer, H., Lehnert, L.W., Wang, Y., et al. (2017) From Local Spectral Measurements to Maps of Vegetation Cover and Biomass on the Qinghai-Tibet-Plateau: Do We Need Hyperspectral Information? International Journal of Applied Earth Observation &amp; Geoinformation, 55, 21-31. &lt;br&gt;https://doi.org/10.1016/j.jag.2016.10.001</mixed-citation></ref><ref id="hanspub.26651-ref19"><label>19</label><mixed-citation publication-type="other" xlink:type="simple">Lecun, Y., Bottou, L., Bengio, Y., et al. (1998) Gradient-Based Learning Applied to Document Recognition. Proceedings of the IEEE, 86, 2278-2324. &lt;br&gt;https://doi.org/10.1109/5.726791</mixed-citation></ref><ref id="hanspub.26651-ref20"><label>20</label><mixed-citation publication-type="other" xlink:type="simple">Szegedy, C., Ioffe, S., Vanhoucke, V., et al. (2016) Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning. arXiv:1602.07261v2 [cs.CV].</mixed-citation></ref></ref-list></back></article>