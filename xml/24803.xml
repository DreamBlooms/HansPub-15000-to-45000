<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd"><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="3.0" xml:lang="en" article-type="research article"><front><journal-meta><journal-id journal-id-type="publisher-id">CSA</journal-id><journal-title-group><journal-title>Computer Science and Application</journal-title></journal-title-group><issn pub-type="epub">2161-8801</issn><publisher><publisher-name>Scientific Research Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.12677/CSA.2018.85070</article-id><article-id pub-id-type="publisher-id">CSA-24803</article-id><article-categories><subj-group subj-group-type="heading"><subject>CSA20180500000_44663193.pdf</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>信息通讯</subject></subj-group></article-categories><title-group><article-title>
 
 
  基于粒子滤波的视觉目标跟踪算法
  Visual Target Tracking Algorithm Based on Particle Filter
 
</article-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>陈</surname><given-names>思萌</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>邓</surname><given-names>雨</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib></contrib-group><aff id="aff1"><addr-line>null</addr-line></aff><aff id="aff2"><addr-line>中南民族大学电子信息工程学院，湖北 武汉</addr-line></aff><pub-date pub-type="epub"><day>03</day><month>05</month><year>2018</year></pub-date><volume>08</volume><issue>05</issue><fpage>619</fpage><lpage>626</lpage><permissions><copyright-statement>&#169; Copyright  2014 by authors and Scientific Research Publishing Inc. </copyright-statement><copyright-year>2014</copyright-year><license><license-p>This work is licensed under the Creative Commons Attribution International License (CC BY). http://creativecommons.org/licenses/by/4.0/</license-p></license></permissions><abstract><p>
 
 
   
   随着社会智能化的发展，视觉目标跟踪成为计算机视觉领域的研究热点之一。在目标跟踪过程中，由于目标自身及环境的变化使得准确跟踪目标变得十分困难。在基本粒子滤波框架下，本文主要研究了一种基于颜色特征的粒子滤波视觉目标跟踪算法。通过引入核函数的RGB颜色空间对目标进行鲁棒的表达，为了适应跟踪过程中的目标变化，利用实时的观测信息对目标模板进行更新。实验表明，基于颜色特征的粒子滤波算法对光照变化和动态干扰具有较强的鲁棒性。 With the development of social intelligence, visual target tracking has become one of the research hotspots in the field of computer vision. In the process of target tracking, it becomes very difficult to track the target accurately because of the change of the target itself and the environment. In the basic particle filter framework, this paper mainly studies a particle filter visual target tracking algorithm based on color features. By introducing the RGB color space of kernel function to the robust expression of the target, in order to adapt to the target change in the tracking process, the target template is updated with real-time observation information. Experiments show that the particle filter algorithm based on color features has strong robustness to light changes and dynamic interference. 
  
 
</p></abstract><kwd-group><kwd>目标跟踪，粒子滤波，颜色特征, Target Tracking</kwd><kwd> Particle Filter</kwd><kwd> Color Characteristics</kwd></kwd-group></article-meta></front><body><sec id="s1"><title>基于粒子滤波的视觉目标跟踪算法<sup> </sup></title><p>陈思萌，邓雨</p><p>中南民族大学电子信息工程学院，湖北 武汉</p><p>收稿日期：2018年4月18日；录用日期：2018年5月1日；发布日期：2018年5月9日</p><disp-formula id="hanspub.24803-formula28"><graphic xlink:href="//html.hanspub.org/file/6-1541009x5_hanspub.png"  xlink:type="simple"/></disp-formula></sec><sec id="s2"><title>摘 要</title><p>随着社会智能化的发展，视觉目标跟踪成为计算机视觉领域的研究热点之一。在目标跟踪过程中，由于目标自身及环境的变化使得准确跟踪目标变得十分困难。在基本粒子滤波框架下，本文主要研究了一种基于颜色特征的粒子滤波视觉目标跟踪算法。通过引入核函数的RGB颜色空间对目标进行鲁棒的表达，为了适应跟踪过程中的目标变化，利用实时的观测信息对目标模板进行更新。实验表明，基于颜色特征的粒子滤波算法对光照变化和动态干扰具有较强的鲁棒性。</p><p>关键词 :目标跟踪，粒子滤波，颜色特征</p><disp-formula id="hanspub.24803-formula29"><graphic xlink:href="//html.hanspub.org/file/6-1541009x6_hanspub.png"  xlink:type="simple"/></disp-formula><p>Copyright &#169; 2018 by authors and Hans Publishers Inc.</p><p>This work is licensed under the Creative Commons Attribution International License (CC BY).</p><p>http://creativecommons.org/licenses/by/4.0/</p><p><img src="//html.hanspub.org/file/6-1541009x7_hanspub.png" /> <img src="//html.hanspub.org/file/6-1541009x8_hanspub.png" /></p></sec><sec id="s3"><title>1. 引言</title><p>目标跟踪技术最早应用于军事领域，即世界上第一部跟踪雷达站。直到20世纪70年代卡尔曼滤波理论 [<xref ref-type="bibr" rid="hanspub.24803-ref1">1</xref>] 的提出才让目标跟踪真正得到广泛关注。随着计算机技术的发展与科技的进步，视频目标跟踪技术在更广阔的领域得到了应用。视频目标跟踪方法融合了图像处理、模式识别、人工智能等多个领域的研究成果，在军事、工业、科学等 [<xref ref-type="bibr" rid="hanspub.24803-ref2">2</xref>] [<xref ref-type="bibr" rid="hanspub.24803-ref3">3</xref>] [<xref ref-type="bibr" rid="hanspub.24803-ref4">4</xref>] [<xref ref-type="bibr" rid="hanspub.24803-ref5">5</xref>] [<xref ref-type="bibr" rid="hanspub.24803-ref6">6</xref>] 方面具有实用价值及良好的发展前景。</p><p>粒子滤波理论 [<xref ref-type="bibr" rid="hanspub.24803-ref7">7</xref>] [<xref ref-type="bibr" rid="hanspub.24803-ref8">8</xref>] 为非线性、非高斯条件下的跟踪问题提供了解决方法。粒子滤波 [<xref ref-type="bibr" rid="hanspub.24803-ref9">9</xref>] 是一种基于蒙特卡罗仿真实现非线性递推贝叶斯滤波的算法，它使用一组带有权值的随机样本集对后验概率密度进行近似。由于粒子滤波不受线性、高斯分布以及维数的限制，适用于任何状态空间模型，且精度可逼近最优估计，因此粒子滤波拥有广阔的应用前景，也是目标跟踪领域的研究热点之一。</p><p>在视频目标跟踪过程中，目标的姿态变化、光照变化、环境的复杂度等都会对跟踪造成极大的困难。文献 [<xref ref-type="bibr" rid="hanspub.24803-ref10">10</xref>] [<xref ref-type="bibr" rid="hanspub.24803-ref11">11</xref>] 利用目标的边缘、颜色信息来刻画目标特征，提高特征表达的鲁棒性；文献 [<xref ref-type="bibr" rid="hanspub.24803-ref12">12</xref>] 建立自适应模型缓解光照变化对跟踪结果的影响；文献 [<xref ref-type="bibr" rid="hanspub.24803-ref13">13</xref>] 提出一种基于颜色特征的自适应粒子滤波算法，利用颜色分布和模板匹配进行目标跟踪。</p><p>本文主要研究了文献 [<xref ref-type="bibr" rid="hanspub.24803-ref13">13</xref>] 的粒子滤波算法，包括构建动态系统、学习目标的颜色分布、模板更新机制，实现了基于粒子滤波的视觉目标跟踪算法。最后通过模拟实验和真实场景对算法的跟踪性能进行了验证。</p></sec><sec id="s4"><title>2. 基本粒子滤波</title><p>粒子滤波是在理论上可实现最小方差的非线性滤波器，它可以有效处理高维、非线性、非高斯问题，具有很强的灵活性。粒子滤波的思想是用一组带有相关权值的离散随机样本(即粒子)来近似表征目标的后验概率密度函数。首先通过状态转移函数预测粒子可能的状态，再从序列重要性采样中递推得到粒子权值，利用蒙特卡罗仿真由粒子加权估计值来逼近真实的后验概率密度，从而实现递推贝叶斯滤波。</p><p>假设从分布已知的重要性函数 [<xref ref-type="bibr" rid="hanspub.24803-ref14">14</xref>] 中采样得到粒子 x k i ∼ q ( x k | x 0 : k − 1 , z 1 : k ) ，并给每个粒子赋予权值：</p><p>w k i = w k − 1 i ⋅ p ( z k | x k i ) p ( x k i | x k − 1 i ) q ( x k i | x 0 : k − 1 i , z 1 : k ) (1)</p><p>其中， x 0 : k − 1 i 表示第i个粒子在0到 k − 1 时刻的状态， z k 表示k时刻的观测值， p ( z k | x k i ) 为似然函数， p ( x k i | x k − 1 i ) 为粒子的状态转移概率。</p><p>由蒙特卡罗仿真可知，目标的后验概率密度可表示为：</p><p>p ( x k | z 1 : k ) ≈ ∑ i = 1 N w ˜ k i δ ( x k − x k i ) (2)</p><p>其中N表示粒子个数， w ˜ k i 为归一化的重要性权值。</p><p>随着时间推移，粒子在传播过程中极易产生粒子退化现象。对于粒子的退化程度，我们可以用有效采样尺度 N e f f [<xref ref-type="bibr" rid="hanspub.24803-ref15">15</xref>] 来度量：</p><p>N ^ e f f = 1 ∑ i = 1 N ( w ˜ k i ) 2 (3)</p><p>其中 w ˜ k i 为归一化权值。由上式可以看出 1 ≤ N e f f ≤ N ， N e f f 越小退化问题越严重。当权重方差接近于零时便得到最优估计。本文采用文献 [<xref ref-type="bibr" rid="hanspub.24803-ref13">13</xref>] 中的重采样方法，在序列重要性采样的基础上再对粒子集进行N次采样，保留大权值粒子，消除小权值粒子，从而产生新的粒子集 { x 0 : k i * } i = 1 N ，提高样本的有效性，解决粒子退化问题。</p></sec><sec id="s5"><title>3. 粒子滤波视觉目标跟踪算法</title><p>本文主要研究了基于颜色特征的粒子滤波跟踪算法，利用颜色特征表达目标，通过目标模板与候选模板的相似度匹配来计算粒子权值，并实时更新目标模板，实现更加稳定的跟踪。</p><sec id="s5_1"><title>3.1. 视觉特征提取</title><p>本文利用文献 [<xref ref-type="bibr" rid="hanspub.24803-ref13">13</xref>] 中引入核函数的颜色直方图来描述目标的视觉信息。颜色是人类视觉中获取目标信息的主要特征，颜色特征对于目标的旋转、尺度变化都具有较强鲁棒性。本文采用典型的 8 &#215; 8 &#215; 8 RGB颜色空间描述颜色分布。</p><p>在计算目标区域的颜色直方图时，为了更加准确的描述目标的颜色特征，引入一个核函数，</p><p>k ( r ) = { 1 − r 2 ,                   r &lt; 1 0 ,                                               otherwise (4)</p><p>其中r表示距中心点的距离。因为在选取目标时边界像素点很可能属于背景，为了增加颜色模型的可靠性，对离目标中心点远的粒子赋予较小的权值，而距中心点近的粒子赋予较大权值。</p><p>假设所选择目标区域的中心点为 z ( x 0 , y 0 ) ，目标区域内像素的位置为 x i ( x , y ) ，那么此区域的颜色分布 p y = { p y ( u ) } u = 1 , ⋯ , m 可表示为：</p><p>p y ( u ) = f ∑ i = 1 I k ( ‖ z − x i ‖ a ) ⋅ δ [ h ( x i ) − u ] (5)</p><p>式中I表示区域内的像素个数，δ为单位冲击函数，a为自适应变量：</p><p>a = H x 2 + H y 2 (6)</p><p>其中 H x 、 H y 为所选区域的半宽和半高，a会随着区域大小的变化而自适应变化。公式(5)中f为归一化常数，</p><p>f = 1 ∑ i = 1 I k ( ‖ y − x i ‖ a ) (7)</p></sec><sec id="s5_2"><title>3.2. 状态空间模型</title><p>目标跟踪的本质是估计目标的运动状态。为了得到目标状态的估计值，要先建立相应的状态空间模型，对状态空间模型中的参数进行估计，从而得到目标状态，实现目标跟踪。</p><p>状态空间模型是一种表示时间序列的方法，它通过系统的状态向量来描述时间序列的演变，状态向量中包含了所要研究系统的全部相关信息，并通过观测向量来描述与状态相关的噪声观测量。</p><sec id="s5_2_1"><title>3.2.1. 系统状态转移模型</title><p>假设从粒子滤波中采样得到的粒子集 { x 0 : k i } i = 1 N ，每个粒子 x i 可表示如下：</p><p>x i = { x , y , H x , H y } (8)</p><p>其中 x , y 表示粒子位置， H x , H y 表示跟踪框的半宽和半高。</p><p>在动态系统中系统状态转移就是粒子随时间更新的过程，称为粒子传播，服从一阶ARP (Auto-Regressive Process)自回归过程方程：</p><p>x k = C 1 x k − 1 + C 2 w k − 1 (9)</p><p>其中 x k 表示k时刻粒子状态， C 1 、 C 2 为常数， w k − 1 是高斯随机噪声。从上式可以看出，预测k时刻的粒子状态 { x k i } i = 1 N 只与 k − 1 时刻的粒子状态 { x k − 1 i } i = 1 N 和噪声 w k − 1 有关，不需要得到观测值 z k 。</p></sec><sec id="s5_2_2"><title>3.2.2. 观测模型</title><p>将状态转移得到的粒子集 { x k − 1 i } i = 1 N 作为候选模板 p = { p ( u ) } u = 1 , ⋯ , m ，对其进行观测。跟踪过程中每一时刻都会获得新的观测信息 z k ，通过观测值来估计粒子状态。为了衡量候选模板 p ( u ) 与目标模板 q ( u ) 的相似度，定义巴氏距离(Bhattacharyya distance)：</p><p>d = 1 − ρ [ p , q ] (10)</p><p>其中ρ表示巴氏系数(Bhattacharyya Coefficient)，定义如下：</p><p>ρ [ p , q ] = ∑ u = 1 m p ( u ) q ( u ) (11)</p><p>公式(10)表明，巴氏距离d越小两种分布的颜色相似度越高，反之相似度越低。对相似性高的粒子赋予较大的权值，相似性低的粒子赋予较小权值，由此计算每个粒子的权值：</p><p>w i = 1 2 π σ e − d 2 2 σ 2 = 1 2π σ e − 1 − ρ [ p i , q ] 2 σ 2 (12)</p><p>其中i表示第i个粒子( i = 1 , 2 , ⋯ , N )，σ表示协方差，d表示巴氏距离，ρ表示巴氏系数， p i 为第i个粒子的候选模板，q为目标模板。</p><p>由蒙特卡洛仿真可知，最终目标的估计状态为：</p><p>E [ x k ] = ∑ i = 1 N w k i ⋅ x k i (13)</p></sec></sec><sec id="s5_3"><title>3.3. 模板更新</title><p>在跟踪过程中光照、视角、背景等会不断发生变化，为了克服目标和环境变化对跟踪结果的影响，及时地对目标模板进行更新。定义模板更新公式：</p><p>q k = ( 1 − α ) q k − 1 + α p E [ x ] (14)</p><p>其中 q k 表示k时刻的目标模板， p E [ x ] 表示粒子估计状态的颜色直方图，α为更新参数。通过模板更新，在目标模板中不断加入得到的观测信息可以更真实的反应目标状态，从而提高跟踪的精确度。</p></sec><sec id="s5_4"><title>3.4. 粒子滤波目标跟踪流程</title><p>本文主要介绍了基于颜色特征的粒子滤波视觉目标跟踪算法。首先，初始化粒子集 { x 0 i } i = 1 N ，权值为 N − 1 ，并建立目标模板q。通过系统状态转移模型预测k时刻的粒子集 { x k i , N − 1 } i = 1 N ，建立候选模板p。在系统观测阶段，度量候选模板p和目标模板q的颜色分布的相似度，得到粒子权值 { x k i , w k i } ，估计目标状态 E [ x k ] 。再利用重采样算法，得到新的粒子集进入下一帧迭代过程。</p><p>基于颜色特征的粒子滤波视觉目标跟踪算法流程如表1所示。</p></sec></sec><sec id="s6"><title>4. 实验结果</title><sec id="s6_1"><title>4.1. 仿真实验</title><p>假设时间离散的非线性动态系统方程为：</p><table-wrap id="table1" ><label><xref ref-type="table" rid="table1">Table 1</xref></label><caption><title> Particle filter tracking algorithm flow based on color feature</title></caption><table><tbody><thead><tr><th align="center" valign="middle" >基于颜色特征的粒子滤波算法：</th></tr></thead><tr><td align="center" valign="middle" >1.初始化 起始帧 k = 0 ； 设置粒子数N； • 采集第一帧图像，手动选取跟踪目标，建立目标模板q并计算其颜色直方图； • 初始化粒子集 { x 0 i } i = 1 N ； 2.粒子传播 • 通过系统状态转移模型预测粒子集 { x k i , N − 1 } i = 1 N ，并建立候选模板p； 3.系统观测 • 计算候选模板的颜色直方图； • 计算候选模板p与目标模板q间的巴氏距离 来衡量模板间的相似度； • 更新粒子权值 { x k i , w k i } ； 4.目标状态估计 • 估计粒子状态 E [ x k ] ； 5.重采样 • 若 N e f f &lt; N t h r （人为设定阈值） 将 { x k i , w k i } 更新为粒子集 { x k i * , N − 1 } ； • k = k + 1 ； 6.目标模板更新 • q k = ( 1 − α ) q k − 1 + α p E [ x ] ； 7.跳到粒子传播，循环上述过程，直至跟踪完成。</td></tr></tbody></table></table-wrap><p>表1. 基于颜色特征的粒子滤波跟踪算法流程</p><p>x k = x k − 1 2 + 25 x k − 1 1 + x k − 1 2 + 8 cos ( 1.2 ( k − 1 ) ) + v k − 1 (15)</p><p>z k = x k 2 20 + w k (16)</p><p>实验中令 Q k − 1 = 10 ， R k = 1 ，粒子状态初始值 x 0 = 0.1 ，迭代次数 t = 50 ，粒子采样数 N = 100 。图1为粒子滤波在非线性系统下状态估计值与真实值的比较。图中星号表示真实值，曲线表示粒子滤波的估计值。从图1可以看出，粒子滤波基本实现了对真实值的估计，但仍存在一定的偏差，其均方误差 R M S = 5.8874 。</p></sec><sec id="s6_2"><title>4.2. 真实跟踪场景</title><p>本文分别在简单场景和复杂场景下对粒子滤波的跟踪性能进行实验。</p><p>实验视频1：如图2所示，男子匀速从镜头右侧走向左侧，背景没有明显的动态变化，对男子进行跟踪实验。视频序列长度为77帧，帧速率为15帧/秒，图像大小为 240 &#215; 360 。</p><p>实验视频2：如图3所示，飞行器在空中进行左右上下平移，摄像头跟随飞行器拍摄，背景不断变化，环境复杂且存在很多干扰，对飞行器进行跟踪。视频序列长度为213帧，帧速率为15帧/秒，图像大小为 240 &#215; 320 。</p><p>从图2中可以看出，在无干扰、无遮挡的简单静态场景下，粒子滤波可以稳定的跟踪目标。在图3的视频序列中有行人干扰、背景杂乱，且产生光照变化，目标处于复杂的跟踪环境中。本文算法仍能准确跟踪飞行器，中心点也未发生偏移。可见粒子滤波在复杂的非线性非高斯情况下，可以实现稳定跟踪，并且对于动态干扰和光照变化具有较强的鲁棒性。</p></sec></sec><sec id="s7"><title>5. 小结</title><p>本文主要研究了基于颜色特征的粒子滤波跟踪算法，利用颜色直方图描述目标特征，通过模板匹配</p><p>图1. 粒子滤波状态估计</p><p>图2. 简单场景下的粒子滤波跟踪结果</p><p>图3. 复杂场景下的粒子滤波跟踪结果</p><p>计算粒子权值，并实时更新目标模板，以实现更加稳定的跟踪。实验结果表明，本文算法在简单或复杂场景下都能准确地跟踪目标，具有较强的鲁棒性。</p><p>计算粒子权值，并实时更新目标模板，以实现更加稳定的跟踪。实验结果表明，本文算法在简单或复杂场景下都能准确地跟踪目标，具有较强的鲁棒性。</p></sec><sec id="s8"><title>文章引用</title><p>陈思萌,邓 雨. 基于粒子滤波的视觉目标跟踪算法 Visual Target Tracking Algorithm Based on Particle Filter[J]. 计算机科学与应用, 2018, 08(05): 619-626. https://doi.org/10.12677/CSA.2018.85070</p></sec><sec id="s9"><title>参考文献</title></sec></body><back><ref-list><title>References</title><ref id="hanspub.24803-ref1"><label>1</label><mixed-citation publication-type="other" xlink:type="simple">Kalman, R.E. (1961) A New Approach to Linear Filtering and Prediction Problems. Journal of Basic Engineering, Transactions ASME Series, 83, 95-108. &lt;br&gt;https://doi.org/10.1115/1.3658902</mixed-citation></ref><ref id="hanspub.24803-ref2"><label>2</label><mixed-citation publication-type="other" xlink:type="simple">Reid, D.B. (1979) An Algorithm for Tracking Multiple Targets. IEEE Transactions on Automatic Control, 24, 843-854. &lt;br&gt;https://doi.org/10.1109/TAC.1979.1102177</mixed-citation></ref><ref id="hanspub.24803-ref3"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Makris, D. and Ellis, T. (2005) Learning Semantic Scene Models from Observing Activity in Visual Surveillance. IEEE Transactions on Systems Man &amp; Cybernetics Part B Cybernetics A Publication of the IEEE Systems Man &amp; Cybernetics Society, 35, 397-408. &lt;br&gt;https://doi.org/10.1109/TSMCB.2005.846652</mixed-citation></ref><ref id="hanspub.24803-ref4"><label>4</label><mixed-citation publication-type="other" xlink:type="simple">Kausler, B.X., Schiegg, M., Andres, B., et al. (2012) A Dis-crete Chain Graph Model for 3d+t Cell Tracking with High Misdetection Robustness. Computer Vision—ECCV 2012, Springer, Berlin, Heidelberg, 144-157.</mixed-citation></ref><ref id="hanspub.24803-ref5"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Xiang, J., Sang, N., Hou, J.H., Huang, R. and Gao, C.X. (2016) Mul-ti-Target Tracking Using Hough Forest Random Field. IEEE Transactions on Circuits and Systems for Video Technolo-gy, 26, 2028-2042. 
&lt;br&gt;https://doi.org/10.1109/TCSVT.2015.2489438</mixed-citation></ref><ref id="hanspub.24803-ref6"><label>6</label><mixed-citation publication-type="other" xlink:type="simple">侯建华, 黄奇, 项俊, 郑桂林. 一种尺度和方向适应性的Mean Shift跟踪算法[J]. 中南民族大学学报(自然科学版), 2015, 34(1): 83-88.</mixed-citation></ref><ref id="hanspub.24803-ref7"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Arulampalam, M., Maskell, S. and Gordon, N. (2002) A Tutorial on Particle Filters for Online Non-Linear/Non-Gaussian Bayesian Tracking. IEEE Transactions on Signal Processing, 50, 174-188. &lt;br&gt;https://doi.org/10.1109/78.978374</mixed-citation></ref><ref id="hanspub.24803-ref8"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">胡士强, 敬忠良. 粒子滤波算法综述[J]. 控制与决策, 2005, 20(4): 361-365.</mixed-citation></ref><ref id="hanspub.24803-ref9"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Carpenter, J., Clifford, P. and Fearnhead, P. (1999) Im-proved Particle Filter for Nonlinear Problems. IEE Proceedings Radar, Sonar and Navigation, 146, 1-7.</mixed-citation></ref><ref id="hanspub.24803-ref10"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Isard, M. and Blake, A. (1998) Condensation—Conditional Density Propagation for Visual Tracking. International Journal of Computer Vision, 29, 5-28. &lt;br&gt;https://doi.org/10.1023/A:1008078328650</mixed-citation></ref><ref id="hanspub.24803-ref11"><label>11</label><mixed-citation publication-type="other" xlink:type="simple">Isard, M. and Maccormick, J. (2001) BraMBLe: A Bayesian Multiple-Blob Tracker. Proceedings of Eighth IEEE International Conference on Computer Vi-sion, 2, 34-41.</mixed-citation></ref><ref id="hanspub.24803-ref12"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Raja, Y., Mckenna, S.J. and Gong, S. (1998) Tracking and Segmenting People in Varying Lighting Conditions Using Colour. IEEE International Conference on Automatic Face and Gesture Recognition, Nara, 14-16 April 1998, 228-233.</mixed-citation></ref><ref id="hanspub.24803-ref13"><label>13</label><mixed-citation publication-type="other" xlink:type="simple">Nummiaro, K., Koller-Meier, E. and Gool, L.V. (2003) An Adaptive Color-Based Particle Filter. Image &amp; Vision Computing, 21, 99-110. &lt;br&gt;https://doi.org/10.1016/S0262-8856(02)00129-4</mixed-citation></ref><ref id="hanspub.24803-ref14"><label>14</label><mixed-citation publication-type="other" xlink:type="simple">Liu, J.S. and Chen, R. (1998) Sequential Monte Carlo Methods for Dynamic Systems. Journal of the American Statistical Association, 93, 1032-1044. &lt;br&gt;https://doi.org/10.1080/01621459.1998.10473765</mixed-citation></ref><ref id="hanspub.24803-ref15"><label>15</label><mixed-citation publication-type="other" xlink:type="simple">Arulampalam, M., Maskell, S. and Gordon, N. (2002) A Tutorial on Particle Filters for Online Non-Linear/Non-Gaussian Bayesian Tracking. IEEE Transactions on Signal Processing, 50, 174-188. &lt;br&gt;https://doi.org/10.1109/78.978374</mixed-citation></ref></ref-list></back></article>